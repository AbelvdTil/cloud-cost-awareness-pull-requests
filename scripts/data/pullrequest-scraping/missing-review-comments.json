[{"url": "https://github.com/tkhoa2711/terraform-digitalocean.git", "pull_requests": []}, {"url": "https://github.com/zubyranks/terraform-project-lien.git", "pull_requests": []}, {"url": "https://github.com/ta8293077/tf-repo1.git", "pull_requests": []}, {"url": "https://github.com/apfm-actions/terraform-lambda-action.git", "pull_requests": []}, {"url": "https://github.com/MiravAcademy/terraform-app-module.git", "pull_requests": []}, {"url": "https://github.com/stealthHat/k8s-terraform.git", "pull_requests": []}, {"url": "https://github.com/MH4GF/terraform-aws.git", "pull_requests": [{"url": "https://github.com/MH4GF/terraform-aws/pull/9", "comments": ["tfsec check aws-sns-enable-topic-encryption failed. \n\nResource 'aws_sns_topic.ort-alert-us-east-1' defines an unencrypted SNS topic.\n\nFor more information, see:\n\n- https://tfsec.dev/docs/aws/sns/enable-topic-encryption#aws/sns\n- https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/sns_topic#example-with-server-side-encryption-sse\n- https://docs.aws.amazon.com/sns/latest/dg/sns-server-side-encryption.html\n"]}, {"url": "https://github.com/MH4GF/terraform-aws/pull/8", "comments": ["tfsec check aws-cloudtrail-enable-at-rest-encryption failed. \n\nResource 'aws_cloudtrail.ort' does not have a kms_key_id set.\n\nFor more information, see:\n\n- https://tfsec.dev/docs/aws/cloudtrail/enable-at-rest-encryption#aws/cloudtrail\n- https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/cloudtrail#kms_key_id\n- https://docs.aws.amazon.com/awscloudtrail/latest/userguide/encrypting-cloudtrail-log-files-with-aws-kms.html\n", "tfsec check aws-cloudtrail-enable-log-validation failed. \n\nResource 'aws_cloudtrail.ort' does not enable log file validation.\n\nFor more information, see:\n\n- https://tfsec.dev/docs/aws/cloudtrail/enable-log-validation#aws/cloudtrail\n- https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/cloudtrail#enable_log_file_validation\n- https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-log-file-validation-intro.html\n", "tfsec check aws-s3-enable-bucket-encryption failed. \n\nResource 'aws_s3_bucket.ort-aws-log' defines an unencrypted S3 bucket (missing server_side_encryption_configuration block).\n\nFor more information, see:\n\n- https://tfsec.dev/docs/aws/s3/enable-bucket-encryption#aws/s3\n- https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket#enable-default-server-side-encryption\n- https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucket-encryption.html\n", "tfsec check aws-s3-enable-bucket-logging failed. \n\nResource 'aws_s3_bucket.ort-aws-log' does not have logging enabled.\n\nFor more information, see:\n\n- https://tfsec.dev/docs/aws/s3/enable-bucket-logging#aws/s3\n- https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket\n- https://docs.aws.amazon.com/AmazonS3/latest/dev/ServerLogs.html\n", "tfsec check aws-s3-enable-versioning failed. \n\nResource 'aws_s3_bucket.ort-aws-log' does not have versioning enabled\n\nFor more information, see:\n\n- https://tfsec.dev/docs/aws/s3/enable-versioning#aws/s3\n- https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket#versioning\n- https://docs.aws.amazon.com/AmazonS3/latest/userguide/Versioning.html\n", "\u30b3\u30f3\u30bd\u30fc\u30eb\u4e0a\u3067CloudTrail\u304b\u3089S3\u306b\u7d10\u4ed8\u3051\u308b\u969b\u306b\u81ea\u52d5\u3067\u4ed8\u4e0e\u3055\u308c\u305f\u30d0\u30b1\u30c3\u30c8\u30dd\u30ea\u30b7\u30fc\u3067\u3059\u3002", "tfsec check aws-s3-enable-bucket-encryption failed. \n\nResource 'aws_s3_bucket.ort-aws-log' defines an unencrypted S3 bucket (missing server_side_encryption_configuration block).\n\nFor more information, see:\n\n- https://tfsec.dev/docs/aws/s3/enable-bucket-encryption#aws/s3\n- https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket#enable-default-server-side-encryption\n- https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucket-encryption.html\n", "tfsec check aws-s3-enable-bucket-logging failed. \n\nResource 'aws_s3_bucket.ort-aws-log' does not have logging enabled.\n\nFor more information, see:\n\n- https://tfsec.dev/docs/aws/s3/enable-bucket-logging#aws/s3\n- https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket\n- https://docs.aws.amazon.com/AmazonS3/latest/dev/ServerLogs.html\n", "tfsec check aws-s3-enable-versioning failed. \n\nResource 'aws_s3_bucket.ort-aws-log' does not have versioning enabled\n\nFor more information, see:\n\n- https://tfsec.dev/docs/aws/s3/enable-versioning#aws/s3\n- https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket#versioning\n- https://docs.aws.amazon.com/AmazonS3/latest/userguide/Versioning.html\n", "tfsec check aws-s3-enable-bucket-logging failed. \n\nResource 'aws_s3_bucket.ort-aws-log' does not have logging enabled.\n\nFor more information, see:\n\n- https://tfsec.dev/docs/aws/s3/enable-bucket-logging#aws/s3\n- https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket\n- https://docs.aws.amazon.com/AmazonS3/latest/dev/ServerLogs.html\n"]}]}, {"url": "https://github.com/JamesWoolfenden/terraform-aws-codebuild-container.git", "pull_requests": []}, {"url": "https://github.com/nikkaushal/terraform-payment.git", "pull_requests": []}, {"url": "https://github.com/dannysievers/gcp-project.git", "pull_requests": []}, {"url": "https://github.com/thomastodon/jabujabu.git", "pull_requests": []}, {"url": "https://github.com/hmcts/launchdarkly-terraform.git", "pull_requests": [{"url": "https://github.com/hmcts/launchdarkly-terraform/pull/97", "comments": ["Generally you should have a team project not a microservice one.\r\n\r\nI'd suggest this:\r\n```suggestion\r\n    name          = \"bulk-scan\"\r\n    display_name  = \"Bulk Scan\"\r\n    azuread_group = \"dcd_group_bulkscan_v2\"\r\n```"]}, {"url": "https://github.com/hmcts/launchdarkly-terraform/pull/83", "comments": ["this is an ms365 group not a security group which breaks the provider v2.\r\n\r\nI checked with PIP and they didn't end up using LD"]}, {"url": "https://github.com/hmcts/launchdarkly-terraform/pull/49", "comments": ["```suggestion\r\n    azuread_group = \"DTS Publication and Information\"\r\n```"]}, {"url": "https://github.com/hmcts/launchdarkly-terraform/pull/35", "comments": ["these don't appear to be included so not sure why you are excluding", "deleted them. They are redundant "]}, {"url": "https://github.com/hmcts/launchdarkly-terraform/pull/30", "comments": ["is this better?\r\n```suggestion\r\n  displayName: 12am every Sunday \r\n```", "```suggestion\r\n  displayName: Weekly Sunday\r\n```", "```suggestion\r\n    - master\r\n```", "modified", "modified", "this doesn't appear to be called?", "deleteuser $id\r\nUSED IN LINE 21/27/36", "o right missed the closing brace", "I think we can just exit from here?\r\n```suggestion\r\n      deleteuser $id\r\n      exit 0\r\n```"]}, {"url": "https://github.com/hmcts/launchdarkly-terraform/pull/29", "comments": ["this should just be your regular team group", "Ah this one? \r\ndcd_group_wa_v2                              cdeb331b-adfe-46a7-a2c8-a628e2d35d96\r\n\r\nwill update", "I notice some of the other teams e.g. sscs are using their ld group obj id which is why I used the one from `dcd_group_ld_wa_v2` above.", "yes, that's legacy. the docs should all say team group now"]}, {"url": "https://github.com/hmcts/launchdarkly-terraform/pull/28", "comments": ["this creates a project for us, I don't think we need that?"]}, {"url": "https://github.com/hmcts/launchdarkly-terraform/pull/26", "comments": ["`A team Azure Active Directory group usually is set up when you join, but if you don't have one ask the Platform Operations team to create it for you.`"]}, {"url": "https://github.com/hmcts/launchdarkly-terraform/pull/8", "comments": ["i don't think this should be needed atm? you aren't using azure, I would have thought the backend and provider are independent", "The provider is required to fetch the launchdarkly_access_token from the KV. "]}, {"url": "https://github.com/hmcts/launchdarkly-terraform/pull/6", "comments": ["the subscription ID shouldn't be hardcoded here, it should go in the pipeline config", "don't leave commented out code in please, either fix or remove", "this is not correct, we should use the default environments that launch darkly provides, production and non prod I believe.\r\n\r\nAAT is not what we've agreed so far as we want AAT to always have the same configuration as prod.", "is this useful to add?", "Please remove all the blank lines below", "This shows us in the launchdarkly portal what resources are being created via terraform. It is also recommended by launchdarkly as best practice. ", "Removed", "Switched back to default envs; Production and Test, however, i've defined them in the configuration so that we have further control if we require any changes. "]}]}, {"url": "https://github.com/sailthru/terraform-kubernetes-ambassador.git", "pull_requests": [{"url": "https://github.com/sailthru/terraform-kubernetes-ambassador/pull/15", "comments": ["should probably remove this from the variables.tf file"]}, {"url": "https://github.com/sailthru/terraform-kubernetes-ambassador/pull/7", "comments": ["I think we'll need to ignore the replica count on the deployment, as this is something the pod autoscaler will adjust. E.g:\r\n\r\n```\r\nlifecycle {\r\n  ignore_changes = [spec.0.replicas]\r\n}\r\n```\r\n\r\nUnfortunately that probably means we'd have to either always enable the autoscaler, or create a separate version/copy of the deployment which has the ignore_changes. Keen for feedback on this!", "I'm thinking I'll just always enable autoscaling and set the default min/max pods to 1/1 - this should make it the same as the existing behaviour.", "Not sure I understand, are we not just turning on autoscaling for ambassador? I think it would feel cleaner to have it enabled with min/max set to 1/5.\r\n\r\nYes will probably have to add the ignore replicas (like kinesis-autoscaler?)", "`ignore_changes` can't be set dynamically in terraform, so it's not very easy to get the `autoscaling_enable` var to work without creating a whole separate deployment with the `ignore_changes` directive in it. I was originally hoping to be able to make this change in a way that was backwards compatible, but I think it'll be a lot easier if I just enable autoscaling by default.\r\n\r\nHave added another commit which does the above, and also sets the default min/max pods to 3 and 6 respectively (that way we'll be able to get one per availability zone)."]}]}, {"url": "https://github.com/tooxie/terraform-workshop.git", "pull_requests": []}, {"url": "https://github.com/deptno/terraform-aws-modules.git", "pull_requests": []}, {"url": "https://github.com/beaulabs/terraform_aws_ec2_instance.git", "pull_requests": []}, {"url": "https://github.com/aws-observability/aws-otel-test-framework.git", "pull_requests": [{"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/1627", "comments": ["Can we keep the image to - public.ecr.aws/aws-otel-test/adot-collector-integration-test integ test image itself as in by default to pick the latest test image. Not a strong reason though, just a preference", "done"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/1509", "comments": ["observationInterval=1000 should we have observation interval configurable.", "nit: this could be replaced by an early return.", "same here.", "this simplifies things a bit. Should we add an warning/raise an exception in case the emitter function is not able to complete in less than 1s? Otherwise the ingestion rate will not be correct right?", "I think you need to fix this as well no? this needs to be scheduled every second and emitter should emitt the rate number of spans?", "Why is this no longer configurable? ", "Doesn't changing the scrape interval affect performance? Why is this change necessary?", "I think as sample app, providing configurable observationInterval is good, but in load generator context and how it is used through test-framework; I think it would be unused functionality and could create problem as well. ", "Updated.", "Updated.", "Raphael, in my opinion, this is already fixed. works little differently than metrics. nextdatapoint is called no of rate times, which produces that many traces in a second, which gets batched and exported at 1s frequency. ", "I think, for load gen its not required to be configured, as we have TPS (100, 1000, 5000) batched at 1s. Adding flush_interval just adds unused complexity. \r\nhttps://github.com/aws-observability/aws-otel-test-framework/pull/1509#discussion_r1416328784", "yes it should affect performance by factor of 15. This is to match the metric load as mentioned in the performance report.", "Reverted. Will pull into separate PR as discussed.", "I am unsure how to implement this. `scheduleAtFixedRate` only throws these three exceptions:\r\n\r\n> RejectedExecutionException \u2013 if the task cannot be scheduled for execution\r\n> NullPointerException \u2013 if command or unit is null\r\n> IllegalArgumentException \u2013 if period less than or equal to zero"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/1474", "comments": ["do you still need to specify `\"AWS_REGION=us-west-2\"` if we use `envVariables` for determining the region dynamically?", "Good catch, it's not needed now.", "In the spirit of leaving things better than what you found, could you create a base class that has most of the logic for initializing the collector?", "boolean flags for behaviour is a code smell. You could make the trace id generator a static property of this test class and then pass it as parameter to each method. It is more explicit than `true` and `false`.", "why do you need this dependency?", "if you use the alpha bom, you don't need to specify the version in any of the opentelemetry dependencies with gid `io.opentelemetry`", "I don't think you need this dependency as you are testing just traces.", "I would prefer to implement a retry so that this code can run as fast as possible.  Example: https://github.com/aws-observability/aws-otel-test-framework/blob/terraform/adot-testbed/app/src/test/java/software/amazon/adot/testbed/LogsTests.java#L249", "Added retry", "Removed", "Removed", "Addressed", "Moved all container initialization to base class.", "changed to alpha bom"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/1472", "comments": ["We can remove this file.", "We may not need this comment here i think", "```suggestion\r\n    log_group_name: \"/aws/ecs/otlp/${testingId}/logs\"\r\n```\r\n\r\nlog group can be something like", "```suggestion\r\n    logGroupName = String.format(LOGGROUPPATH, context.getTestingId());\r\n```", "```suggestion\r\n  protected String logStreamName = \"otlp-logs\";\r\n  \r\n  private static final String LOGGROUPPATH = \"/aws/ecs/otlp/%s/logs\";\r\n```", "Then we need to change it in CWLogValidator as well. How would I get the testingId there?", "Suggested those changes ", "Why have you disabled the metrics exporter?", "```suggestion\r\n      docker-compose -f ${local.docker_compose_path} build\r\n```\r\n\r\nThis was only needed for local builds. We can use the cache normally. ", "nit: This method of building the log group name introduces a strong coupling between the terraform test and the validator. It requires the config to use this exact log group name format. Instead it could be better if the validator is provided the log group and stream name at launch. ", "Why do we call the sample app during init? Should we be calling the sample app each retry attempt instead?", "Don't use `String` class for logging. Use methods such a `log.info()` or `log.error()`.", "Where do these values get populated from? Are they present in the context?", "I was getting a log error stating that I should add this. I'll try rerunning without and see what happens. ", "This would probably break other test cases that may require metrics to be emitted. I would not over analyze the logs in the sample app. ", "As in I should add it as an environment variable or have it as a variable established at runtime? Also, looking at other validators, it seems they establish the log group name in a similar fashion. For example for ContainerInsightECSPrometheus Validator, it is established by\r\n`logGroupName =\r\n        String.format(\r\n            \"/aws/ecs/containerinsights/%s/%s\",\r\n            context.getCloudWatchContext().getClusterName(), \"prometheus\");`\r\nDoes this not have a coupling issue between the tf test and validator?", "Looking at other validators, it seems it is being called in the validate() method, but not in the retry helper(also, I don't think it should be in a retry because calling the sample app uses retry helper on its own right, which would be redundant). I'll move the callSampleApp() to validate() method. ", "Just to clarify, you are saying to use log.error() in place of throwing exception?", "I believe they are being populated from the actual log message. The goal wasn't to test that the values matched up, rather, to confirm that there were these fields present in the actual log message. ", "Yes, there is a coupling there also. You don't need to address this comment now. ", "Ahhh, ignore this comment. I missed that this was being thrown in an exception. my apologies. ", "How will the test case know to fail if it reaches this logical block? Nothing is returned back to the calling function to indicate a failure.\r\n\r\nIt would be much better if you added some unit tests for this new validator class where we could mock out some scenarios. ", "Tests passed, but got this error message in cloudwatch:\r\n`[otel.javaagent 2023-10-31 16:59:10:056 +0000] [OkHttp http://127.0.0.1:4317/...] ERROR io.opentelemetry.exporter.internal.grpc.GrpcExporter - Failed to export metrics. Server responded with UNIMPLEMENTED. This usually means that your collector is not configured with an otlp receiver in the \"pipelines\" section of the configuration. If export is not desired and you are using OpenTelemetry autoconfiguration or the javaagent, disable export by setting OTEL_METRICS_EXPORTER=none. Full error message: unknown service opentelemetry.proto.collector.metrics.v1.MetricsService`\r\nSo, what do you think? Keep it or get rid of it?", "Just leave it. You are adjusting the default template for all ecs test cases. Other test cases may require that, there is a large blast radius in that template. ", "That is an error from the sample app because the collector does not start an OTLP metrics receiver in your test case", "You don't need this. Your entire validator factory should be tested when you call `runValidation()`. \r\n\r\nSee [here](https://github.com/aws-observability/aws-otel-test-framework/blob/efb8515bd27d154787067c8a016fd8ddafbdfd7d/validator/src/test/java/com/amazon/aoc/validators/CWMetricValidatorTest.java#L59) on how the unit test should behave on good data..aka the validation passes. \r\nSee [here](https://github.com/aws-observability/aws-otel-test-framework/blob/efb8515bd27d154787067c8a016fd8ddafbdfd7d/validator/src/test/java/com/amazon/aoc/validators/CWMetricValidatorTest.java#L121) on how the unit test should behavior when it handles bad data...aka the validation fails. ", "Can we use a more descriptive test case name? Why do we expect this log to fail? ", "\n```suggestion\n```\nThese assertions should not be required. No exception being thrown indicates the test case is passing right? ", "How long does this test case take to run? Does it continue to cycle through all of it's retry attempts before it fails?  If it does, we need a way to initialize a CW Log validator where we can pass in the retry attempts and/or duration of retry wait time. \n\nBasically, these unit tests should run fast. ", "\n```suggestion\n  EXPECTED_LOG_NOT_FOUND(50013, \"expected log not found\"),\n```", "No, the retry number is set to 1, so it takes all the tests milliseconds to run", "Ahh, I see. \ud83d\udc4d "]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/1471", "comments": ["Do we need this anymore since we are not updating sample app to al2023?", "What is this default changing? For the sample app or the collector? Either way, I don't think we should change the default. ", "We dont need them but it does not change any behavior on Al2022. Skipping from using `amazon-linux-extras` will make sure the future engineer not face the same issue when they try to upgrade the sample app instances to AL2023", "This didn't even work though right? There were additional issues on top? I would prefer to just remove this if it's not necessary. You can leave it as a comment if you'd like. ", "The collector. But yeah, I agree. I changed default back to AL2022", "They worked but there were additional issues relating to docker login. Okay, I have reverted the changes.", "So the original command was wrong? Or are they different? ", "oops, fixed it"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/1468", "comments": ["Why is this sleep required? And why is to so long? If this is really required then I would expect a comment describing its necessity. ", "It is really not required, please ignore, removed it"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/1427", "comments": ["nit: with [PrintWriter](https://docs.oracle.com/javase/8/docs/api/java/io/PrintWriter.html) you will be able to use the `println` method and will not need to append line break `\\n`.", "do you need this since your method has a `throws Exception`? to simplify the code, I think you don't need to catch this exception here.", "why do you need this sleep? `collector.stop()` will block until the container is fully stopped and `validateLogs` will guarantee that you got the content that is expected.", "why this sleep? isent' `createAndStartCollector` going to wait for the collector to be fully started?", "you van validate the log entries so far here so that you don't need to add a sleep. that will block in a safe way before you move with the rest of the tests.", "again, I don't see a reason for sleeping here ", "https://luzkan.github.io/smells/flag-argument", "why don't you always pass as parameter to this method a list of InputStreams?", "you are not using this exporter. should you delete it?", "why start_at: beginning?", "Yeah, the collector is waiting till start but not until the file log receiver is watching. Because in this test case here the log file to parse is created after the collector is started.", "I agree that validation can be done, but the thread here is making sure to give enough time for the file operations to be done. So even if we do the validation without the thread, since the log file is not generated it would lead FileNotFoundException.", "This thread can be removed, i was playing very safe i think in my local testing. Removed this one", "Agreed, added a check within the method, to let it decide", "True, it is removed", "How does test parallelism work with the framework we are using? Does having these in the Class scope have a potential to cause conflicts if test cases are ran in parallel? ", "Why sleep here?", "Why is flush called inside the try block here but outside of it on line 144?", "Why do we need to validate logs twice? Could we run through the `start -> write -> stop -> write -> start -> stop` cycle then validate once? ", "Is writing to the file a blocking operation? Why do you need to wait? What file operations are you referring to?", "Let's be more thoughtful about what we are printing to std out. We should only need to print if there is a failure. And in the case of the failure it should be descriptive to tell us what was expected and what was actually given. ", "ok, I got it for this one. it is because you are not using read from start. Makes send.", "what operations needs to be done? ", "this is still the boolean flag behaviour disguised.....\r\n\r\nmy suggestion was to change the function signature to use\r\n\r\n```    void validateLogs(String testLogStreamName, List<InputStream> inputStreams) throws Exception {```\r\n\r\nAnother option is to create two functions, one that should only be used for resources paths and another that is used only for local paths. \r\n", "validate is behaving like a sleep here. we need to make sure that logs were read before stopping the collector. ", "I agree, modified", "Simplified as suggested.", "Oh, now I see the suggestion. Modified.", "Sure, I have added it for easy lookout on whats' validated. if we should only need to print during failure then the assertions will log the actual/expected when in failure, removed the print statements", "Actually no specific reason, modified .", "File operations i meant here are to create and write data to File A etc. it takes considerable time for creating and writing to file.\r\nSo without the thread.sleep the collector is not able to parse log line, since it seems the file testlogA.log didn't have the line written to it yet.\r\n\r\n```\r\n        java.lang.AssertionError: \r\n        Expecting actual:\r\n          [\"Message in renamed file - line 1\",\r\n            \"Message in renamed file - line 2\",\r\n            \"Message in renamed file - line 3\"]\r\n        to contain exactly in any order:\r\n          [\"Message in File A\",\r\n            \"Message in renamed file - line 1\",\r\n            \"Message in renamed file - line 2\",\r\n            \"Message in renamed file - line 3\"]\r\n        but could not find the following elements:\r\n          [\"Message in File A\"]\r\n```", "I have tried running with `./gradlew test --rerun-tasks --info --parallel` to have optimal number of threads to use no conlicts were seen. We are also using specific path/file within the directory so parallel wouldn't be a problem IMO", "The sleep is similar as [here](https://github.com/aws-observability/aws-otel-test-framework/pull/1427#discussion_r1356420926), its just to wait for the collector to start watching the file.", "that is why I suggested that you add a `validateLogs` instead of a `Thread.sleep` to validate only \"Message in File A\". It will block until the lines are sent to cwlogs. This will guarantee that it is safe to continue with the tests.", "Committed the changes.", ">we need to make sure that logs were read before stopping the collector.\r\nI tend to agree with that. After changes now it is doing - `start -> write -> validate->stop -> write -> start -> stop` and then it validates again.", "I bet this could be removed and the tests would still succeed. "]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/1426", "comments": ["can you update all the configurations to set the retention period to a small value like 7 days?", "We should also use a more descriptive log group and log stream name to make troubleshooting easier. ", "Consider adding a unique identifier for the test run for each log stream. ", "Why `raw_log` set to true?", "What does this do? ", "What are the local credentials for? ", "Why do we default to the latest from integration test? If test_image I think we could default to the latest production image instead. ", "Why does `4317` need to be exposed here?", "I do not like this fallback. There is a chance secrets may be mounted in the environment and I would not like them present in the container if they do not have to be. ", "Only mount the environment variables you actually need.", "There is a very tight coupling in the validation between the log file name and the stream it expects it in. We should reduce this coupling or clearly document it. \r\n\r\nFor example: `The validation logic expects logs to be in the same log stream as the file name`. \r\n\r\nI think this is bad though. What happens if two instances of these test are ran at the same time. Both will write to the same log stream and log group. This could cause transient failures or even worse, false successes. Each test case should write to a log stream name that is unique to it's test case. ", "acutally logName there meant to be log stream name. Sorry for the confusion changed the usage of variable name.", "Seems to me exposing port for the collector just as part of POC, for any sample app to send otlp. but I think we can remove it if we want to.", "Yeah, the idea is to use the test image from the CI ones if not specified, as we usually default to test image in the rest of the test framework repo. It is not necessary to be the integ test image though, even for rest of the framework.", "Agreed, added unique identifier", "We can use the system property to provide credentials from the local terminal, the command would be something like `./gradlew -Dadot.testbed.localcreds=\"/Users/user/.aws\" test --rerun-tasks --info`.  [at this point](https://github.com/aws-observability/aws-otel-test-framework/pull/1426/files#diff-b6b213810cf9bd4029972a83c70ccf32f71e4f4eb1e32cc5b6b90dd5bcf7961aR77) it would mount similar to `~/.aws:/root/.aws`. ", "We would need the credentials to mount into the container for use in the collector. The idea here is if the system property was not set, then collector will get creds from the [local env like here](https://github.com/aws-observability/aws-otel-test-framework/pull/1426/files#diff-c6a9ad1ffe59a3efeb6ff938e2ce60dfe900c717f4cd85c1eab3f6a71a530eedR7-R10). Yes I will look further to only get required env - (AWS_REGION, AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_SESSION_TOKEN) if that is the suggestion.", "In Terms of validation purpose. It makes it easy as it would just export as is that is parsed from log file and also have one log entry per line .", "you need to setup the credentials otherwise the testbed will not be able to access cw logs.", "can you switch to type library so that we don't need to define an application section with a main class?", "session token is optional. so you should only inject this variable if it is not null.", "yes, lets remove it if it is not being used.", "is the intent to run the testbed tests here?", "the default image should be the prod image if we want to run the tests in this repository.", "In this PR build I am excluding the test part. I think we wont be needing creds for the build part. just to catch for any build failures", "Agreed", "makes sense.", "resolving as we will not run the test", "This is an interesting idea though. Should we add a workflow in this repository to run the tests against the latest version of the collector? It would act as an integration test. I wish we could do it at PR time but I wouldn't love introducing credentials into the PR workflow. ", "Agreed", "Agreed", "Yes, removed the port for now", "you forgot to remove line [64](https://github.com/aws-observability/aws-otel-test-framework/pull/1426/files#diff-b6b213810cf9bd4029972a83c70ccf32f71e4f4eb1e32cc5b6b90dd5bcf7961aR64)  since you are optionally injecting the `AWS_SESSION_TOKEN` on line 66.", "Consider renaming `uniqueLogStreamName`. Log streams must be unique anyways as a [requirement](https://docs.aws.amazon.com/AmazonCloudWatchLogs/latest/APIReference/API_CreateLogStream.html). This also doesn't provide any context on why you would want to use unique log streams for these tests. `createAndStartCollector` is and IMO should be generic. Log stream uniqueness for the test case is a constraint for our tests to execute properly. ", "Is this required? I am not Java expert, apologies. ", "Please remove this logging exporter. It will just create noise in the CI. Viewing the CW Logs for this should be easy enough where we don't have to rely on the logging exporter. ", "Yes, more of this existence is to help in local testing to observe whether the logs exported or not. Removed from pipeline.", "Renamed the usage", "It is not required, yes. removed it .", "Do we need to do an inverse assertion also? \r\n```suggestion\r\n                assertThat(messageToValidate.containsAll(lines)).isTrue();\r\n                assertThat(lines.containsAll(messageToValidate)).isTrue();\r\n```", "We could also validate that their size is the same. This would ensure that no extra logs were went. We expect 1:1 correct?", "yes that's correct it can also be like - assertThat(receivedMessages).containsExactlyInAnyOrderElementsOf(lines); added assertion."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/1425", "comments": ["will this work for any AMI?", "The sample app and mock server is only launched on AL2023 instance. Previously it was on AL2022. So this should be fine", "Are these issues only present for the sample and mocked server host? Why not just use AL2 for sample app and mocked server then?", "We only care about testing the collector on AL3.", "True but AL2 will reach End of Life on 2025-06-30 so we have to upgrade then to AL3. So wanted to tackle 2 birds with 1 stone. ", "Should we [install](https://github.com/lando/lando/issues/3326#issuecomment-1625339749) instead of symbolic link?", "I marked it as a second solution in case any issues come up for symbolic linking. ", "Update: The referred solution is better so changed it."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/1419", "comments": ["```suggestion\r\n            System.out.println(LOCAL_CREDENTIALS);\r\n```\r\nWhat credentials are these printing? Can we remove this if it was just for debugging? ", "this is the path for the file containing the credentials. nonetheless, there is no reason for printing it."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/1369", "comments": ["The name is a bit confusing but `update-types` is a list of update types to ignore. So we would want `version-update:semver-major` here. See dependabot docs [here](https://docs.github.com/en/code-security/dependabot/dependabot-version-updates/configuration-options-for-the-dependabot.yml-file#specifying-dependencies-and-versions-to-ignore). ", "Also, this tabbing does not look correct. ", "does this need to be indented or is it already? I can't tell ", "Oh yes yes, it is indented in my IDE. double checked and recommited\r\n\r\n![image](https://github.com/aws-observability/aws-otel-test-framework/assets/41936996/f5752d7d-e522-4ec6-969a-125513a10e59)\r\n\r\n"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/1367", "comments": ["```suggestion\r\n```", "This needs to be removed. I had committed the change already but it looks like you force pushed over it. Next time pull changes down from your branch before force pushing. \r\n", "In hindsight, I should not have committed the changes myself. I will not do that in the future, in my head this would have made it easier for you but I see how it could be confusing. ", "> This needs to be removed. I had committed the change already but it looks like you force pushed over it. Next time pull changes down from your branch before force pushing.\r\n\r\nI agree with that yes. I shall take latest on the branch."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/1356", "comments": ["Now that I changed the collection of spans from a set to a list, do you mind changing this variable name to something else like `spanList`?", "done"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/1353", "comments": ["If you have this test here, why are you not instantiating the factory so that `create` returns `null` [here](https://github.com/aws-observability/aws-otel-test-framework/pull/1353/files#diff-d564e22ddf81aaa52b4b0ab7244be15864537545edb3538499eba3f27bebf03dR169).", "Good point, I wasn't sure if this was the correct behavior when I was creating this PR. I have moved all the empty checks into `create()`. "]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/1347", "comments": ["```suggestion\r\n    version: \"1.23\"\r\n```", "```suggestion\r\n    version: \"1.23\"\r\n```", "ty, trying to do too many things at once right now. "]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/1330", "comments": ["Can this be changed to aoc_otlp", "I will change that when I bring in changes from `terraform` branch in a separate PR. "]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/1322", "comments": ["super nit: all the rest of the parameters don't use camel case. can we keep the consistency?", "nit: since the test class is in the[ same package ](https://github.com/aws-observability/aws-otel-test-framework/pull/1322/files#diff-5f739c96e0ac9d4a16c6a1bc6fceb2b4f2589bbaa730864035f2cc42bec791ebR1)as this one and this constructor is only intended to be used for tests, you can remove the `public` visibility modifier so that this constructor can only be visible in the tests. ", "do you still need this? ", "no, that was a miss from a previous implementation. "]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/1303", "comments": ["```suggestion\r\n  COLLECTOR_ID_NOT_MATCHED(50011, \"span collector-id attribute does not match\"),\r\n```", "Creating a method just for unit testing does not seem right. I think there is probably another way to go about this. Possibly change the Class `init` method to accept an `XRayService` object. ", "This class shares a lot of functionality as `TraceValidator.java`. That functionality should be abstracted away into where duplicate bits of logic can be shared.", "I'm not sure this comment makes sense. What is being retried twice?", "I'm not sure if this comment or method name makes sense. The purpose of the method is to call the sample app right? Maybe consider renaming the method. It's still okay to return the traceid but that should be documented in method about its return value.", "Why is this being stored in a list? Isn't this a single trace id? ", "Rogue semicolon?", "I'm not sure we need to log this. \r\n\r\nnit: We should be careful about the logging we add in the validator. It can create messy and large log outputs in the github workflow where it is normally called. Later on in this method we log the entire trace which includes the trace id. ", "Same comment here about logging to aggressively. I don't think this is needed.", "```suggestion\r\n                    .filter(s -> s.endsWith(\"collector-id\"))\r\n```\r\nWhy `endsWith` here? Is it due to how the trace keys are mapped? What's the full name for this key? ", "nit: lets extract this into into it's own method. Something like `checkSpanCount`.", "nit: Instead of setting this to `null` you could set it to the first value in your collection. Then iterate from `1 to N`. ", "nit: this log line does not seem necessary. ", "Does XRayService allow us to query by a single trace id instead of a collection of them?", "Again, the use of a list here does not make sense. We are always returning the first set of segments. ", "nit: If we are going to use `loadbalancing` here we should rename the validator to `LoadBalancingValidator`.", "missing EOF new line.", "Having to manually escape JSON strings is a painful developer experience. Let's find another way to provide this mocked trace JSON. Possibly a testdata json file or some type of raw string if java supports it. ", "```suggestion\r\n  /** test validation when fails due to different collector ids */\r\n```", "I don't think this comment is necessary. Your test name does a good job of explaining what the test does. ", "Is this actually required to be set for the trace validator tests? ", "If we could use validator with jdk17, we could use multiline strings and therefore no scaping would be needed.\r\n\r\nI did a bit of research and other solutions include using hashmaps to build the json https://www.baeldung.com/java-org-json#1-creating-jsonarray\r\n\r\nno good solution here :(", "this is actually a common pattern in Java https://timkranen.medium.com/using-visiblefortesting-to-test-your-private-functions-c9e511fd1c2a but many people don't like.\r\n\r\nI think Bryan is right here. You could overload the init method and create a version that accepts a XrayService as parameter.", "Can we just read in and deserialize from a `.json` file instead? ", "Changed in my next commit.", "Hmm does this mean we would have to change the CWMetricValidator as well?  In the CWMetricValidator class, it has a [method](https://github.com/aws-observability/aws-otel-test-framework/blob/35a8e23ee4fb81c5d69b023826132266f9639bdd/validator/src/main/java/com/amazon/aoc/validators/CWMetricValidator.java#L50) for unit tests called setCloudWatchService().  Also, the init method cannot be overloaded it is not present in the interface.  It seems like the other validators use the init() method to only set the parameters needed.", "Comment has been removed.", "I changed the method name to getSampleAppResponse() and documented the return value in the method.", "Removed.", "I believe this can be helpful as I remember sometimes during testing, the traceId could be present but the entire trace cannot be found for some reason.  Having this log could show that the sample app was called and a traceId was returned but the xrayService could not retrieve the full trace.", "In java, can't you define multiple of the same method names as long as they have different parameters? ", "This comment could also helpful to see the entire trace returned to, for example, see why the test failed.", "Isn't the entire trace logged on failure? ", "Yes, because the key for the trace map that I iterate over would look something like `[0].metadata.default.collector-id`.  Therefore, I am only looking for if the key ends with `collector-id` to find the attribute.", "Extracted into its own method.", "I now set this to the first value in the set and then remove it to iterate through the rest.", "Removed in my commit, but would it not be helpful to see that it succeeded?  Or can we assume the user would know it did by seeing that the retry count did not go down and no errors came up?", "Renamed to `LoadBalancingValidator`", "Added EOF new line.", "Changed now in my commit.", "Removed now in my commit.", "It was not necessary.  Removed now in my commit.", "I saw that with a higher JDK version we would use multiline strings which would be helpful but not sure if we want to do that.  I think reading in and deserializing from a `.json` could be a good alternative but we would have to create a folder and manage those files.", "I have now abstracted a class that this one now extends and overoaded the init() method to change the XrayService.", "I have abstracted duplicate logic to an `XrayValidator`", "I have found that we store it in a singleton list because this is the [method](https://sdk.amazonaws.com/java/api/latest/software/amazon/awssdk/services/xray/model/BatchGetTracesRequest.html#:~:text=was%20not%20specified.-,traceIds,-public%20final%C2%A0) required to get the segments.  It takes in a list of traceIds.", "In this specific validator, the entire trace is not logged on failure.  That's why I believe it would be helpful to log the retrieved trace map every retry as the TraceValidator does.", "I have found that we store it in a singleton list because this is the [method](https://sdk.amazonaws.com/java/api/latest/software/amazon/awssdk/services/xray/model/BatchGetTracesRequest.html#:~:text=was%20not%20specified.-,traceIds,-public%20final%C2%A0) required to get the segments. It takes in a list of traceIds.", "Please refer to other comment about the list of traceIds", "I've added what it would look like to read from a `.json` file for the input to the first testcase and it still does not look the best.  I found out that even reading in `.json` is not much better because the value of the `document` key needs to be a string and `.json` does not allow for multi-line strings as well.  This means we still have a long escape json string.  I'm not sure if there are any other alternatives to this.  What do we think?", "Please format this with a json prettier. ", "Shouldn't this be stored in it's own file also?", "Can we use `getClass().getResource()` for loading this file? We do similar file loads in other parts of the validator. https://github.com/aws-observability/aws-otel-test-framework/blob/be90b42b6fbe423a59c1d3fc7df208701ff7d70a/validator/src/main/java/com/amazon/aoc/fileconfigs/PredefinedExpectedTemplate.java#L86", "Remove dead code", "This whole method throws me off a bit. It is called `getRetrievedTrace` (singular) but takes in a list. It then proceeds to use the xrayService to query for a list of traces by id. Then it just blindly grabs all the segments from the first trace.\r\n\r\nShouldn't this method take in a single traceId? \r\n\r\nIs `xrayService.listTraceByIds()` used somewhere else where a List<Trace> data structure is actually needed?", "I think the weird ergonomics of this method force us to write not great code in the classes that extend this abstract class. IMO, it would be cleaner to have two methods `getRetrivedTrace(traceId)` and a `getRetrievedTraces(List<String> traceIdList). ", "Nit: I don't love the word `retrieved` here. Personally, it took me some time to get use to it when diving into the Validator. The validator is basically a big testing application. It does assertions against actual versus expected trace ids and data fields. I think `actual` would be more suiting....but that's just like my opinion man. ", "Nit: You don't actually need to remove this do you? ", "Why a set for this?", "Can we choose a better and more descriptive name for this?", "Can you add this as a comment?", "If it passed then it had to have 5 successes. That should be known. ", "We already use mustache files heavily in the validator. Can we reuse and extend the mustache rendering functionality for expected testcase files? ", "The only difference is that we wouldn't need to inject any data into the mustache files. Unless you find a need to inject data during rendering. ", "I now switched to rendering mustache files and it works.", "Changed in my newest commit.", "I've opted to use `File().getAbsolutePath` still as getClass().getResource(path) returns a URL object but we are looking to pass in a String path to `LocalPathExpectedTemplate` for rendering the .mustache file.", "Changed in my newest commit.", "I believe it was a list of traceIds due to this [method](https://docs.aws.amazon.com/xray/latest/api/API_BatchGetTraces.html) which is the only way to get segments from a trace and only takes in a list of traceIds.  For readability, I have added a method to our XrayService to get the segments from a single traceId and so I can add another method to our XrayValidator called `getActualTrace()` which is less confusing and prevents us from being constricted to providing a list input. ", "I have changed this to a list and no longer need to remove it.", "I have changed this to a list now.", "I have changed the name to `collectorIdList`"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/1302", "comments": ["```suggestion\r\n  description = \"Toggles whether or not the validator will ignore an empty EMF dimension set\"\r\n```"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/1285", "comments": ["if you add the testcases to this file, they will be run by the collector. we need a new testcase file, that can live in the java repository. \r\n\r\ntake a look into how the collector create the testcases: https://github.com/aws-observability/aws-otel-collector/blob/main/.github/workflows/CI.yml#L569", "@rapphil I noticed that all repos have their own copy of testcases.json (adot-operator, adot-collector) along with test-framework. but I couldn't understand why that is required, when we do have argument to pick only certain services (like its done [here](https://github.com/aws-observability/aws-otel-collector/blob/bdeb7a6a4dba7c3a39813c1b1cee9db31c39fd31/.github/workflows/CI.yml#L51) for collector) then there should be no risk of collector running testcases of other services (like EKS_JAVA_INSTRUMENTATION_ADOT_OPERATOR), right? Wanted to check this with you?", "that is not a requirement, in fact, we should move the testcase.json file to the adot collector repository and keep the tool in the test framework repository. The inclusion mechanism in the ADOT collector workflow is used for the case we want to run tests in the dev branch.", "ok. in this case, should I update the `testcases.json` that we have in Collector repo or clone a new one in java-instrumentation repo?\r\n", "1.22 is no longer supported. ", "Why do these need to be two new test case types rather than use the existing `EKS_ADOT_OPERATOR` or `EKS_ADOT_OPERATOR_ARM64` types? ", "I concur, please add a `testcases.json` file in the `java-instrumentation` repo to generate a list of test cases. The collector does not currently do this but that's a deficiency in the collector. ", "@bryan-aguilar I noticed that adot-operator workflow is running the `testcases` that are included in the `EKS_ADOT_OPERATOR` or `EKS_ADOT_OPERATOR_ARM64` tags. \r\nI created the new tag exclusive for java-instrumentation as I wanted to exclude them from all other scopes of adot-Collector and adot-Operator testcases. Reason: To not duplicate the running of same testcases with adot-operator workflow.", "The test cases that are being ran is dependent on which tests are defined in the `testcases.json` file. If you implement the advice given to you elsewhere, to give the java-instrumeentation it's own `testcases.json` file you can only define the test cases necessary. ", "@bryan-aguilar. I can change that but forgot to mention one primary reason. \r\nTag (like `EKS_ADOT_OPERATOR`) is mapped to a cluster. Since java instrumentation tests are deployed on different cluster, so the new `testcases.json` in `java-instrumentation`, will have different cluster values than the other similar files in other repos. I originally thought this is going to be confusing so thought of creating a new tag specific for `java-instrumentation`. \r\nDo you think its ok to map the `tag` to `cluster` here differently by reusing the `EKS_ADOT_OPERATOR` tag?", "A `testcases.json` file should represent the test case configuration required for that specific repository. We SHOULD have a specific `testcases.json` file for each repository. We do not now, but will in the near future. \r\n\r\nI think it's more confusing to separate these into different platform types. There is no reason that we could not run java instrumentation tests within the `ADOT_OPERATOR` test case scope right? In the end these are all tests of the operator. ", "Removed changes in testcases.json and batchtestgenerator from here. ", "Updated to 1.23 as min version.", "Removed changes in testcases.json and batchtestgenerator from here.\r\n"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/1283", "comments": ["I think you can use the `templatefile` function instead of this data module. https://developer.hashicorp.com/terraform/language/functions/templatefile\r\n\r\nDocumentation suggest that the function should be used instead of the module. https://registry.terraform.io/providers/hashicorp/template/latest/docs/data-sources/file.html", "```suggestion\r\n# Description \r\n\r\nThis testcase validates traces emitted using java-auto-instrumentation deployed through Opentelemetry-Operator. This test uses the ADOT java-auto-instrumentation image to instrument a Spark sample-app image (without java-agent baked in) using the OpenTelemetry Operator. The OpenTelemetry Operator also deploys and manages the ADOT collector. The validation and other functionality is similar to otlp_trace_adot_operator testcase. \r\n```", "Is it possible to consolidate this sample app deployment with the other sample app deployment? It seems that not much changes other than some labels and the image being used. ", "Having a default here doesn't seem right. I feel like there could be a scenario where the default is used unintentionally. I think we should not have a default which will lead to test failures instead. ", "Why are we not using the batch processor here? ", "thanks. updated accordingly.\r\n", "Added.", "@bryan-aguilar I can consolidate the two sample app deployment into one. But then it's not possible to pass the exporter endpoints through the `java_auto_instrumentation.tpl`, because currently the `OTEL_EXPORTER_OTLP_ENDPOINT` env variable gets set in `push_mode_samples.tf` and I couldn't get the Operator to override the env values provided with sample_app deployment.  \r\nI thought the right way for this test, is to provide all the OTLP related env variables through the Instrumentation template and not through sample app deployment. And for this reason created a new deployment for sample app deployment without OTLP env variables. \r\nDo you want me to consolidate the apps deployment and keep the OTLP env variables set through the sample-app deployment?", "Removed the default value.", "Updated.", "where are you setting the value for this variable?", "setting `OTEL_SERVICE_NAME` and `service.name` in `OTEL_RESOURCE_ATTRIBUTES` is redundant. pick one of them. ", "@rapphil as per [this](https://github.com/aws-observability/aws-otel-test-framework/pull/1283#discussion_r1242461105) comment from Bryan, I have removed the default value of this variable. So when running this testcase manually the terraform prompts to provide this variable value. But we are passing the value of this variable from [here](https://github.com/aws-observability/aws-otel-java-instrumentation/blob/4c42d3a4dbe418b01d2e1c384bea0f0c4a93367a/.github/workflows/main-build.yml#L255) in mainbuild workflow in java-instrumentation repo.", "thanks. Updated. I have removed `service.name `from `OTEL_RESOURCE_ATTRIBUTES` as setting this doesn't set the `OTEL_SERVICE_NAME`. And `OTEL_SERVICE_NAME` is required to be set to ensure the metrics are exported to desired namespace in Cloudwatch. ", "Wasn't this merged in this PR? https://github.com/aws-observability/aws-otel-test-framework/pull/1285/files", "Was this changed to be a private repo? Does this repo even exist? ", "Is this just a relocation from the `push_mode_sample_app` file?", "My thoughts are that we should do our best to consolidate here to improve readability. Does terraform allow you to optionally define these env variables? Only create them in when `is_inject_auto_instrumentation` is false? \r\n\r\nIf we are going to keep them separate deployments then I'd like to see the services moved into a separate file. I think this indicates that they will always be created in an otlp test case where these deployments are optional depending on some condition.  ", "I don't think the pattern of defining a template file and then using a null resource is a best practice here. I know we may do it in other places but I believe there is a better way to do this. Custom resources can be deployed using the `kubernetes_manifest` module. See a writeup from hashicorp [here](https://developer.hashicorp.com/terraform/tutorials/kubernetes/kubernetes-crd-faas#deploy-an-openfaas-function) on how to manage custom resources. ", "@bryan-aguilar consolidated `push_mode_samples.tf`.", "[This](https://github.com/aws-observability/aws-otel-test-framework/pull/1285/files) PR's target was not based of`terraform` branch but `eks_operator_java_agent_testcase` branch. Hence it was merged to branch of this PR. \r\nOriginally that PR contained changes that were dependent on this PR, so I created that PR dependent on this PR. ", "yes, I just relocated this variable to `variables.tf` to keep the variables in one file.", "@bryan-aguilar yes this is how it is currently done [here](https://github.com/aws-observability/aws-otel-test-framework/blob/0afc4eb0110ad4e3c1dffcab5b4773bcdbb310f6/terraform/eks/otlp.tf#L284) for adot_operator's `adot_collector_deployment` as well, so I reused this component. I am going to look into the proposed method and comeback. ", "@bryan-aguilar thanks. Updated accordingly.", "@bryan-aguilar  No, this was kept as public repo (same as `spark` sample-app with agent). This repo doesn't exist yet. But under this [PR](https://github.com/aws-observability/aws-otel-ops/pull/356) we created this repo [here](https://github.com/aws-observability/aws-otel-ops/blob/378b45801e1aaa0e63da1153f5056102991bd6b2/iam-role-setup/lib/config/ecr/611364707713/ecr-config.ts#L58).  This PR is now merged.", "Where does `kubectl_manifest` module come from? Who is the provider?\r\n\r\nWhy not use `kubernetes_manifest` in the official `kubernetes` provider? \r\nhttps://registry.terraform.io/providers/hashicorp/kubernetes/latest/docs/resources/manifest", "What was your strategy for resolving your previous concerns? I don't see any changes related to the environment variables provided to the deployment. ", "@bryan-aguilar : I am not providing the OTLP related env variables through the `kind:Instrumentation` template now. By not doing that, I was able to consolidate the workload deployment templates. ", "So is this a tradeoff? There is no way to do both? ", "I was getting `kubernetes_manifest unmarshaling unknown values is not supported` error with the same yaml template with the `kubernetes_manifest`. \r\n`kubectl_manifest`:  https://registry.terraform.io/providers/cpanato/kubectl/latest/docs/resources/kubectl_manifest", "@bryan-aguilar yes its a trade off ( I couldn't find a way to override env variables already provided at workload deployment stage). but also discussed this with @rapphil, he also mentioned that since priority of this test is not to test whether the env variables to the workload can be set through the instrumentation crd template - so we should consolidate the workload deployment template to increase readability. ", "Updated accordingly with `kubernetes_manifest`."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/1281", "comments": ["can we remove this if checkstyle is not being used anymore?", "done, good catch"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/1239", "comments": ["do we really need to update this one? it is a new major version that is in alpha state.", "Nope, I will roll this back. good catch\r\n"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/1238", "comments": ["nit: lack of consistency. I think in .gradle file the convention is to not use parenthesis.", "updated"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/1224", "comments": ["the image has to be passed as parameter. we want to test the staged artifact, and not the final one.", "Where is this service defined? "]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/1171", "comments": ["Is the deployment workflow setup to handle this? Will there be issues with `AWS_REGION` env var that gets set? Is the deployment workflow ready for multi region deployments?", "Is the deployment workflow prepared for multi region deployments? Will there be any issue with the `AWS_REGION` env var being set? ", "that is why we need to set the region explicitly here.", "I think we will need to bootstrap the region though.", "Okay good, I was hoping the explicit region fixed that. Agreed on bootstrapping. "]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/1151", "comments": ["should we use loglevel:debug here (and in other configs) or as below:\r\n```\r\nexporters:\r\n  logging:\r\n    verbosity:\r\n```", "does validator also communicates to sample app in this test?", "yes, how otherwise it would exercise the endpoints?", "Example: https://github.com/aws-observability/aws-otel-test-framework/blob/terraform/validator/src/main/resources/validations/spark-otel-metric-validation.yml#L3\r\n\r\n```\r\n\r\n-\r\n  validationType: \"cw-metric\"\r\n  httpPath: \"/outgoing-http-call\"\r\n  httpMethod: \"get\"\r\n  callingType: \"http\"\r\n  expectedMetricTemplate: \"ENHANCED_EXPECTED_METRIC\"\r\n\r\n```\r\nIn the example above, validator will call `/outgoin-http-call` to create metrics.", "I will do this in a different pr because I want to fix all occurrences."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/1147", "comments": ["Can we use the testing id here or at least tag the auto scaling group with the testing ID? ", "Added it and changed the other names", "```suggestion\r\n      \"key\"                 = \"ephemeral\"\r\n```"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/1133", "comments": ["```suggestion\r\n* @aws-observability/adot-collector-maintainers\r\n\r\n```"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/1130", "comments": ["https://developer.hashicorp.com/terraform/language/values/variables#custom-validation-rules\r\nShould we start using validation rules to enforce that the value falls within the set defined in the comment? ", "```suggestion\r\n}\r\n\r\n```", "Do we NEED this? This will generate a lot of extra log lines in the GHA workflow logs. ", "this is logged inside the environment where the collector is running. we don't push those logs to the GHA workflow, do we?", "Good point, thank you for catching that. ", "Isn't there a template value used for this in other config templates?\r\n\r\nedit: I appear to be wrong.  Ignore me.", "It's used in this same config but the `loglevel` values are not the same for the `logging` exporter. I think the logging exporter uses something like `detailed` and something else instead of `debug`. ", "TIL. good idea."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/1126", "comments": ["I understand what you are doing here with this `null_resource` but is the sleep needed? You should be able to depend on `iam_wait` without the sleep. It will only be complete after it's dependencies are resolved. If a provisioner is required I suggest just using something like `echo iam_wait done`. ", "I added the sleep there because the previous module we used put a `sleep` there and I was trying to replicate it but I also think an `echo iam_wait done` would do the same and verified it in my local testing.  Changed in my latest commit.", "do we need to add tags so that ssm knows how to patch this?\r\nhttps://github.com/aws-observability/aws-otel-test-framework/blob/terraform/terraform/ec2/main.tf#L95\r\n\r\nif yes, we also need to wait for the patching to finish before moving on with the tests.", "I've added these tags to the launch template instances in my latest commit", "FYI that's not how the SSM patching is triggered in ec2. The `check_patch` resource uses that variable as a flag. https://github.com/aws-observability/aws-otel-test-framework/blob/80f205ee27e1b60c7e110fdc14ddda8385bc1808/terraform/ec2/main.tf#L143", "See comment further above. Patching is not done through tags. We may have to jump through more hoops to do the same type of patching on ecs ec2 instances. I don't consider this a blocker for this PR because it was not being done previously. ", "Acknowledged the comment above.  So should I remove the `Patch` tag for now then we can look into adding patching on ecs ec2 instances in the future?", "Yes. I would remove the tag because it is not used in the same context as EC2. ", "```suggestion\r\n  instance_state_names = [\"running\", \"stopped\"]\r\n```\r\nWhy do we filter on both `running` and `stopped` rather than just `running`?", "I carried it over from the example.  I think just `running` makes more sense in this case.", "if nothing is depending on this resource, then there is no need for it right?", "are you adding the proper `depends_on` on other resources so that we don't try to start tests while this resource is finishing?", "Never mind. I can see that you added.", "Never mind. I just spotted. "]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/1118", "comments": ["What is this and why was it committed? ", "This will end up being true for all `containerinsight_eks` test won't it? `containerinsight_eks` and `containerinsight_eks_containerd` will both evaluate to true. ", "good catch.\r\nI think we can refactor this a bit so that we don't need to have this branching behavior.\r\n\r\n* Lets create a base class `ContainerInsightStructuredLogValidatorBase` that contains everything currently here, except the LOG_TYPE_TO_VALIDATE. This class should have an abstract method `getLogTypeToValidate`, that will return the `List<String>` containing that information.\r\n* Create a class ContainerInsightStructuredLogValidatorDocker that implements:\r\n```\r\n@override\r\npublic List<String> getLogTypeToValidate() {\r\nreturn Arrays.asList(\r\n          \"Cluster\",\r\n          \"ClusterNamespace\",\r\n          \"ClusterService\",\r\n          \"Container\",\r\n          \"ContainerFS\",\r\n          \"Node\",\r\n          \"NodeDiskIO\",\r\n          \"NodeFS\",\r\n          \"NodeNet\",\r\n          \"Pod\",\r\n          \"PodNet\"\r\n  );\r\n}\r\n```\r\n* Create a class ContainerInsightStructuredLogValidatorContainerd that implements:\r\n```\r\n@override\r\npublic List<String> getLogTypeToValidate() {\r\nreturn Arrays.asList(\r\n          \"Cluster\",\r\n          \"ClusterNamespace\",\r\n          \"ClusterService\",\r\n          \"Container\",\r\n          \"Node\",\r\n          \"NodeDiskIO\",\r\n          \"NodeFS\",\r\n          \"NodeNet\",\r\n          \"Pod\",\r\n          \"PodNet\"\r\n  );\r\n}\r\n```\r\n* Update the ValidatorFactory accordingly creating distinct validation types (`containerinsight-eks-docker-logs` and `containerinsight-eks-containerd-logs`.\r\n* Update testcases accordingly to use the new validator.\r\n\r\n\r\n", "I have resolved it with modified case name. ", "I've sat on this idea a bit more. I don't think the pattern of using the test case name to make decisions is a good idea. I know there are examples elsewhere, in terraform and possibly the validator, but I don't think we should add more functionality that depends on it. It is not apparent when troubleshooting and when not documented properly it can cause a lot of headache. I would prefer that a specific variable gets passed in when necessary to the validator. One that is explicitly named so that we know that we are making a decision based on it. ", "Is this duplicate code from  `ContainerInsightStructuredLogValidatorDocker`? Can we store this in an abstract class that `ContainerInsightStructuredLogValidatorDocker` and `ContainerInsightStructuredLogValidatorContainerd` extend? ", "I think is similar to what @rapphil has requested here https://github.com/aws-observability/aws-otel-test-framework/pull/1118#discussion_r1139093992. We should have a base class for this. ", "do we need to change the name of this file as well?", "`eks-container-insight.yml` -> `eks-container-insight-docker.yml`\r\n\r\n"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/1117", "comments": ["unrelated to the pr description, but very small fix worth slipping into this one.", "Relying on an environment variable does not allow for deterministic deployments. Is it possible that we can hard the required suffix in the stack? Or is there a behavior here that we desire for non deterministic naming like this?", "```suggestion\r\n    const bucketName = `adot-collector-integ-test-configurations${suffix}`;\r\n```\r\n\r\nCan we move away from the `aws-otel` nomenclature for all new infrastructure. ", "Is the purpose of the suffix to allow deployment of this stack in a dev account? If so can we update the naming or add documentation relating to this purpose?", "Adventures in going through all the files. I now see the comment in the `stack` file. \r\n\r\nnit: I  still am not a fan of relying on environment variables even for dev and testing purposes. I would prefer if instead of relying on env variables it was hard coded in the app. I would not hold the PR up for it. ", "It is in the comments:\r\n>   // Suffix used to test the stack and avoid collisions with s3 buckets names, that must be globally unique.", "We cannot get rid of the environment variable because of local tests. I hid the environment variable inside the stack instead of leaking into the app.", "also, I'm happy to hear alternatives for the case of local tests in a dev account.", "Should we be specifying a region here to deploy the cfn template to? Would an error arise if someone tried to deploy this CFN template in multiple regions?", "In scenarios like this, one thing I have done  is to not rely on a bucket name without a UUID. Even in the default, non dev account, scenario. Have we considered attaching the account number as a UUID to the bucket? ", "your question is applicable to all the other resources as well. \r\n\r\nWe are relying on region definition from here: https://github.com/aws-observability/aws-otel-test-framework/blob/terraform/.github/workflows/cdk-deploy.yml#L26\r\n", "I don't think this is true. EKS and MSK are not globally unique in the way that s3 bucket names are. ", "Perhaps there are some resources inside those stacks that are globally unique, IAM Roles(?), and that would be a fair critique. ", "I guess it makes sense to use the account id as a dedup mechanism since it is is only going to be used for the tests.\r\n\r\nthe downside is that we will need to fetch the account id in the tests and it might create confusion in case the account used for holding the configurations is not the same as the accounts used to run the tests. I guess this is ok.", "I see, you are referring to the globally unique names. I think we can add the region name in the bucket name as well.", "You can derive the account ID from inside the stack. Could [this](https://github.com/aws/aws-cdk/issues/1754#issuecomment-513542145) possibly be a good solution? ", "Also, I'm not sure how this \"could\" break unit tests or how unit tests handle account env values. Can you make an account id in the unit tests? ", "The tests that I meant are the integration tests that run in terraform.", "I see "]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/1115", "comments": ["since we are touching this, can we assign names to each of the parameter variables `$1`, `$2` and `$3`?\r\n\r\nDynamodb is schemaless, so can we change the `aoc_version` key to something else that is more descriptive?\r\n\r\nAlso, Is there any side effect besides the cache misses if use add a prefix for everything, including the collector?\r\n\r\nThis pr is a cache miss anyways, so it is ok to use this opportunity to change everything.", "can't we use the other script `checkCacheHit` here instead of duplicating the logic?", "Done", "Switched to using named variables instead of $1$2$3. As we have discussed changing the `aoc_version` field name is not viable at this time. ", "\u2764\ufe0f ", "I think we can remove this line as you updated the condition to exit the loop so that it does not rely on CACHE_HIT:\r\n```while [ $ATTEMPTS_LEFT -gt 0 ] && ! ../checkCacheHit.sh $SERVICE $TESTCASE $ADDTL_PARAMS; do```", "Good point! Nice catch. "]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/1109", "comments": ["```suggestion\r\n\texcludedTestSet map[string]struct{}\r\n```\r\n\r\nYou're using it as a set, should probably name it that way.", "This could probably be done in an `UnmarshalJSON()` method.", "Done!", "Good suggestion, done!"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/1079", "comments": ["Is this not available already in `common`?", "I think I see now, we have to pass it into the `data_aoc_msk` module because this module does not import `common`. ", "Should we also be using the testing id as part of the dedup topic? ", "This module is imported into every platform module.\r\n\r\nDoes it belong in `basic_components`? \r\nWill this module initialize for all test cases? Even non kafka ones? Should we be adding something like\r\n```suggestion\r\nmodule \"aoc_msk_cluster\" {\r\n  # this syntax is wrong, don't copy it. It is merely a suggestion to get my point across. \r\n  count = string.startsWith(kafka, testcasename)\r\n  source = \"../data_aoc_msk\"\r\n\r\n cluster_version = var.kafka_version\r\n testcase = var.testcase\r\n dedup_topic = \"ecs\"\r\n}\r\n```", "Correct. my idea was to make this module totally self contained. It is basically used to enforce the naming conventions for looking up for clusters.", "we cannot use testid because there is a finite number of topics supported in kafka, which are created on first use, but are not deleted automatically, therefore we have to reuse topics across tests. \r\nI still need to figure out how to make this work with the different branches.", "This is is already done inside the `aoc_msk_cluster` module. If the cluster_version variable is empty, it will not fetch any data and it will return an empty map.", "Will this doc be included in this PR or a subsequent one? ", "I'm good with merging to dev without the doc existing. But it should be a blocker for merging to `terraform`. ", "No, it was my miss not to commit this. I added."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/1078", "comments": ["This had to be updated in order to get access to `string.replaceAll`", "Can we instead accept a set of VPCs as input and build clusters based on that? ", "Instead of making the stack generic, I made the setup for generating a msk cluster for tests generic: i create the `MSKTestCluster` construct. \r\n\r\nThe reason why we cannot make the stack generic is because we need to lookup for the aoc VPC that was created in terraform. the lookup can only happen inside a stack, therefore it is not possible to simple pass a set of vpcs to the msk stack. One alternative would be to create a stack just to perform the lookup, but I think that would add too much complexity for little benefit."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/1077", "comments": ["`--` is to pass parameters to the node script that is being called."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/1070", "comments": ["Can you break this in two prs? one for updating dependencies and another one with the functionality that you are adding/changing? This will make your PR easier to review."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/1069", "comments": ["nit: What is the need for this change?"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/1067", "comments": ["Why was this removed? I believe this is required to disable IMDSv1", "Where does the responsibility of choosing the correct `validation_config` lie? In what cases would a test case require different `validation_config` files? To me it seems like if a test case requires a different `validation_config` then it should be it's own test case. \r\n\r\nCan you walk through the use case or constraints where it made it necessary for the terraform ec2 module to ensure the correction `validation_config` value was chosen? ", "Do we need all these null checks or can we just check if `context.getHostmetricsContext()!=null`? Is there a reason where this would be true but we would not want use the host metrics mapper? Or would we at minimum check that the test case name contains `hostmetrics_receiver` and the context is not null?", "Why does this change need to be made? It is repeated in both blocks of the `if/else` below.", "```suggestion\r\n  private List<Metric> convertHostMetricModeltoMetricModel(\r\n```\r\nI believe a more descriptive name is helpful here. ", "```suggestion\r\n      if (hostMetricDataPoint.getDimensions() != null) {\r\n```", "```suggestion\r\n          for (int i = 0; i < hostMetricDataPoint.getDimensions().size(); i++) { // iterate over each dimension\r\n```", "What does dp stand for here? ", "Where did 60s come from, is this just an arbitrary number chosen? Just curious", "Any specific reason why we opt to use the wildcard import here? Small nit which I don't think matters in this context, but for example I believe this would cause a spotbugs warning when compiling. I think this applies to a few other flies' code imports as well", "Isn't this line for removing this change, and adding it to the `if/else` blocks? + the line under initializes `yamlExpectedMetrics` so that it will compile correctly as it won't compile if it is declared only in the `if/else` block", "Oh. removed by mistake. Thanks for highlighting. I have put it back.", "Is it possible to add a prefix `hostmetrics-test` or something like that so that it is possible to still explore the metrics in the cloudwatch console of the integration test account?\r\nE.g.:\r\n```\r\nnamespace: 'hostmetrics-test/${testing_id}'\r\n```", "Is the usage of `one()` going to break our `Canary` tests since we are [pinned](https://github.com/aws-observability/aws-otel-collector/blob/e4ddd80fffefca1bb417ed07996a508931ec96de/.github/workflows/canary.yml#L112) to version 14? `one` appears to require `v15` or newer. [docs](https://developer.hashicorp.com/terraform/language/functions/one). ", "Will having a daemonset deployment for all EKS test cases to be run synchronously? Can we run multiple test cases in parallel with this config? "]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/1058", "comments": ["LGTM, Is this tested in local?", "No, I will monitor the collector CI though and adjust if necessary. "]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/1050", "comments": ["nit: We could pass the AMI type from the test_cluster.yaml file as well, so that we don't need to rely on the name.\r\n\r\nhttps://github.com/aws/aws-cdk/blob/v1.189.0/packages/@aws-cdk/aws-eks/lib/managed-nodegroup.ts#L24", "We could, but we already had the convention of including the architecture in the cluster name and matching on that is likely to be less error-prone than correctly copying the magic AMI type string.  This also ensures that we only use one of these two AMI types."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/1033", "comments": ["Has this change been tested on the dev branch? Are ecs tests ran on the dev branch?", "ecs tests are not ran on the dev branch and so I will have to do more tests locally for these instances.  For now, I will remove the change for the ecs tests and merge the PR to verify that the changes work for the ec2 instances first."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/999", "comments": ["```suggestion\r\n  subnet_ids_random_index = random_id.subnetSelector.dec % length(subnet_ids_list)\r\n```\r\n\r\nMight as well use the list you just made."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/983", "comments": ["Wouldn't this prevent the running of `dockerbuildx rm` if `docker buildx build` failed? I believe that `rm` should always be executed no matter the success status of the previous two commands. "]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/979", "comments": ["In this case I suggest using github marketplace actions to ensure that all docker dependencies are setup correctly. The collector CI has an [example](https://github.com/aws-observability/aws-otel-collector/blob/6f6a27d672b5e266729cfb6da15ec8d106a2826d/.github/workflows/CI.yml#L510) of this. ", "We should publish more than just the latest tag. What about also tagging the image with the git short sha? \r\nAlso, what image tag are dependencies of this project referencing? If they are referencing `latest` does pushing a new image break them? ", "Why?", "```suggestion\r\n  contents: read\r\n```\r\n\r\nI don't think this requires write permissions to the repository does it? ", "AWS Credentials should be acquired using an IAM Role which utilizes a GitHub OIDC provider. ", "What did this comment mean and why is it no longer applicable?", "Yes, why?\r\n\r\nAlso, if not building the application in the Dockerfile then there's more extensive surgery to do.  This probably doesn't even need to be a multi-stage build if that's the case.", "[trace-java-client](https://github.com/aws-observability/aws-otel-test-framework/tree/terraform/trace-java-client) is referenced as local project by two gradle projects: load-generator and [jaeger-zipkin-sample-app](jaeger-zipkin-sample-app). \r\n`Load-generator` build by `Gradle` works by referencing to `trace-java-client` local project. But to build `load-generator` inside `dockerfile` requires commenting out [line 57](https://github.com/aws-observability/aws-otel-test-framework/blob/06496c5e679991d839b628afd737dcf28ce35214/load-generator/build.gradle#L57) and uncommenting [line 54 to 56](https://github.com/aws-observability/aws-otel-test-framework/blob/06496c5e679991d839b628afd737dcf28ce35214/load-generator/build.gradle#L54). - This is the current setup. Dockerfile and Gradle project are not able to build sameway b/c of difference in referencing a local project.\r\n\r\nSo, I noticed that `jaeger-zipkin-sample-app` resolves this thing by [simply not building project inside dockerfile]( https://github.com/aws-observability/aws-otel-test-framework/blob/06496c5e679991d839b628afd737dcf28ce35214/sample-apps/jaeger-zipkin-sample-app/Dockerfile#L12) and rather requires that the project is built before the dockerfile is built so that Docker can simply copy the executable over.\r\n\r\nNow with this, the first stage of copying the source code is indeed meaningless as we are expecting the binary to be available in the local filesystem before docker build command. I avoided to have this change in this PR, but if it's approved then I can edit the dockerfile of both these projects in this PR.", "Ok. Thanks. I will update this.", "Ok. Thanks. I will update this.", "From what I noticed, All the current sample-apps are publishing [image with latest tag only](https://github.com/aws-observability/aws-otel-test-framework/blob/06496c5e679991d839b628afd737dcf28ce35214/terraform/imagebuild/main.tf#L61).\r\nA git short sha can be added as a tag through the GHA workflow, but I couldn't find a solve on how to get that tag to become part of this [dockerfile path](https://github.com/aws-observability/aws-otel-test-framework/blob/06496c5e679991d839b628afd737dcf28ce35214/terraform/ec2_setup/variables.tf#L24) automatically. It will become a manual process to ensure that the latest/recent image is used. \r\nI couldn't find a existing setup in test-framework to reference this as well. ", "Here is a similar example in [collector CI](https://github.com/aws-observability/aws-otel-collector/blob/daf6a4942f318cc31df927bf7e5cc92ba4cfe2dd/.github/workflows/CI.yml#L452). \r\n\r\nIs it possible to run `git rev-parse --short HEAD` in a subsequent step, store it as an output, and then reference that output in the list of tags?  ", "Have you taken a look into the Java sample apps? They use jib to build and push the container images.\r\n\r\nhttps://github.com/aws-observability/aws-otel-java-instrumentation/blob/main/sample-apps/spark/build.gradle.kts#L27\r\n\r\n\r\nIf possible we should avoid assuming things and just build everything.\r\n\r\nThere is an example here of how to use job in a multi project environment\r\nhttps://github.com/GoogleContainerTools/jib/blob/master/examples/multi-module/name-service/build.gradle#L19", "Hi Bryan, my query is how to include this dynamic `short-sha` as part of static path of `load-generator` [docker image](https://github.com/aws-observability/aws-otel-test-framework/blob/06496c5e679991d839b628afd737dcf28ce35214/terraform/ec2_setup/variables.tf#L24)- in the code? This is required to pull this image that we are publishing.", "Could we split the image URL and tag? Then provide the tag value at test execution time?", "Thanks @rapphil for this suggestion. I was not aware of this tool, but now I see it quite a lot in test-framework. I have updated the code to incorporate this. Since the `dockerfile` is not used anymore so I have removed it.", "Thanks I have updated this.\r\n", "Thanks @bryan-aguilar for guiding on this. I have used the role utilizing OIDC provider.", "Thanks. I have updated this. added multiple tags. In the follow up PR, I will pull this image using latest tag.", "Thanks. This section has now been modified to use google jib instead.", "I'm not familiar with this action. It also does not appear to be actively maintained. Have you considered using the marketplace action that the java-instrumentation uses? can be seen [here](https://github.com/aws-observability/aws-otel-java-instrumentation/blob/22af6a0e21b980aeacef711e2fe4db74ef5d1a6b/.github/workflows/main-build.yml#L49). ", "Let's add the [cancel in progress](https://github.com/aws-observability/aws-otel-test-framework/blob/aec36308faa0178ee9a65b4bc4fd6bcbd15caea6/.github/workflows/cdk-deploy.yml#L15) field here also. ", "This will ensure that we don't rely on the default behavior. ", "Updated. Done.", "Updated."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/973", "comments": ["```suggestion\r\n        echo \"dir=$(npm config get cache)\" >> $GITHUB_OUTPUT\r\n```", "```suggestion\r\n\tfmt.Printf(`batch-keys=%s >> $GITHUB_OUTPUT`, githubBatchKeys)\r\n```", "```suggestion\r\n\tfmt.Printf(`batch-values=%s >> $GITHUB_OUTPUT`, githubBatchValues)\r\n```", "```suggestion\r\n\tfmt.Printf(`release-candidate-ready=%s >> $GITHUB_OUTPUT`, succcess)\r\n```", "Should this error be returned instead? Also does calling `Fatal` here prevent the file from being closed correctly? I am not sure how the `defer` is handled in this case. My concern is that the flow goes something like `log -> os.exit(1)` and then the file is never correctly closed. ", "This error should be returned from the function and not just printed. ", "This error should also be returned. ", "How does the `ghEnv` file handle delimiters? Does this need a newline delimter at the end of each string? ", "Same question here. Does this require a newline delimiter? ", "Same questions as above for how this error should be handled. ", "This error should be returned "]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/934", "comments": ["```suggestion\r\n    const clusterNodeGroup = new Nodegroup(this, '{props.name}-managed-ng', {\r\n```\r\n\r\nThe MNG name should include the cluster name.", "Do these need to be public?", "Does this only create subnets in one AZ?  We should have at least three separate AZs.", "No, it creates it in multiple AZs but is determined using runtime context. See the file `cdk.context.json` for AZs used at deploy time."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/932", "comments": ["no more fargte cluster?", "Not yet. Soon\u2122. I plan to do a slow rollout of new clusters and chose these as the first three. "]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/922", "comments": ["I believe this will fail since without a `gradle build` being ran first in the [`jaeger-zipkin-sample-app`](https://github.com/aws-observability/aws-otel-test-framework/tree/terraform/sample-apps/jaeger-zipkin-sample-app). Can we confirm this? I thought at one point the docker file relied on the `build` directory to exist. ", "Should we also publish for `sample_apps`also since `imagebuild` module does both?", "good catch. I will add a command to build it.\r\n", "yes, I updated the list of watched directories.", "When using an OIDC provider the default session length is 1 hour. Are we going to need to set it to be longer for this? \r\n\r\n[ref](https://github.com/aws-actions/configure-aws-credentials#assuming-a-role)"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/914", "comments": ["I'm almost sure you have to build first before running jest. Reason why it worked locally for you is because you probably relied on the previous build.\r\n\r\nMayse use a single npm script to build and test?\r\n\r\n```    \r\n\"build\": \"tsc && jest\",\r\n```", "Am I interpreting [this](https://github.com/aws-observability/aws-otel-test-framework/actions/runs/3422465321/jobs/5699904190#step:6:9) PR Build output incorrectly? It looks like the tests were ran. ", "https://github.com/bryan-aguilar/aws-otel-test-framework/blob/fixUnitTests/cdk_framework/EKS/jest.config.js#L7"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/913", "comments": ["Should this say start? "]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/908", "comments": ["Why was this change made? ", "What owner does this reference? ", "Saw the updated PR description. ", "reverted this change"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/906", "comments": ["No `v21Layer`?", "```suggestion\r\nconst supportedVersions = new Set(['1.21','1.22','1.23']);\r\n```\r\n\r\nAren't all versions prior to 1.21 deprecated and unable to be used for new clusters?", "The v20 layer is used by default for `v1.21` and `v1.20` according to the [docs](https://docs.aws.amazon.com/cdk/api/v2/docs/aws-cdk-lib.aws_eks-readme.html#runtime). A `v21` layer was made available last release though and I have updated the code to use that instead. ", "Good catch, thanks."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/876", "comments": ["These shouldn't be interleaved with stdlib imports.  `goimports` can fix this, I think.", "```suggestion\r\nfunc stringArrayToSet(input []string) map[string]struct{} {\r\n```\r\n\r\nSpecifically here this is making a set for presence detection and not a map to any usable type.", "This is a static regex, so we should be able to move it out to a package-scoped variable and create it once with `regexp.MustCompile()`.\r\n\r\nAlso, raw strings are easier to work with when making regexes:\r\n\r\n```suggestion\r\n\tawsRegionRegex, err := regexp.Compile(`^(us(-gov)?|ap|ca|cn|eu|sa)-(central|(north|south)?(east|west)?)-\\d$`)\r\n```", "This predicate could use an explanatory comment or extraction into a well-named helper function.", "First time hearing about `goimports`. Thanks!", "Refactored to a function that I hope is easier to grok. ", "```suggestion\r\nvar awsRegionRegex = regexp.MustCompile(`^(?:us(?:-gov)?|ap|ca|cn|eu|sa)-(?:central|(?:north|south)?(?:east|west)?)-\\d$`)\r\n```\r\n\r\nMicro-optimization, but since you're not using the contents of these groups they can be made non-capturing.", "why this file is not inside config? This seems to be a complete config.", "nit:  should we add comments and maybe a more meaningful name? Maybe `TestSuite`?", "Let me see if I got the idea here. When a test has platform EKS for example, there can be multiple targets for the EKS platform and the same test will be executed multiple times?", "can we clarify if the test is executed for all the targets?", "nit: add an overview about what this file represents. E.g.: a set of tests that must be run and can be broken into smaller batches. We create combinations for each testcase and platform. Please add more details about the targets in the clustertargets section. Do we create combinations for each target and test case?", "nit: maybe transform  these two into a private methods and call them in a single `Initialize` method. I mean, they have to be called in this order always right, so why leak this detail to a code that rely on it.", "Yes. Each target is synonymous with an EKS cluster to run the test on. ", "These files are mocks for the `testCaseBuilder` tests. I have refactored them into their own directory. I hope this provides a bit more clarity. ", "Added extra info and renamed", "Added additional context", "Added some additional context", "Implemented, I think this ends up looking a bit cleaner in the test cases also. "]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/874", "comments": ["What is the unit here? `ms`?", "Does this need to increase to JDK18?", "Also needs units.", "Are these per-period?  How do these values relate to the other values?", "Should this be debug rather than info?  Seems like it could generate a lot of log noise.", "Thanks. Made changes accordingly.", "Thanks. Revert the change.", "Thanks. Updated read me accordingly. \r\nAlso revised the `statsdmetricemitter` to fix the similar issue of load-generation, and grouped parameters in readme accordingly.", "Thanks. Updated readme with this information.", "Thanks. Made changes accordingly.", "I think this will have unintended effects no? https://docs.oracle.com/javase/8/docs/api/java/util/ArrayList.html#add-int-E-\r\n\r\n>Inserts the specified element at the specified position in this list. Shifts the element currently at that position (if any) and any subsequent elements to the right (adds one to their indices).\r\n\r\nEvery time that you call nextDatapoint, more data will be added to the array. if this gets called enough, you might become out of memory.\r\n\r\nmaybe use plain array `new long[param.getDataPointCount]`?", "nit: I think you could use a Template class pattern or a strategy pattern in order to make the code cleaner instead of having to deal with these two different cases. The idea is that you instantiate a different implementation based on the metric type.", "Can you attach attributes to counters at creation time or does it have to be done here? ", "```suggestion\r\n            GlobalOpenTelemetry.meterBuilder(\"adot-load-generator-metric\")\r\n```", "Just fyi, udp packets have size limitation of 64k. I think it is ok to let the exception bubble up, but maybe we can proactively check what is the size of `buf` before calling `send` and raise an `RuntimeException` asking the user to reduce the number of metrics/datapoints.", "Thanks updated.", "Thanks, Updated.", "as each datapoint has a differentiating(at least one distinct) label, so I think it has to be done here (at the time of datapoint creation).", "Thanks. Updated.", "I have not updated code with this change, as I thought it is just a simple switch case in sample-app. But do let me know if it has to be done, then I will make the necessary changes.\r\n"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/870", "comments": ["Are we going to maintain dev branch. ", "There is no maintenance required. I added this because I plan on doing some work on a dev branch and wanted to ensure that my PRs get all unit tests ran against them. Other developers can use the `dev/*` branch naming schemes in the future if they would like. ", "thanks bryan"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/864", "comments": ["Are there any other places that need this change?", "no"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/863", "comments": ["Do we still need 'x86_64' here in this case", "yes, the terraform ami data filter only use x86_64 as parameter instead of amd64"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/856", "comments": ["Do we need to choose a kernel versions here, or does this pattern only catch the kernel 5.x AMIs?", "It catches the latest kernel version. Currently it is 5.x; but it should ideally pick 6.x if `amzn2-ami-kernel.6.x` is out", "The `arm_ubuntu18` object declares an instance type. Why doesn't `ubunutu18`? What is the default?", "The previous version had a comment about the product code. In your testing did the \"correct\" debian10 get selected?", "The default values come from [here](https://github.com/aws-observability/aws-otel-test-framework/blob/45ee692bac2ca73baa0132c6fcc4e122dc8cdd3f/terraform/ec2/amis.tf#L21) based on the `family` attribute. For ARM images we override to `t4g.nano `because`t2.micro` is not supported to run ARM binaries", "As we use `aws-marketplace` as the `ami_owner`, they have the supported debian images. SO product code is not required now ", "<img width=\"739\" alt=\"Screen Shot 2022-10-04 at 11 33 33 AM\" src=\"https://user-images.githubusercontent.com/28486681/193898078-f75a9f8c-64fe-4fd6-aa02-c1716ecaed9c.png\">\r\n\r\n<img width=\"769\" alt=\"Screen Shot 2022-10-04 at 11 35 58 AM\" src=\"https://user-images.githubusercontent.com/28486681/193898489-428960b3-3673-4f34-8498-0c2d946e91fe.png\">\r\n", "Does it catch the latest kernel version, or the latest AMI?  If there are both `kernel.5.x` and `kernel.6.x` AMIs available would it consistently get the 6.x version or could it get 5.x one time and 6.x another depending on which was published most recently?\r\n\r\nDo we still support the 4.x AL2 releases?  I believe those are the ones with no `kernel` in the AMI name.  Should we have two entries, one for `hvm-*` and one for `kernel.5*`?  We can always add another for `kernel.6*` if it becomes necessary, though I expect that won't happen on AL2.", "We should probably be consistent with `micro` or `nano`.  If we're using `t2.micro` let's also use `t4g.micro` so that RAM and burst performance are equivalent.", ">Does it catch the latest kernel version, or the latest AMI? If there are both kernel.5.x and kernel.6.x AMIs available would it consistently get the 6.x version or could it get 5.x one time and 6.x another depending on which was published most recently?\r\n\r\nThat is a good point, I did not think about that edge case. Even-though idk how to exactly test out this behavior ; the terraform documentation mentions that it pulls the` recent results`. So it will probably pull the `kernel.5.1.x` if it is updated after `kernel.6.x`. I think it is better to update the search patter to `amzn2-ami-kernel.5*` and update to `amzn2-ami-kernel.6*` when its out.\r\n\r\n>Do we still support the 4.x AL2 releases? I believe those are the ones with no kernel in the AMI name. Should we have two entries, one for hvm-* and one for kernel.5*? We can always add another for kernel.6* if it becomes necessary, though I expect that won't happen on AL2.\r\n\r\nShould we ? The initial plan was just to test out the latest version of AL2. The [release notes ](https://aws.amazon.com/about-aws/whats-new/2021/11/amazon-linux-2-ami-kernel-5-10/)for kernal 5 mention various security improvements. So IMO we should suggest users to upgrade.", "Updated in [6e23b18](https://github.com/aws-observability/aws-otel-test-framework/pull/856/commits/6e23b182746786a94cd7da63fe6418cc2eee05a6)", "Updated the search pattern in [ef1a2a0](https://github.com/aws-observability/aws-otel-test-framework/pull/856/commits/ef1a2a0a0d6c13acfb8d84f54fbc0bfa62f41e4c)"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/854", "comments": ["```suggestion\r\n          role-to-assume: ${{ secrets.ASSUMABLE_ROLE_ARN }}\r\n          role-session-name: RelevantNameForWorkflow\r\n```\r\n\r\nWe should probably start adding session names to all of our workflows to help identify which workflow/job/step is using the role."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/846", "comments": ["Since you are use a bom, you don't need to define version for the dependencies:\r\n\r\nhttps://blog.mrhaki.com/2019/04/gradle-goodness-use-bill-of-materials.html\r\n\r\nYou can just update the version of the bom: \r\n```\r\n   implementation platform(\"io.opentelemetry:opentelemetry-bom:1.18.0\")\r\n   implementation \"io.opentelemetry:opentelemetry-api\"\r\n   implementation \"io.opentelemetry:opentelemetry-sdk-metrics\"\r\n....\r\n```\r\n", "Maybe you can use a histogram to record latency instead of a gauge: https://aws-otel.github.io/docs/getting-started/java-sdk/trace-manual-instr#creating-metrics", "Thanks. updated accordingly.", "thanks. as discussed keeping Gauge for now.", "```suggestion\r\n            .add(10, METRIC_ATTRIBUTES);\r\n```\r\nWhy did you change the value being added? Will this affect the tests in any way?"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/809", "comments": ["Can we add a type to these variables?", "```suggestion\r\nvariable \"operator_tag\" {\r\n  type = string\r\n```", "```suggestion\r\nvariable \"operator_repository\" {\r\n  type = string\r\n```"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/804", "comments": ["Why do we need pprof?", "There is a new flag in the test framework that will control this. see other configs for an example.", "Do we expect the images to be available on ECR or can we build them locally in the test environment? ", "Also, this standard template should be used with a variety of sample apps right? Should this value be set at test runtime and not explicitly defined in the parameters file? ", "nit: newline needs to be fixed at EOF (end of file). ", "I believe pprof was added because Alex was building the otconfig based on the otlp_trace and otlp_metric testcases which include pprof.  pprof can be used to collector performance profiles and investigate issues with the Collector but if we decide it is not necessary then I can remove it.", "Can you point me to this new flag in the test framework?  I can't seem to find it in the other configs", "We can explore both options when it comes to ECR vs. building images locally, and I can edit this behavior depending on what we decide.  If the images were available on ECR, I believe it would be easier to just pull the different images in the workflows and allow people to easily grab the sample app images if needed.  However, it would require more maintenance in ECR and takes up resources.  If the images were built locally in the test environment then that maintenance would not be required and resources are saved, but the workflow would require more work to build each different image and people would have to learn how to build each respective image on their own if needed.  What do you think would be the best path considering this?", "Yes this standard template should be used with a variety of sample apps, so this value should be set at test runtime", "My apologies for the late reply. But yes, Huy is correct.", "The original idea was to pull the images from ECR where they would be maintained. But it makes sense to also build them locally in order to know that an image passes all testing to then being updated or uploaded to ECR.", "Is it necessary? ", "https://github.com/aws-observability/aws-otel-test-framework/blob/23f605c6125b4465c5961b292f01f8bccf228e7d/terraform/testcases/otlp_trace/otconfig.tpl#L29", "Although that is being used to control the telemetry log level and not the logging exporter. I am not sure if we should be using it for both. So I may be off base here. ", "What is this used for? Are we planning on doing soaking tests for this test case?", "I found this [note](https://github.com/humivo/aws-otel-test-framework#:~:text=Note%3A%20Please%20enable%20pprof%20extension%20in%20your%20otconfig.tpl%20for%20the%20debugging%20purpose.) in the test framework README advising to enable pprof extension"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/801", "comments": ["```suggestion\r\n      docker buildx create --use --name sapbuilder.${count.index} --platform=linux/arm64,linux/amd64 --driver  docker-container --bootstrap\r\n```\r\nWhat is the reason for having to create a new builder instance for each sample app? Is it because these builds are done in parallel and thus we require a builder for each one? ", "Yes. that's correct. Had to create distinct builders for this reason."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/795", "comments": ["```suggestion\r\n  cluster : eks.Cluster\r\n```", "Why is this commented out? Is this dead code? If so, please remove. ", "This file name is missing a type extension", "```suggestion\r\n  cluster : eks.Cluster\r\n```", "```suggestion\r\n    if(size.length < 1){\r\n```", "Would this make more sense?", "nit: Checking that the node size is in the `supportedNodeSize` set and then using a switch statement may be easier to read here. \r\n", "```suggestion\r\n  cluster : eks.FargateCluster\r\n```", "Does this stack require any sort of IAM policies like the ec2 worker roles?", "Why is this file here? Is this dead code? If so, please remove. ", "`Map<string, FargateStack | EC2Stack>()` gets reused a lot. Can we use a type alias instead of repeating this everywhere? Find a good place to define\r\n```\r\ntype clusterMapType = Map<string, FargateStack | EC2Stack>\r\n```", "There is a default role provided assumed by anyone with permissions in the same account", "I'm going to redo the validation because now I am using interfaces. So going to delete this function. ", "I'll look into it. I plan on redoing the validation because I am using interfaces now. ", "The issue is that there are 2 sets because the node sizes for t4g is so different from the other ones, I decided to put it a whole different set. Let me know if you still think I should change it from this though. ", "Why did you remove the carat from some dependencies?\r\nhttps://github.com/npm/node-semver#caret-ranges-123-025-004\r\n\r\nPlease use carat in all dependencies unless you have a good reason for not doing it.", "I had an issue with my dependencies not lining up, where I was getting the error illustrated in this stackoverflow post - https://stackoverflow.com/questions/66572044/how-to-resolve-aws-cdk-error-argument-of-type-function-is-not-assignable-to-p#:~:text=37,to%20avoid%20different - so I followed the solution given. ", "Now everything works, so I'll try re-adding the up-carats", "Can these `validateInterface` calls be done once before the `if` statement?", "Why does the `version` field require double quotes?", "```suggestion\r\n      defaultCapacity: 0,  // we want to manage capacity ourselves\r\n```", "What is the purpose of this master role?", "Should version be a string or number type?", "Please add a newline", "So that it is of type string.  https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-eks-cluster.html#cfn-eks-cluster-version This is a link that Raphael sent me that seems to support this. ", "https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-eks-cluster.html#cfn-eks-cluster-version This is a link that Raphael sent me that seems to support this.", "Oh shoot. That was a mistake, I was playing with things. Good catch!", "The reason I do it after is because I want to potentially cast to `ec2ClusterInterface`, so that the validation will also check the `instance_type`", "doesn't a single `npm install` command do this?"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/793", "comments": ["This seems to assume that this cluster will only ever have a single task.  Is this a valid assumption?  What gives us confidence it is valid?", "Do other validation methods do this?  It feels wrong.  The validation shouldn't start until all necessary resources are in place.", "Ensure all files end with a newline.  Many are not.", "Other validations methods implement lots of retries to wait for resources to initialize.", "Why do we need multiple health check extensions? Especially since `healthcheck/1` isn't defined in the service.", "can we replace all this nesting by early returns? \r\n\r\ne.g.: \r\n```java\r\nif (context == null || context.getEcsContext() == null || ontext.getEcsContext().getEcsClusterArn() == null) {\r\n          throw new BaseException(\r\n                  ExceptionCode.ECS_RESOURCES_NOT_READY,\r\n                  \"[ECSHealthCheckValidator] Awaiting on ECS Resources to be ready\");\r\n}\r\nDescribeTasksResult result =\r\n                  taskService.describeTask(context.getEcsContext().getEcsClusterArn());\r\nif (result == null || result.getTasks() == null || result.getTasks().isEmpty()) {\r\n          throw new BaseException(\r\n                  ExceptionCode.ECS_RESOURCES_NOT_READY,\r\n                  \"[ECSHealthCheckValidator] Awaiting on ECS Resources to be ready\");\r\n}\r\nTask task = result.getTasks().get(0);\r\nif (task == null  || task.getContainers().isEmpty()) {\r\n          throw new BaseException(\r\n                  ExceptionCode.ECS_RESOURCES_NOT_READY,\r\n                  \"[ECSHealthCheckValidator] Awaiting on ECS Resources to be ready\");\r\n}\r\nList<Container> containers = task.getContainers().stream()\r\n                      .filter(container -> container.getName().equalsIgnoreCase(\"aoc-collector\"))\r\n                      .collect(Collectors.toList());\r\n.....\r\n\r\n```\r\n\r\nYou can transform \r\n```java\r\nthrow new BaseException(\r\n                  ExceptionCode.ECS_RESOURCES_NOT_READY,\r\n                  \"[ECSHealthCheckValidator] Awaiting on ECS Resources to be ready\");\r\n\r\n``` \r\nin a method if you need to.\r\n\r\n", "Thanks. I have updated the code now to not take this assumption.", "Thanks. I have updated the code. I left the `log.info` and `time.sleep` by mistake in the code. I have removed it now. ECS resources are created before the validator.", "Thanks. I have updated the code now.", "Thanks. I have updated the code now.", "Thanks. Yes, we can do that. Actually, its easier to write the passing case, and then the complement of that case goes for exception (retries). With early return (as you described) we need to catch all the negative cases so that the complement (single case- positive) passes the test. I have updated the code as per this comment, as it becomes more readable, debug-able. I tried to incorporate all the negative cases and catch all exceptions.", "```suggestion\r\n        {\r\n            \"name\": \"OTEL_RESOURCE_ATTRIBUTES\",\r\n            \"value\": \"service.namespace=${otel_service_namespace},service.name=${otel_service_name}\"\r\n        },\r\n```\r\n\r\nCheck the alignment of these and other values.  Doesn't affect the functionality but it is easier to scan as a human when they're consistent.", "Are these needed?  If so, they probably need to have different ports.", "```suggestion\r\n      level: ${log_level\r\n```\r\n\r\nA new variable is available to control this behavior and should be used here.", "Thanks. I have updated code accordingly.\r\n", "Thanks. I have updated code accordingly.", "Thanks. I have updated code accordingly.\r\n", "Does this need to use the log level variable also? ", "In my opinion, it's not required here. for ref: https://github.com/aws-observability/aws-otel-test-framework/blob/812a4eef108a878c28f76f8493b4e1b38f590370/terraform/testcases/otlp_metric_mock/otconfig.tpl"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/787", "comments": ["Can you also fix the spacing for L8-10 here, it seems to be tabs instead of spaces"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/778", "comments": ["is this sentence unfinished? "]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/768", "comments": ["Does validator need otel exporter?", "no", "Why would we want to run this on PR and Push?", "```suggestion\r\n```\r\n\r\nthese aren't being used anywhere. Also using inputs from a workflow dispatch in a workflow which can also be triggered on PR or Push can get tricky. The defaults will not be used on non `workflow_dispatch` events because the `inputs` field will not exist at all. I don't think it's a good practice to mix the two. If you are do not rely on any inputs. ", "What are these and why are they required?", "```suggestion\r\nexample-collector-config file. Clone the ADOT Collector repo and start the collector with commands.\r\n```", "```suggestion\r\nexample-collector-config file. Clone the ADOT collector repo and start the Collector with commands.\r\n```", "```suggestion\r\n### Start integration tests\r\n```", "```suggestion\r\nRun this command in the root directory(aws-otel-test-framework) of the testing framework once the Collector \r\n```", "```suggestion\r\nand sample app are up and running. Ensure that the AWS account being used on your local account has no \r\n```", "what is this for?", "```suggestion\r\n1. There must be the ADOT collector running with\r\n   AWS X-Ray on port 2000, i.e. Collector running at http://localhost:2000.\r\n```", "This syntax will only run on PR and Pushes involving the centralized-sampling-tests folder. That way if someone tries to change the tests in some way, it will validate that their changes don't break it", "They are required for oidc github tokens which is needed to configure aws-credentials, https://docs.github.com/en/actions/deployment/security-hardening-your-deployments/configuring-openid-connect-in-amazon-web-services#updating-your-github-actions-workflow\r\nIt also is done in aws-otel-java-instrumentation, https://github.com/aws-observability/aws-otel-java-instrumentation/blob/main/.github/workflows/main-build.yml#L9\r\nThe contents is unnecessary so I deleted that but will not work without id-token", "Passes in the aws credentials into docker containers, so that the docker collector can connect to AWS X-ray backend, \r\nAlso used in the aws-otel-java-instrumentation, https://github.com/aws-observability/aws-otel-java-instrumentation/blob/main/.github/collector/docker-compose.yml\r\n"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/767", "comments": ["One question here is should `EKS_ADOT_OPERATOR_ARM64` be added in this case, with `additionalVar: runConfig.EksARM64Vars` or should it be in the next case, with `additionalVar: runConfig.EksVars`? They're the same variables from my understanding (`ampEndpoint`, `clusterName`, and `region`) but will have different values depending on if it is arm64 or not", "This has changed, since operator arm 64 tests do not need the arm64 endpoint/cluster/region variables as it uses the same endpoint/region as the EKS tests, and the cluster is set as a `-var=` flag during `executeTerraformTest.sh` since that takes [precedence](https://www.terraform.io/language/values/variables#variable-definition-precedence) over the [`parameters.tfvars`](https://github.com/aws-observability/aws-otel-test-framework/blob/terraform/terraform/testcases/otlp_metric_adot_operator/parameters.tfvars#L7) used to set the EKS cluster name in a non-arm64 operator test case\r\n\r\nEDIT: `parameters.tfvars` is provided as a `-var-file` option on the command line which has the same precedence as a `-var` flag, but if the `-var` option is provided after the `-var-file` option it will have the correct oreder of precedence ", "```suggestion\r\n```\r\n```", "Missing newline", "```suggestion\r\n    \"EKS_ADOT_OPERATOR_ARM64\") TEST_FOLDER=\"./eks/\"\r\n        export TF_VAR_eks_cluster_name=arm64-adot-op-cluster;\r\n    ;;\r\n```\r\nI think we should stay consistent with how we set the `eks_cluster_name` variable in this file. ", "The issue here is that for operator tests, `eks_cluster_name` is passed in through a `.tfvars` file (see [here](https://github.com/aws-observability/aws-otel-test-framework/blob/terraform/terraform/executeTerraformTest.sh#L31) or [this example](https://github.com/aws-observability/aws-otel-test-framework/blob/terraform/terraform/testcases/prometheus_static_adot_operator/parameters.tfvars#L10)). This takes [precedence](https://www.terraform.io/language/values/variables#variable-definition-precedence) over environment variables, so we cannot do an `export TF_VAR_...` for setting the arm64 operator cluster name", "To add on to this, the `-var-file` option that provides `parameters.tfvars` would be provided before the `-var=eks_cluster_name` option, which would follow the correct order of precedence for us to set `arm64-adot-op-cluster` as the name", "Seems like it's added in the line below", "Not sure what this is supposed to be - if it's to add a newline then that should be added if not already present", "I feel a little conflicted on this choice. On one hand I understand why the env var won't work, but on the other it's a little confusing to look at from an outsiders perspective. I would be wondering \"why is it done one way here and a different way below\". \r\n\r\nI think we have two options\r\n1. Add some documentation explaining this choice, a comment will probably do\r\n2. Remove the cluster name from the existing parameters files so that we can uniformly use env vars. \r\n\r\nI think another downside to this is that we have a hard dependency for our arm-64 cluster names to use this specific name. It's not very portable between accounts but I am not sure if we are going for portability with this script. To be fair, all EKS tests other than the `EKS_ARM64` tests have this issue because we are using default values from the terraform modules. ", "```suggestion\r\n    \"EKS_ADOT_OPERATOR_ARM64\") TEST_FOLDER=\"./eks/\";\r\n```\r\nDon't we also need to set the cluster name here? ", "```suggestion\r\n`serviceName`: `EKS`, `EKS_ARM64`, `EKS_FARGATE`, `EKS_ADOT_OPERATOR`, `EKS_ADOT_OPERATOR_ARM_64`, `ECS`, `EC2`\r\n```", "I think this was a mistake in the original documentation. These values should match the `switch` statement in the bash script right?", "Unsure - if yes, does cluster name also need to be set in for `EKS_ARM64` test cleanup? Does it need to be set in `EKS_ADOT_OPERATOR` test cleanup too?\r\n\r\nEDIT: answer is yes for operator, and likely no for arm64, since it currently doesn't set cluster name in cleanup. Adding on to this, the operator cluster name will be included in `opts`, so that should be taken care of already", "Fixed", "Update here, I've filed #784 that changes the usage of environment variables to set terraform variables in the script to use the `-var` option instead. It also addresses a few other things as well. The hard dependency for operator/arm64 operator tests to use these cluster names still exists, but it's slightly better than having `eks_cluster_name` set in multiple `parameters.tfvars` files. "]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/755", "comments": ["Can we remove this instead of leaving a commented out block?", "+1. It'll be there in the git history if we need it later.", "Changed it"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/751", "comments": ["I would suggest applying a linter to this code :) The variable naming should be consistent, and these fields probably shouldn't be exposed as `public`.", "It would probably be better to use the Builder pattern instead of this collection of parameters. That way when we're getting a particular JSON object, we can see which data types each input map to clearly. For example:\r\n\r\n```java\r\nString sampleRuleJson = SampleRuleBuilder\r\n  .withName(\"AcceptAll\")  // These return the buil\r\n  .withPriority(1000)\r\n// ...\r\n  .toJson();  // This actually converts it to a JSON string\r\n```\r\n\r\nSee [this guide](https://howtodoinjava.com/design-patterns/creational/builder-pattern-in-java/)", "If method is \"GET\", reqbody should be null?", "May extract these header keys to be static constants, then shared by both validator and sample app.", "no *", "Process response by callback onResponse() https://square.github.io/okhttp/3.x/okhttp/index.html?okhttp3/Callback.html", "Can we think about extract these to be enum? String is not good to be tracked.", "think about change to enum?", "yes GET requests cannot have requestBody", "probably doable, haven't worked with enums yet, but shouldn't be too challenging\r\n", "also weird because POSTs are required to have a reqbody even though I am not using it hence the empty reqbody", "Wondering what is major difference in 3 tests? They all make rule, go though cases, verify the response with retry. ", "usually use slf4j", "I documented this in sampleRules, but probably worth documenting here. The difference is in how the rules are set and when the calls are made. sampleRulesTests creates 1 rule, calls all tests cases and repeat. Reservoir tests creates 1 rule, waits x amount of time because of the need to wait for the reservoir to fill and repeat. Priority test creates all rules then calls all test cases to test priority.\r\n", "I'm assuming you mean I should use a logger instead of sout", "There might be some elegant retry framework or code style we can refer to https://stackoverflow.com/questions/4738510/retry-task-framework", "I suppose List contains `enum SampleRuleName` but not String. "]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/750", "comments": ["```suggestion\r\n  default = \"latest\"\r\n```\r\n\r\nShould we remove the default for this variable? This would make it required and thus would error out of this was not provided. \r\n\r\nOn the other hand I am not certain that if doing would cause non `adot-operator` tests to error if they do not supply an `operator_tag` variable. We would need to test this to confirm. ", "I think we should keep the default in as it would follow the logic that we had before where the operator repo/tag were hardcoded in `adot-operator-values.yaml`, just adding in more flexibility in it being a variable. Also, like you mentioned, removing it might cause issues elsewhere"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/742", "comments": ["```suggestion\r\n```", "```suggestion\r\n[Otel-Collector-Contrib](https://github.com/open-telemetry/opentelemetry-collector-contrib/releases).\r\n```\r\nIs there a reason this is using upstream collector contrib rather than the ADOT Collector? Also I do not believe this is the correct link to find upstream collector releases. ", "```suggestion\r\n```", "That was the collector I have been using. No particular reason for using it over the ADOT collector, will change it. They both work the same for this.", "unnecessary links ", "duplicate with line 33", "May install a google formatter plugin", "Do we use Resource for?", "1. 1000 is reused at 3 places, move to `final static private String`\r\n2. Do we want to make it be configurable?", "why set attributes here?", "If here just return sampled in total, I guess you hardcode another `1000` in validator? better to control this magic number in one place in validator", "Line 38 and 40, to build the AWSXrayRemoteSampler", "Changed to final static private String, I don't think it makes sense to be a configurable option", "not sure what is meant by this comment unless you mean I should make 1000 a hardset variable in validator and make these endpoints configurable.\r\n", "unnecessary now, was using for visual clarity on the console. Has no relation to sampling decision, will delete\r\n", "3 methods look very similar, can we extract common logic to a function?", "move resource builder to here", "add final before all static", "If openTelemetry is not static, we can new a opentelemetry or tracer instead of rebooting sample app?", "static variable name should be capital", "where is `LISTEN_ADDRESS` from?", "it's from the java instrumentation sample app examples. It makes the host address configureable, so if I didn't want to use local host I could set the listen address as an environment variable. Could delete since it's not totally necessary but just extra configuration available in the sample app\r\n", "yes but we shouldn't ever need to reboot the sample-app based on current design", "You need to build the resource before hand to create the remote sampler. Not possible to build resource in the setter then use it for the setSampler", "We can think about remove all exporters from sample app and collector?", "see exporters comments", "public -> private, method name might be getSampledSpanCount?", "why Integer?", "can remove static modifier from OPEN_TELEMETRY", "if (span.getSpanContext().isSampled())", "no need set propagator if we don't export trace to xray backend.", "1 might be too crazy?", "we can remove aws depedencies, no need aws id generator", "no need static modifier", "no need static and public modifier", "no need public modifier", "Thought you meant to not set as a string in a comment up above, works the same this way without an extra cast. Http calls auto make the response a string so nothing changes", "Can we remove private attributes resource and opentelemetry, just autowire a Tracer?", "Not setResource", "does not follow java doc standard", "```suggestion\r\nIt is possible that this is already done. Available ADOT Collector releases can be found here\r\n[aws-otel-collector](https://github.com/aws-observability/aws-otel-collector/releases).\r\n```", "Where is this config being copied from? ", "Which sample-apps in the sample app folder are configured for centralized sampling? ", "realistically all of the sample apps in this subfolder would be, but that comment was for if other sample apps get added later on when I'm gone for some reason that aren't configured for the testing. Might not be necessary to include that\r\n", "If you cannot say for sure I would remove this statement. Considering the sample-apps folder hosts sample apps that are used in the collector integration tests. Sample apps for other languages live in their respective language repositories. ", "this was copied from the aws-otel-collector run locally with docker. There will be in later PRs added steps to include github workflows. might make more sense to have run with my example collector though both methods work. The specific config file is under examples/docker/config-test.yaml"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/706", "comments": ["Is it necessary to have an extra module for this? Can the variables just be referenced using `var.operator_tag` in the subsequent modules? ", "Are these sensible defaults? Would we rather point them to latest? If we do not want to point them to latest then should we have no default and error out if none is provided? \r\n\r\nAlso missing a newline at EOF", "In `eks/main.tf` there was a similar implementation ( [here](https://github.com/aws-observability/aws-otel-test-framework/blob/6f0f8929cdf602244750da9728b621dec8232429/terraform/eks/main.tf#L36) ) so followed off it.", "Is there any reason these cannot be scoped to the specific file like `testing_id` and `kubeconfig`?", "Implemented the suggestion", "For now, Yeah I think so. Considering we are running this branch of `17.0.1`, the operator and helm chart would always be the same version. This cuts down our tasks of editing the workflow to pass this variable from CLI.\r\nIf we decide to port this over to the `terraform` branch, we can change the defaults to latest and none respectively"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/684", "comments": ["```suggestion\r\n      log.info(String.format(\"[StructuredLogValidator] log structure validation successful\"\r\n```\r\n\r\nToo many placeholders."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/665", "comments": ["Thank you so much for detailed PR description, can we possibly have an optional flag to include like `aocImage` to run test cases with custom `adot collector image`? or we can plan to use `common.tf` for these specific use-cases. :-)", "Can we also include mock tests ", "AOC Image is already customizable by setting the `TF_VAR_aoc_version` before running `make execute-batch-test`. ", "Unless there is a use case where different tests will use different images then I do not believe it is in scope of this tool. ", "yeah agreed", "While it may not be documented clearly the primary use of this tool is to generate batches for use in the `Batched` CI workflow in the collector. The `local` command merely exists as an easier way to test the `make execute-batch-test` target without any copying needed by the user. I do not believe there is a use case for mock tests within a `test-case-batch` file because it would not integrate with the `make execute-batch-test` script. ", "Also mock tests are not used during the CI workflow."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/636", "comments": ["`\\n` at `EOF`.", "```suggestion\r\nThe values for these fields are as follows\r\n```", "```suggestion\r\nBatch testing allows a set of tests to be run synchronously. To do this,\r\n```", "```suggestion\r\nIt is also expected that`TF_VAR_aoc_version` and `TF_VAR_aoc_image_repo` are set to valid values\r\n```", "```suggestion\r\nTo clean up the successful test run cache\r\n```", "```suggestion\r\n```", "```suggestion\r\n\r\nCreates batches of test cases for use locally or in a GitHub action.\r\n\r\n```", "Is this the output file?  Would `--output` make sense here?  It's a common flag name and shorter than the alternative.", "```suggestion\r\nEndpoint for EKS AMP workspace.\r\n```", "```suggestion\r\n\t\t\treturn fmt.Errorf(\"max batches must be greater than 0\")\r\n```\r\n\r\nOr fix the condition if it really must be <1.", "Are these combined, or does this happen in place of the `PersistentPreRunE` from the root command?", "Should this have an allowlist for validation?", "```suggestion\r\n\tregexPattern := `^[a-z]{2}[-][a-z]+[-]\\d+[\\|][^\\|]+[\\|][^\\|]+$`\r\n```\r\n\r\nLet's be optimistic, we might have double-digit regions in a geo!\r\n\r\nAlso, be careful about escaping regex meta characters such as `|` and use exclusion classes (`[^\\|]`) and anchors when attempting to validate structure with regex.\r\n\r\nThis is only used once, so it doesn't matter much, but good practice would be to use `regexp.MustCompile()` to compile this into a package-global variable that gets reused.", "```suggestion\r\n\tvar b strings.Builder\r\n\r\n\tfor _, tsi := range testSet {\r\n\t\tfmt.Fprintf(&b, \"%s %s %s\\n\", tsi.serviceType, tsi.testcaseName, tsi.additionalVar)\r\n\t}\r\n\r\n\treturn b.String(), nil\r\n```\r\n\r\nA `strings.Builder` is probably the way to go here, no need to build up a string slice to join later.", "```suggestion\r\n\tfor batchName := range batchMap {\r\n\t\tbatchArray = append(batchArray, batchName)\r\n\t}\r\n```", "```suggestion\r\n\r\n```", "```suggestion\r\n\r\n```", "```suggestion\r\n\r\n```", "```suggestion\r\n\r\n```", "```suggestion\r\n\r\n```", "```suggestion\r\n\r\n```", "No this is the `testcases.json` file not the final `test-case-batch` file. ", "No it happens after. The `persistentprerun` is executed before prerun. See [here](https://github.com/spf13/cobra/blob/master/user_guide.md#prerun-and-postrun-hooks).", "Yes, that's a good idea. I'll add one.", "Added", "I don't know that a UUID is needed here since DDB tables are not global.", "```suggestion\r\n\toutput := make([]string, 0, len(testSet))\r\n```\r\n\r\nProbably doesn't make a huge difference, but setting the required capacity when it is known is a good practice that can save allocations in some circumstances.", "[AWS docs](https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_CreateTable.html) state DDB table names must be regionally unique"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/634", "comments": ["Infinite?  Surely it's at least bounded by available disk space.", "Why?  This seems unnecessary and impedes portability.  I wouldn't be able to run this locally as I have `GNU Make 3.81`.", "The argument was found in this [post](https://tech.davis-hansson.com/p/make/) as I was doing some `make` research. The gist is that the recipe prefix can avoid any errors brought by tabs or spaces.", "Updated"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/622", "comments": ["Should the docs here make clear that this is appended to a fixed portion of a bucket name and doesn't need to be a whole bucket name?  Maybe provide an example that generates a random value rather than just `example`?\r\n\r\n```shell\r\nexport TF_VAR_bucketId=$(dd if=/dev/urandom bs=1k count=1k | shasum | cut -b 1-8)\r\n```", "Yea your suggestion makes more sense.\r\nWould changing the variable name away from `bucketId` help also? What could we call it instead? `bucketUUID`?"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/611", "comments": ["Is this correct?  Doesn't this get a 301 to `https://...`?", "yep. this should be `301`. Just tested the sample app locally.\r\n\r\n```\r\n{\r\n    \"Id\": \"1-62448ed9-4733ff1a38db832ba446bbb7\",\r\n    \"Duration\": 0.075,\r\n    \"LimitExceeded\": false,\r\n    \"Segments\": [\r\n        {\r\n            \"Id\": \"20130a68ea1b0408\",\r\n            \"Document\": {\r\n                \"id\": \"20130a68ea1b0408\",\r\n                \"name\": \"aws-otel-integ-test\",\r\n                \"start_time\": 1648660185.9195466,\r\n                \"trace_id\": \"1-62448ed9-4733ff1a38db832ba446bbb7\",\r\n                \"end_time\": 1648660185.990404,\r\n                \"fault\": false,\r\n                \"error\": false,\r\n                \"throttle\": false,\r\n                \"http\": {\r\n                    \"request\": {\r\n                        \"url\": \"http://localhost:8080/outgoing-http-call\",\r\n                        \"method\": \"GET\",\r\n                        \"user_agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.84 Safari/537.36\",\r\n                        \"client_ip\": \"127.0.0.1\"\r\n                    },\r\n                    \"response\": {\r\n                        \"status\": 200,\r\n                        \"content_length\": 0\r\n                    }\r\n                },\r\n                \"aws\": {\r\n                    \"xray\": {\r\n                        \"auto_instrumentation\": false,\r\n                        \"sdk_version\": \"0.25.0\",\r\n                        \"sdk\": \"opentelemetry for nodejs\"\r\n                    }\r\n                },\r\n                \"metadata\": {\r\n                    \"default\": {\r\n                        \"otel.resource.telemetry.sdk.name\": \"opentelemetry\",\r\n                        \"net.transport\": \"ip_tcp\",\r\n                        \"http.flavor\": \"1.1\",\r\n                        \"http.route\": \"/outgoing-http-call\",\r\n                        \"http.status_text\": \"OK\",\r\n                        \"otel.resource.service.name\": \"aws-otel-integ-test\",\r\n                        \"otel.resource.telemetry.sdk.language\": \"nodejs\",\r\n                        \"net.host.ip\": \"127.0.0.1\",\r\n                        \"otel.resource.telemetry.sdk.version\": \"0.25.0\"\r\n                    }\r\n                },\r\n                \"subsegments\": [\r\n                    {\r\n                        \"id\": \"584849890004c9f8\",\r\n                        \"name\": \"aws.amazon.com:80\",\r\n                        \"start_time\": 1648660185.9197578,\r\n                        \"end_time\": 1648660185.9947398,\r\n                        \"fault\": false,\r\n                        \"error\": false,\r\n                        \"throttle\": false,\r\n                        \"http\": {\r\n                            \"request\": {\r\n                                \"url\": \"http://aws.amazon.com/\",\r\n                                \"method\": \"GET\",\r\n                                \"client_ip\": \"18.65.225.66\"\r\n                            },\r\n                            \"response\": {\r\n                                \"status\": 301,\r\n                                \"content_length\": 0\r\n                            }\r\n                        },\r\n                        \"aws\": {\r\n                            \"xray\": {\r\n                                \"auto_instrumentation\": false,\r\n                                \"sdk_version\": \"0.25.0\",\r\n                                \"sdk\": \"opentelemetry for nodejs\"\r\n                            }\r\n                        },\r\n                        \"metadata\": {\r\n                            \"default\": {\r\n                                \"net.transport\": \"ip_tcp\",\r\n                                \"http.flavor\": \"1.1\",\r\n                                \"http.response_content_length_uncompressed\": 183,\r\n                                \"http.status_text\": \"MOVED PERMANENTLY\"\r\n                            }\r\n                        },\r\n                        \"namespace\": \"remote\"\r\n                    }\r\n                ]\r\n            }\r\n        },\r\n        {\r\n            \"Id\": \"0d16cdad11ac4230\",\r\n            \"Document\": {\r\n                \"id\": \"0d16cdad11ac4230\",\r\n                \"name\": \"aws.amazon.com:80\",\r\n                \"start_time\": 1648660185.9197578,\r\n                \"trace_id\": \"1-62448ed9-4733ff1a38db832ba446bbb7\",\r\n                \"end_time\": 1648660185.9947398,\r\n                \"parent_id\": \"584849890004c9f8\",\r\n                \"inferred\": true,\r\n                \"http\": {\r\n                    \"request\": {\r\n                        \"url\": \"http://aws.amazon.com/\",\r\n                        \"method\": \"GET\",\r\n                        \"client_ip\": \"18.65.225.66\"\r\n                    },\r\n                    \"response\": {\r\n                        \"status\": 301,\r\n                        \"content_length\": 0\r\n                    }\r\n                }\r\n            }\r\n        }\r\n    ]\r\n}\r\n```", "I suppose this raises the question of why there isn't a segment for following the redirect, but that can be investigated separately from this PR."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/607", "comments": ["Is the purpose of this bucket to house the terraform state file? If so there is a better way to implement this using the terraform backend module. https://www.terraform.io/language/settings/backends", "I now see the commented code out on top. I am unsure why that's not being used. "]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/606", "comments": ["does this need to be? I see it in this format in the exporters section.\r\n```suggestion\r\n    region: '${region}'\r\n```", "```suggestion\r\n      region: '${region}'\r\n```\r\n`awsemf` exporter uses this format. Does it need to be used here?", "```suggestion\r\n    endpoint: '${cortex_instance_endpoint}/api/v1/remote_write'\r\n```", "```suggestion\r\n    region: '${region}'\r\n```", "Do we need `''` ticks?\r\n```suggestion\r\n  awsprometheusremotewrite:\r\n    endpoint: '${cortex_instance_endpoint}/api/v1/remote_write'\r\n    aws_auth:\r\n      region: '${region}'\r\n      service: \"aps\"\r\n    timeout: 10s\r\n```", "Why is region fixed here but passed in on other configs?", "Same question on why this region is fixed.", "```suggestion\r\n    region: '${region}'\r\n```", "```suggestion\r\n    region: '${region}'\r\n```", "Is this tab spacing correct?", "```suggestion\r\n      awsprometheusremotewrite:\r\n        endpoint: '${cortex_instance_endpoint}/api/v1/remote_write'\r\n        aws_auth:\r\n          region: '${region}'\r\n```", "Should this use prometheus remote write and sigv4 instead? Or is this test specifically for `awsprw`?", "```suggestion\r\n    region: '${region}'\r\n```", "```suggestion\r\n    region: '${region}'\r\n```", "Is this tab spacing correct?", "```suggestion\r\n      awsprometheusremotewrite:\r\n        endpoint: '${cortex_instance_endpoint}/api/v1/remote_write'\r\n        aws_auth:\r\n          region: '${region}'\r\n```", "Same question as before, should this be using `awsprw`?", "We don't use ticks, here or above/below; any of the tests with the `_awsprw` suffix are the same as tests that already exist in the repository (and thus have been passing already)", "Good question, I didn't write the original tests so I'm not sure why it's fixed, and same for above. ", "It does look off, but again I did not write these and are exactly what they are in the current repository", "any of the tests with the `_awsprw` suffix are the same as tests that already exist in the repository (for example, the `prometheus_sd_awsprw` testcase is the same as the `prometheus_sd` testcase that lives in the repository already. I've modified the `prometheus_sd` testcase to use prw+sigv4, and moved usage of the aws prw to the `prometheus_sd_awsprw` testcase", "See this [comment](https://github.com/aws-observability/aws-otel-test-framework/pull/606#discussion_r840787649) above", "See [here](https://github.com/aws-observability/aws-otel-test-framework/pull/606#discussion_r840788037)"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/604", "comments": ["Is this the only way to save the state file to a local machine after this change is merged? I am very much opposed to leaving in instructions to `comment out` code. This will greatly increase changes that we will have commented code merged back into the codebase. \r\n\r\nShouldn't every user be saving the state file remotely even if it to a personal account? There are cost associations but so are the other infra assets that are being deployed. ", "Does the backend module have a version we can pin? I think it would be a good idea to move away from using latest in these modules especially for sensitive items such as state files. ", "Are any other solutions possible? Toggle the saving of the file through a user provided variable? Maybe just always saving the file remotely but instructing users on how to pull the file from s3?", "I think its recommended to always have the state file saved on the s3 bucket. I don't see a way to disable the back-end block through a variable. We can give instructions to the user on curl the latest version of the state file from s3 bucket or reverting back to an older version.", "Sure, I would agree with that. We should remove this comment then. ", "The backend s3 module is part of the main terraform release. https://github.com/hashicorp/terraform/blob/main/website/docs/language/settings/backends/s3.mdx. So we can lock down the terraform version. But I am not sure if we want to do that as the tf script before the backend upgrade didn't lock down to a specific version. Lmk if its okay to do that", "I think it should be safe for this version but it may make sense to open an issue to see if it should be done as a whole for all modules in this repository. ", "okay, pushed that into the new commit", "@bryan-aguilar is it okay we push this PR up? As per anuraag suggestion, I can lock the versions of others tf scripts on another PR"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/590", "comments": ["Why are we commenting this out rather than pinning to a version prior to 4.0.0? When did our canary tests start to pick up version 4.0.0? ", "Also why is this commented out rather than use the solution provided in your link [here ](https://github.com/hashicorp/terraform-provider-aws/issues/23125#issuecomment-1038424883)", "sure, probably, can create a seperate PR if this is required. since there is a workaround shall remove the comment. thank you", "Yea, if it is not relevant to this PR it should probably be removed"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/560", "comments": ["```suggestion\r\n                \"metric in %n toBeCheckedMetricList: %s is not found in %n baseMetricList: %s %n\",\r\n```"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/558", "comments": ["```suggestion\r\n* the changes to build the new component into ADOT Collector. \r\n```", "```suggestion\r\n* the performance test with the mocked endpoint will be performed in the github workflow after your code is merged to ADOT Collector repository. \r\n```", "```suggestion\r\nthere are some basic components needed to run the tests.\r\n```"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/537", "comments": ["Is there a reason we aren't just using the latest?", "Merging for now to get ci passing we can discuss later "]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/536", "comments": ["Shouldn't the other prometheus tests also use this image?"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/527", "comments": ["nitpick: These comments aren't really useful."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/525", "comments": ["This has arm support? ", "Currently not. But we can build it from the source code with same tags though. The current image is the same as old image (the only difference is converting from private to public though)"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/524", "comments": ["Is this actually a syntax issue? Doesn't the command still work without the quotes?", "looks like the command still works, its more of like a good practice/consistent syntax to include the quotes."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/515", "comments": ["You'll want to change it in more places than this one. There are a lot of testcases (`logzio_exporter_trace_mock`, `newrelic_exporter_metric_mock`, etc.) that use the default sample app, which is the spark app."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/499", "comments": ["This provider doesn't seem to be used", "We need to pin a version hwere for the eks module. We ran into the same issue with the `adot-op-cluster` where breaking changes made us unable to deploy. @sethAmazon  do you happen to have the version available? Would it be the same as the `adot-op-cluster` because we were dealing with the issue around the same time this PR was filed. ", "We also need to pin a VPC version", "Is there a reason this is deployed in `us-east-2` instead of `us-west-2` with our other testing clusters?", "Deployed in `us-east-2` due to limitations of number of vpcs available", "missing new line", "Used on line 102", "should this be `var.region`?", "No. Backend does not accept variables because `backend is initiated before variables initiated` according to https://github.com/hashicorp/terraform/issues/13022 . Therefore, we can only use hard-code variables for backend."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/498", "comments": ["Long value recorder is no longer supported. Closest I found was DoubleHistogram", "There is a long histogram but Meter only has double histogram  ", "There was a migration guide from 1.4.0 -> 1.5.0 https://github.com/open-telemetry/opentelemetry-java/discussions/3506\r\nI'm not sure how much it still applies, but they used the `LongHistogram` to replace the `LongValueRecorder`."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/495", "comments": ["Are these getters used? I don't see a change in the clients that calls them.", "This `sample_app` name should probably be `jaeger-zipkin-sample-app` since that's the directory.", "Did you run the `jaegar_mock` test? I'm a bit surprised this works. With the mock tests, if the `sample_app_image` is provided, it'll try to pull the image. Usually, I've seen it complain about credentials because the mock module isn't set up to login to ECR.", "This is public ecr", "I did test on my mac but maybe I was still logged in when I ran this. I still think this will work since it is public ecr and you should not have to log in to pull. ", "Should we log any information about `e` here as well?", "if we're only using `map` here, should we just pass it in directly to the tracer.inject() function?", "This has to do with how the java generics works for tracer.inject(v1,v2,v3) v2 and v3 must be of the same class. ", "Maybe I'm reading this wrong, but from the documentation, it looks like you need to authenticate in order to pull.\r\nhttps://docs.aws.amazon.com/AmazonECR/latest/public/docker-pull-ecr-image.html\r\n\r\n![image](https://user-images.githubusercontent.com/84729962/149197466-a4780fbc-9881-44b5-900f-4059a4cbb34e.png)\r\n", "Added", "From Tracer.java\r\n<C> void inject(SpanContext spanContext, Format<C> format, C carrier);", "Unfortunately \"public\" ECR does still effectively require login to avoid pull limits. It's a reason we can't run integration tests for instrumentation (which don't use terraform) against PR builds still - GHCR wouldn't have that problem. GHCR used to have an operations problem where images were all scoped to the organization but now they are scoped to repositories so perhaps we can give it a revisit, I notice we do seem to use it for python images already\r\n\r\nhttps://github.com/orgs/aws-observability/packages", "Changed to using ghcr as repo", "It looks like it was changed in the `zipkin_mock`, but not in the `jaeger_mock`.", "Should this be in `aws-otel-test-framework`? The sample app isn't really a part of the collector.", "Use old image until we can make ghrc public"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/480", "comments": ["is there any reason to make this configurable?", "This is to get the mock tests passing", "Our mocks only run on linux/amd64", "see https://github.com/aws-observability/aws-otel-collector/pull/870", "If you look in the logs it not defaulting the target which is weird because running a docker build will default "]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/473", "comments": ["would a default be useful here?", "Should this default be smaller? ", "As far as I can tell, this is only used by the performance tests. I don't know if we can reduce the size. Some of our performance tests take 20+ GBs of memory with our current setup. An m5.xlarge wouldn't have enough memory (16GB)."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/468", "comments": ["Does this cause exceptions in the collector? ", "It does not. https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/exporter/awsemfexporter has documentation about it, but the awsemf endpoint config allows the user to override the cloudwatch service endpoint. In this case, we're overriding it so the mock backend gets the request."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/460", "comments": ["do we need to keep the `isEmpty()` as i assume the empty keySet would equal the empty validatedSchema?", "nice makes much more sense \u2714\ufe0f ", "I'm not sure how this is being used in other tests. But I do think this could be removed. There are multiple validators that are inherited from this abstract. ", "okay we can try it in another PR as you suggested \u2714\ufe0f "]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/459", "comments": ["\r\nWhat are the comments for?", "The purpose of terraform backend s3 is to `uploading  terraform.tfstate to s3.` However, since the backend is not supporting condition checking with S3 bucket and DynamoDB Table currently; so first time dev setup which does not have DynamoDB Table and S3 bucket on their aws account will not able to pass the error. Therefore, it would be good for us to treat this as optional feature to upload it and let's the dev decide to use it or not. Moreover, I have documented it out for everyone to know more: https://github.com/aws-observability/aws-otel-test-framework/pull/459/files#diff-0776469b54a50b9aaf826b5d5b9d11f4f34df0af615498fe9222343fdd9d8d33R26-R35", "Maybe this can be added to setup?", "Currently, it is in the setup. My intention was uploading the terraform setup state file but currently found no way to upload it besides ```terraform apply``` a second time though."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/451", "comments": ["what will we need readonly s3 access for?", "Our sample app reaches out to s3 for extra traces  "]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/440", "comments": ["Should we add the auto approve. Some people might want to look at the terraform plan. ", "IDC either way ", "IMO, mostly the behavior from Dev when joining the first time is making sure its work beforehand. Also the frequency using terraform plan is less than terraform apply/destroy with -auto-approve. Therefore, it should be good for us to add terraform apply/destroy -auto-approve with any worries.", "I'm a bit confused. Why did you move this up? It used to be 2.4. If you're going to move things around, then you need to fix the links to the sections in the README.", "Mostly for consistency with what being show [in the README](https://github.com/aws-observability/aws-otel-test-framework/blob/terraform/README.md#2-run-testing-framework). Also fixed the links. Nice catch", "Have you tested this?", "Yes. Tested it at local and also it would be easier to keep it consistent with [Soaking Github workflow ](https://github.com/aws-observability/aws-otel-collector/blob/main/.github/workflows/soaking.yml#L52-L53)"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/438", "comments": ["Might want to look into https://commons.apache.org/proper/commons-lang/apidocs/org/apache/commons/lang3/StringUtils.html otherwise this is fine with me", "Looked through it. The equals will have problem [when the reference object is null](https://stackoverflow.com/questions/4501061/java-null-check-why-use-instead-of-equals/4501084#4501084) so I cannot use that. Therefore, it makes more sense for me to use [Object.equals ](https://stackoverflow.com/a/44799807) instead and I have already tested it out without any issue.", "Seems it is not feasible to use Object.equals since the PR build shows the errors https://github.com/aws-observability/aws-otel-test-framework/runs/4539943758?check_suite_focus=true (Cannot compare null with string )"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/437", "comments": ["Shouldn't this also only be created on fargate deployments? It seems fargate specific.", "Should've refreshed."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/435", "comments": ["Think you need to include the license header.", "Has this been tested? Maybe add a comment describing the steps this takes.", "What is `ATLAS_WORKSPACE_SLUG`? I don't see it used anywhere else.", "Is this meant to be the default?", "Yes I have tested this. \r\nTHUMBPRINT=$(echo | openssl s_client -servername oidc.eks.us-west-2.amazonaws.com -showcerts -connect oidc.eks.us-west-2.amazonaws.com:443 2>&- | tail -r | sed -n '/-----END CERTIFICATE-----/,/-----BEGIN CERTIFICATE-----/p; /-----BEGIN CERTIFICATE-----/q' | tail -r | openssl x509 -fingerprint -noout | sed 's/://g' | awk -F= '{print tolower($2)}')\r\n", "{\"thumbprint\": -thumb print is here-}", "This is some cargo cult programming on my end. I can remove. ", "Would recommend using the terraform-aws-modules for EKS. It handles a lot of the weirdness for setting up EKS and I've had good experience with it\r\n\r\nhttps://github.com/terraform-aws-modules/terraform-aws-eks", "Now I'm using the eks module. ", "Oops sorry forgot that vpc and eks are different modules. Let's use the VPC module to handle all of this gateway stuff automatically\r\n\r\nhttps://github.com/terraform-aws-modules/terraform-aws-vpc", "Any reason not to let it manage? I think it would let us remove many role definitions", "I think eks module supports `enable_irsa` to avoid having to setup this OIDC stuff manually", "terraform eks module automatically outputs a kubeconfig. We could set `kubeconfig_output_path` but I think it's better to not automatically modify the home directory with terraform, command line flag or env var can be used, or file can be manually copied.", "I believe this is hardcoded into terraform eks module and won't be needed when using `enable_isra`", "Don't think this is needed", "Maybe default or something instead of example", "It's OK but we generally wouldn't explicitly add depends_on, since we reference module.vpc in the resource config, terraform automatically adds the dependency", "Do we need this? I thought terraform eks module is automatically outputing it, it has a `kubeconfig_output_path` property\r\n\r\n"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/430", "comments": ["This is because one of the $ gets removed when you use this as a template file"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/426", "comments": ["Are these the final state of the policy or will end up going back and specify them out?", "We can specify them out later. I think this should be fine because we only create the policy for the test then we tear it down after test execution so a wild card policy is not floating around. ", "Considering we use a role with an admin policy currently this is really stripped down :) aoc-integ-test-dev"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/425", "comments": ["What does roll-up for? Any documents on that since I could not fine one.", "@khanhntd  Hi, rollup is a new feature for cwmetricsvalidator to enable or disable dimension rollup for expected test templates. By default it was set to true earlier, but with this newly implemented feature we can also turn it off. ", "For this port, can we set as a variable port instead of default one? ", "Can we set the account Id to a dynamic one instead of default one?", "```suggestion\r\n.DS_Store\r\n**/.DS_Store\r\n```\r\nhttps://git-scm.com/docs/gitignore\r\n>A leading \"**\" followed by a slash means match in all directories. For example, \"**/foo\" matches file or directory \"foo\" anywhere, the same as pattern \"foo\".", "I don't think we need to duplicate this file in our repo. We can probably just link to the example in our docs. https://github.com/kubernetes-sigs/aws-load-balancer-controller/blob/main/docs/examples/2048/2048_full.yaml", "This I was going to change in the next phase. ", "Got cha. Should  catch up with the plan for the current phase.", "Are we using a fixed config for each of the tests? Can we use a template and render setup?", "Is this the same config as in `aoc_fargate_deploy.yml`?", "Reasonable. Thanks for explaining. ", "It's a bit difficult to parse nested ternary statements. Can we use parentheses to break it up?", "That link does not use the default namespace. It uses another namespace. ", "I can add that in later commits. So we can get the testing in.", "Is that the only difference?", "Yes the first file contains the fill config. I can delete it. Sorry I was using it as a reference. ", "yes", "Eventually this will be removed when I get the cluster creation fully working. ", "So, could you explain that in the doc instead of adding the file? Like\r\n> * Create Ingress controller fargate\r\nDownload config [here](https://github.com/kubernetes-sigs/aws-load-balancer-controller/blob/main/docs/examples/2048/2048_full.yaml) and replace all instances of namespace `game-2048` with `default`.", "This image is in a personal ECR account. Let's replace it with `nginx:latest` and remove the command section. ", "Let's rename this to `app-container` in 5 places. This is not related to Fluent Bit. It was added only for testing purposes. "]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/424", "comments": ["```suggestion\r\n    log.info(\"Fetch and validate logs with types: \" + String.join(\", \", schemasToValidate.keySet()));\r\n    for (String logType : schemasToValidate.keySet()) {\r\n```"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/412", "comments": ["One of the reason I changed this is because the `private repo image does not have the latest tag` except the public one. Therefore, we could change this in this PR or another PR if that make sense.", "One of the reason I added this is because the [expected metric template ](https://github.com/aws-observability/aws-otel-test-framework/blob/terraform/validator/src/main/resources/expected-data-template/ecsContainerExpectedMetric.mustache#L2-L7) needs to `get the metrics from the container context`. However, the current context does not have that. Therefore, `it returns NullPointerException whenever variable sample_app_callable return true`. ", "Can we have the reformat in a diff pr?", "Yes, we can. Fixed it. "]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/411", "comments": ["These should be provided as a terraform config for making it easier to run. If the reason to not include the k8s setup in the test tf files is the time it takes to provision a cluster (it is indeed best practice to decouple cluster creation and use) it's still good to provide these as a separate terraform deployment instead of manual steps.", "Sorry read your doc now and realized that this is your plan - that being said, it might be easier to achieve it if this is a separate installation step, but using terraform.", "The current functionality for eks testing is we do not bring up an eks cluster.", "Could we use parentheses to clarify the ternary statements or could it be rewritten like this?\r\n```suggestion\r\n  sample_app_endpoint          = length(kubernetes_ingress.app) > 0 ? (var.deployment_type == \"fargate\" ? \"http://${kubernetes_ingress.app.0.load_balancer_ingress.0.hostname}:80\" : \"http://${kubernetes_service.sample_app_service.0.load_balancer_ingress.0.hostname}:${module.common.sample_app_lb_port}\") :  \"\"\r\n```", "Yeah but here we're documenting complicated steps for starting up a cluster - instead we should provide a simple way to do it, with just a single terraform command. And it should make it easier in the future to move toward automatically bringing up the cluster in tests too. I don't think it's worth adding these complicated steps now instead of modeling them with terraform (a separate deployment, not part of the test, for now)"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/407", "comments": ["The format is due to the linter. \r\n+ must be a on a new line \r\nMust be under 100 char"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/406", "comments": ["Is this needed or is this just to match convention? ", "This is for mod caching? ", "This is not needed. I just copied over that part of the Dockerfile from the other mocked_servers. Didn't notice they were different.", "It's not for it, but I believe it will cache the modules if the go.mod doesn't change between runs.", "I think in order to achieve that you might need to copy just `go.mod` and `go.sum` as otherwise any changes in other files would cause a different layer hash a couple steps previously and force this step to execute again.  The remaining files could be copied in after this step."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/405", "comments": ["This has to do with when there is one metric it will set the quantile as 0 and 1. This is really 1 metric ", "Values can be random since we are testing a latency metric. It is not a static value.", "The spark app sends out the otlp metrics. Thus call the generator is this step. "]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/403", "comments": ["is there a default for this grpc_port value or does it have to be specified?", "There is a default", "4317", "This looks just like the `default-mocked-server-validation.yml`", "Most of the other tests set the logging level to debug.", "The other tests do not run the log exporter. Look at the exports portion of the test ", "Yes it is the same since mock server tests do not validate data, it only validates if data is sent to the mock server do you think I should use that yml file? ", "What's the difference between these files? https://github.com/aws-observability/aws-otel-test-framework/blob/terraform/validator/src/main/resources/validations/default-mocked-server-validation.yml", "If they're the same, then I don't see a reason to make another one.", "I can change this to what other tests do if you think I should ", "https://github.com/aws-observability/aws-otel-test-framework/blob/a61d96e03129b20f252ab41b256de6faf5ffa540/terraform/testcases/otlp_metric/otconfig.tpl#L13-L24", "It's more of a nitpick. All of the other tests use debug."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/396", "comments": ["Please add a comment saying open ssl must be installed without sudo requirement for this to work. At least I think you will need to install open ssl for this to work. "]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/395", "comments": ["Think it's better to use the OTel docker build tool\r\n\r\nhttps://github.com/open-telemetry/build-tools/blob/main/protobuf/README.md", "Recommend `gcr.io/distroless/static` in case the lack of TLS certificates becomes an issue even in a mocked server in the future since the errors can be very mysterious", "Is it necessary to have a separate stage for this?  What advantage does it provide?", "Perhaps even `gcr.io/distroless/static:nonroot` since we shouldn't need to be running as root.", "Ended up just using https://github.com/open-telemetry/opentelemetry-proto-go instead as suggested by @Aneurysm9 ", "Does this require a completely separate implementation?  This looks almost identical to the metrics implementation.", "It's identical just uses different protos.", "I copied it from the prometheus sample app https://github.com/aws-observability/aws-otel-test-framework/blob/terraform/sample-apps/prometheus/Dockerfile\r\n\r\nI don't think it's necessary to have the separate stage.", "Once gcr.io use has been verified, I can make the changes.", "Is this still needed? ", "It's not. Good catch!", "Is the entire directory needed or do you only need to copy certain files? ", "I would assume yes on this. ", "There's only 4 files in the directory to begin with. I guess I don't need to pull in the Dockerfile, but I don't think that'll make much of a difference.", "```suggestion\r\n\th.mu.Lock()\r\n\r\n\th.data = SuccessMessage\r\n\th.transactions++\r\n\t\r\n\th.mu.Unlock()\r\n```\r\n\r\nNo need to retain the lock while sleeping.  I suspect that the lock could be removed entirely using [`sync/atomic`](https://pkg.go.dev/sync/atomic) types.  `h.data` is basically a boolean indicating whether data was ever received and thus can be replaced with `h.transactions > 0`.  That can be addressed in a followup PR if throughput becomes an issue.", "```suggestion\r\n\t// Calculate duration in minutes\r\n\tnow := time.Now()\r\n\tduration := now.Sub(h.startTime)\r\n\t\r\n\th.mu.Lock()\r\n\ttpm := h.transactions / int(duration.Minutes())\r\n\th.mu.Unlock()\r\n```\r\n\r\nAgain, minimize lock contention where you can.", "```suggestion\r\n```\r\n\r\nThese are the zero values for their types, no need to explicitly initialize them.", "Switched to using `AddUint32`, `LoadUint32`, and `StoreUint32` instead of locking."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/385", "comments": ["Magic number 1000000", "nitpick: Move up to line 24.\r\n```suggestion\r\n  private static final int BYTES_IN_MEGABYTES = 1000000;\r\n```"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/383", "comments": ["Not sure if this one is needed? Maybe AWS X-Ray backend uses this to set the `AWS::S3` origin?", "Doesn't service go here, not in metadata?", "Yeah I was surprised about this too, but based on my test with the most recent release layer I don't see it there? Here is a screenshot of the raw data on AWS X-Ray:\r\n\r\n<img width=\"449\" alt=\"image\" src=\"https://user-images.githubusercontent.com/23139455/140793558-4c173729-6a59-478a-9d0b-707d32e5420b.png\">\r\n\r\nI put a more concise version of the entire raw data in the PR description (it is using the default Lambda function we provide in the [opentelemetry-lambda repo](https://github.com/open-telemetry/opentelemetry-lambda/blob/2921a4582fd0796585195a7cebdce74458342b22/python/sample-apps/function/lambda_function.py)), but here is the entire output if that is convenient \ud83d\ude42 \r\n\r\nI guess this means the X-Ray backend must be reading the `metadata` since the collector is not populating service in the `\"aws\"` key?\r\n\r\n```\r\n{\r\n    \"Id\": \"1-6189643c-0a5ed1e06cae8505021d6d20\",\r\n    \"Duration\": 3.315,\r\n    \"LimitExceeded\": false,\r\n    \"Segments\": [\r\n        {\r\n            \"Id\": \"51014f1583193090\",\r\n            \"Document\": {\r\n                \"id\": \"51014f1583193090\",\r\n                \"name\": \"Python-1-5-API-GateWay-OTel\",\r\n                \"start_time\": 1636394046.2079146,\r\n                \"trace_id\": \"1-6189643c-0a5ed1e06cae8505021d6d20\",\r\n                \"end_time\": 1636394046.9450457,\r\n                \"parent_id\": \"aa80a1f3c893f2d4\",\r\n                \"fault\": false,\r\n                \"error\": false,\r\n                \"throttle\": false,\r\n                \"aws\": {\r\n                    \"xray\": {\r\n                        \"auto_instrumentation\": false,\r\n                        \"sdk_version\": \"1.5.0\",\r\n                        \"sdk\": \"opentelemetry for python\"\r\n                    }\r\n                },\r\n                \"metadata\": {\r\n                    \"default\": {\r\n                        \"otel.resource.telemetry.sdk.name\": \"opentelemetry\",\r\n                        \"faas.id\": \"arn:aws:lambda:us-west-2:<ACCOUNT_ID>:function:Python-1-5-API-GateWay-OTel\",\r\n                        \"otel.resource.faas.name\": \"Python-1-5-API-GateWay-OTel\",\r\n                        \"faas.name\": \"Python-1-5-API-GateWay-OTel\",\r\n                        \"faas.version\": \"$LATEST\",\r\n                        \"faas.execution\": \"4cdd4679-1173-47e6-a42c-2b58aa55db7c\",\r\n                        \"otel.resource.cloud.region\": \"us-west-2\",\r\n                        \"otel.resource.service.name\": \"Python-1-5-API-GateWay-OTel\",\r\n                        \"otel.resource.telemetry.sdk.language\": \"python\",\r\n                        \"otel.resource.cloud.provider\": \"aws\",\r\n                        \"otel.resource.faas.version\": \"$LATEST\",\r\n                        \"otel.resource.telemetry.sdk.version\": \"1.5.0\"\r\n                    }\r\n                },\r\n                \"subsegments\": [\r\n                    {\r\n                        \"id\": \"d9f4fddc5bc49889\",\r\n                        \"name\": \"HTTP GET\",\r\n                        \"start_time\": 1636394046.2276938,\r\n                        \"end_time\": 1636394046.4599159,\r\n                        \"fault\": false,\r\n                        \"error\": false,\r\n                        \"throttle\": false,\r\n                        \"http\": {\r\n                            \"request\": {\r\n                                \"url\": \"http://httpbin.org/\",\r\n                                \"method\": \"GET\"\r\n                            },\r\n                            \"response\": {\r\n                                \"status\": 200,\r\n                                \"content_length\": 0\r\n                            }\r\n                        },\r\n                        \"aws\": {\r\n                            \"xray\": {\r\n                                \"auto_instrumentation\": false,\r\n                                \"sdk_version\": \"1.5.0\",\r\n                                \"sdk\": \"opentelemetry for python\"\r\n                            }\r\n                        },\r\n                        \"namespace\": \"remote\"\r\n                    },\r\n                    {\r\n                        \"id\": \"7b60c864be47092d\",\r\n                        \"name\": \"S3\",\r\n                        \"start_time\": 1636394046.5654962,\r\n                        \"end_time\": 1636394046.9063969,\r\n                        \"fault\": false,\r\n                        \"error\": false,\r\n                        \"throttle\": false,\r\n                        \"http\": {\r\n                            \"request\": {},\r\n                            \"response\": {\r\n                                \"status\": 200,\r\n                                \"content_length\": 0\r\n                            }\r\n                        },\r\n                        \"aws\": {\r\n                            \"xray\": {\r\n                                \"auto_instrumentation\": false,\r\n                                \"sdk_version\": \"1.5.0\",\r\n                                \"sdk\": \"opentelemetry for python\"\r\n                            },\r\n                            \"region\": \"us-west-2\",\r\n                            \"operation\": \"ListBuckets\",\r\n                            \"request_id\": \"QGNTZRZRSTMNJ7WN\"\r\n                        },\r\n                        \"metadata\": {\r\n                            \"default\": {\r\n                                \"aws.service\": \"s3\",\r\n                                \"retry_attempts\": 0\r\n                            }\r\n                        },\r\n                        \"namespace\": \"aws\"\r\n                    }\r\n                ]\r\n            }\r\n        },\r\n        {\r\n            \"Id\": \"210945ae60512faf\",\r\n            \"Document\": {\r\n                \"id\": \"210945ae60512faf\",\r\n                \"name\": \"Python-1-5-API-GateWay-OTel\",\r\n                \"start_time\": 1636394044.454,\r\n                \"trace_id\": \"1-6189643c-0a5ed1e06cae8505021d6d20\",\r\n                \"end_time\": 1636394047.769,\r\n                \"http\": {\r\n                    \"response\": {\r\n                        \"status\": 200\r\n                    }\r\n                },\r\n                \"aws\": {\r\n                    \"request_id\": \"4cdd4679-1173-47e6-a42c-2b58aa55db7c\"\r\n                },\r\n                \"origin\": \"AWS::Lambda\",\r\n                \"resource_arn\": \"arn:aws:lambda:us-west-2:<ACCOUNT_ID>:function:Python-1-5-API-GateWay-OTel\"\r\n            }\r\n        },\r\n        {\r\n            \"Id\": \"6d190c52179b6225\",\r\n            \"Document\": {\r\n                \"id\": \"6d190c52179b6225\",\r\n                \"name\": \"Python-1-5-API-GateWay-OTel\",\r\n                \"start_time\": 1636394046.206664,\r\n                \"trace_id\": \"1-6189643c-0a5ed1e06cae8505021d6d20\",\r\n                \"end_time\": 1636394047.7654328,\r\n                \"parent_id\": \"210945ae60512faf\",\r\n                \"aws\": {\r\n                    \"account_id\": \"<ACCOUNT_ID>\",\r\n                    \"function_arn\": \"arn:aws:lambda:us-west-2:<ACCOUNT_ID>:function:Python-1-5-API-GateWay-OTel\",\r\n                    \"resource_names\": [\r\n                        \"Python-1-5-API-GateWay-OTel\"\r\n                    ]\r\n                },\r\n                \"origin\": \"AWS::Lambda::Function\",\r\n                \"subsegments\": [\r\n                    {\r\n                        \"id\": \"fe2b475aacb3f09f\",\r\n                        \"name\": \"Initialization\",\r\n                        \"start_time\": 1636394044.5885403,\r\n                        \"end_time\": 1636394046.2052553,\r\n                        \"aws\": {\r\n                            \"function_arn\": \"arn:aws:lambda:us-west-2:<ACCOUNT_ID>:function:Python-1-5-API-GateWay-OTel\"\r\n                        }\r\n                    },\r\n                    {\r\n                        \"id\": \"aa80a1f3c893f2d4\",\r\n                        \"name\": \"Invocation\",\r\n                        \"start_time\": 1636394046.2069714,\r\n                        \"end_time\": 1636394047.7519643,\r\n                        \"aws\": {\r\n                            \"function_arn\": \"arn:aws:lambda:us-west-2:<ACCOUNT_ID>:function:Python-1-5-API-GateWay-OTel\"\r\n                        }\r\n                    },\r\n                    {\r\n                        \"id\": \"c3650172c503402d\",\r\n                        \"name\": \"Overhead\",\r\n                        \"start_time\": 1636394047.7520638,\r\n                        \"end_time\": 1636394047.7653346,\r\n                        \"aws\": {\r\n                            \"function_arn\": \"arn:aws:lambda:us-west-2:<ACCOUNT_ID>:function:Python-1-5-API-GateWay-OTel\"\r\n                        }\r\n                    }\r\n                ]\r\n            }\r\n        },\r\n        {\r\n            \"Id\": \"2221f6e3138a697f\",\r\n            \"Document\": {\r\n                \"id\": \"2221f6e3138a697f\",\r\n                \"name\": \"HTTP GET\",\r\n                \"start_time\": 1636394046.2276938,\r\n                \"trace_id\": \"1-6189643c-0a5ed1e06cae8505021d6d20\",\r\n                \"end_time\": 1636394046.4599159,\r\n                \"parent_id\": \"d9f4fddc5bc49889\",\r\n                \"inferred\": true,\r\n                \"http\": {\r\n                    \"request\": {\r\n                        \"url\": \"http://httpbin.org/\",\r\n                        \"method\": \"GET\"\r\n                    },\r\n                    \"response\": {\r\n                        \"status\": 200,\r\n                        \"content_length\": 0\r\n                    }\r\n                }\r\n            }\r\n        },\r\n        {\r\n            \"Id\": \"043674cb1059683b\",\r\n            \"Document\": {\r\n                \"id\": \"043674cb1059683b\",\r\n                \"name\": \"S3\",\r\n                \"start_time\": 1636394046.5654962,\r\n                \"trace_id\": \"1-6189643c-0a5ed1e06cae8505021d6d20\",\r\n                \"end_time\": 1636394046.9063969,\r\n                \"parent_id\": \"7b60c864be47092d\",\r\n                \"inferred\": true,\r\n                \"http\": {\r\n                    \"request\": {},\r\n                    \"response\": {\r\n                        \"status\": 200,\r\n                        \"content_length\": 0\r\n                    }\r\n                },\r\n                \"aws\": {\r\n                    \"xray\": {\r\n                        \"auto_instrumentation\": false,\r\n                        \"sdk_version\": \"1.5.0\",\r\n                        \"sdk\": \"opentelemetry for python\"\r\n                    },\r\n                    \"region\": \"us-west-2\",\r\n                    \"operation\": \"ListBuckets\",\r\n                    \"request_id\": \"QGNTZRZRSTMNJ7WN\"\r\n                },\r\n                \"origin\": \"AWS::S3\"\r\n            }\r\n        }\r\n    ]\r\n}\r\n```", "Huh this is unexpected but it looks to be the case, e.g. in the X-Ray SDK for Java we record the `aws.operation` attribute in the AWS SDK instrumentation but never `aws.service`, and there is no key for service in our reserved `aws` attribute keys: https://github.com/aws/aws-xray-sdk-java/blob/c2d101b5c0ea9c087776e1d27c3d264ed5f4ac86/aws-xray-recorder-sdk-aws-sdk/src/main/java/com/amazonaws/xray/handlers/TracingHandler.java#L188\r\n\r\nI guess that makes sense because we're recording the service name as the name of the subsegment.\r\n\r\n> I guess this means the X-Ray backend must be reading the metadata since the collector is not populating service in the \"aws\" key?\r\n\r\n@NathanielRN can you explain what you mean here?", "Sorry, this may just be my incorrect assumption. I was assuming that the `\"aws\"` key in the segment document is created by the AWS X-Ray exporter in the ADOT collector. i.e. this part of the \"Document\":\r\n\r\n```json\r\n\"aws\": {\r\n    \"xray\": {\r\n        \"auto_instrumentation\": false,\r\n        \"sdk_version\": \"1.5.0\",\r\n        \"sdk\": \"opentelemetry for python\"\r\n    }\r\n},\r\n```\r\n\r\nThen, later when AWS X-Ray backend creates the `inferred: true` span, you see the following updated value for this `\"aws\"` key:\r\n\r\n```json\r\n\"aws\": {\r\n    \"xray\": {\r\n        \"auto_instrumentation\": false,\r\n        \"sdk_version\": \"1.5.0\",\r\n        \"sdk\": \"opentelemetry for python\"\r\n    },\r\n    \"region\": \"us-west-2\",\r\n    \"operation\": \"ListBuckets\",\r\n    \"request_id\": \"QGNTZRZRSTMNJ7WN\"\r\n},\r\n```\r\n\r\nSo I assumed the X-Ray backend is **reading the default.metadata** key to be able to set things like `\"operation\": \"ListBuckets\"`.\r\n\r\nFinally, to update the X-Ray console UI, I guess X-Ray backend reads from `aws.operation` for operation (as seen above). Because (as we noticed) `aws.serivce` does not exist, I assumed it reads from `default.metadata.\"aws.service\"` to determine the `\"origin\": \"AWS::S3\"` and name and other things.\r\n\r\nBut maybe it does not do that at all and just reads from the segment name. Maybe that's the same conclusion you came to when you said this @willarmiros\r\n\r\n> I guess that makes sense because we're recording the service name as the name of the subsegment.\r\n\r\n", "Yeah, I think generally speaking because metadata is typically customer-defined (except in the case of ADOT which the backend is still not really aware of) the backend rarely if ever attempts to parse the content of the metadata. But hopefully that can change in the future as the backend becomes more aware of the otel semantic conventions/they become more stable.", "Ah I guess service was leftover from code initially inherited from the opencensus x-ray exporter. In that case we probably don't need to validate that here, and presumably do validate the subsegment name which seems to be what the backend uses.", "Sounds good! I assumed you meant we don't need to verify that `aws.service` is set in the `metadata.default` so I have removed it from this template."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/381", "comments": ["Good catch", "can't?"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/336", "comments": ["Never use insecure! Change the URL to https (ideally replace with a library from Maven Central)", "For reference, ported this to new API here https://github.com/aws-observability/aws-otel-java-instrumentation/blob/main/sample-apps/springboot/src/main/java/com/amazon/sampleapp/MetricEmitter.java", "if we don't need it, why not remove it?"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/332", "comments": ["it looks the yaml content is not well formatted as well in this PR", "I changed the formatting to match the otlp_trace_adot_operator. It works now. ", "I think the formatter is putting this file at the begging of line thus we need a double indent. https://github.com/aws-observability/aws-otel-test-framework/blob/terraform/terraform/eks/adot-operator/adot_collector_deployment.tpl https://github.com/aws-observability/aws-otel-test-framework/blob/terraform/terraform/testcases/otlp_trace_adot_operator/otconfig.tpl"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/318", "comments": ["can we make the `mode` as variable? what if we need to add the test cases running in daemonset, etc. ", "Yeah, this makes sense. I will make the change.", "nit: can we remove `demo` from module name?", "what is the mocked server setup variables for? I am not seeing these placeholders in `./adot-operator/adot_collector_deployment.tpl` template", "Yeah, sure", "It's my fault. I set it up when debugging and forgot to delete."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/317", "comments": ["I know there are some metric related breaking changes after OTel 1.3.x SDK. Could you help to run `otlp-metric ` test case before merging the change?", "Or can we split this PR. let's put the SDK upgrade into a separate PR?", "Sounds good. I'll separate and test it."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/316", "comments": ["do we need to retire `prometheus-sd-validation.yml` which is used to validate AMP exporter test case?", "If the current prometheus-sd-validation.yml is still used to validate AMP exporter with the current sample-apps setup, we should not retire it.", "This validator will also be used for validating the metrics coming in from aws-otel-lambda."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/308", "comments": ["do we only verify 2 kind of workloads?", "We can't verify nginx plus unless we change a email every 30 days to get a trail. The app mesh environment is too hard to setup using terraform and is not that useful because as long as one workload is running, it should works for other, the discovery and scraping mechanism is the same."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/298", "comments": ["The log for eks and ecs container insight is different, I am not sure if you need to update this file since you already defined the same list in `ConatinerInsightECSStructuredLogValidator.java`", "Thanks for pointing it out, I forget correcting it.", "can we define these magic code as constants?", "can we define these magic code as constants?\r\n\r\n", "can we define these magic code as constants?\r\n\r\n", "maybe add a unittest for it?", "Is this log group name correct? I think ecs container insight has `ecs` in log group name, they one w/o `ecs` is for `eks`, you can deploy a cwagent and see it's behaviour.  Also the log group is used by ecsagent (or other agent?) as well for generating most metrics (except for instance).\r\n\r\nThough even if the logroup name is wrong, as long as emf log has the right namespace, container insight dashboard still work (at least for prometheus, didn't try ecs instance).", "Can I block Ying for my future PR, I didn't write any unit test for ecs prometheus test /w", "@pingleig  Yea, you are right, the log group name should be` /aws/ecs/containerinsights/{ClusterName}/performance`", "Sure, will make it as constants.", "Not sure how to do that, this `filterPattern` will be changed with different `logType`", "i just added some unit-tests, maybe [this](https://github.com/aws-observability/aws-otel-test-framework/blob/terraform/validator/src/test/java/com/amazon/aoc/validators/ContainerInsightPrometheusMetricsValidatorTest.java) can be a quick example.", "Actually I changed the logic here in recent PR\r\n\r\nhttps://github.com/aws-observability/aws-otel-test-framework/blob/acddf135e1205078a2eb720540ed503e084bb751/terraform/ecs/main.tf#L49\r\n\r\n https://github.com/aws-observability/aws-otel-test-framework/blob/acddf135e1205078a2eb720540ed503e084bb751/terraform/ecs/main.tf#L287-L303\r\n\r\nhttps://github.com/aws-observability/aws-otel-test-framework/blob/acddf135e1205078a2eb720540ed503e084bb751/terraform/templates/defaults/cloudwatch_context.json#L2\r\n\r\nThe default json contains cluster name, can you change to use the default.\r\n", "Is vpc a valid default value? should it be `awsvpc`?", "Yea, you are right it should be awsvpc. Thanks!", "Changed it thanks!"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/297", "comments": ["Maybe we can send more detail info like how long it takes for ssm installation? Though that logic can be put into the python script.", "Is there a way to get the last element in list in terraform? ", "SSM service has sent such metrics to owner of SSM package. This is only for canary test and will align with other canary testcases.", "Something like element(split(\"/\", var.testcase), length(split(\"/\", var.testcase))-1) should work. However the same statement is used to get testcase name by performance and soaking tests. Prefer to refactoring all of them in separate PR."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/296", "comments": ["Why logging is required?", "I'll remove it. it was for debugging."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/295", "comments": ["I would prefer merge `LocalPathExpectedTemplate` and `PredefinedExpectedTemplate` into one, and register the predefined templated into local. It looks like predefined is just a subset of local path.", "Is it possible to make the functions in Helper class static?", "It's sad to see the exception is less specific. Any thoughts?", "Can the transformation be simplified as `getPath().toString()`?", "there're two differences driving me divide them into two.\r\n1.  PredefinedExceptedTemplate uses different way to get its file path: `GetResource.GetPath()`, as its interface FileConfig defined, the function `getPath` is the key for different implementation.\r\n\r\n2. PredefinedExcecptedTemplate is an enum class, i'm not sure how to merge them together, it will be great if you can shed me some lights? ", "i wonder what's the benefit to make it static?  I tended to use non-static class/function as they are more friendly to unit-test(it's not easy to mock static functions/classes), but i'm open to change it if it's the best practice to use static here. ", "good point! we should try our best to have specific exceptions defined in most of the cases. will change it back.", "yes, we can, thanks for pointing out!", "Usually `static` could better explain that methods are stateless, it would also slightly improve the runtime performance, which won't make any difference here in the integration test... I don't think it worths much effort to change it to static.", "Get it. The pain is we need to convert a string to a built-in FileConfig. Let's keep it as what it is, merging two won't make the whole thing easier. Please help update the comment of `PredefinedExpectedTemplate`, I think we need to refine the class name in the java doc.", "thanks! learned now :)"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/289", "comments": ["Should we call it `AbstractCWMetricsValidator` to make it clear it is only for cloudwatch metrics.", "Might change it to something like schemas , pending schemas or schemasToValidate (because you remove the item when it passes the validation) ? It seems there is method with same name `validateJsonSchema` as well.", "Can we provide a way to toggle the report level?  When missing field, the validator does not throw exception in default level and it's hard to debug. The draw back is once enabled it will print a lot of useless information as most time only a few log in the stream matches the full schema. It's mainly for debugging during development.", "Done", "Changed to `schemasToValidate`", "Supported the exception level customization. I agree that we possibly can't benefit from it for CI job, but I feel it would be useful when unit testing Validators. Nice to have it."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/287", "comments": ["do we also need to add these lock checks for Debian10 below?", "It is for all Debian based distributions including Debian 10."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/281", "comments": ["I would suggest to add some comments for this file to explain it is for container insights. Or you could rename the file to `CIAgent.tf`", "So the service account is shared for all eks test cases? Just wondering if there is any issues because different test cases require different permissions. If two test cases are running at the same time, will this service account be assigned with different permissions. ", "Oops, I thought CI stood for continuous integration... ", "I don't think so. `ServiceAccount` is namespaced level resource. Also `ClusterRole` and `ClusterRoleBinding` are all suffixed with testing id (although I do feel we can downgrade RBAC into namespaced level too). As long as the two test cases are not executed in a same container at the same time, we'll be good. ", "would be possible we place template files under `https://github.com/aws-observability/aws-otel-test-framework/tree/terraform/terraform/templates`?", "better have a var as namespace and construct in one place (maybe in `shared`)?", "we use >= for kubectl and ~> for kubernetes, is it intended? or we are okay with big version upgrade?", "would every testcase need kubectl? \r\nbut i think it's okay to leave it created since it makes not hurts and save \"ifelse\".", "better put local vars definition at the beginning of the file", "better have a var for namespace name as we use it multiplaces?", "now i kinda understand what's `aoc_base`.  this name seems not quite verbose, and in some cases like testing promotheus exporter we uses mock server as well.  maybe think of another name? for example: `launch_mock_server` ?\r\n\r\nif the only difference is mockserver, maybe we just leave mockserver there so that we don't need those ifelses?", "do we need a default value here?", "would be possible move it to the setup folder? and have a parameter to control whether these policies are needed? so that we keep setup material in one place.", "i seems don't find \"infra\" used any places?", "I'm thinking would it be better to keep those related file together.", "This is a file ported from @pxaws 's PR. I think he could possibly give a good answer~", "No. Currently only container insight infra tests would use `kubectl` provider. As providers are global-wise configuration, I would prefer to have them stayed in `main.tf` to avoid duplicated declaration in the future. That's my original thinking. ", "I think it's already in setup folder, isn't it?", "It is used to overwrite the default value of `otlp` to avoid creating otlp related resources.", "We could have one. I thought it was unnecessary because `/eks/otlp` is actually an inner module of `eks` (to isolate bootstrap process for otls, prometheus and infra), the var input is taken cared of by us, and is not exposed to end user. ", "Thanks for the second thought. Another difference is declared here. Let me know if the current name would look any better. https://github.com/aws-observability/aws-otel-test-framework/pull/280#discussion_r624341233", "No. There shouldn't be any hardcode elsewhere for namespace value. Updated to use reference.", "Done", "Thanks for pointing out the issue. I don't think we should hardcode namespace elsewhere.\r\nhttps://github.com/aws-observability/aws-otel-test-framework/pull/281#discussion_r624363642"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/280", "comments": ["license header?", "i assume shared.tf will not only be used for config file, but all the shared resources? ", "what's the other possible values for aoc_base? trying to understand it's meaning.", "Added comments to the variable. The deployment spec of AOC will be different under different scenarios, this is used to identify the testing purpose.", "Changed the name to `oltp.tf` to avoid confusion. Basically it's the file that is used for both `pull mode` and `push mode`, sth. like the `main.tf` in a module, but I couldn't think of a good name. Any suggestion is also welcomed.", "Nice catch, thx!"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/276", "comments": ["If my memory didn't fail me, `eks:cluster-name` is not a guaranteed tag on every ec2 instance launched by eksctl.\r\nThe `kubernetes.io/cluster/<cluster-name>: owned` is the only reliable tag.\r\n\r\nRef: https://docs.aws.amazon.com/eks/latest/userguide/worker.html", "Shall we make it amendable?", "Better to add more validation under `_aws`, e.g.\r\nhttps://github.com/aws-observability/aws-otel-test-framework/blob/911979fedeb9a520e2b90906645ea6835b39842e/validator/src/main/resources/expected-data-template/container-insight/eks/prometheus/appMesh.json#L10-L19", "Could you please remove this line?", "nit: ClusterRoleBinding doesn't depend on the creation of the object it binds to the ClusterRole. \r\nThe service account is not created for controller, it's safe to remove the service_account from `depends_on`, it seems to be redundant.", "Is the variable referred anywhere?", "Sure. I missed the placeholder here.", "Right! I will add them.", "Sure.", "It's not used. I will remove it.", "Actually since we are checking metrics after structured log, we don't really need to check those emf related fields \ud83d\udc36 ", "I will remove the usage of the upstream processor and do the cluster name detection inside receiver (like what cloudwatch agent does).", "Sure. I will remove it"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/271", "comments": ["Can you change the name to be something like \"eks-container-insight-prometheus-log\" so that it's different from the container insight case? Same for line 65", "rename to `findJsonSchemaForValidation`?  ", "rename to `updateSchemaValidationResults`? ", "Done", "Yeah, better! Done.", "Done"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/267", "comments": ["\ud83d\udc4d ", "can we not use `hack` as folder name?", "There are other projects using hack folder as well, e.g. k8s https://github.com/kubernetes/kubernetes/tree/master/hack\r\n\r\nThough we can change it to something like `tools` or move it to a `cmd/aotutil` so it's more go project style, but this is a java project ... ", "Moved to cmd cc @bjrara PTAL", "Could you please remove the empty block?", "I would prefer checking `act` as well before return in case of failure retries.", "it stops on error and we expect f to swallow the error if it thinks it is retry-able. I have updated the comment."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/264", "comments": ["maybe change it to `install_mode` with some 'enums' like package manager (i.e. download deb/rpm directly in user data) or `ssm`\r\n\r\nOr reuse `install_package_source` (See comments in other files).", "Actually we can convert those shell script into go code to make life easier. I haven't created the PR for https://github.com/aws-observability/aws-otel-test-framework/issues/255 it has some ssm wrapper for patching related ssm status query.", "Can we reuse `install_package_source` to have `ssm` instead of having both `install_package_source` and `ssm_mode`? ", "Why we want to disable setup mocked server cert when using ssm?", "There should be indent here, if you install terraform plugin, it can format the file like other languages. Though existing format in ec2/main.tf is not consistent, and you can configure tf to align properties in different ways.\r\n\r\nI will create another pr for the formatting, format the entire file will the pr hard to read. https://github.com/aws-observability/aws-otel-test-framework/issues/265\r\n\r\n![Screen Shot 2021-04-03 at 2 45 39 PM](https://user-images.githubusercontent.com/72180622/113492308-61605400-948b-11eb-8102-d4e4d43e3684.png)\r\n\r\n\r\n", "Agree. I will use install_package_source for installation methods. However I want to keep ssm_mode to disable terraform resources for SSM testcase.", "Agree. Golang will make error handling easier. No matter what language, the logic of async execution is required. The testcase should fail when any error occurs. We can use bash script for now and convert its logic to golang later.", "Agree.", "Actually SSM testcase don't use mocked server instance. It will only check whether ADOT Collector is running in aoc instance.", "Agree", "I think it's better to add a var to disable mocked server to common e.g. `var.disable_mocked_server`, because there are other tests that don't require mocked server. Then when testing ssm you can set that variable to true. I am not sure if there is one hanging around, though since ssm is only for ec2 using ssm_mode should be fine as well.", "Good idea. I add `disable_mocked_server` and `enable_ssm_validate` to replace `ssm_mode`. All new variable definitions are moved into terraform/ec2/variables.tf because it is only for ec2 test."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/261", "comments": ["can we make the version of load generator an [arg](https://docs.docker.com/engine/reference/builder/#arg)", "I think builder is more common, it makes ppl life easier when they copy and paste, so +1 for reverting back to `builder`.", "Just curious,  where do we we define those port numbers and the are targeting to the receivers in otel col? I guess they were originally from existing stand alone daemon for ziplin and jaeger?", "I think you didn't use jib in the config ... and we are not using jib when building image in terraform as well .. https://github.com/aws-observability/aws-otel-test-framework/blob/09fdedd1c80f2fbe8fbdc91787f612a5cea93535/terraform/imagebuild/main.tf#L59\r\n\r\nIt seems @anuraaga introduced jib, is it only used for local test?", "shouldn't it read some arg and determine which emit to run?", "It seems it is only used for load generation, then can we move it into existing load generator folder? Or it is expected to be used by some other places?", "Jib pushes the test framework image for use in other repos without building it every time.\n\nhttps://www.github.com/aws-observability/aws-otel-test-framework/tree/terraform/.github%2Fworkflows%2Fmain-build.yml\n\nWe don't need to bring up any infrastructure for running tests for SDKs, just run on GitHub runner, so it's easy to run them with docker-compose", "It is also used by the `jaeger-zipkin-sample-app` for end 2 end testing, I refactor the code to generic emitter client", "it's for developer to do local testing/debugging. no-one else reference it. wanted to just keep it simple.", "> Can we split the PR (finally, it's my turn to say this) to merge the trace generator logic from https://github.com/Omnition/synthetic-load-generator first, I suppose most of the code are identical? ... I still prefer to move it into load generator folder\r\n\r\nThey're not identical. I extracted and refactored the core code to a generic data emitter client.", "> Just curious, where do we we define those port numbers and the are targeting to the receivers in otel col? I guess they were originally from existing stand alone daemon for ziplin and jaeger?\r\n\r\nyes. it is the default port introduced in Jaeger and Zipkin receiver from upstream. I think they're also from original jaeger/zipkin agents.", "It might be better to put it into the test package, or just add some comment to `Test` class.", "Can you mention packages that depends on trace-java-client in the README?", "ok, so you only need the validator and do not need the sample apps? https://github.com/aws-observability/aws-otel-test-framework/issues/228", "done"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/254", "comments": ["I think all AMI owned by amz has ssm by default? Though it won't hurt to reinstall ssm even if AMI has ssm agent already, as it simply update ssm agent. ", "terraform does not allow you to define string constant that can be used in variable defaults, and you can not use local or variable in variable defaults as well, so copy the userdata everywhere is the only way ... /w\r\n\r\nAnother way is we add userdata based on os family, but some os need extra init logic like install python (for patching #253 ). I prefer we just inline the userdata here as we don't need to update them most of the time."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/250", "comments": ["I think we can make the image and the common part of the command a var or local", "So one test run contains all workload and expect all the metrics (memcache, jmx, nginx etc.) to show up?", "Yes"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/248", "comments": ["I think we don't need `http://` for grpc right? Or something has changed in sdk and requires `http`?\r\n\r\nAnd will it cause problem for other language? Though I think we only have java sample app push to otlp receiver.", "Can we use same style for import? https://docs.gradle.org/current/dsl/org.gradle.api.artifacts.dsl.DependencyHandler.html#N17433\r\n\r\nI think we can use `implementation 'foo.bar'` for most packages that does not require extra notation (e.g. platform)", "Maybe we should make it an `ARG` in Dockerfile and give it a default value. In that case we can bump the version in tf files.\r\nDoes all otel sdk (for different languages) follows same version number? Or each language has its own?", "Actually we can bump gradle wrapper to a new major version (though I think this is modified by IDEA because it used to suggest me to download full gradle to get better competition etc. ", "yes, OTel SDK added this recently.\r\n\r\n```\r\n /**\r\n   * Sets the OTLP endpoint to connect to. If unset, defaults to {@value DEFAULT_ENDPOINT_URL}. The\r\n   * endpoint must start with either http:// or https://.\r\n   */\r\n  public OtlpGrpcMetricExporterBuilder setEndpoint(String endpoint) {\r\n```", "This is Java Auto Instrument Agent for Tracing. It is not OTel SDK so the version # is not in v1.0.x yet.\r\n\r\nThis sample app image doesn't change frequently yet. I like your `ARG` idea. I'll save it for later. :)", "yea. it is updated by IDE. "]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/247", "comments": ["why change this? If you clone the test in the gopath way, the relative path should work.", "Why not? `$GOPATH` is more accurate than relative path. ", "may i know the reason why we don't do the logic in `eks` folder? the folder name `eks-cloudwatch` seems not verbose enough? hard to guess its usage", "if we configure a different account_id, would it be a cross-account call?", "should we use underscore or hyphens?", "since the role name is fixed, when we run multiple tests in one aws account, any conflict would be expected?", "do we make an assumption that \"~/.kube/config\" is provided before we run the test? or i guess it's generated during the test? ", "why 1.3.0? ", "it's the only way to deploy it? any possibility to use terraform?", "better define vars in a separate file", "would that be possible we can somehow extract the existing `eks` module a bit so that we can reuse some of the common things?", "i might missed this part, who generates this config?", "would it be a common var in the common.tf?", "some people don't really have gopath there, the assumption we are making here is testing-framework code is at the same folder of collector code.  if we want to change it, please change the document also.", "since this validator aims to support multiple component, not just cloudwatch, maybe giving it a concrete name would be better?", "small nits, it would be better if we can define magic code `60`, `integrationTest` as vars.", "additonal spaces?", "i guess we forgot to put license header in validator sometimes :)", "what's the difference between appmesh validation and the normal cloudwatch metric validation? seems we just do a simple check on it? is it intended or we had a \"todo\" for it?", "* EKS seems to have its own testcases. The current folder `eks` is too general yet serves for a very specific testing purpose. For instance, it requests user to set up cortex in the account, which is of no interest when testing container insight features. Vice versa, the framework should not ask users to install AppMesh when testing EKS merely.\r\n* The new `eks-cloudwatch` uses a separate container insight configuration rather than the default one, which conflicts with the one that eks should use. Related PR: https://github.com/aws-observability/aws-otel-collector/blob/92414f1de2fba3a9c846922304b4bce81252a952/config/eks/prometheus/config-all.yaml\r\n\r\nSo I don't feel it's a good idea to couple eks and the test cases I'm adding. Perhaps `eks-containerinsight` is more self-explained? btw the name should be able to split `ecs` and `eks` cuz we would have container insight test cases on ECS soon as well.", "Removed it from the variables.", "Thanks for the explanation. Reverted.", "Changed the format to `AppMeshControllerRole-${var.testing_id}`", "https://github.com/aws-observability/aws-otel-test-framework/pull/247#discussion_r601029859", "To finalize the version of AppMesh to avoid version conflict", "The AppMesh controller is deployed through helm. `appmesh_readiness_check` waits the controller to be ready, otherwise the injection of envoy sidecar would fail for the following traffic application deployment.", "Removed.", "https://github.com/aws-observability/aws-otel-test-framework/pull/247#discussion_r600981387\r\n\r\nLet me know if you have other suggestions. ", "Sorry about the confusion. This integration test will be introduced in the PR: https://github.com/aws-observability/aws-otel-collector/pull/394", "Code cleansing done. Nice catch!", "Changed to `CloudWatchContext`", "Removed unrelated format.", "Thanks for the reminder!", "Yes, I guess we need a discussion on how to merge the two validators. There're some presumption that breaks container insight validations in the original `CWMetricValidator`.", "Thanks for pointing it out. Updated.", "should we use version constraint to get the latest version? eg `\"~> 3.0\"`", "Q: should we use `config-all.yaml`? Or make it as variable and each test case (eg, appmesh, nginx. etc) only apply their own configurations?", "nit: pls add `\" \"` to match code style", "we should avoid wildcard imports", "In the final PR of this integration test series, we test all the workload all at once. Metrics and logs are separated by namespaces, testing workload one by one makes no difference in validation with testing in a batch. However, testing separately surely will make integration test more expensive because of the extra effort on building and compiling and initiating new containers for testing. Also test order should be taken care of, which is what terraform is poor at. \r\n\r\nCloudWatch agent doesn't even provide separated config for each workload IIUC. I'm still questioning myself whether those separated configs are valuable.", "Done", "Done", "Done", "would this context include \"log\" and \"metric\"? or just metric?", "so, what's the path forward now? we're gonna use this simple validation instead of making the validator more generic? i'd prefer we do the latter, but if we have to do so, let's add a \"todo\" here", "better put variables in variables.tf", "i wonder do we need to specify type here as string is the default type?", "and i remember this is a var in common.tf, why's the reason to create one here?", "looks like many vars are duplicate with the ones in common.tf?", "we use it for debugging?", "Done", "I prefer we add todo and deal with it later, this PR is already pretty big and we are not enabling it until the related features merge into adot repo. We have plenty time to refactor those validators, both me and @pxaws will use cw metrics and log validators for other container insight related features and we can figure out the generic way along the way.", "I think `containerinsight-eks-prometheus` should be good and I can do `containerinsight-ecs-prometheus`, cause they are just setting up container insight auto dashboard specific workloads. btw: there is little to share between eks and ecs containersight when setting up environment so we don't need a common module for containerinsight.", "where's the source code of this sample app? i wonder if we could put it under the sample-apps folder so that we can manage it?", "are these dimension values from eks?", "i guess this folder is just for eks container insight but not for ecs?", "Good question. Prometheus metrics are the only one being tested. However these metrics are pushed to CloudWatch using structured log, which explains why we test metrics and logs both. ", "@wyTrivail Let me know if any of the proposed names sounds good to you.", "containerinsight-eks-prometheus sounds good", "btw, let's don't forget to change this script: https://github.com/aws-observability/aws-otel-collector/blob/main/e2etest/get-testcases.py", "To make sure we're on the same page, appmesh works as an independent stateless module, which only accepts input vars, and export variables that would be used by its caller. It self doesn't rely on any other module, that's why we don't put the variables in a common place. ", "https://github.com/aws-observability/aws-otel-test-framework/pull/247#discussion_r604486146", "https://github.com/aws-observability/aws-otel-test-framework/pull/247#discussion_r604486146", "https://github.com/aws-observability/aws-otel-test-framework/pull/247#discussion_r604486146", "It's referred in the main function: https://github.com/aws-observability/aws-otel-test-framework/pull/247/files#diff-2d154fdde544d49c61326e5b38c46e422cf1c06757fc916fe2edd5d33c7ed0f0R182", "Also the variables in `common.tf` is poorly documented. I'm not sure how it is used and how it should be used. As you may see appmesh requires multiple app image, and apparently a single variable naming `sample_app_image` can't fulfill my needs.", "i'm not sure if that's a good approach to bake all the testing configurations into image and release it to customer? for example, if we want to test with negative endpoint where we need to modify the endpoint value in config, how would we do that? \r\n\r\n", "my point is not about we should do it right away, but instead, we need to think about what's the overlapping parts we are making with the eks folder, how do we extract the common parts, if there's a contributor who wants to add a new testcase, how do we guide him to add.", "The source code can be found following our official setup guidance, it is maintained in another AWS repo: https://github.com/aws/aws-app-mesh-examples/tree/master/walkthroughs/howto-k8s-http-headers.\r\nRef:\r\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/ContainerInsights-Prometheus-Sample-Workloads-appmesh-EKS.html\r\n\r\nI didn't put it under the sample-apps folder because I personally think:\r\n1. It increases the effort to sync this copy with the original one.\r\n2. I can't see any potential user that is interested in running the integration tests locally. If this image would only be used by aoc integration test, I don't see a strong reason to maintain it. What's the benefit?\r\n3. We don't aim to test sample apps, they serve for testing aoc. A stable version of sample app is enough to meet the requirement.", "maybe you want to add a comment above `sample_app_image_repo` to explain it's for multiple app images, which i was not aware of when i saw this code.", "1. It increases the effort to sync this copy with the original one. make sense.\r\n2. I can't see any potential user that is interested in running the integration tests locally. If this image would only be used by aoc integration test, I don't see a strong reason to maintain it. What's the benefit? -> who is maintaining this sample app now? does it have workflow for auto-build? how do we track the version?\r\n3. We don't aim to test sample apps, they serve for testing aoc. A stable version of sample app is enough to meet the requirement. ->  would we need performance test?", "i wonder if this sample app is just for aoc integration-test, why don't we move it into this repo? i'm okay with that if this sample app has multiple usages than aoc inregration-test", "Not sure if I understand your concern correctly, but if `the testing configurations` refer to the [prometheus container insight configuration](https://github.com/aws-observability/aws-otel-collector/blob/main/config/eks/prometheus/config-all.yaml), it's not TESTing configurations, but official configurations that end users could use when they switch to aoc for container insight hands-on. Same as what [cloudwatch agent prometheus-eks.yaml](https://github.com/aws/amazon-cloudwatch-agent/blob/master/amazon-cloudwatch-container-insights/k8s-deployment-manifest-templates/deployment-mode/service/cwagent-prometheus/prometheus-eks.yaml) is doing.\r\n\r\nAnd I still remember the conversation we had on why not merge into eks foler: https://github.com/aws-observability/aws-otel-test-framework/pull/247#discussion_r600981387.\r\n\r\nI, as a contributor, am confused what eks folder is served for. Maybe a document to illustrate the existing eks module would be greatly helpful for developers to follow.", "> who is maintaining this sample app now? does it have workflow for auto-build? \r\n\r\nI believe it's EKS team, checking the contributors. \r\nPer [README](https://github.com/aws/aws-app-mesh-examples/blob/master/walkthroughs/howto-k8s-http-headers/README.md), they've provided a deploy script that will build the image, and deploy the relating resources to the cluster (cleansing should still be taken cared of by users).\r\n\r\n> how do we track the version?\r\n\r\nImages are for sample apps, we don't need version tracking, or so I thought.\r\n\r\n> would we need performance test?\r\n\r\nI'd like to see it happen. We don't have concrete plan. Yet that's unrelated to sample app images IIUC.\r\n\r\n> this sample app is just for aoc integration-test, why don't we move it into this repo? \r\n\r\nApparently it's not for aoc integration-test, but is recommended by CloudWatch for AppMesh quick start.", "pls help to leave source code link in the comment. ", "Renamed the folder", "I'm hoping containerinsight-ecs-prometheus would reuse this configuration too.", "Renamed the folder.", "Added def and source code links to the variable."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/238", "comments": ["Q: why do we only need to apply `product_code` filter for this AMI? How about the others?", "For AMI owned by amazon, there is no product code, and if you apply the filter with `*`, the API returns nothing. I didn't check other marketplace AMI, based on subscription in the test account we only have subscription for Debian 10 and CentOS.\r\n\r\nThe reason we need product code for debian 10 is the filter pattern alone will return two products, one from Debian, one from dshop. Those two types of AMIs can only be distinguished using product code."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/217", "comments": ["could you remove logging because this config will also be used in performance test and logging would impact the result.", "Sure, will remove. Sure, I can include the changes for performance test later. ", "you might want to add soaking_data_mode and soaking_data_type for performance test on mock test case as well", "please follow naming convention, sendStatsd ", "this variable name has no meaning, you might want to change it to \"payload\"?", "did you check on cloudwatch console to ensure there're a mount of metrics appearing?", "normally statsd use 8125 port, can we change it to 8125 in readme?", "Sure, thanks\r\n", "Yes, checked.", "Make sense. "]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/216", "comments": ["can we get the name more specific?", "like `enable_patch`?"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/215", "comments": ["I thought only v0.13.0 doesn't work. Does v0.12.1 also has issue for emitting the compatible metrics?", "why we don't use auto-instr-agent to send metrics anymore?", "I added this when I tested it locally without java-agent and docker. Will remove this part.", "Same reason as in the other comment. I was testing it locally without java-agent and docker and `v0.12.1` is not compatible with the `IntervalMetricReader` builder. Will change this back.", "i'm afraid changing this template would break the test in SDK repo which would probably be using this template as well with another sample app, we might either use another template or let them to use our latest sample app image.", "looped through the sdk repos, where the default template is not used, so it's not a concern."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/210", "comments": ["just curious. why CentOS need update iptables but other OSs do not need?", "Yeah, centos6 blocks almost all the ports by default"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/208", "comments": ["can this namespace be sent from terraform to validator instead of define a constant here?", "i think we just emit one metric after all the retries, but looks like we are going to emit metrics for every retry?", "yes, it will emit metrics for every pulling alarm check. I feel not too much difference on emitting the metrics for each retry and all retries. For every retry gets better granularity on the metrics. "]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/205", "comments": ["I updated this to the public ecr image, let me know if this is not desired", "same here but I think this gets overwritten by the other one anyways", "Wondering, why can't we make it `latest`?", "We probably can, I just did a specific version because previously a specific version was also used", "nit: Can we rather increase the sleep time than mex_retries? Then we will see less logs in the terminal which is good in my opinion. ", "good point, will change", "Can we move all the template files in `templates` folder under `terraform` folder? in this case, we can create `prometheus` folder under `templates` folder for this template. The test case folder only leave `.var` and `otconfig.tpl` for all the testcases", "can you pls help rename this file to `ecs_taskdef_sidecar.tpl` so we can differentiate it with other deployment mode?", "ditto", "The integration should always test against on the newly built images that's why you see \"v0.4.0-38xxxx\". We always take it from terraform input in the workflow. So a fixed version number or `latest` doesnt' matter too much here.", "\ud83d\udc4d  will do", "hmm both are still sidecar deployments though right?", "the only difference here is that I changed the sample app, as prometheus sample app takes different environment variable inputs than spark sample app", "> hmm both are still sidecar deployments though right?\r\n\r\nYea, you sent two examples - deploy collector as sidecar with sample app, with file name `ecs_taskdef.tpl `. I mean what if in the future we want to deploy the collector as DaemonSet or a Pure service, what would be the example file name?\r\n\r\n", "I've done some example configs to deploy the collector as  service, daemonset and sidecar before. I gave each example config a different name. \r\nhttps://github.com/aws-observability/aws-otel-collector/tree/eks_daemonset/examples/eks"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/195", "comments": ["you might need to change all the trace templates?", "Ah I missed all the ones nested in packages. Good catch!", "Also FWIW, even if a period wasn't escaped like this (for example in the interpolated `endpoint` variable), it wouldn't break validation. Because the unescaped period matches any character, including a literal period, so the correct endpoint would still be considered a match. But of course it's still better to escape them and match it exactly where we can.", "gotcha!"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/176", "comments": ["can this server also expose a http port 8080 as well so that we don't need to write code in validator to call grpc?", "for now, we have three mocked_server,\r\n1. https mocked server\r\n2. grpc metric mocked server\r\n3. grpc trace mocked server.\r\n\r\ncan we create a folder named `mocked_servers` and subfolders for each mocked server. \r\n\r\nthen, in the imagebuild folder, we make some modification to loop through all the subfolder under `mocked_servers`, build them and push them to ecr with its name as the image tag.  just like how we do for sample_apps: https://github.com/aws-observability/aws-otel-test-framework/blob/terraform/terraform/imagebuild/main.tf#L38\r\n\r\nafter that, we can define a var `mocked_server` in common.tf just like `sample_app` https://github.com/aws-observability/aws-otel-test-framework/blob/terraform/terraform/imagebuild/main.tf#L38,  use `mocked_server` if `mocked_server_image` is not provided. and get the actual mocked_server image link base on the `mocked_server` value just like how we do for sample apps here: https://github.com/aws-observability/aws-otel-test-framework/blob/terraform/terraform/basic_components/outputs.tf#L45\r\n\r\n", "we might also define a var for mocked_server_port since different mocked_server would use different port.", "will that be possible we can all use 443 for the grpc port, so that we don't need to specify the port?", "to get validator to access the grpc from public internet, we will need to create a lb in front of it. if we can have the 8080 http port, then we don't need to change the code in ecs and eks", "it should be `../../mocked_servers/${mocked_server}`?", "it should be ../../mocked_servers/${mocked_server}?", "can you add a batch here?", "can we remove the timeout so that all the testcases will use the default batch config"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/174", "comments": ["there's a concurrent issue since ++ is not atomic", "Since Node.js is single-threaded, all operations on global vars are atomic by default.", "oh yeah, make sense, it will only return once i/o happens"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/169", "comments": ["Can we support regex here? If not, we can remove `name` from template like serverlessrepo-aot-py38-sar/api, serverlessrepo-aot-py38-sar-function-XMKMYMQM3776", "Yeah I'm going to add regex support in a separate PR, didn't want to clutter this one too much. Will remove the `name` in the meantime.", "I think it's a good idea if we keep recursion depth limit. Major reason being since this is validation tests we can absolutely control the trace data. Also, we wouldn't expect data more than certain depth and if we do program should not go in the loop. I don't see any point of doing recursion after some depth especially in testing scenario. breaking condition looks fine but i strongly suggest we should also break the recursion by some level of depth (maybe 6?).", "That's a good callout, I can add a limit to prevent infinite looping if, say, a subsegment had itself as a child (which wouldn't be possible in practice but still good to check for). This also made me realize another bug with the stop condition that it shouldn't just ignore if an entity only has a single child, because that single child could itself have many children that need sorting. So I'll address that too.", "Also, not sure how often this scenario would occur but do you think mapper should not be able to map some values from document to the class you have created? If this is the case then we will also have to do some handling on fields because for example let's say if mapper didn't translate `name` then validation would fail if we are checking `name` value in stored validation template.", "Hmm well `Entity` has all the fields that we support in the (sub)segment model, in addition to `inferred` which is added by the backend service. If we want to validate against any field that isn't yet a part of the Entity class, we can just add it to the Entity class so it's read properly then validate it normally. Like I mentioned new fields for entities are allow-listed pretty rarely, so I think it's acceptable to have to update that class when they do come in.", "sounds fair."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/166", "comments": ["should terraform send datamode to validator?", "It's already being sent via config.", "https://github.com/aws-observability/aws-otel-test-framework/blob/e550c5d523133f5df82dff802cd93e51606f992e/validator/src/main/java/com/amazon/aoc/models/ValidationConfig.java#L50"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/154", "comments": ["can we remove the throttle from here?", "from  here too", "from here too", "here as well", "Do you think all SDKs will generate this name? We should just use the env variable to set the service name so that top level segment name can be similar within all SDKs", "Should've removed them from the start, they've been removed!", "I'm actually not sure, I think this service name makes sense _if_ the sample app has a backend service that is instrumented to create a span with a `http.host` attribute, but if it doesn't, this will break.\r\n\r\nIn this specific case, the `{{environment}}` variable has `http://127.0.0.1:8080` so it will fail to match `127.0.0.1:8080` \ud83d\ude15 \r\n\r\nI think if we count on there being `http.request.url == {{endpoint}}/aws-sdk-call` then we can count on there being a service name of `127.0.0.1:8080` because that _is_ the service. So in that case, it would be _ok_ to leave this.\r\n\r\nOtherwise we might consider removing the `\"name\"` check if the SDK _does not_ add `http.host` or even if it adds `service.name` instead. What do you think?", "what's the difference between the spark template and the springboot template?", "the segment hierarchy diff", "We spoke about it and decided that for now, we should remove the `\"name\"` property until we establish something consistent across the SDKs.", "I don't think we would need this config we can just use the default one we have. let's try to reduce the possible templates.", "sometimes \"https://aws.amazon.com/\" return 500/504 so that error/fault equal to true, how do we deal with it?", "if we just want to test the outgoing-http-call, maybe just calling the sample app itself will make the test more stable", "just got 500 in our canary test. here is the json body we got from xray, you can see status is 500 and error is true\r\n\r\n                \"subsegments\": [\r\n                    {\r\n                        \"id\": \"9d629cbd0d36a450\",\r\n                        \"name\": \"aws.amazon.com\",\r\n                        \"start_time\": 1606969615.2203882,\r\n                        \"end_time\": 1606969615.2429497,\r\n                        \"fault\": false,\r\n                        \"error\": true,\r\n                        \"http\": {\r\n                            \"request\": {\r\n                                \"url\": \"https://aws.amazon.com\",\r\n                                \"method\": \"GET\"\r\n                            },\r\n                            \"response\": {\r\n                                \"status\": 500,\r\n                                \"content_length\": 0\r\n                            }\r\n                        },\r\n                        \"aws\": {\r\n                            \"xray\": {\r\n                                \"auto_instrumentation\": false,\r\n                                \"sdk_version\": \"1.1.0\",\r\n                                \"sdk\": \"X-Ray for Go for Go\"\r\n                            }\r\n                        },\r\n                        \"metadata\": {\r\n                            \"default\": {\r\n                                \"http.response_content_length\": \"\"\r\n                            }\r\n                        },\r\n                        \"namespace\": \"remote\",\r\n                        \"subsegments\": [\r\n                            {\r\n                                \"id\": \"a35b9f0af395066e\",\r\n                                \"name\": \"request\",\r\n                                \"start_time\": 1606969615.2204092,\r\n                                \"end_time\": 1606969615.2205038,\r\n                                \"fault\": false,\r\n                                \"error\": false,\r\n                                \"aws\": {\r\n                                    \"xray\": {\r\n                                        \"auto_instrumentation\": false,\r\n                                        \"sdk_version\": \"1.1.0\",\r\n                                        \"sdk\": \"X-Ray for Go for Go\"\r\n                                    }\r\n                                }\r\n                            },\r\n                            {\r\n                                \"id\": \"4e70f38632f72310\",\r\n                                \"name\": \"response\",\r\n                                \"start_time\": 1606969615.2205071,\r\n                                \"end_time\": 1606969615.2429152,\r\n                                \"fault\": false,\r\n                                \"error\": false,\r\n                                \"aws\": {\r\n                                    \"xray\": {\r\n                                        \"auto_instrumentation\": false,\r\n                                        \"sdk_version\": \"1.1.0\",\r\n                                        \"sdk\": \"X-Ray for Go for Go\"\r\n                                    }\r\n                                }\r\n                            }\r\n                        ]\r\n                    }\r\n                ]\r\n            },\r\n            \"Id\": \"db8287ae0cb92c4d\"\r\n        },\r\n", "That's really interesting that it returns 500, I would expect it to never return 500... Is this avoided if we pick a different endpoint?", "> if we just want to test the outgoing-http-call, maybe just calling the sample app itself will make the test more stable\r\n\r\nDo you mean not including the HTTP call in the App route method? I think that's reasonable for a different route, like even the `/` route, but I think the point of the `/outgoing-http-call` is to make a request to an external service so we should probably keep that validation... although we should resolve this 500 response code issue \ud83d\ude15 ", "I don't think `https://aws.amazon.com` should return 500/504 unless it's down right?", "Can we remove this? The name differs between the SDKS for example the segment mapped by JS is the name of the query \"aws.amazon.com\".", "The [OpenTelemetry Specifications on HTTP](https://github.com/open-telemetry/opentelemetry-specification/blob/master/specification/trace/semantic_conventions/http.md) say that HTTP client spans SHOULD follow this conventation:\r\n\r\n> Therefore, HTTP client spans SHOULD be using conservative, low cardinality names formed from the available parameters of an HTTP request, such as \"HTTP {METHOD_NAME}\"\r\n\r\nOnly if it is a HTTP server span should it look like the route `/outgoing-http-call`\r\n\r\n> In case of HTTP servers, these endpoints are often mapped by the server frameworks to more concise HTTP routes, e.g. /api/users/{user_id}, which are recommended as the low cardinality span names.\r\n\r\n`aws.amazon.com` doesn't fit into either of those situations, do you think an issue in the JS SDK would be a better solution?", "make sense, then maybe don't validate the error, fault and statuscode key?", "Do you know why it returns a 500 status code? I don't expect endpoints to ever return 500+ status codes, maybe we should pick a different endpoint?", "I think we should because that is very essential to test. That will tell us about any kind of throttle or fault  span issues. We must keep those in validation.", "Sounds good, I will remove the Springboot templates", "Then we need to figure out a way, we saw 500 from time to time", "@wyTrivail The test framework was already validating status code 200 before, this PR does not change that, so I think it's out of scope for the changes here.", "i suspect this template would make the test unstable even though it's already there. in collector test, we use the spark one, as you can see there we removed lots of items...", "For JS one the current expected template will not work due to some minor issues such as status code/names. I think the question is should we simplify it like the Spark one so that it can work for JS as well and be more stable?", "I think we can remove all the names for now but I believe status code should be `200`", "i think it might take some time for us to find the balance between complexity and stability.  i'm okay with the current the template since we can improve it later. we don't need make it perfect at the beginning. \r\n\r\nin additional, we should always try our best to add unit tests to validate the data structure instead of relying on end to end test, which is consuming multi resources and hard to debug. \r\n\r\nfor the js sdk one, maybe you can try to use the spark template, let me know if there's any field js sdk can't support. ", "To keep the validation on `HTTP GET` for the span name (which I think is useful), we could merge this PR for now and then create a new one for JavaScript later. We should create an issue in the JavaScript repo that includes @KKelvinLo 's concerns and link it to that PR to remove the custom JavaScript template when the fixes are included.", "@wyTrivail I think that's good justification, we can always improve it later and this does look good for now."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/150", "comments": ["the same comment, could you move it into the ami family def"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/146", "comments": ["same as the comment in the other pr :)", "can you help to change the name of \"data_emitter\" to \"sample_app_image\"? in case any confusion.", "cool", "can you help to change the soaking_data_emitter_image to soaking_sample_app_image?", "this was a variable I added that was meant to be what \"sample_app\" is to \"sample_app_image\" for data emitter images. The idea was for data_emitter to be from the imagebuild sample apps. Setting this to \"sample_app_image\" will overlap with a variable with a different meaning so I don't think that is the right thing to do. I think I can remove this variable and just use the variable \"sample_app\" because it has no other uses in ec2_setup, soaking, and performance", "On second thought I realised sample_app is in the common.tf and has a default of \"spark\", so it cannot be reused here, I will instead name it \"soaking_sample_app\"", "will do \ud83d\udc4d ", "maybe we can use sample_app instead of data_emitter? check if sample_app is set first and then use soaking_data_emitter_image if not?"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/145", "comments": ["i guess this comment should be \"no call to prometheus sample app needed to get expected metrics\" ?", "my understanding was that the caller is used to tell the sample app to produce metrics to send to AOC, rather than get expected metrics"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/144", "comments": ["you can remove this line now, we don't need it anymore", "can you configure it as a parameters in the ami family somewhere? like [here](https://github.com/aws-observability/aws-otel-test-framework/blob/terraform/terraform/ec2_setup/amis.tf#L3), i'm not sure if you want to support windows because the soaking test will also cover windows", "I tried that before, but it does not allow the use of the variable that I require (aws_instance.sidecar.public_ip)", "As for windows support I can add that in, I was under the assumption that only amazon linux is used for perf/soaking tests", "did you test soaking with windows?", "Will do so first thing tomorrow morning ", "would this parameter to be in common.tf?"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/130", "comments": ["it will be a fixed value? if we put it in the output of common module, we can't use var to change its value while we use var to change the value in github workflow. can we configure it in variables?", "i think we can define this var in the common.tf so that all the platforms can leverage this flag even though they don't have the logic yet.", "will we be able to use this config in ec2?", "will we be able to use it in ec2?", "can we try to run one testcase which is using push mode in case this change break it?", "use == \"push\" would be more straightforward", "do we need it in push mode?", "i would suggest we keep mock server no matter if it's a pull mode, so that we can also switch to use mock server to validate in the future.", "since this file is going to be too long, can we put all the things about pull mode into a separate file named pull_mode_deployment.tf something?", "No, this config is specific to kubernetes (as its doing service discovery on the Kubernetes objects). ", "It should be able to without many changes. Right now it isn't, it only works for EKS, as we need to add some environment variables (`SAMPLE_APP_HOST` and `SAMPLE_APP_PORT`) to the EC2 instance so the Collector can point to the right host.", "Nope, we can take it out.", "I tried running the otlp_mock test case, and it looks like it's passing: \r\n\r\n```\r\nmodule.validator.null_resource.validator (local-exec): validator_1  | 20:29:56.842 [main] INFO  com.amazon.aoc.validators.MockedServerValidator - mocked server validation passed\r\nmodule.validator.null_resource.validator (local-exec): eks_validator_1 exited with code 0\r\nmodule.validator.null_resource.validator (local-exec): Aborting on container exit...\r\nmodule.validator.null_resource.validator: Creation complete after 1m37s [id=7503739792628168714]\r\n```", "Do we need to get it working on EC2 in order to merge this PR? I have made the changes to get it working with EC2 and was going to submit the change in a PR for soaking/performance tests. I can move those changes to this PR if preffered", "no, we can tackle that in the next pr"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/129", "comments": ["when will this lib to be available on maven?", "what's \"b3772780da\"?", "the name of \"ExpectedResultClient\" made me think it's a generic client for all the types of metrics including cw and prometheus but looks like it's just for prometheus?", "do you wanna retry on it in case any network issue would make the endpoint unstable?", "instead of defining a new exception from runtimeexception, do you want to define a new exception code in the baseexception?", "i'm assuming this is to call the sample app? any possibility we can make it generic? name it as \"PullModeSampleAppClient\"?", "same as above, try baseexception?", "it will be great if we could do it in a helper class, so that other metric validator could use it?", "just retry once?", "using retry would be better than purely waiting.", "what's the difference between \"prom-metric-scraping\" and \"prom-metric-sd\" from validator perspective?", "I forgot to remove this jar (we don't actually use it in the code and it's not actually in this PR).", "Oh, this one is to call our Cortex Instance. The ExpectedResultClient is actually the one that calls the sample app. I'll rename both clients to make it more clear.", "It's the version of the library in maven: https://mvnrepository.com/artifact/com.github.awslabs/aws-request-signing-apache-interceptor?repo=mulesoft-public.", "There is no difference between the `prom-metric-scraping` and `prom-metric-sd` testcases when instantiating the validators. It only instantiates different comparators later on in the actual validation. \r\n\r\nI'll add a field `shouldValidateMetricValue` that can be configured in the Validator Config instead."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/128", "comments": ["this file is a symlink to the common.tf, you don't need to really add content for it. just create a symlink instead", "i guess canary will always equal to true here?", "maybe give a comment here to explain the meaning of the \"canary\" var?", "any possibility we can write this part of logic in a separate method? ", "any dimension?", "how long does it take to run a round of canary, there's a limit on github that a job can only be running for no more than 6 hours.", "i guess you don't need to skip this check now, we changed the metric template.", "Previously, I included `testingId` as one dimension, but then I found we cannot set alarm if the each run generates a different metric. I think canary tag is included in the namespace. What other information do we need for dimension?", "30, 31 minutes"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/96", "comments": ["could you remove the metric block here since the test case is for trace?", "I should have made a comment about this, my bad: this is necessary because we actually send some stats about traces to that endpoint when running the trace exporter; if we leave it unset we would be hitting Datadog's backend on each test", "Make sense then, thx for explaining."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/75", "comments": ["Why are we removing all of it?", "What do you mean by json format is wrong?", "check this: https://github.com/aws-observability/aws-otel-collector/runs/1397013128?check_suite_focus=true, the \"e2etest-ecs (otlp_trace, EC2)\" one, looks like xray returned a empty/invalid json of segment. but i can't reproduce it on my local even with the same trace id, so i suspect xray backend somehow returned a invalid json", "the final one is \r\n\r\n```\r\n[{\r\n  \"name\": \"aws-otel-integ-test\",\r\n  \"fault\": false,\r\n  \"error\": false,\r\n  \"throttle\": false,\r\n  \"http\": {\r\n    \"request\": {\r\n      \"url\": \"{{endpoint}}/aws-sdk-call\",\r\n      \"method\": \"GET\"\r\n    },\r\n    \"response\": {\r\n      \"status\": 200\r\n    }\r\n  },\r\n  \"subsegments\": [\r\n    {\r\n      \"fault\": false,\r\n      \"error\": false,\r\n      \"throttle\": false\r\n    }\r\n  ]\r\n}]\r\n```\r\n\r\nthe http block under subsegments are unpredictable, some times a put request is appeared "]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/56", "comments": ["I think we should make `parameters.tfvars` file as optional. Should we require each testcase need to be able to run locally as mandatory requirement?\r\n", "a little confusing phrase. can we say \"we require the new components to be tested on all platforms for all the test cases.\"", "can we move this test emitter code into this repo?", "can we use the same metric pipeline config from our default collector configuration files? ", "the same here, copy the same trace pipeline config from the default config.", "just to make sure we maintain all the sample app in one repo?", "maybe change \"true\" to \"success\" :)\r\n", "-var=\"aoc_version={{ the docker image tag name}} -var\r\n\r\nmissing `\"` after `}}`", "the sample app code is in the sdk repo.", "yes we can", "okay", "yes we will, this is a temp one", "okay", "thx"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/54", "comments": ["remove the commented code?"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/49", "comments": ["you can remove this.", "you can remove this", "you can remove this", "you can remove this", "OK, will delete it", "Removed"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/44", "comments": ["this won't work for other tests, i think we still need to use 8080", "no need to add this i reckon, depends on how you init your aws sdk in your sample app", "same as above", "why not use the existing one?", "region isn't needed.", "same as above", "Sure"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/42", "comments": ["is \"OTelLib\" there? looks like you removed it?"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/40", "comments": ["let's wait until you have the real dimensions, then we can merge", "We are planning release with empty dimensions. Will create a new PR once the label/dimensions settings feature is available.  "]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/37", "comments": ["Can we add a line here saying validator for this path is done successfully? Currently we don't see any kind of success log it would be good for debugging on Github actions.", "good catch!! let me add it"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/32", "comments": ["we will still need a bigger retry count, service launching time in different platform varies. 3 times might not be enough in some cases. ", "sleeping 15 seconds might not be enough in some case, instead, retry it until success could make this validation more stable.", "log?", "it will be better if we can do null point check here", "if we want to test in other region?", "why the ip is 127.0.0.1? i imagine the ip should be the ip of the service? ", "same ask on ip :)", "what's the reason to use json-simple instead of jackson? \r\njackson is also easy to create map from json. https://mkyong.com/java/how-to-convert-java-map-to-from-json-jackson/ :)\r\n\r\nand it's built-in in java, no need to add a dependency.\r\n\r\n", "Basically challenge was to convert nested structure like segment documents to a flattened map (since for validation we want to access each field) but not sure we can do that using Jackson. I have tried couple of examples but unfortunately no luck.", "Yes. I agree. Maybe we can probably keep this to 10? I feel 60 times retry is too much especially we will be using this module on Github actions where we don't have any control to terminate it we just have to wait for 60 retries to complete.", "Yes initially I was trying retry only but with retry it doesn't block consecutive operation for example, it tried for the first time and `retrieveTraceList` is empty so it tries again but when it retries second time it actually executes program with whatever it got on first retry so I want something blocking in order to use retries. Basically, can we block retry handler until `retrieveTraceList` is populated and once we have the list then only it performs further execution.", "good suggestion!", "sure.", "good point. maybe we can provide env variable to set this value? because url will be depending on which platform we deploy application right? so we won't be having url value on hand.", "maybe this also we can set using env variable?", "env var will work, like https://github.com/aws-observability/aws-otel-test-framework/blob/terraform/validator/src/main/java/com/amazon/aoc/validators/MetricValidator.java#L146, we can use mustachehelper to render the context object into it. ", "you add some parameter into the context object", "i'm not sure if 10 would work, because it normally takes 10+ times to get it work for ecs test. probably 30?", "sorry i don't quite follow, can you retry on \"listTraceByIds\" until its size becomes none-zero?", "Okay we can do 30 then.", "yes so the issue is retry helper retries when there is an exception but in the case of `listTraceByIds` we want to keep retrying until list becomes non empty. Here we have to wait for couple seconds because sample app sends trace to x-ray service and then we can retrieve it. ", "okay will give it a shot.", "i see, can you throw a baseexception when the list is empty so that it will retry", "you can throw a new baseexception(\"the trace id list is empty\") then retry handler can capture it", "cool", "i remember the interval is a parameter, not a fixed 10 seconds", "can we move this out of the loop? since when the retries exhausted, it exit the loop", "can we use \"{{httpPath}}\" here?", "can we use {{httpPath}} here?", "the reason I kept that inside is because we can print the actual exception after retry is exhausted (why retry failed?). ", "sure will add param here."]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/27", "comments": ["you can remove this line", "you can remove this line also"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/26", "comments": ["please follow the guide, to use LISTEN_ADDRESS env var first.  you can have 8080 as the default port", "please follow the guide, to return \"traceId\"", "you might not need this, since you will need to read the env var LISTEN_ADDRESS", " you will need to build this image with the repo: https://github.com/aws-observability/aws-otel-js whenever there's code commit, so i'm thinking how do we put the dependencies here, looks like it's using the official repo instead? \r\n\r\nmaybe try to add aws-itel-js as a local lib? https://stackoverflow.com/questions/48944051/package-json-add-local-directory-to-node-modules/48944131", "done", "done", "removed", "Will be moving to aws-otel-js repository to resolve dependencies issues", "nitpick: add a line here", "here too!"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/12", "comments": ["please follow the requirement of building the sample app.  \r\n\r\n1. *Web application/Docker image:  *The data emitter needs to be a web application serving a http endpoint, and needs to be able to built as a Docker image and run for testing as a Docker app. A Dockerfile needs to be provided.\r\n2. *Integrate with SDK Repo workflow: *For each new code commit you make in the SDK, you will need to build a new Docker image. Every new Docker image should have a unique tag (you can use the code commit as the tag). Also maintain a \u201clatest\u201d tag for this image which builds with the released SDK. This will help theAOC (https://github.com/aws-observability/aws-otel-collector) repo to use the latest tag image to test with the latest version of the SDK. The SDK workflow sends a dispatch event with the built image link.\r\n3. *Response pattern:* The response of each URL path need to be followed using the data structure listed below i.e. you just need to return the traceid. [json/application]\r\n\r\n{\r\n    \"traceId\": \"xxxx\"\r\n}\r\n\r\n4. *Unique ID*. [skip it if you just do trace not metric]Every time the validator, which is a component in the testing framework, calls the URL, the validator will generate a test-suite-id, which is unique for each run. The URL parameter, for example: http://x.x.x.x:8080/get-trace?testing-id=12313123241, can be used as an unique identifier for the metric e.g. adding this id as part of the metric name so that the metric could be different for each testing run. Note that no matter which http method you use, it will not be in the body, but just in the url parameter.\r\n5. *Environment Variable: There will be some env vars which will be set while running this web application. The env vars will be but not limited to:*\r\n    1. OTEL_EXPORTER_OTLP_ENDPOINT\r\n    2. OTEL_RESOURCE_ATTRIBUTES\r\n    3. *LISTEN_ADDRESS : *This is a mandatory environment variable. This web application address, for example (0.0.0.0:8080), makes the address controllable by the upper level; prevents port conflict with any other software on the testbed and also helps us limit the web application access within a private subnet.\r\n6. *Support multiple URL path: *There\u2019s no limitation on the URL path. There could be multiple URLs in this web application depending on the number of test cases you want.\r\n7. *Keep \u201c/\u201d accessible with response code 200.:* This \u201c/\u201d will be used for the load balancer health check.\r\n\r\n\r\nthis code doesn't meet 1, 2, 3, 5\r\n", "1.  you need to add a Dockerfile\r\n2. reach out xray go sdk to add image building in sdk.  bhautip@\r\n3. return the trace id in the response.\r\n4. leverage OTEL_EXPORTER_OTLP_ENDPOINT as the aoc endpoint\r\n5. leverage LISTEN_ADDRESS as the listen address of your endpoint. \r\n\r\n\r\n6. create pr with xrayreceiver.  check the workflow\r\n7.  adding testing suite, follow https://github.com/aws-observability/aws-otel-collector-test-framework/tree/terraform/terraform\r\n"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/2", "comments": ["```suggestion\r\n  owners = [\"amazon\"]\r\n```", "```suggestion\r\n  owners = [\"amazon\"]\r\n```", "Is it possible to generate private key with terraform instead of maintaining a bucket?\r\n\r\nhttps://registry.terraform.io/providers/hashicorp/tls/latest/docs/resources/private_key\r\n\r\nIt would be ephemereal and deleted when terraform destroy happens automatically", "+1", "Ah I see you generate key here - do you need to store it in a bucket? I think it's ok to generate key ever PR run, unless you know of a throttling limitation of `aws_key_pair`. Less permanent keys is safer :)", "Since you use default VPC you can clarify that here, I assumed from this comment you were creating a VPC here", "Looks like we'll save a lot by deleting this folder! https://github.com/aws-observability/aws-otel-collector-test-framework/tree/master/integ-test/src/main/java/com/amazon/aocagent/services", "Though maybe you want to consider just creating a VPC here, so it's easier to manage e.g., private subnets\r\n\r\nhttps://github.com/aws-samples/aws-xray-sdk-with-opentelemetry-sample/blob/both-otel-and-xray/scripts/terraform/network.tf#L75", "thx, will do", "i'm trying to keep the private key in case we need to log into the ec2 instance for debugging. we usually need to log into the instance to debug the collector and the image as the log of integ-test can't tell too much info to us. ", "yeah, just keep the key in s3 for debug purpose. And there might be a limit on it, but not like vpc (5 vpcs in one account), it could be hard to reach. ", "yes, i will probably create a vpc for integ-test when i do ecs and fargate if the default one is not easy to use.", "yeah, it does!! i will provide ecs and eks soon"]}, {"url": "https://github.com/aws-observability/aws-otel-test-framework/pull/1", "comments": ["can you pls help add \"-e ecsTaskDef=ECS_EC2_TEMPLATE\" at the end?", "can you pls help add \"-e ecsTaskDef=ECS_FARGATE_TEMPLATE\" at the end?", "added"]}]}, {"url": "https://github.com/DoctDocs/doctdocs-infra.git", "pull_requests": []}, {"url": "https://github.com/ministryofjustice/opg-metrics.git", "pull_requests": [{"url": "https://github.com/ministryofjustice/opg-metrics/pull/76", "comments": ["these keys should be per service. What service is shared is going to use opg-metrics?", "Intention is to set up the infrastructure in opg-jenkins which lives on those accounts", "the keys should be for jenkins rather than for the account then", "Okay I see what you mean now - updated", "Is jenkins using a specific role? we should use that where possible."]}, {"url": "https://github.com/ministryofjustice/opg-metrics/pull/73", "comments": ["Can we specify roles that can push to metrics. Corrent setup will allow anything in the account to push to metrics\r\n"]}, {"url": "https://github.com/ministryofjustice/opg-metrics/pull/56", "comments": ["tfsec check aws-api-gateway-enable-access-logging failed. \n\nDescription: Access logging is not configured.\n\nSeverity: MEDIUM\n\nFor more information, see:\n\n- https://aquasecurity.github.io/tfsec/v1.26.0/checks/aws/api-gateway/enable-access-logging/\n- https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/apigatewayv2_stage#access_log_settings\n", "tfsec check aws-s3-enable-bucket-encryption failed. \n\nDescription: Bucket does not have encryption enabled\n\nSeverity: HIGH\n\nFor more information, see:\n\n- https://aquasecurity.github.io/tfsec/v1.26.0/checks/aws/s3/enable-bucket-encryption/\n- https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket#enable-default-server-side-encryption\n", "tfsec check aws-s3-enable-bucket-encryption failed. \n\nDescription: Bucket does not have encryption enabled\n\nSeverity: HIGH\n\nFor more information, see:\n\n- https://aquasecurity.github.io/tfsec/v1.26.0/checks/aws/s3/enable-bucket-encryption/\n- https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket#enable-default-server-side-encryption\n", "tfsec check aws-s3-enable-bucket-logging failed. \n\nDescription: Bucket does not have logging enabled\n\nSeverity: MEDIUM\n\nFor more information, see:\n\n- https://aquasecurity.github.io/tfsec/v1.26.0/checks/aws/s3/enable-bucket-logging/\n- https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket\n", "tfsec check aws-s3-enable-bucket-logging failed. \n\nDescription: Bucket does not have logging enabled\n\nSeverity: MEDIUM\n\nFor more information, see:\n\n- https://aquasecurity.github.io/tfsec/v1.26.0/checks/aws/s3/enable-bucket-logging/\n- https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket\n", "tfsec check aws-s3-encryption-customer-key failed. \n\nDescription: Bucket does not encrypt data with a customer managed key.\n\nSeverity: HIGH\n\nFor more information, see:\n\n- https://aquasecurity.github.io/tfsec/v1.26.0/checks/aws/s3/encryption-customer-key/\n- https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket#enable-default-server-side-encryption\n", "tfsec check aws-s3-encryption-customer-key failed. \n\nDescription: Bucket does not encrypt data with a customer managed key.\n\nSeverity: HIGH\n\nFor more information, see:\n\n- https://aquasecurity.github.io/tfsec/v1.26.0/checks/aws/s3/encryption-customer-key/\n- https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket#enable-default-server-side-encryption\n", "tfsec check aws-kms-auto-rotate-keys failed. \n\nDescription: Key does not have rotation enabled.\n\nSeverity: MEDIUM\n\nFor more information, see:\n\n- https://aquasecurity.github.io/tfsec/v1.26.0/checks/aws/kms/auto-rotate-keys/\n- https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/kms_key#enable_key_rotation\n", "tfsec check aws-kms-auto-rotate-keys failed. \n\nDescription: Key does not have rotation enabled.\n\nSeverity: MEDIUM\n\nFor more information, see:\n\n- https://aquasecurity.github.io/tfsec/v1.26.0/checks/aws/kms/auto-rotate-keys/\n- https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/kms_key#enable_key_rotation\n", "tfsec check aws-api-gateway-enable-access-logging failed. \n\nDescription: Access logging is not configured.\n\nSeverity: MEDIUM\n\nFor more information, see:\n\n- https://aquasecurity.github.io/tfsec/v1.26.3/checks/aws/api-gateway/enable-access-logging/\n- https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/apigatewayv2_stage#access_log_settings\n", "tfsec check aws-s3-enable-bucket-logging failed. \n\nDescription: Bucket does not have logging enabled\n\nSeverity: MEDIUM\n\nFor more information, see:\n\n- https://aquasecurity.github.io/tfsec/v1.26.3/checks/aws/s3/enable-bucket-logging/\n- https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket\n", "tfsec check aws-s3-enable-bucket-logging failed. \n\nDescription: Bucket does not have logging enabled\n\nSeverity: MEDIUM\n\nFor more information, see:\n\n- https://aquasecurity.github.io/tfsec/v1.26.3/checks/aws/s3/enable-bucket-logging/\n- https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket\n"]}, {"url": "https://github.com/ministryofjustice/opg-metrics/pull/54", "comments": ["tfsec check aws-s3-block-public-acls failed. \n\nDescription: No public access block so not blocking public acls\n\nSeverity: HIGH\n\nFor more information, see:\n\n- https://aquasecurity.github.io/tfsec/v1.26.0/checks/aws/s3/block-public-acls/\n- https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket_public_access_block#block_public_acls\n", "tfsec check aws-s3-block-public-policy failed. \n\nDescription: No public access block so not blocking public policies\n\nSeverity: HIGH\n\nFor more information, see:\n\n- https://aquasecurity.github.io/tfsec/v1.26.0/checks/aws/s3/block-public-policy/\n- https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket_public_access_block#block_public_policy\n", "tfsec check aws-s3-enable-bucket-encryption failed. \n\nDescription: Bucket does not have encryption enabled\n\nSeverity: HIGH\n\nFor more information, see:\n\n- https://aquasecurity.github.io/tfsec/v1.26.0/checks/aws/s3/enable-bucket-encryption/\n- https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket#enable-default-server-side-encryption\n", "tfsec check aws-s3-enable-bucket-logging failed. \n\nDescription: Bucket does not have logging enabled\n\nSeverity: MEDIUM\n\nFor more information, see:\n\n- https://aquasecurity.github.io/tfsec/v1.26.0/checks/aws/s3/enable-bucket-logging/\n- https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket\n", "tfsec check aws-s3-enable-versioning failed. \n\nDescription: Bucket does not have versioning enabled\n\nSeverity: MEDIUM\n\nFor more information, see:\n\n- https://aquasecurity.github.io/tfsec/v1.26.0/checks/aws/s3/enable-versioning/\n- https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket#versioning\n", "tfsec check aws-s3-encryption-customer-key failed. \n\nDescription: Bucket does not encrypt data with a customer managed key.\n\nSeverity: HIGH\n\nFor more information, see:\n\n- https://aquasecurity.github.io/tfsec/v1.26.0/checks/aws/s3/encryption-customer-key/\n- https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket#enable-default-server-side-encryption\n", "tfsec check aws-s3-ignore-public-acls failed. \n\nDescription: No public access block so not ignoring public acls\n\nSeverity: HIGH\n\nFor more information, see:\n\n- https://aquasecurity.github.io/tfsec/v1.26.0/checks/aws/s3/ignore-public-acls/\n- https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket_public_access_block#ignore_public_acls\n", "tfsec check aws-s3-no-public-buckets failed. \n\nDescription: No public access block so not restricting public buckets\n\nSeverity: HIGH\n\nFor more information, see:\n\n- https://aquasecurity.github.io/tfsec/v1.26.0/checks/aws/s3/no-public-buckets/\n- https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket_public_access_block#restrict_public_buckets\u00a1\n", "tfsec check aws-s3-specify-public-access-block failed. \n\nDescription: Bucket does not have a corresponding public access block.\n\nSeverity: LOW\n\nFor more information, see:\n\n- https://aquasecurity.github.io/tfsec/v1.26.0/checks/aws/s3/specify-public-access-block/\n- https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket_public_access_block#bucket\n", "Remove that", "```suggestion\r\n```"]}, {"url": "https://github.com/ministryofjustice/opg-metrics/pull/46", "comments": ["```suggestion\r\n    name: Terraform Plan\r\n```", "Some names need t be updated here. Maybe they should be project agnostic as they get copied around.", "Should this be te docker job?", "Instead of ineriting all secrets, you can specify just the one you need for this job. That's one of the benfits we'd like to realise with actions over circle\r\nsee https://docs.github.com/en/actions/using-workflows/reusing-workflows#creating-a-reusable-workflow", "same for the name of the job below if it's not limited to working with account"]}, {"url": "https://github.com/ministryofjustice/opg-metrics/pull/20", "comments": ["is that a typo mate - did you want `dns_namespace_env` ?", "It is mate, thanks!", "I don't think this is being done elsewhere but I think it's worth naming the session to show that it's for opg-metrics. The management account is used by pretty much every service/ws account, so it will be helpful to differentiate for audit.\r\n\r\n```suggestion\r\n    session_name = \"opg-metrics-terraform-session\"\r\n```", "Need to name this differently", "I find it helpful to leave a comment here to show what the record name should interpolate out to.\r\n```suggestion\r\nresource \"aws_route53_record\" \"opg_metrics\" {\r\n# <environment.>api.metrics.opg.service.justice.gov.uk\r\n```"]}, {"url": "https://github.com/ministryofjustice/opg-metrics/pull/14", "comments": ["we should have just one stage I think, and name it after the workspace or version (perhaps the version would be better)", "Yeah will remove the dev stage and just keep the prod for now. Will add the workspace name instead of a version in the short term until we figure out a versioning strategy. ", "This would do it for using the workspace name\r\n```suggestion\r\n  stage_name    = terraform.workspace\r\n```"]}, {"url": "https://github.com/ministryofjustice/opg-metrics/pull/11", "comments": ["Not sure Gamify is an aim. ", "Feel like it needs something about how it should be comprehensible to non-technical staff to make decisions or kickstart investigations..", "2021", "Top phrasing! \ud83d\udc4d ", "Is it worth linking out to https://docs.opg.service.justice.gov.uk/documentation/get_started.html#get-started "]}, {"url": "https://github.com/ministryofjustice/opg-metrics/pull/9", "comments": ["Wonder if this OpenAPI spec is in the right location, /docs/ folder maybe or app level. Not sure TF env is the place.", "Might be better to just recommend the dockerised version as fewer prereqs. (updated as I should read down)", "Wonder if putting metrics should be a 202 accepted?", "I would usually agree however the same spec is used to create the API Gateway endpoint and want to not duplicate the code and also leave it in the appropriate area.\r\n\r\nAlso I keep refereeing to it as Swagger, do you think OpenAPI would be more appropriate in the description as it is the spec rather than the brand name?", "You are right, in this instance it is a fire and forget onto a seperate async process so this fits nicely. As well as that I am going to change the response so that it returns an appropriate message of the status of the request. Something like \"Processing\" as defined in the spec", "I'd go with OpenAPI as it's the standard, Swagger is the tools. https://swagger.io/blog/api-strategy/difference-between-swagger-and-openapi/ for a summary.", "Ah, code location makes sense then. May need a way to wayfind it from the repo root/app, but I guess that's what our new repo docs standards are for!"]}]}, {"url": "https://github.com/coreos/tectonic-installer.git", "pull_requests": [{"url": "https://github.com/coreos/tectonic-installer/pull/3325", "comments": ["We have no use for ever overriding this so it seems like this should be a local rather than a variable.", "shouldn't this be local instead of `var.const_id_to_group_name_regex`? "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3324", "comments": ["Why do we need a ternary at all? We have two strings a and b. c is defined as a+b. If b == \u201c\u201d then c == a, no? Can\u2019t we simplify this to always output the local var?", "Same as above", "Same for this file", "Same for this file too"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3322", "comments": ["there's no other error in this func besides `errGlobal`. To avoid confusion let's rename this to `err`.", "It doesn't matter if you already validated the file path. What if the user deleted the path between the invocation of both pieces of code? What if the host OS had some error? There is no cost in checking the error again. If you feel strongly about the guarantee of the validate func, then it could be appropriate to `panic(err)` if `err != nil` since it is a program error", "same as above", "this function does not seem very useful IMO", "remember we like to format errors with `%v`", "This seems like an unnecessary level of abstraction. Users of this func still need to create a configuration (now a CSRCfg rather than a x509.CertificateRequest, and still need to call a func (now CertificateRequest rather than x509 CreateCertificateRequest). Given that more teams will be working on this and this function is quite trivial it seems better to maintain convention than to customize.", "these functions  are now duplicated across multiple packages. We should avoid copy and pasting code across multiple packages and instead import those funcs from other packages.", "just curious, is there a convention why we are injecting in multiline rather than a single line? "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3319", "comments": ["just to clarify by design this will never be the case as kingpin won't allow it right?", "Yup, forgot to remove this. Didn't have Required() at first on the arg in kingpin."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3318", "comments": ["Maybe instead of \"install Kubernetes the Tectonic Way\" it should now read \"install Tectonic Kubernetes clusters\" since we're not supporting or encouraging \"vanilla kubernetes\" (I believe that options was removed from track-1 too no?)", "Maybe replace \"platform\" with \"Tectonic\" since elsewhere we use \"platform\" to mean a cloud provider.", "Tectonic clusters", "or \"Tectonic Kubernetes clusters\"", "remove Ubuntu and \"and others\"", "remove etcd Operator part", "Remove this. The file was deleted."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3317", "comments": ["Please change `Open Shift` to `OpenShift`."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3316", "comments": ["as a rule, we like to format errors with `%v`", "did you mean to pass the file destination for the `(%s)`? otherwise lets be consistent and wrap the error like `: %s`", "nit: since you are ignoring the non-error return value, we can make this a little bit nicer with:\r\n```go\r\nif _, err := generateRootCA(clusterDir, key); err != nil {\r\n...\r\n}\r\n```", "same question here as above concerning the `(%s)`", "for consistency please use `%v` to format errors.", "`Key` and `File` at the end of the sentence do not need to be capitalized ", "`File` at the end of the sentence does not need to be capitalized.", "Please use `%v` for errors.", "No need for a colon here", "s/privateKeytoPem/privateKeyToPem/\r\nBy convention, identifiers in golang should be camelcased so every separate word in a golang identifier should be capitalized. ", "`Config` can me lowercase here", "nit: we can use\r\n```go\r\nif _, err := x509.ParseCertificate(block.Bytes); err != nil {\r\n...\r\n}\r\n```", "between lines 383 and 389 it looks like we went from a string, to a reader, to a byte array. It would be easier, and error-free, to go directly from a string to a byte array like:\r\n```go\r\nblock, _ := pem.Decode([]byte(v))\r\n```", "nit: for better maintainability, we could consider generating a throwaway certificate here instead of hardcoding a hand-generated one. not a blocker.", "same as above", "we can delete this extra newline after the return", "this newline here is a little funny", "this is not actually checking the error returned by the `generateRootCA` func, but rather the error from the parent scope.", "there should be no need to have these block-scoped variables here. for long functions it can lead to shady scenarios where we unsuspectingly shadow the variables or forget to assign variables since the variable is already declared (as happened below where the error from `generateRootCA` was not actually being checked; if this variable was not declared here then the compiler would have caught that bug).", "I think it would be easier to follow the logic of this long function if both the private key generation and certificate generation were done close together and if the key file copying and the cert file copying were done together. WDYT? This `if` statement could be:\r\n```go\r\nif c.CA.RootCAKeyPath == \"\" && c.CA.RootCACertPath == \"\" {\r\n// generate key and certificate\r\n} else {\r\n// copy key and certificates\r\n}\r\n```", "Do you know why are we writing to the writer using fmt instead of using `w.WriteString` [0]?\r\n\r\n[0] https://golang.org/pkg/bufio/#Writer.WriteString", "we should always check returned errors, even in tests. If we get an error then we can call: `t.Fatalf(\"failed to generate test private key: %v\", err)`", "same as above", "same as above", "should we wrap the returned error here? or is it not necessary?", "nit: this sentence has some funny casing.", "you are shadowing a constant here, which is a little funny. Also, as far as this function is concerned, the `newTLSPath` is just the `path`, right? This func doesn't know about anything but the new TLS stuff anyways so there is no need to further qualify the variable name in this lexical context.", "I don't think we need to use the `isMatch` test anymore. The `PrivateKey` test you rewrote is quite thorough enough. I do not think that the matching provides any extra benefit and it is extra noise.", "I think that the validation of the certificate file and private key file should occur here in the validation phase rather than (or maybe in addition to) the workflow stage. The reason for this is that we want to catch user errors as early as possible so that a user can't even initialize an installer config if it is invalid. Currently, a user could point their CA cert to an arbitrary file, run the install command, and then get an error halfway through. WDYT?", "Yes, should be pretty much analogous to ignition validation https://github.com/coreos/tectonic-installer/blob/master/installer/pkg/config/validate.go#L296", "this validation func does not return any content of any file, only an error if any was encountered.", "same as above", "I think this got lost in the last round of reviews. We should be checking the errors returned by any func even in tests rather than ignoring them. If we do get an unexpected error in the setup, then we can call: `t.Fatalf(\"failed to generate private key: %v\", err)` and the test suite will fail gracefully.", "same here", "Seems this still need to be addressed?", "Is this just changing order? it'd be useful to proactively add context for that when that's the case :)", "Updated"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3310", "comments": ["The previews rspec took care of deploying a cluster. We should make clear here that a cluster needs to be deployed first and point to the steps in readme", "just ignore me :)"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3306", "comments": ["should we remove this as well then https://github.com/coreos/tectonic-installer/blob/master/Jenkinsfile#L92?", "I think that line produces an artifact which can be downloaded later, so I would leave it as is."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3302", "comments": ["We should add some more test cases to really verify all the code paths. Can you add a test case that returns an error?", "I think \"expected no error\" is not always the case here. There's a case where you fall here when expecting an error (c.err -> true), but the method is erroneously returning nil so (err !=nil -> false) so either we show a more generic message or do something of the likes of https://github.com/coreos/tectonic-installer/blob/master/installer/pkg/validate/validate_test.go#L482 "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3301", "comments": ["we try to standardize on starting errors with lowercase and chain with colon separators", "FYI semantic validations are currently centralised within https://github.com/coreos/tectonic-installer/blob/master/installer/pkg/config/validate.go#L79 so might want to consider to follow that pattern", "Yes, but this is a syntactic validation. It shouldn't be possible to instantiate a `Platform` that isn't AWS or Libvirt (though Go doesn't actually let us enforce this)."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3297", "comments": ["this is actually a terraform variable to be interpolated so don't need quotes", "terraform templating will try to interpolate and complain about this"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3296", "comments": ["Are we actually currently leveraging  internal-cluster somehow? should we remove the whole contrib?", "I looked through it and the code is still valid although unused. WDYT? I'm happy to eliminate it entirely", "Cool let\u2019s remove it if you are good with it, we can always get back to the git history if we need it "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3294", "comments": ["where are these locals being defined?", "this won't work for the bootstrap node request resolved to s3 as the tls aws certs does not know about this domain", "They were added in 37f29a5.", "Christ, we need to kill off this S3-pivot insanity.", "aws?", "https://github.com/coreos/tectonic-installer/blob/master/installer/pkg/config/cluster.go#L25", "Also calling I think it's advised to `c.Platform.String()`", "Doesn't `etcdctl endpoint health` have its own retry logic?\r\ncc @gyuho ", "I observed it failing to retry.", "The retry logic would depend on the error types. Since endpoint health is just a simple get request, it's safe to retry here."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3286", "comments": ["This should go in another PR, no?", "sure https://github.com/coreos/tectonic-installer/pull/3287, lets see if we get it green asap. This is due to tests were not run here https://github.com/coreos/tectonic-installer/pull/3285"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3284", "comments": ["this is huge. without this, we may be directly impacting Terraform's behavior unintentionally.", "Remove comment", "can we eliminate these?", "same here or add a note about who it's for", "remove comment", "remove comment", "delete this line", "is there a way around generating and uploading a new key for every run?", "remove these lines as well", "This behaviour is backported from old CI framework. Also we are running it in a docker container so the only solution would be to embed ssh key into docker container", "@squat could you elaborate?", "What I\u2019m saying is that this is a great improvement!", "just to clarify are we actually shellcheking this or did you do it manually? ", "I did it manually", "We used to shell check as part of the basic tests. We should add this back in ASAP", "Later, in another PR, I'll add shellcheck to travis jobs.", "@squat it looks like shellcheck wasn't enabled in CI pipeline for at least 4 months or it wasn't checking every `*sh` file. It is just my guess based on the fact that shellcheck prints errors in `buildvars.sh` file which was last modified 4 months ago.", "why we need to redirect?", "extra space here", "This (with `SMOKE_TEST_OUTPUT=$(./smoke -test.v --cluster | tee >(cat - >&5))`) allows to write output of smoke tests to the variable and simultaneously to the screen.\r\nHow it works:\r\n`tee` gets output from `smoke` command and outputs to stdout (this is written to a variable) and also it tries to output to a file. In this case we use `>(cat - >&5)` construct in place of a file. It creates a new file descriptor no. 5 and writes to it, but since fd 5 isn't printed on screen by default, we need to inform shell before to redirect everything from fd 5 to stdout (`exec 5>&1`)."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3282", "comments": ["Should we be calling this OpenTonic or just Openshift?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3273", "comments": ["You probably don't want to validate here as it's redundant with .ioutil.ReadFile and does not belong to this responsibility boundary.", "This is looking good!\r\nhaving \r\n`\r\ntype ConfigGenerator struct {\r\n config.Cluster\r\n}\r\n`\r\nfeels a bit confusing as this is currently contained within its own package.\r\nwe should probably eventually align with it (so details from this library could be consumed from the configGenerator package) see the down path for https://github.com/coreos/tectonic-installer/blob/master/installer/pkg/workflow/install.go#L145 On the other hand might be good to keep this selfcontained for now wdyt?", "Yeah, i'll probably move this section inside the `config/tls` package, as it belongs there anyways.", "Agreed. I'll validate the config parameters inside `config/tls` so as to remove redundancies.", "These two variables are modified by the `GenerateTLSConfig` func but they are never used anywhere. Nothing actually uses the certs.\r\nAlso, why do we need global variables? `GenerateTLSConfig` should not need to store state anywhere other than generating certificates and writing them to disk, right?", "This function suppresses all errors and always returns nil. How do we know if something is failing? We need to check all errors and surface them.", "Were all of these `Printf`s for testing during development? We should either eliminate them all of replace them with logs of either trace or debug.", "The function description says that if no CA cert path is provided then a cert is generated but I don't see that here. Where does the generation occur?", "Same with the case where no key is provided: where is the key generated?", "We like all errors to begin with a lowercase letter so that they can be wrapped by other functions (just like you are wrapping another error here).", "There is no need to validate that the file exists before trying to read the file; if you get an error when reading just wrap and return that, e.g.\r\n```go\r\nreturn fmt.Errorf(\"failed to ready certificate key file: %v\", err)\r\n```\r\n\r\nIn fact, we will already need to validate that these paths are either valid or null in `installer/pkg/config/validate.go` so this function should really just check the error returned by `ioutil.ReadFile`.", "I see that you alphabetized all of the fields but put this one out of order. Was there a reason for that?", "Nit: these changes break the naming pattern that the other commands and workflows had. Previously it was:\r\ncommand: X\r\nworkflow: workflow.NewX\r\nWe should try to be consistent so that future maintainers have an easier time.", "I was planning to generate the certs in a separate tls package `installer/pkg/tls` but If i called that package now, when it doesn't yet exist, It would fail the build. Hence, the printfs that will be replaced with the correct function call.", "I see. In that case we should work backwards. The first PR we should merge is a fully working `instaler/pkg/tls` package that can generate certificates. This is self-contained and feature complete. The second PR we merge is `installer/pkg/config-generator/tls.go`. which builds on the first one. In general, we should be merging the self-contained dependencies first and then merge the code that depends on it. Otherwise, we are merging known-broken code :/", "yeah let's try to get small batches of self-contained library details respecting the dependencies, then we add abstractions, integrate and expose to the user. i.e:\r\nINST-1107..INST-1113 by order, then we get this in. Otherwise this one need to go in hand with an implementation for tls.generateRootCA", "This func was quite confusing for me to read because of the name `certTemplate`. In the Golang x509 package functions, `template` is a variable name used for actual certificate structs that serve as the basis for new certificate structs, however the `tls.SelfSignedCACert` func does not actually accept a template but rather a config. In Golang it is common practice to name configs simply `cfg`. Can we rename this here?", "we should not ignore this error", "We should check the error returned by this function", "Same as above", "same as above", "This function does not seem very \"general-purpose\" to me. The common-name and org unit are hardcoded so it does not seem appropriate to put this function in a `utils` file. It would be more general-purpose, util function if what it did was accept a certificate config struct and write the new cert to disk. This way it stays abstract enough for a `util` but also provides a utility, namely generating a certificate and writing it to disk. Otherwise, this function is not really a utility since it performs core business logic and adds a single extra function call at the end `writeFile`. Instead, its contents could be moved to one of the core functions of the `config-generator/tls.go` file and it could be renamed to something like `generateRootCA`.", "There is no need for these `break` statements here. In Golang, the case statements of a switch do not automatically fallthrough [0] [1] \r\n[0] https://tour.golang.org/flowcontrol/9\r\n[1] https://play.golang.org/p/cnclx9UobBm", "we need to explicitly add a `fallthrough` statement here to actually test both error conditions.", "The renaming of these functions should be a separate commit so as to not conflate it with the new TLS work. In fact, we could make it a completely separate PR and merge it before the TLS work", "There's no need for this extra newline here", "not related to your changes but we should lowercase `generates`", "No need for this newline here.", "The creation of this TLS directory is unrelated to the rest of this `generateClusterConfigMaps` func. We should move it somewhere else IMO", "remember to start errors with lowercase words so they can be wrapped", "we could summarize the two separate cases above into one single case like:\r\n```go\r\ncase (c.CA.RootCACertPath == \"\") != (c.CA.RootCAKeyPath == \"\"):\r\n    errs = append(errs, fmt.Errorf(\"rootCACertPath and rootCAKeyPath must both be set or empy\"))\r\n```", "nit: We should try to ensure that comments describing are full sentences with correct casing an identifier start with the name of the identifier, even if it is unexported. So this comment should look like:\r\n```go\r\n// parseCertFile validates and returns the content of a certificate file.\r\nfunc parseCertFile(path string) (string, error) {\r\n```", "nit: lowercase `Certificate`", "nit: fix comment as described above.", "nit: same as above"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3272", "comments": [":+1: this is much better than using `TF_VAR_tectonic_license_path` since this affects the terraform execution both indirectly, through rspec, and directly."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3270", "comments": ["what's running on 6444 and 6445?", "why not just `cp -r bootstrap-configs /etc/kubernetes/bootstrap-conf` without the `$(pwd)`?", "Who is `they`?", "we should keep the newline", "Why do we need to use `--insecure-options`? Can we instead add a task to make the image secure?", "I see that this commit didn't introduce the mistake but we should add a newline here.", "because we're pulling a docker image instead of an ACI. No choice :-(", "This goes away when we switch to quay.", "Right, this is my point. Can we either:\r\na: switch to quay right now\r\nor\r\nb: make a task to switch to quay and remove this flag", "Is this necessary? or just some debug code that leaked?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3268", "comments": ["we'll need to mirror this docker image", "we'll need to mirror this docker image", "we'll need to mirror this docker image.\r\nFYI at some point you might wanna try to revive https://github.com/coreos/tectonic-installer/pull/3115 and integrate gometalinter here somehow", "do we need `--output_base=.cache`? we already have a .bazelrc file", "And maintain it?", "And maintain it?", "And maintain it?", "I wanted to stay close to commands we have in README.md, but I can remove `--output_base=.cache`", "@paulfantom. Yes as a rule we try not to depend on random third party containers whose maintenance and security we cannot guarantee.", "The idea behind .bazelrc is to have consistent and replicable behaviour across envs. Update readme sound good to me unless I'm missing something different when building via docker cc @squat ", "@enxebre @squat I agree that golang-testing and yamllint containers should be mirrored, but this one (wata727/tflint) is an [official one](https://github.com/wata727/tflint#running-in-docker), do we also mirror official ones?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3267", "comments": ["I'm confused about what is this actually doing?", "Performing a simple go build of the installer (just enough to run an install).  I'm trying to kill a few birds with one stone:\r\n\r\n1. familiarize myself with the build toolchain so I know what is coming upstream\r\n2. check for any places where bazel is needed (it doesn't look like it) since that's more effort to turn into official builds\r\n3. get a simple single file dockerfile that we can potentially run identically with multiple bases in CI or out (fedora, centos, minimal image, rhel, etc)", "@smarterclayton Bazel was a decision we made to help us gain control of the user deliverables in the context of Tectonic as an end-user product. It gave us strong guarantees that the contents of what we ship come from where we expect them to (reproducible builds). Not once has it happened that we shipped wrong versions of our dependencies because of \"handcrafted\" release scripts.\r\n\r\nThat being said, that made sense back when Tectonic was shipping directly to customers and no other process was available. It's worth reconsidering if Bazel still makes sense in the RedHat context. I'm not familiar with the options we have now.", "Yeah, I had talked to Crawford a bit about it.  It's not that Bazel is bad on its own, it just doesn't integrate well into systems that already do reproducible builds (like the koji/brew build systems for Fedora/CentOS and debian).  Most of the assumptions bazel makes are either not helpful when layered on top of another reproducible build system (that for instance requires end to end source and rebuild capability, blocks external dependencies, already has a strong versioning and scope management tool, etc).  It's not that bazel can't eventually fit into that, but it will take some time.  I like a lot of bazel, am so-so on other parts at smaller scale.  \r\n\r\nGenerally the release scripts are \"outside of\" the repo context (for either images or the content within), but I agree that handrolled is bad.  This is more of a bridge step that allows us to simulate those environments (where we have hermetic inputs delivered via RPM) while still having a familiar Dockerfile.  So the \"release\" dockerfile might look like this but instead say \"yum install terraform\" where terraform was an external RPM managed dependency with its own hermetic seal, and the RPM is brought into scope by the build system at the point we tie the image (koji / brew have \"tags\" which bring together explicit versions of RPMs into a pool that can be used to build new content)."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3265", "comments": ["Let's get \"tectonic\" out of this - how about `osbr0`", "It's not 100% necessary, but if you want to validate that this doesn't overlap with the cluster and service cidrs, that would be awesome!", "sounds good. I should have confirmed with you earlier, I just grabbed what was in defaulted in the Terraform config.", ":+1: ", "Is it possible to validate that this is a valid path on disk? Even more amazing would be validating that the first four bytes match `QFI\\xFB`", "cool idea!", "at this point, it's completely arbitrary. oh, did you know that Linux interface names have no restrictions on characters? Let's just call it :bridge_at_night: "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3262", "comments": ["The only difference here is the removal of the `TLSValidityPeriod` field. The rest is white space."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3260", "comments": ["I think we could omit `FileExists` here as it's implicit in `JSONFile` which calls `ioutil.ReadFile` wdyt?", "I think we could omit `FileExists` here as it's implicit in `License` which calls `ioutil.ReadFile` wdyt?", "yes sounds good", "agreed"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3250", "comments": ["I think we need to keep the condition for `var.etcd_iam_role == \"\" ? 1 : 0}` here", "Yes. Already on it :muscle: "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3244", "comments": ["`adds` should be `add` and `updates` should be `update`", "no comma needed here", "it's a little bit funny to say `commit x as a commit`. maybe `commit vendored code changes separately from any other changes`", "a comma is odd here. use `;` or maybe `i.e.`", "no comma needed before `but`"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3241", "comments": ["Because the binary is now generated by `installer/cmd/tectonic` (which is generated by gazelle) we ensure with pkg_tar that is dropped in the expected path at build time, i.e `installer/`", "Thanks for reverting this to how it used to be, this was very painful for Bazel/gazelle."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3239", "comments": ["this should probably go away as well", "can you clarify why do we need the additional libraries above and this last RUN?", "Google removes all older bazel versions from their apt repo. So in order to fetch older versions we need to install it from github. The last RUN is supposed to install all the declared dependencies in the deb file.", "the additional libraries are required per the documentation: https://docs.bazel.build/versions/master/install-ubuntu.html"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3238", "comments": ["nit: personally I'd find easier to read just `sprintf(%s-tnc.%s, c.Name, c.BaseDomain)`", "Might put 63 in a constant", "printing `bucket` in the error would give immediate info to the user ", "Couldn't we check the length, then just `validate.DomainName(bucket)`?", "Well, there are valid domain names that are not valid bucket names. Domain names are allowed to end in a `.` where as S3 buckets are not", "valid domain name but invalid s3 bucket name cc @enxebre "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3237", "comments": ["There is no variable `pullSecret` it should probably be `pullSecretPath`.", "Also `libvirt-devel` is needed by terraform-provider-libvirt. Otherwise `go get` will exit with error message:\r\n```\r\nPackage libvirt was not found in the pkg-config search path.\r\nPerhaps you should add the directory containing `libvirt.pc'\r\n```", "Config is located at `../tectonic.libvirt.yaml`", "Root README says also to add binaries to PATH: `export PATH=$(pwd)/installer:$PATH`", "Bash won't allow exporting variables starting with `$`.", "First node is *test1-master-0.tt.testing*", "Master node is located at `$CLUSTER_NAME-master-0.$BASE_DOMAIN`", "There is no `tectonic` namespace. There are:\r\n- tectonic-system\r\n- tectonic-ingress\r\n- kube-system"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3236", "comments": ["this func was not necessary. we were already validating that `configFilePath` was not empty so the only thing this func did was access a struct member", "yeah I originally put the func there to make it clear for others that during the current `init` process it only need to read the config file to get the cluster name. This will change as we refine the `init` process"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3233", "comments": ["The smoke tests currently rely on being able to read the networking type from the config file [0] so we cannot remove this value just yet even though it has a default.\r\n\r\n[0] https://github.com/coreos/tectonic-installer/blob/master/tests/rspec/lib/config_file.rb#L21", "People loooove to overlap podcidr and servicecidr. Can you check for that?\r\n\r\nThere is an implementation here you can crib: https://github.com/containernetworking/plugins/blob/master/plugins/ipam/host-local/backend/allocator/range.go#L125", "@squeed I just added overlap validation. PTAL when you can", "very cute :-)", "this wound't be optional anymore. Nevertheless I think tf does not need this var anymore", "this wound't be optional anymore. Nevertheless I think tf does not need this var anymore", "this wound't be optional anymore. Nevertheless I think tf does not need this var anymore", "why do we need to pass this value here?\r\nI think this variable is actually not used by tf anymore so we should remove it in a different PR as part of further cleanup and per step vars review but no need to pass it here\r\n", "why do we need to pass this value here?\r\nI think this variable is actually not used by tf anymore so we should remove it in a different PR as part of further cleanup and per step vars review but no need to pass it here", "why do we need to pass this value here?\r\nI think this variable is actually not used by tf anymore so we should remove it in a different PR as part of further cleanup and per step vars review but no need to pass it here", "why do we need to pass this value here?\r\nI think this variable is actually not used by tf anymore so we should remove it in a different PR as part of further cleanup and per step vars review but no need to pass it here", "We must pass this value here because the entire `/step/x/base` pattern is broken. Every variable that could potentially be used by the underlying step needs to have variables explicitly passed along. Otherwise: variables with defaults will use the defaults instead of the user-specified values and variables without defaults will cause the module to break.", "We must pass this value here because the entire `/step/x/base` pattern is broken. Every variable that could potentially be used by the underlying step needs to have variables explicitly passed along. Otherwise: variables with defaults will use the defaults instead of the user-specified values and variables without defaults will cause the module to break.", "We must pass this value here because the entire `/step/x/base` pattern is broken. Every variable that could potentially be used by the underlying step needs to have variables explicitly passed along. Otherwise: variables with defaults will use the defaults instead of the user-specified values and variables without defaults will cause the module to break.", "We must pass this value here because the entire `/step/x/base` pattern is broken. Every variable that could potentially be used by the underlying step needs to have variables explicitly passed along. Otherwise: variables with defaults will use the defaults instead of the user-specified values and variables without defaults will cause the module to break.", "yup, until we segregate variables per step we need to inject the ones needed into /base, however It seems pointless to inject the ones we know won't be used. Not a big deal anyways, let's approach it in different PR "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3232", "comments": [":p"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3231", "comments": ["this resource was never used :/", "I'm curious if you considered to use a ternary here to return either `tectonic_aws_external_private_zone` or `aws_route53_zone.tectonic_int.*.zone_id` then it would be transparent for consumers steps, so the `private_zone_id` input wouldn't need to do the check and could keep just `private_zone_id \r\n = \"${data.terraform_remote_state.topology.private_zone_id}\"` ", "yes I did, but I decided against it for consistency and clarity. Otherwise, I foresee a near future where someone forgets that this variable is already the result of a ternary and adds another ternary on top. It wouldn't hurt the output but it is muddy.", "Does this mean we're not doing split horizon anymore?", "we still have split horizon, it was just moved somewhere else and this was never cleaned up: https://github.com/coreos/tectonic-installer/blob/master/steps/topology/aws/main.tf#L22", "Got it. Makes sense then. All cool!"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3230", "comments": ["we should probably move this path to a local variable at some point"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3228", "comments": ["why does it need to be a pointer?", "receiver methods should generally be pointers unless there's a good reason for them not to be. Otherwise, the underlying datastructure is copied for every call."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3227", "comments": ["nowadays terraform suggests you place third party providers in os-neutral directories [0], although os-explicit ones are still supported. I suggest we document `~/.terraform.d/plugins/` so that this binary ends up with other third party providers on a user's system.\r\n\r\n[0] https://www.terraform.io/docs/configuration/providers.html#third-party-plugins", "didn't know that, thanks!"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3213", "comments": ["nit: variables are usually in `variables.tf`", "Yes. Yes they are."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3211", "comments": ["The tests look for /opt/tectonic/init_tectonic.done and /opt/tectonic/init_bootkube.done to determine the services were run successfully, this might be introducing a race?", "Hmm good point. Yes this is probably racing but is seems strange to me that Jenkins should win that race ever since it is polling where as this deletion is happening immediately. Any suggestions? We _could_ leave the .done files in place.", "Hum... yeh it's not clear to me why Jenkins always wins, unless the script breaks and exits before actually running `bootstrap_cleanup`. Also I can't see how we are ensuring the order since the \"after\" instruction was removed here https://github.com/coreos/tectonic-installer/commit/b2e0bcf2f26141706cbf96e508afd14ee351af7c#diff-1a97b193d989dc396fb00a024f0e42a8L4\r\nWe could add an spec (may be in a different PR) to verify files the node was actually cleaned up correctly.\r\nLeaving the .done files sounds reasonable to me, It'd be nicer to leverage systemd instructions (status/is-active, etc) to check a expected status so we don't leave any clue but I'm not sure if there's simple way to do it ", "It\u2019s delcate since we are also removing the systemd service files. We do not run systemctl daemon-reload so it\u2019s possible the exit state of the services is still available even without the unit files.", "If all we need is a signal that the bootstrapping process was successful, then perhaps we can touch /opt/tectonic-done and keep it regardless?", "do you have a link to the systemd substate docs? I wonder if \u201cexited\u201d make a difference when the service exits because of a failure, otherwise looks good to me", "as written OOB: if it had failed then the service would not be active, so `systemctl is-active` would return non-zero"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3204", "comments": ["Unfortunately this doesn't work, because `.bazelrc` does not expand environment vars. On my Bazel 0.12.0 it creates a directory tree `$PWD/build` (literally - i.e. the directory name has a `$` sign in it). (And even if it did work, bazel would still have to be run from the workspace directory, it can't be run from any sub-directory).\r\n\r\n`.bazelrc` has some limited support for interpolating the workspace directory using `%workspace%` macro. However it's not available for the build/startup directives.", "This change works by accident, I think. I don't believe it's expanding `$PWD` for the reasons stated above. There is some buggy path parsing in 0.12.0 so I think it's the presence of something other than '.' that's making this work.\r\n\r\nI had success by moving `buildvars.sh` to `hack/buildvars.sh` and using that instead, albeit with the restriction that I only use the bazel client from the workspace directory.", "This works, albeit the user must still run bazel from the `WORKSPACE` directory. I don't think there's anything we can do about that. :/\r\n\r\nBe aware that `bazel run //:gazelle` breaks a lot of `BUILD.bazel` files within the `build` directory. This can be prevented by adding `# gazelle:exclude build` to the workspace's `BUILD.bazel`.", "Surprisingly, this works even when the user runs bazel outside the `WORKSPACE`. Bizarrely, `$PWD` is set to the `WORKSPACE` path when running the command, rather than the bazel client's actual PWD. I guess this is a lucky (and apparently undocumented) quirk. Here's hoping that future versions formalize this behavior."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3200", "comments": ["I'm not sure ingress_kind is actually used at all in tf. I think is only used by the configs generated by the cli and it's currently a hardcoded value, so we'd need to pick it from the config https://github.com/coreos/tectonic-installer/blob/master/installer/pkg/config-generator/generator.go#L33", "couldn't we move this to config.tf and get rid of the symlinked variables.tf file? then `variables2` can be just `variables`", "Oh, that's definitely a problem; ingress needs to be HostPort for bare-metal situations.", "Oh, good idea."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3197", "comments": ["delete these comments?", "does it make sense to log a warning here? or is this an expected state?", "extra return", "just a FYI, I had to move this before the `runInstallStep(assetsStep)` as part of #3183.", "One little thing: could you convert platform to lower case? Otherwise I'll have to update that in a separate PR.", "This is a lot cleaner, nice.", "https://github.com/coreos/tectonic-installer/pull/3197/files#diff-e22bb80d035913a0a75945c1e983a35bR88", "can we pull this function definition out of the `main` func? there is no need to do this inline.", "`clusterInstallDirFlag` is a funny name for this parameter. the function should not care if it is a flag or an argument or how the string was provided to the function. Could simply be named `dir`.", "creating a cluster should be separate from parsing the log level. In fact, this change introduces a new behavior where log levels are not parsed for the `convert` command since that command does not execute this `newCluster` func. I think parsing the log level should be done outside of this func.", "We typically make errors lower-case so they can be wrapped.", "same as above", "same as above", "should this be a return? currently this line evaluates the `errors.New` func but does nothing with the returned value", "same as above", "same as above", "This statement does not do anything with the returned value from `errors.New`. Did you mean to `return` here?", "Log lines typically begin with a capital letter", "it's typical to put the error check immediately after the error declaration"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3193", "comments": ["In follow ups we'll simplify the init flow by moving the clusterDir Name to be a user input value, which makes UX sense as a user could source the same cluster config in different environments and we'll avoid to read the source config file ", "I think this should be renamed to drop the `aws`"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3183", "comments": ["Do we have 'config/bootstrap' ?", "Yeah. it's the third step in the redirect chain, and it has a private acl.", "I\u2019ve been scratching my head to figure out how to make the http s3 endpoint more secure, this is just very nice and super simple, thanks!", "This splat evaluates to a list, which means the `ignition_file_id_list` will be a list which contains a list element (which I'm assuming is not intended). A pretty robust way to deal with this is and ensure the output is always a flat list of id's:\r\n\r\n```\r\nvalue = [  \"${flatten(list(data.foo.bar.*.id, data.blah.thing.id, data.blah.otherthing.id))}\"  ]", "Same thing here, when mixing splat id lists and singelton ids into a single list, use `flatten(list(...))` so you get a flat list consistently", "`flatten(list(...)))`", "Ternary expressions conditionally consuming lists can make terraform behave \"oddly\". Would recommend doing something more generic like:\r\n\r\n`${join(\"\\n\",compact(flatten(list(tls_self_signed_cert.root_ca.*.cert_pem, var.root_ca_cert_pem))))}`\r\n\r\nAlso- I'd think you'd want to join the certificate pem blocks using a newline, instead of empty string?", "This (and all other private keys) need to be `0600` mode", "0600", "0600", "0600", "0600", "0600", "This will also be a nested list situation, recommend flattening the whole list. (nice use of compact here).", "flatten here as well", "It would be nice if these generated file paths were canonically defined in a `locals` block.", "Should also include a `set -u` here, so if `$LOCATION` is omitted bash will complain, and we don't just get a cryptic S3 API error back. ", "What is the reason this a `replace` and not an `append` block? ", "Basically to keep people honest :-).", "oh man, thanks!", "I just copied this from the line above; while you're probably right, I'd rather not change what \"works\". I'm not sure that custom certificates work right now anyways.", "In other words, I don't want there any to be any chance that there's insecure ignition information out there.", "a good rule of thumb w/ terraform is to only use ternary expressions when all inputs and outputs are primitives. we learned this the hard way in earlier versions of terraform, for all I know this could be perfectly fine with more current versions."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3179", "comments": ["some retry logic here would be nice.", "Increased the timeout to 10m, the command has it's own retry logic I think", "I thought the static pod was under bootkube control now so we don't need this", "this seems to be unused inside /resources/manifests", "this seems to be unused inside /resources/manifests", "why are we moving back this out of bootkube control? ", "couldn't we run this a static bootstrap pod, so it would get removed once etcd comes up and so the cluster gets state, so when bootkube flips to the long term control plane it removes all static pods? same that we are doing for tnc-bootstrap pod", "We were originally doing this, but unfortunately we can't do that.\r\nThis is because signer sits on the same port as the api server, so no api server will ever come up unless the signer is taken down. And to make it worse if the signer runs as a static pod, it's not possible to tell kubelet to delete it by removing the on-disk manifest when api server is not available.\r\n"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3174", "comments": ["The creation of ` resource \"random_string\" \"kubelet_bootstrap_token_id\"` and `resource \"random_string\" \"kubelet_bootstrap_token_secret\"` at the top of this file can be removed now", "nit: missing EOF new line here", "does this actually ever get used as sever_auth?", "do we need exec perms here? shouldn't it be 0644 or even 0440, not sure we need it to be writable for some use case but pretty sure we can remove the exec perms", "This requires to update the golang unit tests for config-generator", "If I'm understanding correctly this is the kubeconfig that the TNC static pod will read from disk and serve, how is it being restricted to only CSR?\r\nSince this not using bootstrap token anymore, how are we ensuring this is bound to a \"Role-Based Access Control (RBAC) policy which limits requests strictly to client requests related to certificate provisioning\"", ":+1: ", ":+1: ", "no actually, fixed :+1: ", "changed to 0644 :+1: ", ":+1: ", "@abhinavdahiya @yifan-gu could you help me to understand this? I see the long running TNC serves the SA token which make sense https://github.com/coreos-inc/tectonic-operators/pull/328/files#diff-5e6686fc064b3b88c5ff3ca4bfbfec84R514 but how is this one restricted", "See discussion https://github.com/coreos/tectonic-installer/pull/3179#issuecomment-382304954", "@enxebre \r\nkubeconfig for bootstrap node: (`kubeconfig-kubelet` file)\r\n- this kubeconfig uses a short lived certificate, valid only for 1 hr only,\r\n- has admin priviledges\r\n- hence kubelet on bootstrap node is forced to rotates its certificate eventually.\r\n\r\nkubeconfig for other nodes: (served by TNC)\r\n- this kubeconfig uses a service account token `node-bootstrapper-token` for authn\r\nhttps://github.com/coreos-inc/tectonic-operators/blob/master/operator/kube-core/spec/manifests/node-bootstrapper-sa.yaml\r\nhttps://github.com/coreos-inc/tectonic-operators/blob/master/operator/kube-core/spec/manifests/node-bootstrapper-token.yaml\r\n- restricted to only to CertificateSigningRequest endpoint. \r\nhttps://github.com/coreos-inc/tectonic-operators/blob/master/operator/kube-core/spec/manifests/csr-bootstrap-role-binding.yaml"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3170", "comments": ["is this needed here?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3164", "comments": ["would be very nice to add a unit for this ", "ayayay this pattern is a lil bonkers. not this PR but something we need to clean up", "Yes.", "would you mind making the `E` lowercase? by convention we typically do not capitalize error messages so they can be wrapped. Also, there is an extra space character between `templates` and `:`", "we could also pass m.clusterDir, m.Platform here to runDestroyStep to make the dependencies explicit and less loose", "ugh FINE but only if you eat more fruit."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3162", "comments": ["Description seems incomplete here", "why is generateClusterConfigMaps part of the TLS workflow? I'd say Kube assets should belong to NewInstallAssetsWorkflow", "We could create locals with ignition_file_id_list within ignition-tls.tf and consume then here keeping the ignition_file_id_list pattern for the sake of easier readibility and better code organization", "this data seems to be not used anywhere ", "Because \"template_file\" \"etcd_hostname_list\" is not used this can be removed as well\r\n\r\n", "shouldn't this be local.oidc_ca_cert?", "Personally I'd be in favour of removing this output file and rely on the files dropped to disk by the tls module inside `generated/tls`, then the consumers i.e steps/assets can just assume the paths and data source the files, this would remove the coupling and would make transparent for the consumers the way that tls certs are generated, so making easier an eventual migration from tf to a different tool to generate the tls certs", "duplicated \"value\"", "The Id block isn't needed now that we're using ignition for asset provisioning (sorry, I should have removed it!)"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3161", "comments": ["Why do any of these values need to be templated at all?", "It seems to me this & the S3 location are the only things that need to be templated in from Go. No?", "Add a comment to this exported type or keep it internal", "Yeah, you're totally right. I was going to open a discussion as part of the follow up for cleaning up input variables in case we still wanna allow an easy way for the user to override this images, e.g offline. I'll just remove the templating and hardcode the values for now "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3157", "comments": ["Is there anything stopping us from rendering this from golang with  c.tncoConfig() (or similar) so we completely remove boilerplate here?\r\nThen we could also remove all tf related code e.g ```data \"template_file\" \"tnco_config\"```", "Just to clarify the casuistic here. This means tectonic-node-controller-pod.yaml will be owned by bootkube so it will be removed as part of the teardown as soon as bk deploys the required pods (i.e bootstrap cp with checkpointer). Then, there won't be TNC available until the TNCO gets deployed and it does its job.", "Yes, but since the operator is also deployed by the bootkube, so the time window should be small. Do you think this is a potential problem?", "Yes, I'd like to remove it, but not sure where to add the code for generating those on-disk configfile, same for the kco-config.", "OK, added the code to generate kco-config and tnco-config using go code.", "I think is ok. Ignition consumers of the TNC will retry until it's reachable so it should be fine. We can discuss about having a golang entity to handle the switch over if we need it in upcoming sprints ( INST-1019 )", "this is orthogonal for this PR, but just as a reminder for us, we should probably abstract this logic away into a config-generator packet func and just call it from here", "this is orthogonal for this PR, but just as a reminder for us, we should encapsulate this `cidrhost(c.Cluster.Networking.ServiceCIDR, 10)` into its own function ", "agree"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3147", "comments": ["I think we should drop the final colon from the title"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3142", "comments": ["platforms folder does not exist anymore", "why is this commented out?", "terraform_fmt currently relies on this output so would need to be updated", "It's mentioned in the comment above. It's because we need a change from https://github.com/bazelbuild/rules_go/pull/1393 which is not yet released. Once a release is cut, we can revert back to http_archive retrieval. That's why I kept it commented.", "Cool. I'm going to remove it here too. Thanks!", "ok, I'll put it back then \ud83d\udc4d ", "we can remove platforms", "missing line", "Fixed it.", "> Once a release is cut, we can revert back to http_archive retrieval.\r\n\r\nI've filed openshift/installer#28 with a stab at this."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3140", "comments": ["also for subnet_ids: why use a local var and not just use the direct module output? IE `module.vpc.aws_lbs`", "same as aws_lbs: why not use `module.vpc.master_subnet_ids`?", "same as aws_lbs", "the name of the output is confusing, since we have both `module.vpc.aws_lbs` (which is normally referred to as `aws_lbs`) and `module.masters.aws_lbs` which is usually referred to as `aws_lbs_masters`.", "`module.vpc.aws_lbs` along with all vpc infra related topology lives in a different step - topology - then the input for the bootstrap step is consumed from the topology state and encapsulated as locals https://github.com/coreos/tectonic-installer/pull/3140/files#diff-236e14b6eaceb7ab872e1d017635b8f3R10", "`module.vpc.master_subnet_ids` along with all vpc infra related topology lives in a different step - topology - then the input for the bootstrap step is consumed from the topology state and encapsulated as locals https://github.com/coreos/tectonic-installer/pull/3140/files#diff-236e14b6eaceb7ab872e1d017635b8f3R10", "`module.vpc.master_sg_id` along with all vpc infra related topology lives in a different step - topology - then the input for the bootstrap step is consumed from the topology state and encapsulated as locals https://github.com/coreos/tectonic-installer/pull/3140/files#diff-236e14b6eaceb7ab872e1d017635b8f3R10", "the string `\"-var=tectonic_aws_bootstrap=false\"` has actual semantic meaning to this workflow engine. It's value is well-known and required for the step to work in an idempotent fashion. Could we consider making this a const? Or maybe abstract the `TNCDNSStep` into a func that accepts a bool and can generate two different steps based on the parameter value? The latter would be ideal IMO", "Good point. I already tried to abstract it away with `createTNCCNAME` and `createTNCARecord`. How about adding a `destroyTNCDNS` func. And in addition: \r\n```\r\nconst(\r\nbootstrapOn = -var=tectonic_aws_bootstrap=true\r\nbootstrapOff = -var=tectonic_aws_bootstrap=false\r\n)\r\n```\r\nwdyt?", "Yes this sounds fine to me. The alternative to having four distinct steps would be to have two step generators (`func newCreateTNC(bool) step` and `func newDestroyTNC(bool) step`)that accept a bool and create the necessary steps", "Looks like this const is only used inside this package. Can we make it not-exported?", "I'm confused why this single step `destroyBootstrapStep` is crossing the boundary of multiple Terraform `steps` modules. It is hard to reason about why they are distinct steps in Terraform configuration but single steps inside of this Go abstraction. Seems to me like each Terraform module should be its own step inside the workflows for both create and destroy."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3139", "comments": ["Link to branch?", "Is this still required? ", "I thought it is now an option in the config file?", "It is an option in the config. This variable is used in the commands to template the file names", "I\u2019ll simplify and take it out"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3138", "comments": ["But this is not recommended because it would lead to a non-hermetic build which could lead to unpredictable results depending on the environment configured on the build host. Therefore we recommend using the build instructions outlined in the README for consistent reproducible builds."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3133", "comments": ["is there anything doing this terraform specific? should probably be just  `save_logs`?", "as a followup we could probably keep run_tectonic_cli purely as it is but returning the output, and add wrapper function that handles the timeout and call save_logs", "ok, since we are planning to refactor all the code, I dont want to spend to much time now", "this just save the terraform logs", "we use it in the reference above for the terraform logs. But there's nothing intrinsic in the function which makes it terraform specific. It just take a file path and a data stream, and fill the first one with the second one "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3132", "comments": ["should probably rather be named `TECTONIC_INSTALLER_GOVCLOUD_ROLE` wdyt?", "doesn't the value need to be 'tf-tectonic-installer-govcloud'?", "the role name in the govcloud accout is called `tf-tectonic-installer` :) \r\n\r\nI will update the first comment thanks!"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3131", "comments": ["Does this struct actually need to be exported?", "Does this func actually need to  be exported?", "do we actually need `executionPath`, it seems to me that is just adding complexity while not supporting any practical use case. Couldn't we just error if no cluster dir is provided and remove executionPath field from the struct?", "This doesn't seem to be used anywhere. Also would it need to be exported?", "we might move the binary names to constants", "I think we should either use `log.error` or `fmt.Errorf` here. @squat might knows better", "small hint: this should probably go at the top of the func before creating the cmd struct", "`out` sounds a bit confusing to me, I'd rather use `bin` or `path`, wdyt?", "no need to export this variable", "this is no used anywhere", "you can just:\r\n`return cmd.Run()` here and avoid the `if err` verbosity"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3128", "comments": ["I think you probably need `bazel-src` as well.", "I don't get that directory locally, but we can add it if other people do. JW, your working directory for the installer isn't named `src` is it? Because bazel will create a directory called `bazel-<working-dir>` by default."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3120", "comments": ["Should we change these to `(internal)` since users should not touch it?", "What do you think about supplying the full json here rather than a file path? This way the tectonic CLI does not need to write anything to disk, just add the text to the terraform.tfvars.", "extra newline", "Can you add a comment to this exported func?", "extra newline", "why do we generate a pointer to the struct and then de-reference it in the next statement?", "We redefine these exact same consts in https://github.com/coreos/tectonic-installer/pull/3120/files#diff-6db5d266dcce2af01d3bf830d357bc26R16", "It does not look like anyone is using this type? https://github.com/enxebre/tectonic-installer/blob/07fe3dab9cc74f8184bb23b821063c8f75eaacda/installer/pkg/config/cluster.go#L36", "what do you mean by wrong? Invalid maybe?", "extra newline", "there is no need for the `if` here. Just always `return err`. This way, if the error is nil, then you are returning nil and if the error is not nil then you are returning an error", "extra newline", "Technically make sense, from a user perspective I like the file input ", "We should probably in-line the this struct for readability", "We should really wrap error so for improved context when debugging", "This error seems to be completely ignored", "Could you document these exported values?", "Can you please ignore yaml in this and the below lines."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3116", "comments": ["will need to change the pattern https://github.com/coreos/tectonic-installer/blob/master/steps/bootstrap/tnc-s3.tf#L16 and https://github.com/coreos/tectonic-installer/blob/master/steps/bootstrap/s3-assets.tf#L4", "Can't find tectonic_dns_name in the config file", "It's in the AWS-specific variables.tf files: https://github.com/coreos/tectonic-installer/blob/master/platforms/govcloud/variables.tf#L182"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3115", "comments": ["Does this need to be added to every sub-package, or could it be a top level definition?", "You could use our custom `gen_test` here, instead of generating a shell script via a `genrule`. `gen_test` is in no way perfect, but might be a bit less verbose.", "`large` is a bit exaggerated, resulting in: `There were tests whose specified size is too big. Use the --test_verbose_timeout_warnings command line option to see which ones these are.`. Would you mind adjusting it to a more reasonable level? (See Bazel level docs: https://docs.bazel.build/versions/master/test-encyclopedia.html#role-of-the-test-runner)", "Can we add the validate package? it is newly created to be used in the CLi for valdation: https://github.com/coreos/tectonic-installer/tree/master/installer/pkg/validate", "can we remove the `cli_` prefix from these tests? I think it is clear enough with `bazel test installer:gometalinter` or even just `bazel test installer:lint`", "Afaik it's needed. I can't find a way to filegroup crossing target boundaries, but my knowledge here is limited, would love to hear any ideas.", "I worry that this is not flexible enough. Next time somebody adds a new package that has broken linting but forgets to add it here we will never know. We should use `go list` to grab all the packages.", "Yeah, I don't really like it much either...\r\nA new package would need to add the filegroup\r\n`\r\nfilegroup(\r\n    name = \"go_files\",\r\n    visibility = [\"//visibility:public\"],\r\n    srcs = glob([\r\n        \"*.go\",\r\n    ]),\r\n)\r\n`\r\nAnd then it has to be referenced here.\r\nHowever I couldn't find nicer way to collect all the go files crossing target boundaries with Bazel.\r\nFor using something like go lint, wouldn't the packages need to be made available for it during bazel run time? so wouldn't it still require manual static reference of the packages?\r\nI can't see a way in bazel to \"collect all the files\" without adding static targets"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3113", "comments": ["> `-u 0`\r\n\r\nDoes this has to be run as root?", "huh.. I thought it was failing without running as root, but now I'm testing again and I am finding it's fine. I'll make the change. Thanks for bringing it up", "No need to _replace_ the current instructions. I just meant to add running with Docker as _another_ option.", "PTAL again"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3108", "comments": ["Hey @abhinavdahiya You'll need to change the actual templates kubeconfig/kubeconfig-kubelet as well to use that value `root_ca_cert`.\r\nCerts questions, shouldn't the kube_ca_cert be enough here and be used by both kubeconfig anyways?", "@enxebre \r\n> You'll need to change the actual templates kubeconfig/kubeconfig-kubelet as well to use that value root_ca_cert.\r\n\r\nFixed it.\r\n\r\n> shouldn't the kube_ca_cert be enough here and be used by both kubeconfig anyways\r\n\r\nkubelet should trust the root CA, so in case the kube CA needs to be rotated, we don't have to update the kubelets on all the nodes.", "The same change needed to be added to all the self generated certs (not CAs) - IE, identity, etcd, kube. you can see the list of of files and the changes in #3031 ", ":+1: Oh i didn't realize that. will do that.", "@trawler #3031 was closed in favor of #3050 and #3050 only updates the CAs with organisation and organizational_unit. ??", "doh! sorry, you're right... got these two PRs confused. you're correct.", "so, since only root_ca is the self-signed cert and kube_ca, aggregator_ca and etcd_ca are signed by root_ca, is adding uuid() to root_ca sufficient or should i add uuid() to all of them?", "You can test this by verifying that the cluster always generates tls certs with a different hash: `openssl x509 -in cert.crt -hash -noout`", "Added uuid to all CAs"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3106", "comments": ["This variable declaration does not match its use in the module; it is missing the `cl_` prefix"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3092", "comments": ["nit: can we remove the word `padding` and leave as just `\"\"` as in https://www.terraform.io/upgrade-guides/0-11.html#error-checking-for-output-values\r\n\r\notherwise, we can change this for \r\n```hcl\r\nvpc_id = \"${local.external_vpc_mode ? var.external_vpc_id : join(\"\", aws_vpc.new_vpc.*.id)}\"\r\n```", "I am a little surprised this is not accounted for in terraform fmt. can we remove these extra whitespaces?", "and here as well", "fixed"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3090", "comments": ["This doesn't seem right. The kubeconfig should be dynamically generated by TNC. This PR doesn't change the interaction though, but I think this should be removed eventually.", "thanks! I agree. It's unrelated to this PR. That would need to go hand in hand with the bootstrap token generation. Is there a place where we track what the TNC should do, and what it actually currently does?", "Rather than make this a file that is always in the repo, shouldn't this be a top level input that users can provide optionally? this would allow us to perform validation in the CLI as well rather than just appending whatever is given.", "And here we would do something like \r\n```hcl\r\n\"${var.tectonic_user_ignition_master}\"\r\n```", "and we would not need to template anything here.", "Even if we do not go with the top level config option, this should be \r\n```hcl\r\ndata \"local_file\" \"foo\" {\r\n    filename = \"${path.module}/foo.bar\"\r\n}\r\n```\r\nrather than `template_file`\r\nhttps://www.terraform.io/docs/providers/local/d/file.html"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3089", "comments": ["The issue is that this code expects a file that is named differently than the defaults that are downloaded from quay and account.tectonic.com. Why not look for tectonic-license.txt and config.json? Oytherwise, who would know to name the files that way?", "Actually, `license.txt` and `pull_secret.json` match the filenames we used in `assets.zip`.", "but assets.zip is only generated _after_ the installer has already run and the files were already not in the right place"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3088", "comments": ["our imports were ordered incorrectly in several places", "some type names did not follow casing conventions", "Errors should not start with a capital letter to enable better legibility when wrapping", "typo semantically?", "curious if you considered:\r\n```yaml\r\nnodePools:\r\n  foo:\r\n   - count: 3\r\n  bar:\r\n   - count: 1\r\n```\r\nand then unmarshal directly into a map", "Yes definitely considered. I decided against it because it does not follow the patterns in kubernetes manifests. This is more familiar. Plus, writing yaml is hard enough, and if arbitrary keys are allowed, it is harder to read IMO. last, modelling as map keys obfuscates the fact that any value is allowed for the name, not just certain \u201cspecial\u201d keys", "Thanks good catch", "Do I understand correctly, that in the future, you could have multiple different node pools as `workers`? If so, wouldn't it make more sense to have an array here?\r\nE.g.:\r\n```yaml\r\nworkers:\r\n  nodePools:\r\n  - high-memory-beasts\r\n  - tiny-cpu-boxes\r\n```", "Just as a train of thought on my end: Instead of a reference to a node pool via a string, a real golang reference would be nice and more consistent. The benefit of easier and more idiomatic access needs to be compared to the overhead while unmarshaling.", "Don't you mean: `// ErrMissingNodePool implements the error interface.`?", "See same occurrence further below.", "How about a for loop here, to dry out the code a bit:\r\n\r\n```go\r\n\tpools := []string{c.Master.NodePool, c.Worker.NodePool, c.Etcd.NodePool}\r\n\r\n\tfor _, pool := range pools {\r\n\r\n\t}\r\n```", "How about a for loop here to dry out the code a bit:\r\n\r\n```go\r\n\tpools := []string{c.Master.NodePool, c.Worker.NodePool, c.Etcd.NodePool}\r\n\r\n\tfor _, pool := range pools {\r\n\r\n\t}\r\n```", "Do I understand correctly, that NodePools should never be shared? If so, I would rename this function to `validateNoSharedNodePool`.", "Why use a map with empty structs here, instead of a slice of strings?", "Just a small nit: In the Prometheus project and as well with `https://github.com/pkg/errors`, the convention is to chain errors with colons and not commas. What do you think? ", " Is there a way of only using a subset of the error levels, or do we have to buy in on all the levels of sirupsen/logrus?", "I guess we should switch to `ETCD` as well, right?", "yeah we can do, but note that it needs to be an array of structs so that we can have a `NodePool` field, and also a string name for the error if the `NodePool` field is empty", "Imagine if all of your nodepools have the same name, then if you look for dupes you would get a list that says: `[\"master\", \"worker\", \"master\", etcd\", \"worker\", \"etcd\"]`. Using a map is an easy way to de-dupe this.", "I agree, this is our convention everywher; this is carried over from before, as you can see. The change here was intended to fix the formatting of the error to not contain the extra prefix, but the mistake at the end slipped. thanks for catching", "Yes, we can force users to choose a subset by eliminating choices from the enum, but I don't see too much value in that at the moment. these verbosity choices are very common, IMO. In fact, Terraform also has many verbosity choices.", "yeah I agree. I'll implement this and for the moment force the list to be length 1", "no, `etcd` is not an acronym", "Hmm do you mean you expect users to provide a complete nodepool struct here as well as in masters as well as in workers? Or you want to automagically link the fields while unmarshaling?", "sounds good :+1: ", "Automagic! \r\n\r\nBut I guess implementing the custom unmarshaller and making sure, node pools are parsed before the master configuration ... is pretty over-engineered.", "thank you!", "yeah I think it's a little too magic. If we look at kubernetes types that reference other structs by name, they are also implemented as `name string` rather than with magic", "good suggestion! it also cuts down on some length :)", "ayy yeah thanks again for catching! I realize that I also let slip another format string mistake: we used `%s` instead of the conventional `%v`", "left over comment?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3086", "comments": ["Can you adjust the description to match the style of the destroy command? E.g.: \"Convert a tfvars.json to a Tectonic config.yaml\"", "Why are we modeling each of these fields as its own package? This seems like a lot of overhead to me. Some of these fields have identically named sub-fields that need to marshal to different names, but we can just name these types differently, e.g. RootVolumeMaster, RootVolumeEtcd, etcd", "The idea behind that was that the workflows can still access the structs the same way they're references in the config yml. We used to do that two weeks ago, but I can't see anything anymore that does that. I'll rename it.", "can we add a unit for NewConvertWorkflow?", "Sure", "Please remove this line. Tectonic installer currently fails to bootstrap a cluster when cluster_name and dns_name differ. The test framework creates a random cluster name. I will report this issue as a separate one.", "We should really use proper Godoc-style comments for all exported types. Otherwise, linting will be very sad :crying_cat_face: ", "Is this a leftover debug line?", "No actually thats the thing that prints the reversed config to your terminal.", "Whats the benefit of traversing via `dig`?", "To address Lucas confusion, you could rename this function to `printYAMLConfigStep`.", "If admin is not set for example it doesn't explode.\r\nnil doesn't have [].", "cool :+1: "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3085", "comments": ["this is to distinguish between ipv4 and ipv6, ya?", "yes", "this depends implicitly on the split slice having at least two elements. we know that this should be the case since we have validated the cidr already.\r\n\r\nInstead of splitting and parsing the string, I think it would be better to:\r\n```go\r\n_, c, err := net.ParseCIDR(v)\r\nif err != nil {\r\n    return errors.New(\"not a valid CIDR\")\r\n}\r\nif _, mask = c.Mask.Size(); mask < 16 || mask > 28 {\r\n    ...\r\n}\r\n```", "we normally just say IPv4", "here you could consider composing with IntRange", "should not be an exported type", "extra newline here", "\ud83d\udc4d ", "\ud83d\udc4d ", "\ud83d\udc4d ", "\ud83d\udc4d ", "\ud83d\udc4d "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3079", "comments": ["Ignition does not continuously retry to download forever, so I think this introduces a race. What if one of the etcd machines gets provisioned and tries to load it\u2019s ignition before the TNC is up?\r\n\r\nI think this should go after the waitForTNC step.", "yes there's a race which is currently only relying on retries. The problem here is that there's no obvious way for etcd to waitForTNC (when this is running as static pod) as the kubeclient won't be able to get answers until the server gets the state", "By having it here we ensure that the step holds until etcd comes up (so the api server actually gives a response and waitForTNC finish when the TNC daemonset gets deployed)", "I second @squat's concern about the race condition. If we know there could be one, we should try to find a solution.\r\nI don't have enough insight into the matter right now to suggest one here, but let me know if you need my help looking into it.", "@alexsomesan @squat this relies on ignition retries https://github.com/coreos/ignition/blob/master/internal/resource/http.go#L200 which will keep retrying until it times out, and if I'm not wrong by the look of `httpTotal` here https://coreos.com/ignition/docs/latest/configuration-v2_1.html it will keep retrying for ever by default https://github.com/coreos/ignition/blob/master/internal/resource/http.go#L69", "@alexsomesan @squat it's verified that Ignition will never continue if it isn't completely successful.\r\n`waitForTNC(m)` where it is now, will ensure that the step holds until etcd comes up (so the cluster get state, so the TNC daemonset gets deployed and so the api server actually gives a response, so waitForTNC can finish)\r\nThis is not strictly necessary as the every node will be able to get its config from the TNC pod, so the question is: do we still want to `waitForTNC(m)`? wdyt? ", "quay.io/coreos/tectonic-node-controller-bootstrap-dev:f6d5e710a97a8cd6f4cd2963f4426131f854a869", ":p it\u2019s a little funny doing both interpolation and formatting but not a blocker", "Just like instance_count, this could be just `ignition` since we are in the etcd step and know that everything is etcd-related", "Also for sanity we should standardize the output names to either be `prefix_value` or `value_suffix` but not both. That can be a separate cleanup pr"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3077", "comments": ["This static pod is not managed by the channel operator", "A static pod does not need a node selector; it is manually scheduled", "Are you sure the toleration is required? I suspect this is not needed for static pods", "Extra newline", "I think this is a little abusive of the rm-assets script, which is only concerned with removing assets from object storage. Until we create the cleanup service, I think this would be a better fit for the end of the tectonic service, which is responsible for launching all tectonic components. This way the removal of the static pod is more directly coupled with the creation of the operators"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3076", "comments": ["If I understand correctly, this is using the param via environment variable, and leveraging bash's quotes to escape it. This is a pretty clever and elegant solution, albeit a bit subtle to the untrained eye. "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3067", "comments": ["Why eliminate this block?", "These FAQs are actually repeated in other sections of the doc.", "we can remove Nodejs as well , can't we?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3064", "comments": ["It seems that if the new workflow is used, then this check for the old workflow will fail and the script will prematurely exit on the next line, so the new workflow's files won't be uploaded. Is that correct? The script should only exit if files from neither location were found.", "If the new workflow is used but the old one is not, then wouldn't this check fail to find any old workflow build logs and then exit, so the new workflow files would not be uploaded? It seems to me that the script should only exit if no files are found from either old/new workflows."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3061", "comments": ["Nit: To be defensive about poorly-formatted user input, I suggest .trim()ing the params.SPECIFIC_GIT_COMMIT before using it in this and subsequent lines. (i.e. `params.SPECIFIC_GIT_COMMIT = params.SPECIFIC_GIT_COMMIT.trim()`)", "Nit: I would simply say \"This supports users who require builds at a specific git ref instead of the branch tip.\" I'll add more info in the RA pipeline.", "Nit: \"Checkout a specific git ref **(e.g. sha or tag)**. If not set, ...\"", "If it doesn't exist, can Jenkins add a \"build_metadata.txt\" file to the artifact that contains the following?\r\n```\r\n- Git repo: github.com/${params.GITHUB_REPO}\r\n- Git SHA: ${originalCommitId}\r\n[If built from branch tip] - Branch: ${BRANCH_NAME}\r\n[otherwise] - Git ref: ${params.SPECIFIC_GIT_COMMIT}\r\n```\r\n\r\nI think this would be useful when determining the provenance of an artifact bundle. E.g. when the RA pipeline pulls the bundle, it can check that the artifact's build SHA is the SHA it asked for.\r\n\r\n\r\n", "It's possible for a user to enter a tag, and unfortunately the SHA that a tag points to is mutable. So I would prefer if originaCommitId was actually the SHA. i.e.\r\n`originalCommitId = sh(returnStdout: true, script: \"git rev-parse ${params.SPECIFIC_GIT_COMMIT}\").trim()`\r\n\r\nHowever the above code is not ideal because it uses unparsed user input directly in a shell command. I'd much prefer it if it was escaped, but that apparently is not easily done. A workaround is described a the bottom of this issue: https://issues.jenkins-ci.org/browse/JENKINS-44231, so perhaps something like:\r\n\r\n```\r\ndef shellEscape(s) {\r\n    '\\'' + s.replace('\\'', '\\'\\\\\\'\\'') + '\\''\r\n}\r\noriginalCommitId = sh(returnStdout: true, script: \"git rev-parse \" + shellEscape(params.SPECIFIC_GIT_COMMIT)).trim()\r\n```", "I guess embedding the commit sha could be a general feature of our Bazel build process. I will suggest it in the installer team.", "I will follow up on this with https://github.com/coreos/tectonic-installer/pull/3069\r\n\r\nGood point.", ":+1: ", ":+1: ", "Tag to sha conversion is a great idea. I have added that.\r\n\r\nI think untrusted user input validation and escaping should be considered as a general improvement to the pipeline, not particularly scoped to this PR. If you don't mind I will create a follow up task for this. ", "@mxinden We'll agree to disagree there; My feeling is that style + security concerns are fundamentally part of any PR, unless they overwhelm its original purpose. Leaving security concerns as techdebt doesn't guarantee they'll ever be addressed. However I think the risk is fairly low in this case so I won't press the point.", "Fair point. See the direct follow up PR here: https://github.com/coreos/tectonic-installer/pull/3076"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3055", "comments": ["You should not be labeling the case yourself here. The failure message appears contextually beside the name of the test.  Normally you only label the case when you are looping over a slice of several units for a single test point so.", "Both of these errors are the same. Maybe you can specify what you are loading: \u201cfailed to load tfvars\u201d", "Extra newline here", "Conventionally we use \u201c.\u201d", "Is this name too generic that the will collide with something in the actual package in the future?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3054", "comments": ["why not `configGenerator` ?", "I think the internal file should not be YAML. YAML is intended to be human readable-writable, but this is internal-only, right? No humans should be touching this ever, so I think we should serialize to some other format, e.g. JSON", "I would add this as a `defer` to the top, just to prevent future issues were someone adds a `t.Fatal()` before. Not very important though.", "Small thing: We have been writing `Tectonic` instead of `tectonic` in previous descriptions in this file.", "JSON sounds good. Argument for YAML would be, that we can add a comment at the top like `Do not touch, auto-generated`.", "hmm yes that's a good point. the question would be: what discourages modification more?", "Can you make that:\r\n\r\n```golang\r\n  Internal `json:\",inline\" yaml:\"internal,omitempty\"`\r\n```\r\n\r\nI changed that in another PR which is not merged yet and this simplifies mine.\r\n\r\nHighly appreciated \ud83d\ude03 ", "Same here:\r\n\r\n```golang\r\ntype Internal struct {\r\n```", "And here:\r\n\r\n```golang\r\n  ClusterID string `json:\"tectonic_cluster_id,omitempty\" yaml:\"clusterId\"`\r\n```", "that's how the package is called in generator.go What's the golang convention here? cc @spangenberg ", "That's a good point, however while I can't see any drawbacks from using yaml here, I can see the benefits of sharing and reusing the approach", "@enxebre Go imports should be [all lower case](https://blog.golang.org/package-names).", "> Package names\r\n> \r\n> Good package names are short and clear. They are lower case, with no under_scores or mixedCaps. They are often simple nouns, such as:\r\n> \r\n>   -  time (provides functionality for measuring and displaying time)\r\n>   -  list (implements a doubly linked list)\r\n>   -  http (provides HTTP client and server implementations)\r\n> \r\n> The style of names typical of another language might not be idiomatic in a Go program. Here are two examples of names that might be good style in other languages but do not fit well in Go:\r\n> \r\n>   - computeServiceClient\r\n>   - priority_queue\r\n> \r\n> A Go package may export several types and functions. For example, a compute package could export a Client type with methods for using the service as well as functions for partitioning a compute task across several clients.\r\n> \r\n> Abbreviate judiciously. Package names may be abbreviated when the abbreviation is familiar to the programmer. Widely-used packages often have compressed names:\r\n> \r\n>   - strconv (string conversion)\r\n>   - syscall (system call)\r\n>   - fmt (formatted I/O)\r\n> \r\n> On the other hand, if abbreviating a package name makes it ambiguous or unclear, don't do it.\r\n> \r\n> Don't steal good names from the user. Avoid giving a package a name that is commonly used in client code. For example, the buffered I/O package is called bufio, not buf, since buf is a good variable name for a buffer. \r\n", "@mxinden @squat added the \"Do not touch, auto-generated\" message but happy to discuss more about this and concerns about state", "As this should never appear in the yaml config, how about adding `json:\"-\"` and `yaml:\"-\"` here? Just in case we ever read and write a config yaml in the future.", "can you omitempty clusterID\r\nOtherwise this will make converting from tfvars weird.", "I put back `json:\",inline\" as is needed by the tf vars generation"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3053", "comments": ["@enxebre where can I mount the CA assets from?", "ca certs are dropped into https://github.com/coreos/tectonic-installer/blob/master/modules/ignition/ca_certs.tf#L19\r\nOther kube certs a temporary dropped into /opt/tectonic/tls\r\nThis probably relates to https://github.com/coreos/tectonic-installer/pull/2972/files", "can't download this image with my tectonic license", "The docker image seems to be created from a branch which does not support rest like, but querystrings https://github.com/thorfour/tectonic-operators/blob/templates/controller/node/pkg/ignition/server.go#L81", "The docker image seems to be created from a branch which does not support rest like, but querystrings https://github.com/thorfour/tectonic-operators/blob/templates/controller/node/pkg/ignition/server.go#L81", "`cluster-config.yaml` is now generated at runtime by the cli, so this template is ignored, there's already a PR to delete it.\r\nTo get this config through the cluster-config will need to modify\r\nhttps://github.com/coreos/tectonic-installer/blob/master/installer/pkg/config-generator/generator.go#L66\r\nand\r\nhttps://github.com/coreos/tectonic-config\r\n", "this lives in tectonic-system but the config in kube-system so it's not accessible for the pod", "this does not like to the current image, docker inspect shows:\r\n```\r\n           \"Entrypoint\": [\r\n                \"/app/controller/node/cmd/bootstrap/bootstrap\"\r\n            ],\r\n```\r\nSo command should be removed and need to add args:\r\n```\r\n        args:\r\n        - --config=/etc/cluster-config/tnc-config\r\n        - --port=45900\r\n        - --cert=/opt/tectonic/tls/ca.crt\r\n        - --key=/opt/tectonic/tls/ca.key\r\n```", "Also I tried to modify and `bazel build //controller/node/cmd/bootstrap` but got `running external/local_config_cc/cc_wrapper.sh failed: exit status 1\r\nld: library not found for -lcrt0.o`", "that's weird since I added your user to have read access on quay", "Yea the image was old. I pushed a new dev image that uses the rest path", "Fixed in image: cb561ffb2b7c747a037231fab07a64fe6ebc7322", "this is setting master label for both master and workers", "wouldn't it be to have \"ExecStartPre=\" as part of the go template a bit less error prone?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3052", "comments": ["Really we should bump this to something that is more appropriate for the master branch. As of right now we're using Kubernetes 1.9.3, so perhaps `1.9.3-tectonic.1`?", "Done", "the version of `hyperkube` is `v1.9.1_coreos.0` does that means we are using 1.9.1 instead of 1.9.3 or am I missing something? this is always confusing to me", "@coverprice  @diegs  \u2b06\ufe0f ", "Waiting for @diegs or someone else to weigh in on the comment above before this gets merged.", "The hyperkube in the installer currently only affects the kubelets IIUC. Once the TNC is merged that will no longer be true. We should update that one to 1.9.3 as well though to match what's used by the control plane, as installed by the kube-core operator."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3049", "comments": ["Why not use a splat so that this does not have to be updated in the future when more fixtures are added? It\u2019s also fewer LOC. Also, no one else depends on these fixtures, so do we really need a file group or can we just put a the expression `glob([\u201cfixtures/**\u201d])` in the `data` field of the test rule", "@cpanato @squat @enxebre Do we have any tests that we don't want to run on Jenkins? If not, we could replace the `bazel test xxx` lines by `bazel test ...`. What do you think?", "There are tests that we do not want to run together e.g. GUI tests. We only want to run those some times. It would be better to tag the different tests and then run `bazel test` to either ignore those suites or run all PRs in a particular group, e.g. `unit`", "Thanks a lot! still getting familiar with bazel semantics", "Mm I like how this shows as individual drop-downs on blue ocean. Also don't have strong knowledge   but bazel test ... might run undesirable tests e.g in go vendors?", "the one thing I wonder is if this is the correct place for this test suite. shouldn't it go in installer? or installer/pkg?", "make sense, moved to installer package"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3046", "comments": ["seems to be wrongly indented.", "go fmt", "go fmt", "Seems to be only in my browser, not in `raw` mode."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3045", "comments": ["Would you mind adding a comment with parts of your PR description for the future us?", "The description is already in the commit message. Would you like to see it in the code as well?", "@squat I would have done so, but I don't know what your convention is here. This is not a strong opinion. Go ahead with whatever suits best.", "OK @mxinden I just added some comments. PTAL and leave a review", "would may be lookup help here?\r\n https://www.terraform.io/docs/configuration/interpolation.html#lookup-map-key-default-", "this does not help because the splat gives us a list of maps and we first of all need to use a trick to allow evaluation of the 0th element of the list. This breaks because join and element do not work of lists of maps. Using lookup directly does not work in the case that count = 0"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3043", "comments": ["need to be:\r\n`\r\ndata['Clusters'][0]['Master']['Count']\r\n`\r\n`\r\ndata['Clusters'][0]['Worker']['Count']\r\n`"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3040", "comments": ["To test different regions and to not hit capacity limits we are randomly selecting the region (see [aws-region.rb](https://github.com/coreos/tectonic-installer/blob/master/tests/rspec/lib/aws_region.rb#L6)).\r\n\r\nFor local development, it skips the random selection whenever `TF_VAR_tectonic_aws_region` is defined. With this change, it would always be skipped.\r\n\r\nWhats the use case for you to set the region? Which AWS account are you running on? Do you have enough capacity to run in a single region?", "`TF_VAR_base_domain` defaults to `tectonic-ci.de` by [default anyways](https://github.com/coreos/tectonic-installer/blob/master/contrib/internal-cluster/vars.tf#L10), in addition the Jenkins default is also set to `tectonic-ci.de` by you. I guess you can just remove this mention entirely here, right?", "See comment above.", "Our team engineering services AWS account only has adequate limits in a single region. I see what you're saying though- with this patch the region environment variable will always be set. \r\n\r\nPerhaps we could change this boolean expression to:\r\n```ruby\r\nreturn if ENV.key?('TF_VAR_tectonic_aws_region') && ENV['TF_VAR_tectonic_aws_region'] != \"\"\r\n```\r\n\r\n", "You're suggesting we just let the `TF_VAR_base_domain` env var propagate through and not explicitly deal with setting in the Rspec framework?", "same question as above", "Yes. Do you have any concerns in that regard?", "Sure, this would be a valid fix for me. @cpanato what do you think?", "Nope, sounds reasonable. Just wanted to clarify on my end", "Actually- @mxinden I just remembered why it is this way. The case I had in mind is if you want to specify a different base domain for **only** the AWS tests. Unless we do it this way (or, perhaps more preferably, split up the platforms into different stages so we can set environment variables on a per-stage/per-platform basis.). Let me know what you think", "In the case of our separate development environment- we want to do exactly this. Change the base domain on a per-platform basis- which given the current setup and defaulting pattern is quite difficult.", "sounds good"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3036", "comments": ["curious why are we initialising to nil", "because if we don't use that, it will pass nil to the functions that call aws", "then we can support both cases: with roles and without role"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3031", "comments": ["should be `organizational_unit`", "can we add `organizational_unit = \"identity\"`", "can we add `organizational_unit = \"ingress\"`", "can this be lowercase to match the other certs?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3030", "comments": ["is it delete now, or still destroy?", "Thanks. Fixed.", "Is this correct? Install takes a `\u2014dir` flag but destroy does not? If so, this is pretty weird UX and warrants a change in the CLI. Surely both the flag and the cluster name argument serve the same purpose and can fulfill the same needs", "This is already tracked [here](https://jira.coreos.com/browse/INST-959) as a follow up.", "thanks for filing that. we really need to polish up the CLI"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3029", "comments": ["both these fields have the same struct tag", "this struct tag should say `yaml`", "will fix", "will fix"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3028", "comments": ["why not untar it for user convenience?", "@sym3tri `docker build` already does that for us: https://docs.docker.com/engine/reference/builder/#add", "Why do we rely on such a large base image? Is there a reason we can't use scratch or even alpine?", "I wanted other teams to easily install whatever tools they need in addition via `apt`. But if you want I am happy to change.", "I think this depends on how other teams leverage this container. If they want to install custom packages, then maybe `alpine` is sufficient since that distro has its own package manager. If they want to install very custom things nicely using a more advanced package manager and larger eco-system then `debian` will be better. If they only need to rely on it as a base image and COPY/ADD in other deps then `scratch` would be fine.\r\n\r\nI see this as a good opportunity to slim down our container, but you are probably in the best position to make that decision since you work more closely with other teams and may have a better idea of how they leverage this container.", "fancy", "+1 for smaller a base image. I don't think we need to try to support every use-case, if so we'd be publishing images based on every linux distro. If other users want to do more customizations they can create their own images & copy the files out. All we really need for now is a place to put the bits.", "@squat Switched to `alpine` so users still have bash to look around. Let's see what the requirements for this are in the future. Long term I would prefer nightly signed releases with just the tarball on e.g. an S3 bucket."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3019", "comments": ["Is this a valid definition for the action creator? Now that all actions have been re-written as action creators rather than helpers, calling `dispatch(configActions.addIn(...,...))` will be dispatching a function rather than an action object with a payload and type. Does dispatch support this?", "Sorry, I should have said in the PR description that as well as standard action creators, some are Redux Thunk action creators.\r\n\r\nFrom https://github.com/gaearon/redux-thunk:\r\n> Redux Thunk middleware allows you to write action creators that return a function instead of an action. The thunk can be used to delay the dispatch of an action, or to dispatch only if a certain condition is met. The inner function receives the store methods dispatch and getState as parameters."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3018", "comments": ["All of the Parameters are in upper case style. Would you mind doing the same here?", "I thought uppercase = for users, and lowercase = system config (i.e. less likely to need modification). But if there's no pattern, I'll be happy to make them consistently uppercase."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3015", "comments": ["shouldn't the TNC be rendered by kube-render as part of /opt/tectonic/bootstrap-manifests/? if not, it should be deployed as a static pod somehow, so eventually etcd can get its config from it, so the cluster can get state and continue with the bootstrap process. i.e this should be converted to a TNC pod https://github.com/coreos/tectonic-installer/blob/ut2-integration/modules/bootkube-ut2/resources/manifests/ncg.yaml", "cc @alexsomesan @squat ", "@enxebre I think that is what @thorfour  is trying to accomplish here. He is manually running TNC on docker so that it can be used to bootstrap etcd.\r\n\r\nAlthough this works, I would prefer to see this run as a static pod as well so that the kubelet can take care of retries. Currently, `kube-core render` and `bootkube start` are one-shot operations with short lifetimes, while TNC is a long running process that does not exit. Also, as a static pod, all of its configuration could be defined as a declarative manifest. Finally, if we make it a static pod then we can avoid overloading this script with operations that are not directly related to bootkube.", "Why do we need this for tectonic?", "this should be bootkube-ut2", "@squat you're mostly correct. However tnc is split into two separate binaries. This is running the bootstrap binary which isn't the long-running tnc, and needs to be torn down along with bootkube. The follow on TNC will be the long-running one that needs to run in-cluster. ", "No idea? I didn't add that", "Right I understand that this is not the TNC deployment that runs indefinitely in the cluster, that would be the TNC deployment/daemonset. Rather, this TNC only exists for bootstrapping purposes. However, I think that it is more beneficial to implement this bootstrap TNC as a static pod rather than as a raw docker container for the reasons listed above.", ":D I meant the \"#ignition bootstrapping variables\" because I thought they were injected into the tectonic module, disregard it", "Got it. Yea static-pod might be the way to go. We just need a story on how to ensure it gets torn down after bootstrapping. I only globbed it onto the bootkube.sh as a path of least resistance in an attempt to get a POC working.", "FWIW original design was to have tnc-boostrap be a systemd unit, and have a follow-on service have a conflict with that so it gets torn down.", "Yeah I see. Ultimately, the bootstrap node is supposed to be recycled, so any static pods will be properly removed and will no longer be run when the node comes back up as a master", "@thorfour @squat while there's no pivoting mechanism in place we could modify this PR to just run it as a long running static pod for now\r\n ", "The problem with that is that this bootstrap containeris actually a different image. So we would have a daemonset running on other nodes exposing one api and a static pod running here exposing a different API so if you happen to get load balanced to the bootstrap node you may not be able to boot", "@thorfour @squat so the goal is to get the bootstrap TNC serving static config running as pod, and a pivot mechanism to tear it down and switch to a long running TNC (different binary) serving \"dynamic\" config from CRD. To get there while there's no such mechanism we need to define a transition path, choices IMO are:\r\n- Swap the current NCG daemonSet by a TNC daemonSet serving static config (etcd nodes can't be bootstrapped from it this way as the daemonset requires state)\r\n- Remove the current NCG and only run the TNC as a static pod (cluster might be unstable as if the node running the pod gets rebooted other nodes will fail to join)\r\n- Run both TNC as a pod and as a DaemonSet simultaneously with the problem stated in the comment above and probably other conflicts "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3014", "comments": ["kubelet will start and this new master will join the existing cluster or support bootkube recovery. ", "maybe put something in the log that says you are calling it a success?", "nit typo: bootsrapped -> bootstrapped"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3013", "comments": ["Hoping for better ideas here", "What is `count` used for here?", "What is the purpose of the changes here?", "https://github.com/coreos/tectonic-installer/pull/3013/files#diff-ab1cdfcf8c59247cffcabbac2f236b96R21\r\nIf the user desired capacity `tectonic_master_count` is 3 masters, as the bootstrap node is not part of the scaling group,  the scaling group expected capacity would be = userinput  - the bootsrapnode"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3011", "comments": ["We removed this in a previews PR as it was overlapping with PodCIDR ", "https://github.com/coreos/tectonic-installer/pull/2994/files#diff-0a70c3d9395f8f34a8fbbb179bf987b8L118", "this might be making units to fail"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3009", "comments": ["This line is intended to be indebted further back to match the `printf` since it is not part of the actual script but rather a piece of the machinery that generates the script", "Same here", "This genrule is identical to the unit test rule except for `s/test/lint`. Can we change it to be just one genrule that accepts another argument for which test to run?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/3001", "comments": ["the docker build needs to ADD the smoke test binary to the container, so the binary needs to be built. Either we use the output from Bazel in the Dockerfile, we re-build the binary using Make, or we build the container entirely using Bazel. I vote for the latter, so we can entirely eliminate this Makefile"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2995", "comments": ["I think you can combine the two test targets into one, like the `bazel build tarball tests/smoke` below, right?", "We can but if we separate them then we can view them as separated steps in blue ocean I think", "@squat Ah, sounds like a good idea. As far as I know, you need to use a separate `sh` step for each one then.", "I will split in separate `sh`", "done"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2986", "comments": ["This is a very clearly repeated pattern and warrants its own little func e.g. `tryDestroy`", "Return here?", "And here?", "typo", "typo", "We should either wrap this bare error or wrap the first error in baselocation, which is also currently bare (ideally both). Otherwise, we will see an error initializing an executable and wonder where it\u2019s coming from", "As a follow up we should create `runDestroyStep` analogous to `runInstallStep` to DRY this logic", "there should be one indeed! :)", "\ud83d\udc4d ", "That's a good point!\r\nWould you rather have a concrete type for each or just more meaningful messages via fmt.Errorf(..)?", "For now wrapping the error via fmt.Errorf is plenty. Unless we needed to do some programmatic error recovery and need the types we can skip creating the error types right now IMO", "Again, this is needed here in particular since we are doing a few levels of error bubbling without wrapping the messages making the source more difficult to identify", "I think this is similar to what @squat suggested above by the tryDestroy method, no?\r\nI'll see what I can do there.", "\ud83d\udc4d ", "\ud83d\udc4d ", "OK, fixed. Log line for such errors now looks like this:\r\n```\r\n2018/02/20 12:50:44 invalid path for '/Users/alex/Desktop/tectonic/steps/assets' templates: stat /Users/alex/Desktop/tectonic/steps/assets: no such file or directory\r\n```", "I implemented `runDestroyStep` like you suggested.", "I implemented a `runDestroyStep` to mach the already present `runInstallStep` (per suggestion from @enxebre).\r\nLooks cleaner now.", "just to clarify if I'm reading this correctly this assumes the output of `bazel build tarball` and it won't work in a different context e.g dev running bazel build //installer/cmd/tectonic:darwing May be worth a comment clarifying that?", "You're right, this assumes running from the built tarball.\r\nThis *is on purpose* because all testing should be done against the release layout, not the source repository one.\r\n\r\nThe main reason why we adopted Bazel is to have a fast, reproducible build that we could use during development to test against the same artefacts as the one we release. \r\nWe've failed multiple times in the past because of this usage skew between development and released items.\r\n\r\nIf you're testing the repository itself, please switch to testing from the build output.\r\nWhatever rough edges there are in this process we should identify and iron out so that we make it as smooth as possible to follow this flow.", "Here's the steps I'm taking to test a new change:\r\n1. `bazel build tarball && tar -C ~/Desktop/ -xf bazel-bin/tectonic.tar.gz`\r\n2. `cd ~/Desktop`\r\n3. `./tectonic/tectonic-installer/darwin/tectonic init --config test-cluster.xml`\r\n4. `./tectonic/tectonic-installer/darwin/tectonic install assets --dir TestCluster`\r\n5.  `...`"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2984", "comments": ["What does the `10` stand for?", "Either `generateRandomId`, `generateClusterId` and `cidrhost` are literally replicating tf logic so we can reproduce previews behaviour for now. Added a comment on the function https://github.com/coreos/tectonic-installer/pull/2984/files#diff-0a70c3d9395f8f34a8fbbb179bf987b8R270", "Cool, thanks for the clarification. The fact that it's not obvious (at least to me) where that comes from is a reason enough to try to improve such cases.\r\n\r\nWould you mind also dropping in a `//TODO: re-evaluate solution` in such cases which are not meant to be the long term solution?\r\n\r\nThis would allow us to have a simple auditing command to collect all these when we plan future work.", "nit & not a blocker: i'd suggest later returning an IP instead of a string.", "TODO for later: all these should be isolated as constants somewhere."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2983", "comments": ["I will port these over with @spangenberg today.", "Mhh, ... *starting a bike-shedding discussion*", "Either for now or for future improvements, we don't need to exchange data via env variables anymore, but can have `export_random_region_if_not_defined` return the region which we save into the config file right away. What do you think?", "We probably need to get this back for the other platforms.", "Can we disable this just on AWS?", "it only runs for aws now :(", "done", "cool", "We will delay this to a separate PR", "I'd be in favour of relying on the raw test.yaml config as much as possible and fail otherwise, unless the reason to set a not defined is representing a specific user behaviour test case ", "do we want to remove the commented line?", "do we want to remove this commented code?", "'bootstrap.tfstate' and 'tectonic-ci.de' should move into constants eventually", "we will do all of that in a followup", "?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2976", "comments": ["Why don\u2019t we return the comparison expression here like in the other cases?", "Yes, that logic looks like it was incorrect to me.\r\n\r\nActually, I think we can greatly simplify this because our version strings can now be ordered alphabetically. The current logic dates from June, before our release naming became consistent, so I've replaced it."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2972", "comments": ["As far as I can tell, AWS is missing the `user_provided_tls` folder. Once we re-enable `tests/rspec/spec/aws/custom_tls_spec.rb` this would fail, right?", "Just a very small thing: This function does not only create the namespace, but also create a rolebinding. Thereby I find the name misleading. What do you think @abhinavdahiya.", "Yes.\r\n`dest_folder = \"#{root_folder}/platforms/#{@tfvars_file.platform}\"` copies the `tls.tf` to `platform/`\r\nand since AWS doesn't use this folder, I didn't sertup the `user_provided_tls` folder for AWS.\r\n\r\nWhen all platforms merge to UT2, only `steps/assets/tls.tf` will have to be replaced.", "It's setting up the namespace for the test.\r\n1. Create the namespace.\r\n2. Create the rope binding, which is required to allow pods to run in the namespace (the default PodSecurityPolicy is very limited).\r\n\r\nBoth these steps are related to namespace... so I grouped them together.", "there no such a variable in this module, current name is `aggregator_ca_key_pem_path`", "organization field is duplicated", "there no such a variable in this module, current name is aggregator_ca_cert_pem_path", "Shouldn't this remain using kube_ca_cert? if not, why only bootkube (not also bootkube-ut2)?", "Shouldn't this remain using kube_ca_cert? if not, why only bootkube (not also bootkube-ut2)?", "Are we deliberately (from a product prespective) removing the choice for the user to set `tectonic_tls_validity_period`? if so, we should remove the variable from the config.tf, and the references int the cli (this could be done as a follow up once we got this ready as otherwise this is becoming massive pr) because as far as I can see it wouldn't be used anymore?", "are these test changes related to this PR?", "good catch... also, this PR regresses #3031\r\nplease integrate these changes in a new commit."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2960", "comments": ["I'd rather move this constants and findTemplatesForStep to a different package may be utils or step, and keep terraform workflow agnostic, with which is purely terraform", "why is the readClusterConfigStep step needed?", "Metadata always just gets the cluster dir:\r\n```go\r\nmetadata: metadata{clusterDir: clusterDir}\r\n```\r\nThe `readClusterConfigStep` takes care of ensuring that the config gets parsed, e.g. for cluster `Name` or `Platform`.", "Makes sense, will change that."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2958", "comments": ["I think we actually want to invalidate both `assets.zip` and `ignition`.\r\nWould something like `echo > ignition` and `echo > assets.zip` before each `cp` operation work for that?", "isn't what we are doing by `touch /tmp/assets.zip`? I can rename if it's not clear", "Unless /tmp/assets.zip doesn't already exist.\r\nIn that case it just gets it's timestamps updated and ends up being uploaded to S3.\r\nNot the right time and place to obsess about edge cases tough, so this might be nitpicking."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2957", "comments": ["like Fedora? or just remove the `like`", "oops. thanks."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2955", "comments": ["i've seen this exact issue and root cause testing on bare-metal. I think this hack should work for now"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2949", "comments": ["This should be the default path. No need to explicitly have a sub-command.\r\n#lessismore #minimalism", "By adding full as default the user can just run `cli install --config` otherwise the same command complains about it expecting a subcommand. Not sure yet how to tell kingpin that the subcommand is not mandatory"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2947", "comments": ["Can we unify these names? I.e. why is one \u201clatestRelease\u201d and the other \u201ctectonicVersion\u201d? They are both versions of Tectonic. And it should already be assumed that they are releases since they are in the /release/ path. Could this be renamed `latest` and `current` to make it more intelligible?", "Just logging an error with \u201cfmt.Printf\u201d is not really sufficient. We should return an error here.", "This function can fail, so let\u2019s restore the function signature to also return an error.", "None of the code below this point is valid if we got an error earlier. We need to skip all of this by returning an error early."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2941", "comments": ["Whats the reason to set this after the function definitions and not before?", "As far as I understand, this shifts the command line argument indices, now that the `-d` option is handled, right? Would you mind adding a comment for the _future Max_, just in case my bash knowledge stays at the poor level it is at the moment.", "\ud83d\udc4d this makes it a lot cleaner.", "This line is where execution really begins, so I wanted to place it next to the rest of the code. The `-x` option does not print function definitions anyway, so it would make no difference to put it at the top of the file if we were so inclined. (The code within the functions is still emitted when they are executed).", "Will do. I always find `getopts` usage to be confusing myself."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2940", "comments": ["It think these should be called something  'bootstrap_*'  rather then \"s3\"\r\n", "that will be the ignition config for all masters not only bootstrap, so may be ignition_masters"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2936", "comments": ["Talk to @enxebre about his solution from #2901 \r\nWe need a common ground :)\r\n", "This seems a reasonable abstraction according to the code changes introduced by this PR, we can always reshape organically as per https://github.com/coreos/tectonic-installer/pull/2901 once the underlying steps introduce more tf hassle"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2931", "comments": ["What is the reason for splitting these up into separate stages? As far as I know, stages have to run in sequence.", "Spinning up a lot of clusters in the same region resulted in many random cloud provider api failures in the past. I am not sure this is still an issue."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2926", "comments": ["why are we explicitly setting a default to `undefined`? this is the default value of any parameter that was not set. moreover, we don't do this anywhere else, I believe", "This was just meant to indicate that the parameter is optional, but after looking at it again, I think it's better to move the textarea tests to `testFileTextCombo` and remove the `textSelector` parameter completely.", "is this extra newline wanted?", "We're generally putting a newline between package imports and imports from the same repo."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2918", "comments": ["what does this mean for cloud environments or anywhere you don't want to use BGP?", "I'm glad you pointed this out.  `k8s,bgp` is not a valid value for that field and what I updated it to was not any better.  It should be 'bird'.\r\nThat field specifies how Calico will distribute the routes and for this it uses BGP and defaults to using bird for that.\r\n\r\nAs for your question.  Calico uses BGP if it is setting up pod networking, by default it creates a BGP mesh between the nodes.  If one doesn't want to use BGP then they must use a different method to configure networking between pods (for example Canal).\r\n\r\nThat field should be set to `none`, `bird`, or `gobgp`.  If it is set to none then calico operates in a policy only mode.\r\n\r\nI'll push up changes in a minute switching it to `bird`.", "@alexsomesan How would we need to template this for canal users?", "@robszumski Canal currently exists in the tectonic-installer as a separate manifest, are you thinking about combining those manifests into one and templating the differences? You can see that Canal has `CALICO_NETWORKING_BACKEND` set to `none`."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2915", "comments": ["need to use the name `build`? because the other is using `latest` and this new endpoint is to get the current. then maybe use `current` instead of `build`", "I was deliberating between the two (I actually created the endpoint with \"current\" to start with). I thought that \"current\" sounded weird. can be changed, if you think it's better.", "What does `stamp` mean? Is it `timestamp`? It is convention to call this package `version`, see for example https://github.com/coreos/matchbox/blob/master/matchbox/version/version.go or https://github.com/coreos-inc/bridge/blob/master/version/version.go. Please rename for legibility and consistency", "For simplicity can we just call this `Version`? ", "This returns a json object with title-cased keys, which is a little odd. By convention, json keys are normally camel-cased, or sometimes snake-cased. Can you fix the casing?", "For cases such as this where all the fields are known, we typically use an anonymous struct rather than a map. This should also be more memory-efficient", "There is no need to specify the type of this variable in the name. Please rename to just \u201cversion\u201d", "Where is this API endpoint consumed in the front end? Without it, this pull request does not fully solve our issue of the reported build version being wrong", "Who sets this environment variable? Please add this detail to the build documentation. For consistency, with the rest of the build process, I think that this variable should be simply `VERSION`", "please add `-e` here", "I'd actually prefer to keep these environment inputs namespaced like this, with TECTONIC_*\r\n\r\nTwo reasons for this:\r\n1. VERSION is much too common and the probability of it affecting other tools or just being used for something else in the system seems rather high.\r\n2. The prefixing helps to visualize the current state of the environment much easier by piping `env` to `sort`.", "that's fine; the main issues here are twofold:\r\n\r\n1. Who sets this variable? We need this documented somewhere.\r\n2. We need to make this consistent with the rest of the build process; if we want to go the namespaced route, then that means changing the variables used by the tarball bazel build rule so that we do not need to set two different variables.", "The name was taken from a bazel example of using x_defs to add variables to compiled binaries, and they named it \"stamped bin\". But your suggestion is actually clearer.", "I'm planning to add that change in a separate commit", "Sounds good. Separate commit in this same PR or a different PR?", "I agree with @alexsomesan in that using just `VERSION` would be too generic. We could use this api endpoint in the future, to output any kind of build information that would help us debug issues, such as go / bazel versions, etc, etc. So I'd opt for modifying the documentation and existing vars.", "Sounds good. Please make those changes in this PR then", "@squat Both are valid questions.\r\nI think for 1) it's whatever RA ends up running in - most likely their Jenkins pipeline.\r\n\r\nFor 2), if there're no hard blockers, I'd prefer we align everything that's an input to the build process under TECTONIC_ or TECTONIC_BUILD_. We have to keep in mind that the CLI will also support env var overrides. We might want to make a distinction between the runtime and the buildtime inputs (namespaces). But that's mostly off-topic for this change.", "nit: can you eliminate this extra newline?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2914", "comments": ["no need to export this type", "Thanks @squat. I renamed it to `awsVPC`.", "in Go types all have `zero-values`. the zero-value for a string is `\"\"`; so the conventional way to declare a string and have memory allocated for its value on the stack is just:\r\n\r\n```go\r\nvar name string\r\n```", "same here with the declaration of the string.", "@squat Fixed. Thanks!", "Fixed"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2907", "comments": ["@cpanato We have the logs output as a Jenkins archive. Is the print statement to the Jenkins logs still needed?", "you can remove, please.", "I can combine the `unstash` lines here into a function and invoke that function in `runRSpecTestBareMetal` as well.", "Instead of relying on the current dir to be the correct dir, I use absolute paths via the `RSPEC_PATH` and `RELEASE_TARBALL_PATH`. What do you think @cpanato? Should make the framework more robust for the future. ", "Smoke test binary is build by Bazel from now on.", "@mxinden address TODO", "With the new CLI, this should not be needed anymore.", "good!", "do you need this?", "+1"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2906", "comments": ["Is this line still needed? Looks like a debugging line.", "opppssss.... \ud83d\ude04 ", "done"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2903", "comments": ["How about switching `## Building A Release Tarball` with `## Building the Installer Binary`? Building the tarball should be the goal of the majority of the readers.", "If I understand this correctly, running `./tarball` should work for everyone? How about moving this section to the top of `## Building A Release Tarball` then, so users know what to do and can dive deeper if needed.", "Maybe callout why I would choose this option over `bazel build tarball` and vice vesra. It's not really clear from the docs.", "`s/do build/to build/`", "Shouldn't this be `VERSION` instead of `VARIABLE`?", "same?", "Can you link to the docs on running smoke tests?", "Maybe a brief sentence or two about what's included in the tarball too.", "consider a \"Quickstart\" section at the top with the most common/basic flow.", "Done. I think Max's comment about changing the order helps disambiguate the importance of the different targets. I also added a small blurb about why you might want only the binary. I added a Quickstart documenting the two most important use-cases:\r\n\r\n1. build a tarball for development/testing\r\n2. build a release tarball", "done", "thanks!", "yup thanks!", "got it", "sure! I thought the file trees would be helpful for this. I added this info explicitly in the quickstart now"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2901", "comments": ["The init step should be included in the destroy workflow as well.\r\nIf everything is in order, it will just no-op and move on.\r\nBut it does help the user experience when modules or plugins may be missing, in which case it repairs rather than throwing an error.", "Why are the commented parts still in there?", "Awesome! Thanks for adding units for this!", "this is commented out base on the TODO above, so once there's a config parser, initially we could run multistep workflow if platform is aws or single step workflow otherwise"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2895", "comments": ["another, faster way to do this, I think, would be to bitshift the pieces and `|` them together.", "should you `parseInt` here?", "hmm though we may run into the same issue with the 32bit int", "Good catch, but I discovered another bug in `cidrStart()` and ended up changing it anyway.", "I checked this again, but unfortunately we do run into the signed 32-bit int issue, so I left it as is."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2884", "comments": ["by convention, JSON is encoded in camel-case. Why is this using title casing?", "rather that comment these out, can you skip the tests so that their lack of implementation is noted in the test output? See https://golang.org/pkg/testing/#T.Skip", "Done", "Like you said in your other comment, I'm just matching the existing JSON keys. I agree that they should be changed to camelCase though.", "Ok thanks for confirming. We\u2019ll need to follow up and fix this on the config-generator side of things"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2878", "comments": ["this is tricky. what if there is no version specified in the tf_vars? since the cl_version defaults to `latest` maybe we should account for that here.", "for metal tests we need to define the version, otherwise, the setup part that downloads the CL will not work.\r\nprevious this change we always have the version set in the tfvars.\r\n\r\nlet me know if you want to change this then I will rethink the logic\r\n\r\n@squat ", "sounds good. I don't think we need to over-engineer this :sunglasses: "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2873", "comments": ["this is correct to keep hardcoded?", "there's no sensitive information there so it's fine, we could remove it in a follow up to keep it less opinionated if we want though", "sound good"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2867", "comments": ["Why not use https://github.com/coreos/tectonic-installer/blob/master/tests/rspec/lib/with_retries.rb here?", "done"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2862", "comments": ["we'll need to mirror this into quay.io/coreos", "We can do that ourselves in a follow up. "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2855", "comments": ["This makes `LOGSTASH_BUCKET` defined twice, right?", "forgot to remove, doing that", "done @mxinden ", "Let me know once you pushed the changes.", "pushed"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2854", "comments": ["Let's call it something that will make it clear it's used during installation and not for any on-cluster stuff.\r\nFor example `tectonic_aws_installer_role`", "Why do we now need to pass credentials into these functions? ", "this function will create an aws client and then will create the keys ", "ok, any ideas? \ud83d\ude04 ", "this is same we do for other functions that interact with AWS. Before we just used the AWS_KEY/SECRET environment vars. But now since we are using a user that needs to assume the role, we can set the role_credentials, instead of set the env vars. \r\nThen if the credentials expire we can renew that. @alexsomesan ", "As far as I can tell, `credsUI` and `creds` are always used together, right? Why not merge them into one?", "Can you add a comment here why you commented this line out?", "no. I can explain to you in person. \r\nBut the credsUI have the aws cred that Jenkins provides the session token for us. then we don't need to assume the role explicitly.\r\n\r\nthe creds have the aws credentials with no session token and we need to assume that. this is useful in the terraform and in our rpec.\r\n\r\nI also don't like this approach to have two creds, but I would like to see this running for a while and see if works, then I can do a followup to we assume tole in all parts of the build.", "we are not using this in this part of the code. I will remove that in a followup."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2850", "comments": ["I don't think this should be used as a serving cert, just a client cert.", "Common name has to match the value specified by:\r\n\r\n```\r\n--requestheader-allowed-names\r\n```", "Ah, I thought that was the CN in the CA. The docs are very unclear, and the metrics server appeared to be working. But I'll change the flag to this one in the operators-PR.", "So, remove the dns names and ip addresses?", "Yes. Allowed usages bellow should also drop \"server_auth\"", "Done", "wouldn't this need to be `module.kube_certs.apiserver_proxy_cert_pem` and `module.kube_certs.apiserver_proxy_key_pem`? same question for all platforms", "shall we add same todo in contrib module?", "Done", "Great catch, thank you! Changed to the correct value.", "I'm curious: why does this module output an aggregator_ca_key but not the tls/kube/user-provided?\r\n\r\nIt seems like this output is not consumed anywhere either.", "Should this module also create local files for the aggregated ca key and crt just like `modules/tls/kube/self-signed` does? i.e.:\r\n```hcl\r\nresource \"local_file\" \"aggregator_ca_key\" {\r\n...\r\n}\r\nresource \"local_file\" \"aggregator_ca_crt\" {\r\n...\r\n}\r\n```", "You're right, it's not a required output. Got copy-paste happy. Removed.", "Done"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2846", "comments": ["If there are similar settings for other cloud providers it's probably better to have a single top-level variable that each of them is aware of. You can indicate which platforms are supported in the var description.", "I will make top level. thanks for the review", "done @sym3tri ", "we should break apart this module into variables.tf and outputs.tf to match the other modules", "done"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2836", "comments": ["Should this be \"The resolver _IP_...\"?", "@enxebre here you are hardcoding `private_endpoints` to `true` and `public_endpoints` to `false` but you are keeping all of the ternary expressions. Why not just simplify this and eliminate all of the ternarys? It makes it much easier to read. These changes are in VCS so we don't need to keep this around. If you really need to keep it around even if the ternarys do nothing, then please add a comment"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2835", "comments": ["extra \"is\" - \"This setup\"", "t2.micro might be kind of small for all those components.", "I presume the `compact(list(..))` come from a time when more than one entries were used here?", "Is this instance also supposed to act as a NAT gateway?", "Afaik there's no nat gateway service in govcloud https://docs.aws.amazon.com/govcloud-us/latest/UserGuide/using-services.html so some sort of solution is needed for instances in a private subnet to connect to the internet ", "injected as a variable now"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2834", "comments": ["typo here. will fix", "Same as #2836: @enxebre here you are hardcoding `private_endpoints` to `true` and `public_endpoints` to `false` but you are keeping all of the ternary expressions. Why not just simplify this and eliminate all of the ternarys? It makes it much easier to read. These changes are in VCS so we don't need to keep this around. If you really need to keep it around even if the ternarys do nothing, then please add a comment"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2833", "comments": ["Default set to true would mean, that we have to edit all trigger jobs, right?", "will set to false", "done"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2828", "comments": ["we also need to update the kubernetes version below.\r\n\r\n(and someone should also update the tectonic version, cc @robszumski )", "bumped kubernetes version"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2826", "comments": ["Is this instance also supposed to act as a NAT gateway?\r\n\r\n", "I presume the compact(list(..)) come from a time when more than one entries were used here?\r\n\r\n", "t2.micro might be kind of small for all those components.\r\n\r\n", "extra \"is\" - \"This setup\"\r\n\r\n"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2825", "comments": ["This file has just been re-arranged so that this entire section matches the corresponding section in the master profile"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2819", "comments": ["So, when set to `false`, the default, we want `profile.env` to include proxy settings", "This does the opposite of the documented behavior: when set to `false`, we DO want profile.env to be created so that ALL processes are proxied, however here, if `proxy_exclusive_units` is `false`, no profile.env will be created.", "This variable has no effect on the ignition generated for Matchbox since it does metal does not use the ignition provider, so profile.env will always be created when http_proxy is defined.", "Fixed in the latest commit"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2816", "comments": ["This is probably ok to start, but experience tells me that it's going to end up being too noisy and we'll move it to a dedicated channel", "this will send just when master/track-1 fail as we have today", "What is the reason for removing this line?", "If an `log-es-error` happens on a PR, we still want to be notified, right?", "forgot to readd, will put it back", "yes"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2810", "comments": ["We should really pin the version of Bazel. Specifically, 0.9.x is known to have issues when crossconpiling go binaries. ", "@squat as discussed this pins the Bazel version to `0.10.0~rc6` from the deb repository. Good hint, thanks! Let me know if there is anything else. ", "@mxinden could you add nodejs to PATH for these two frontend tests as well? that way all of the frontend building is consistent and hermetic?", "@squat Done. In addition I added the `frontend_test` target to the Jenkinsfile to run after every build."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2809", "comments": ["why the lower etcd version?", "spelling: privileges", "privileges", "I would consider renaming this one too (to `kubeconfig-admin`) to make it really clear that you shouldn't use it for anything in the cluster. Others might have different feelings though.", "bootkube start expects the admin kubeconfig to exist at this path. \r\nhttps://github.com/kubernetes-incubator/bootkube/blob/master/pkg/bootkube/bootstrap.go#L38-L41", "Heh, look at the fool who left that TODO there :-/", "oh, fixed that.", "done", "done", "Why not?:\r\n```\r\n--kubeconfig=/path/to/to-be-generated-kubeconfig\r\n--require-kubeconfig\r\n--bootstrap-kubeconfig=\"/path/to/bootstrap/kubeconfig\"\r\n```", "may be just add a comment on the kubeconfig file if that does not break any consumer?", "This needs (along with everything else) to be kept in sync within contrib/user-provided-certs.\r\n@abhinavdahiya We are in the process of decoupling the tls generation from the installer. Eventually we'll rely on modules/tls/user-provided to just wire the previously generated certificates into the installer.\r\nAs a transitional step for automation purposes we plan to rely on contrib/user-provided-certs to pre-generate the certificates before moving to a more suitable tool.", "I believe he alphabetized them.", "I meant what's the reasoning to not use the ```--bootstrap-kubeconfig``` flag and then letting the kubelet write the new config on approval in the path pointed by ```--kubeconfig``` as suggested here https://kubernetes.io/docs/admin/kubelet-tls-bootstrapping/#kubelet-configuration.", "https://github.com/kubernetes-incubator/bootkube/pull/663#discussion_r156296326", "@enxebre I think i have synced all these changes to `contrib/user-provided-certs` in this PR iteself .\r\n(https://github.com/coreos/tectonic-installer/pull/2809/commits/771525ba923f8b856110c3ae5e59db7dca8dd5f5#diff-1e46a06517303b3aa2caeddc2865efb5)\r\n(https://github.com/coreos/tectonic-installer/pull/2809/commits/771525ba923f8b856110c3ae5e59db7dca8dd5f5#diff-266340c2b198d2324636d1e007ce3a66)\r\n(https://github.com/coreos/tectonic-installer/pull/2809/commits/771525ba923f8b856110c3ae5e59db7dca8dd5f5#diff-a870b0054dd4ceba57305ced8ff8b116)\r\n\r\nIs anything else required?", "I guess there will be a release of `kube-core-renderer` before this change needs to merge, so that we don't have to carry the `dev` tag into installer's master?", "//cc: @diegs ", "Is there a serious problem with using dev images on master? Then we cut over to release images for release branches?", "I don't have any concerns myself as long as we track the follow-up to catch up with the future release.", "Let's go forward with that for now then."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2806", "comments": ["I think something funny happened with the rebase: these definitions are out of date with ut2-integration. We no longer define `PLATFORMS` in BUILD.bazel", "Same here, these rules are no defined in `examples/BUILD.bazel` and `Documentation/BUILD.bazel`", "we should add explicit rules for darwin and linux. can be done in a followup but it is a requirement before the task is done.", "what about any other syscall-related errors? is this error actually safe to ignore?", "`tectonic_cluster_name` should be made into a constant", "currently this method only works with .tfvars and not .tfvars.json, right? maybe add a note saying that", "This is a little bit cleaner and easier to read if you use a rune, e.g. \r\n```go\r\nvalue = strings.Trim(value, `\"`)\r\n```", "This case only occurs if the given file does not include a `tectonic_cluster_name`, right? I think the error should reflect that, e.g. \r\n```go\r\nfmt.Errorf(\"the given file does not specify a %q\", TectonicClusterNameKey)\r\n```", "why is this error suppressed?", "same here", "An unexported type should not have exported methods", "`build_path` should probably be a const as well; maybe a type imported from another pkg", "likewise, these types are implementation details of the `Workflowtype` type and should not be exported.", "Rather than model `Step` as an interface, why not model it as a function type? This way defining the list of steps in install.go would be easier and you wouldn't need to define throwaway structs just to define methods.", "This type should strictly be unexported, otherwise there is no real point to exporting the interface. If the `Workflow` interface is the API for all other packages, then this type should be internal, i.e. an implementation that is of no concern to users.", "Please rename this type; it is odd in Go to suffix any type with `Type` just as we do not suffix interfaces with `IFace` or the like. If this is truly going to be one of several implementations then I suggest that this type be named after that implementation. On the other hand, if this type is going to be the only implementation, then there should be no interface at all and this should be the only exported type from this package. In this case this type should be named simply `Workflow`.", "why not just name this `err`?", "it's convention in Go to name the range value either  the singular of the splice, i.e. `step`, or the first letter, i.e. `s`.", "This whole method is only meant to be around until we merge Daniel's config object parser. Then we scrap this and get the name from the config object.\r\nI agree though, technically \"tectonic_cluster_name\" should be a constant. I also expect the compiler would optimize towards that, no?", "Same as above. This is just mock-up code - Daniel's config parser will be the long term solution.", "Good point. Forgot about that form. Will fix", "Im suggesting it from code maintainability perspective.", "Crappy mock-up code. Meant to be dropped entirely when config object parsing gets in.", "This is not the actual implementation we want to have here.\r\nOnly meant as a minimally working surrogate until we implement a proper way to find the templates within the release bundle.", "Out of haste. Should be handled. I'll make the change.", "Old habit from other more talkative languages. I'll make it 'err'.", "I had the same dilema myself.\r\nThe reality is we (or I) don't know for sure if this is going to suffice as a sole implementation or not in the long run. That's why the interface is there and it's being referenced via the interface. I think this is the safer design choice at this point.\r\n\r\nHow about we call this implementation SimpleWorkflow for now? I'm not great with picking good names..", "sure call it something like `basicWorkflow`/`simpleWorkflow` but the type should really be unexported", "Simple steps appear as overkill with this approach I know, but I can imagine more complex ones would be split across multiple functions that would want to share some state. Even then we could explicitly pass around all necessary state as arguments (functional style) and still use a function type as entrypoint.\r\nI tend to think this form is easier to reason with for most people so I'm tempted to keep it. If you feel strongly the other way, we can switch though.\r\nEither way, empty structs should get optimised away by the compiler (unless they are being very \"original\") so they should not bloat in any way.", "Agree. Making it unexported.", "That's right. Will lower-case it.", "I'm actually thinking to make build path a first-class attribute of metadata.\r\nIt's always going to be set and will be accessed from pretty much everywhere.\r\nSame applies for other \"core\" attributes we'll run across as we develop this.\r\nWDYT?", "Will change them.", "Agreed on the compiler angle. However, in order to avoid premature optimization for a potential future complexity, I would have gone with the function style first. It's possible we may need to make the change in the future, though it's also possible that if we go down the current route, we will never need the structs to carry any state and we'll have struct steps simply because we thought we'd need the complexity. Not a big problem either way. Again, not concerned about the binary performance but more about the legibility and maintainability", "My instinct is that `metadata` should be a config struct inside the Workflow. The struct should only define the fields we know it needs now. If we need arbitrary keys and values in the future then we can move to `map[string]interface{}` but it's a little much right now, especially for type that only has one known field ATM. Plus it would be good to avoid having to do type assertions down the road", "nit: the descriptions should all end without a period or all end with a period. I prefer no period but either way is ok as long as it is consistent", "can we have a default case that shows the help?", "These methods should be unexported as well. Also, why are we wrapping the map with setters and getters?", "good point, I'll drop the periods.", "Not sure I understand this right, but the Kingpin library actually produces automatic help based on those descriptions strings of each command. Here's how it looks today:\r\n```\r\nbazel-bin/installer/cmd/tectonic/darwin_amd64_stripped/tectonic --help\r\nusage: tectonic [<flags>] <command> [<args> ...]\r\n\r\nFlags:\r\n  --help     Show context-sensitive help (also try --help-long and --help-man).\r\n  --dry-run  Just pretend, but don't do anything.\r\n\r\nCommands:\r\n  help [<command>...]\r\n    Show help.\r\n\r\n  install --config=CONFIG\r\n    Create a new Tectonic cluster.\r\n\r\n  delete [<dir>]\r\n    Delete an existing Tectonic cluster.\r\n```\r\n\r\nWe could obviously add additional information to it, but I presume this is enough to get started.", "Two reasons I had in mind when I did this.\r\n\r\nThe practical one is avoid the ugly syntax of dereferencing the m pointer every time since this is going to be done in a lot of places. May be a personal bias though.\r\n\r\nThe other one is a bit more on the hypothetical side: make sure we don't have to sweep through the whole code if we want to swap the map out for something else.\r\n\r\nYou think we should switch to accessing the map directly?", "You've got a valid point. But this method is disposable and should only be in here until Daniel gets to merge his stuff in. I'll add the constant thought.", "add a `.` at the end of the description. like the other \ud83d\ude04 ", "what happens if just execute `tectonic`? Will it show the help as well?", "The same help output is shown.\r\nThis is all autogenerated by the kingpin CLI framework.\r\n```\r\n$ bazel-bin/installer/cmd/tectonic/darwin_amd64_stripped/tectonic\r\nusage: tectonic [<flags>] <command> [<args> ...]\r\n\r\nFlags:\r\n  --help     Show context-sensitive help (also try --help-long and --help-man).\r\n  --dry-run  Just pretend, but don't do anything.\r\n\r\nCommands:\r\n  help [<command>...]\r\n    Show help.\r\n\r\n  install --config=CONFIG\r\n    Create a new Tectonic cluster.\r\n\r\n  delete [<dir>]\r\n    Delete an existing Tectonic cluster.\r\n\r\n```", "\ud83d\udc4d ", "missing a word in this sentence \"failed to ____ current directory...\"", "What \u201cContext\u201d?", "This type should be unexported. The exports type is the interface. No one outside of the workflow package should care about or depend on this type at all", "It seems odd to me that the steps mutate the metadata. This should happen in the install workflow constructor IMO", "tfInit sounds like a carry over name from previews ```terraformInitStep```\r\nin a follow up PR we can probably\r\n\r\n```\r\nfunc runTfCommand(buildPath string, args ...string) error {\r\n\ttfCommand := exec.Command(\"terraform\", args...)\r\n\ttfCommand.Dir = buildPath\r\n\ttfCommand.Stdin = os.Stdin\r\n\ttfCommand.Stdout = os.Stdout\r\n\ttfCommand.Stderr = os.Stderr\r\n\terr := tfCommand.Run()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}\r\n```", "In my mind that was the whole point of passing the metadata object around.\r\nIt was supposed to provide a vehicle for passing data between steps, without coupling the steps to each other.", "leftover. needs fixing.", "If you want to decouple the steps then the metadata must be an invariant that is completely filled during construction. This implementation is the opposite. IMO. All steps that require the statePath metadata are now dependent on this step.", "I deliberately chose to stay away from abstracting this just yet, because I wanted to get a feel of what the interface to the TF runner abstraction would need to look like once we have a few workflows in place.\r\n\r\nI'll incorporate your suggestion and we'll watch how it maps to some real workflows and evolve it from there if needed."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2798", "comments": ["`s/true if exit_status.success?/exit_status.success?/`", "done", "Let me know once you pushed the changes.", "same here, how about just `return run_command(env, 'apply')`?", "roger that", "done @mxinden "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2794", "comments": ["don't we need to update this one as well?", "That would be a good idea, not my responsibility though...", "ah ok. will check thanks", "This makes me nervous. Do you guys intend to keep pushing and overwriting this same tag? If so that could break our installs in unexpected and untrackable ways.", "That tag should only be for the beryllium m1 release. Further releases will use a different tag. It's effectively a version number but with a descriptive name", "Yeah we didn't have a version number for m1 so I just used that as a tag. We should switch to semver for actual beryllium.\r\n\r\nIt's 1:1 with the tag in our repo (tagging in our repo auto-builds container images):\r\nhttps://github.com/coreos-inc/tectonic-operators/releases/tag/beryllium-m1"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2792", "comments": ["@arithx We will assume the Tectonic installer AWS IAM role in the RSpec framework from now on. Let me know if this is blocking you. ", "made a small change. only if you set the env var `TECTONIC_INSTALLER_ROLE` we will assume the role. otherwise will use the existing keys. so no changes. @mxinden @arithx "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2777", "comments": ["FWIW this is what kubeadm sets:\r\n\r\nhttps://github.com/kubernetes/kubernetes/blob/master/cmd/kubeadm/app/phases/controlplane/manifests.go#L169\r\n\r\ncc @aaronlevy ", "@justaugustus I would feel slightly better copying what kubeadm does...", "@diegs I'm down for that too. \r\nHonestly, any method that prefers `InternalIP` over `Hostname` should address the issue.\r\n\r\nI'll push that change. Thanks for the feedback!!", "Updated!"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2775", "comments": ["@alexsomesan I have discussed this with Lucas. Let me know if you agree. Needed for the terraform fmt `-check` flag.", "Yeah, definitely. Upstream is already at 0.11.2.\r\nWe can try going all the way there. There should be no breaking changes, according to changelog.", "nit: it's convention to put the name first", "rather than use `./bin/terraform` this should be `$(location :terraform_runtime)`", "Also, this command should operate on a set of file, otherwise, how do we know what files are being checked? The whole command should probably be something like:\r\n```\r\n$(location :terraform_runtime) -list -check -write=false $(SRCS)\r\n```\r\nwhere the `:terraform_files` filegroup is specified as a source.", "\ud83d\udc4d ", "Using `$(location :terraform_runtime)` would be my preferred method as well. I am still facing the following issues when trying to achieve this:\r\n- `$(location :terraform_runtime)` via the [`ctx.expand_location`](https://docs.bazel.build/versions/master/skylark/lib/ctx.html#expand_location) function expands to `bazel-out/k8-fastbuild/bin/bin/terraform`.\r\n- The `bazel-out` folder is not symlinked into the working directory of a test.\r\n- There are no enviroment variables injected that point to the `bazel-out` directory.\r\n\r\nAccording to the bazel [test encyclopedia](https://docs.bazel.build/versions/master/test-encyclopedia.html#runfiles) one should leverage the [`runfiles`](https://docs.bazel.build/versions/master/test-encyclopedia.html#runfiles) concept. I am doing this via:\r\n``` python\r\nrunfiles = ctx.runfiles(files=ctx.files.deps)\r\nreturn [DefaultInfo(runfiles=runfiles)]\r\n```\r\nThis makes all directly referenced files available in the current directory itself and all binary targets available in the `bin/` folder. Downside to this approach, is, that the files are not referenced directly in the `command =` string.\r\n\r\nI have looked into how other `github.com/bazelbuild/rules_***` projects solve this. One example would be [`_jsonnet_to_json_test_impl`](https://github.com/bazelbuild/rules_jsonnet/blob/745566196e26107042a5f787f34ded8eaeb908fb/jsonnet/jsonnet.bzl#L177), which heavily depends on setup functions, which I don't feel comfortable just importing into this project.\r\n\r\nLet me know if you have more ideas. As of now, I would suggest this solution as a first iteration.", "\ud83d\udc4d "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2774", "comments": ["what is this first one for? (bazel)", "\ud83d\udc4d removed."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2771", "comments": ["Is this still needed after https://github.com/coreos/tectonic-installer/pull/2762 landed?", "In #2762 we're still pulling them remotely so it breaks the vendoring rule.\r\n\r\nThe real solution is to move all the vendored packages to a top-level vendored folder, which would also make bazel happy about this.\r\n\r\nI think we should do that before we merge the integration branch (or soon after)."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2766", "comments": ["Could you rename this specfile and method as well?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2761", "comments": ["what's the motivation behind removing `compact(list(` ?", "the `compact(list)` wasn't there to begin with and was accidentally introduced in #2714. This PR rectifies that.", "The original PR [1] actually introduced that `compact(list(` change.\r\n\r\n[1] https://github.com/coreos/tectonic-installer/pull/2609/files#diff-92eb4aaccf04300684240249801f91f2"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2758", "comments": ["Please leave a note for NCG developers that this needs to be changed to \"master\" not \"controller\""]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2757", "comments": ["Turns out this needs to be `/etc/ssl/certs/ca-certificates.crt`\r\n\r\nThe go binary can't read all the certs it needs the cert bundle specifically. \r\nWe need /etc/ssl/certs/ca-certificates.crt as opposed to /usr/share/certs/ca-certificates.crt as we need to be able to trust certificates that are added to the bundle at install time. The /usr/share/cert I think is immutable.", "This change was cherry-picked from your PR. Should I make that change for you?", "Would it be bettre to use `--env HTTP_PROXY --env NO_PROXY` (and any other proxy-related variables; those are the ones the go stdlib understands iirc)?\r\n\r\nThe `profile.env` file is meant for full shell parsing and for interactive user shells, so it's perfectly possible a user will, for valid reasons, have set it to include more complex statements than docker's `--env-file` may understand.\r\n\r\nMinimizing the set of environment variables getting passed through is also good from a security perspective.\r\n\r\nWith the `--env` suggestion above, using a dropin for specifically this service or globally via `/etc/systemd/system.conf.d/` should work, and it won't require touching anything in the default case since docker doesn't error if an `--env` value doesn't exist.", "the problem tho is that the docker container needs the env vars. I am fine with pointing at a diff file. In most cases I am blindly expecting the env vars in /etc/profile.env to apply cleanly here. ", "I think this makes sense. Basically extend the k8s-node-bootstrapper.service with the proxy vars and feed them in with `--env` This is probably cleaner cause the `--env-file` doesn't have to exist.\r\n"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2754", "comments": ["So far we have identified all machines by IP address in the log files. Would the same be possible here?", "I dont have the IP, I will change the code to push the IPs", "done @mxinden ", "s/an/a right?", "In addition it is `{ip => log}` and not `{log => ip}`, right?", "You could just add this once to the `cluster.rb` function, instead of adding it to every single platform. This way, in case we are adding a new platform, we don't need to add it.", "done", "done"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2749", "comments": ["Unfortunately, this breaks the example tfvars generation since the slash causes the path to be interpreted as a directory with a leaf called `neutron`", "I think we can drop example var generation. We'll soon need to replace that with example cluster config generation, anyway."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2747", "comments": ["```hcl\r\nvalue = \"${element(concat(data.ignition_file.ntp_dropin.*.id, list(\"\")), 0)}\"\r\n```", "```hcl\r\nvalue = \"${element(concat(data.template_file.ntp_dropin.*.rendered, list(\"\")), 0)}\"\r\n```", "After removing the `count` var from the template file, this change is not needed.", "After removing the count var from the template file, this change is not needed."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2740", "comments": ["Seems like a good case for a retry function? e.g. https://github.com/coreos/tectonic-torcx/blob/6a9620014cce2cf580ad9b91e6b82f202d8eb392/internal/kube.go#L198", "this test already use retry: https://github.com/cpanato/tectonic-installer/blob/dcee8e0d356b53ed163981c0b2bdf4d382ab8e5c/tests/smoke/cluster_test.go#L81", "All test points are already wrapped in retry logic :+1:", "duplicating all this code is a little dirty. can we make this whole section identical to the one above, abstract it into a function, and just call the function twice with a timer in the middle?", "sure, will do that"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2736", "comments": ["We can't yet use 0.9 because that version breaks cross compilation https://github.com/bazelbuild/rules_go/issues/1240"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2735", "comments": ["This should either go in all the READMEs or in a general one", "can we make the order of `exist_tf` and `exist_plat` the same here and for `ClusterFactory.from_variable`", "yes, wrong place. my bad", "s/Applying cluster failed/terraform init failed/", "Why are you skipping this test, when it is run locally?", "Great, I like the \"fail fast\" approach!\r\nCan you do the same with the `CLUSTER` variable?", "done", "done, thanks!", "because this is the scale up, and if you run for example 3-4 times or more it will scale up your cluster a lot. also takes some time and the developer maybe need just a fast feedback loop.\r\n\r\nthe scale-up tests are used for a single test or in CI. not for local tests and debug.\r\nif the dev really need this he can comment out this part", "done", "\ud83d\udc4d "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2723", "comments": ["ah, needs a rebase here"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2722", "comments": ["Can we also fix the `coreos` here? It should really say `Container Linux images`. Or at the very least `CoreOS`.", "Please use `Container Linux`", "Thanks. I changed it to `Container Linux images`."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2713", "comments": ["There was an unfortunate typo here (https://github.com/coreos/tectonic-installer/pull/2748). However I'm concerned that neither reviews nor tests blocked this.", "it blocked, but unfortunately for this PR it was not set to run on bare metal. we saw the issue when we run the nightly in master \ud83d\ude22 ", "This is a side effect of relying on human intervention for setting the labels for running the tests. This needs to be automated so we ensure by code that relevant tests are run when needed", "agree, let's discuss to check what we can do.\r\n\r\nbut the code review that we do should check this as well if all relevant platform was covered "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2701", "comments": ["unnecessary since the template file doesn't extend var.nfs_config", "could use var.nfs_config directly", "could use var.nfs_config directly", "We are usually trying really hard not to inline contents for files in input variables.\r\nDoing so will make it complicated to process these files with tools, such as the cli tool. Is is also very confusing to look at when dealing with the varfile manually in a editor.\r\n\r\nI suggest we require the desired NFS config in a file and make this variable a path to that file.\r\nYou can use the `\"${file(...)}\"` interpolation function in the templates to read the contents from the supplied file."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2695", "comments": ["This is the stuff that makes \"Make\" brittle.\r\nOn a more immediate note, it fails on macOS due to divergent flags to `cp`.\r\n\r\nHere's what I get:\r\n```\r\nbazel build installer/frontend\r\nWARNING: /Users/alex/go/src/github.com/coreos/tectonic-installer/installer/frontend/BUILD.bazel:20:1: target 'node_modules' is both a rule and a file; please choose another name for the rule\r\nINFO: Analysed target //installer/frontend:frontend (15 packages loaded).\r\nINFO: Found 1 target...\r\nERROR: /Users/alex/go/src/github.com/coreos/tectonic-installer/installer/frontend/BUILD.bazel:20:1: Installing JavaScript dependencies... //installer/frontend:node_modules failed (Exit 1)\r\ncp: the -H, -L, and -P options may not be specified with the -r option.\r\nTarget //installer/frontend:frontend failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 14.637s, Critical Path: 0.18s\r\nFAILED: Build did NOT complete successfully\r\n```", "intermediate solution suggestion: use pipe chained `tar` instead of `cp` for now?", "@alexsomesan please try again now. I forgot that `-r` is not defined as a flag for `cp` for MacOS. Instead, we can use `cp -RL`. This is easier and cleaner than resorting to a tar pipe IMO.", "Confirmed working! Thanks for fixing it.\r\n\r\nWe should be good with this for now, but ideally we do all of this in SkyLark rules as a follow-up."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2684", "comments": ["you need to use `credentials` instead of `creds`"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2673", "comments": ["The first sentence is a little funny:\r\n\"If any page before ...\" this is can be many pages\r\n\"... jumps back to that page\" this can only be one\r\n\r\nMaybe:\r\nThe app automatically jumps back to the first page before the current page that has a disabled Next button.", "Does this flag signal that the field is being validated or just that some asynchronous call is in progress?", "Should probably be `fields'` since there are multiple fields in a form.", "\ud83d\udc4d ", "\ud83d\udc4d ", "It actually signals that the field is being validated because the field's `validator()` can be `async`. I added a note stating that."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2670", "comments": ["could also make events default to false as I see two calls not using true here. Nevertheless seems a reasonable pattern to have all enable by default for now", "could just raise the string straightaway here\r\n\r\n", "yes, i want to try this out, reverting", "ok\r\n"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2666", "comments": ["Shouldn't this value be updated before line 25?", "Why we need to fix location on both willMount and on willReceiveProps?", "Purely stylistic, but I prefer `sections` to `navSections` since it is more legible and we already understand that it is related to `nav` from context. Not a blocker.", "Yeah, I just I'm just trying to avoid clashing with the `sections` defined in `trails.js`, but I guess both should be renamed.", "It's because the link should only be disabled if the *next* page's `canNavigateForward()` returns `false`.", "When the component first mounts, `willMount()` is called, but not `willReceiveProps()`. We might need to fix the location when the component first mounts as well as on subsequent property updates, so we need both.", "I've now added a commit to this PR that renames them."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2663", "comments": ["tectonic_vanilla_k8s has been removed, need rebase", "Ugh.  Sorry 'bout that.  I did see it had been removed.  Mistakenly left in during merge conflict resolution."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2637", "comments": ["I don't think showing logs should be conditioned on `clusterName`. As it stands, the logs would be shown if the terraform apply has succeeded and the cluster state is not populated, which is not desired. IMO we do not want to show logs ever if apply has succeeded.\r\n \r\nThis should probably remain as `isApplySuccess`", "Same as below"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2618", "comments": ["Its config object is in the `kube-system` `ConfigMap` though right?", "I'll have to move that. I'm basing these assumptions off that the dev image it's pointing to is using the hardcoded tectonic-system namespace for everything", "Not sure if that's relevant? The image is going to read it off the disk where we mounted it in.", "oh right...\r\n", "Hey @thorfour, we just removed vanilla support, so don't need this check. Need to rebase", "Yea I figured, I was just copy/pasting for now to try and get the smoke tests to pass. Will remove on final squash before merge", "0.0.0 is the correct version?", "hum, then the manifests in the tectonic-system namespace will not get the secret, or am I wrong?", "yea, this version number is basically a placeholder since the operators aren't versioned", "You're probably right. I think that can be changed back to being in tectonic-system", "but do you need this secret in the kube-system as well? maybe then you create in both places", "I shouldn't need it in kube-system"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2609", "comments": ["I'd prefer we not add any new top-level config options unless we also add support for other platforms. \r\n\r\nCan you keep these changes localized to VMWare only for now? Otherwise please add & test similar changes for the other main platforms (aws, azure, baremetal)?", "If this is a list, why not make it a list type instead of a string?", "nit: `tectonic_http_proxy_address` would be a clear name.", "I realize this makes the code uglier, but I'd rather infer proxy is enabled by the presence of the above 2 vars and removing this one entirely. We've already got way too many top-level config options, I'd like to avoid adding any that aren't absolutely necessary. \r\n\r\nAlso it causes confusing behavior if this is true but the others are both empty & there's no way to validate that in this PRs current form.", "nit: `tectonic_https_proxy_address` would be a clear name.", "@sym3tri Agreed.  That would be clearer.  I'll change that.", "@sym3tri  I gave this a lot of consideration.  Normally I would not add top-level configs when changes are only effective on one platform.  But localizing to VMware will make the change to add other platforms quite a bit more work.  Whereas this change will allow other platforms to be readily added.  I've written the code for AWS and SE's just completed testing it this morning for a POC they're working on for Pearson.  T-Mobile will need it for BM very soon (next month).  I don't have the means to test on Azure or BM but it's possible I could add an AWS PR later today.\r\n\r\nSo I _could_ shuffle this around to localize it to VMware but I that will burn a lot more precious cycles in the long-run.", "@sym3tri Are you sure you want me to do that?  I totally appreciate the effort to limit new config options but the trade-off is make the code uglier to save one config option.  Of course, I'll do it if you feel strongly.  I would just argue that cleaner, more maintainable code would be a higher priority in this case. ", "@sym3tri  Because it's not really a list.  It's just a string that gets set as an environment variable.  To make it a terraform list type would just mean I'd have to iterate over the list and create a string to set as an env var.", "Isn't it as simple as calling `join(\",\", var.mylist)`?\r\n\r\nhttps://www.terraform.io/docs/configuration/interpolation.html#join-delim-list-\r\n\r\nI'll leave it up to you, I don't feel too strongly about it.", "How about you add the code for the other platforms as well (best-effort) in a separate PR, then we'll take over the PR and make sure they're all tested and working? If so pls create a Jira issue in our backlog with a link so we can track it.", "I'll defer to @alexsomesan on what he thinks is best here.", "Spoke to him on slack...\r\nI think it's not much of an issue given we'll be refactoring quite a bit soon. No need to change.", "Deal!  Will do.", "I'm with @sym3tri here. I think the `enabled` flag is unnecessary in this context as that state can be inferred from `tectonic_http_proxy_address` having a non-empty value. The code is not necessarily uglier if you use a local Terraform variable to proxy the `enabled` value to the other resources. Here's an example of how I'd express that:\r\n\r\n```\r\nlocals {\r\n  tectonic_http_proxy_enabled = \"${length(var.tectonic_http_proxy_address) > 0}\"\r\n}\r\n```\r\nThen to use it you would do something like:\r\n```\r\nhttp_proxy_enabled      = \"${local.tectonic_http_proxy_enabled}\"\r\n```", "I'm in favor of a list variable + `join()`.\r\nWe plan to add validation to user inputs in the near future and it would help to know from the variable type what kind of data to expect in it, etc.", "I guess you're right.  TIL.  I'll make that change.", "Yeah, that is a clean solution.  I'll add that change."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2608", "comments": ["Will need to remove these once your other PR lands."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2607", "comments": ["Why removing :: here? if so, we should do the same for destroy method for consistency", "for destroy, we don't care if timeout. but i will update", "afaik in this case it sticks to the styling guide both ways with :: and without :: https://github.com/bbatsov/ruby-style-guide#double-colons so lets be consistent and choose the same approach for all the cases\r\n  "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2606", "comments": ["We should override the wording of the mock and change the text to `TLS assets` or even `TLS certificates` since `contents` doesn't actually make sense in this context.", "I changed it to \"TLS certificates\"."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2595", "comments": ["This seems a little funny. Now it is possible for titles to read \u201cTerraform Destory\u201d and other to read \u201cApplying Terraform\u201d. Should be made consistent like before? Also, what other Terraform actions do we recognize?", "I changed it to \u201cTerraform `<ACTION>`\u201c for all actions.\r\n\r\nI've seen a case where the action is `show` when the app is launched and detects an install in progress, but I think that case will go away with planned changes to the restore logic. Still, this change makes it more general / tolerant."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2588", "comments": ["Very fancy \ud83d\udc4d ", "I presume the `compact()` ensures no empty lines when some attributes are missing, right?", "Exactly", ":smirk:"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2582", "comments": ["I don't think we need to make this distinction at all. We should just have a list of keys to skip and remove those keys, if they exist, from both the expected list and the actual list. This will simplify our lives and remove some complexity IMO", "\ud83d\udc4d I've changed it to not distinguish between `actual` and `expected` vars."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2571", "comments": ["@spangenberg this is overwriting the 5.2 image that already exists in Quay, which is probably why you saw those errors. The correct tag to use for the new version of this image would be v5.14. Please note that overwriting existing tags is not good practice since anything that may have wanted to reference it is now broken.", "Similarly, 1.5 already exists; the correct tag to use would be v1.42.", "version v5.2 should not exist, I bumped that since we are increasing the terraform version. but now I'm checking what is wrong", "same here", "spoke OOB. These images did in fact exist from several months ago due to the versioning scheme used.", "build new images:\r\n`quay.io/coreos/tectonic-builder:v1.42` and `quay.io/coreos/tectonic-smoke-test-env:v5.14`\r\n\r\nplease @spangenberg update the branch\r\ncc @squat \r\n"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2568", "comments": ["test are broken because this has no value. Default values could be set here for watches and instances or just set  opinionated values in the template.\r\n ", "Output would need to be injected for all platforms as per https://github.com/coreos/tectonic-installer/blob/master/platforms/aws/main.tf#L148", "I see that these were copied from the referenced PR, but I didn't see any reasoning about these values. Are these just arbitrary?", "Same value came from release notes for docker for mac https://docs.docker.com/docker-for-mac/release-notes/#beta-181-release-notes-2016-07-07-1120-rc3-beta181, also is referenced in some other moby issue (https://github.com/moby/moby/issues/2259), as well as some other third party issues (http://confluence.jetbrains.com/display/IDEADEV/Inotify%2BWatches%2BLimit)"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2559", "comments": ["don't you need to remove this 443?", "no, this will be used to give access to console ingress controller running on 443. that's why I added a new group", "Can we centralize this version? I fear we'll have skew eventually.", "Absolutely, I\u2019ll follow up this PR with another that centralizes this config. I\u2019ll merge this PR for now since it was for last sprint. "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2557", "comments": ["Please update the comment", "I would like this to be consistent. Either use `result` or `status` everywhere. As Jenkins chooses the keyword `result`, maybe stick with that."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2551", "comments": ["We should do something about this so that we don't have to manually update this. We could eliminate this or replace it with the short one-liner used in our Terraform CL module to fetch the latest available version. We could also add the cl version to the ignored keys. Not required for this PR but we should keep in mind.", "We could also eliminate this so that matchbox transparently download the version of CL as required by the configuration rather than being seeded.", "i tried to use latest and looks like it failed. I will try again. can I do a follow-up? , is it ok @squat?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2531", "comments": ["%s/is idempotency when doing a terraform plan after an terraform apply/terraform plan after a terraform apply is an idempotent operation (does not suggest further changes)/", "I will update that in the next commit which I will disable the test as well. ", "done"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2530", "comments": ["/s/'-'/','", "This is an outdated comment, right?", "Instead of `filename=${file}` at the end, I would prefer just `${file}`, so we can use the same pattern in the `file` as well, like e.g. `platform=aws,xyz=abc.log`.", "This looks like an indentation issue, right?", "The comma between `${additionalvarplatform},${additionalvarspec}` should not be necessary, right?", "`set --` seems like quite some bash magic. How about making this a little more simple:\r\n\r\n```bash\r\n#!/bin/bash \r\nset -xeo pipefail\r\n\r\ntestFilePath=$2\r\nadditionalFields=\"\"\r\n\r\nif [ -n \"$testFilePath\" ]; then\r\n        platform=$(echo $testFilePath | cut -d'/' -f1)\r\n        specName=$(echo $testFilePath | cut -d'/' -f2 | sed 's/_spec\\.rb//')\r\n        additionalFields=\"${additionalFields}platform=${platform},specName=${specName},\"\r\nfi\r\n\r\n\r\necho $additionalFields\r\n```", "Is this needed?", "Debug", "Brilliant, discussed.", "Like this, rspec will only save the output to `test.log` and not to standard out anymore. Users still need to be able to check the output via the Jenkins UI, thereby can you change this to:\r\n\r\n```bash\r\n# Directing test output both to stdout as well as a log file\r\nrspec ${testFilePath} --format RspecTap::Formatter --format RspecTap::Formatter --out ../../templogfiles/test.log\r\n```\r\n", "See documentation here: http://www.rubydoc.info/gems/rspec-core/RSpec/Core/Formatters"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2521", "comments": ["Is this differentiating bare metal and all other platforms? If so, could you add a comment?", "/cc @enxebre "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2520", "comments": ["Discussed OOB. It is not totally obvious why this data source is needed. If we are just using the iam role name, then we could directly use the etcd_role variable in the instance profile rather than this data source. Spoke with @cpanato and it seems like this exists here for consistency with other role customizations. We should follow up and check if this data source is indeed needed, i.e. if the output `data.aws_iam_role.etcd_role.*.name` is something different than just the role name, e.g. a full ARN."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2518", "comments": ["this is a much simpler implementation of the search"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2515", "comments": ["This function seems to be the same on GCP and AWS. Can you make it part of `cluster.rb` itself and then bare metal and Azure simply overwrite it?", "Why do this map over an array with a single entry? Why not something like:\r\n```ruby\r\nprint_service_logs(etcd_ip, 'etcd-member', @name, master_ip_address)\r\n```", "because in some cases we have more then one etcd server", "the way to get the etcd hosts differ from platforms"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2511", "comments": ["In the future we should consider re-factoring and making a stepsFactory func to avoid some of the duplication here now."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2510", "comments": ["Should this happen per master? Aren't Kubernetes events per cluster?", "I would suggest \"kubernetes_events\" or \"k8s_ev\" instead of \"kubectl\" as `service_type`, as this has little to do with the Kubernetes command line client. What do you think?", "Same for \"kubectl_ev_all_namespaces\", I would prefer \"kubernetes_ev_all_namespaces\".", "good catch thanks!", "agree", "done", "s/save_kubernetes_events_logs/save_kubernetes_events/\r\n\r\nJust to distinguish between Kubernetes events and Kubernetes logs.", "done, thanks"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2507", "comments": ["Please bump to `v1.8.4-kvo.2`", "v1.8.4-kvo.3 is out."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2497", "comments": ["With respect to the Tectonic, the version mentioned here corresponds to the same tag used in the cluster on the Hpyerkube image. It's worth mentioning Hyperkube (add link to its quay.io hyperkube image).\r\n\r\n---\r\n\r\nAlso, can you add more details about the version requirements?\r\n\r\ni.e. Does the test image tag _always_ have to match _exactly_ the hyperkube image tag version?\r\n\r\n", "did my best"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2495", "comments": ["To align with `master_ip_addresses`:\r\n\r\n`s/workers_ip_addresses/worker_ip_addresses`", "Why not use https://github.com/coreos/tectonic-installer/blob/master/tests/rspec/lib/tfstate_file.rb#L9 here?", "done", "done", "Just as an observation, you can achieve this effect of constructing the `ssh_master_ip_addresses` array via the `.map` operation on `instances_id`, like this:\r\n\r\n`instances_id.map { |instance_id| AwsSupport.preferred_instance_ip_address(instance_id, @aws_region) }`\r\n\r\nThis ^ expression will evaluate to the same list of master IP addresses, but you would not have to use an explicit variable like `ssh_master_ip_addresses` for that. You could just use that expression as the return statement.\r\n\r\nNot saying you should change anything, just wanted to let you know about this Ruby feature.", "great! forgot about the map thing. thanks so much!", "done", "@cpanato Thanks for updating it here as well."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2493", "comments": ["These changes should go in another PR"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2490", "comments": ["We ship a `tectonic-console-tester` for each version of console - the two versions must match when running tests.", "@kans Thanks for the note! Good to know.\r\n\r\nWhat do you do, when you want to release a *test-only* fix?\r\n- Bump both versions anyways\r\n- Bump a subversion in the `tectonic-console-tester` image", "We build and push both images in the same pass, so we would bump both versions for the fix.  \r\n\r\nI don't think this problem will come up too often past the initial merge because we run the same tests before we merge.\r\n\r\nedit: ...and we have tentative plans to run the tests in the tester-image on cluster for releases (actual e2e on our end too).", "Make sure to bring this line back, before merging.", "`tectonic_console_url` is not an attribute of a `cluster` instance.\r\n\r\nWould you mind adding a function to the `Cluster` class like e.g.:\r\n\r\n``` ruby\r\n  def tectonic_cluster_url\r\n    \"#{@name}.#{@tfvars_file.terraform_base_domain}\"\r\n  end\r\n```", "Really? It seems working on AWS. I inspired this line from the following:\r\n\r\n```\r\n  describe 'Interact with tectonic console' do\r\n    before(:all) do\r\n      @driver = WebdriverHelpers.start_webdriver\r\n      @login = Login.new(@driver)\r\n      @console_url = @cluster.tectonic_console_url\r\n    end\r\n```\r\n\r\n```\r\n\"Env\": [\r\n                \"BRIDGE_AUTH_USERNAME=quentin.machu@coreos.com\",\r\n                \"BRIDGE_AUTH_PASSWORD=*******\",\r\n                \"BRIDGE_BASE_ADDRESS=qmachu-test-int.tectonic-ci.de\",\r\n                \"BRIDGE_BASE_PATH=/\",\r\n                \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\",\r\n                \"NODE_VERSION=8.9.2\",\r\n                \"YARN_VERSION=1.3.2\"\r\n            ],\r\n```", "you can use the `tectonic_console_url`it is already defined for each platform", "just call `@cluster.tectonic_console_url`", "@cpanato @Quentin-M Sorry, I missed the inheriting platform specific cluster classes. Your approach is absolutely right.", "Would you mind extending the `expose-environment-variables` section in the `tests/README.md` in the same PR?\r\n\r\nhttps://github.com/coreos/tectonic-installer/blob/master/tests/README.md#1-expose-environment-variables\r\n", "Done.", "@Quentin-M Thanks! :)", "@Quentin-M The tests fail constantly with `./tests/jenkins-jobs/scripts/report-status-to-github.sh: No such file or directory`.  This means that Jenkins fails  somewhere before `unstash 'clean-repo'`, so that the `report-status-to-github.sh` is not unstashed when `reportStatusToGithub` is called.\r\n\r\nI got a simple suspicion: `withCredentials` expects a simple array. Both `creds` and `quayCreds` return an array themselves, thereby `[creds, quayCreds]` returns an array containing two arrays instead of just an array of credentials. Can you try combining the two arrays instead like e.g. `withCredentials(creds + quayCreds)`?", "You are darn smart. Looking at how I do it there: https://github.com/coreos-inc/tectonic-release-automation/blob/d42f6e3/jobs/build-tectonic/Jenkinsfile#L101, I have `withCredentials([[1], [2], ...])`. Looks like here, `creds` is already `[[1], [2], ...]`, so indeed it cannot be wrapped more.", "Why are we configuring these directly in the code? Shouldn't this be coming from config params to Jenkins or some other repository? I'd really like to get away from dumping _all the things_ into the installer repo. It's not scalable.\r\n\r\n/cc @mxinden @sudhaponnaganti ", "we can add a input parameter in our Jenkins pipeline", "Having a parameter was definitely the idea behind using container images. That's why I pushed literally for *weeks* against the initial pod design that was proposed. RA should provide that list for you guys.", "OK then... unless there's a good reason to ship this _inside_ the source code I'd suggest moving this to a Jenkins param before merging.", "agree", "The version of our test image is tightly coupled to the version of Console and it is not backwards compatible.  Eg, a PR to bump Console would require changing Jenkins and would break the tests in master.  It may not make sense to store the test version at this exact spot, but I think it should be in code somewhere.\r\n\r\n| Shouldn't this be coming from config params to Jenkins or some other repository?\r\n\r\nThe original idea was that the tester would be a different repo but have the same exact version of Console, but we have been churning through test versions trying to get the tests to pass. ", "can we do a docker pull again here? or it might be running a out of date image when we force push an image to the same tag."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2486", "comments": ["Nit: everything else in this vars list is alphabetized. Please move up to line 19", "nit: remove this shellcheck directive since it is no longer needed", "I think this is a little backwards. Reading the comment:\r\n\r\n> selfHostedEtcdManifests represents the manifests that are ignored by testAllResourcesCreated when manifestSelfHostedEtcdEnv isn't set to empty string\r\n\r\nSo, when `SMOKE_MANIFEST_SELF_HOSTED_ETCD` is set to `true` then `selfHostedEtcdManifests` is appended to the list of manifests to ignore. Otherwise the manifests to ignore is just `bootstrap`. So, if we are eliminating self-hosted etcd testing, then we should never have `SMOKE_MANIFEST_SELF_HOSTED_ETCD` set to true, so the ignored manifests should *always* be *just* `bootstrap`.\r\n\r\nPlease change so that\r\n```go\r\ndefaultIgnoredManifests = []string{\"bootstrap\"}\r\n```", "This entire slice can be removed per comment above", "since we are never appending anything to `defaultIgnoredManifests`, please consider cleaning this up by eliminating `ignoredManifests` and instead directly using `defaultIgnoredManifests` to avoid allocating another variable for no reason:\r\n```go\r\nerr := retry(allResourcesCreated(manifestsPathsSp, defaultIgnoredManifests), t, 30*time.Second, max)\r\n...\r\n```", "Fixed", "removed", "Done", "fixed"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2479", "comments": ["This is just a temporary image. This is a chicken and egg problem, because of the fixed `rake` option introduced in this PR, but not present in our current image. Thereby I am introducing this temporary image which will be removed once https://github.com/coreos/tectonic-installer/pull/2472 is merged."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2476", "comments": ["s/get a/got an/", "`system` returns whether the command succeeded or not. Could you react on that exit code? Something like https://github.com/coreos/tectonic-installer/blob/master/tests/rspec/lib/cluster.rb#L170", "why using \\` and not just `system` which returns the exit status right away?", "How about using `with_retries` here? https://github.com/coreos/tectonic-installer/blob/master/tests/rspec/lib/with_retries.rb", "s/apply reach/apply to reach/\r\n\r\ns/to/before we/", "done"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2467", "comments": ["nit: can you update this description to match the new name? e.g.: `works with aws (existing VPC)`.", "Done. Thanks."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2465", "comments": ["nit: maybe rename the file to kubernetes-addon-operator.yaml?", "nit: maybe rename to appversion-kubernetes-addon.yaml to be consistent to other files?", "We can just add `kubectl create -f update/operators/kubernetes-addon-operator.yaml` below line 219", "Same for the appversion yaml", "for the install mode, shouldn't we leave the currentVersion empty?", "yup fixing"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2460", "comments": ["@coresolve the k8s-notebootstrapper service already bindmounts in /etc/ssl/certs/ca-certificates.crt [0]. Do you explicitly need all of /etc/ssl? If so, you should omit the first bind mount, since it's being stomped.\r\n\r\n[0] https://github.com/coreos/tectonic-installer/pull/2460/files#diff-dea3ad9663a5b686a1d43a0d5d7b167eR18", "JW, why is this needed?", "I've pulled the other mount. We need it to support things like egress proxy where all traffic is sent to an env set proxy server.", "Needed to makes sure we pull in settings like: \r\n```\r\nHTTP_PROXY=thisisabadidea:3279\r\nHTTPS_PROXY=stillbad:3279\r\n```\r\netc", "I'm going to put this back"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2459", "comments": ["Would you mind making the ct version configurable (See `DOCKER_VERSION`).\r\n\r\nIn addition can you add a comment `# Install container linux config transpiler`?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2457", "comments": ["@kyoto  @squat  now I realize this will fail if we have more then 2 builds at the same time. We need somehow to overwrite this with random or I can change this in the rspec code."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2455", "comments": ["Can you check if this is needed?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2454", "comments": ["the convention is to prefix all top-level variables with `tectonic_`. let's rename `extra_storage_params` to `tectonic_extra_storage_params`, etc.", "naming question: is it necessary to prefix with `extra_`? or would `tectonic_storage_params` be more concise?", "couldn't we just check if extra_storage_params_list is not empty so no need to coordinate both variables?", "just so we are aware this most likely won't work as gcp is currently not using --cloud-provider flag", "a list type parameter cannot be parsed as bool, hence the dual parameters:\r\n```\r\n* data.template_file.init: 1 error(s) occurred:\r\n\r\n* data.template_file.init: At column 3, line 1: condition must be type bool, not type list in:\r\n\r\n${var.extra_params_list ? \"parameters:\\n  ${indent(2, join(\"\\n\", var.extra_params_list))}\" : \"\"}\r\n```", "Good catch. Similar to #51. I think we should open a separate ticket for that, though.", "@kalmog I believe the suggestions is to use https://www.terraform.io/docs/configuration/interpolation.html#length-list- to determine if the list is empty or not and make decisions based on that", "yep something like ```\"${length(var.extra_storage_params) > 0 ? \"parameters:\\n  ${indent(2, join(\"\\n\", var.extra_storage_params_list))}\" : \"\"}\"```"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2452", "comments": ["Looks like you have to change the `attr` to `path`", "The problem is that a variable `path` already exists in the outer scope, but using `path: attr` did look odd. I've changed it to use a loop variable instead so that it doesn't look strange."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2437", "comments": ["We should stick to either camelCase or snake_case. The [Groovy documentation](https://stackoverflow.com/a/14534685/4011134) follows the latter. Would you mind changing this and the two definitions above to camelCase?", "done!! \ud83d\ude04 "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2436", "comments": ["what is `fin`?", "I guess it is a metaphore for `FIN` packets, aka \"end\", I agree this could be named more idiomatically, i.e. `exit_code`?", "ok"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2433", "comments": ["`vpn_tunnel` needs to be passed to `withRunningClusterExistingBuildFolder`", "done"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2430", "comments": ["Is this still needed?", "wooopsss :/ my bad, will fix that tomorrow morning ", "done"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2421", "comments": ["couldn't we just run `rm-assets.sh` as a ExecStartPost in ~~bootkube~~ tectonic service to alleviate dependency hassle? then each platform implements the cleaning up as they wish (basically adding or not the cloud storage api call)", "is this meant to be always disabled?", "yes the idea is for it to be path-activated", "some platforms don't have the notion of `rm-assets.sh` which semantically only deletes remote assets.\r\n\r\nLocal assets are being removed inside `tectonic.sh` but here I believe another service makes sense.\r\n\r\nPlatforms not supporting pull semantics (openstack, vmware, baremetal) don't need this service.", "We also internally discussed the idea of running a one-shot k8s Job post-install, but this is better punted to a later refactoring (track 2), as this adds yet more manifest skew.", "do we need to ignore lifecycle changes on the bucket too even though only the one file is changing?", "When I did experimentation locally and removed one file from the bucket, this affected also the bucket itself, hence I had to add this here."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2409", "comments": ["`coreos`*", "This should probably be the ALM operator version, no?", "thanks!", "thanks!", "Need the same annotation for the deployement as well so that the operator can be created.", "Also need to add the \"manged-by-channel-operator\" label, see: https://github.com/coreos/tectonic-installer/pull/2522"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2402", "comments": ["I thought the labels are supposed to match the selector labels", "Discussed clarification offline", "side note: I think the label was here in case of orphan pods, but I am fine with removing it as orphan pods should be taken care of by the deployment/daemonset they belong."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2398", "comments": ["Why just node1?", "just for debugging purposes @squat ", "Why initialize output to empty string? Why not just do `output = \"Journal of #{service} service (exitcode #{exit_status})\"`", "done"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2384", "comments": ["This script has dozes of operations that could fail, but the script does not exit on failure. We should exit on failure and simply retry the entire process if there was a failure.", "We need this complicated escape sequence because in the script's previous form, `/[a-zA-Z]$//` was not surrounded in single quotes, meaning two problems:\r\n 1. `/[a-zA-Z]$//` could have variables expanded by the shell running s3-puller; and\r\n2. the sed command was actually executing `sed s/[a-zA-Z]$//`, so the `/[a-zA-Z]$//`  could also variables expanded by the subshell created by docker.", "\ud83d\udc4d ", "good catch \ud83d\udc4d this also amplifies the necessity to this in code rather than in a shell."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2379", "comments": ["\"dns managed zone\"?", "The following diagram illustrates a 3 master and 6 worker setup deployed in the `europe-west1` region:", "A [tcp global load balancer]() is being used for load balancing the master machines.", "This setup can be improved as cross region load balancing is not needed and might introduce latency issues.", "An upstream issue (https://issuetracker...) related to healthchecks for external/internal regional load balancing prevents machines not running bootkube to join the cluster.", "Until this issue is resolved, cross region load balancing must be used to bootstrap an HA cluster.", "Currently the existing networking options (flannel/canal/calico-bgp) can be used.", "Instead of using the default account, a dedicated service account can be created with at least the following roles: ", "should be \"logging\"", "s/enable/enabled/", "s/next/following/", "Consider reordering to:\r\n```md\r\nEnsure that the DNS zone for the account is already created and available in [Cloud DNS](https://console.cloud.google.com/net-services/dns).\r\n```", "either:\r\n\"a cross region global load balancer\"\r\nor \r\n\"cross region global load balancing\"", "This is a funny construction in English. Consider changing to:\r\n`Doing so would require setting ```--configure-cloud-routes``` in the controller manager and ```--network-plugin=Kubenet``` ...`", "where should the ```--network-plugin=Kubenet``` flag be set?", "Single backticks are enough for all of these. I don't think triple backticks are needed."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2375", "comments": ["Update this once we build a new tuo image.", "Update this once we build a new kao image.", "merge error?", "Is this safe to remove completely?", "Again, merge?", "Yeah, looks like it's left by the resolution of the merge conflict.", "Will remove.", "This config is managed and will be created by the TUO as well.", "Fixed", "Can you also remove:\r\n* `console`\r\n* `stats_emitter`\r\n* `stats_extender`\r\n??", "Fixed.  Also removed the error server image.\r\nWe probably also need to remove those dns, heapster images.", "Need to remove the reference to error_server here", "done", "in bare metal it is failing because it not find this config map\r\n\r\n```\r\n2m          2m           1         tectonic-channel-operator-65bbfb98c8-f2tvv.1506570072eca483             Pod                                                          Normal    Scheduled               default-scheduler                Successfully assigned tectonic-channel-operator-65bbfb98c8-f2tvv to node1.example.com\r\n2m          2m           1         tectonic-channel-operator-65bbfb98c8-f2tvv.150657007f4fffa6             Pod                                                          Normal    SuccessfulMountVolume   kubelet, node1.example.com       MountVolume.SetUp succeeded for volume \"certs\"\r\n2m          2m           1         tectonic-channel-operator-65bbfb98c8-f2tvv.150657008b2e048c             Pod                                                          Normal    SuccessfulMountVolume   kubelet, node1.example.com       MountVolume.SetUp succeeded for volume \"default-token-c7lvc\"\r\n2m          2m           1         tectonic-channel-operator-65bbfb98c8-f2tvv.150657014200c196             Pod          spec.containers{tectonic-channel-operator}      Normal    Pulling                 kubelet, node1.example.com       pulling image \"quay.io/coreos/tectonic-channel-operator:0.6.2\"\r\n1m          1m           1         tectonic-channel-operator-65bbfb98c8-f2tvv.150657055faa24da             Pod          spec.containers{tectonic-channel-operator}      Normal    Pulled                  kubelet, node1.example.com       Successfully pulled image \"quay.io/coreos/tectonic-channel-operator:0.6.2\"\r\n1m          1m           5         tectonic-channel-operator-65bbfb98c8-f2tvv.150657055fd9e877             Pod          spec.containers{tectonic-channel-operator}      Warning   Failed                  kubelet, node1.example.com       Error: configmaps \"tectonic-config\" not found\r\n1m          1m           6         tectonic-channel-operator-65bbfb98c8-f2tvv.150657055fdb0d0f             Pod                                                          Warning   FailedSync              kubelet, node1.example.com       Error syncing pod\r\n1m          1m           5         tectonic-channel-operator-65bbfb98c8-f2tvv.150657058b78b3ea             Pod                                                          Normal    SandboxChanged          kubelet, node1.example.com       Pod sandbox changed, it will be killed and re-created.\r\n1m          1m           5         tectonic-channel-operator-65bbfb98c8-f2tvv.15065706500a50a8             Pod          spec.containers{tectonic-channel-operator}      Normal    Pulled                  kubelet, node1.example.com       Container image \"quay.io/coreos/tectonic-channel-operator:0.6.2\" already present on machine\r\n2m          2m           1         tectonic-channel-operator-65bbfb98c8.15065700712deaaf                   ReplicaSet                                                   Normal    SuccessfulCreate        replicaset-controller            Created pod: tectonic-channel-operator-65bbfb98c8-f2tvv\r\n2m          2m           1         tectonic-channel-operator.150657006cf2c2ad                              Deployment                                                   Normal    ScalingReplicaSet       deployment-controller            Scaled up replica set tectonic-channel-operator-65bbfb98c8 to 1\r\n```", "But it will eventually come up once the configmap is installed by the tuo."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2372", "comments": ["Is it necessary to move this out of the `build` folder?", "Whats is the needed difference between `<<` and `+=`?", "I realize we do a cleanup then all logs are wiped. that's why I move to the rspec folder", "https://stackoverflow.com/questions/41375818/operator-appears-to-modify-frozen-string"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2364", "comments": ["i dont have a strong opinion on this, but I guess we should use the ips we get from the terraform console.", "Thanks for feedback @cpanato \r\nWe use a manage group https://cloud.google.com/compute/docs/instance-groups/ and instance templates for masters machines so there's no awareness from terraform about the specific machine ips.\r\nWe could use a ruby client library but all are quiet abandoned. gcloud cli seems to have more energy focus and support from google and this is specific use with no potencial grown so it seems the simplest way to go to me here\r\n", "use `auth_command = \"gcloud auth activate-service-account --key-file=\\\"${GOOGLE_APPLICATION_CREDENTIALS}\\\"\"`", "will `gcs-puller.sh` retry? If so, how often, and does it have back-off?", "I suggest we move this to Go code eventually.", "actually ... rather sooner than later ;-) Do you mind to open an issue for that?", "Ah it is used here, sorry ;-) Please update `init-assets.service` inside `modules/igntion` and use the implementation from aws.", "Done!", "added basic retry now. Thanks!", "This invocation has a ton of hidden network operations inside of `detect-master`, which could all fail. I suggest we add a retry around this as done in: https://github.com/coreos/tectonic-installer/pull/2384/files#diff-a8f67da9bff3df820b94ce8b1c1b3cd5R5", "Docker automatically downloads images if they are not present. I would prefer to rely on that build-in logic in docker rather than on this alias, which is a little over-engineered IMO.", "The more appropriate construct is a POSIX function, rather than an ALIAS IMO. This way the operation does not have to be forced into a tricky one-liner.\r\n\r\nConsider defining:\r\n```sh\r\ngsutil() {\r\n    docker run --net=host -v...\r\n}\r\n```", "does this container really need to be interactive?", "What if the remove operation fails due to some network issue?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2363", "comments": ["From my side we don't have to carry on adding the `.0_golang1.9.1` tag to the conformance test image. I just did so, to update the already existing `v1.7.5_coreos` without removing the old one.", "done"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2362", "comments": ["The worker is missing the `var.ign_update_ca_certificates_dropin_id` service", "not for this pr but we really need to refactor this platform so that it uses the same ignition format as all the other platforms", "totally agreed \ud83d\udc4d ", "fixed, thanks!", "/cc @lucab This works, because we are enforcing rehashing all files. Rather the default service should work, but openssl is pointing to the wrong default bundle.", "@s-urbaniak Why did you need to add ECR permissions?", "It might've been a copy&pasta oversight, but without this the machine didn't seem to boot.", "I'm new to Terraform and was scratching my head about this after not finding `count` in [the `aws_s3_bucket_object` docs][1].  It turns out it is a [meta-parameter][2] (more [here][3]).  I thought I'd add this note in case it helps any other Terraform newbies ;).\r\n\r\n[1]: https://www.terraform.io/docs/providers/aws/r/s3_bucket_object.html\r\n[2]: https://www.terraform.io/docs/configuration/resources.html#meta-parameters\r\n[3]: https://www.terraform.io/docs/configuration/resources.html#using-variables-with-count"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2359", "comments": ["Just a small nit: this commit alone is actually incorrect; it duplicates several fields and then the next commit cleans it up. Would make sense to redo both the commits but it is not a blocker at all."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2358", "comments": ["Why `\"$${ASSETS_PATH:?}/\"*` and not just `\"$ASSETS_PATH/*\"`? All other parts of the file assume ASSETS_PATH exists and make that assumption before the asset_cleanup function is run. If we want to ensure the variable is set, then set the sh option `-u` at the top of the file e.g.:\r\n```sh\r\n#!/bin/sh\r\nset -eu\r\n```", "This operation could fail due to transient network issues. Please consider adding a loop around this like we do in s3-puller.sh: https://github.com/coreos/tectonic-installer/blob/master/modules/ignition/resources/bin/s3-puller.sh#L33", "the syntax itself is due to this automatic lint check: \r\nhttps://github.com/koalaman/shellcheck/wiki/SC2115\r\n\r\n```In ../modules/tectonic/resources/tectonic.sh line 107:\r\n  rm -rf \"$ASSETS_PATH/*\"\r\n         ^-- SC2115: Use \"${var:?}\" to ensure this never expands to /* .```", "OK, well, either way. Not a blocker from me.", "Couldn't we call the s3 remove function from the puller script so we pull, move and remove in one go and we avoid to introduce a new systemd dependency?  ", "(Unfortunately) the puller script is also reused in download kubeconfig once the cluster is up, so it cannot include logic removing things from S3."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2357", "comments": ["Won't this conflict with @s-urbaniak PR?", "@alexsomesan the @s-urbaniak's PR add the functionality and here we are using that \ud83d\ude04 ", "As far as I can tell `stderr` and the `exitcode` is unused. Can you check whether they are nil / zero before continuing. Otherwise we loose maybe helpful error messages.", "Teamwork! :-)\r\n[https://media.giphy.com/media/TTfj0eequY6ru/giphy.gif](https://media1.giphy.com/media/26h0oQ3erWGYjdSi4/giphy.gif)", "Shouldn't the `ip` be encoded in the file path as well? Otherwise we will overwrite the previous logs when we call `save_docker_logs` on two e.g. master machines.", "Can you add \"what\" failed here? Like e.g. `failed to retrieve docker logs on ip #{ip} with: #{e}`.", "This seems to duplicate the logic in `save_docker_logs`. How about extracting it into a function instead?", "Am I right, that these logs will be saved in `tests/rspec/logs`? How about saving them in `build/#{CLUSTER}/logs` instead. So whenever someone runs RSpec twice in parallel the logs will not be overwritten for one of the two executions.", "As far as I can tell you want to both log the outputs as well as save them to a file, right? How about first writing everything  into `output` and then both print and save it? This way you don't need to format the strings twice.", "true, thanks!", "ok", "I did some tests locally and something in the docker logs I saw some strings in the stderr", "ok sure, just making my life a little bit easy \ud83d\ude04 ", "ok", "actually not because the filename will contain the ip", "Yes exactly, but as far as I can tell, this code never looks at `stderr` or `exitcode`, right? So when `docker ps -a --format '{{.ID}} {{.Names}}'` fails, we never know why it failed.", "done", "done", "done", "done", "How about adding the `artifactDaysToKeep` and `artifactNumToKeep` option in the `logRotator`? Or is this not needed?\r\nhttps://github.com/jenkinsci/jenkins/blob/master/core/src/main/java/hudson/tasks/LogRotator.java#L70", "This will swallow any error messages that were thrown earlier. Please rescue like: `rescue => e`.\r\n\r\nThis helped me understand the rescue system of Ruby: https://robots.thoughtbot.com/rescue-standarderror-not-exception", "Here you can raise the exception `e` you caught in line 194.", "s/service/container", "done", "done", "done", "done"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2352", "comments": ["@cpanato This reduces the stash size from ~5500 files down to 725 files. Hope this brings more stability and speed. We need to keep in mind, that the vendor folders are not included in the `clean-repo` stash.", "do we need to have the vendor folders for our tests?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2346", "comments": ["Both a virtual and serial console are already specified. We do not need this line", "Ah, this seems to have crept in due to a recent rebase. I'll update.\r\nedit: sorry, it was not due to rebase, it was copy-pasted from edit on my server."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2327", "comments": ["is this missing a default value?", "Seems like it -- the changes in this stanza result from https://github.com/coreos/tectonic-installer/pull/2322, I think.", "@joshix please update your local copy of `terraform-examples` to the newest version. There used to be an early bug which caused variables to be rendered in a wrong way. I re-executed `make docs examples` and have a clean state, as is also reported by CI.\r\n\r\nI will update this PR accordingly."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2325", "comments": ["@crawford any feedback on this?", "Seems fine. You'll want to give it a test run since the OS team doesn't test BBR specifically (though, I can't imagine what might fail)."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2320", "comments": ["lines 12 and 13 need to be indented. Please run `terraform fmt platforms/aws/variables.tf`. Also, we will need to regenerate docs. Please run `make docs examples` and commit the result as a separate commit.", "@squat Are you sure the heredoc should be indented? If you look at `tectonic_aws_config_version`, the heredoc lines are not indented. It makes sense to me, as the indentation wouldn't only be stylistic but also be part of the documentation string."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2314", "comments": ["just a nit: let's add that \"This setting is ignored if user provided certificates are used.\"", "Done :)"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2305", "comments": ["s/have/has", "`prepare_assets` overrides the `terraform.tfvars` file. Doesn't that then undo your worker count changes?", "Why not make `wait_nodes_ready` part of `wait_til_ready` (append at the very end)? Waiting for all workers to become ready should be part of our normal startup tests as well. Then the entire `update_cluster` function is not needed anymore. Instead you can call `start` from the `_spec.rb` file.", "Why not use the `with_retries` logic here?", "Raising an error without an error message seems not to be a good practice to me. Can you either throw a custom error message (See https://github.com/coreos/tectonic-installer/blob/master/tests/rspec/lib/kubectl_helpers.rb#L11), or add an error message to the `StandardError`?", "`StandardError` can be a lot of different issues, not only your `raise StandardError` from before. Thereby if anything else fails here, debugging it is very difficult, as this rescue just swallows the error message.", "How about making the above two `puts` statements part of the error message instead?", "I would prefer `wait_nodes_ready` not only to check whether all present nodes are ready, but also that the amount of ready nodes matches the amount of nodes specified in the `terraform.tfvars` file. That way we don't need the check below anymore. What do you think?", "This doesn't really configure the worker, but set the worker count. How about `set_worker_count`?", "no, because we read the once and the values are in the `@data` variable.", "sounds good I will update that", "ok", "ok, will refactor", "Ok, but there is no need to override the file itself with the initial tfvars file during an `update_cluster`, right?", "Is there an urgent need to bump this? I  would prefer small functions over big ones.", "How about making this part of `wait_til_ready` at the end of the function?", "See comment below: If we make `wait_nodes_ready` part of `wait_til_ready`, this function call is not needed anymore.", "See comment below:  If we make `wait_nodes_ready` part of `wait_til_ready`, instead of introducing this function, one could just call `start` right?", "If `nodes_ready` is only containing `false`, `nodes_ready.uniq.length` will be `1` as well, right?", "How about `skip \"This test is not ready to run in #{platform}\" if (platform == 'metal') || (platform == 'azure'`)", "I think `wait_nodes_ready` already checks not only, that all nodes are up, but also that all nodes exist as described in the `tfvars_file`. If that is checked in the function, this logic doesn't need to be repeated here.", "Again, the check whether enough nodes exist is part of `wait_nodes_ready`. It can be removed here.", "Is this and the following linebreaks needed or by accident?", "\ud83d\udc4d ", "Getting nodes of a cluster can be extracted into a function `get_nodes` of the `cluster.rb` class, what do you think? ", "Am I right that this waits for 1h? To me that sounds too long. If a cluster needs 1h to come up, after the api-server is available and the `bootkube` and `tectonic` service is done, it's time to fail. What do you think?", "Why setting `nodes` to empty string?", "Am I right, that this line can also be executed, when `kubectl` works fine, but doesn't return all nodes as ready? If so, this error message is misleading. How about something like `waiting for all nodes to become ready timed out`.", "In addition, can't this be replaced with `with_retries` instead, including the `sleep 20` below?", "we can make, but I also would like to have the `update_cluster` to be more explicit in the action we are doing. We are not starting a cluster, we are updating that. make sense?", "the other test I agree to remove, but this tests this check needs to be here, otherwise, what should I test?", "You can wrap `@cluster.update_cluster` like this:\r\n\r\n```ruby\r\nexpect { @cluster.update_cluster }.to_not raise_error\r\n```\r\n", "@cpanato What do you think of this idea?", "\ud83d\udc4d ", "Is this and the following linebreaks needed or by accident?", "done", "\ud83c\udf2e ", "removed", "done", "Is this and the following linebreaks needed or by accident?", "Is this and the following linebreaks needed or by accident?", "Is this and the following linebreaks needed or by accident?\r\n", "\r\n\r\nIs this and the following linebreaks needed or by accident?\r\n", "@cpanato As discussed, the `.done` files will stay. So why replacing the simple alias here?\r\n```ruby\r\ndef update_cluster\r\n  start\r\nend\r\n```", "done", "done", "done", "done", "done"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2296", "comments": ["`-r` does a recursive remove. `ouput.log` should be a single file, right? Thereby this option would not be needed.", "Don't you need to inject the AWS credentials? ` withCredentials(<xxx>)`", "Add ` node('worker && ec2') {` above this line, otherwise you will get `Required context class hudson.model.Node is missing`.", "In addition please also add ` forcefullyCleanWorkspace()` to make sure your workspace is clean.", "there is no aws credentials you need to set that", "Please make sure to have a newline at the end of this file. https://robots.thoughtbot.com/no-newline-at-end-of-file", "Why is this called `flaked`? Is this only for the `flaked` builds?", "If I am not mistaking`CHANGE_ID` will not be defined on a branch build, only on PR builds. Thereby e.g. on `master` this will result in `OUTPUT=\"-xx\".log` which might not be ideal, right?", "What about 'log-analyzer-installer' ?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2294", "comments": ["s/then/than", "A test should be non-disruptive. Changing the environment might influence preceding tests. Could you make a snapshot of `ENV` in a `before` block and recover from it in an `after` block?", "See: https://github.com/coreos/tectonic-installer/blob/master/tests/rspec/spec/azure/private_external_spec.rb#L12", "what is `full_name` used for?", "done", "done", "done"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2293", "comments": ["Can you add a comment here, so we don't forget why we are waiting here?\r\n\r\nSomething like `Giving downstream job enough time to scan parameter configuration in Jenkinsfile.`", "done"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2291", "comments": ["what do you think to we use labels in the tests? because if the environment variable is not set the test will always report passed, and in the report will say conformance test passed even if this never run\r\n\r\nhttps://stackoverflow.com/questions/5069677/how-do-i-run-only-specific-tests-in-rspec", "then we can remove this", "Addressed in idiomatic way. Thanks for the tip @cpanato!"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2290", "comments": ["As this function is executed at the beginning of the build, `Build_Status` will always be empty, right?", "Can you add a comment above this function. Something along the lines of: `Function prints meta data used to aggregate and analyse build logs in long term storage.`", "Can you add a space before the `+`? Same for following lines.", "Do you need this line? This will only inject credentials into the environment, which I would prefer to not save in any long term storage system.", "@mxinden I prefer not too, because then I would have to change the logic of my Logstash and write a custom pattern. ", "Can we create a separate function and call that one at the end of the build?", "To get the build status? Jenkins prints it by default at the end of the build. (e.g. \"Finished: SUCCESS\")", "build status will be null because the job did not finish"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2288", "comments": ["Do not use \"We\". consider changing to:\r\n```\r\nIf set to `true`, all etcd endpoints will be configured to use the \"https\" scheme.\r\n```", "Avoid using \"we\". Also, it's not an assumption that we don't self-sign; we actually know that we don't use the self-signed certs at all. Consider changing to:\r\n```\r\nNote: if this variable is defined, the installer will not create self-signed certificates for etcd.\r\nTo provide a CA certificate to trust the etcd servers, set \"tectonic_etcd_ca_cert_path\".\r\n```", "These two lines are out of place IMO. They _could_ go in the description of `tectonic_etcd_cert_path` but let's just keep this simple for now and omit them.", "Why is self_signed being turned into an integer? I think it is much easier to reason about these things as booleans (or their terraform equivalent). Furthermore, although in POSIX we treat exit code 0 as a positive, in most interpretted languages, 0 is a falsey value and 1 is truthy. In fact, in terraform we use `count = 0` to disable components. So I would ask that if we absolutely need to go the route of converting this variable to an integer that we reverse the values. Still, I would prefer to keep this a boolean.", "What if TLS is disabled? then we don't want to provision anything here.", "Addressed", "Addressed", "Addressed", "Addressed", "Addressed", "There is something funny in the second sentence. Please correct it to say:\r\n```\r\nNote: if this variable is defined, the installer will not create self-signed certificates for etcd.\r\n```"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2285", "comments": ["@jonmosco, please fix the spacing in this string then LGTM", "`s/datacenter,host,vm,/datacenter, host, vm,/`"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2284", "comments": ["this most probably needs a migration for KVO. Do we really need this setting now?\r\n\r\n/cc @diegs ", "This would need to go into a config map for the potential tectonic network operator, /cc @rithujohn191 ", "see above, we potentially need a migration for this setting for all other platforms, if this is a showstopper for GCP.", "see above", "is there any possibility to do this via ignition and some datasource in terraform itself? If possible it would be great to leave resolving the hostname on GCP to intrinsic CL methods, /cc @lucab @crawford ", "Isn't `10.2.0.0./16` dependent on the `tectonic_cluster_cidr` value?", "this is tricky, as we have no upgrade path for the kubelet for now. Changing the manifest with dynamic values leaves an open door here. Is it possible to get along without these settings? /cc @diegs @aaronlevy ", "see above. for the kubelet it is even trickier, since no upgrade path exists on the KVO side.", "It's not strictly necessary at the moment. It basically prefixes the resources created by the controllers so it might help to solve the problem of cleaning up the resources. It seems right to have it", "The hostname will still resolve to intrinsic CL methods. This will just set a env variable then used by the kubelet with ```--hostname-override```, haven't found a cleaner way so far. This is needed because of this https://github.com/kubernetes/kubernetes/pull/54504\r\nWe could avoid to use ```--hostname-override``` if we set ```hostname $(hostname -s)``` for the system before running the kubelet", "yup, needs to be injected", "See https://github.com/coreos/tectonic-installer/pull/2284/files#r148466487", "coreos-metadata has `COREOS_GCE_HOSTNAME`, but I don't know if it matches with @enxebre requirements.\r\n\r\nIn any case, please don't use `kubelet.env` to store this, as it has very specific semantics and ordering during bootstrap and is also manipulated by operators. Just use your own cloud-specific dropin.\r\n\r\n/cc @squeed I think we may want have an env-dir at some point for such cases.", "Also annoyingly, there is a limit of 300 routes, globally, across a GCP account. This can be raised, but it requires a manual request.", "For kubelet changes, for GCP purposes we can accept a one-time change because we don't manage it. There will be skew but we'll have to track it. However, we need to guarantee that for non-GCP then the resulting kubelet.service file is the exact same as it has been (forever).\r\n\r\nAlso, in the future there will be no way to change it under the current paradigm, so this is your one chance to make GCP-related changes.\r\n\r\ncc @aaronlevy ", "Same comment as above; if there are GCP-only changes that have to go in I'm of the opinion that it's ok to introduce skew under the current paradigm as a one-shot. But you have to know that (a) this can never change again for GCP either and (b) the `hostname_override_command` can only be used for GCP. All other platforms must have identical kubelet.service files as before."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2273", "comments": ["Please add a \u201c.\u201d between the two sentences and add a \u201c,\u201d after \u201cWhen set\u201d so it reads better.", "We need to declare \u201cetcd\u201d in platforms/gcp/etcd otherwise GCP will fail to build.", "Same here, let\u2019s declare etcd in platforms/vmware/etcd so as to not break this platform. ", "fixed", "fixed"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2271", "comments": ["Would you mind updating this reference as well (https://github.com/coreos/tectonic-docs/blob/master/Documentation/platform-lifecycle.md)"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2245", "comments": ["The first implementation of this retry logic is in the ssh lib and now we have two more copies. We should now break this into a little function so that the implementations don\u2019t drift or get written incorrectly. Let\u2019s make a little retry lib", "If I am not missing something here, `import_key_pair` is only executed once per test. The logic that exceeds the limit is: https://github.com/coreos/tectonic-installer/blob/master/tests/rspec/lib/cluster.rb#L162 in the bootstrap phase. So adding the `rescue` here will only fix the result, not the root cause.\r\n\r\nThe reason why we are refreshing the master ips so often in [`wait_for_service`](https://github.com/coreos/tectonic-installer/blob/master/tests/rspec/lib/cluster.rb#L162) is because we can't be sure, that at the first point in time, all master machines are returned by the `master_ip_addresses` function.\r\n\r\nI guess in this [build](https://jenkins-tectonic-installer.prod.coreos.systems/blue/organizations/jenkins/tectonic-installer/detail/PR-2219/3/pipeline/143/) it exceeded in `import_key_paris`, because other parallel builds were in the bootstrapping loop at that moment. @cpanato is that a reasonable theory?\r\n\r\nIf you think `wait_for_service` is the source of this issue as well, @cpanato, I will add better back off into `wait_for_service`, and thereby prevent the request limit exeeded error. (@squat I will extract it into a separate retry function.)", "Can you include something that says how many times this has been retried, like it used to do? e.g.\r\n```ruby\r\nputs \"Error #{e}; retrying in #{sleep_time} seconds\"\r\n```", "Does anything actually use this class?", "How come we are not importing the `with_retries` module in this lib? Is this because of the Object Class changes?", "done", "discussed offline", "discussed offline", "\ud83d\udc4d for importing it here as well."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2242", "comments": ["Please ensure there is an appropriate newline character at the end of this file. You may need to tweak your editor's config for this.", "Please add a single space character after the commas between items in the list."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2233", "comments": ["you can use idx which is the counter", "print \"tf_apply_attempts=#{idx}\\n\"", "or use puts", "Instead of printing the platform on every spec file, why not adding it once to e.g. the cluster factory https://github.com/coreos/tectonic-installer/blob/master/tests/rspec/lib/cluster_factory.rb#L12 ?", "Instead of adding this to every spec file we could instead change the RSpec output format to e.g. `documentation`. @cpanato What do you think?", "sounds good to me.\r\n"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2232", "comments": ["I think we typically try to avoid \"you\" in the docs.Maybe:\r\n```\r\n`tectonic_etcd_backup_size` and `tectonic_etcd_backup_storage_class` must be configured when using this setting.\r\n```", "terminate with a `.`", "terminate with a `.`", ":+1: ", "We have something a little funny going on with the directories for the different self-hosted etcd manifests. As it stands:\r\n`resources/self-hosted-etcd/manifests` -> `./generated/etcd/manifests`\r\n`resources/self-hosted-etcd/bootstrap-manifests` -> `./generated/etcd/bootstrap-manifests`\r\nBUT\r\n`resources/self-hosted-etcd/etcd/bootstrap-etcd-service.json` -> `./generated/etcd/bootstrap-etcd-service.json`\r\nNote the extra `/etcd` in the source directory hierarchy that is not present in the destination. It is a little funny objectively to have manifests in the tree `modules/bootkube/resources/self-hosted-etcd/etcd/...`, since all self-hosted etcd manifests _are_ etcd manifests.\r\n\r\nFor consistency and better comprehension, I suggest we eliminate the nested `etcd` directory inside of the `self-hosted-etcd` dir.", "should be _backed_ up", "used _to handle_ etcd", "used _to handle_ etcd", "size in MB of", "my OCD is concerned about the alphabetization of these variables :stuck_out_tongue: ", "backups to Persistent Volumes", "nit: self-hosted", "even a small description might be useful here", "this should never be `true`, right? only `\"\"`, `\"enabled\"` or `\"pv_backup\"`", "should be `azure-external-self-hosted-etcd`", "good catch, yes, I need to test for empty string", "![sort](https://upload.wikimedia.org/wikipedia/commons/1/1b/Sorting_heapsort_anim.gif)", "good catch ;-)", "indeeed, I'll add a ref to `config.tf`", "I do agree, your proposal is way cleaner.", "ack and the file needs a rename", "Don't need the parenthetical comment anymore.", "Don't need the parenthetical comment anymore.", "Any reason to use JSON here rather than YAML? Most/all of the other manifests are YAML.", "You already have a default set in `config.tf`. Should probably defer to those defaults to prevent mismatch bugs.", "You already have a default set in config.tf. Should probably defer to those defaults to prevent mismatch bugs.", "This is effectively maintained by the upstream etcd team, hence I would prefer not to touch this to avoid maintanance skew/confusion.", "oh definitely, I'll remove this", "actually, this variable declaration is outdated and needs to be removed"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2230", "comments": ["nit: can we make this fully \"master\" rather than abbreviated to \"mstr\"? All other platforms and other resources in this platform use the full word.", "here too"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2229", "comments": ["lowercase `example`", "These map keys should be indented, no?", "same changed for this map and casing", "same changed for this map and casing"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2228", "comments": ["Does this KVO include the console bump above?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2224", "comments": ["We should bump this to 1.7.9 right?", "We can leave as 175 until the real 179 is out.\r\nI did this PR just for the sake of upgrade tests, it expects a payload with newer version than the latest release."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2221", "comments": ["`v0.2.2` appears 4 times, does bazel have some methods to define a central constant?", "The removal of this file is \ud83d\udc4d \ud83c\udf89 :-)", "this is darwin, I don't expect this to run on my machine ;-)", "This is hardcoded for me now. I'll soon have it do autodetection for the arch and OS.", "It does. All versions will eventually be based on variables configurable in a single place.", "do you need to do two-time Dir.chdrir(@build_path) ? it is here and in line 36", "Not really. That's a good point, I'll clean that up."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2220", "comments": ["s/comand/command", "thanks!", "Are the brackets inside the `\"` needed?", "If the exit status is not `0`, why not print out `stderr` as well?", "maybe not", "will remove", "@cpanato \"Remove\"? I though about adding something like:\r\n\r\n```Ruby\r\nwhile (line = stderr.gets)\r\n         puts line\r\nend\r\n```\r\n\r\nWhat do you think? Am I missing something here?", "ahh, got it, ok ", "done", "done"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2219", "comments": ["@cpanato I have build similar logic in #2157 (https://github.com/coreos/tectonic-installer/pull/2157/files#diff-783c678aa2ad2e25fb996138dce80d93R4) in a separate `TFStateFile` class. If you don't mind, I will finish up the PR, get it merged and then you can use it here. What do you think?", "ok", "will close this one", "Sorry, I did a bad job at explaining my changes. They will only introduce the `TFStateFile` class, which your changes could use, they will not do this clean-up.\r\n\r\nI would still very much like to get your clean-up changes merged! Let's adjust this PR once #2157 is merged."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2218", "comments": ["learning ruby, I guess:\r\n```\r\n[\"bootkube\", \"tectonic\", \"kubelet\", \"k8s-node-bootstrap\"].each do |s|\r\n  print_service_logs(master_ip, s)\r\nend\r\n```\r\nis more idiomatic?", "i would use that to avoid duplication"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2216", "comments": ["looks good, let's just add a comment `once INST-566 is resolved, set this to \"latest\"`", "yep! \ud83d\ude04 "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2213", "comments": ["This should probably go in its own dropin (i.e. `/etc/systemd/timesyncd.conf.d/10-tectonic-installer.conf`) and be skipped if the terraform configuration value is not set by the user (to avoid bloating userdata and hardcoding defaults in config)."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2207", "comments": ["In Ruby, the `merge()` method of a Hash doesn't modify that actual Hash instance. Rather, it returns a new copy of a hash, with the contents of the argument hash merged into the old one.\r\nIf you want to modify the env_variables in place, you need to use the `merge!()`(with an exclamation mark) method instead. \r\nDocumented here: https://ruby-doc.org/core-2.4.1/Hash.html#method-i-merge\r\n\r\nAlso, I think the check after unless might not be necessary since the subsequent `merge!` would just overwrite the value of TF_LOG in place in the hash.", "done"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2195", "comments": ["@thorfour if the pod has the critical-pod annotation then it is required to have the criticaladdonsonly toleration to be guaranteed space. Without the toleration:\r\n1. the node will get the CriticalAddonsOnly taint\r\n2. the scheduler will try to schedule the kube-calico pod but since it doesn't tolerate the correct taint, it will not be schedulable\r\n3. so the rescheduler will keep evicting pods from the nodes until the kube-calico pod can be scheduled (which it will never be)\r\n4. go to 2\r\n\r\nTL;DR: if we are removing criticaladdonsonly tolerations then we must remove this annotation as well.\r\n\r\nMore info: https://kubernetes.io/docs/tasks/administer-cluster/guaranteed-scheduling-critical-addon-pods/", "we need to remove the annotation in this manifest as well.", "we need to remove the annotation in this manifest as well.", "Good to know, thanks for that information. I've removed the remaining annotations. "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2191", "comments": ["I'm glad the logs made it in!"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2185", "comments": ["These comments are a little confusing. They say to provide a path but then show the contents of the file. Please make these comments match the descriptions for the other PEM path variables, e.g. https://github.com/coreos/tectonic-installer/blob/master/config.tf#L202", "These variables are not specific to AWS. Please move them out of the AWS-specific variables.tf and into config.tf.", "Since this is not AWS-specific, please add this into the Azure, Openstack, bare-metal, and GCP Terraform as well."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2184", "comments": ["@enxebre please change to: `Tectonic Installer`", "dont need to change, we will need to rewrite this bindings :)", "delete this line and add: \r\n`file(credentialsId: 'GCP-APPLICATION', variable: 'GOOGLE_APPLICATION_CREDENTIALS'),`"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2183", "comments": ["you can do the same and still keep the onliner\r\n`puts \"Waiting for bootstrapping of #{service} service to complete...\\nChecked master nodes: #{ips}\" if (elapsed.round % 5).zero?`\r\n\r\njust a comment dont need to implement if you think it is not useful", "True, just preferred the shorter lines for easier readability."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2181", "comments": ["mention and link to `tectonic-torcx` here?", "Makes sense, good suggestion. Slightly reworded to mention and link to it."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2178", "comments": ["This change here works for other platforms?", "From my understanding Container Linux should be shipping with this identification file, which is expected by systemd so should be fine in any platform. This makes the test deterministic as otherwise the test might be run before update-engine generates the aleph-version file", "This needs to be `TF_VAR_tectonic_gcp_ssh_key`", "please remove `tectonic-` from the name for consistency with other platforms, e.g. https://github.com/coreos/tectonic-installer/blob/master/modules/aws/master-asg/master.tf#L24", "same as below", "This is not correct. This change would revert a fix that was merged in https://github.com/coreos/tectonic-installer/pull/2093. `/etc/os-release` contains the _current_ version when we are actually interested in the _originally_ installed version of CL. This change would not make the test deterministic: what if this SSH command was executed on the node _after_ it rebooted? This is actually what was consistently happening and causing the tests to fail. In any case, a possible change would be to:\r\n```sh\r\nif [ -f /var/lib/update_engine/prefs/aleph-version ] ; then\r\n  sudo cat /var/lib/update_engine/prefs/aleph-version\r\nelse\r\n  source /usr/share/coreos/release && echo \"$COREOS_RELEASE_VERSION\"\r\nfi\r\n```", "\"/etc/os-release contains the current version when we are actually interested in the originally installed version of CL\" thanks for spotting that @squat ", "Will rebase an change this after https://github.com/coreos/tectonic-installer/pull/2167 gets in", "will rebase with https://github.com/coreos/tectonic-installer/pull/2193", "2193 is merged please rebase and lets get this merged as well"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2177", "comments": ["s/api_inernal_elb_dns_name/api_internal_elb_dns_name", "corrected", "nit: Can we deduplicate this by adding a `local`?", "see above", "let's add a newline between `source` and the variables and sort variable names lexically."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2176", "comments": ["This method no longer returns master IP addresses so the name is not representative anymore.\r\nWe should rename it to be descriptive of its current role."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2167", "comments": ["consider removing `-tectonic` from the name. none of the other names use it.", "same as above.", "we should ensure we only create this resource on clusters that actually use Flannel networking.", "remove `-tectonic` from the name for consistency with the other resources and other providers, e.g. https://github.com/coreos/tectonic-installer/blob/master/modules/aws/master-asg/master.tf", "same for this whole file", "same as above for this whole file", "same for this whole file", "this is only used once; is it worth creating this local expression? maybe", "We'll probably move to use routes and kubenet, will handle this in a follow up networking specific PR"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2157", "comments": ["I'm afraid such debug sections will be forgotten around the code once the issues get fixed.\r\nDo you think it makes sense to gate these sections with an environment variable flag so that they only run while that var is set? That way we can also grep the tests code for that var name to discover any stale debug statements.", "@alexsomesan Would a comment with a keyword like `DEBUG` be enough? This way we can grep for it in the code base."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2148", "comments": ["@mrwacky42 Would you mind adding an `Example` section like e.g. in `tectonic_aws_worker_custom_subnets`?", "Our tests are failing with:\r\n`* module.vpc.aws_security_group_rule.master_ingress_ssh: \"cidr_blocks.0\" must contain a valid CIDR, got error parsing: invalid CIDR address: 0.0.0.0`\r\n\r\nAs a wild guess, shouldn't this be `[\"0.0.0.0/0\"]`?", "Indeed it should", "Done."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2146", "comments": ["extra \" at end of line?", "These variables would need to be declared into ```modules/tectonic/variables.tf```. Then the values could be injected from platform/foo/tectonic.tf ", "I believe you want 1440", "I believe you want 1480 if its going to be a default value."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2137", "comments": ["Can this be moved to `ssh.rb`?", "`create_ssh_key` does not export it to AWS or Azure, right?", "As this uses a new socket, we don't need to mount the host socket via Docker in our [Makefile](https://github.com/cpanato/tectonic-installer/blob/f7b9752071a53b5e26db2d3db87318d920043af5/Makefile#L174) anymore, right? ", "How about something more descriptive like `create_if_not_exist_and_add_ssh_key`. ", "This is a very long line. Could you break it up?", "As we are using a new socket here, do we still need to bind the host socket in the [Makefile](https://github.com/cpanato/tectonic-installer/blob/f7b9752071a53b5e26db2d3db87318d920043af5/Makefile#L174)?", "In case a user wants to use her ssh key, the key needs to be mounted in the [`Makefile`](https://github.com/cpanato/tectonic-installer/blob/f7b9752071a53b5e26db2d3db87318d920043af5/Makefile#L166)", "done", "done. i'm really bad with names", "changing the make", "removing", "you right, just export the key and start the ssh-agent", "Just for safety resons, can you add a `ro` for read only access? `-v \"${HOME}/.ssh:${HOME}/.ssh:ro\" \\`. See docker run reference: https://docs.docker.com/engine/reference/run/#volume-shared-filesystems", "done", "Isn't this a duplicate check?", "This is still a reference to `@aws_ssh_key` which will fail, right?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2136", "comments": ["Doesn't [`after(:each)`](https://github.com/cpanato/tectonic-installer/blob/fb5af60866fe1389f81a3260ec168c3a8fc08c52/tests/rspec/lib/shared_examples/k8s.rb#L24) trigger the  `Forensic` scripts already?", "discussed offline :)", "Nit, for legibility, consider renaming this variable to: bootkube_failed_exitstatus, since this is the exit status of the bootkube failed command and _not_ a boolean indicating if the bootkube exit status is failed.", "Same here", "done"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2124", "comments": ["Bare metal cluster", "Correct me if I am wrong: If the subclass doesn't implement a function, the parent function will be used directly. That would mean `initialize` is not needed here.", "Is this still needed?", "Is this still needed?", "I am a little confused by this error message. Does it mean something like \"failed to get the console url to use in the UI tests\"?", "This is the end of the `initial setup`, right? I would suggest `Finished initial setup` then.", "\"once the test i**s** done\"", "s/curent/current", "Where is it being restored?", "done", "i guess so, removing", "done", "done", "done", "done", "we don't need this, removing ", "This builds Ruby from source every time. What's the runtime of this step compared to the other platforms? Is this going to be the step that drags down every PR build?", "This would be better sourced from the cluster config variables.\r\nIt's going to get skewed at some point if maintained here separately and that is going to be a hard issue to debug, due to uncertain behaviour of mismatching kubectl vs api versions.", "Same thing about versions. We already have a few different places where we track Terraform versions that need to be kept in sync.\r\nThis one is not critical though, because it will be fixed by the build logic revamp.", "it builds in the first time if other builds happen in this slave it will bypass the installation. I can try to install when booting the packet machine. Can I do that as a follow-up? @alexsomesan ", "can we add those in the tfvars file? if yes I can do as a followup \r\n@alexsomesan ", "If any of these commands executed via ` `` `  fail, the execution will continue, right? This will make it very difficult to debug a failed build just with the log output. I know checking the exist code after each command is quite tedious. Is there a better idiomatic ruby approach?", "Why define `CLUSTER` here? Isn't that already set via https://github.com/coreos/tectonic-installer/blob/master/tests/rspec/lib/cluster.rb#L22 ?", "at this time we dont have the cluster yet created and I need the varfile to do some stuffs", "I can check each output. I can do in this PR or as a followup, what do you prefer? I would like to get this merged asap @mxinden ", "As a follow up sounds good. @cpanato thanks!", "Ok, thanks for clarifying."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2115", "comments": ["s/salve/slave", "s/salve/slave", "// fix indentation", "Why saving this into `vars` even though we never use it again?", "Does this mark the job as failed?", "Is it not possible to kill the job while it is in the queue?", "Is `it` the remote file from above?", "yes", "done", "done", "fixed", "no, because in the queue time looks like Jenkins does not know the parameters, they need to be in the running mode.", "done", "the localfile and when you use withInputstream you can use that.", "In case there is a bug and the tectonic installer job never leaves the queue, this will run forever. Can you add a global timeout to the trigger job? Something like:\r\n\r\n\r\n``` groovy\r\n// defines an absolute timeout with a maximum build time of 30 minutes\r\n    wrappers {\r\n        timeout {\r\n            absolute(30)\r\n        }\r\n    }\r\n```", "Shouldn't this be 2 spaces?", "done", "done"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2103", "comments": ["s/create a an s3/create an S3/", "s/with and S3/with an S3/", "Consider rephrasing to simply:\r\nThe installer will always create an S3 VPC endpoint for new VPCs.", "Consider rephrasing without \"you\"/\"your\":\r\nS3 VPC endpoints allow EC2 instances to communicate with the S3 service without leaving the AWS network and without incurring bandwidth charges for Internet Gateways or NAT Gateways when uploading to or downloading from S3.", "nit: add space between \"vpc\" and \"-\"", "Terraform lists are finicky. This may in some conditions need a `compact` around the `concat`", "this output is now distinctly different. Shouldn't this now be `[\"${local.master_subnet_ids}\"]`?", "same as above s/master/worker/"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2102", "comments": ["This policy isn't actually very limited. You can still mount arbitrary host volumes, for example.", "nit: maybe name this something like `tectonic:psp-permissive`? It's clearer that this is a custom policy for tectonic and this will be easier to make sense of in an alphabetized list.", ":+1: that's the flag I was looking for.", "just raising a small red-flag that this introduces manifest skew we need to fix in KVO", "same as below, this introduces manifest skew we should fix in the KVO", "Hmmm, sucks that there's not a common group we can target here...", "Agreed. We need to come up with _how_ restrictive this _default_ policy should be.", "sgtm", "This looks like the same bindings (kube-system) as the permissive grant just above. The subjects all still say `namespace: kube-system`.\r\n\r\nAm I reading this incorrectly?", "@joshrosso Should this be daemonset-controller or not?", "same question here.", "Figured out, `daemon-set-controller` is correct... https://kubernetes.io/docs/admin/authorization/rbac/#controller-roles", "https://kubernetes.io/docs/admin/authorization/rbac/#controller-roles"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2093", "comments": ["It would be cool to use this ssh_exec wrapper everywhere where ssh is needed by tests.\r\nBut to do that we need to make the retry behaviour configurable as some actions might not be retriable or might lead to unexpected results when inadvertently retried.\r\nAlso, unbounded retries are a very efficient way of shooting one's foot off.\r\nHow about we add a retry count here?", "yeah sounds good. I did not want to overengineer this wrapper but it definitely makes sense if we want to generalize its use. I had already ported the `wait_for_bootstrap` check to use this method in a previous PR. I can port the azure_vpn's use of ssh to this method in a follow up, since it is unrelated.", "Thanks a lot for porting the rest of the use cases to the wrapper. It certainly helps fighting tech debt as we improve the test code.\r\nEven if we were to not use it in a more generalised setting, the unbounded retry is dangerous, especially when put into the perspective of flaky networking to the node instances.", "Yes that's a good point; I didn't want to overengineer this method but it makes sense especially if we want to generalize its use. I already had ported the `wait_for_bootstrap` method to use this wrapper in a previous PR. I'll port the `azure_vpn` use of SSH to this wrapper as well but in a followup since it is unrelated to this race condition."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2079", "comments": ["This isn't quite right; docker just uses 172.17.0.0/16.", "While it can technically choose basically anything in 172.16/12, within Tectonic, Docker will always choose 172.17.0.0/16"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2078", "comments": ["It looks like this directive re-declares the `tectonic_azure_vnet_cidr_block` variable."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2076", "comments": ["Why not just `rm -rfv \\$WORKSPACE` ?", "I want to make sure $WORKSPACE is not corrupted and e.g. set to `/`."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2063", "comments": ["we should consider adding an ID or class to this element so we can select it more easily and not need to rely on fragile nested selectors that are likely to continue to evolve", "@squat yes, I'm cloning the console repo to add those :)", "but lets fix this quickly :) @squat "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2062", "comments": ["Previously, if someone started the installer with `--platforms=bare-metal-tf`, the frontend wouldn't fetch the AMI list and they could set up a baremetal cluster without requiring internet access. Now they can't. I don't know how much of an edge case this is.", "This brings the number of file upload parsers to 3. There's one for restoring from a progress file, another for SSH keys (previously also used for license & pull secret), and now this. Their functionality and purposes seem to overlap a decent amount, but I'm not sure how easy it would be to generalize & dedupe the code.\r\n\r\nI think this change is fine, but it'd be a good target for cleanup in the future.", "Thanks, I'll try to clean this up in a future PR.", "Go convention, and requirement for generating docs, is for function comments to begin with the function name. In this case it should look like:\r\n```go\r\n// tectonicFactsHandler gets a listof available Container Linux AMIs as well as the Tectonic\r\n// license and pull secret if they exist.\r\n```", "consider logging this error as a warning", "same", "we reserve uppercase type names for exported types. since this is only relevant for this one function, lets make it lowercase.", "Fixed", "Fixed", "Decided to leave as is, but can add a warning in the future if people feel it would be helpful.", "Decided to leave as is, but can add a warning in the future if people feel it would be helpful."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2061", "comments": ["Looks like an extra new-line", "@squat Just following Unix convention. I don't have a strong opinion on this. Shall I remove it?", "this is distinct from unix convention. This is an EXTRA newline apart from the trailing newline after the file.", "When the file does not have a trailing newline, GitHub renders a :no_entry_sign:", "Ah, sorry for the confusion. Should be fixed now.", "yes looks good now. This has the correct newline at the end of the file."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2060", "comments": ["This step the maintainer is not approving the PR yet, he/she will just enable the tests to be executed. I guess after that the maintainer will approve the PR.", "That's an important fact to clarify. "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2055", "comments": ["this you don't need since we are generating random keys everytime", "Thanks, fixed.", "`Merge the PR if have approvals`", "or something like that", "add a colon after platforms to introduce the list.", "I don't think this paragraph is strictly true. The Make target for `tests/smoke` automatically bind mounts several directories including the license and pull secret paths:\r\n```\r\n\tdocker run \\\r\n\t--rm \\\r\n\t-it \\\r\n\t-v \"${CURDIR}\":\"${CURDIR}\" \\\r\n\t-w \"${CURDIR}/tests/rspec\" \\\r\n\t-v \"${TF_VAR_tectonic_license_path}\":\"${TF_VAR_tectonic_license_path}\" \\\r\n\t-v \"${TF_VAR_tectonic_pull_secret_path}\":\"${TF_VAR_tectonic_pull_secret_path}\" \\\r\n\t-v \"${SSH_AUTH_SOCK}:${SSH_AUTH_SOCK}\" \\\r\n\t-v \"${TF_VAR_tectonic_azure_ssh_key}\":\"${TF_VAR_tectonic_azure_ssh_key}\" \\\r\n...\r\n```"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2039", "comments": ["We don't ship 1.13. We should instead just jump straight to 17.03.", "This was just an optimistic forecast made at 1.7 time. This file is not yet consumed by the bootstrapper anyway, so I'm keeping this in sync with the old one for the moment, will bump them all at the same time once testing is green. We'll also need a forecast for 1.9.", "@enxebre it looks you copied this file instead of symlinking it. I'm fixing GCP here as it's making my PR fail. Thanks to @squat for quickly figuring this out.", "@s-urbaniak @sym3tri this gets rid of the mutable tag."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2017", "comments": ["`1.6.10+tectonic.2` please"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2016", "comments": ["bump to `1.7.3+tectonic.3`", "Do we need to do that usually? I think this is to indicate hyperkube bumps if I remember clearly.", "this tells the KVO which version payload to use", "Ack. Thanks!", "also the KVO version will be `quay.io/coreos/kube-version-operator:v1.7.3-kvo.4`"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/2014", "comments": ["I think this needs to be `CamelCase`. I think this is a Kubernetes standard", "maybe adding `|` to keep consistency? ", "ditto", "Isn't the | unnecessary?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1997", "comments": ["This validator will be triggered when BM_MATCHBOX_RPC changes but it looks like BM_OS_TO_USE is set from a GET.  Do the timings work out here?  You may need to convert BM_MATCHBOX_HTTP as well.\r\n\r\nedit: I did not see this was marked WIP :P", "I ended up moving this logic back to `BM_Matchbox.canNavigateForward()` to work around the problem."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1994", "comments": ["I guess this is OK... it goes in localstorage but not progress files.", "total nit: this newline should be above the iamSvc declaration, right?", "This seems like a funny construct to be `connect`-ing a connected component. Why not get it all from the stateToProps?", "Is this commit necessary for this feature? Could we break this into a separate PR?", "We actually use `<Connect>` inside a `connect`-ed component in a few places. This component case is copying the pattern of `IOPs` above.", "Yes this is what I suspected, it just seems funny/inefficient to need to bind twice. I understand why it is done but not why it needs to be this way vs just putting everything in the `connect`. In any case, we do not need to fix this today but we should consider refactoring it away in the future to improve performance and simplify our code.", "OK, I moved it to a separate PR: https://github.com/coreos/tectonic-installer/pull/2026, but it will need to be merged before this PR.", "Fixed", "Sorry, that's why I was asking if this commit was necessary for this PR. If it needs to be merged before this feature then it *is* necessary. In any case, I am LGTMing #2026."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1993", "comments": ["This is how you spot a C veteran ;)", "Do we need to have this as an option out-of-the-gate or is it something that a default will cover most users?", "This is more of a nit, as control of these manifests/options will be moved out of the installer soon, but just want to raise the discussion point:\r\n\r\nI feel like this would be better served by maintaining separate manifests that are conditionally applied as a whole. While this keeps the cni plugins and config from being applied, it leaves all kinds of unnecessary cruft around (containers, mounts, env vars).\r\n\r\nFor example, if you choose flannel as your provider, there is a distinct set of manifests that relate to flannel. Same with Canal, same with Calico. Otherwise these parameter substitutions become very hard to maintain long-term.\r\n\r\nBut again, soon we'll be moving such that the installer will simply output the provider selected into a config, and the business logic of transforming that into distinct manifests won't live in terraform -- so I wouldn't block on changing this.", "nit: not sure how terraform outputs information about module variables, but if it's not clear - might suggest prefix for this.", "Why is Tectonic using a different path from upstream? Not `/opt/cni/bin`?", "I guess top level `log_level` is hoping every app supports the standard log levels?", "Why is this configurable? Why not set the version you intend to support? ", "In other places we've been clarifying `pod_cidr` or `service_cidr`", "Feels wrong. At some point I'm worried everything just a variable and the installer just a general template. Looks like this is done to save a manifest right?", "I don't think this should be a parameter.", "`tectonic_cluster_cidr` is a top-level variable injected into this value. `pod_cidr` is not being used in the installer. While I agree that the term `pod_cidr` is the better term, this question is unrelated to this PR.", "This is unrelated to this PR, as this is a mechanical file rename, but I am more than happy to pin this to `0.3.0` in this PR.", "Unrelated to this PR due to the mechanical file move, but I am more than happy to pin this to the default value `WARNING` in this PR.", "Relates to https://github.com/coreos/tectonic-installer/pull/1993/files#r141493957: yes, this was to reduce the amount of manifests, as optional modules in terraform are effectively non-existent. We do have some (hacky) HCL/ICL tricks in place to cope with this, i.e. calculating hashes of module IDs to enforce happens-before invariants, but it is not pretty.\r\n\r\nNevertheless I am happy to introduce a dedicated `modules/net/calico-bgp` manifest and trade TF complexity, as I agree with @aaronlevy that this leaves unnecessary cruft around and in the long-term this manifest will disappear from this repository (and thus also quite some TF hacks enforcing invariants).", "agreed, see https://github.com/coreos/tectonic-installer/pull/1993/files#r141541166", "xref'ing the original discussion https://github.com/coreos/tectonic-installer/pull/780/files#r126188220", "see comments in https://github.com/coreos/tectonic-installer/pull/1993#issuecomment-332752160", "ok", "Sounds good. You'll need to use CNI 0.3.1 when bumping to flannel-cni:v0.3.0, unless you override the default CNI config.\r\n\r\nhttps://github.com/kubernetes-incubator/bootkube/pull/697#issuecomment-329617739\r\nhttps://github.com/kubernetes-incubator/bootkube/pull/697#issuecomment-329839399\r\nhttps://github.com/coreos/flannel-cni/releases/tag/v0.3.0\r\n", "hm, ok. Thanks for the link. Looks like a conscious choice you guys are making for organization.", "Would it be reasonable to rename all the `calico_bgp` variables to just `calico`, since calico can only use `BGP` seems like an overkill", "By `bgp_enabled`, are you intending to mean Calic's special `policy-only` mode that is run atop a cluster with an existing flannel setup? We might want to make this more clear because at first I'm wondering, \"BGP, of course BGP is enabled, that's how Calico (proper) exchanges routes\"", "It might be a better idea to rename Calico's special policy-only mode to canal and handle it separately. That way the separation of manifests will be more clear too.", "I'd leave the bump to flannel-cni from v0.2.0 to v0.3.0 as a separate PR and leave this as a mechanical refactor if you don't mind (one change at a time). I created INST-517 to track the flannel 0.3.0 bump.", "flannel isn't alpha, just canal/calico. One option might be to use \"alpha\" as part of the identifier:\r\n\r\n```\r\nflannel\r\nalpha-canal\r\nalpha-calico\r\n```", "The way this is structured with flannel above is confusing. Should be explicit (canal/calico are only known to work on baremetal installations). Also, why is this the case?", "is there ever a reason to have different MTUs for each of these modes?", "This is rather unfortunate. Are we sure it's needed? Ideally we would just use the service (`https://kubernetes` or `https://kubernetes.default.svc` etc). Or because we're deploying calico as a pod -- apiserver addressability should be known / injected via the service account. Probably worth at least looking into if this is actually needed.", "Also, maybe instead we just set a sane default and if the user wants to modify it they can go do that directly in the manifest. cc @dghubble \r\n\r\nIt's a slippery slope to just plumb through every option (we should have strong reasons for doing this vs, \"if you need a different MTU - go change it in the manifest).", "I think he just means that's what they tested. Calico can work quite fine on cloud platforms.\r\n\r\n", "I also think some of the language here is confusing. \"native\" flannel? What do you mean by \"native\". Flannel is an xvlan overlay, Calico is IP or IPIP routing with BGP for determining routes. If any of them are described as \"native\" its Calico.\r\n\r\nFor network policy, maybe include that in parenthesis (implements network polocy) since Calico and Canal both have it, but that's not so clear to the reader.", "Why can't you use the usual `https://__KUBERNETES_SERVICE_HOST__:__KUBERNETES_SERVICE_PORT__`?", "The correct value varies by platform. On AWS, the correct value varies by instance type. You could use the lowest value as an out-of-box default, but it sacrifices performance.\r\n\r\nI'd recommend fixing it on platforms where there is a single correct value and allowing it to be customized only where users need to think about it (AWS). [Performance stats](\r\nhttps://typhoon.psdn.io/topics/performance/#network-performance).\r\n\r\n[Upstream Calico docs](https://docs.projectcalico.org/v2.6/usage/configuration/mtu).", "This has been taken over 1:1 from the existing setup on master: https://github.com/coreos/tectonic-installer/blob/35c5377/modules/net/calico-network-policy/resources/manifests/kube-calico.yaml#L33.\r\n\r\nI do agree that accessing the API server via the service is more optimal. Having said that I was under the impression, that (mainly due to the service IP flapping which has been addressed in https://github.com/kubernetes/kubernetes/pull/51698 coming in k8s >= 1.9) we prefer communicating via the external API endpoint rather than the internal service IP.\r\n\r\nBeing an alpha feature I suggest to address this as a follow-up. I filed INST-524 to track this.", "My suggestion would be to leave these values. Once we introduce a tectonic-network-operator, we can pass this setting 1:1 in a ConfigMap without changing values.\r\n\r\nI'll add the `[ALPHA]` label to the bullet points instead of the top-level description.", "I would prefer that we just fix this now. We don't want to be plumbing this through then remembering to remove it later - we know it's not the approach we should be using.", "@dghubble is there any reason to have both `mtu` and `mtu_ipinip` two configuration items or can we just set it once?", "When I commended, I thought there was just one MTU setting, but maybe I missed this.\r\n\r\nNo, I don't think you want to allow users to customize both. Its recommended they match and you can reduce complexity and prevent misconfigurations by not allowing them to differ unless a good reason comes along:\r\n\r\n> Typically the MTU for your workload interfaces [i.e. pods] should match the network MTU. If you need IP-in-IP then the MTU size for both the workload and tunnel interfaces should be 20 bytes less than the network MTU for your network.\r\n\r\nIn general, I think there are really only two new variables users should touch for networking: `network` (like flannel, calico, etc.) and `network_mtu`.\r\n", "Also it looks like the calico docs use @dghubble's suggestion - so we should probably just switch to that.", "ack, no problem, I'll switch to the service IP then.", "ack, I'll set the `mtu_ipinip=mtu-20 bytes` internally then.", "I think your variables here correspond to the workload and tunnel MTUs and should match, unless I've misunderstood something. The network MTU is whatever the platform actually offers.", "Careful, enabling IPinIP is not a safe default:\r\n* It doesn't work in Azure\r\n* It doesn't make sense for bare-metal, from a performance and reachability perspective.", "It is the upstream default and supposed to be the lowest common denominator that works despite some cloud providers dropping unrecognized packets. I agree its not required on bare-metal, I've left it on in my own clusters, the performance difference is quite minimal.\r\n\r\nI can't speak to Azure at all.", "a little confused about the need for this", "indeed it is, the tldr is that TF cannot compute dependencies between data sources and modules as a whole execution unit:\r\nhttps://github.com/coreos/tectonic-installer/blob/d301ea000e5891493440faf674f318f1e700c5cf/platforms/aws/tectonic.tf#L179-L189", "I propose we move forward with this PR as-is, and keep the setting as `true`. \r\nRationale:\r\n\r\n- This is an alpha feature. We can iterate and make additional changes before it goes to beta.\r\n- It is intended for _evaluation_ and _testing_ for baremetal platforms only.\r\n- The upstream default is `true`.\r\n- Turning it off on baremetal seems like a performance optimization.\r\n- Most importantly, this is not the final design. We have an open issues that must be addressed before this feature moves to beta. We can have ongoing discussions there on the design going forward (INST-529, INST-435) and weather or not to make this configurable etc.\r\n"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1992", "comments": ["The `master` word in the name is misleading. This method doesn't do anything specific to master nodes. It could potentially be used for any node in the cluster.\r\nI would just call it something like `preferred_instance_ip_address` or something similar.", "If `tectonic_aws_region` is set from the config file rather than environment, this will fail with a very unintuitive exception.\r\nI suggest you retrieve the value for region via the `TFVarsFile` wrapper class. Eventually we should make `TFVarsFile` source from both file or environment transparently.", "I'm bad with names, picked your suggestion :)", "In my opinion `return` is not needed here to understand the function by its name.", "Can you remove these commented out lines?", "How about we make `wait_for_bootstrapping` part of `wait_til_ready`?", "sure, done!", "ok, removed the return :)", "ok, done", "Might be difficult to wrap ones head around, but fancy!", "`systemctl is-active bootkube` is more robust. `is-active` will return exit status 0 when the unit goes active.", "AFIK, `systemctl is-active` turns true once the unit has been started, not when it returns.\r\nIn this case, we want to acknowledge that the unit (oneshot type) has completed.", "@alexsomesan Double-checked, and it works as intended. It will go into state `activating` until the unit completes/returns, at which point it returns a 0 exit status.\r\n\r\nIt accomplishes the same thing as the grep, but is robust to e.g., the active message changing.", "You are correct. I just did the same test myself and it works as you mentioned.\r\nWe should switch to using `systemctl is-active`.\r\nThanks for bringing this up.", "Same trick with `systemctl is-active` should happen here too.", "done", "Instead of having `wait_for_bootstrapping` inside the loop, how about moving it to the end of the function and replacing the `return` with a `break`? `wait_for_bootstrapping` has nothing to do with the `KubeCTL::KubeCTLCmdError`, so it will not be repeated anyways in case it fails.", "Do we have to add this here? As far as I can tell, whenever we run any test, it will create ssh keys for it. We have some tests that don't need this, e.g. unit tests and dry runs. Can we move this e.g. to a shared example or a step in the before blocks?", "done", "will keep like this per our discussion.", "ENV['HOME']", "done"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1991", "comments": ["Can we please have S3 in lowercase here? We actually don't use capitals in variable names anywhere in the project.", "It's not obvious from this text what this parameter does.\r\nThe description should clearly explain what the input parameter is used for.", "@alexsomesan I've got this now:\r\n```\r\n(optional) Unique name under which the Amazon S3 bucket will be created. Bucket name must start with a lower case name and is limited to 63 characters\r\n\r\nIf name is not provided the installer will construct the name using \"tectonic_cluster_name\", current AWS region and \"tectonic_base_domain\"\r\n```\r\n\r\nIs this what you had in mind?", "Not really actually, but mentioning it's naming restriction is useful too.\r\nI was referring to the purpose of this parameter. What the installer is doing with this bucket.", "@alexsomesan how does this sound?\r\n```\r\n(optional) Unique name under which the Amazon S3 bucket will be created. Bucket name must start with a lower case name and is limited to 63 characters. \r\nThe Tectonic Installer uses the bucket to store tectonic assets and kubeconfig.\r\n```\r\n\r\n", "Sounds good, thanks for addressing it.", "Two more nits: \r\n1. This input is platform specific so it needs to have the `_aws_` infix in the variable name like the rest of them. Also it needs to move to `platforms/aws/variables.tf`.\r\n2. Can we reflect a little bit of the purpose in the name of the variable?\r\nI'm thinking something like renaming it to `tectonic_aws_assets_s3_bucket_name`", "maybe if we keep it shorter `tectonic_aws_s3_bucket_name` since the purpose of the parameter is already given in description. ", "And to make sure we should imply in description that the parameter is AWS specific ", "Since this change touches the user facing API, I'm trying to be a little future-proof here. There might be a case in the future when we need to add a second s3 bucket for something else.\r\nImagine that one of them is called `tectonic_aws_s3_bucket_name` and the other one is called `tectonic_aws_s3_bucket_for_something_else`. It's going to become confusing then.", "We should stick to the naming convention already established & used by all other variables as @alexsomesan suggests.", "gotcha "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1990", "comments": ["The first `false` is a string while the second is a boolean. Should this type confusion be a concern here?", "This seems to be a dropin, not a service, right?\r\nPerhaps it should be moved to `../dropins`, prefixed with ordering and get the suffix changed to `.conf` like dockeropts?", "This seems to be a dropin, not a service, right?\r\nPerhaps it should be moved to `../dropins`, prefixed with ordering and get the suffix changed to `.conf` like dockeropts?", "very good catch, this should be fixed to be string and is also present on current master: https://github.com/coreos/tectonic-installer/blob/0cf916e/platforms/metal/matchers.tf#L50", "sounds good \ud83d\udc4d I can do the change.", "same comment as above, agreed, I'll move it to a `dropins` folder.", "Very minor nit: because it's called `_enabled` it sounds like it's effectively enabling / disabling the actual metadata service, when in fact it's just switching whether or not to use it.\r\nWould it make sense to call this flag something like `use_metadata` instead?", "very good idea, I'll rename the variable", "fixed"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1979", "comments": ["One detail that I would like to see documented somewhere: when is this external value determined and would it be re-computed as a side-effect of some terraform invocations?\r\n\r\nMy understanding is that the goal for this is to be computed exactly once per cluster and then never change, but I would like to have this confirmed and noted down.", "This value is computed *exactly once* per platform per `terraform <operation>` and used for the entire operation. \r\n\r\nNote that this does create the following dempotency issue:\r\nif a user sets `tectonic_container_linux_version = \"latest\"`:\r\n* runs `terraform apply` and creates a cluster today; then\r\n* runs `terraform apply` next week\r\nthey will see a diff caused by the newly calculated version of CL.\r\n\r\nI think that this lack of idempotency is strictly better than what we have now: currently, users will see the same idemptency issues in AWS caused by the lookup of the latest container linux AMI. This PR at least unifies the behavior of the installer. We could add declarations to all created instances to ignore the `ami` field (and appropriate field for other clouds) if the container linux version was set to \"latest\", however I think that is fair to tackle in a separate issue.", "What about noting these details somewhere under `Documentation/`?", "Definitely. I'll add another commit to that end.", "This has no `count` and is instead always run, otherwise Terraform's issue with evaluating both sides of ternary expressions causes problems in the output.", "as discussed OOB: we should write a custom datasource for this as this code might break platform compat (looking at you, Windows).", "This is necessary to prevent torx from rebooting the node when it finds that the version of CL is not the latest.", "could we bump this while being here?", "Correct. We are considering writing a small binary to provide cross-OS compatibility for this request. we could make a Tectonic resource provider that exposes this and other needed datasources.", "This kind of construct is more idiomatically expressed in Ruby with the condition at the end. \r\nLike this:\r\n```\r\nversion = @cluster.tf_value('module.container_linux.version') if version == 'latest'\r\n```", "yes. good catch. this is ruby convention (though I disagree that it increases legibility). updating this now", "updated!", "I'm not super keen on staying dead-on idiomatic with Ruby because there's a lot of weird conventions about it, I agree.\r\nAlthough they take time to get used to, this kind of conditionals read more like natural language.\r\nNot the best place to debate this, but I think their intention was to have code read like a phrase: \"Do eat IF you are (==) hungry\"."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1969", "comments": ["I dont' think we should leave this default value here. Let's leave it unset to enforce setting a value when declaring the module.", "Please also update the documentation in https://github.com/coreos/tectonic-installer/blob/master/Documentation/dev/node-bootstrap-flow.md as this introduces a new service, `kvo.service`, and a new dependency between `kvo.service` and `bootkube.service`.", "I suggest not to model this as a `oneshot` service, but rather as a `simple` service type using `Restart=on-failure`. You need to move the `docker run` statement to `ExecStartPre` to express restartability in case the docker download/run fails. Please see https://github.com/coreos/tectonic-installer/blob/0cf916e/modules/ignition/resources/services/k8s-node-bootstrap.service#L7-L33 as a reference point.", "I guess these are going away ;-)", "let's group the single line vars and sort them alphabetically and only let the `etcd_server` variable have a newline between them like so:\r\n```\r\nvars {\r\n   advertise_address      = \"${var.advertise_address}\"\r\n   cloud_config_path      = \"${var.cloud_config_path}\"\r\n   cloud_provider_profile = \"${var.cloud_provider != \"\" ? \"${var.cloud_provider}\" : \"metal\"}\"\r\n   cluster_cidr           = \"${var.cluster_cidr}\"\r\n...\r\n   etcd_servers = \"${\r\n      var.experimental_enabled\r\n        ? format(\"https://%s:2379\", cidrhost(var.service_cidr, 15))\r\n        : var.etcd_ca_cert_pem == \"\"\r\n          ? join(\",\", formatlist(\"http://%s:2379\", var.etcd_endpoints))\r\n          : join(\",\", formatlist(\"https://%s:2379\", var.etcd_endpoints))\r\n      }\"\r\n  }\r\n}\r\n```\r\n\r\nWe found this is easier for diff'ing than with logical grouping.", "Heh, yes. Had to modify for local testing.", "Done", "Wondering if we should just squash the kvo.service step as part of bootkube.service? Really it's \"bootstrap\" service - and it should only ever run once on a single node anyway (I believe as this stands kvo.service would run once on every master)"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1967", "comments": ["What requires build-essentials in this image?", "This nest of ifs is not very idiomatic.\r\nMethods implicitly return the value of the last statement in the method body. So `return` statements are not needed when not returning early. \r\nAlso, exceptions messages are not really log messages, thus they should be as concise as possible (one can log more elaborate statements before raising).\r\n\r\nCould be compacted to:\r\n```ruby\r\nraise 'could not get the console url' if ingress_ext.empty? && ingress_int.empty?\r\ningress_ext || ingress_int\r\n```", "Cool fix!", "these simple ifs usually go at the end of the statement, according to Ruby idioms.", "Is it really needed to put this at the top level? We already have tests (like the meta-tests) that are not actually building clusters. In those cases this is not needed.\r\nI think this code can go at the shared example level. Are there any blockers to that?", "will change! thanks so much for the review :)", "\ud83c\udf89 ", "I tested that before and did not return the second because it is not nil. I will figure out that", "ok", "this not work because the variable is not `nil` instead the variable is `\"\"`", "We need to build the bcrypt gem and for the webdriver (ffi)", "I guess that was expected, that some gem would require this sooner or later. There are a lot that build native extensions at runtime. \r\n\r\nWe should keep this in mind when restructuring the environment images. These build steps should rather be done in a builder image.", "OK, then no need to stress too much over this. Let's keep it like this for now.", "ok", "lets do that when we move to the builder/runtime"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1962", "comments": ["I don't think you need this at all anymore, buts its been a while...", "There is a way to tell `CA_CERTIFICATE` to look at `CA_TYPE` and optionally enable it - I think `ignore` or maybe `ignorewhen` ...", "Apparently it's still needed for the unit tests.", "Thanks, I added `ignoreWhen` callbacks for the cert and key fields and updated the PR description.", "Oh, I think you just need to import the file in the test suite.", "You should be able to remove this logic now.", "Actually the tests do pass, but they start to output \"Removed clusterConfig.caType because it's not in defaults.\" with `console.error`. Maybe the tests should be changed? I'm thinking that shouldn't be part of this PR though.", "OK, I changed it so that this is now just `CertificateAuthority.canNavigateForward = form.canNavigateForward` and all the validation is done in the form level `validator`.", "Not part of this pr but I am just noticing that this should really be \"etcd v3\" rather than the other way around.", "Fixed: #2019"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1955", "comments": ["Now that the terraform version is removed from this repo, how will we know which version of terraform is required? The version seems to be in a Jenkinsfile in another repo, but that loses history. eg: If I'm on master and I check out branch 1.8.0, how will I know whether I'm supposed to use a different version of terraform?\r\n\r\nBefore this PR was merged, I could simply run `get_terraform_resources.sh` and know I had the right terraform binary.\r\n", "https://github.com/coreos/tectonic-installer/blob/21c039a2ee5eedd5c03984484e3542681d2edbb5/config.tf#L1-L3", "Ah, thanks."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1950", "comments": ["My fuzzy recollection of this behavior is that we have 1/1 of some resource, then 1/2, then 2/2, etc.  Assuming this is accurate, I'm not sure locking the results to `true` is what we want."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1938", "comments": ["cc @dghubble (I'm not sure the implications here)", "whops, sorry, this is a left-over from testing, I will revert this. thanks for pointing out.", "Can you add an error message here like `raise \"ssh exec on master #{ip} failed with exit code #{fin} and stderr #{stderr}`", "Ignoring `stderr` might make debugging difficult in the future. Can you log it like described below?", "As far as I can tell, this function is not called anywhere. Would you mind removing it?", "Instead of implementing this retry logic yourself you can now use the `with_retries` lib from @cpanato.\r\n\r\nSee it used here: https://github.com/coreos/tectonic-installer/blob/master/tests/rspec/lib/aws_support.rb#L23\r\nThe library with examples on the top: https://github.com/coreos/tectonic-installer/blob/master/tests/rspec/lib/with_retries.rb", "See retry related comment above.", "See `stderr` handling above.", "See adding error message above.", "done"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1933", "comments": ["I thought we were putting all of these in one `ConfigMap`, which is why you renamed it in #1928?", "@diegs That's good question. The reason is that then I realized that the bootkube module doesn't have all these required terraform variables defined.\r\nSo I am not sure if we want to put all those tectonic related terraform variables into bookube module.\r\n", "Hm, maybe we should make this a `cluster-config` in the `tectonic-system` namespace and make the bootkube module `cluster-config` in the `kube-system` namespace then?\r\n\r\nThat way we can try and limit our number of config objects to one per module.", "@diegs I am ok with that, wdty @aaronlevy ?", "I feel we can actually dissolve key-values under this key into the above sub-keys.\r\nI can do an investigation on who is using these values. But if someone knows this already, that will be helpful.\r\n/cc @amrutac @squat @rithujohn191 ", "Hmmm interesting thought. I agree that components should not need to cross namespace boundaries for their config (ideally). I'd be fine starting with these in different namespaces - and during the next few weeks of burn-in we can decide if we like that pattern. ", "Do we need this? I'd prefer that we don't keep anything sensitive in this config (also why do we need this - what component consumes?)", "The identity configmap already contains it: https://github.com/coreos/tectonic-installer/blob/master/modules/tectonic/resources/manifests/identity/configmap.yaml", "I'm on fence if this should be kube-addon or tectonic-utility. It's in the tectonic-system namespace - so I guess it makes sense here.", "wouldn't this be tectonic-system if it's managing components in that namespace?", "this one is in the `bootkube` module", "nm. mixing up files", "If we plan to remove all the `callbacks` from the [IdentityConfig](https://github.com/coreos-inc/tectonic-utility-operator/pull/8/files) we should remove it from here as well", "will do.", "`cluster-config.yaml` and update `echo` text?", "@alexsomesan @s-urbaniak Does anyone know why this is not just `\"${var.base_address}\"`?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1929", "comments": ["I think this can be tightened even more to just the etcd subnet CIDR, right?", "same thing, can just be the etcd CIDR block here.", "master subnet CIDR block", "etcd CIDR block.", "master subnet CIDR", "etcd CIDR", "same as above", "etcd CIDR", "etcd CIDR", "vnet CIDR", "master subnet CIDR", "I think this can just be one rule shared by all the nodes in the cluster, no?", "this seems to have identical rules to the one above.\r\nsee my comment about sharing it."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1923", "comments": ["this is not related to this PR, but we should upgrade the openstack and vmware platforms to use the bootstrapper too. We can do this as a follow-up.", "100% agree. I just want to bake it here a bit, see how well it's fighting flakiness.\r\nI'll follow up with the other platforms in the coming days.", "@alexsomesan Are you still planning to add bootstrapper support for the other platforms?", "@lblackstone Yes, this should be ported to other platforms eventually.\r\nWe need to plan some capacity for it, there has recently been a lot of higher priority work.\r\nI also don't have any means to test openstack at the moment. Would you be able to help out with that?", "@alexsomesan Yes, we're very interested in this feature for OpenStack, and are happy to help with testing. I could probably do the implementation myself, but wasn't quite clear how it was supposed to work. Do you have any documentation for that workflow?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1921", "comments": ["please use ` unstash 'repository'` instead of `checkout scm` and `unstash installer/smoke`", "please use `cleanWs notFailBuild: true` instead of `deleteDir()`", "Done", "Done"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1918", "comments": ["do you mind to move all dns related bootstrapping to `modules/dns`? That way we make the DNS story swappable, as this is requested by some users.", "note to myself: we really need to unify this. We already have done this for the kubelet, but etcd is a complex service and needs one place to be configured. Leave it here for now, we will tackle this as a follow-up.", "no strong feelings, but I'd like to keep editor-specific metadata out of the files.", "see nit above", "...", "this is a carbon-copy of `modules/aws/master-asg/resources/services/init-assets.service`. As we use the very same thing here, this becomes a candidate for unification.\r\n\r\nCan you please move this to `modules/ignition/resources/services` and dependency inject it as the other ignition artifacts?", "same comment as above for etcd. let's bootstrap all dns records in `modules/dns/google`.", "just a naming nit/question: in platforms we call it `platforms/gcp`, in modules we call this `modules/google`. seems impedance mismatch'y a little bit, no?", "Hey @s-urbaniak thanks for the comments! I'm looking at the refactoring stuff but may be better leave it for a follow up PR? This is something functional now and refactoring can lead to difficult to anticipate dependency issues which can affect to other clouds which can lead to other problems out of the scope of having an \"alpha\" gcp version in place which should be the target here. What do you think?\r\n", "I'd like to avoid platform skew as much as possible. We loosened constraints in the past for other platforms and it turned out to be a big mistake, especially in the light of alpha platforms. Being an alpha platform we can loosen the constraint on test coverage but I would like to avoid to loosen the constraint on general architectural compliance.\r\n\r\nMore specifically we are working on enabling optional modules. If we leave GCP behind (as we already did with `modules/aws` which still has its internal DNS implementation) re-priorization of tasks could slip tech-debt.\r\n\r\ntldr: I'd really advocate for having dns logic in `modules/dns/gcp`. Sorry if this complicates things.", "PS: this is already planned for the next sprint.", "\ud83d\udc4d ", "Unless I'm missing something this is not being used anywhere in the current change set.\r\n\r\nAlso, is this intended to configure autoscaling for etcd nodes? Can't really make that out from the description.", "This seems to be a GCP specific setting. It should be infixed with `_gcp_` just like the other ones introduced in this file.", "Why doesn't this one have a `tectonic_gcp_` prefix?\r\n\r\nAll installer inputs have to be namespaced (at least) under `tectonic_`. If it refers to an externally provisioned resource we usually denote that by including something like `_external_` or `_ext_`.\r\n\r\nSee here, for example: https://github.com/coreos/tectonic-installer/blob/master/platforms/aws/variables.tf#L80", "`_gcp_` platform infix? Same for the one below.", "Hey @alexsomesan thanks for pointing that out, just removed the stale variables and fixed namespacing", "Why does this need to be a user-facing input?", "Why does this need to be a user-facing input?\r\n", "Why does this need to be a user-facing input?\r\n", "Could you rather use [this](https://www.terraform.io/docs/providers/google/d/google_compute_zones.html) here and not have this as an input?\r\nAlso we'd rather not have default values here, for the same reason as the region parameter.", "We're deliberately not setting any default for regions in any of the other platforms. We want this to be a deliberate input from the user. This is to raise the user's awareness about where their resources are going to be created.", "This domain is already registered in Route53 for the AWS installer.\r\nDoes this actually also work here? Does it not need to be registered in Google Cloud NS?", "Hey @alexsomesan make sense, just removed the default. Raising a warning here though as it seems we are actually currently setting the default for aws https://github.com/coreos/tectonic-installer/blob/master/platforms/aws/variables.tf#L262", "Hey @alexsomesan just removed default values. This is related to how we handle the number of instances,  the instance group managers here https://github.com/coreos/tectonic-installer/pull/1918/files#diff-00091bc50a0d600c32caba6d18409955R53, how we'll want to handle them once this lands in terraform https://github.com/terraform-providers/terraform-provider-google/pull/394 and also to adding autoscaling. I'd rather leave it explicit for now as it makes things more obvious, simple and easy, we can complement it later in conjunction with those other factors. what do you think?\r\n", "yep, don't really need to. This also might be taken into consideration on how we handle the zones. I removed the user facing var and hardcoded the value on the module input. In line with my comment above, keeping things simple and explicit for now ", "same as above", "stale variable, thanks!", "Neither \"project-id\" or \"managedzone-name\" exist yet. I set those values as a sample, proper values will need to be set later when hooking into CI system", "Got it, thanks for making that clear. Makes sense now.", "To keep things aligned with the other platforms and allow the CI tool to work consistently, we should only inject the region via config variables.\r\n`credentials` and `project` should come from the corresponding Terraform / SDK environment variables.\r\n(See [here](https://www.terraform.io/docs/providers/google/index.html#credentials) and [here](https://www.terraform.io/docs/providers/google/index.html#project))"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1917", "comments": ["I'm guessing this could be made more accurate by looking at the number of nodes in the cluster. eg: `total = 40 + (nodes * 20);` Some experimenting would have to be done to figure out the right constants.", "Actually, the number of nodes doesn't change the number of created resources reported in the Terraform logs. Provisioning a cluster for etcd does though, so I will create a separate PR for that. Thanks."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1909", "comments": ["ok, just for completeness: this manifest change is taken care of in KVO by @brancz."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1897", "comments": ["nit: I would alphabetize all the keys to make it easier to find stuff as this grows.", "I see why we need to create the namespace sooner now, but I would keep it in its own file rather than combining it with the kvo config.", "`s/canel/canal/g` (in all the files?)", "Yeah, but @aaronlevy said bootkube can't handle order requirement.", "Lets drop this for now, it won't actually end up under KVO management long-term so it's not immediately needed in this config", "drop - not immediately needed for core k8s components", "also drop for now", "We should discuss if this is the best option -- but fine to leave it in for now.", "drop", "drop", "drop", "drop", "done", "done", "done", "done", "done", "kube-scheduler and kube-controller-manager both need the `replica:` parameter in their deployments. we set this currently to `master_count`. I initially assumed this could be implied at the KVO side by listing all nodes having the `node-role.kubernetes.io/master` label, but at bootstrap time not all masters are registered yet.\r\n\r\nSo, does it make sense to add `master_count` here?", "another suggestion is to name it `initial_master_count` to make the semantics more explicit.", "There are a couple of other alternatives we've thought about:\r\n\r\n- Use the cluster-proportional autoscaler to set the replicas: https://github.com/kubernetes-incubator/cluster-proportional-autoscaler\r\n- Migrate the scheduler and controller-manager to daemonsets once this feature lands in 1.9: https://github.com/kubernetes/community/pull/977\r\n- In the near term, just set the replicas to something fixed (like 2).\r\n\r\nFor this iteration I think passing the \"initial_master_count\" through is probably fine.", "OK, I just stored the `initial_master_count` under the `networkConfig` key since I can't think of a better name and it will be removed later anyway.", "I suggest perhaps adding `InitialConfig` in case we have other parameters like this.", "Done."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1882", "comments": ["Here we are keeping the job that posts to the tectonic installer ci room, but below we are keeping the one that posts to the team tectonic room. Why the difference?", "for this job (hyperkube trigger) is only on the tectonic-installer-ci room the other job (tectonic_installer_nightly_trigger.groovy) I replaced to send to our main room because of this ticket https://coreosdev.atlassian.net/browse/INST-251. Here I updated this because I added the wrong room name :/"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1878", "comments": ["I'm a bit frightened by sed'ing through templates during a test :)\r\n\r\nMay I suggest you inject the updated `tectonic_container_images` as an override environment variable?\r\n\r\nThe code below extracts it from config.tf, updates the hypercube and exports the override all in one line.\r\nFeel free to adapt it as you see fit.\r\n\r\n```shell\r\nexport TF_VAR_tectonic_container_images=`pushd -q build/${CLUSTER}; \\\r\necho \"jsonencode(var.tectonic_container_images)\" | \\\r\nterraform console ../../platforms/${PLATFORM} | \\\r\njq -c '.|.hyperkube=env.hyperkube_image'; \\\r\npopd -q `\r\n```", "Much cooler! \ud83d\udc4d "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1877", "comments": ["nit: CombinedOutput should be used. But as stated in the header comment, the function needs some rework (i.e. the header comment itself should state that the main difference of that command is that the output is returned rather than written to the log file."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1862", "comments": ["nit: missing docs", "just wondering, a small grep reveals:\r\n\r\n```\r\n$ rg -T go 32000\r\nDocumentation/generic-platform.md\r\n23:      - MUST allow 32000-32002 from all for: Tectonic ingress (if using node ports for ingress like on AWS, otherwise use host ports on workers) \r\n\r\nmodules/azure/vnet/lb-console.tf\r\n15:  name                    = \"${var.cluster_name}-console-lb-rule-443-32000\"\r\n23:  backend_port                   = 32000\r\n45:  port                = 32000\r\n\r\nmodules/aws/vpc/sg-master.tf\r\n186:  from_port = 32000\r\n197:  from_port = 32000\r\n\r\nmodules/aws/vpc/sg-worker.tf\r\n166:  from_port = 32000\r\n177:  from_port = 32000\r\n\r\nmodules/aws/master-asg/elb.tf\r\n107:    instance_port     = 32000\r\n\r\nmodules/tectonic/resources/manifests/ingress/nodeport/service.yaml\r\n20:      nodePort: 32000\r\n```\r\n\r\ndoes it make sense to dependency-inject that value?", "nit: rather use an env var in Jenkins for this?", "same nit: rather use an env var in Jenkins for this?", "the same applies to `3200[1..2]`, but we could tackle this in a separate PR.", "good point! \r\nthis is leftover from my sketchy local testing", "Yeah, I can totally see the use for injecting this port.\r\nRight now, this is the port all versions of Tectonic have been using behind LBs.\r\nI'm tempted by the future PR option though, as I'd like to keep manifest skew to a minimum for this one. ", "good point. Will do!", "Added docs.", "nit: can be dropeed since https://github.com/coreos/tectonic-installer/pull/1852 landed", "done"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1859", "comments": ["@alexsomesan As far as I know this will lint the `vendor` folder as well, right?", "there should be no vendor folder in there actually."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1858", "comments": ["this is extreme wizardry ;-)\r\n\r\non a serious note, let's put a reference here (as a comment) on the upstream disucssion with the maintainers so we can backtrack any potential fixes.\r\n\r\nWe use hardcoded class names and use reflection to resemble deprecated behavior here, so I am afraid this would break again, once we do another jenkins update round.", "\ud83d\udc4d "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1845", "comments": ["@cpanato can you adjust the `customMessage` in the above block accordingly so that both match and capitalize \"**M**aster **B**ranch\" (or make the rest lower case).", "yes sure \ud83d\udc4d ", "done @mxinden "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1844", "comments": ["Looks like this got accidentally changed from 60000 to 100000. Probably easier to change back in a separate PR.", "ok, i increased that and forgot to remove, will do in another pr later"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1843", "comments": ["Is this equivalent to `https://$CHANNEL.release.core-os.net/amd64-usr/current/version.txt`? Also, please no plaintext HTTP.", "thanks, I forgot that version.txt existed. This simplifies life considerably."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1841", "comments": ["consider making this a var at the top of the file so it is clear it is a canonical value.", "I wish we didn't need to spec this so many places. We should make an internal not about all the places to bump this so it's easier when the time comes.", "s/VER/VERSION/ we can be explicit in configuration like this and it is more consistent with our other files.", "s/VER/VERSION/ here as well", "It's a bit misleading. The only relevant place for this version is actually here in the Makefile.\r\n\r\nThe release scripts have been relocated to their own repo and the versions in here are to be removed. I'm waiting for @Quentin-M to give the green light on that.\r\nIn the meantime I just updated everywhere for consistency.", "not a show-stopper, but raising awareness, that this could be a potential flake. Looking at the code for this test, `terraform init` downloads `provider.local` and `provider.template` for the tested `main.tf` file, hence we are dependent on the network.\r\n\r\nIn practice I did see `terraform init` failures locally due to temporarily unreachable endpoints, so I am predicting we will see it here too.", "super small nit: terraform is at `0.10.4` already.", "nit: we are declaring this version twice. here and [here](https://github.com/coreos/tectonic-installer/pull/1841/files#diff-b67911656ef5d18c4ae36cb6741b7965R15). can we have one place for this var?", "same argument as above. can we unify this and maintain one place used for the tf version? it is also declared [here](https://github.com/coreos/tectonic-installer/pull/1841/files#diff-ccc44698b3fb7a18daf57e1d0d6acb66R3).", "This version of the smoke test is in the refactoring pipeline to move to RSpec already.\r\nThe refactored version will use different configuration conventions, so I guess it's not worth refactoring now.", "These release scripts have been moved out into their own repo so this version will soon be removed and is not in use anymore. I've just updated for consistency, but this is dead code already. Just waiting for Quentin to give the go-ahead to remove these.", "Bumped.", "This UI only code for now.\r\nI agree that we need to do smarter things here (like retries) once this get on the critical path of any automation.", "Did someone run yarn in the wrong directory, then check this file in?", "Ditto here. It looks like someone ran `yarn install` in the installer dir instead of `frontend/`."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1839", "comments": ["please remove the comments when you think we can get it back )"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1836", "comments": ["Would be nice to give a list of valid providers in the description.", "I'd expect this to have a reasonable default value.", "I'd prefer to leave it blank because then it [uses the default](https://github.com/openstack/neutron-lbaas/blob/c0a7975bd17baafac3cccba78bb8292dc23f5024/neutron_lbaas/services/loadbalancer/plugin.py#L152-L165) LB provider for that environment (which is configurable). Probably better to let the operator decide what's the best default IMO", "\ud83d\udc4d  I'll list the most common and also link off to docs"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1831", "comments": ["if marked as `(optional)`, we must provide a default value here.", "s/`(Optional)`/`(optional)` (lowercase)", "AFAIK there is no default StorageClass in Kubernetes, so does that mean this value needs to be required? If so, I'm concerned that users who _don't_ want to back up etcd will need to provide a value, even though they have no interest in using it. \r\n\r\nMaybe we could use a default placeholder value like \"default\"? ", "In this case I suggest to add `default = \"\"` and make it clear in the description that this value must be set iff `tectonic_enable_etcd_backup` is set to `true`. Unfortunately terraform does not give us more expressiveness in terms of inter-variable dependencies.", "small nit: Do you mind to add `(optional) [ALPHA] Indiciates whether ...`?", "Why is the cloud provider configuration path being unset here?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1823", "comments": ["We really should be using Azure CLI 2.0", "I will try to figure out how to use the new version with our current docker image or build a new one.\r\nAdded to my things to do"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1818", "comments": ["I don't think this value is actually needed anywhere but I added it to align with the API in #1811. We can always keep this just in case for future use.", "I was told by @kans that `WithClusterConfig` is legacy and we should be switching over to `Connect` instead.", "100% agree. Im using it in this PR for consistency. We'll migrate this component over in a separate PR.", "thanks for the heads up, @s-urbaniak ", "\ud83d\udc4d ", "no problem \ud83d\udc4d "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1812", "comments": ["can we use `ensure` then we can avoid this code duplication. `ensure` will always run no matter what, then in the `rescue` we get the error and log it\r\n\r\nwhat do you think?", "Thanks for the hint!"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1811", "comments": ["This needs to be the CA cert for the CA that signed the identity certificates, not the CA that signed the ingress certs. In its current state, tectonic-console will fail to come up because the identity TLS certs are not trusted. I don't think anyone actually requires the ingress CA cert. We can remove it from the ingress certs module API.", "In our current setup yes, but not in the case of user-provided, externally signed certs. In the case of user provided certs this is the public CA that signed the ingress CSR, i.e. some public authority (I used let's encrypt for my tests).\r\n\r\nYou need to set `BRIDGE_DEX_CLIENT_CA_FILE` (Dex's identity GRPC client CA) in console, otherwise console would crash loop as you mentioned, see https://github.com/coreos/tectonic-installer/commit/40da8e2a840df0254c15c5b90947e561812bc563#diff-75010753e0caeb22b20777ee897ebebdR102. (I don't see this setting in your PR https://github.com/coreos/tectonic-installer/pull/1818/files).\r\n\r\nSide note: I tested successfully this PR with certs signed with let's encrypt, providing them as described in https://github.com/s-urbaniak/tectonic-installer/blob/40da8e2a840df0254c15c5b90947e561812bc563/modules/tls/ingress/user-provided/README.md.\r\n\r\nI hope that clarifies it a bit. I will draw a graph today which gives more clarity about our TLS topology. @sym3tri and me yesterday did a first pass and he documented the results in https://docs.google.com/document/d/1nRkwCCL5QkqeqUwMPo1ax2gBLzQ-x7keMI98pSxljL4/edit.", "Hmm there is one detail that seems odd to me. Does console use `BRIDGE_CA_FILE` as the Dex CA cert if that cert is not explicitly passed? That is a funny gotcha that we should rectify.", "Yes, just confirmed that dex ca defaults to the console ca, that's was the source of my confusion. I'll make sure to add both flags to my PR as well."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1806", "comments": ["Lgtm. Can you remove the link to the tectonic-sandbox repo though?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1798", "comments": ["s/Additionally, s/S/ (redundant)", "\"Each guide walks through:\"", "\"...deploy, scale, upgrade, and manage...\"", "s/; choose/: Choose/\r\ns/platform/provider/\r\n", "shouldn't this/these img src URL be instead, e.g., `img/cookie-v1.png`?\r\n\r\n((maybe) later: we should have a common images dir at `tutorials/img/` and then just the images that differ for each in `tutorials/$provider/img/`.) "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1795", "comments": ["Just one small nit: Is there a reason for using the first generation D1 / D2?\r\n\r\nThere are newer generations of the D1 / D2, called D1_v2 or even D1_v3 depending on the region.\r\nThese usually provide better performance for the same or less of the price.\r\nAlso, when using less than the current generation we run the risk of them being taken out of service in the datacenters and resulting in errors about not enough capacity.", "makes a lot of sense, will change! thanks for pointing out."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1792", "comments": ["Why not let `cidrSize` return whatever, then use `_.isInteger(addresses)` here?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1791", "comments": ["`capitalize` works for Azure clusters, but not for AWS clusters, because `aws` capitalized turns into `Aws`, but the class is called `AWSCluster`. Instead of capitalizing here, can we have the cluster type enum written correctly (`Azure`, `AWS`) and lower case the strings in line 43 of tests/rspec/lib/tfvars_file.rb?", "s/platform/platform.downcase\r\n(See comment above)", "s/aws azure metal vmware/AWS Azure Metal VMWare/", "I fixed it the other way around: I adapted the AWSCluster class to follow the camel-case convention.\r\nThe reason is that I would like to keep the data from the `.tfvars` as the source of truth (as I was mentioning earlier on in the project). Seems like a simpler rule to follow: the tfvars file is always right.", "Sounds good to me. Thanks for the changes."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1787", "comments": ["html -> md"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1781", "comments": ["s/log/logs/", "s/log/logs/", "should it be \"changed\"?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1773", "comments": ["\"...scaled and monitored *with* either graphically...\" <-- Remove the extra \"with\"", "Remove this sentence or rephrase. We've not yet deployed an app at this point.", "Useful info, but the user probably doesn't need to delete an app at this point.", "`simple-ingress` -> `simple-ingress.yaml`\r\n\r\nMainly for consistency's sake since the file extension was used for `simple-deployment.yaml` and `simple-service.yaml`", "\"simple deployment\" -> \"simple-ingress\"", "This should also be \"simple-ingress\"", "\"...create the Ingress\" -> \"...create the Ingress resource\"", "Ingress -> Ingress resource", "At this point, we're far enough away from `simple-deployment.yaml`, that a link up to it would probably be useful.", "Why a period here but not for the next two bullet points?", "Rephrase to \"Remove the deployment *and service* just created...\" since the following code example is removing both.\r\n\r\nShould the Ingress resource also be deleted? Since the entire app is being redeployed in the next section? If yes, remember to update the following code snippet.", "Applications aren't people. They can't own property :)   should be applications not applications'", "nit: Image is of the deployment's overview. If we're telling the user that they can monitor pods through the console, the image should show the deployment \"Pods\" tab.", "We want to leave the service and ingress. Corrected the command to delete just the Deployment.", "an abstract way to refer to a set of Pods, and route to access them? \r\n", "The comma in this sentence is unnecessary.", "Similarly to what was done in`first-app.md`, tell the user to delete their current `cookies` deployment before moving on, since they'll be redeploying the app.", "At the least this is an l4 load balancing technique that uses round robin algo.", "This is an l7 mechanism. In that it is path based load balancing across services.", "Might be worth pointing out this is a security mechanism. ", "\"If the update fails it can roll...\" <-- Missing a comma after \"fails\"", "Ingress -> Ingress resource", "You can also just `export KUBECONFIG=~/Downloads/kubectl-config`\r\nnow `kubectl` will use the config from that env var as the default. ", "Instructions are listed with bullet points in this doc, but earlier in the tutorials, they've been numbered.\r\n\r\nConsistency is nice. Number all the following instructions please.", "you don't have to explicitly say true. --expose is enough.", "Should ingress be capitalized here?", "HUGE IMPROVEMENT ALERT:\r\n\r\nBefore you delete it do this:\r\n\r\n`kubectl get svc,deploy simple -o yaml --export > simple.yaml`\r\n\r\nWhich places the yaml for the deployment and service into a file called simple.yaml\r\n\r\nNow you can delete the objects with \r\n\r\n```\r\nkubectl delete svc,deploy simple\r\nservice \"simple\" deleted\r\ndeployment \"simple\" deleted\r\n```\r\nAnd look at the file simple.yaml\r\n\r\n```\r\napiVersion: v1\r\nitems:\r\n- apiVersion: v1\r\n  kind: Service\r\n  metadata:\r\n    creationTimestamp: null\r\n    labels:\r\n      k8s-app: simple\r\n    name: simple\r\n    selfLink: /api/v1/namespaces/default/services/simple\r\n  spec:\r\n    clusterIP: <unknown>\r\n    ports:\r\n    - port: 80\r\n      protocol: TCP\r\n      targetPort: 80\r\n    selector:\r\n      k8s-app: simple\r\n    sessionAffinity: None\r\n    type: ClusterIP\r\n  status:\r\n    loadBalancer: {}\r\n- apiVersion: extensions/v1beta1\r\n  kind: Deployment\r\n  metadata:\r\n    annotations:\r\n      deployment.kubernetes.io/revision: \"1\"\r\n    creationTimestamp: null\r\n    generation: 1\r\n    labels:\r\n      k8s-app: simple\r\n    name: simple\r\n    selfLink: /apis/extensions/v1beta1/namespaces/default/deployments/simple\r\n  spec:\r\n    replicas: 3\r\n    selector:\r\n      matchLabels:\r\n        k8s-app: simple\r\n    strategy:\r\n      rollingUpdate:\r\n        maxSurge: 1\r\n        maxUnavailable: 1\r\n      type: RollingUpdate\r\n    template:\r\n      metadata:\r\n        creationTimestamp: null\r\n        labels:\r\n          k8s-app: simple\r\n      spec:\r\n        containers:\r\n        - image: quay.io/coreos/example-app:v1.0\r\n          imagePullPolicy: IfNotPresent\r\n          name: simple\r\n          ports:\r\n          - containerPort: 80\r\n            protocol: TCP\r\n          resources: {}\r\n          terminationMessagePath: /dev/termination-log\r\n          terminationMessagePolicy: File\r\n        dnsPolicy: ClusterFirst\r\n        restartPolicy: Always\r\n        schedulerName: default-scheduler\r\n        securityContext: {}\r\n        terminationGracePeriodSeconds: 30\r\n  status: {}\r\nkind: List\r\nmetadata:\r\n  resourceVersion: \"\"\r\n  selfLink: \"\"\r\n```\r\n\r\nThen just do `kubectl create -f simple.yaml`\r\n\r\n:)", "Ingress -> Ingress resource", "ditch the also", "\"...rate at which updates will occur, and health checks...\" <-- Remove the comma before \"and\"", "\"...to create a Service which more...\" <-- Did you mean to type Deployment here? \r\n\r\nIf no, please provide a sentence explaining why the user needs to edit `simple-deployment.yaml` to create a service.", "nit: I'd split the instruction (Add a `readiness` and `liveness` probe) and explanation (everything after that) up into two sentences. The current phrasing is somewhat awkward to read. ", "So it took me a while to figure out what's happening with the ingress here. \r\n\r\nYou are piggy backing on the on the console url with a new path: /simple-deployment. \r\n\r\nWhy are we doing that?", "\"...live updates as newer pods appear, and the corresponding...\" <-- Remove the comma before \"and\"", "external ip should show `<none>` here.", "With the run command we are creating a service of type ClusterIP why a NodePort here?", "s/Instantiate/Create/", "simple-deployment -> simple-ingress", "simple-deployment -> simple-ingress", "To verify if `ssh-agent` is running do this: \r\n\r\n`ssh-add -L`\r\nIt will interact with the running agent if it exists and provide a list of public keys for the keys that are known by the agent: \r\n\r\n```\r\n$ ssh-add -L\r\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDxVzf2OUJ0wlR+y3CFwEI7fgZXzlwyMlCdRJ1pmZt5GovnN4vjS2RPWTETWZm4KWA20kDVSdIGS0DxkvvOwq2q+toArJgAknfvsXYYtGtAuODWuXf8IXRS+dX6R3bLnqanEq1z45wyc0aVrvU880DS3XtHMuoV3KuvXiPQnuvkWX1pSii+i8MU9LGahqHng1A/BcEh0JeHGR+v7cGmkdpUr6ea5hHwbNL/hdf2BFcyb3HhaHhTiBApIAanM1aoqGra6+tTJwBAUiWt24j0Y67tnFmQxcRY6z7hJM5VBnuOmsVyrA1pKFPodyaTI26EL06r6d0F7eyBkQVtaFVY5d1F /Users/dcooley/.ssh/id_rsa\r\nssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIPBOstcdR9AZSI5dO4XQScJhaHdhZJtxJrRluo+EHKpE dcooley@Duffies-MacBook-Pro.local\r\nssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEA6NF8iallvQVp22WDkTkyrtvp9eWW6A8YVr+kz4TjGYe7gHzIw+niNltGEFHzD8+v1I2YJ6oXevct1YeS0o9HZyN1Q9qgCgzUFtdOKLv6IedplqoPkcmF0aYet2PkEDo3MlTBckFXPITAMzF8dJSIFo9D8HfdOV0IAdx4O7PtixWKn5y2hMNG0zQPyUecp4pzC6kivAIhyfHilFR61RGL+GPXQ2MWZWFYbAGjyiYJnAmCP3NOTd0jMZEnDkbUvxhMmBYSdETk1rRgm+R4LOzFUGaHqHDLKLX+FIPKcF96hrucXzcWyLbIbEgE98OHlnVYCzRdK8jlqm8tehUc9c9WhQ== /Users/dcooley/.ssh/vagrant_rsa\r\n```", "free (as in puppy) ;)\r\n", "Wrong image is being used here. This is an image of the service, rather than deployment pods.", "Insert an image of Cookie Shop v2.0 after this sentence.", "nit: While the explanation is useful, this first sentence is redundant (especially since the user has already used `kubectl logs -f` to review logs by this point). I'd rephrase this a bit.", "yes and in the edit I think we have enough context to just say \"Ingress\" w/o the \"resource\"", "`kubectl get ing` -> `kubectl get ingress`", "This doesn't actually work. See https://coreos.com/tectonic/docs/latest/tutorials/azure", "\"...it will create two [sub-]subdomains; one for the Tectonic...\" <-- Change the semicolon to a colon", "Remove the reference to Route53.", "with it used above in console example, foregoing here", "I don't think `ARM_SUBSCRIPTION_ID` is actually noted above?", "Maybe a little more about \"Bcrypted value\"", "//TODO", "If it's going to be behind an ingress. This should not be LoadBalancer it should be NodePort. \r\n\r\nThe key diff is that type:LoadBalancer will create an public lb and expose the service directly. You shouldn't do this unless you are going to use that as a way to access the app. Otherwise your just throwing money down the tube and exposing your app in a bad way.", "Yes, but why show the image for v1 twice but not v2?", "trailing slash\r\nsee https://coreos.com/tectonic/docs/latest/tutorials/azure/", "Kubernetes Deployment Objects by default use rollingupdate as the way to make changes to pods. ", "line 60? or too unclear/distant?", "use `kubectl explain service`", "use `kubectl explain ingress`", "use `kubectl explain deployment.spec.template`\r\n\r\nexample:\r\n```\r\n$ kubectl explain deployment.spec.strategy.type\r\nFIELD: type <string>\r\n\r\nDESCRIPTION:\r\n     Type of deployment. Can be \"Recreate\" or \"RollingUpdate\". Default is\r\n     RollingUpdate.\r\ngit: enable_psp\r\ndcooley@lynx ~/go/src/github.com/coreos/tectonic-installer\r\n$ kubectl explain deployment.spec.strategy.rollingUpdate\r\nRESOURCE: rollingUpdate <Object>\r\n\r\nDESCRIPTION:\r\n     Rolling update config params. Present only if DeploymentStrategyType =\r\n     RollingUpdate.\r\n\r\n    Spec to control the desired behavior of rolling update.\r\n\r\nFIELDS:\r\n   maxSurge\t<string>\r\n     The maximum number of pods that can be scheduled above the desired number\r\n     of pods. Value can be an absolute number (ex: 5) or a percentage of desired\r\n     pods (ex: 10%). This can not be 0 if MaxUnavailable is 0. Absolute number is\r\n     calculated from percentage by rounding up. By default, a value of 1 is used.\r\n     Example: when this is set to 30%, the new RC can be scaled up immediately\r\n     when the rolling update starts, such that the total number of old and new\r\n     pods do not exceed 130% of desired pods. Once old pods have been killed, new\r\n     RC can be scaled up further, ensuring that total number of pods running at\r\n     any time during the update is atmost 130% of desired pods.\r\n\r\n   maxUnavailable\t<string>\r\n     The maximum number of pods that can be unavailable during the update. Value\r\n     can be an absolute number (ex: 5) or a percentage of desired pods (ex: 10%).\r\n     Absolute number is calculated from percentage by rounding down. This can not\r\n     be 0 if MaxSurge is 0. By default, a fixed value of 1 is used. Example: when\r\n     this is set to 30%, the old RC can be scaled down to 70% of desired pods\r\n     immediately when the rolling update starts. Once new pods are ready, old RC\r\n     can be scaled down further, followed by scaling up the new RC, ensuring that\r\n     the total number of pods available at all times during the update is at\r\n     least 70% of desired pods.\r\n```\r\n", "true enough...", "use\r\n```\r\nkubectl explain deployment.spec.template.spec.containers.livenessProbe\r\nkubectl explain deployment.spec.template.spec.containers.readinessProbe\r\n```", "call out to docs here as a reader I want a link where I can go read more about \"based on application load model\"", "Ah, okay. It should be good then. Didn't actually type in `az login`, but I guess that's where the output is coming from?", "I believe we did that to avoid a trip back to DNS configuration.", "I (somewhat arbitrarily) chose one of the ways I knew to set kubeconfig. I didn't want an intro tutorial freighted with more than one way to do it (with apologies to Larry Wall).", "(resolved)", "noted in sentence introducing the numbered list", "(resolved)"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1771", "comments": ["@edevenport why was this included in this PR? could we remove this doc?", "@squat Sorry about that. It was updated in my original PR before it was removed from master and seems to have gotten restored during my pull. I  rebased and removed the file.", "s/should/must/ to convey that it is a requirement.", "s/should/must/ to convey that it is a requirement.", "Thanks for making that change. Looks like we need to `make docs && make examples` again now", "Done. I also moved the special character requirement to the `Note` line for better division between parameter description and requirements.", "Done.", "And done.", "general concern from my side: this could end up in the tfstate file in cleartext. we have to make sure this is not the case.", "@s-urbaniak I checked the generated `tfstate` file after running a test and the encrypted value is being stored:\r\n\r\n    \"vars.admin_password_hash\": \"$2a$12$TrRQ6hcDeE/ydq49r9.z4.YNjrIncDia3ojSJa7aXbktFe40jdH6O\",\r\n\r\nSo it appears the `modules/tectonic/assets.tf` is storing the encrypted value in the `tfstate` rather than the clear-text value.", "Let's get rid of this here and inject it via an env var in CI, @cpanato do you mind to give directions here?", "I strongly suggest to remove this default value here.", "those variables should be dependency-injected via CI, /cc @cpanato ", "@cpanato I have no visibility into Jenkins. Would you be able to assist me here?", "@cpanato Same issue here with no visibility into Jenkins.", "We dont need to set the admin_email/password because in the rspec tests we randon generate those.", "can you please remove this change?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1767", "comments": ["Nit: Maybe abbreviate to something like\r\n```\r\nif (validate.nonEmpty(name) || /\\s/g.test(name) || !domain || validate.domainName(domain)) {\r\n  return 'Invalid email address.';\r\n}\r\n```\r\n\r\nBTW, do you think `domainName()` should run a nonEmpty() test itself? I notice that some other validators do.", "Good call on the code golf. Fix pushed.\r\n\r\nIdeally I'd like to chain validators. eg: pass an array of validators into a form & have them all required to pass. That way we could avoid an explosion of similar validators (domainOptional, domainRequired)."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1760", "comments": ["I don't think we need to specify the lower-case format here. That is an implementation detail that is taken care of in Terraform.", "Thanks Lucas. \r\n\r\nAgreed, the idea was to \"train\" the user as they may enter mixed characters but provisioning changes it based on the requirement. Happy to remove the docs bits if the team feels like that's the way to go.\r\n\r\nPlease let me know", "I actually think the documentation would be helpful...it shouldn't seem like we are changing user inputted values just to fit our back end needs"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1756", "comments": ["@mxinden can you please add the `ansiColor('xterm')`?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1751", "comments": ["I'm a bit confused by these two new flags. Even though they are named relative to DNS, they affect other resources as well (ELBs).\r\nIs there maybe a more descriptive option for naming them, that better depicts the effects? ", "Right, this is an important point: we need to have names here that are sensible and convey some actual meaning. We could also name them `tectonic_aws_public/private_ingress`. If you have a better suggestion I am all ears; I just don't want to make the name too long and confusing.", "I knew this would come back to haunt me. I'm no better at naming things myself.\r\n\r\nI guess, because they also touch API we can't call them ingress? How about *endpoints* or just *access*? ", "right \"ingress\" can be confusing also because it means something specific in k8s land, although you could argue that here we are referring to \"ingress to the API\".\r\n\r\n\"access\" makes it sound like it's more about security than it really is. Let's go with `private/public_endpoints` for now.", "endpoints it is then!"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1748", "comments": ["@brancz just cut the actual 1.5.1 version (https://github.com/coreos/tectonic-installer/pull/1740#issuecomment-324256049)\r\n\r\n```\r\nquay.io/coreos/tectonic-prometheus-operator:v1.5.1\r\n```"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1743", "comments": ["Suggestion while at it: use a `nn-foo.conf` name scheme.", "@lucab ack, good idea!", "Nit (maybe for later): I think this `bash -c` is useless here and just a leftover from a similar line in another service which is doing a redirection.", "that is indeed a valid point, I factored `bash -c` out in this PR.", "s/ignition_masters/ignition_workers/ (here and lines below)", "good catch, fixed"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1740", "comments": ["Didn't we have a new release?", "This is the release that fixes the upgrade bug. @brancz noted that they will have another bug fix coming this week, which will likely result in 1.5.1 / 1.5.2 actually being cut officially and we will replace that image in a later RC. "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1736", "comments": ["Unfortunately, container_linux_update_operator was the longest name so terraform fmt reformats the whole section and Github shows it as a bunch of changes.", "this is the addition", "@dghubble Can you change line 84 as well to make it consistent? Thank you!", "Using desiredVersion in both places now"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1735", "comments": ["Waiting for a kvo release, /cc @diegs @derekparker ", "ditto"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1719", "comments": ["I'm pretty sure we'll need to add the anti affinity here eventually for patch merges to work.", "@diegs Could you elaborate? Will there be a conflict? Despite that, ideally we don't need the anti-affinity in the selector right?", "It gets defaulted into the selector. So then when you update it later, unless you update in both places you can hit conflicts.\r\n\r\nSee: https://github.com/kubernetes/kubernetes/issues/26202#issuecomment-228558649", "After OOB discussion with @diegs , we think this should work since we now specify both labels and selectors, so selectors will not be default to the label value. Someone also mentioned this in https://github.com/kubernetes/kubernetes/issues/26202#issuecomment-299164110\r\n@diegs will manually test this if he has a chance."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1713", "comments": ["Why is this needed for disruption budget?\r\nWithout this, the budget is able to select both old and new CM.\r\nWith this, then it only selects the new CM and old CM's can all be evicted, what's the purpose of doing this? @squat ", "same here.", "@yifan-gu these are changes that @diegs added, i'm just putting them in the right place. Ask him. If this is not right, then I am just going to revert the changes and we can let @diegs submit the right PR.", "@squat I looked at @diegs 's PR, his didn't add the selector in the **disruption budget**. Am I missing something?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1711", "comments": ["why this specific exception? what if you have 5 nodes but only 50% utilization? that will still cause an alert. as mentioned below, utilization is derived from maxNodes, so you can actually get away with just saying:\r\n```js\r\nif (utilization < 0.75) {\r\n  return null;\r\n}\r\n```", "What about running a single master node with pod range /24? This would cause an error when it should work just fine.", "This test is a little funny IMO; you are using two metrics, one of which is a derivative of the first. Are you only including `maxNodes` because there are times we do not know the real utilization?\r\n\r\nI think it would be more correct to do:\r\n```js\r\nconst isError = utilization > 1;\r\n```", "what about Azure?", "GUI does not support Azure. I changed the comment to be more general.", "Removed bare metal support to make this PR simpler. Will add bare metal support in a future PR when it can be done without needing this hack.", "Removed bare metal support to that this could be simplified."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1710", "comments": ["I believe this line is supposed to go under `module \"masters\"` instead of etcd?", "It is already under \"masters\", github folding is tricking you into believing it's under \"etcd\" instead ;)", "darn you github!", "`${var.tectonic_vanilla_k8s ? \"true\" : \"false\" }`", "let's remove `default` here to enforce variable declaration.", "`installer-latest`: do we want this as a final value?", "Yes, this is a mutable tag dedicated to the installer. We need this here for forward compatibility until some higher level component takes care of the kubernetes->docker mapping.\r\n@robszumski has a tracker item for this somewhere.", "nit: double back-tick on `kubelet.service`", "nit: one of the master nodes", "nit: It does more than that now right? @lucab "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1702", "comments": ["I'm unsure if we want to remove this toleration though. Might need to look into the upstream behaviors this ties into.", "If we leave the toleration then it is possible that a controller-manager or scheduler pod could get scheduled into a slot that was designated for a different critical pod. Maybe this is not a big issue.", "Oh, right. Well we probably do want the controller-manager to have this toleration. it is critical it's just unsafe with the behavior of the rescheduler. But I'm not immediately sure what the interaction would be like. The rescheduler might just keep kicking it off, and then it keeps getting rescheduled.\r\n\r\nIt's probably just not safe to run the rescheduler on the master nodes at all -- maybe that's the end goal we get to (and then we also remove the annotation / taint). And priority / preemption will deprecate rescheduler anyway).", "This might be less of a big deal now that I'm thinking of it. We should just say \"do not run the rescheduler on master nodes, your master nodes should be provisioned such that they have a minimum of X resources and nothing else is scheduled there\"."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1699", "comments": ["We should keep -amd64 I guess?", "@rithujohn191 Is 2.6.0 okay for 1.7.3 or do we plan to get another version?", "@xiang90 @hongchaodeng Can we update to etcd v3.1.8 and etcd-operator v0.4.2?", "we should also bump here", "2.6.0 is fine :+1: ", "@xiang90 - can you review etcd version for 1.73, so we can move forward with the release milestone", "@sudhaponnaganti Just talked to @hongchaodeng. Let's keep using the old etcd / etcd-operator versions until the TPRs are migrated to CRDs in our repository.", "0.4.4 is going to come out", "kvo is not bumped", "sweet, thank you!", "yes, it is not out yet (cc @derekparker).", "actually 0.4.3", "I reverted that change anyways"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1696", "comments": ["Does Jenkins setup Github Hooks additionally?", "which githooks?", "the pr trigger does the githooks, this is exactly the same we have today"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1684", "comments": ["Just remove this before merging. No need to checkin commented code", "Removed"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1681", "comments": ["s/under/in the/", "done", "s/folder/directory/", "no need for backticks around \"Tectonic Installer\"", "s/`master` branch or other//", "s/around/at/\r\n\r\nWe are configuring this test and we should be able to say confidently when it runs.", "If I change this file in Git, the changes will be reverted? What do you mean by \"here\"?", "typo: s/brach/branch/", "done", "done", "done", "changes in the jenkins, when you read this in the jenkins, here then means in jenkins not in the git"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1680", "comments": ["2nd sentence is confusing  ... Export an environment variable with the cluster name on which the build directory structure will be based?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1676", "comments": ["Go ahead and merge in case there are no spaces (e.g. `worker && ec2`) needed here."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1661", "comments": ["~~Shouldn't this be `this.refs.dropdownElement`?~~ Nevermind I see the relevant changes below."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1660", "comments": ["nit: this regular expression only checks if a string is version <0.10, not if it is a valid version in general, so consider renaming for clarity and maintainability, e.g. `sub10Rx`", "s/TerraForm/Terraform/", "s/TerraForm/Terraform/", "typically, we don't use `var` within func blocks. Consider rewriting as `prepCommand := \"init\"`", "Good spot!\r\nThis is all over the file, and thus got copy-pasted in here.\r\nI'll fix it everywhere.", "copy-paste. will fix.", "Don't have any preference here. I'll rename it.", "Make sense. I'll adapt it."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1658", "comments": ["Just a minor thing: Update the message to be `Tectonic Installer PR Trigger No Smoke Tests` or something like that", "Good catch. Thanks. Fixed."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1654", "comments": ["The link is missing here"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1652", "comments": ["Is the point of editing your machine's `/etc/hosts` here to avoid making DNS changes and to use the name from the hosts file for the duration?", "I have no idea.", "No, this is intended only as a test. We expect users would create this dns record out of band for a permanent setup."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1650", "comments": ["What does `currentBuild()` contain that the Jenkins pipeline needs?", "before we didn't pass anything to the job. Now I just add this in case for the future we send parameters from this trigger", "If we don't need to send anything over, can we delete this? Just makes debugging easier in the future. What do you think?", "sure", "done"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1644", "comments": ["Unfortunately, container_linux_update_operator was the longest name so terraform fmt reformats the whole section and Github shows it as a bunch of changes.", "added ^", "added ^"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1641", "comments": ["Looks good overall, but tests are failing because our linter is complaining that rather than making the hosted zone slice here, you should just declare the slice var:\r\n```go\r\nvar allZones []*route53.HostedZone\r\n```"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1637", "comments": ["The ident is wrong here. One space too much. When bootkube is trying to create the image it fails.\r\nWhen trying to manually create the manifest against a cluster, I get the following error:\r\n```\r\nerror: error converting YAML to JSON: yaml: line 58: did not find expected '-' indicator\r\n```\r\nWhen removing one space from line 96 through 101, I can create the manifest successfully.", "Sorry about that, the lines I added below there were indented one extra too so I fixed that too."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1636", "comments": ["let's just use https://account.coreos.com", "The following steps must be executed on a machine that has ...."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1631", "comments": ["<3"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1624", "comments": ["separated - for all three files.", "@zbwright argh!! English as second language.. Can I have do not test-doc tag to save time and $$ ?\r\n", "of course. can you not apply the tag yourself? I know I can't apply it myself in some repos.\r\n", "@zbwright : I can't apply tags, thanks :)"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1623", "comments": ["> Large group counts will not work with reverse proxies that limit HTTP headers to 4K.\r\n\r\nThe Ingress Controller limits headers to around ~8 Kb by default.  `groups` refer to LDAP or github - something that you connect to dex.  I think these docs would make more sense with other auth docs somewhere.\r\n\r\n\r\n> These counts will return an error similar to that returned for a cookie based approach. \r\n\r\nThe error that end users will see is something like: `400: Request Header Or Cookie Too Large` after they log in to console.  Also, we no longer use cookies for auth.\r\n\r\n> \"Normal\" HTTP header setups will support 1M header.\r\nA \"vanilla\" Tectonic cluster will run into the Ingress Controller limit mentioned above.", "I believe the configmap in question is actually called `tectonic-custom-error` in `tectonic-system`.  "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1622", "comments": ["nit: might assign this name to a var because it's used as `f` above, and here.", "I'm assuming this is just unfortunate git diff parsing?", "yes.", "Fixed"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1618", "comments": ["This should probably have a newline", "missing new line"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1616", "comments": ["This is unnecessary. This behavior was introduced specifically for supporting updates of core components where we must guarantee that there is always at least one copy running (even on single master). We don't need to ensure that consoles can be co-located on a single-master during an upgrade. If the console is down for a moment during an upgrade - it will be recreated soon enough (and not worth the complexity here).\r\n\r\nIf you're going this route I'd just say use a daemonset, you're essentially trying to re-create that behavior. But either way, any changes to these manifests need to have full upgrade plans before merging here. Moving these from a deployment to a daemonset would currently require a migration step.\r\n\r\n", "Thanks @aaronlevy, makes sense.\r\n\r\nI don't think a daemonset is required either. I'll elaborate further on what i'm trying to solve in the comments of this PR."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1591", "comments": ["Are these correct? Maybe good to run `make-update-payload.sh` on the branch if you haven't cherry-picked your check code in yet?", "Looks like the TPO was not cherry-picked yet. Good catch. That's why.", "Oh so https://github.com/coreos/tectonic-installer/pull/1576 only cherry-picked parts of that TPO PR. That's kinda ridiculous.", "When the TPO went in the payloads were not updated, that's why my PR had these changes too.\r\n\r\nI'd say just make sure you run `make-update-payload.sh` on the release branch before you cut the next RC. And maybe consider cherry-picking the check you added, it's a really good addition :)", "There was an issue with the cherry-pick still: \r\n- https://github.com/coreos/tectonic-installer/pull/1574/files\r\n- https://github.com/coreos/tectonic-installer/pull/1576/commits/e6b5d5a57896c7e69c898edded5b722ab50d8dbf\r\n\r\n@amrutac had a similar issue during the last release - where cherry-picking the commit would not get everything - because there was also a merge commit.", "I always always run make-update-payload.sh on the release branch. The payload is indeed in sync with what is in the branch. But what is in the branch is not accurate.", ":+1: ", "Fixed by https://github.com/coreos/tectonic-installer/pull/1594"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1588", "comments": ["Not sure that I agree with the approach... this assumes that the service principal (and by extension, `ARM_CLIENT_SECRET`) used for the installer is the same as the one we want to use for cloud provider config.\r\nIs that what we want to do?", "@metral I'll let Mike comment on this as the change came based on a recommendation Mike made to me. (Also I just realized I was asked to rebase commit & push again but I'll wait until after we answer your point @justaugustus )"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1586", "comments": ["is it always eth0? cc @crawford @euank "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1582", "comments": ["nit: Can we make this an ES6 arrow function?", "Weird. I have no idea why I did it the old-school way."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1577", "comments": ["lets strike tectonic.com"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1573", "comments": ["Just to make sure the folder exists, can we add a `folder(\"triggers\")` here? Or would that conflict with duplicate ones?", "Just to make sure: Does this notify us if a PR build fails, or if a PR trigger failed? The former could become quite noisy.", "What does this label do? I am confused because we are testing PRs with this Jenkins job and not the master branch. Sorry if this is a stupid question.", "this was in the original job. It means this job will run only on master. since this is just a trigger and doesn't have any dependencies we can trigger that in the master and not in the slaves.", "both cases.", "the folder is already there"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1564", "comments": ["s/and to check the build/and check the build/", "Why is this written as a string and then parsed?", "I will split this in another file and load here. Will be better for reading", "I am just confused why we are using a workflow definition here?", "done", "because It is a little bit better when using the parametrized cron", "I will keep this for now, I need more experiments to split that.\r\n\r\nif you want to see the job please look into this https://jenkins-tectonic-installer.prod.coreos.systems/job/maintenance/job/tag_clean_aws_resources_grafiti/configure\r\n\r\nafter let me know then I will delete that. I also disable the job to not run this is just for your validation", "@cpanato Why don't we use `script` like we do in the main [Jenkinsfile](https://github.com/coreos/tectonic-installer/blob/master/Jenkinsfile#L145)?", "Is it possible to load this from a file or something so we can avoid all the escaping?", "yes! will do that", "will change that"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1562", "comments": ["Appears that the public key changes aren't working:\r\n```\r\n* module.master_nodes.var.core_public_keys: variable core_public_keys in module master_nodes should be type list, got string\r\n* module.etcd.var.core_public_keys: variable core_public_keys in module etcd should be type list, got string\r\n* module.worker_nodes.var.core_public_keys: variable core_public_keys in module worker_nodes should be type list, got string```"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1561", "comments": ["these will need `-tectonc.1`", "these will need `-tectonc.1`", "the channels are either `Tectonic-1.7-preproduction` or `Tectonic-1.7-production`", "note that these are separate from the complete version string", "these will need `-tectonc.1`", "capital in the channel name", "update channel name to reflect it not being the version", "reorder this so its at the top maybe?\r\n\r\n - if you see this error\r\n - this caused it\r\n - this is how you fix it", "whats the `or t` here? typo?", "maybe say \"ThirdPartyResource which stores update status\""]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1542", "comments": ["Does this still make sense to be configurable? Can you have standard storage with managed disks?", "Small nit: this value isn't really used inside the tectonic module and it's also required when building vanilla K8S clusters (which would normally skip everything else in module tectonic. It's also required pretty early on. \r\n\r\nMay I suggest we move this ID into the `modules/azure/resource-group` module? \r\nThat module would eventually become some sort of boilerplate where we collect global stuff and we'd change it's name to something more appropriate.", "@alexsomesan Yes, `managed_disk_type` is actually required to enable the use of managed disks for the OS disk.\r\n`Premium_LRS` yields SSD, while `Standard_LRS` will provide HDD.\r\n\r\nI considered parameterizing the value, but I'm not sure that we want to encourage HDD use.", "We already have a parameter for the storage type today. I think it sets the storage account type. Was suggesting to repurpose it for here.\r\nWe can do that in a follow up as well."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1535", "comments": ["Doesn't the number of resources to create depend on the size of the cluster? Would larger clusters claim to be completed far sooner than they actually are?", "Since pending & cancel are styled the same and the cancel parameter isn't used anywhere besides this PR, would it make sense to subsume them both into a parameter & style called inactive? eg:\r\n\r\n```jsx\r\n <WaitingLi inactive={terraformRunning || tfError} done={allDone} error={anyFailed} key=\"tectonicReady\">\r\n```\r\n", "Actually, the style is different. They have the same text color, but different icons.", "Oh. Nevermind then.", "Yeah, I tried getting a more accurate number my looking at the number of instances, but that turned out to not be so helpful. It needs more experimentation, but I'd like to do that in a separate PR."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1527", "comments": ["Not sure if we need pick #1235 here, I asked in https://github.com/coreos/tectonic-installer/pull/1235#issuecomment-318546360", "Thanks for catching this.", "it is extremely subtle that this PR modifies the CLUO flags. Do you know why it is the case?", "The payload is generated from all the updater manifests. This is pulled from some changes in this file:\r\n\r\nhttps://github.com/coreos/tectonic-installer/blame/master/modules/tectonic/resources/manifests/updater/operators/container-linux-update-operator.yaml\r\n\r\nThis file is strictly auto-generated from other parts of the tree, which is why your other PR to sanity check it makes sense. In some sense it should be automatically updated as part of the release process rather than relying on someone to manually run a script as we do today.", "Agreed. My question I guess was ... Why did PR #1235 modify the CLUO flags?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1526", "comments": ["This is still in a folder named `flannel-vxlan`; it should probably be moved/copied to be less confusing.\r\n\r\nAlso, does this folder really only impact azure?", "May I suggest that we still pass the input variable to configure the type and in case of it not being set default to udp?\r\n\r\nSomething like:\r\n`flannel_backend_type = \"${var.tectonic_flannel_backend_type == \"\" ? \"udp\" : var.tectonic_flannel_backend_type}\"`", "By default, `flannel_backend_type` is being set to vxlan to ensure that all other providers other than Azure are set up appropriately per our recommended settings, and so that the user does not have to provide this variable themselves in their tfvars: https://github.com/coreos/tectonic-installer/pull/1526/files#diff-264131a8410d0f8f58af1c713d120c53R100\r\n\r\nTherefore, `flannel_backend_type` won't ever be an empty string unless the user makes it so in their tfvars for Azure - an action we cannot rely on the user to do/know about. I hardcoded it to `udp` for Azure to force it as the backend type, while we wait for a proper fix for the Azure + vxlan issue.\r\n\r\nI'd like to to make the type be configurable with a default value available as you show in your suggestion, but I'm not sure if the current implementation and assumptions allow for it. Any ideas?\r\n", "@metral Sorry, I missed the fact that we default the toplevel var to `vxlan`. Your approach makes sense then, especially in the light of it being temporary while the vxlan issue is being addressed."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1525", "comments": ["Maybe put a warning that you should first upgrade to `v1.6.7_tectonic.2` before trying to upgrade to v1.7?", "Absolutely, I mentioned it earlier in Slack and forgot to include it there, thanks! Maybe @robszumski you'd like to input your own wording?", "note that this isn't confirmed yet", "Should the date be updated?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1520", "comments": ["would these read better as a list?", "would these read better as a list?", "can we replace `SOME-VERSION` with `1353.8.0` as it appears above?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1511", "comments": ["To allow the Tectonic worker to what?", "change to 'Or, use `yum-config-manager`:", "change to 'Configure SELinux' or 'Set SELinux to Permissive mode' or something descriptive.", "does this line need to be removed, since (I assume) `yum-config-manager` is the case for when subscription manager isn't in use?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1510", "comments": ["TCO allow to upgrade through every intermediate versions"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1502", "comments": ["Clicking this opens a new window. Don't we want to keep the icon so the user knows what to expect?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1483", "comments": ["this should not be the `description` instead of `default`?\r\nand `default = \"\"`", "Haha, a good catch ;-D"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1482", "comments": ["do we need to build every time this image?", "@cpanato Just out of simplicity I do right now as the image is changing quite a bit. In the long run I will push it to quay.", "need this? or is just for debug?", "same here", "`aws` should be inferred from the tfvars file.", "Let's pin this down to the latest available and update explicitly when new versions come out.", "For documentation purposes, as discussed: Gem file versions are enforced via 'Gemfile.lock` which is checked in as well. I added a commit that executes RSpec via Bundler to make sure these versions are enforced. Thanks for the hint.", "I think we have a chance to streamline the test workflow here if we move the building of this image to it's own workflow. We already have a good story there for the builder image, so we can just do the same.", "This should actually not be necessary. The ruby base image already provides bundler and rake, while rubocop and rspec should be installed via bundler from the project Gemfile (so we know which versions we run with).", "Sounds good. That's a sane plan. Thanks.", "You don't need a helper method for this. \r\nThere is a simpler way to achieve this in ruby - just call the `to_s` method on the boolean var:\r\n```ruby\r\nflag = true\r\nflag.to_s\r\n```", "Let's call this something neutral like `data` or `values` or something, just in case we end up also supporting parsing the key-value format of tfvars.", "I'd put this as a method in `EnvVar`:\r\n```ruby\r\nEnvVar.aws_credentials_defined?\r\n```\r\nalternatively I'd outsource it into a method in `AWS`\r\n```ruby\r\nmodule AWS\r\n  def self.check_prerequisites\r\n    raise 'AWS credentials are not defined.' unless aws_credentials_defined?\r\n  end\r\n\r\n  def self.aws_credentials_defined?\r\n    credential_names = %w[AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY]\r\n    EnvVar.set?(credential_names)\r\n  end\r\nend\r\n```\r\nSame goes for every other `set?` call", "You could also make it bang method:\r\n```ruby\r\nmodule AWS\r\n  def self.check_prerequisites!\r\n    check_aws_credentials!\r\n  end\r\n\r\n  def self.check_aws_credentials!\r\n    raise 'AWS credentials are not defined.' unless aws_credentials_defined?\r\n  end\r\n\r\n  def self.aws_credentials_defined?\r\n    credential_names = %w[AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY]\r\n    EnvVar.set?(credential_names)\r\n  end\r\nend\r\n```\r\nThe `!` indicates a dangerous operation, which this one is, as it raises an error if certain environment variables are not defined.", "You can also write this as\r\n```ruby\r\nEnvVar.set?(%w[TF_VAR_tectonic_aws_ssh_key])\r\n```\r\nas it is more consistent with your other array definition.", "You could rewrite this method to this\r\n```ruby\r\ndef self.set?(*vars)\r\n  vars.all? { |var| ENV.has_key?(var) }\r\nend\r\n```\r\nThis has two advantages:\r\n1. `has_key?` is more readable than `!ENV[cred].nil?`, plus instead of `cred` you'd use `var`, which is the singular of your initial parameter name\r\n2. The `*` before the `vars` argument automatically turns the parameters into an array. This way you can call this method with an array, one or multiple single parameters. E.g:\r\n```ruby\r\nEnvVar.set?('env_var')\r\nEnvVar.set?('env_var1', 'env_var2')\r\nEnvVar.set?(%w[env_var1 env_var2])\r\n```\r\nare all valid method calls that will return your desired result.", "Maybe you could put all these small modules where you wrote `helper functions` into a comment into a separate `helpers` folder.", "```ruby\r\n@name = (ENV['CLUSTER'] || generate_name(prefix)).downcase\r\n```", "You could use an alias for this, directly below the `destroy` method:\r\n```ruby\r\n  alias stop destroy\r\n```", "I'd suggest to let this class name end with `Error`, e.g. `KubeCtlCmdError`", "This can raise errors, so maybe make it a bang method. Same goes for the rest of the code where errors are raised.", "This is never called. But if you use it later on, In case the result is not expected to change, you could also cache it\r\n```ruby\r\n@amount_nodes ||= begin\r\n  KubeCTL\r\n    .run_and_parse(@kubeconfig, 'get nodes')\r\n    .fetch('items')\r\n    .length\r\nend\r\n```", "No helper method for this? ;)\r\nI'd invest a little time into some meta programming for all these envs to abstract a little further, as they really appear all over your code.", "Maybe the method name is slightly misleading? I'm not sure.", "```ruby\r\n\"#{Dir.pwd}/../../build/etc...\"\r\n```\r\nWhy don't you check here if the copying is successful? In all the other preparation methods you check if the process finished successfully.", "```ruby\r\ndef destroy\r\n  3.times do\r\n    return if system(env_variables, 'make -C ../.. destroy')\r\n  end\r\n\r\n  raise 'Destroying cluster failed'\r\nend\r\n```", "```ruby\r\ndef wait_til_ready\r\n  100.times do\r\n    begin\r\n      KubeCTL.run(@kubeconfig, 'cluster-info')\r\n      return\r\n    rescue\r\n      sleep 10\r\n    end\r\n  end\r\nend\r\n```\r\n\r\nThis method also doesn't raise an error. It appears kind of inconsistent to me, but maybe it has its purpose. In that case nevermind.", "Constants should be defined at the very top of a class definition.", "If you use three dots, you get the same result\r\n```ruby\r\nname += SecureRandom.hex[0...RANDOM_HASH_LENGTH]\r\n```\r\nFurthermore, you could rewrite this as the following, if you want\r\n```ruby\r\ndef generate_name(prefix)\r\n  prefix.tap do |name|\r\n    if Jenkins.environment?\r\n      build_id = ENV['BUILD_ID']\r\n      branch_name = ENV['BRANCH_NAME']\r\n      name.replace(\"#{prefix}-#{branch_name}-#{build_id}\")\r\n    end\r\n\r\n    name.replace(name[0..(MAX_NAME_LENGTH - RANDOM_HASH_LENGTH)])\r\n    name << SecureRandom.hex[0...RANDOM_HASH_LENGTH]\r\n  end\r\nend\r\n```", "When I hear `run`, I don't think about a helper method,  I think about a service. Kind of like a command pattern.", "I'm a little confused where this `kubectl` method comes from and what the `English` import is.\r\nFurthermore\r\n```ruby\r\n...\"#{args} -ojson\")\r\n```\r\nWhy is there no Error raised in case of failure like in the method above?", "Is this defined outside of the module on purpose?", "If you move this into a class, you can save states and don't have to look up the compiled binary to check if compilation was successful. On top of that, see the service comment above.", "In case you unit test a certain class, you can simply write it's name here. Additionally you should be able to get rid of the `RSpec`\r\n```ruby\r\ndescribe TFVarsFile do\r\n...\r\nend\r\n```", "As you now used `TFVarsFile` as an argument for the `describe` method above, you can change this into\r\n```\r\nsubject { described_class.new(TFVARS_FILE_PATH) }\r\n```\r\nwhere `described_class` refers to `TFVarsFile`. This is executed before every single test, contrary to your existing `before` method.\r\n`subject` is a shorthand for RSpecs default method to set up variables\r\n```ruby\r\nlet(:subject) { ... }\r\n```\r\nOn top of that, it allows you to refer directly to this subject with `it` and use a one-liner syntax for tests. See below.", "If you test methods, you usually describe them with a `#`\r\n```ruby\r\ndescribe '#path' do\r\n  subject { described_class.new(TFVARS_FILE_PATH).path }\r\n\r\n  it { is_expected.to eq(TFVARS_FILE_PATH) }\r\nend\r\n```\r\nThis would require you to define the subject again for every test. You could also define you subject on top once and then do it like this:\r\n```ruby\r\ndescribe '#path' do\r\n  it 'returns the correct file path' do\r\n    expect(subject.path).to eq(TFVARS_FILE_PATH)\r\n  end\r\nend\r\n```\r\nI'd also discourage you from testing simple attribute readers.", "```ruby\r\ncontext 'with a wrong file path' do\r\n  subject { describe_class.new('wrong-file-path') }\r\n\r\n  it { is_expected.to raise_error(RuntimeError) }\r\nend\r\n```\r\n\r\nThis is the one-liner syntax previously referred to. `subject` is, just like `let` lazy evaluated.", "???", "Shared examples are used to reuse code across various different specs. You use it only once and do not refer to the object under test at all. This should be a stand alone spec imho.", "Expect this to not raise an error.", "Went with the first solution for now. Once the function gets out of hand I will split it up further. Good to know about the bang convention! Thanks.", "Uuh, this is fancy. Adjusted accordingly.", "This looks a lot better. Thanks", "I will probably extend this method in the near future. Should I still make it an alias? \r\n\r\nDidn't know about alias feature. Thanks.", "I have removed it, as we will probably not use it in the near future. Is there any tooling around finding unused code even though it is a dynamic language?\r\n\r\nThis still looks interesting. I didn't know ruby's syntax allows the `|| =`, cool, thanks!", "Moved to separate private method. Thanks for the hint.", "That's true, but only because they don't throw proper exceptions. `Fileutils.cp` does. Is it a bad coding style to let this exception just propagate down to RSpec?", "Now this is just marvellous! Changed. Thanks.", "This is a lot better to read. Thanks. Function now raises an exception as well. Thanks for raising the awareness here.", "\ud83d\udc4d Thanks", "Changed to the triple dots. `tab` syntax seems too complicated for me as a ruby beginner, but good to know for my ruby future.", "Good catch. Fixed. Thanks.\r\n\r\nIf `run` throws an error, `run_and_parse` will throw the error on to the initial caller, right?", "Sounds better, thanks.", "So far there is only one spec, but there will be many more once this PR is merged.\r\n\r\nThe shared example will actually create the object under test (`@cluster`). The `withCluster` shared example defines a minimum set of things, every test should have, namely:\r\n1. Spin up cluster\r\n2. Stop cluster\r\n3. Run the Smoketest suit\r\n\r\nFrom here we can define specific test steps inside the tests themselves with additional `it` blocks, which access the `@cluster` created by the shared example.\r\n\r\nDo you think this is a bad practice?", "\ud83d\udc4d thanks", "I don't want to export this function to the outside of this file. So I thought not to include it in the module. What would be a better way to make this private?", "But then I need to keep a reference to the class around as well. I think I prefer the module for now. Or is there anything that speaks against modules in general? I am mostly using it to structure the code, and to emphasize, what should be used outside the file, and what not.", "The plan is to add the `include_examples` to every test that needs a running k8s cluster. Do you think this is a bad practice? `withCluster` will inject a set of basic logic into the test. Specific test logic can then be added to the test e.g. with adding `it` blocks here. ", "\ud83d\udc4d Cool, thanks", "Ah, cool. Changed that. Wow, RSpec has a lot of features.", "This is fancy, thanks! Always wondered how to catch exceptions that are raised in the prepare steps.", "Do I need to wrap the `describe` around each `it`, even though there is only one `it`?\r\n\r\nI don't want to test the attribute readers in particular, but the parsing logic of the file underneath. Let me know if you can think of a better way of doing that?", "Good hint. Will do that once this gets out of hand.", "Well no you don't have to. I think readability-wise there's not much of a difference.", "I'm not sure about that. What I do know is that there are gems to measure your test coverage. If you test conscientious and don't dynamically define methods then you should be on the right track.", "That's up to you. If you catch the exception and raise your own, then you lose the information from the initial exception and won't see it in the stack trace. You could also define your own custom error class like you did with `KubectlCmdError` and pass it the message of the initially raised exception.", "Not if you use a class and save the state statically. If you insist on using the module then you could just remove the `build unless compiled?` line and the `compiled?` method. It's an internal API and if it's properly communicated and documented that `build` has to be called before `run` then there shouldn't be a problem. This way you can spare yourself the file system access on EVERY call of `run`.", "Well, it is exported anyway and exposed to the global namespace as soon as you require it from another file. You cannot really cherry pick afaik. You can make the method private though:\r\n\r\n```ruby\r\nmodule SmokeTest\r\n  ...\r\n  def self.env_variables(cluster)\r\n    ...\r\n  end\r\n\r\n  private_class_method :env_variables\r\nend\r\n```", "Well it's just a suggestion for structuring your tests:\r\n```ruby\r\ndescribe '#method_name' do\r\n  it 'does this and that' do\r\n  end\r\n\r\n  it 'does something else with different parameters' do\r\n  end\r\nend\r\n```", "For the second part, I don't understand what you mean. What you do with this specific test mentioned is to test if the attribute reader returns the path that you assigned to it in the initializer. There is no logic under test in this method at all.", "I think I'd rather appear.in about this than to discuss this in text form :D", "You used the wrong method name here.", "Ah, yes, you are right.", "Good catch, thanks."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1481", "comments": ["Nits: Why is `Tectonic Installer` hyphenated? This should not have dashes anywhere, unless you are delimiting words in a string.", "same", "same", "same", "same", "done", "done", "done", "done", "done", "I would prefer to call this \"tectonic-installer-nighlty-trigger\", because it is not actually testing but just triggering the testing pipeline. What do you think? The file would then be \"tectonic-installer-nightly-trigger.groovy\".", "done @mxinden ", "@cpanato merci\r\n", "de nada :)"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1480", "comments": ["Just grepped `tectonic-dns-group` in our code base and didn't find anything, also our test setup doesn't include this resource. Unless I am missing something (which is possible) creating this resource group seems unnecessary?", "I believe we established the convention in the documentation not to use Makefile targets at all (/cc @robszumski @sym3tri for verification).", "nit: the `null_resource` provisioner is an implementation detail. I don't think we should mention it here.", "Is there any way that the docs can omit the Azure-specific notes? Though the note is relevant to Azure, they are also being added into the docs for AWS, baremetal, openstack etc. which may confuse the end user of those other platforms.", "nit pick - should be: Master nodes are fronted by one load balancer for the API **and** one for the Ingress controller.", "I suggest we rephrase this bullet point to call out that Terraform on Azure currently leverages SSH to copy the assets and run bootkube on the first master chosen.", "@metral Fixed.", "@metral Agreed I felt the same, but nothing came to mind as it's a top-level var.\r\nMaybe @s-urbaniak or @alexsomesan have thoughts?", "add a blank line after the header.\r\n\r\nand \"Ensure [Go][go] is installed.\"\r\n\r\nadd \"[go]: https://golang.org/doc/install\" at the bottom of the page.", "This is Azure's default DNS implementation. For more information, see the [Azure DNS overview][azure-dns].\r\n\r\nand add to the bottom of the page:\r\n[azure-dns: ]https://docs.microsoft.com/en-us/azure/dns/dns-overview", "See the Microsoft Azure documentation for instructions on how to [delegate a domain to Azure DNS][domain-delegation].\r\n\r\nadd: [domain-delegation]: https://docs.microsoft.com/en-us/azure/dns/dns-delegate-domain-azure-dns", "[Azure CLI][azure-cli]\r\n\r\nand, bottom of the page:\r\n[azure-cli]: https://docs.microsoft.com/en-us/cli/azure/install-azure-cli", "... are created as an availability set ...", "At this time there is really a way. \r\nWe would need to evolve the terraform-docs tool to support this. It would be great to have it though."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1475", "comments": ["Could we add some more clarification for what these experimental manifests are? link them to the path in our repo?", "Should we add the --test.v option so they know to run it verbosely?", "It will be helpful to split out the \"Get Tectonic cluster ID\" code into a separate function which can be reused later.", "has this been tested to be a good upper bound timeout?", "Rather not do that. This documentation is not relevant to my Pr. I am just cleaning up some stuff that was not properly documented before when the test-all-manifests tests were added. ", "Sure, I can add a note", "ok", "Yes, it takes fraction of a second to do big query test once the API is up. This allows us 6 attempts at getting the data from bigquery. ", "Ok will do", "added it in a note below this line :)", "i created a getTectonicClusterConfig func that we can use to generically get vars from it"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1469", "comments": ["I removed these 3 commands because they're already being run by `make structure-check`. I thought it would simplify things for contributors to only have 1 command to run instead of 4.", "Small thing: the re-generated docs and examples are NOT automatically committed. The contributor must explicitly include the changes to the examples and docs into their commits.", "@alexsomesan Good clarification. Can't be too explicit about that. Give the new wording a look."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1468", "comments": ["maybe s/translates/correlates/", "all labels can be a single label. I don't think you need `(s)`"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1467", "comments": ["Why not just rename `gui-tests-cleanup` on line 133? It does the same thing.", "Ahh! overlook that. This pr dont need then. closing"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1466", "comments": ["Can you add \", defaults to CoreOS custom terraform release (github.com/coreos/terraform)\" to the description?", "I would like to use this job both for our standard tectonic-builder as well as the *upstream-terraform* tectonic builder. Can we change this to something along the lines of \"Build quay.io/coreos/tectonic-builder Docker image, either with github.com/coreos/terraform (default) or custom Terraform release, e.g. http://github.com/hashicorp/terraform/.\"?", "What do you mean by \"Changes here will be  reverted\"? ", "sure will do", "if you change the jenkins job manually in the jenkins server the next time the seed job runs it will revert any manual change. To change the job you need to change this code.", "for the first comment will do as well", "%s/and for/and/", "%s/create/creates/", "%s/jobs/job/", "%s/have/has/", "Can you follow markdown convention here?\r\n\"## Tectonic-Builder Jenkins Job\r\n\r\ne.g. https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet", "%s/need build/need to build/", "%s/not/don't/", "done", "done", "done", "done", "done", "s/Tectonic-Builder/tectonic-builder/", "s/Tectonic-Installer/Tectonic Installer/", "done", "done", "by \"version\" you mean \"tag\", right?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1464", "comments": ["Would it at all be possible to /s/flannel-manifets/cni-manifests/ \r\n\r\nThis would be handy if we were to support other CNI plugins in the future.", "or `net`"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1450", "comments": ["more background on \"this situation\". Am I off the internet? What does my account look like?", "Agree on lack of context- aded some"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1449", "comments": ["This looks really cool!\r\nJust one suggestion: As a general rule we're trying to keep the user-facing configuration as simple as possible. I think we actually don't need two variables to take this input.\r\n\r\nWould you mind using just one user input variable and make it an array?\r\n"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1444", "comments": ["s/We/The Tectonic CI", "the path for the Dockerfile is not right", "also dont need to use the `-t quay.io/coreos/tectonic-builder:v1.33-upstream-terraform` as described in the readme?", "\ud83d\udc4d ", "Its up to you if you build and then tag, or just tag during building via `-t`. But probably easier in two steps. Adjusted accordingly. Thanks.", "ok thanks!", "let's be consistent with the casing of `Terraform`. Either `terraform` or `Terraform` but we should not switch.", "Is this the release bundle or the binary itself?", "Nevermind, I saw it below \ud83d\udc4d ", "This is hard to comprehend on one line.\r\nAny chance we could break it down into multiple lines?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1440", "comments": ["cleaning up the existing Kubernetes state \r\n\r\nnot just etcd. it is actually more k8s related state.", "we probably want to warn people a little bit on this. maybe ask them to backup etcd data before removing?", "systemctl restart kubelet.service?", "found that this needed to be sudo", "`$` in front of all of these", "found that this needed to be sudo", "sudo", "Even with sudo, this did not work for me, spewed a bunch of:\r\n\r\n```\r\nrm: cannot remove '/var/lib/kubelet/pods/e3d123f3-6cc3-11e7-bb4f-06c278b62e96/volumes/kubernetes.io~secret/default-token-krhns': Device or resource busy\r\nrm: cannot remove '/var/lib/kubelet/pods/1cc369d7-6728-11e7-ada1-06c278b62e96/volumes/kubernetes.io~secret/default-token-krhns': Device or resource busy\r\nrm: cannot remove '/var/lib/kubelet/pods/1cc60359-6728-11e7-ada1-06c278b62e96/volumes/kubernetes.io~secret/default-token-krhns': Device or resource busy\r\nrm: cannot remove '/var/lib/kubelet/pods/dfb5ccd6-6727-11e7-ada1-06c278b62e96/volumes/kubernetes.io~secret/default-token-krhns': Device or resource busy\r\nrm: cannot remove '/var/lib/kubelet/pods/d6912990-6728-11e7-a172-02c7e4d4d0f8/volumes/kubernetes.io~secret/default-token-kbmm6': Device or resource busy\r\nrm: cannot remove '/var/lib/kubelet/pods/1cc47b6f-6728-11e7-ada1-06c278b62e96/volumes/kubernetes.io~secret/default-token-krhns': Device or resource busy\r\nrm: cannot remove '/var/lib/kubelet/pods/1cc8c865-6728-11e7-ada1-06c278b62e96/volumes/kubernetes.io~secret/default-token-krhns': Device or resource busy\r\nrm: cannot remove '/var/lib/kubelet/pods/1cc8c865-6728-11e7-ada1-06c278b62e96/volumes/kubernetes.io~secret/secrets': Device or resource busy\r\nrm: cannot remove '/var/lib/kubelet/pods/dfb3a234-6727-11e7-ada1-06c278b62e96/volumes/kubernetes.io~secret/default-token-krhns': Device or resource busy\r\nrm: cannot remove '/var/lib/kubelet/pods/dfb3a234-6727-11e7-ada1-06c278b62e96/volumes/kubernetes.io~secret/secrets': Device or resource busy\r\nrm: cannot remove '/var/lib/kubelet/pods/e0491ac8-6728-11e7-a172-02c7e4d4d0f8/volumes/kubernetes.io~secret/default-token-krhns': Device or resource busy\r\nrm: cannot remove '/var/lib/kubelet/pods/e0491ac8-6728-11e7-a172-02c7e4d4d0f8/volumes/kubernetes.io~secret/member-peer-tls': Device or resource busy\r\nrm: cannot remove '/var/lib/kubelet/pods/e0491ac8-6728-11e7-a172-02c7e4d4d0f8/volumes/kubernetes.io~secret/member-server-tls': Device or resource busy\r\nrm: cannot remove '/var/lib/kubelet/pods/e0491ac8-6728-11e7-a172-02c7e4d4d0f8/volumes/kubernetes.io~secret/etcd-client-tls': Device or resource busy\r\nrm: cannot remove '/var/lib/kubelet/pods/e351e704-6cc3-11e7-bb4f-06c278b62e96/volumes/kubernetes.io~secret/default-token-krhns': Device or resource busy\r\nrm: cannot remove '/var/lib/kubelet/pods/d18f54d0-6728-11e7-a172-02c7e4d4d0f8/volumes/kubernetes.io~secret/default-token-kbmm6': Device or resource busy\r\nrm: cannot remove '/var/lib/kubelet/pods/0125571f-6729-11e7-a172-02c7e4d4d0f8/volumes/kubernetes.io~secret/default-token-kbmm6': Device or resource busy\r\nrm: cannot remove '/var/lib/kubelet/pods/1cc66376-6728-11e7-ada1-06c278b62e96/volumes/kubernetes.io~secret/default-token-krhns': Device or resource busy\r\n```", "Did not work:\r\n\r\n```\r\ncore@ip-10-0-0-230 ~ $ cp $(find /var/etcd/ -iname db) /root/backup.db\r\nfind: `/var/etcd/kube-system-kube-etcd-0001': Permission denied\r\ncp: missing destination file operand after '/root/backup.db'\r\nTry 'cp --help' for more information.\r\n```", "What did work:\r\n\r\n```\r\nsudo cp $(sudo find /var/etcd/ -iname db) /root/backup.db\r\n```\r\n\r\n", "sudo", "Needs sudo and the unit is called `kubelet.service`", "Putting my user hat on...where do I get bootkube from?\r\n\r\nPutting my PM hat on...we have requirements on the version of bootkube, right? Do we need to tell them to get a specific one?", "is the kubelet and all containers stopped? this means the dir is still mounted somewhere.", "Won't Tectonic Installer by default install it ?", "Oops that was a typo ", "saw this too late, i already recovered it (guess it didnt matter too much)", "I could not find it hunting around on disk on the master. But if it was, we would still need to tell them where it was.\r\n\r\nPlus, your instructions say copy it from somewhere to the master. It's not in the install download or the assets bundle.", "@robszumski \r\n\r\nit matters when self hosted etcd is enabled. kubelet has a bug to mount previous used empty dir to static pod if you do not clean this up. ", "I made a wrong assumption by thinking people would know it already! My mistake. will get it resolved after talking to @squat ", "I can't get these to remove. Verified that both docker and the kubelet are stopped.", "/cc @coresolve ", "probably try lsof +D xxx to check who opens these files. but i will let @coresolve to provide more details on this.", "`lsof +D` doesn't help either...", "this should be put before bootkube recover"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1436", "comments": ["Is this a valid shebang?\r\nhttp://docs.groovy-lang.org/latest/html/documentation/#_shebang_line", "Not sure if this runs even though previous lines like `sh` failed. Do you know @cpanato?", "it works on my ide :) but I can change if you want or remove", "yes, it runs", "Ok, just leave it like this. I don't have a strong opinion about it."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1435", "comments": ["probably change the doc file name to just self-hosted-ecd.md?\r\n\r\nthis doc is more generic than configuring.", "in which step can we select the checkbox? ideally we can have a graph to show that?", "change to s3?", "we can remove PV. we suggest users to use s3 for tectonic.", "etcd is **highly available**", "link to either https://coreos.com/operators/ or https://github.com/coreos/etcd-operator?", "\"Tectonic can deploy and manage the cluster's central etcd service on Kubernetes. This configuration is referred to as \"self-hosted\", because the Kubernetes central key-value store, etcd, is itself deployed on Kubernetes. Tectonic deployments that enable the optional self-hosted etcd cluster during installation create an etcd cluster in the `kube-system` namespace. This document describes self-hosted etcd clusters, their benefits, limitations, operation, and installation. Within this document, the terms \"etcd\" and \"etcd cluster\" may be considered interchangeable.\"", "\"A self-hosted etcd is an automatically managed cluster of etcd pods running on Kubernetes. It is the primary configuration key-value store for the cluster on which it runs. Self-hosted etcd clusters operate differently than external etcd services, both those created by Tectonic Installer, or separately maintained. When self-hosted etcd is enabled during Tectonic installation, Tectonic manages deployment, upgrades, backups, and recovery of the self-hosted etcd cluster.\"", "1) we generally avoid the master/slave terms in k8s now\r\n2) I understand the point of this sentence but for the reader of this document, the objective is easier management of etcd\r\n3) strike this sentence", "\"Self-hosted etcd joins other self-hosted Tectonic control plane components, aimed at simplified, self-contained management and upgrades throughout Tectonic Kubernetes clusters, and provides the following benefits:\"", "etcd is secured by TLS encryption and authentication", "s/a stable storage/stable storage/\r\n(ideally provide some examples of what storage?)", "etcd can be automatically upgraded\r\n(promote up one line)", "s/machine/node/", "s/host/host(s)/ (?)", "caption should not be part of the link back to the source image", "ideally in a new document we would alphabetize the link labels list (See style guide)", "\"Tectonic deploys the [etcd operator][], which itself is a self-hosted component, a pod running on the same cluster, to manage self-hosted etcd. The etcd operator handles bootstrapping, maintaining quorum, cluster membership, backups, recoveries, and monitoring of self-hosted etcd clusters.\"", "\"## The etcd Operator\"", "s/###/##/", "space between cluster and (alpha)\r\n", "\"Tectonic uses [`bootkube`][LINK] to install a Kubernetes cluster with a self-hosted etcd service. `Bootkube` creates an external etcd cluster member for bootstrapping the installation. This initial etcd cluster member is crated and only used during initial setup.\r\n\r\nThe following list summarizes the self-hosted etcd bootstrap and installation process:\"", "1. Start a temporary, external etcd cluster with a single member", "s/Starts/Start/", "s/Starts/Start/", "4. Use the etcd operator to add one of the Kubernetes etcd pods as a cluster member", "s/Creates/Create/", "s/Starts/Start/\r\ns/a/the permanent/", "s/Removes/Remove/", "s/Stops/Stop/", "s/transient//", "first sentence: replace with: \"Self-hosted etcd clusters can be automatically upgraded by the etcd operator.\"", "s/will have/has/\r\ns/item/object/\r\ns/expected/desired/\r\ns/on/in/", "Operators?\r\ns/for etcd operator/for the etcd operator/\r\ns/the etcd/etcd/", "s/resource specification/manifest/ (?)", "\"Most Tectonic updates include an etcd version update. When such an update exists, Tectonic adjusts the `version` field in the etcd CRD to trigger the etcd operator to update to that version.\"", "Operator_s_?", "s/the/a/\r\ns/upload/writes/\r\ns/policy,/policy \u2013/\r\ns/S3/Amazon S3/\r\ns/as S3/as an S3/\r\ns/as Persistent/as a Persistent/\r\ns/However,//\r\n", "s/taking/creating/\r\ns/backup/backups/", "s/is failed/has failed/\r\ns/and add the/and adds the/\r\ns/etcd operator attempts/the etcd operator attempts/\r\n", "maybe add a comment re-affirming that all of this is automatic via the installer", "@xiang90 no one should do this manually right? should this be removed?", "..but you can recover via...", "this explains how etcd operator upgrades etcd at high level. this doc explains how self hosted etcd works in general.", "maintenance include both stable (eg: upgrade) and transient.", "`taking backup` is regular usage, like taking a snapshot", "s/these bootstrapping and installation process/this installation process/", "s/Customized/Custom/", "s/creating etcd backup/creating etcd backups/", "s/the pod health/pod health/\r\ns/Ensure that you create backup/Create backups/", "s/The/the/\r\ns/perform/performs/"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1425", "comments": ["question: why is this insisted to go into a log file? Are these debug messages also going to visible in `kubectl logs your-etcd-operator`?", "I am worried that we are hardcoding a host path here. The etcd-operator is a deployment, hence subject to be rescheduled by k8s at any time. This `/var/tmp/etcd-operator/debug/debug.log` file will eventually be sprinkled across all master nodes. Judging from https://github.com/coreos/etcd-operator/blob/c946e30490947dc8b171fc4439a98356c7a85078/pkg/debug/debug_logger.go#L51 I see that this at least opens the file file using `O_APPEND`, but those logs would still be pretty inconsistent in the face of rescheduling.\r\n\r\nCannot debug simply output to stdout such that its output is captured by standard k8s logging facilities?", "for self hosted etcd, when it is down, k8s is down. when k8s is down, kubectl is unusable. the whole point of this is to enforce we log down to disk for debugging purpose.", "if we can force every tectonic users to use a logging system like splunk, then it is a great help. Most of the users we interact with today have no logging system setup, this brings a huge problem for debugging self hosted etcd. when k8s is down, we have no easy way to get logging.\r\n\r\nwith this hack way, we at least can get the logging we want by downloading files from a well known path on all master nodes. we do not really worry about logging spreading too much. the operator is leader elected and time skew should not be a really problem. \r\n\r\nand something is better than nothing."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1419", "comments": ["let's user heredoc syntax:\r\n```\r\ncontent = <<EOF\r\n[Service]\r\n...\r\nEOF\r\n```", "let's use underscores, as we do for other variables, i.e. `cloud_config_username`.", "This ternary `var.cloud_provider == \"vsphere\" ? .. : ..` introduces programmatic logic inside bootkube depending on only vmware. If we (for some reason) need other provider mounts, this will become hard to maintain and introduce ternary spaghetti.\r\n\r\nLet's simply inject `volume_name`, `volume_host_path` and `volume_mount_path` from the outside, leaving default values as empty string. The var declarations would look like:\r\n```\r\nvolume = ${var.volume_name == \"\" ? \"\" : <<EOF\r\n      - name: ${var.volume_name}\r\n        hostPath:\r\n          path: ${var.volume_host_path}\r\nEOF\r\n```\r\nand\r\n```\r\nvolume_mount = ${var.volume_name == \"\" ? \"\" : <<EOF\r\n      - mountPath: ${volume_mount_path}\r\n        name: ${var.volume_name}\r\nEOF\r\n```\r\n"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1410", "comments": ["if it is not more experimental we maybe can remove the `exp` from the tfvars file. eg: `vars/aws-exp-np.tfvars` to be `vars/aws-np.tfvars` or to be `vars/aws-net-policy.tfvars`", "If `smoke.sh assume-role` fails three times, `smoke destroy` will never be executed, because with `-e` bash exits as soon as one command fails.\r\n\r\nI think we don't really care whether `assume-roles` is working correctly, but we do want the tests to fail whenever `smoke.sh destroy` fails. So what I would suggest is to remove the `-e` so that the exit code of the last command (`smoke.sh destroy`) is returned and all commands are always executed.\r\n\r\nWhat do you think?", "Sure, done", "@mxinden  if `smoke.sh assume-role` fails, I don't think `smoke destroy` will work as assume-role setups the AWS keys.... ? ", "thanks do much \ud83d\udc4d ", "@abhinavdahiya Actually I think the AWS credentials should still be set due to the credential injection in the Jenkinsfile. So that should be enough to just destroy the resources. I am sorry if I am misunderstanding this here. So my question would be, why are we still running `assume-role` right before destroying the cluster?\r\nhttps://github.com/coreos/tectonic-installer/blob/master/Jenkinsfile#L23", "@mxinden looks like assume-role creates temporary secrets [here](https://github.com/coreos/tectonic-installer/blob/master/tests/smoke/aws/smoke.sh#L23) for use. I tried to use [this](https://github.com/coreos/tectonic-installer/blob/master/Jenkinsfile#L105-L142) as template for running the test.", "@abhinavdahiya Ok, nevermind then. Sorry for the noise. Thanks for the comments."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1400", "comments": ["We want the tests to fail if destroy fails. This changes that behavior.", "Ah, I see. I don't think this is an issue in this line, as bash without '-e' just returns the last exit code. There is only one line here, whose exit code will be returned. But this is definitely a concern in other changes I made.\r\n\r\nThanks for the catch. I have updated the PR. Will follow up with a comment.", "If either `destroy` step fails but this succeeds, `EXIT_STATUS` will be overwritten and exit 0.", "@kans The right side of the `||` will only be executed when the left side fails. See: http://www.unix.com/shell-programming-and-scripting/42417-what-does-mean-double-pipe.html\r\n\r\nHope I understood your comment correctly.", "Good point. I would still refactor this as suggested to make it cleaner.", "@estroz Are other `timeout` blocks still executed even if one of them fails?", "No they won't be if you're using `-e`, but outside of the `catch` block you want to check for failure", "@estroz But this would defeat the purpose of this PR. If `make destroy` fails I still want to execute the following clean up steps. \r\n\r\nI could move the `make destroy` step into the `try` block. But if `make apply` fails in the middle, ressources will not be cleaned up properly, as `-e` makes the script fail entirely after the `make apply`. What do you think?", "To confirm, you're talking about the timeouts in the [case I've linked](https://github.com/estroz/tectonic-installer/blob/9f075b498a5283ae08c7deedfb470160183ca7d9/Jenkinsfile#L113-L152) right?\r\n\r\nIn the above case, `destroy` has a chance to run first in the `try` block. If either `apply` or `destroy` fail, both of which we want to test for failure, then we should try `destroy` again in the `catch` block. This will give the behavior that you want (run clean-up steps no matter what). Does that make sense?", "@estroz Ah, thanks for the explanation. Understood. I will adjust the PR accordingly, remove my verbose logic and duplicate the make destroy. Looks a lot cleaner. ", "No problem! Apologies if I was being unclear earlier. Thanks!"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1398", "comments": ["nit: maybe move this option to just after `kubelet_node_taints` option.", "makes sense."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1393", "comments": ["Typos: \"ACLs\" and \"not\"\r\n\r\n"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1389", "comments": ["do you mind to remove this commented code?", "see above", "can't we unify `etcd_ingress_ssh_from_external_master` and `etcd_ingress_ssh_from_master` doing the following?\r\n```\r\nsource_security_group_id = \"${var.external_sg_master == \"\" : aws_security_group.master.id ? var.external_sg_master}\"\r\n```", "see question above", "The resource is computed before any conditionals, and terraform will throw an error that `aws_security_group.master.id` does not exist when using an external security group.", "done. derp", "You can wrap `aws_security_group.master.id` in a TF interpolation `join()` to get around the fact that it is conditionally created and implement just one rule as @s-urbaniak is proposing.\r\n\r\nSee https://github.com/coreos/tectonic-installer/commit/e0c2d67a559aca2d0514c537985b9ce7c0072304#diff-95b96d483bc6fb7c40b02ec5c06c86a9R6 and the commit message for more info.\r\n\r\n", "oh neat. rebased/pushed this fix. Thanks!", "can we remove this whole commented block?", "done", "last nit from my side: can you join lines 156-164 with a separate newline? Once done, please resort it with the variable list between lines 165-179.\r\n\r\nkeeping things in lexical order will make it a little easier on future merges and avoids variable name fragmentation.", "@s-urbaniak I'm not sure I understand. You want me to separate these four variables with a new line and then remove duplicates on lines 177 - 180?", "@jasmingacic the whole block shouldn't contain duplicate entries yes. after a quick iteration I believe it should look like so:\r\n```\r\n  autoscaling_group_extra_tags = \"${var.tectonic_autoscaling_group_extra_tags}\"\r\n  cl_channel                   = \"${var.tectonic_cl_channel}\"\r\n  cluster_id                   = \"${module.tectonic.cluster_id}\"\r\n  cluster_name                 = \"${var.tectonic_cluster_name}\"\r\n  ec2_type                     = \"${var.tectonic_aws_worker_ec2_type}\"\r\n  extra_tags                   = \"${var.tectonic_aws_extra_tags}\"\r\n  instance_count               = \"${var.tectonic_worker_count}\"\r\n  root_volume_iops             = \"${var.tectonic_aws_worker_root_volume_iops}\"\r\n  root_volume_size             = \"${var.tectonic_aws_worker_root_volume_size}\"\r\n  root_volume_type             = \"${var.tectonic_aws_worker_root_volume_type}\"\r\n  sg_ids                       = [\"${split(\",\", var.tectonic_aws_external_worker_sg_id == \"\" ? join(\",\", var.tectonic_aws_worker_extra_sg_ids, list(module.vpc.worker_sg_id)) : join(\",\", var.tectonic_aws_worker_extra_sg_ids, list(var.tectonic_aws_external_worker_sg_id)))}\"]\r\n  ssh_key                      = \"${var.tectonic_aws_ssh_key}\"\r\n  subnet_ids                   = [\"${module.vpc.worker_subnet_ids}\"]\r\n  vpc_id                       = \"${module.vpc.vpc_id}\"\r\n  worker_iam_role              = \"${var.tectonic_aws_worker_iam_role_name}\"\r\n```", "@s-urbaniak What about load_balancers \r\n```\r\n  load_balancers               = [\"${var.tectonic_aws_worker_load_balancers}\"]\r\n```\r\n\r\nShould it go into the same block?\r\n"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1376", "comments": ["Just as a hint for other reviewers: \"Makefile,installer/Makefile: turn off file permission checks\"", "`withDockerContainer` executes code inside the container as uid1000 by default. As far as I can tell the *file-permission* errors are due to the fact that we are running as uid1000 but some folders and files are owned by root. If this is the case, `chmod -R 777` executed by uid1000 will fail, right? Am I missing something?", "Yes you're correct. Weirdly enough, permissions failures only occurred on one or two stages per test run, and those seem to have disappeared from Jenkins as of now."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1371", "comments": ["Can this be renamed to <code>BRIDGE_TECTONIC_CLUSTER_NAME</code> and updated in bridge accordingly", "I'd rather keep `BRIDGE_CLUSTER_NAME` to avoid ambiguity: the installer frontend creates a `tectonic_cluster_name` and passes it to bootkube and tectonic Terraform modules, where it is referred to as `cluster_name` (see [here](https://github.com/coreos/tectonic-installer/blob/master/platforms/aws/main.tf#L11)), which is the context we care about. Does that make sense?", "Well, it's still the `tectonic_cluster_name` and my guess is that terraform modules expect `cluster_name` variable. As far as bridge is concerned, this is still `tectonic-cluster-name`. Bridge also displays etcd clusters and I feel `tectonic-cluster-name` variable is more precise.", "sgtm. i'll update."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1354", "comments": ["@s-urbaniak Need to double-check this version. Looks like it was reverted to `1.6.6+tectonic.1` in https://github.com/coreos/tectonic-installer/pull/1154, but that may have been a mistake.", "@lblackstone very good catch! that was indeed mistakenly reverted, I will follow up with a PR.", "for this PR we also have to bump to `1.6.7-tectonic.1`"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1352", "comments": ["Whats going on here?", "`_.map(nodes, 'mac')` is shorthand for `_.map(nodes, n => n.mac)`."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1351", "comments": ["I believe this is unrelated to this PR.", "That would execute `update-ca-certificates` at every boot, no? I would like to recheck with the OS team (/cc @crawford @euank) whether this is the canonical way of adding public CAs using ignition as I think https://github.com/coreos/coreos-overlay/blob/master/app-misc/ca-certificates/files/update-ca-certificates.service#L7 does this already at first boot. ", "Additionally I would like to avoid encoding private keys in the state. As you are using this currently only to transfer assets I would prefer not using the private key but rather rely on the host's SSH agent.", "oop, good call. That bled over from the rebase I was doing for #625. I'll pull that out.", "Sounds good. As it currently is, the `ConditionPathIsSymbolicLink` and the `--skip-rehash` can cause it not to pick up the new certificate, so I removed those, but I'm open to a more canonical way.", " @crawford @euank any thoughts to add here?", "Apologies for not responding; this dropped off my radar.\r\n\r\nDo you know of any specific cases where the existing `ExecStart` line actually does miss new certificates? It looks like it should generally do the right thing already with its timestamp comparison.", "I'm not 100% clear on the reasoning, but it definitely requires both to get this to work. Here's what happens if I remove the drop-in, as well as with the drop-in changes:\r\n\r\n```bash\r\n# This is what we're looking for in the CA list\r\ncore@terraform-master-0 ~ $ sudo cat /etc/ssl/certs/kube_ca.pem | openssl x509 -noout -subject\r\nsubject= /C=/ST=/L=/postalCode=/O=bootkube/OU=/CN=kube-ca\r\n# update-ca-certificates didn't run because of the precondition (maybe already ran during the image build?)\r\ncore@terraform-master-0 ~ $ systemctl status update-ca-certificates \r\n\u25cf update-ca-certificates.service - Update CA bundle at /etc/ssl/certs/ca-certificates.crt\r\n   Loaded: loaded (/usr/lib/systemd/system/update-ca-certificates.service; static; vendor preset: disabled)\r\n   Active: inactive (dead)\r\nCondition: start condition failed at Wed 2017-07-26 19:33:02 UTC; 18min ago\r\n           \u2514\u2500 ConditionPathIsSymbolicLink=!/etc/ssl/certs/ca-certificates.crt was not met\r\ncore@terraform-master-0 ~ $ sudo mkdir /etc/systemd/system/update-ca-certificates.service.d/\r\n# Just reset ConditionPathIsSymbolicLink in the drop-in\r\ncore@terraform-master-0 ~ $ sudo vi /etc/systemd/system/update-ca-certificates.service.d/edits.conf\r\ncore@terraform-master-0 ~ $ sudo systemctl daemon-reload\r\ncore@terraform-master-0 ~ $ sudo systemctl start update-ca-certificates\r\n# update-ca-certificates runs now but doesn't do much\r\ncore@terraform-master-0 ~ $ systemctl status update-ca-certificates\r\n\u25cf update-ca-certificates.service - Update CA bundle at /etc/ssl/certs/ca-certificates.crt\r\n   Loaded: loaded (/usr/lib/systemd/system/update-ca-certificates.service; static; vendor preset: disabled)\r\n  Drop-In: /etc/systemd/system/update-ca-certificates.service.d\r\n           \u2514\u2500edits.conf\r\n   Active: inactive (dead) since Wed 2017-07-26 20:06:42 UTC; 6s ago\r\n  Process: 6327 ExecStart=/usr/sbin/update-ca-certificates --skip-rehash (code=exited, status=0/SUCCESS)\r\n Main PID: 6327 (code=exited, status=0/SUCCESS)\r\n      CPU: 34ms\r\n\r\nJul 26 20:06:42 terraform-master-0 systemd[1]: Starting Update CA bundle at /etc/ssl/certs/ca-certificates.crt...\r\nJul 26 20:06:42 terraform-master-0 update-ca-certificates[6327]: Recreating certificate bundle /etc/ssl/certs/ca-certificates.crt\r\nJul 26 20:06:42 terraform-master-0 systemd[1]: Started Update CA bundle at /etc/ssl/certs/ca-certificates.crt.\r\n# Still no certificate in the list\r\ncore@terraform-master-0 ~ $ awk -v cmd='openssl x509 -noout -subject' '/BEGIN/{close(cmd)};{print | cmd}' < /etc/ssl/certs/ca-certificates.crt | grep kube\r\n# Change the ExecStart too\r\ncore@terraform-master-0 ~ $ sudo vi /etc/systemd/system/update-ca-certificates.service.d/edits.conf\r\ncore@terraform-master-0 ~ $ sudo systemctl daemon-reload\r\ncore@terraform-master-0 ~ $ sudo systemctl start update-ca-certificates\r\ncore@terraform-master-0 ~ $ systemctl status update-ca-certificates\r\n\u25cf update-ca-certificates.service - Update CA bundle at /etc/ssl/certs/ca-certificates.crt\r\n   Loaded: loaded (/usr/lib/systemd/system/update-ca-certificates.service; static; vendor preset: disabled)\r\n  Drop-In: /etc/systemd/system/update-ca-certificates.service.d\r\n           \u2514\u2500edits.conf\r\n   Active: inactive (dead) since Wed 2017-07-26 20:07:43 UTC; 2min 52s ago\r\n  Process: 6691 ExecStart=/usr/sbin/update-ca-certificates (code=exited, status=0/SUCCESS)\r\n Main PID: 6691 (code=exited, status=0/SUCCESS)\r\n      CPU: 5.597s\r\n\r\nJul 26 20:07:43 terraform-master-0 update-ca-certificates[6691]: WoSign_China.pem => 5d63b0ae.0\r\nJul 26 20:07:43 terraform-master-0 update-ca-certificates[6691]: XRamp_Global_CA_Root.pem => 706f604c.0\r\nJul 26 20:07:43 terraform-master-0 update-ca-certificates[6691]: certSIGN_ROOT_CA.pem => 8d86cdd1.0\r\nJul 26 20:07:43 terraform-master-0 update-ca-certificates[6691]: ePKI_Root_Certification_Authority.pem => ca6e4ad9.0\r\nJul 26 20:07:43 terraform-master-0 update-ca-certificates[6691]: kube_ca.pem => dc214808.0\r\nJul 26 20:07:43 terraform-master-0 update-ca-certificates[6691]: thawte_Primary_Root_CA.pem => 2e4eed3c.0\r\nJul 26 20:07:43 terraform-master-0 update-ca-certificates[6691]: thawte_Primary_Root_CA_-_G2.pem => c089bbbd.0\r\nJul 26 20:07:43 terraform-master-0 update-ca-certificates[6691]: thawte_Primary_Root_CA_-_G3.pem => ba89ed3b.0\r\nJul 26 20:07:43 terraform-master-0 update-ca-certificates[6691]: Recreating certificate bundle /etc/ssl/certs/ca-certificates.crt\r\nJul 26 20:07:43 terraform-master-0 systemd[1]: Started Update CA bundle at /etc/ssl/certs/ca-certificates.crt.\r\n# There it is\r\ncore@terraform-master-0 ~ $ awk -v cmd='openssl x509 -noout -subject' '/BEGIN/{close(cmd)};{print | cmd}' < /etc/ssl/certs/ca-certificates.crt | grep kube\r\nsubject= /C=/ST=/L=/postalCode=/O=bootkube/OU=/CN=kube-ca\r\n```", "This should be part of the `systemd:` section, not the `storage:` section", "Thanks for checking, sorry for the bit of a runaround there.\r\n\r\nThis still seems a bit sloppy, but since I don't have a better suggestion, I'm okay with it.", "Oop, good catch. Moved in the controller too.", "I believe this should be `10-always-update-ca-certificates.conf`, no?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1347", "comments": ["Can we just delete this code?", "This too"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1330", "comments": ["Oops, this should be 1.6.7", "ditto"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1323", "comments": ["even though it starts getting super wordy, I think if you want to do this, you should break the two commands apart (on both pages).\r\n\r\nRun the Tectonic Installer for your platform. \r\n\r\nFor macOS users:\r\n```bash\r\n$ ./tectonic-installer/darwin/installer\r\n```\r\n\r\nFor Linux users:\r\n```bash\r\n$ ./tectonic-installer/linux/installer\r\n```"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1314", "comments": ["It would also be OK to dump these three lines into the [loop above](https://github.com/estroz/tectonic-installer/blob/1b16a5a5a638e0fc2ee03352e4bcf8f629572bab/installer/frontend/cluster-config.js#L222).\r\n\r\nedit:\r\nIt looks like `extraAutoScalingTags` should be an array and you should push objects onto it like so:\r\n\r\n```javascript\r\nconst extraAutoScalingTags = [];\r\n...\r\nextraAutoScalingTags.push({key, value, propagate_at_launch: true});\r\n```", "Fixing now.\r\nI kept the autoscaling tags in a separate loop to keep the code clean.", "You should remove \"awsASGTags\" from both progress files (which will also get rid of the console.errors) - you'd only want these here if we were storing the tags in memory at this location, but we only really want to output a new tfvar.", "I don't think this is being used."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1295", "comments": ["Is there a more elegant way to do this rather than a bunch of ifs?", "curently no :-( I think it is time for custom datasources.", "We may run into similar issues here with ELB maxchar naming limits that we had with long cluster names.\r\n\r\n@s-urbaniak @squat thoughts on how to address?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1293", "comments": ["Looks like you dropped the check for `tectonic_vanilla_k8s`. That condition is needed to allow deploys that don't use Tectonic-specific resources.", "You will need to run `make docs` and `make examples` to generate the corresponding docs/configs."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1292", "comments": ["`window.config.platforms` comes from a command line flag.  I believe the old behavior was that we would remove items from the platform dropdown in the case that `platforms` were specified. ", "I think this is `OpenStack` with a capital S", "Thanks @kans. I brought back `SELECTED_PLATFORMS` and added \"aws\" and \"bare-metal\" as additional options accepted by `-platforms` to preserve the current behavior.", "Updated", "why there are two bare metals docs and the `BARE_METAL` points to the terraform doc and the `BARE_METAL_TF` points to another doc, should not be the other way round?\r\n\r\n", "`BARE_METAL` / `metal-terraform.html` is for installing with the command line (using Terraform).\r\n`BARE_METAL_TF` / `index.html` is for installing with the GUI (`_TF` suffix because it also uses Terraform).\r\n\r\nIt is confusing and should probably be renamed, but I don't think that should be part of this change because the naming pattern existed before this PR.", "thanks for the explanation"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1290", "comments": ["The term \"in servers\" is a little ambiguous and innacurate. Can you say \"These clusters run outside of Kubernetes\" or \"These clusters are not controlled by Kubernetes...\"", "Strictly speaking, nothing is managed \"by\" the console but rather \"with\" the console.", "s/is not/are not/", "A self-hosted etcd cluster", "\"The term itself inplies that it is...\" -> \"The term itself implies that the cluster is...\"", "\"An external etcd cluster\" we should be consistent and precise and call them \"etcd cluster\"s", "The `pod-checkpointer` is autonomous--there is no way for a user to interact with it. I would say that we provide two tools to help avoid (`pod-checkpointer`) and recover from (`bootkube recover`) some of these disaster scenarios.", "Some inaccuracies in this paragraph. Here's an attempted rewrite:\r\n\r\nThe pod checkpoint utility recovers critical pods in the absence of an API server. The utility runs on each master node, periodically checking for locally-running [parent pods][parent-pod] that have the `checkpointer.alpha.coreos.com/checkpoint=true` annotation and writing [checkpoints][checkpoint] of their manifests to local disk. If the utility detects that the parent pod is no longer running it then activates the checkpoint by running a static local copy of the pod. The checkpoint continues running until the parent pod is restarted on the local node, or an API server can be contacted to determine that the parent pod is no longer scheduled to this node.\r\n\r\nFor example, the apiserver pod is checkpointed because when a master node restarts all pods local to that kubelet are stopped. If one of these pods is running the only apiserver (non-HA scenario), the kubelet will have no apiserver to contact to determine which pods to run, and therefore will not restart the apiserver. In this case, (1) the checkpointer will detect that the parent apiserver pod is not running and start the checkpointed apiserver, (2) the kubelet will now have an apiserver to contact to determine which pods to run, (3) the kubelet will start the parent apiserver pod, and (4) the checkpointer will detect that the parent pod is running again and stop the checkpointed pod.", "Inaccurate. Tectonic deploys the pod checkpointer as a DaemonSet running on all master nodes by default. No user action is required or available.", "Again, it's enabled by default, so maybe rephrase to say that it is \"...highly recommended and enabled by default. Disabling it may lead to cluster outages during node upgrades or reboots.\"", "a master node (user may have several, any should work).", "This method is manual, but does not require bootkube?\r\n\r\n(To convey that it is a tradeoff)", "I would emphasize that the checkpointer is not a user-facing tool.", "Loss the majority of self hosted etcd nodes when self hosted etcd is enabled.", "Using bootkube to recover Tectonic clusters", "The control plane ... following catastrophic failures:", "Use `bootkube recover` to re-bootstrap the self-hosted control plane ...", "drop this paragraph.", "A self-hosted etcd cluster runs in containers managed by Kubernetes. Self-hosted etcd may be deployed using Tectonic Installer, and may be managed using Tectonic Console.", "... deployed by Tectonic Installer ...\r\n\r\n(we're not using 'the' with Tectonic Installer or Tectonic Console.)", "I think your 'only' is misplaced. \r\n\r\nTectonic Installer assumes network connectivity to the external etcd cluster only at the given URL.", "The parent pod's manifest is ...", "'Scenario' is really awkward, and I don't know that these need to be numbered. maybe:\r\n\r\nRecovery with a running API server\r\nRecovery with an external etcd cluster\r\nRecovery with an external etcd backup\r\n... a provisioned etcd backup\r\n... a self-hosted etcd backup", "one more thing. this recovery technique  also works for provisioned etcd. As long as etcd is not self-hosted and the cluster is running, the control plane information can be extracted. In other words, this is not unique to external etcd", "\"A self-hosted etcd cluster is deployed\"\r\n\r\n\"and is manged using the Tectonic Console\"", "it's documented in the next section :-)", "have anyone tried this against a failed tectonic cluster?", "I think \"vulnerable\" is too scary. Is there a way to tone this down or add a clarifying sentence to say that these situations would only occur under extenuating circumstances? cc @zbwright ", "nit: though `pod-checkpointer` lives in the bootkube github project, it's an independent program and we are in the process of moving it to its own repo. I'd just treat them as two separate programs.", "nit: \"only API server pod (non-HA scenario) in the [Tectonic] cluster.\"\r\n\r\nOr, if you meant `Deployment` (kubernetes concept), apiservers actually run as `DaemonSets`.", "will automatically recover the API server as follows:", "mismatched tenses between \"will perform the following\" (future) and \"Starts / Detects\" (present)", "The pod checkpointer is enabled", "Going with my comment at the top, may want to say why you might end up in this situation. It should never be because of Tectonic itself. It's usually due to an external problem, e.g. your master nodes were all deleted by accident. cc @coresolve ", "@coresolve, am told.", "susceptible ?", "I don't love the word catastrophic either. This doc is all about that we _can_ fix some of these scenarios.", "someone should try this out in the context of a tectonic cluster, make sure this doc is accurate in my opinion.", "can we combine these into one step?\r\n\r\n> Copy `bootkube` to a master node and then SSH to it:\r\n\r\n> ```\r\n> $ scp bootkube user@master-node\r\n> $ ssh core@master-node\r\n> ```\r\n\r\nNote that the user is core and the master node shouldn't have a `:` after it, unless we are specifying a certain path, which we probably don't need to do.", "where do I find these states?", "oh its below, we should mention that", "there are described in section starts with \"Recovery with..\"", "@robszumski the `:` is required, otherwise it just copies the file to a new file named `user@master-node`\r\n\r\nI like combining the steps though", "The control plane of a Tectonic cluster may fail under certain circumstances. Symptoms may include:", "nit: failures may occur", "They're actually not very intelligent... :-/", "nit: delete \"to monitor the API servers\"", "nit: remove self-hosted clusters; all Tectonic clusters are self-hosted", "disruptions:", "I think this sentence goes away.", "@robszumski asked me to add the sentence in order to link what's following", "I'm not sure if this sentence stays or goes, but i do know that it should end with a '.' (period)."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1284", "comments": ["Not sure if this is a typo", "I should have mentioned that the BM Masters page uses the text \"end-user apps\", so I changed this to match."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1283", "comments": ["I don't think you can put this one at 60 or else the post/failure stage won't have time to run."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1279", "comments": ["Use this guide to troubleshoot an indeterminate failure type, and determine which of the more in-depth guides will help to solve the issue. Knowledge of ...", "Josh prefers * to - for bullets.", "* A cluster is down, but the problem is unknown. Use this troubleshooting guide.\r\n* Specific cluster or node components are down. See the guides listed below. \r\n    (I would expect a section at the bottom, that I could link to, listing the other guides - beth)\r\n* Cluster installation is failing. See [Troubleshooting Tectonic Installer][installer-terraform].\r\n* I don't think the FAQ belongs in this list.", "For all other issues, work through this guide.", "Open Tectonic Console in a browser, and use the following list to check its status and to determine if there are any networking issues between it and the cluster.", "i do no think this section covers anything about troubleshooting. the content is a high level description of the failure model of etcd. ", "question: are these two issues similar in their presentation? or not? that is, can they both be described as 'Console will not load. Browser returns xxx error - or not?", "I would move this to the top of the 'Console will not load' errors listed, as it feels like it's the first in the sequence of events.", "Tectonic Console does not load due to connectivity issues. Use `kubectl get nodes` to evaluate the connection. ", "probably link to https://github.com/coreos/etcd/blob/master/Documentation/op-guide/failures.md.", "probably give an example of https://github.com/coreos/etcd/tree/master/etcdctl#endpoint-health to start with. that is usually the first step to troubleshoot an etcd cluster. ", "... | kubeconfig is misconfigured. It should point to the remote Tectonic cluster, not localhost. See xxx in [Deploying an application on Tectonic][Documentation ...\r\n\r\nI would call out the specific section in that doc you want people to look at. I can't figure out which section that would be. Are you sure you want to send them to first-app.md, and not somewhere else?\r\n\r\n", "... may be down ...", "... load balancer, security group, or firewall ...\r\n\r\nand add a note telling people what to do next.", "this one is sort of weird - how would you know the console is working, if you're not logged in? maybe change intro to:\r\n\r\nVerify that Tectonic Identity is configured correctly. Log out of any active Console sessions, then log in using a username and password configured for the cluster.", "what's a connectivity issue symptom? I would describe 1 or 2 in the opening sentence.", "... configured correctly. Test the control plane, the brain of the cluster, to see if it is misconfigured or down.", "If the Controller Manager ...", "The cluster ... Be aware that troubleshooting and recovery differ slightly based on how the etcd cluster was launched with Tectonic Installer. Make a note of which option was selected during installation:", "... pick one to inspect.", "fewer available masters", "cluster (not clsuter, even though it's a TODO. ;) )", "Connection through Tectonic Console and through the Kubernetes API are similar in function, but may be configured differently, and therefore may act differently in an outage.", "DNS appears to be configured to point either to your master nodes, or to a load balancer.", "add a 'what to do next', please.\r\n\r\nDNS records do not point to any master node or load balancer. (either both plural, or both singular. also: is it that it doesn't point to either of these? or it doesn't point to one or the other of these?)", "... If DNS passed validation in [Troubleshooting connectivity to cluster] above, the Ingress address is available, and delivering traffic to the cluster.", "In general, I think every one of these sections should point to next steps. what should people do given these two responses? Even if it's just to point them to somewhere with more info on how Ingress works?", "... Console, Kubernetes API, or `kubectl`. ...", "yes, I want to link off to the relevant guides based on @radhikapc's work", "the first is a native browser error, and the second is a styled error that has a tectonic logo on it", "it still loaded and redirected you to dex, which confirms that it is working at a really basic level", "totally agree, this was just to get something up for now until we have that guide. we do have an overall ingress doc, but nothing that helps you troubleshoot further.", "i will provide links from the doc am creating.", "it must point to 1+ master nodes, or a single LB", "typo - Use, not QUse", "Make them all the same, please - either Troubleshoot or Troubleshooting.", "add period - [configure-kubectl].\r\n\r\nthere are a few other places missing periods throughout. it's a nit. If you care to, take a look at all the Observed Behavior / Action sections, and add periods as needed.", "e.g.", "applications", "Tectonic Ingress routes traffic to your containers ... It also routes traffic to Tectonic components ...", "... backup of etcd, run a [temporary ...", "It reads \"See view the guide\". Probably change to \"See [Troubleshooting Tectonic Installer] for more information on installation failure.\" ", "I received the official terminologies for different flavors of etcd from @squat @Quentin-M \r\n\r\n1. External\r\n2. Provisioned\r\n3. Self-hosted\r\nI am using these terms in the doc that I have created. Let's consistently follow them across the docs.", "... [using the bootkube recovery tool][etcd-recover]"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1276", "comments": ["Why differentiate between `client` and other CA? There is only one CA for all etcd certificates, no?", "bootkube expects this path to be present for auto-detecting self-hosted TLS migration, see https://github.com/kubernetes-incubator/bootkube/blob/4a87785/pkg/util/etcdutil/migrate.go#L240", "To minimize redundant files, I simply used this path as the canonical etcd ca path.", "Thought we decided to only use a single CA (the one provided or generated) for all Tectonic needs. Looks like we are generating one of etcd? It doesn't matter to this PR at all tho.", "Ah ok. I was curious about the terminology and why we were specifically calling the ca a \"client\" ca. Thanks for the context", "@Quentin-M gah, you are right, we could use the cluster-wide CA.", "For additional context, we created separately-named CAs for each of the etcd configuration flags, since technically you *could* use different CAs for each. However, in practice `bootkube render` uses the same CA for all of them (just makes copies), and Tectonic could certainly do the same (or point to the same one)."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1275", "comments": ["Our convention is to omit the lead in `tectonic_` on variable names in the actual modules.", "So this would just be `vanilla_k8s =...`", "Fixed in f74f0a5, thank you @squat!"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1269", "comments": ["please use underscore notation for the variables."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1268", "comments": ["nit: this should be added to `.PHONY`", "Very true! Let me fix that.", "small nit though: this probably won't work with v1.0/0.2x/0.3x....", "That's right, it wouldn't.\r\nI'm hoping we can get rid of the check though, once we're a few versions over 0.1x.x "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1263", "comments": ["@estroz Why are all these tests commented out? (I am just guessing this is up for review, as you changed the title ~~WIP~~)", "When is this the case?", "Can we get this back in before merging?", "Changed the title back. All this is commented out to test failure recovery, and will be un-commented before merge."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1256", "comments": ["a Quay Enterprise **or other registry.**"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1239", "comments": ["Do you think it'd be valuable to add a prompt here to ask whether it is going to do what was intended? As we also run this in CI, could add a `-f` flag to bypass it.", "You already trap that, right?", "I feel like the description is not super clear, especially given this script will remove that directory. What if I pass /tmp there? :'(", "ditto", "ditto", "Hardcoded /tmp/config, versus $tmp_dir.", "ditto", "A bit more description would be nice here too.", "nit: Would be nice if some day grafiti didn't _require_ config files, and you could pass these as flags or env vars to avoid needing stuff like this.", "or if at least some of them could be overridden with flags", "In general it would be nice if most of this logic could be moved into Go or accommodated by grafiti in some way. Having a big bash wrapper script is not fun.", "the script will create a `\"${workspace}/config\"` dir and only remove that ", "once the file is in the Docker container, its location does not matter", "I agree. I'll make an issue in `coreos/grafiti`, unless you'd like to", "yea", "oh yeah cool soz, didn't pay attention", "As in prompt the user with a printout of tag/config files before actually deleting resources with those tags?", "@sym3tri would you like to postpone merging these scripts until that time? I'm going to add env variable support for certain config file fields asap.", "@estroz https://github.com/spf13/viper is your best friend. CLI arguments + Env-based configuration + YAML/JSON/TOML/HCL! configuration in one tool. Usually used with https://github.com/spf13/cobra too.", "Yeah. Tags to delete: ... Are you sure?", "Yup I can add that", "The last worldwide S3 outage was due to a cleanup/scale-down user-operated script that was given 'a little more'.", "@estroz Is this concern resolved? Are we addressing this in another PR?", "@Quentin-M @sym3tri final thoughts? Writing this in Go wouldn't be difficult, but perhaps it should be written in Ruby as per @mxinden's work"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1235", "comments": ["The established practice throughout the rest of the code is to just have variables interpolated into templates. Any calculations necessary to get to the values of those template variables should ideally be done higher up the stack, in the template_* resource inputs or the module inputs.\r\n\r\nNot a technical issue, just a code consistency one.", "We generally want to keep the number of user-facing input variables to the lowest amount possible and try hard to keep it that way. These inputs are our API to the users. The less inputs we expose the simpler the tool is to understand and use. Also, the easier it is to manage / evolve the API of the installer as it inevitably grows.\r\n\r\nNow, in my opinion there's very little reason for this to be a user input. Under the vast majority of use-cases this value will not change and I'd really appreciate if users had one less item to worry about when creating their cluster configs.\r\n\r\nIf you agree with my point above, let's make this an internal variable to the module and not expose it.\r\n\r\nAs a side note, I'm using the very same approach for parsing Azure resource IDs and have also added a similar constant variable to the azure modules.", "Now I noticed that the input variable is already there, introduced by your earlier PR, which already got merged. My assessment still holds and I think the input var should be removed.\r\nSince it's already in, no reason to block on it this time. I should have payed better attention to the original PR.\r\n\r\nCan you please then follow-up with a PR to remove the input var?", "The only reason I have it as a user input is to avoid re-defining the regex in all the modules, instead allowing the value of `tectonic_image_re` to propagate down to all the modules. Is there a way to accomplish this consolidation without defining the variables as we have here?", "ping @alexsomesan ", "Gave more thought to this issue. We're seeing more often the need for similar \"global constant\" type of vars, that only make sense internally. We need to find a way to keep all of them out of the sight of the docs & examples generators, which requires a bit of refactoring.\r\nSince we need to do this anyway for all other situations, let's keep things as they are for now here too, also since this change is not the one that introduced that top-level var.", "May I ask why is this flag modification here? /cc @dghubble", "Bump ^", "After talking with Colin, its for his plan to try to make other image caches work. However, we're dropping all operator/management flags from CLUO (the application) in the release after this one so it won't be here for long.\r\n\r\nWhether its there or not, I can write the migration to account for it.", "If this change isn't going in v1.7.1 there's nothing to worry about :), the `-agent-image` flag will be a NoOp or removed in the release after this one.", "My understanding is that It'd apparently break some migration work, and it affects the payload. It should probably have been discussed a bit more before merging. But as this is not going to be in the 1.7.1 release, we are probably fine. In the next CLUO release, this flag will be NoOp, so it should not affect it. Thanks for the explanations!", "It'd actually make the migration easier if this were reverted to remove this before the next Tectonic release. CLUO will not be responsible for \"managing\" or \"operating\" other Kubernetes objects then (another component will do it), so no reason to have them at all. We could delete the code that backs these flags entirely. Thoughts? @colhom ", "@dghubble sgtm. sorry for the difficulty"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1233", "comments": ["nit: `no resources were found, retrying in 5 seconds`", "- nit (remove the extraneous whitespace) in `$( echo...`\r\n- additionally we have to wrap this call with `set +e`/`set -e`. `grep` will return with exit code 1, causing the whole script to fail. I think this is also the cause for the CI failure.", "Done", "Done. Thought it would be more clean to `set +e/set -e` for the whole function.", "@rithujohn191 agreed \ud83d\udc4d "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1232", "comments": ["this is fine. are you making this variable so you can rkt run awscli optionally?", "@squat Yes, in upgrade test's jenkins job [here](https://github.com/coreos-inc/tectonic-upgrade-test/blob/master/scripts/jenkins.sh#L219)"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1215", "comments": ["This cluster name will change if `buildExpectedJson()` is called in a different second. (And it is being called many times.)", "Don't you want to read some data out of the progress file? That's what contains UI state. eg `tectonic-baremetal.progress`'s `clusterConfig.matchboxHTTP` contains the http-less matchbox url.", "This breaks tests. The matchbox url must have a protocol.", "If you updated the version here, you also need to change the progress file so that tests pass.", "Again, if you updated the generated value here, you must update the progress file so that tests pass.", "you are right, we are not using it across any other methods. I can move to diff method", "I thought the plan is to have one consolidated tfvars which will be used by frontend and backend. let me know if this is going to change", " I'm yet to push the progress file changes. Will let you know once i push  ", "These functions are quite verbose.  Why not just export `json` and reference the fields you care about directly where you need them?", "I'm hoping for these functions to evolve over time to help manipulate data for the tests.", "What do you have in mind specifically?", "If we want to use these functions in multiple places [ex: pages, tests].  ", "> I thought the plan is to have one consolidated tfvars which will be used by frontend and backend. \r\n\r\nProgress files are basically a memory dump of the frontend (with all inputs filed in).  For input for the GUI tests, it would make more sense to use the progress files since they already contain user input (instead of generated output).  The goal is to match the generated output (tfvars) to the ones used in the smoke tests, and then to consolidate.", "It looks like most of these functions are only used once and I don't think aliasing the fields behind a function call provides much value.  It is also quite unexpected that some of these functions have side effects (eg, adminPassword).", "Sure. Will address this change in a different PR. "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1214", "comments": ["this line is covered by:\r\n> Ed: No release-team/installer-team/product-team issues due to communication breakdown?\r\n\r\nright? let's remove it to be consistent with the other lifecycle stages, e.g. stable doesn't say this.", "are we capitalizing each word or using natural casing like in `Network security`? we should make this more consistent.", "s/configuration/configurations/", "s/configuration/configurations/", "I think \"platform manifest\" should be plural", "This sentence reads a little ambiguously. Is it:\r\n1. the ability to upgrade the cluster is compromised because the manifests are vetted and certified to not diverge; or\r\n2. we certify that manifests do not diverge, which could have caused the ability to upgrade to be compromised.\r\n\r\nIt should be 2, but it's awkward because of the negative in the middle of the sentence. I think it would be clearer if we replace `such that` with `so much that`.", "s/configuration/configurations/", "This isn't really meaningful here. Either be explicit or drop this.", "What does this mean?", "These are the same as the testing requirements for Beta and should be automatically inherited. Do we need to spell them out?", "\"top\" and \"most\" are redundant here.", "same redundancy", "Conformance tests using appropriate cloud-provider (if applicable)", "yes. fixed.", "disregard, removed since we already have \"Network Security\".", "removed", "fixed", "fixed", "noted", "you're right. removed."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1203", "comments": ["@yifan-gu Can you also change `modules/tectonic/assets.tf` to also use this variable like it's being done in `modules/update-payload/assets.tf`. It's still using the container image tag. \r\nhttps://github.com/yifan-gu/tectonic-installer/blob/f98cc0ff72eaf288d84b71c0249e65a5f87fcaef/modules/tectonic/assets.tf#L41", "@hasbro17 Good catch, done."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1201", "comments": ["I'd recommend something like;\r\n\r\n----------\r\n\r\nWhen using an existing VPC, tag AWS VPC subnets with `kubernetes.io/cluster/my-cluster-name = shared` tag. `shared` is used to tag resources shared between multiple clusters, which should not be destroyed if any individual cluster is destroyed. In absence of this tag ,AWS ELB integration with Tectonic may not be able to utilize VPC subnets.\r\n\r\n----------\r\n\r\nor something similar", "nit: s/with/with the/ in first sentence.\r\n"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1200", "comments": ["@alexsomesan Just to make sure: This is a wanted change, right?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1198", "comments": ["Why two retries?", "We create two clusters on aws - `aws.tfvars` and `aws-vpc.tfvars`.", "Is this long enough for two grafiti runs?", "Definitely. `grafiti delete` takes less than 10 minutes to delete an entire AWS region, so 1 cluster shouldn't take more time than that.", "One last thing: if `destroy` is failing, we this code run?", "Now that I've removed `-e` all shebangs, they should fall through to grafiti"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1196", "comments": ["Can you add the link to the release job in here?", "The old script was also export aws credentials, is that not needed anymore?", "Just did! Thanks~"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1195", "comments": ["a note about using this for workers but running masters on Container Linux would be great here. Just a quick sentence and link to the general platform section on the index should suffice.", "what do you think of something like this at the end of this paragraph:\r\n\r\n> You can join these Red Hat Enterprise Linux workers to the same cluster as your Container Linux workers.", "Slight restructuring, what do you think?\r\n\r\n> Before continuing on this guide, use Tectonic Installer to deploy a cluster on [bare metal][bare-install] (or [AWS][aws-install]). The Installer will use Container Linux for the master nodes, and you may configure additional Container Linux worker nodes. \r\n\r\n> Once the cluster is deployed, follow this guide to configure and join additional worker nodes running Red Hat Enterprise Linux.", "Some random notes:\r\n- using `configure and join` vs `launch` because technically we aren't launching these, the users bring them to us\r\n- didn't want to encourage setting workers to 0, but they can", "I feel like we need an ending here, just to confirm that you're done. Something like:\r\n\r\n> You're done! The new worker nodes should be visible in the Tectonic Console and are ready to start running your containers."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1192", "comments": ["Can you make this \"generated/auth/kubeconfig\" a const with a comment ", "Please clarify are these systemd services, k8s or both?", "Please add comments to all these functions. Also, etcd is always hosted, the question is whether it is \"self\" hosted.", "Could you stat this filepath to make sure the kubeconfig exists already and return an error if it does not. This would give you information to branch off of in tectonicStatus.", "Rather than return nil, return a known error and branch off of that in the function that calls this func. Otherwise you're flying blind here", "Same as above", "This error should communicate that the function \"failed to determine if etcd is self hosted\".", "Better name for this member.", "I don't think this is a good heuristic. Instead switch on the namespace. \"kube-system\" or \"tectonci-system\" and no default", "It is confusing to call these things services in the context of k8s since a service is a particular concept. just call them pods.", "Document this function please", "Why are we ignoring these errors?", "Please rename hadetcd to something like etcdIsSelfHosted.", "Using \"tectonic_experimental\" for determining if etcd is self hosted is brittle - the meaning of this flag has changed every release.\r\n\r\n", "Is there a better way to do it? This is how both Quentin and Geoff said to find out.", "We generally try to avoid CSS pseudo-classes because they cause so much trouble.", "The \"right\" way to check would be to see if we are running etcd on k8s.  I'm not sure its worth effort honestly.", "Good question, I'm not sure; this section was just taken from the previous terraformStatusHandler() function.", "ok, let's handle these errors then. We can afford to be careful and verbose here.", "`Console` is a different type than the rest of these fields.  Any chance we could clean this up while we are here?", "I would expect components in this context to refer to React Components.", "Its hard to follow this logic.  If am I reading this correctly, `anyFailed` means any one component has a failed status and `allDone` means every component has a success status besides `tectonic` which should have the ready status.\r\n\r\nSince we don't care about efficiency at all, you could write `anyFailed` as eg:\r\n\r\n`const anyFailed = _.some(components, c => tectonic[c.key].failed)`\r\n\r\n... and the equivalent for `allDone`.  Cleaning up the actual response from the back end would also make life easier here.", "I just realized that the formatting for this file is a little off. please format using `gofmt -s -w`", "How would you recommend I rewrite that section? As it is, it basically just mirrors the .wiz-launch-progress classes.", "Gofmt didn't cause any changes.\r\n\r\nI have my IDE set so that it should automatically run gofmt anyway.", "The primary issue is that the DNS waiting icon depends on the ServiceStatus \"instance\" field. How would you recommend separating that?", "ok good. Looks like github diff view just renders tabs oddly.", "Keep track of the position in JS when you render the the Components and add classes to the fist/last ones.  You can punt on it if its too much work."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1189", "comments": ["Can we make `tectonic_openstack_etcd_flavor_id` optional when using self-hosted etcd (i.e. when `tectonic_experimental == true`)?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1184", "comments": ["Un comment these tests.", "Run gofmt on this file", "One of the things that the last version of te test did was _attempt_ to ensure that the API server pod was stable by ensuring it stayed up for more than one check. This removes that test", "I see. Checking for crash loops? We thought it was for mis-checking checkpointed pods. Will add back something then. Thanks!"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1177", "comments": ["Could you `set -o pipefail`?", "I don't think we want x or pipefail here - this is just for debugging.", "These would all be more succinct with\r\n```sh\r\nprintf \"hostname %s\\n\" \"$(hostname)\"`\r\n```", "Ah ok fair enuff. No pipefail, e; yes x.", "Is there something else we can do? Like useradd on the executor/in the image, changing the UID/GID mapping? Terraform could be made to do anything with that."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1169", "comments": ["Do we really need this as a variable? Is it reasonable to just make it part of the interpolated string?\r\nThe resources where it's being used wouldn't be reused across modules.", "@alexsomesan the thought was that this could be used for an Azure companion PR of #1115.\r\nI can pull it out though, just let me know.", "This name needs to exactly match the resource name in order for the azure cloud provider to work when searching for the machines definition in the azure api.", "Same comment as the master name."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1156", "comments": ["Missing `- --client-cert-auth=true`", "Missing `dnsPolicy: ClusterFirstWithHostNet`, which upstream has", "ah, that was introduced in https://github.com/kubernetes-incubator/bootkube/pull/603 today"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1154", "comments": ["this seems to be in conflict with `tectonic_cl_channel` and is also not very portable across platforms. i.e. AWS uses the channel semantics, OpenStack expects an explicit VM image. I am afraid we are introducing redundancies and inconsistencies here.", "We should describe the behavior if this field is left empty.", "Same here, we should describe the behavior if this field is left empty and all the `*_id` fields below. I suppose this is for bring-your-own use cases?", "\ud83d\udc4d ", "First, great catch with `tectonic_cl_channel`. \r\nIt seems hardcored for Azure. I'll make it draw from that var.\r\n\r\nAs to the version number, I used it to pin down to a lower version recently when the latest CL had networking regressions on Azure. I suspect this would come in handy in future similar situations. \r\n\r\nShould we rather try to port it to the other platforms the same way? What do you think?", "Yeah, all the `*_id` are for bring your own stuff.\r\nYou mean make it explicit that setting them to empty creates new resources of that type?", "@alexsomesan We could try that, but I am afraid not all platforms will be able to support it. As a data-point:\r\n\r\n- AWS: queries `tectonic_cl_channel` only\r\n- OpenStack: refers to a hard-coded image referenced by `tectonic_openstack_image_id`.\r\n- VMWare: expects a converted VM image template referenced by `tectonic_vmware_vm_template`\r\n- Bare Metal: needs both a CL version as here referenced by `tectonic_metal_cl_version` which is in sync with `tectonic_cl_channel`", "@alexsomesan yes, i.e. `if left empty/blank, a new network security group will be created.`", "I guess we should add custom tags like `tectonic_aws_extra_tags` to all the things.", "And probably also add the same cluster ID tag per default as we do in AWS:\r\n```\r\n...\r\n\"tectonicClusterID\", \"${var.cluster_id}\"\r\n...\r\n```", "\ud83d\udc4d makes sense. let me do that.", "having said that, this is probably less critical in Azure as we have resource groups.", "just a naming nit: `worker_ips`/`master_ips`/.... would be way shorter.", "Pinning to 1353.8.0 gets around https://github.com/coreos/tectonic-installer/issues/1171, but with locksmithd and update engine still enabled, the CLUO can still bump this up to 1409.x.0 creating dropped network packet errors on Azure.", "Along the same token as cluster ID tagging, resources like Azure storage account, containers etc. do not utilize the cluster name in their respective names. This results in some resources to be easily identified when listed by the cluster name set since its used as a prefix for the resource name, where as others don't have it. This does not take into consideration naming constraints on resources: https://blogs.msdn.microsoft.com/jmstall/2014/06/12/azure-storage-naming-rules/\r\n\r\nThoughts?", "If experimental is not enabled, this will always default the count of etcd to be 1 instance per the `min` interpolation syntax. How come we are not using the tectonic_etcd_count?", "You're right. Good catch!\r\nThe logic is wrong here. It should have been a max() not a min().\r\n\r\nThe aim was to make sure that when experimental is disabled, we create at least 1 etcd node.\r\nThis comes after debugging an issue for a user who had set both etcd_count to 0 and experimental to false. In that case everything would still start up but API would be unresponsive due to no etcd available.\r\n\r\nWill change it to max().\r\n", "\ud83d\udc4d \r\n", "Makes total sense. \r\nThe measure was meant to unblock me from making progress with these changes, but apparently other users have been asking for such an option.\r\nAs you rightfully point out, it's pretty useless without the corresponding support in CLUO.\r\n\r\n@robszumski Are there any plans for CLUO to support version pinning, similar to this?\r\n", "How about using `examples/terraform.tfvars.azure` here instead?", "Sounds good \ud83d\udc4d Let's iterate on this, once CI passes green. I also have a better commit for the `etcd_count` fix. The only diff to the native example I see is the worker count (1 vs. 3) and azure location (\"\" vs. \"eastus\").", "As terraform favours file defined variables over env defined variables, this is quite a messy change?!", "I talked to @s-urbaniak. We decided to use `tfvars` file shadowing in the long run, but to delay this task to a different PR.", "Yes, I believe there is a way to stop a roll out. @euank or @dghubble, is this true?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1150", "comments": ["period/limit could have better names.", "I agree. `interval` and `max`? Also, I'll rename all occurrences of `wait` to `max` or whatever", "updated :)", "can we add some comments for these vars explaining what they do", "Sure, I'll add that to the commits now. these two variables are flags used to gate white tests to run.", "@rithujohn191 updated"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1137", "comments": ["Should we use the DNS name generated by `modules/azure/dns/etcd.tf`? That way we don't need to update the masters if the etcd ips change. Not sure what the reasoning was to use IPs here."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1133", "comments": ["Kubernetes", "also - above this line, 'underging'  should be 'undergoing' (I can't figure out how to add comments to unedited lines.)", "Use GUI installer to configure cluster.\r\n\r\nmaybe change to 'GUI (if available)' rather than 'GUI Only'", "Not recommended for production", "same as above."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1131", "comments": ["This guy is still used by other apps (like release). We should keep it \ud83d\udc4d  "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1128", "comments": ["/cc @hongchaodeng @xiang90 ", "lgtm.", "I added the `dnsPolicy` in the original PR already, so this is added now twice here and in line 36. I suppose this doesn't matter, but we can remove the redundant entry.", "Shoot probably at rebase \ud83d\udc4e Good catch!"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1126", "comments": ["Does anyone know what this does?", "I don't think this is even close.   Lets fix it now?", "It is a mystery.", "I'm worried by \"fixing\" it, we'll break something. For all we know, this script depends on broken behavior. :("]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1124", "comments": ["why this gets removed?", "Yeah I think I messed up the rebase from master. Let me fix this.", "@hasbro17 ideally this should be matched the version teo (line51) currently manages. or we have to keep them in-sync manually every time.\r\n\r\nbut it should not block this pr. just something we should keep in mind.", "Yeah currently this would have to be done manually. I'll try to think of a way to match the etcd-operator tag with the one that the TEO expects for its current mapping.", "fixed", "probably we do not need the status section.", "50mi memory seems too small...\r\n100m cpu + 128mb memory makes more sense to me.", "I think the status needs to be set since the TEO will compare the `spec.desiredVersion` with the `status.currentVersion`. If `status.currentVersion` is not present it will try to reconcile.", "/cc @yifan-gu what other operator does?", "Same as @hasbro17 said above.", "This should be in the `if [ \"$EXPERIMENTAL\" = \"true\" ]` section, as the Tectonic etcd operator is for self-hosted etcd only, correct?", "same comment applies as above."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1110", "comments": ["This should use PLATFORM_TYPE.", "This guy should also use the `const`.", "Some debugging code?", "Is this what we actually want? It seems like it'd make it harder to carve-up things in GA. I'm no expert though.", "@ggreer the tool where we consume this can do fancy string manipulation and regex searches so we can break this out. The problem is that we only have a few things that we report back, so we have to stuff both of these in here."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1107", "comments": ["\"in .pem format\"", "thanks @squat , updated"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1085", "comments": ["s/worker/etcd/", "s/worker/master/", "s/worker/master/", "s/worker/etcd/g", "only the master nodes are.", "^", "nit: remove me"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1084", "comments": ["Can we setup a `default = \"\"`, haven't tested but I believe that should let it create the VMs without adding it to a resource pool. ", "Was this edited by hand? we generate these programmatically using `make examples` . You should be able to keep this same as variables.tf and run `make examples` across the repo."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1082", "comments": ["not super opinionated but perhaps `vm_disk_lun` may flow better as a variable name?", "can we set the defaults to \"\" for the `tectonic_vmware_etcd_lun` , `tectonic_vmware_master_lun` and `tectonic_vmware_worker_lun` ? I believe having those as defaults should allow the users to use datastore directly (if they are not part of datastore cluster.", "var.vm_disk_lun seems to be a string. [count.index] requires it to be a map. Should remove [count.index]", "var.vm_disk_lun seems to be a string. [count.index] requires it to be a map. Should remove [count.index]"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1076", "comments": ["Removing this since it's not working as expected and I am refactoring this in https://github.com/coreos/tectonic-installer/pull/1064", "This gets the tag(if any) associated to the commit. If not then it returns <code>unknown</code> (https://github.com/coreos/babel-plugin-git-version-build/blob/master/lib/index.js#L107)", "Could the ternary be switched and !== be changed to ===? eg:\r\n\r\n    return GIT_RELEASE_TAG === 'unknown' ? false : semver.valid(GIT_RELEASE_TAG) && !GIT_RELEASE_TAG.includes('-rc.');\r\n\r\nThat logic just seems easier to follow.", "Do you remember what this is for? I totally forget. I don't know why we'd want to send any ga events in dev mode or non-release versions.", "This was used being used for debugging. Deleted it.", "Right you are! Done!"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1075", "comments": ["nit: <code>chrome<code>", "me spel gud"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1073", "comments": ["I suggest to use the heredoc format like\r\n```\r\ncontent = <<EOF\r\nUsePrivilegeSeparation sandbox\r\n...\r\nEOF\r\n```", "This doesn't do what you want it to. People will still be able to attempt password login due to PAM..... Yeah, I know, but really.\r\n\r\n`AuthenticationMethods publickey` is what you actually want.", "We shouldn't decide this IMO. Notably, on GCE a named user-account is made for members of the project with access to the machine. In order for things like gcloud ssh to work that user-account needs access.\r\n\r\nI know we don't *actually* support GCE yet, but regardless I think this is an overly-broad default.", "Might as well toss in `UseDNS no`", "@euank I pulled this example config from https://coreos.com/os/docs/latest/customizing-sshd.html\r\n\r\nMight be worth updating those docs if you have revision suggestions there.", "Looks like this is already [the default](http://man.openbsd.org/sshd_config#UseDNS)"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1072", "comments": ["post-merge nit: I believe `$i` will stay 0 in the logs as it is unused/undeclared.", "Woopsy! Thanks :D", "Opened https://github.com/coreos/tectonic-installer/pull/1089."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1070", "comments": ["we should use some default jenkins location and override `TF_VAR_tectonic_azure_ssh_key` for local execution.", "s/Azure/azure, just to be consistent with the other platforms.", "Good catch! You're right, this needs to come from Jenkins.\r\nThis was just a hack to run them locally.", "Are these random creds?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1067", "comments": ["Does it have to be 0.0.0.0 instead of localhost? Instructions look \"funny\" since URL in the browser will be 127.0.0.1", "loopback nonsensical to in-container installer; loopback (127.1) is just the handy endpoint for the port mapping. Dicussed OOB, confirmed by test. Stet.", "I feel like this is a bug unclear. Especially the last sentence..\r\n\r\nWhat about something like that? Not sure it's any better.\r\n```\r\nTectonic v1.6.4 does not include an Installer binary for Windows. However, Windows users can install Tectonic by running a container with Docker Community Edition (CE). This document describes how to leverage Docker CE on Windows in order to provision Tectonic clusters on any supported cloud provider.\r\n\r\nNote that this document does not describe deploying Tectonic clusters against Windows hosts. \r\n```", "Yeah, it must be `0.0.0.0:4444` here. It cannot be `127.0.0.1` or we won't have access outside of the container (i.e. on Windows)."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1066", "comments": ["A comment describing what the function does would be helpful.", "Walk recursively \"through\" the provided folders", "Maybe we could rename this to \"containSubstring\" or just \"stringContain\" for simplicity? :)", "Is the idea here to break out at the first err that cannot be decoded? because then we can just return here and avoid the if statement below.", "\"all\" resources defined...", "will this be enough buffer time for creating all the resources? Just wondering cause I have seen longer than 10 min wait times :)", "Please add a comment to define the functionality", "No, we want to show every errors (cannot be decoded, missing, etc) so they can all be fixed at once. Also, because there is no guarantee on the order of which the manifests will be read, it is better to show all errors because some custom resources might fail to decode if the CRD was not created (missing) - which will appear too.", "I haven't seen failures on this but I can happily increase this if judged necessary? Was trying to keep it low so we can see errors early (and avoid having the process killed by Jenkins).", "Sorry, I usually do.", "ahh ok got it! thanks for the clarification. ", ":+1: "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1065", "comments": ["instead of duplicating the regex, can't we just pass `image_re` from `config.tf`?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1064", "comments": ["You don't need this `if`.", "I have no idea what to do with this error?  Maybe just log it.", "I see`\t\"API rate limit exceeded ...)\"` when I curl this URL.  I'm guessing this will be common at the office :-/", "Yeah, just saw that too. Looking into it.", "Sorry for the additional chime in here, but shouldn't we use a URL we control completely (e.g. somewhere under https://coreos.com) rather than relying on github?", "Yeah, I thought about scraping it from our docs site originally, looking into that again now that we are hitting api rate limit.", "I think you can replace all three of these conditionals with `semver.gt(latestRelease, GIT_TAG);`", "It doesn't recognize <code>rc</code> as the prerelease string and returns <code>false</code> for <code>semver.gt('1.6.4-tectonic.1', '1.6.4-tectonic.1-rc.3');</code>", "Ah, nevermind then.", "Probably makes sense to log the caught error."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1059", "comments": ["There is no reason to mess around with assuming roles when we are recovering from a failure. If the assumed role is not privileged enough to destroy then that failure will be caught in the respective stage.", "should it be called something mentioning internal cluster / vpc?", "could you squash the var definition / export statements?\r\nand jump some lines maybe between individual logic blocks?", "Remember, this command does not create a cluster. It only creates a vpc into which we can launch a cluster. Maybe \"create-private-vpc\" but now we start getting into long command names. I can live with that if you feel strongly about it. ", "It is okay to do that all the time? Does not look bad, but figured I'd ask.", "You can run destroy-vpc multiple times in a row with no error. Unless terraform destroy fails, this command should exit 0.", "I think we need an independent retry block per apply.", "yeap, now that we create multiple clusters, they all need to be destroyed. it's probably okay to have them in the same retry block tho? it'd just read no state, and finish.", "Its maybe OK for two clusters.  What happens if the first destroy throws, or if it doesn't halt, or even if it just takes a really long time?", "@kans I changed it so that there are two retries. one for every cluster that is actually created.", "Should we export these in common or something? Otherwise vpc-destroy won't work, since it will lack these env vars. See https://jenkins-tectonic-installer.prod.coreos.systems/job/tectonic-installer/job/PR-1075/19/execution/node/198/log/ for an example of this failing."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1042", "comments": ["does it make to configure this setting?", "At some point yes, but for introducing this it's fine, plus I wanted to keep the templating effort to a minimum. I'd expect this only to become configurable once the experimental flag disappears.\r\n\r\nConsidering the Prometheus replicas are not configurable, and it's not being asked for yet I wouldn't put in the effort before it's necessary.\r\n\r\nSome people said the monitoring stack was using too much memory in the first place, so we wanted to keep it at a minimum initially."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1036", "comments": ["Name changes here require an upgrade path to all existing clusters as well - otherwise we have some clusters with one set of flags and another set with different flags. This could cause problems in the future.\r\n\r\nAre the file name changes a requirement, and if so - this needs to have an upgrade path prior to merging.\r\n\r\ncc @diegs as he's been working on flag merging logic.", "I'll let @coresolve clarify, but IIUC, this switch happened because client auth with Kubelet's using the apiserver cert & key required access to the CA key: https://github.com/coreos/tectonic-installer/pull/1036/files#diff-a6092b44e14d3f0ebd9d657ab9ba5998L85.\r\n\r\nProviding the CA Key is understandably something not all users may not want to do.\r\n\r\nThe kubelet's instead generate their own self-signed cert to get around the CA key requirement we had when using the apiserver cert, to continue encrypting internal comms.\r\n\r\nHowever, I agree that an upgrade path is in order to manage the different sets of flags clusters can have.\r\n", "None of these should necessitate the use of the CA key. The CA key doesn't/shouldn't even need to exist at all in the cluster right now (until we actually use the CSR endpoint). This is simply saying that the apiserver key/cert should be used as the client cert -- which is pretty valid: the client is the apiserver reaching out to the kubelet api.\r\n\r\nCould be misunderstanding something (or maybe tectonic does this differently than bootkube).", "@coresolve I probably misunderstood the change here. Care to clear things up?", "From an offline discussion:\r\n\r\nIt sounds like the need is to allow the apiserver to use separate client and server certificates (right now it uses the same certificate for both). We shouldn't be using the kubelet cert for this, however, so as follow up this should change to generating 2 certs for the apiserver, one with server usage, one with client.\r\n\r\n@ericchiang any particular rbac group that the client usage cert should get?", "Also, if \"provide your own certificates\" needs to be merged faster -- that functionality can go in without disruption. Then the change to use separate server / client certs in apiserver could be a follow-up (which needs to have an upgrade path).", "Thanks @aaronlevy I will address this change."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1026", "comments": ["From what I've noticed, we've been managing the LB configs within the `modules/<platform>/<role>`.\r\nAny specific reason to pull this into `modules/vnet/`?\r\n\r\nI'm not against it, but think if we do this, we should consider doing the same for master, api, console LBs (separate PR). ", "Could we shorten this to just `cluster_name` within `platforms/azure/main.tf`?", "definitely, good catch", "Please see https://github.com/coreos/tectonic-installer/pull/1026#issuecomment-307169483 for the rationale.", "For some reason this becomes `--initial-cluster=10.1.0.4=http://%!s(MISSING):2380` when rendered on a single etcd node cluster. If etcd_count is set > 1, I can't even plan/apply.", "The [] needs to be remove on both endpoints and network_interface_ids, otherwise the module gets a list of list.", "I'll have to verify this nit, I believe terraform passes this as a flat list, but I might be wrong.", "Ok, found the fix (also needs the changes mentioned below):\r\n\r\n```\r\n-  --initial-cluster=${join(\",\",formatlist(\"%s=http://%s:2380\",var.endpoints))}\r\n+  --initial-cluster=${join(\",\",formatlist(\"%s=http://%s:2380\",var.endpoints,var.endpoints))}\r\n```", "fixed", "Without this, I think it only had a single peer (without proper url due to the other issue). So I think it's necessary.", "I am wondering though, why this is not the case in all the other places we use the `[ ... ]` idiom :-/"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/1024", "comments": ["I'm pretty sure the installer needs to be built before it can be run.", "The second part of this line (`yarn run installer-tests`) is ~~run in the current directory, not frontend.~~ Edit: It looks like the lack of build dependency is causing this error. Jenkins is running this on a fresh checkout of the repo.\r\n\r\nYou probably want to remove the semicolon and the export. eg: `DISPLAY=:99 yarn run installer-tests`\r\n", "since its already build as part of previous steps on jenkins file which gets stashed. I'm testing these changes though", "That stash command only stashes the installer binary. It doesn't stash node_modules.", "cannot run ```yarn run installer-tests``` as package.json is in forntend. ", "I think this step needs the environment stuff from up on line 37-40.", "Not a blocker, but I think it's possible to avoid adding another apt source by using Chromium instead of Chrome."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/999", "comments": ["Not all cloud provider configs are json. Azure uses json or yaml, but the Openstack provider uses gcfg.", "Hrm okay, would it be reasonable to just drop the extension? Alternatively we need to make this a variable too. I'd rather not do that unless we have to due to other clouds complaining if you point them to a empty config, haven't tried that yet.", "this looks like a merge conflict", "Ah right, forgot to push my the fix. Did that now.", "The azure subscription, client id, and tenant id can all come from the terraform provider.\r\n\r\nSee:\r\n\r\n* https://github.com/coreos/tectonic-installer/pull/690/files#diff-a220ed1b5bfb31f80a78b7419badeadaR1\r\n* https://github.com/coreos/tectonic-installer/pull/690/files#diff-a220ed1b5bfb31f80a78b7419badeadaR13\r\n\r\nThis reduces the configuration an end user has to duplicate.", "I see you avoid the duplication through configuring the terraform provider using these values. I think that is a reasonable alternative.", "@discordianfish Can you integrate @cehoffman's suggestion of leveraging the `azurerm_client_config` data source for the subscription_id, client_id and tenant_id? This will help reduce the variables users have to provide.", "Why did etcd become a dependency here? How is this related to the cloud provider config?", "See @alexsomesan's note about embedding the client secret in the TF configuration file: https://github.com/coreos/tectonic-installer/pull/690/files#diff-75a7ba1b6d2b014a605357c4b944b351\r\n\r\nYou map it into the k8s components as a k8s Secret, but the client secret is still being configured in TF file itself.\r\n\r\nThoughts Alex?", "Oh good point: It's actually a fix for a regression. IIRC in #1026 the dependency on etcd was dropped by not referring it's output anymore. That caused terraform to create the bootkube stuff before etcd which failed.", "[x] done", "This can't be read from azurerm_client_config, so it needs to be a variable. I don't see a problem with that either. You can set them via env variables and doing so is required anyway by not giving explicit variables to the provider. I'm using the following env file which sets all these up\r\n```\r\nexport ARM_SUBSCRIPTION_ID=xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\r\nexport ARM_CLIENT_ID=xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\r\nexport ARM_TENANT_ID=xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\r\nexport TF_VAR_tectonic_azure_cloud_environment=AZUREPUBLICCLOUD\r\nexport TF_VAR_tectonic_azure_client_secret=\"abcd\"\r\n```", "I don't think `tectonic_azure_client_id` is used anymore with the move to `azurerm_client_config`.", "Similar comment to the client_id. `azurerm_client_config` obsoleted these variable inputs.", "This may need a default value\r\n "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/994", "comments": ["I have no idea if the quotes change the behavior, but https://github.com/coreos/tectonic-installer/pull/936 didn't use quotes.", "Don't use quotes. Agree that a linter would help with this."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/991", "comments": ["For the sake of consistency I would also call this `tectonic_ssh_network_external`", "Please name these new variables concerning azure only with a `tectonic_azure_...` prefix, i.e. `tectonic_enable_ssh_external` would become `tectonic_azure_enable_ssh_external`", "The default indiciates `VirtualNetwork` rather than `*`", "That is not a bad idea, indeed. Especially in the context of testing this might be useful.", "This object is already of type \"network security group\", hence I would not redundantly encode it in the name. I suggest to call it simply `${var.tectonic_cluster_name}-etcd`.", "We should be consistent with underscores `_` and dashes `-` across the names. We tend to use underscores `_` only.", "We don't have jumpbox creation for AWS, but I believe this is a great idea, also for the sake of testing :+1:", "Besides what @s-urbaniak said, please be aware that our naming convention requires platform specific parameters to include the platform as infix right after `tectonic_` (for example `tectonic_azure_`).\r\n\r\nNow, this particular variable is currently named like a generic one, applicable to all platforms. That is fine, functionality wise, since this is actually a feature we could backport to the other platforms.  But in that case, we should not expect it to carry Azure specific values, like `VirtualNetwork`, or `Internet`. Instead we should stick to CIDR blocks only which are compatible cross-platform.", "+1 for no type references in names", "@s-urbaniak thoughts on moving this to `config.tf`?\r\nRight now, it's inactive, but the intention would be to introduce it for each of the cloud platforms.", "@s-urbaniak Ideally, I'd like to keep this as is for now.\r\nThere are several instances where hyphens are used over underscores e.g., https://github.com/coreos/tectonic-installer/blob/master/modules/azure/master/master.tf#L23-L28\r\n\r\nIf we make the decision to definitively go one way or another, it should probably be its' own PR with a wholesale cleanup.\r\n\r\nLet me know what you think!", "Agreed, I am fine this not being part of the PR.", "Created #993 as a follow-up issue.", "I am fine with moving this to `config.tf` with a disclaimer in the description, that this works only for Azure right now.\r\n\r\nBut to be sure, let's gather also the opinion of @alexsomesan about the possibility to add an option to instanciate a bastion/jumpbox vm for encapsulated networks.", "This seems like an extremely fine-grained possibility to tweak security group creation vs. external reference. Do we actually need this level of granularity?\r\n\r\nI.e. in AWS we simply create those security groups, always. I wonder why in the case of Azure we need to optionally reference them?", "@s-urbaniak For context, this was a requirement coming from a customer, due to a fairly restrictive IAM policy.\r\n\r\nIt would be useful in other similar scenarios.", "I agree it's a great idea. We should backport this to the other platforms.", "I second what @s-urbaniak suggested. This is a level of granularity we can't realistically sustain in Tectonic from a product perspective. If we set such a precedent for one corner-case, it could backfire into an unsustainable set of corner-case uses that ask to be supported. We want to keep the product maintainable and generic enough to appeal to the maximum number of users.\r\n\r\nThe way we currently tackle this particular usage of security groups in AWS is better suited for generic consumption. I think we should use that as a guideline. \r\n\r\nSo in AWS, we allow users to opt out of tectonic creating networking resources and instead bring in their own, pre-configured network. In this mode, we stay COMPLETELY hands off. Meaning we don't try to create anything, but also expect that the user takes full control of configuring those resources.\r\n\r\nHow that would translate in here is: just ask the user to supply us with correctly configured NSGs, which have all the rules. When users supply NSG, we completely refrain from creating them or their rules.\r\n\r\nI suggest we move in the direction of that approach and drop these `create_*_nsg_rules` flags altogether. The user input would then become just a set of NSG ids.", "@s-urbaniak @alexsomesan Awesome. Moved to `config.tf` with a note to work on backporting it.", "@s-urbaniak @alexsomesan Thanks for the feedback regarding this. Agreed that it's quickly moving into untenable territory.\r\n\r\nThe hope is to find a happy medium between fully created NSGs via TF and fully unmanaged.\r\n\r\nAs we're using this in a fork for a customer, I'm tagging in @metral and @coresolve to provide their feedback as well, before proceeding with any additional edits.\r\n\r\nThanks again for looking this over guys!", "This can be removed since its no longer used", "What Mike said :)"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/990", "comments": ["@discordianfish The defaults are correctly set, however the example tfvars don't reflect that.\r\nCan you run `make docs examples` and then push?", "Oh wow, nice tooling. Didn't know about that :). Fixed!", "Awesome! Thanks @discordianfish!"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/986", "comments": ["These instructions can be used for the official stable platforms listed above, and for the following alpha/beta platforms:", "The [latest Terraform binary](https://www.terraform.io/downloads.html) may not always work with Tectonic Installer, which sometimes relies on bug fixes or features not yet available in the official Terraform release.", "... environment variable. This example uses ..."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/985", "comments": ["I tend to go one 'l' on 'colocation' - I think it's the standard now, but could be wrong.", "Tectonic 1.6 and later leverage ... (i think the subject is plural here)", "it would be good to add an example of special property. \r\nTaints are an attribute or marker applied to a node that describe a special property, such as....\r\n", "I am unable to understand what taint is by reading this documentation. I would require example to understand the concept. If we don't have a doc describing what taint is, probably we should add some additional details to elaborate the concept.", "Tectonic 1.6 and later versions leverage ....", "update or rescheduling operations.", "Fixed the spelling/grammar nits.\r\n\r\nThe suggestions for adding content/explanation are acknowledged but are out of scope for this PR, which intends only to update version strings for the 1.6.4-t.1 release."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/974", "comments": ["we don't need to plan here. if you want to plan and create then execute two calls: `smoke.sh plan...` followed by `smoke.sh create...`", "make this a function so we can make the variables local. this is useful so that sourcing the script does not set a bunch of variables like `COMMAND` on the calling shell.", "these are common dependencies so it makes sense for them to go in `common`.", "set +x so that the eval'd credentials are not printed out to stdout", "we use `eval` rather than `source` as the method for passing variables because if we source the script, we try to execute bash-specific commands like `set -o pipefail` in `sh` which causes an error."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/968", "comments": ["Plz set bash options `-ex` to ensure it exits on error and all commands are executed in debug mode. ", "We recently went through a good bit of iteration to get  a lot of this working well in the smoke.sh script. It would make sense instead or recreating all this logic here, to simply call `smoke.sh create ...` and `smoke.sh destroy ...` to create and destroy your cluster respectively.", "Done", "Added a function to handle checking cluster name and randomizing AWS region. Exporting the function from smoke.sh requires a lot more restructuring.", "please also set `-o pipefail` to catch errors that would be hidden by a pipe.", "are you using smoke.sh? I thought you re-implemented the region and cluster name generation.", "these statements should all be indented equally. It looks like they're indented 1 space character.", "the indentation should match this `if` statement.", "also indent.", "this statement should be indented and then the heredoc should be unindented since whitespace is interpreted literally in a heredoc.", "this will work but it is a little fragile. If you happened to move the increment to a different line from the value test, then this would fail on the first try since `(( 0++ ))` returns error code `1`.", "same thing with this heredoc.", "this in-line bash script needs to have `set -exo pipefail` as well since it is executing a bunch of bash and make file invocations.", "you will need to ensure that these credentials do not leak.", "once you add `-o pipefail` this while check will not do what we want. if kubectl returns an error, then the error will not be swallowed by the pipe, even if you do `+e`. As a result, if kubectl returns any error, then the while condition will evaluate to false and the function will exit.", "if possible, we should avoid having +e here", "any specifics on how?", "Setting `+x` before line 105 and then `-x` on line 123 may be sufficient", "Can we have the image as a variable at the top so it's easier to update? This is already super old. Also do you need to pull before running?", "do you need to pull? can you move this as a variable?", "I see all the other scripts pulling before running it, so thought it would be a safe move. Changed it to a var.", "done"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/966", "comments": ["You should wrap the destination in quotes to prevent globbing or spaces from messing this up.", "Hmm.. i'm not convinced this fixes it because this invocation of tar changes *into* `TECTONIC_RELEASE_DIR` so we are still including `.` just by a different name now.", "I think it works. I ran `make dist` and untarred the result with `tar xzvf`. It didn't print out `.`. Everything extracted was prefixed with \"tectonic\".", "I tried this change locally.", "```\r\nBuilding release tarball\r\na tectonic\r\na tectonic/config.tf\r\na tectonic/examples\r\na tectonic/modules\r\na tectonic/platforms\r\na tectonic/tectonic-installer\r\na tectonic/terraformrc.example\r\na tectonic/tectonic-installer/darwin\r\na tectonic/tectonic-installer/linux\r\na tectonic/tectonic-installer/linux/installer\r\na tectonic/tectonic-installer/linux/terraform\r\na tectonic/tectonic-installer/darwin/installer\r\na tectonic/tectonic-installer/darwin/terraform\r\na tectonic/platforms/.DS_Store\r\na tectonic/platforms/aws\r\na tectonic/platforms/azure\r\na tectonic/platforms/metal\r\na tectonic/platforms/openstack\r\na tectonic/platforms/vmware\r\na tectonic/platforms/vmware/config.tf\r\na tectonic/platforms/vmware/main.tf\r\na tectonic/platforms/vmware/provider.tf\r\na tectonic/platforms/vmware/remote.tf\r\na tectonic/platforms/vmware/tectonic.tf\r\na tectonic/platforms/vmware/variables.tf\r\na tectonic/platforms/openstack/neutron\r\na tectonic/platforms/openstack/nova\r\na tectonic/platforms/openstack/nova/config.tf\r\na tectonic/platforms/openstack/nova/dns.tf\r\na tectonic/platforms/openstack/nova/main.tf\r\na tectonic/platforms/openstack/nova/nodes.tf\r\na tectonic/platforms/openstack/nova/variables.tf\r\na tectonic/platforms/openstack/neutron/config.tf\r\na tectonic/platforms/openstack/neutron/dns.tf\r\na tectonic/platforms/openstack/neutron/main.tf\r\na tectonic/platforms/openstack/neutron/network.tf\r\na tectonic/platforms/openstack/neutron/nodes.tf\r\na tectonic/platforms/openstack/neutron/variables.tf\r\na tectonic/platforms/metal/cl\r\na tectonic/platforms/metal/config.tf\r\na tectonic/platforms/metal/matchers.tf\r\na tectonic/platforms/metal/profiles.tf\r\na tectonic/platforms/metal/provider.tf\r\na tectonic/platforms/metal/remote.tf\r\na tectonic/platforms/metal/tectonic.tf\r\na tectonic/platforms/metal/variables.tf\r\na tectonic/platforms/metal/cl/bootkube-controller.yaml.tmpl\r\na tectonic/platforms/metal/cl/bootkube-worker.yaml.tmpl\r\na tectonic/platforms/metal/cl/coreos-install.yaml.tmpl\r\na tectonic/platforms/azure/config.tf\r\na tectonic/platforms/azure/dns-todo\r\na tectonic/platforms/azure/main.tf\r\na tectonic/platforms/azure/tectonic.tf\r\na tectonic/platforms/azure/variables.tf\r\na tectonic/platforms/azure/dns-todo/worker.tf\r\na tectonic/platforms/aws/.DS_Store\r\na tectonic/platforms/aws/.terraform\r\na tectonic/platforms/aws/config.tf\r\na tectonic/platforms/aws/main.tf\r\na tectonic/platforms/aws/route53.tf\r\na tectonic/platforms/aws/s3.tf\r\na tectonic/platforms/aws/tectonic.tf\r\na tectonic/platforms/aws/variables.tf\r\na tectonic/modules/aws\r\na tectonic/modules/azure\r\na tectonic/modules/bootkube\r\na tectonic/modules/openstack\r\na tectonic/modules/tectonic\r\na tectonic/modules/update-payload\r\na tectonic/modules/vmware\r\na tectonic/modules/vmware/etcd\r\na tectonic/modules/vmware/node\r\na tectonic/modules/vmware/node/ignition.tf\r\na tectonic/modules/vmware/node/nodes.tf\r\na tectonic/modules/vmware/node/outputs.tf\r\na tectonic/modules/vmware/node/resources\r\na tectonic/modules/vmware/node/variables.tf\r\na tectonic/modules/vmware/node/resources/services\r\na tectonic/modules/vmware/node/resources/services/kubelet-env.service\r\na tectonic/modules/vmware/node/resources/services/kubelet.service\r\na tectonic/modules/vmware/etcd/ignition.tf\r\na tectonic/modules/vmware/etcd/nodes.tf\r\na tectonic/modules/vmware/etcd/outputs.tf\r\na tectonic/modules/vmware/etcd/resources\r\na tectonic/modules/vmware/etcd/variables.tf\r\na tectonic/modules/vmware/etcd/resources/etcd-cluster\r\na tectonic/modules/update-payload/assets.tf\r\na tectonic/modules/update-payload/awsutil.sh\r\na tectonic/modules/update-payload/config.tf\r\na tectonic/modules/update-payload/make-update-payload.sh\r\na tectonic/modules/update-payload/payload.json\r\na tectonic/modules/update-payload/publish-payload.sh\r\na tectonic/modules/update-payload/sign-payload.sh\r\na tectonic/modules/update-payload/upload-payload.sh\r\na tectonic/modules/tectonic/assets.tf\r\na tectonic/modules/tectonic/crypto.tf\r\na tectonic/modules/tectonic/output.tf\r\na tectonic/modules/tectonic/resources\r\na tectonic/modules/tectonic/variables.tf\r\na tectonic/modules/tectonic/resources/manifests\r\na tectonic/modules/tectonic/resources/tectonic-rkt.sh\r\na tectonic/modules/tectonic/resources/tectonic.service\r\na tectonic/modules/tectonic/resources/tectonic.sh\r\na tectonic/modules/tectonic/resources/manifests/config.yaml\r\na tectonic/modules/tectonic/resources/manifests/console\r\na tectonic/modules/tectonic/resources/manifests/etcd\r\na tectonic/modules/tectonic/resources/manifests/heapster\r\na tectonic/modules/tectonic/resources/manifests/identity\r\na tectonic/modules/tectonic/resources/manifests/ingress\r\na tectonic/modules/tectonic/resources/manifests/monitoring\r\na tectonic/modules/tectonic/resources/manifests/namespace.yaml\r\na tectonic/modules/tectonic/resources/manifests/rbac\r\na tectonic/modules/tectonic/resources/manifests/secrets\r\na tectonic/modules/tectonic/resources/manifests/stats-emitter.yaml\r\na tectonic/modules/tectonic/resources/manifests/updater\r\na tectonic/modules/tectonic/resources/manifests/updater/app-version-kind.yaml\r\na tectonic/modules/tectonic/resources/manifests/updater/app-version-kubernetes.yaml\r\na tectonic/modules/tectonic/resources/manifests/updater/app-version-tectonic-cluster.yaml\r\na tectonic/modules/tectonic/resources/manifests/updater/app-version-tectonic-monitoring.yaml\r\na tectonic/modules/tectonic/resources/manifests/updater/container-linux-update-operator.yaml\r\na tectonic/modules/tectonic/resources/manifests/updater/kube-version-operator.yaml\r\na tectonic/modules/tectonic/resources/manifests/updater/migration-status-kind.yaml\r\na tectonic/modules/tectonic/resources/manifests/updater/node-agent.yaml\r\na tectonic/modules/tectonic/resources/manifests/updater/tectonic-channel-operator-config.yaml\r\na tectonic/modules/tectonic/resources/manifests/updater/tectonic-channel-operator-kind.yaml\r\na tectonic/modules/tectonic/resources/manifests/updater/tectonic-channel-operator.yaml\r\na tectonic/modules/tectonic/resources/manifests/updater/tectonic-prometheus-operator.yaml\r\na tectonic/modules/tectonic/resources/manifests/secrets/ca-cert.yaml\r\na tectonic/modules/tectonic/resources/manifests/secrets/identity-grpc-client.yaml\r\na tectonic/modules/tectonic/resources/manifests/secrets/identity-grpc-server.yaml\r\na tectonic/modules/tectonic/resources/manifests/secrets/ingress-tls.yaml\r\na tectonic/modules/tectonic/resources/manifests/secrets/license.json\r\na tectonic/modules/tectonic/resources/manifests/secrets/pull.json\r\na tectonic/modules/tectonic/resources/manifests/rbac/binding-admin.yaml\r\na tectonic/modules/tectonic/resources/manifests/rbac/binding-discovery.yaml\r\na tectonic/modules/tectonic/resources/manifests/rbac/role-admin.yaml\r\na tectonic/modules/tectonic/resources/manifests/rbac/role-discovery.yaml\r\na tectonic/modules/tectonic/resources/manifests/rbac/role-ingress-controller.yaml\r\na tectonic/modules/tectonic/resources/manifests/rbac/role-user.yaml\r\na tectonic/modules/tectonic/resources/manifests/monitoring/kube-state-metrics-cluster-role-binding.yaml\r\na tectonic/modules/tectonic/resources/manifests/monitoring/kube-state-metrics-cluster-role.yaml\r\na tectonic/modules/tectonic/resources/manifests/monitoring/kube-state-metrics-deployment.yaml\r\na tectonic/modules/tectonic/resources/manifests/monitoring/kube-state-metrics-service-account.yaml\r\na tectonic/modules/tectonic/resources/manifests/monitoring/kube-state-metrics-service.yaml\r\na tectonic/modules/tectonic/resources/manifests/monitoring/node-exporter-ds.yaml\r\na tectonic/modules/tectonic/resources/manifests/monitoring/node-exporter-svc.yaml\r\na tectonic/modules/tectonic/resources/manifests/monitoring/prometheus-k8s-cluster-role-binding.yaml\r\na tectonic/modules/tectonic/resources/manifests/monitoring/prometheus-k8s-cluster-role.yaml\r\na tectonic/modules/tectonic/resources/manifests/monitoring/prometheus-k8s-rules.yaml\r\na tectonic/modules/tectonic/resources/manifests/monitoring/prometheus-k8s-service-account.yaml\r\na tectonic/modules/tectonic/resources/manifests/monitoring/prometheus-k8s-service-monitor-apiserver.yaml\r\na tectonic/modules/tectonic/resources/manifests/monitoring/prometheus-k8s-service-monitor-kube-state-metrics.yaml\r\na tectonic/modules/tectonic/resources/manifests/monitoring/prometheus-k8s-service-monitor-kubelet.yaml\r\na tectonic/modules/tectonic/resources/manifests/monitoring/prometheus-k8s-service-monitor-node-exporter.yaml\r\na tectonic/modules/tectonic/resources/manifests/monitoring/prometheus-k8s-service-monitor-prometheus.yaml\r\na tectonic/modules/tectonic/resources/manifests/monitoring/prometheus-k8s.yaml\r\na tectonic/modules/tectonic/resources/manifests/monitoring/prometheus-operator-cluster-role-binding.yaml\r\na tectonic/modules/tectonic/resources/manifests/monitoring/prometheus-operator-cluster-role.yaml\r\na tectonic/modules/tectonic/resources/manifests/monitoring/prometheus-operator-service-account.yaml\r\na tectonic/modules/tectonic/resources/manifests/monitoring/prometheus-operator.yaml\r\na tectonic/modules/tectonic/resources/manifests/monitoring/prometheus-svc.yaml\r\na tectonic/modules/tectonic/resources/manifests/ingress/default-backend\r\na tectonic/modules/tectonic/resources/manifests/ingress/hostport\r\na tectonic/modules/tectonic/resources/manifests/ingress/ingress.yaml\r\na tectonic/modules/tectonic/resources/manifests/ingress/nodeport\r\na tectonic/modules/tectonic/resources/manifests/ingress/nodeport/deployment.yaml\r\na tectonic/modules/tectonic/resources/manifests/ingress/nodeport/service.yaml\r\na tectonic/modules/tectonic/resources/manifests/ingress/hostport/daemonset.yaml\r\na tectonic/modules/tectonic/resources/manifests/ingress/hostport/service.yaml\r\na tectonic/modules/tectonic/resources/manifests/ingress/default-backend/configmap.yaml\r\na tectonic/modules/tectonic/resources/manifests/ingress/default-backend/deployment.yaml\r\na tectonic/modules/tectonic/resources/manifests/ingress/default-backend/service.yaml\r\na tectonic/modules/tectonic/resources/manifests/identity/configmap.yaml\r\na tectonic/modules/tectonic/resources/manifests/identity/deployment.yaml\r\na tectonic/modules/tectonic/resources/manifests/identity/services.yaml\r\na tectonic/modules/tectonic/resources/manifests/heapster/deployment.yaml\r\na tectonic/modules/tectonic/resources/manifests/heapster/service.yaml\r\na tectonic/modules/tectonic/resources/manifests/etcd/cluster-config.yaml\r\na tectonic/modules/tectonic/resources/manifests/console/deployment.yaml\r\na tectonic/modules/tectonic/resources/manifests/console/service.yaml\r\na tectonic/modules/openstack/etcd\r\na tectonic/modules/openstack/nodes\r\na tectonic/modules/openstack/secrets\r\na tectonic/modules/openstack/secrets/secrets.tf\r\na tectonic/modules/openstack/secrets/variables.tf\r\na tectonic/modules/openstack/nodes/ignition.tf\r\na tectonic/modules/openstack/nodes/output.tf\r\na tectonic/modules/openstack/nodes/resources\r\na tectonic/modules/openstack/nodes/secgroup.tf\r\na tectonic/modules/openstack/nodes/variables.tf\r\na tectonic/modules/openstack/nodes/resources/etcd-member.service\r\na tectonic/modules/openstack/nodes/resources/kubelet.service\r\na tectonic/modules/openstack/etcd/ignition.tf\r\na tectonic/modules/openstack/etcd/output.tf\r\na tectonic/modules/openstack/etcd/secgroup.tf\r\na tectonic/modules/openstack/etcd/variables.tf\r\na tectonic/modules/bootkube/assets.tf\r\na tectonic/modules/bootkube/assets_tls.tf\r\na tectonic/modules/bootkube/outputs.tf\r\na tectonic/modules/bootkube/resources\r\na tectonic/modules/bootkube/variables.tf\r\na tectonic/modules/bootkube/resources/bootkube.service\r\na tectonic/modules/bootkube/resources/bootkube.sh\r\na tectonic/modules/bootkube/resources/bootstrap-manifests\r\na tectonic/modules/bootkube/resources/experimental\r\na tectonic/modules/bootkube/resources/kubeconfig\r\na tectonic/modules/bootkube/resources/manifests\r\na tectonic/modules/bootkube/resources/tectonic\r\na tectonic/modules/bootkube/resources/tls\r\na tectonic/modules/bootkube/resources/tectonic/console\r\na tectonic/modules/bootkube/resources/tectonic/heapster\r\na tectonic/modules/bootkube/resources/tectonic/identity\r\na tectonic/modules/bootkube/resources/tectonic/ingress\r\na tectonic/modules/bootkube/resources/tectonic/monitoring\r\na tectonic/modules/bootkube/resources/tectonic/rbac\r\na tectonic/modules/bootkube/resources/tectonic/secrets\r\na tectonic/modules/bootkube/resources/tectonic/updater\r\na tectonic/modules/bootkube/resources/tectonic/ingress/default-backend\r\na tectonic/modules/bootkube/resources/tectonic/ingress/hostport\r\na tectonic/modules/bootkube/resources/tectonic/ingress/nodeport\r\na tectonic/modules/bootkube/resources/manifests/kube-apiserver-secret.yaml\r\na tectonic/modules/bootkube/resources/manifests/kube-apiserver.yaml\r\na tectonic/modules/bootkube/resources/manifests/kube-controller-manager-disruption.yaml\r\na tectonic/modules/bootkube/resources/manifests/kube-controller-manager-secret.yaml\r\na tectonic/modules/bootkube/resources/manifests/kube-controller-manager.yaml\r\na tectonic/modules/bootkube/resources/manifests/kube-dns.yaml\r\na tectonic/modules/bootkube/resources/manifests/kube-flannel.yaml\r\na tectonic/modules/bootkube/resources/manifests/kube-proxy.yaml\r\na tectonic/modules/bootkube/resources/manifests/kube-scheduler-disruption.yaml\r\na tectonic/modules/bootkube/resources/manifests/kube-scheduler.yaml\r\na tectonic/modules/bootkube/resources/manifests/kube-system-rbac-role-binding.yaml\r\na tectonic/modules/bootkube/resources/manifests/pod-checkpointer.yaml\r\na tectonic/modules/bootkube/resources/experimental/bootstrap-manifests\r\na tectonic/modules/bootkube/resources/experimental/etcd\r\na tectonic/modules/bootkube/resources/experimental/manifests\r\na tectonic/modules/bootkube/resources/experimental/manifests/etcd-operator.yaml\r\na tectonic/modules/bootkube/resources/experimental/manifests/etcd-service.yaml\r\na tectonic/modules/bootkube/resources/experimental/manifests/kenc.yaml\r\na tectonic/modules/bootkube/resources/experimental/etcd/bootstrap-etcd-service.json\r\na tectonic/modules/bootkube/resources/experimental/etcd/migrate-etcd-cluster.json\r\na tectonic/modules/bootkube/resources/experimental/bootstrap-manifests/bootstrap-etcd.yaml\r\na tectonic/modules/bootkube/resources/bootstrap-manifests/bootstrap-apiserver.yaml\r\na tectonic/modules/bootkube/resources/bootstrap-manifests/bootstrap-controller-manager.yaml\r\na tectonic/modules/bootkube/resources/bootstrap-manifests/bootstrap-scheduler.yaml\r\na tectonic/modules/azure/dns\r\na tectonic/modules/azure/etcd\r\na tectonic/modules/azure/master\r\na tectonic/modules/azure/resource-group\r\na tectonic/modules/azure/vnet\r\na tectonic/modules/azure/worker\r\na tectonic/modules/azure/worker/ignition-worker.tf\r\na tectonic/modules/azure/worker/resources\r\na tectonic/modules/azure/worker/variables.tf\r\na tectonic/modules/azure/worker/workers.tf\r\na tectonic/modules/azure/worker/resources/worker-kubelet.service\r\na tectonic/modules/azure/vnet/outputs.tf\r\na tectonic/modules/azure/vnet/security-groups.tf\r\na tectonic/modules/azure/vnet/variables.tf\r\na tectonic/modules/azure/vnet/virtualnet.tf\r\na tectonic/modules/azure/resource-group/rsg.tf\r\na tectonic/modules/azure/master/api-lb.tf\r\na tectonic/modules/azure/master/console-lb.tf\r\na tectonic/modules/azure/master/ignition-master.tf\r\na tectonic/modules/azure/master/lb.tf\r\na tectonic/modules/azure/master/master.tf\r\na tectonic/modules/azure/master/output.tf\r\na tectonic/modules/azure/master/resources\r\na tectonic/modules/azure/master/variables.tf\r\na tectonic/modules/azure/master/resources/master-kubelet.service\r\na tectonic/modules/azure/etcd/etcd.tf\r\na tectonic/modules/azure/etcd/ignition.tf\r\na tectonic/modules/azure/etcd/lb.tf\r\na tectonic/modules/azure/etcd/network.tf\r\na tectonic/modules/azure/etcd/output.tf\r\na tectonic/modules/azure/etcd/variables.tf\r\na tectonic/modules/azure/dns/etcd.tf\r\na tectonic/modules/azure/dns/main.tf\r\na tectonic/modules/azure/dns/master.tf\r\na tectonic/modules/azure/dns/outputs.tf\r\na tectonic/modules/azure/dns/variables.tf\r\na tectonic/modules/aws/etcd\r\na tectonic/modules/aws/ignition\r\na tectonic/modules/aws/master-asg\r\na tectonic/modules/aws/vpc\r\na tectonic/modules/aws/worker-asg\r\na tectonic/modules/aws/worker-asg/variables.tf\r\na tectonic/modules/aws/worker-asg/worker.tf\r\na tectonic/modules/aws/vpc/existing-vpc.tf\r\na tectonic/modules/aws/vpc/outputs.tf\r\na tectonic/modules/aws/vpc/sg-elb.tf\r\na tectonic/modules/aws/vpc/sg-etcd.tf\r\na tectonic/modules/aws/vpc/sg-master.tf\r\na tectonic/modules/aws/vpc/sg-worker.tf\r\na tectonic/modules/aws/vpc/variables.tf\r\na tectonic/modules/aws/vpc/vpc-private.tf\r\na tectonic/modules/aws/vpc/vpc-public.tf\r\na tectonic/modules/aws/vpc/vpc.tf\r\na tectonic/modules/aws/master-asg/elb.tf\r\na tectonic/modules/aws/master-asg/master.tf\r\na tectonic/modules/aws/master-asg/outputs.tf\r\na tectonic/modules/aws/master-asg/variables.tf\r\na tectonic/modules/aws/ignition/ignition.tf\r\na tectonic/modules/aws/ignition/outputs.tf\r\na tectonic/modules/aws/ignition/resources\r\na tectonic/modules/aws/ignition/variables.tf\r\na tectonic/modules/aws/ignition/resources/detect-master.sh\r\na tectonic/modules/aws/ignition/resources/init-assets.sh\r\na tectonic/modules/aws/ignition/resources/s3-puller.sh\r\na tectonic/modules/aws/ignition/resources/services\r\na tectonic/modules/aws/ignition/resources/services/init-assets.service\r\na tectonic/modules/aws/ignition/resources/services/kubelet-env.service\r\na tectonic/modules/aws/ignition/resources/services/kubelet.service\r\na tectonic/modules/aws/etcd/dns.tf\r\na tectonic/modules/aws/etcd/ignition.tf\r\na tectonic/modules/aws/etcd/nodes.tf\r\na tectonic/modules/aws/etcd/outputs.tf\r\na tectonic/modules/aws/etcd/variables.tf\r\na tectonic/examples/terraform.tfvars.aws\r\na tectonic/examples/terraform.tfvars.azure\r\na tectonic/examples/terraform.tfvars.metal\r\na tectonic/examples/terraform.tfvars.openstack-neutron\r\na tectonic/examples/terraform.tfvars.openstack-nova\r\na tectonic/examples/terraform.tfvars.vmware\r\n```\r\n\r\n```\r\nx tectonic/\r\nx tectonic/config.tf\r\nx tectonic/examples/\r\nx tectonic/modules/\r\nx tectonic/platforms/\r\nx tectonic/tectonic-installer/\r\nx tectonic/terraformrc.example\r\nx tectonic/tectonic-installer/darwin/\r\nx tectonic/tectonic-installer/linux/\r\nx tectonic/tectonic-installer/linux/installer\r\nx tectonic/tectonic-installer/linux/terraform\r\nx tectonic/tectonic-installer/darwin/installer\r\nx tectonic/tectonic-installer/darwin/terraform\r\nx tectonic/platforms/._.DS_Store\r\nx tectonic/platforms/.DS_Store\r\nx tectonic/platforms/aws/\r\nx tectonic/platforms/azure/\r\nx tectonic/platforms/metal/\r\nx tectonic/platforms/openstack/\r\nx tectonic/platforms/vmware/\r\nx tectonic/platforms/vmware/config.tf\r\nx tectonic/platforms/vmware/main.tf\r\nx tectonic/platforms/vmware/provider.tf\r\nx tectonic/platforms/vmware/remote.tf\r\nx tectonic/platforms/vmware/tectonic.tf\r\nx tectonic/platforms/vmware/variables.tf\r\nx tectonic/platforms/openstack/neutron/\r\nx tectonic/platforms/openstack/nova/\r\nx tectonic/platforms/openstack/nova/config.tf\r\nx tectonic/platforms/openstack/nova/dns.tf\r\nx tectonic/platforms/openstack/nova/main.tf\r\nx tectonic/platforms/openstack/nova/nodes.tf\r\nx tectonic/platforms/openstack/nova/variables.tf\r\nx tectonic/platforms/openstack/neutron/config.tf\r\nx tectonic/platforms/openstack/neutron/dns.tf\r\nx tectonic/platforms/openstack/neutron/main.tf\r\nx tectonic/platforms/openstack/neutron/network.tf\r\nx tectonic/platforms/openstack/neutron/nodes.tf\r\nx tectonic/platforms/openstack/neutron/variables.tf\r\nx tectonic/platforms/metal/cl/\r\nx tectonic/platforms/metal/config.tf\r\nx tectonic/platforms/metal/matchers.tf\r\nx tectonic/platforms/metal/profiles.tf\r\nx tectonic/platforms/metal/provider.tf\r\nx tectonic/platforms/metal/remote.tf\r\nx tectonic/platforms/metal/tectonic.tf\r\nx tectonic/platforms/metal/variables.tf\r\nx tectonic/platforms/metal/cl/bootkube-controller.yaml.tmpl\r\nx tectonic/platforms/metal/cl/bootkube-worker.yaml.tmpl\r\nx tectonic/platforms/metal/cl/coreos-install.yaml.tmpl\r\nx tectonic/platforms/azure/config.tf\r\nx tectonic/platforms/azure/dns-todo/\r\nx tectonic/platforms/azure/main.tf\r\nx tectonic/platforms/azure/tectonic.tf\r\nx tectonic/platforms/azure/variables.tf\r\nx tectonic/platforms/azure/dns-todo/worker.tf\r\nx tectonic/platforms/aws/._.DS_Store\r\nx tectonic/platforms/aws/.DS_Store\r\nx tectonic/platforms/aws/.terraform/\r\nx tectonic/platforms/aws/config.tf\r\nx tectonic/platforms/aws/main.tf\r\nx tectonic/platforms/aws/route53.tf\r\nx tectonic/platforms/aws/s3.tf\r\nx tectonic/platforms/aws/tectonic.tf\r\nx tectonic/platforms/aws/variables.tf\r\nx tectonic/modules/aws/\r\nx tectonic/modules/azure/\r\nx tectonic/modules/bootkube/\r\nx tectonic/modules/openstack/\r\nx tectonic/modules/tectonic/\r\nx tectonic/modules/update-payload/\r\nx tectonic/modules/vmware/\r\nx tectonic/modules/vmware/etcd/\r\nx tectonic/modules/vmware/node/\r\nx tectonic/modules/vmware/node/ignition.tf\r\nx tectonic/modules/vmware/node/nodes.tf\r\nx tectonic/modules/vmware/node/outputs.tf\r\nx tectonic/modules/vmware/node/resources/\r\nx tectonic/modules/vmware/node/variables.tf\r\nx tectonic/modules/vmware/node/resources/services/\r\nx tectonic/modules/vmware/node/resources/services/kubelet-env.service\r\nx tectonic/modules/vmware/node/resources/services/kubelet.service\r\nx tectonic/modules/vmware/etcd/ignition.tf\r\nx tectonic/modules/vmware/etcd/nodes.tf\r\nx tectonic/modules/vmware/etcd/outputs.tf\r\nx tectonic/modules/vmware/etcd/resources/\r\nx tectonic/modules/vmware/etcd/variables.tf\r\nx tectonic/modules/vmware/etcd/resources/etcd-cluster\r\nx tectonic/modules/update-payload/assets.tf\r\nx tectonic/modules/update-payload/awsutil.sh\r\nx tectonic/modules/update-payload/config.tf\r\nx tectonic/modules/update-payload/make-update-payload.sh\r\nx tectonic/modules/update-payload/payload.json\r\nx tectonic/modules/update-payload/publish-payload.sh\r\nx tectonic/modules/update-payload/sign-payload.sh\r\nx tectonic/modules/update-payload/upload-payload.sh\r\nx tectonic/modules/tectonic/assets.tf\r\nx tectonic/modules/tectonic/crypto.tf\r\nx tectonic/modules/tectonic/output.tf\r\nx tectonic/modules/tectonic/resources/\r\nx tectonic/modules/tectonic/variables.tf\r\nx tectonic/modules/tectonic/resources/manifests/\r\nx tectonic/modules/tectonic/resources/tectonic-rkt.sh\r\nx tectonic/modules/tectonic/resources/tectonic.service\r\nx tectonic/modules/tectonic/resources/tectonic.sh\r\nx tectonic/modules/tectonic/resources/manifests/config.yaml\r\nx tectonic/modules/tectonic/resources/manifests/console/\r\nx tectonic/modules/tectonic/resources/manifests/etcd/\r\nx tectonic/modules/tectonic/resources/manifests/heapster/\r\nx tectonic/modules/tectonic/resources/manifests/identity/\r\nx tectonic/modules/tectonic/resources/manifests/ingress/\r\nx tectonic/modules/tectonic/resources/manifests/monitoring/\r\nx tectonic/modules/tectonic/resources/manifests/namespace.yaml\r\nx tectonic/modules/tectonic/resources/manifests/rbac/\r\nx tectonic/modules/tectonic/resources/manifests/secrets/\r\nx tectonic/modules/tectonic/resources/manifests/stats-emitter.yaml\r\nx tectonic/modules/tectonic/resources/manifests/updater/\r\nx tectonic/modules/tectonic/resources/manifests/updater/app-version-kind.yaml\r\nx tectonic/modules/tectonic/resources/manifests/updater/app-version-kubernetes.yaml\r\nx tectonic/modules/tectonic/resources/manifests/updater/app-version-tectonic-cluster.yaml\r\nx tectonic/modules/tectonic/resources/manifests/updater/app-version-tectonic-monitoring.yaml\r\nx tectonic/modules/tectonic/resources/manifests/updater/container-linux-update-operator.yaml\r\nx tectonic/modules/tectonic/resources/manifests/updater/kube-version-operator.yaml\r\nx tectonic/modules/tectonic/resources/manifests/updater/migration-status-kind.yaml\r\nx tectonic/modules/tectonic/resources/manifests/updater/node-agent.yaml\r\nx tectonic/modules/tectonic/resources/manifests/updater/tectonic-channel-operator-config.yaml\r\nx tectonic/modules/tectonic/resources/manifests/updater/tectonic-channel-operator-kind.yaml\r\nx tectonic/modules/tectonic/resources/manifests/updater/tectonic-channel-operator.yaml\r\nx tectonic/modules/tectonic/resources/manifests/updater/tectonic-prometheus-operator.yaml\r\nx tectonic/modules/tectonic/resources/manifests/secrets/ca-cert.yaml\r\nx tectonic/modules/tectonic/resources/manifests/secrets/identity-grpc-client.yaml\r\nx tectonic/modules/tectonic/resources/manifests/secrets/identity-grpc-server.yaml\r\nx tectonic/modules/tectonic/resources/manifests/secrets/ingress-tls.yaml\r\nx tectonic/modules/tectonic/resources/manifests/secrets/license.json\r\nx tectonic/modules/tectonic/resources/manifests/secrets/pull.json\r\nx tectonic/modules/tectonic/resources/manifests/rbac/binding-admin.yaml\r\nx tectonic/modules/tectonic/resources/manifests/rbac/binding-discovery.yaml\r\nx tectonic/modules/tectonic/resources/manifests/rbac/role-admin.yaml\r\nx tectonic/modules/tectonic/resources/manifests/rbac/role-discovery.yaml\r\nx tectonic/modules/tectonic/resources/manifests/rbac/role-ingress-controller.yaml\r\nx tectonic/modules/tectonic/resources/manifests/rbac/role-user.yaml\r\nx tectonic/modules/tectonic/resources/manifests/monitoring/kube-state-metrics-cluster-role-binding.yaml\r\nx tectonic/modules/tectonic/resources/manifests/monitoring/kube-state-metrics-cluster-role.yaml\r\nx tectonic/modules/tectonic/resources/manifests/monitoring/kube-state-metrics-deployment.yaml\r\nx tectonic/modules/tectonic/resources/manifests/monitoring/kube-state-metrics-service-account.yaml\r\nx tectonic/modules/tectonic/resources/manifests/monitoring/kube-state-metrics-service.yaml\r\nx tectonic/modules/tectonic/resources/manifests/monitoring/node-exporter-ds.yaml\r\nx tectonic/modules/tectonic/resources/manifests/monitoring/node-exporter-svc.yaml\r\nx tectonic/modules/tectonic/resources/manifests/monitoring/prometheus-k8s-cluster-role-binding.yaml\r\nx tectonic/modules/tectonic/resources/manifests/monitoring/prometheus-k8s-cluster-role.yaml\r\nx tectonic/modules/tectonic/resources/manifests/monitoring/prometheus-k8s-rules.yaml\r\nx tectonic/modules/tectonic/resources/manifests/monitoring/prometheus-k8s-service-account.yaml\r\nx tectonic/modules/tectonic/resources/manifests/monitoring/prometheus-k8s-service-monitor-apiserver.yaml\r\nx tectonic/modules/tectonic/resources/manifests/monitoring/prometheus-k8s-service-monitor-kube-state-metrics.yaml\r\nx tectonic/modules/tectonic/resources/manifests/monitoring/prometheus-k8s-service-monitor-kubelet.yaml\r\nx tectonic/modules/tectonic/resources/manifests/monitoring/prometheus-k8s-service-monitor-node-exporter.yaml\r\nx tectonic/modules/tectonic/resources/manifests/monitoring/prometheus-k8s-service-monitor-prometheus.yaml\r\nx tectonic/modules/tectonic/resources/manifests/monitoring/prometheus-k8s.yaml\r\nx tectonic/modules/tectonic/resources/manifests/monitoring/prometheus-operator-cluster-role-binding.yaml\r\nx tectonic/modules/tectonic/resources/manifests/monitoring/prometheus-operator-cluster-role.yaml\r\nx tectonic/modules/tectonic/resources/manifests/monitoring/prometheus-operator-service-account.yaml\r\nx tectonic/modules/tectonic/resources/manifests/monitoring/prometheus-operator.yaml\r\nx tectonic/modules/tectonic/resources/manifests/monitoring/prometheus-svc.yaml\r\nx tectonic/modules/tectonic/resources/manifests/ingress/default-backend/\r\nx tectonic/modules/tectonic/resources/manifests/ingress/hostport/\r\nx tectonic/modules/tectonic/resources/manifests/ingress/ingress.yaml\r\nx tectonic/modules/tectonic/resources/manifests/ingress/nodeport/\r\nx tectonic/modules/tectonic/resources/manifests/ingress/nodeport/deployment.yaml\r\nx tectonic/modules/tectonic/resources/manifests/ingress/nodeport/service.yaml\r\nx tectonic/modules/tectonic/resources/manifests/ingress/hostport/daemonset.yaml\r\nx tectonic/modules/tectonic/resources/manifests/ingress/hostport/service.yaml\r\nx tectonic/modules/tectonic/resources/manifests/ingress/default-backend/configmap.yaml\r\nx tectonic/modules/tectonic/resources/manifests/ingress/default-backend/deployment.yaml\r\nx tectonic/modules/tectonic/resources/manifests/ingress/default-backend/service.yaml\r\nx tectonic/modules/tectonic/resources/manifests/identity/configmap.yaml\r\nx tectonic/modules/tectonic/resources/manifests/identity/deployment.yaml\r\nx tectonic/modules/tectonic/resources/manifests/identity/services.yaml\r\nx tectonic/modules/tectonic/resources/manifests/heapster/deployment.yaml\r\nx tectonic/modules/tectonic/resources/manifests/heapster/service.yaml\r\nx tectonic/modules/tectonic/resources/manifests/etcd/cluster-config.yaml\r\nx tectonic/modules/tectonic/resources/manifests/console/deployment.yaml\r\nx tectonic/modules/tectonic/resources/manifests/console/service.yaml\r\nx tectonic/modules/openstack/etcd/\r\nx tectonic/modules/openstack/nodes/\r\nx tectonic/modules/openstack/secrets/\r\nx tectonic/modules/openstack/secrets/secrets.tf\r\nx tectonic/modules/openstack/secrets/variables.tf\r\nx tectonic/modules/openstack/nodes/ignition.tf\r\nx tectonic/modules/openstack/nodes/output.tf\r\nx tectonic/modules/openstack/nodes/resources/\r\nx tectonic/modules/openstack/nodes/secgroup.tf\r\nx tectonic/modules/openstack/nodes/variables.tf\r\nx tectonic/modules/openstack/nodes/resources/etcd-member.service\r\nx tectonic/modules/openstack/nodes/resources/kubelet.service\r\nx tectonic/modules/openstack/etcd/ignition.tf\r\nx tectonic/modules/openstack/etcd/output.tf\r\nx tectonic/modules/openstack/etcd/secgroup.tf\r\nx tectonic/modules/openstack/etcd/variables.tf\r\nx tectonic/modules/bootkube/assets.tf\r\nx tectonic/modules/bootkube/assets_tls.tf\r\nx tectonic/modules/bootkube/outputs.tf\r\nx tectonic/modules/bootkube/resources/\r\nx tectonic/modules/bootkube/variables.tf\r\nx tectonic/modules/bootkube/resources/bootkube.service\r\nx tectonic/modules/bootkube/resources/bootkube.sh\r\nx tectonic/modules/bootkube/resources/bootstrap-manifests/\r\nx tectonic/modules/bootkube/resources/experimental/\r\nx tectonic/modules/bootkube/resources/kubeconfig\r\nx tectonic/modules/bootkube/resources/manifests/\r\nx tectonic/modules/bootkube/resources/tectonic/\r\nx tectonic/modules/bootkube/resources/tls/\r\nx tectonic/modules/bootkube/resources/tectonic/console/\r\nx tectonic/modules/bootkube/resources/tectonic/heapster/\r\nx tectonic/modules/bootkube/resources/tectonic/identity/\r\nx tectonic/modules/bootkube/resources/tectonic/ingress/\r\nx tectonic/modules/bootkube/resources/tectonic/monitoring/\r\nx tectonic/modules/bootkube/resources/tectonic/rbac/\r\nx tectonic/modules/bootkube/resources/tectonic/secrets/\r\nx tectonic/modules/bootkube/resources/tectonic/updater/\r\nx tectonic/modules/bootkube/resources/tectonic/ingress/default-backend/\r\nx tectonic/modules/bootkube/resources/tectonic/ingress/hostport/\r\nx tectonic/modules/bootkube/resources/tectonic/ingress/nodeport/\r\nx tectonic/modules/bootkube/resources/manifests/kube-apiserver-secret.yaml\r\nx tectonic/modules/bootkube/resources/manifests/kube-apiserver.yaml\r\nx tectonic/modules/bootkube/resources/manifests/kube-controller-manager-disruption.yaml\r\nx tectonic/modules/bootkube/resources/manifests/kube-controller-manager-secret.yaml\r\nx tectonic/modules/bootkube/resources/manifests/kube-controller-manager.yaml\r\nx tectonic/modules/bootkube/resources/manifests/kube-dns.yaml\r\nx tectonic/modules/bootkube/resources/manifests/kube-flannel.yaml\r\nx tectonic/modules/bootkube/resources/manifests/kube-proxy.yaml\r\nx tectonic/modules/bootkube/resources/manifests/kube-scheduler-disruption.yaml\r\nx tectonic/modules/bootkube/resources/manifests/kube-scheduler.yaml\r\nx tectonic/modules/bootkube/resources/manifests/kube-system-rbac-role-binding.yaml\r\nx tectonic/modules/bootkube/resources/manifests/pod-checkpointer.yaml\r\nx tectonic/modules/bootkube/resources/experimental/bootstrap-manifests/\r\nx tectonic/modules/bootkube/resources/experimental/etcd/\r\nx tectonic/modules/bootkube/resources/experimental/manifests/\r\nx tectonic/modules/bootkube/resources/experimental/manifests/etcd-operator.yaml\r\nx tectonic/modules/bootkube/resources/experimental/manifests/etcd-service.yaml\r\nx tectonic/modules/bootkube/resources/experimental/manifests/kenc.yaml\r\nx tectonic/modules/bootkube/resources/experimental/etcd/bootstrap-etcd-service.json\r\nx tectonic/modules/bootkube/resources/experimental/etcd/migrate-etcd-cluster.json\r\nx tectonic/modules/bootkube/resources/experimental/bootstrap-manifests/bootstrap-etcd.yaml\r\nx tectonic/modules/bootkube/resources/bootstrap-manifests/bootstrap-apiserver.yaml\r\nx tectonic/modules/bootkube/resources/bootstrap-manifests/bootstrap-controller-manager.yaml\r\nx tectonic/modules/bootkube/resources/bootstrap-manifests/bootstrap-scheduler.yaml\r\nx tectonic/modules/azure/dns/\r\nx tectonic/modules/azure/etcd/\r\nx tectonic/modules/azure/master/\r\nx tectonic/modules/azure/resource-group/\r\nx tectonic/modules/azure/vnet/\r\nx tectonic/modules/azure/worker/\r\nx tectonic/modules/azure/worker/ignition-worker.tf\r\nx tectonic/modules/azure/worker/resources/\r\nx tectonic/modules/azure/worker/variables.tf\r\nx tectonic/modules/azure/worker/workers.tf\r\nx tectonic/modules/azure/worker/resources/worker-kubelet.service\r\nx tectonic/modules/azure/vnet/outputs.tf\r\nx tectonic/modules/azure/vnet/security-groups.tf\r\nx tectonic/modules/azure/vnet/variables.tf\r\nx tectonic/modules/azure/vnet/virtualnet.tf\r\nx tectonic/modules/azure/resource-group/rsg.tf\r\nx tectonic/modules/azure/master/api-lb.tf\r\nx tectonic/modules/azure/master/console-lb.tf\r\nx tectonic/modules/azure/master/ignition-master.tf\r\nx tectonic/modules/azure/master/lb.tf\r\nx tectonic/modules/azure/master/master.tf\r\nx tectonic/modules/azure/master/output.tf\r\nx tectonic/modules/azure/master/resources/\r\nx tectonic/modules/azure/master/variables.tf\r\nx tectonic/modules/azure/master/resources/master-kubelet.service\r\nx tectonic/modules/azure/etcd/etcd.tf\r\nx tectonic/modules/azure/etcd/ignition.tf\r\nx tectonic/modules/azure/etcd/lb.tf\r\nx tectonic/modules/azure/etcd/network.tf\r\nx tectonic/modules/azure/etcd/output.tf\r\nx tectonic/modules/azure/etcd/variables.tf\r\nx tectonic/modules/azure/dns/etcd.tf\r\nx tectonic/modules/azure/dns/main.tf\r\nx tectonic/modules/azure/dns/master.tf\r\nx tectonic/modules/azure/dns/outputs.tf\r\nx tectonic/modules/azure/dns/variables.tf\r\nx tectonic/modules/aws/etcd/\r\nx tectonic/modules/aws/ignition/\r\nx tectonic/modules/aws/master-asg/\r\nx tectonic/modules/aws/vpc/\r\nx tectonic/modules/aws/worker-asg/\r\nx tectonic/modules/aws/worker-asg/variables.tf\r\nx tectonic/modules/aws/worker-asg/worker.tf\r\nx tectonic/modules/aws/vpc/existing-vpc.tf\r\nx tectonic/modules/aws/vpc/outputs.tf\r\nx tectonic/modules/aws/vpc/sg-elb.tf\r\nx tectonic/modules/aws/vpc/sg-etcd.tf\r\nx tectonic/modules/aws/vpc/sg-master.tf\r\nx tectonic/modules/aws/vpc/sg-worker.tf\r\nx tectonic/modules/aws/vpc/variables.tf\r\nx tectonic/modules/aws/vpc/vpc-private.tf\r\nx tectonic/modules/aws/vpc/vpc-public.tf\r\nx tectonic/modules/aws/vpc/vpc.tf\r\nx tectonic/modules/aws/master-asg/elb.tf\r\nx tectonic/modules/aws/master-asg/master.tf\r\nx tectonic/modules/aws/master-asg/outputs.tf\r\nx tectonic/modules/aws/master-asg/variables.tf\r\nx tectonic/modules/aws/ignition/ignition.tf\r\nx tectonic/modules/aws/ignition/outputs.tf\r\nx tectonic/modules/aws/ignition/resources/\r\nx tectonic/modules/aws/ignition/variables.tf\r\nx tectonic/modules/aws/ignition/resources/detect-master.sh\r\nx tectonic/modules/aws/ignition/resources/init-assets.sh\r\nx tectonic/modules/aws/ignition/resources/s3-puller.sh\r\nx tectonic/modules/aws/ignition/resources/services/\r\nx tectonic/modules/aws/ignition/resources/services/init-assets.service\r\nx tectonic/modules/aws/ignition/resources/services/kubelet-env.service\r\nx tectonic/modules/aws/ignition/resources/services/kubelet.service\r\nx tectonic/modules/aws/etcd/dns.tf\r\nx tectonic/modules/aws/etcd/ignition.tf\r\nx tectonic/modules/aws/etcd/nodes.tf\r\nx tectonic/modules/aws/etcd/outputs.tf\r\nx tectonic/modules/aws/etcd/variables.tf\r\nx tectonic/examples/terraform.tfvars.aws\r\nx tectonic/examples/terraform.tfvars.azure\r\nx tectonic/examples/terraform.tfvars.metal\r\nx tectonic/examples/terraform.tfvars.openstack-neutron\r\nx tectonic/examples/terraform.tfvars.openstack-nova\r\nx tectonic/examples/terraform.tfvars.vmware```\r\n\r\nAs you can see, we do not include `.` anymore."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/963", "comments": ["Won't this only be true if one builds a release of an old tag? eg: If I build v1.6.4 today, `GIT_TAG` and `GIT_LATEST_TAG` will both be v1.6.4 in the generated js. If someone tags a new release later, the js in the installer binary isn't going to change.\r\n\r\nIs one of the requirements that it checks for new versions when run?", "Ah, yes. You are right, I tested this locally by rebasing off of older tag, but this will not work for generated js. Probably need an external API to provide the latest version then?", "Yeah. I don't think that should block this PR.", "How do you feel about scraping the latest version from the http://coreos.com/tectonic/releases/?", "There's probably some programmatic way to get it from github. eg, a machine-readable version of https://github.com/coreos/tectonic-installer/releases"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/962", "comments": ["I don't love that the etcd-operator writes to $HOME/.aws, but if that's an unavoidable side-effect of using AWS then so be it."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/957", "comments": ["does a cluster-wide account have a namespace?", "s/desired//", "subject will have namespace. plz see the image.", "I don't think any of these are prerequisites. Service accounts are another form of authentication. You don't have to know about how we do auth through dex to work with service accounts.", "The subject, the service account, does.", "Instead of:\r\n\r\n> For example, when an `ngnix` service running on a pod uses `kubectl` to communicate with Kubernetes APIs, it's credentials are loaded automatically for authentication.\r\n\r\nI'd suggest:\r\n\r\n> For example, when an ingress controller running in cluster needs to read ingress resources, it loads service account secrets mounted into the pod at well known locations to authenticate with the API server.\r\n\r\nAlso maybe eliminate the \"It's similar to\" sentence or sharpen it to talk about bearer tokens? I don't think it adds much.", "> Given is an example service account for ingress.\r\n\r\nThink that's a typo.", "Don't think this title makes sense. \"a namespace service account\" sounds like you're provision a single service account for a namespace. Maybe \"Granting roles to a service account\"?", "This isn't the full set of powers an ingress controller needs. Do we need one? I know @robszumski put one together a while back.", "Pretty much all namespaces have multiple pods. I'd like to stress this as a best practice. e.g. \"only use the default service account if you have to\"", "nit: Can we change this to use a unique service account?", "nit: add a comment inline to call out this field as something the reader should focus on"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/956", "comments": ["I don't like this, but I want to get at clusterConfig data in error rendering. Other ideas welcome."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/947", "comments": ["this could end up in an endless loop. I suggest to include a max-retry break, maybe similar to https://github.com/coreos/tectonic-installer/blob/2bede2c/modules/tectonic/resources/tectonic.sh#L23?", "Also, does it make sense to sleep before the continue?", "Neat improvement!\r\nBut +1 on both the max-retry and sleep.\r\nIt is dangerous without a way out of the loop.", "An endless loop is exactly the point. If detect-master fails, it's never restarted (because init-assets service is a oneshot). No node will think it's the first master and the cluster will never come up.", "But is there a point in hammering the AWS API and getting that account blacklisted with throttling if the failure can't be recovered from within N retries?", "This amounts to 1/4 req/s.  ", "I think Alex made that comment before I added the sleep to the continue logic."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/946", "comments": ["This will now potentially loop forever. I have doubts this is really what we want to achieve. Why not bumping `i` to a higher value?", "If this script exits early, the cluster won't come up. So in this case, waiting forever seems like a reasonable thing to do. It allows for users on slower connections to bring up clusters.", "We could move the slow / flaky / less critical resources to the bottom. Thus, we'd create most of the cluster regardless (console, ingress, ...). Then we can wait forever or what, it'd matter less.", "Order of resource creation seems orthogonal to this PR. There is no case in which waiting indefinitely would cause cluster bringup to fail that wouldn't also cause the old code to fail. In short: this change strictly dominates."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/940", "comments": ["Why not use a newer version of go? 1.8.3 just shipped.", "?", "Yes, thanks for the hint.", "This is still a *work in progress*. I had to create the PR in order to be able to run this on our Jenkins. Sorry for the noise.\r\n\r\nThis is commented out for now to run it on this `mxinden:build-docker-image` branch as well.", "why use a different image here? You can just reuse the builder image, it is based off of `golang`", "This is repeated in a lot of places. Is there any way to make this a variable that can be reused?", "Would be nice if we could reuse the logic in `make release` https://github.com/coreos/tectonic-installer/blob/master/installer/Makefile#L77 instead of repeating it all here.", "Yeah, I am not sure of this either.", "When I commented on the issue initially, I pretty much wanted to use the release scripts as well, as much as possible (so it can be used for nightly builds).", "@sym3tri @Quentin-M I thought of running each step in its own Docker image with the least amount of dependencies in it as possible, instead of running each step with the same Docker image, where dependencies are getting a little messy. I find this cleaner and easier to reason about. I am fine with changing this back to using the `tectonic-builder` image. Whatever you prefer?", "We could probably move the `tectonic-builder` image url to a variable?", "Sounds like a good idea. If you don't mind I would just open a new issue for that, so we can fix it in a separate PR. What do you think?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/937", "comments": ["By removing both the tectonic and bootkube service we are disabling the functionality to install a vanilla k8s cluster.", "Why is the bootkube service actually removed?", "This will always restart the service, also when it exits successfully, see https://www.freedesktop.org/software/systemd/man/systemd.service.html#Restart=, effectively busy-looping after installation. The only thing preventing it from busy-looping is the ConditionPathExists which seems like a fragile construct to me.\r\n\r\nI strongly suggest to set `Restart=on-failure`. This will not potentially busy-loop, if the scripts exits with 0.", "Hmm, indeed `Type=oneshot` does not work with `Restart`, that's a bummer. There is a corresponding upstream issue: https://github.com/systemd/systemd/issues/2582", "This raised my eyebrows, but is also the effective setting when `Type=oneshot`.", "ok", "The ExecStartPres timeout otherwise.", "Yes, but why is that a feature we support in the *tectonic installer*?", "It was requested in https://github.com/coreos/tectonic-installer/issues/133 and this feature is currently used by the Prometheus team in their CI pipeline on AWS to test operator versions.", "Thanks for the link."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/930", "comments": ["s/cloud providers/platforms/\r\n\r\nNot all are \"cloud\"", "Consider adding a `...` to indicate all future platforms should go here too", "Maybe explicitly call this out as the \"_Installer_ user interface\" to avoid confusion with Console.", "where is this file?", "where did this logic go?", "this logic is in common.sh https://github.com/coreos/tectonic-installer/pull/930/files#diff-96cc1c7bce85cf8467a5311279f454ccR14", "thanks, I switched between the two a couple of times. I'll revert to \"platforms\".", "I see, thanks! I did not notice the weird rename `test/scripts/aws-destroy.sh \u2192 tests/smoke/aws/common.sh`."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/899", "comments": ["s/name/the name/\r\n", "Do not break sentences onto separate lines when you intend them to render as a paragraph.", "the complex formatting of this list breaks it in rendering:\r\n<img width=\"971\" alt=\"screen shot 2017-05-26 at 12 04 56 pm\" src=\"https://cloud.githubusercontent.com/assets/72905/26508982/96829f20-420b-11e7-8f34-35f64a434f26.png\">\r\n", "fix the link definition at bottom to target \"identity-management.md#default-roles-in-tectonic\" so that this link makes sense."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/895", "comments": ["What's the purpose of a prefix? Why not just name the cluster with the prefix you want?", "@sym3tri I think this could be useful for instances where a customer decides to use the prefix for some alternate purpose, like establishing cost centers.\r\n\r\nSay a cluster is named `team-x-tec-prod01` with the cost center being tied to `team-x`.\r\n`tectonic_cluster_name = \"team-x-tec-prod01\"` would not be sufficient to uniquely identify the cost center, without some variable magic that would be specific to a customer's env / naming conventions.\r\n\r\nHaving `tectonic_cluster_prefix = \"team-x\"`, `tectonic_cluster_name = \"tec-prod01\"` would allow us to use the prefix as a tag for resources and thus uniquely define that cost center.", "@sym3tri thoughts?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/892", "comments": ["Can you try using if conditions to ensure these lines don't even get added unless the user chooses to use them? I know the effect is the same, but this seems cluttered atm and I worry the complexity will lead to mistakes.", "proto -> protocol", "opts -> options", "done", "done", "done", "I've noticed this complicates things in a lot of places. Between line continuations and terraform templating not supporting conditional blocks, it's really a lot cleaner to just have the default value for `rkt_insecure_options=none` and template it in regardless. ", "Imagine implementing these conditionals in /modules/aws/etcd/ignition.tf to set `RKT_RUN_ARGS` for `etcd.service` - I don't even think it would be possible. On side note, that platform is going to be next to support these configuration directives.", "@s-urbaniak I'll trade you another hint then! This will unfortunately break with kube-version-operator updates :( the `/etc/kubernetes/kubelet.env` file is the coordination point for updating the kubelet version). "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/884", "comments": ["you can drop the inner id"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/872", "comments": ["\"For example, the `view` Cluster Role referred to in the following Role Binding grants the permission to view but not change objects in the `kube-system` namespace.\" \r\n\r\nalso remove line break - this sentence should be part of first graf", "s/or a/or to a/\r\nsecond sentence: \"Administrators have full control over all resources within their cluster or namespace.\"", "s/an user/a user/\r\ns/the Tectonic Console/Tectonic Console/", "reference a desired Role Binding? Or reference a desired [Cluster] Role?", "First sentence: \"Grant access rights to an administrator by associating an appropriate Cluster Role with a Cluster Role Binding.\"\r\nSecond sentence: \"Use the default *cluster-admin* role for cluster administration.\"", "Is this part of the above graf or a second paragraph? (fix line break and/or extra spaces between line 22 and 23)", "1) consistent capitalization of Cluster Role Binding and other proper names\r\n2) Choose either *italics* or `mono` type for these role and binding names (see conflict between line 22 and 23)", "no newline needed", "According to line 22-23, namespace is omitted because this is cluster-wide. Should step 6 be here?", "\"To assign a namespace administrator, use one of the default Cluster or Namespace Roles, or create a new role for the selected Namespace. Bind the role to an appropriate Role Binding.\"", "\"While a Cluster Role can be bound down the hierarchy to a Namespace Role Binding, a Namespace Role can't be promoted up the hierarchy to be bound to a Cluster Role Binding.\"", "You definitely do _not_ need \"Note:\" for this.", "that's a mistake - forgot to remove. I am deleting it.", "so \"...and bind to the new role.\" ?", "It'll be nice if we can change the User name to a specific name other than \"view\" to highlight this field could be a real user name. (e.g. In k8s upstream doc, they use \"**jane**\" or \"**dave**\" as the sample user name.)\r\n\r\n<img width=\"649\" alt=\"screen shot 2017-05-26 at 10 53 27 am\" src=\"https://cloud.githubusercontent.com/assets/5903705/26506518/caab7740-4201-11e7-9b2e-ac3a95250cf7.png\">\r\n<img width=\"644\" alt=\"screen shot 2017-05-26 at 10 53 48 am\" src=\"https://cloud.githubusercontent.com/assets/5903705/26506521/ce3b02c2-4201-11e7-9d68-adedf366faf2.png\">\r\n\r\n\r\n"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/870", "comments": ["Minor thing, but I think you can get the same result with `autoFocus={!!autoFocus}` (coercing it to bool).", "\ud83d\udc4d", "Why check if length is > 1? You can have 0 tags and click \"add more\":\r\n\r\n![screen shot 2017-05-25 at 13 37 56](https://cloud.githubusercontent.com/assets/200121/26469585/6701a7ee-414f-11e7-9b6e-129254ce5db8.png)\r\n\r\nIn that case, the new tag input isn't auto-focused.\r\n", "Fixed"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/862", "comments": ["What happens if the first sh throws?", "Is  it cromulent to run multiple tfs in the same dir at the same time?", "You can scale this down to 1 or 2. There's no need for 4 nodes.", "This has no effect when using self-hosted etcd right? If not please remove.", "necessary?", "While your at it can you please provide a test CA to ensure the \"provide your own CA\" path works too?", "Seems weird having 2 side-by-side. Only 1 will ever be valid.", "Maybe we should exec the destroy in each block above after the apply steps? Then this would be the \"catch all\" in case that one fails. If the first one succeeds I think it'll just be a noop.", "it's completely fine but only because they are NOT running in the same dir. They have different build dirs. The build dirs use the vars file name in the directory name see https://github.com/squat/tectonic-installer/blob/44ef854eb4373c897b4d179be331719be6a892e7/test/scripts/aws#L7", "Having two destroys is required in order to delete the different clusters that would be launched by the different `applys`. the destroy script uses the var file name to generate the build dir name so each invocation will destroy a different cluster.", "I can add a CA though, though this should really be a separate test in the matrix.", "In an ideal world yes, but we can't boot test clusters for ever possible permutation. I just want to increase our coverage with the fewest number of test files.", "platform is special & used elsehwere", "BRANCH_NAME should just be PR number due to char constraints", "+1", "Just checked and apparently `BRANCH_NAME` evaluates to `pr-862` in this case, so it seems to be the pull request name. To shorten this cluster name, I'm setting it to be `${TEST_NAME}-${BRANCH_NAME}-{BUILD_ID}` so it may be `aws-exp-pr-862-10`. This should work for the time being.", "Don't forget to optionally bail after plan. I don't want to run this on every PR until we're more confident our resource limits can handle it."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/855", "comments": ["Is this an intrusive change for existing users? I have to write a migration for this in the KVO.", "not an intrusive change. access to the console is handled by the ingress resource, which forwards requests to the console service.", "closing in favor of #854 "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/845", "comments": ["`[label]: destination.md`\r\nspace after colon\r\nthroughout", "\"Add a user\"\r\n\"Add an administrator\"\r\n\"Add a team\"\r\n\"Add a service account\"", "space after colon", "spacing", "spacing after colon, throughout", "spacing", "spacing"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/842", "comments": ["`scenarios` (no s on the end)", "is this really an \"and\" or is it \"or\"?\r\n\r\ndoes this present the same to the end user/admin either way?", "maybe mention that we run multiple", "to keep the progression going, would this be `Higher risk to clients...`", "in line with above, `Highest risk if ...`", "found this confusing. is it basically saying that \"if dex is down, dex is down\"?", "add `$`, remove newline below", "on github you can link to the relative path", "API server actually only talks to /.well-known and /keys. e.g. if the token or auth endpoints fail the API server will be fine.", "We also might want to note that we should increase the number of dex instances deployed. That would mean we could aim for zero downtime from misbehaving dex instances (not storage failures).\r\n\r\nMaybe a \"future improvements\" section?", "Maybe \"dex will be unable to authenticate new users or refresh existing credentials\"?", "Nit: the answer part does not render on a new line.", "same"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/823", "comments": ["Just curious, but do we know what shell `sh` runs? Some of these scripts (like on line 36) have shebangs for `/bin/bash`. They might be using a different shell than steps without shebangs.", "pretty sure it's straight `sh`", "You need single quotes here, not double quotes.", "grr we need to be more consistent across this file"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/817", "comments": ["what about this doc? https://github.com/coreos/tectonic-installer/blob/master/Documentation/admin/aws-scale.md", "aw - I forgot about that one. @joshix asked that it be deleted as part of this PR, as it describes the old way to delete, and not the new. please confirm, and I will delete it.", "The benefit of having a stable link to it would be for support, etc to be able to easily send it out. If we kept it, move this content there any maybe add a short intro to how terraform stores state and how you end up using it to scale up?", "Is it worth having a separate doc, rather than adding an anchor to aws-terraform.md? Is there that much call for that information? It will be weird, going forward, to have an aws-scale doc, and not a metal-scale, azure-scale, and etc. It's also a little weird to have so little info on its own page. I think it makes more sense to show how easy and quick it is to use the product to scale, delete, spin up, and etc. all on a single page. \r\n\r\nI think add a sentence on how Terraform stores state to the other doc(s), and delete aws-scale.\r\n\r\nBut I could be wrong.", "My personal opinion is that those other guides need to exist. Scaling on VMware or bare metal is very different than how it works for the clouds.", "yes, but how much descriptive text will be involved? is it so different that it's more than 6 or 8 lines? does it merit its own page?", "it can't be platforms/azure", "this PR was only to edit the scaling information - nice catch on the inaccurate destroy info. What should it be for terraform destroy for Azure?", "one would need to at least power on machines before getting here, right? In other words, have you been able to test or confer with someone on how this works on metal? ", "This comment is just on the wrong file, beth. My mistake. Disregard", "what about this much more complete file: https://coreos.com/tectonic/docs/latest/install/aws/uninstall.html ?", "See https://github.com/coreos/tectonic-installer/pull/817#discussion_r118329256 for the question that still stands: Should the delete section in aws-terraform be removed in favor of a link to the more complete delete procedure in install/aws/uninstall?", "also need to grow `tectonic_metal_worker_macs`, `tectonic_metal_worker_domains`, `tectonic_metal_worker_names` variables", "(aleks's comment applied to metal-terraform rather than aws)", "Rob and I decided to try to land this page, and open a separate issue to review the scaling docs - https://github.com/coreos/tectonic-installer/issues/834\r\n", "I think this comment duplicates that below - in that we should review and consider 'uninstall' (destroy) docs for all terraform platforms.", "the aws/uninstall.md instructions were accurate when I last QA'd them. I suggest that, like the scaling information, I open an issue to review the destroy docs separately from this PR. \r\n\r\nhttps://github.com/coreos/tectonic-installer/issues/908", "I think the 'power on' bit is implicit in the previous step, where Tectonic Console was up and running, isn't it? or am I missing your point? We ran the GUI installer process yesterday. I can compare those instructions to these, and see if it should be called out more explicitly.", "https://github.com/coreos/tectonic-installer/issues/908#issuecomment-304389684", "so the closing step of this advice would be something like \"run `terraform apply` then power on the new nodes\", perhaps linking to the anchor for the Power On step above?", "aside from the \"future projects review for adding uninstall to other platforms, is the more immediate question of just using the information you have for the two current plaftorms, aws and bare metal:  https://github.com/coreos/tectonic-installer/issues/908#issuecomment-304389684", "but you don't have to 'power on new nodes' for the other platforms?", "addressed.", "... and then \"set cluster nodes to boot from your previous, standard PXE image...\" ? "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/816", "comments": ["Since you no longer use props.updater, you should drop the call to connect.", "Oh, you are right, I saw line 14 and thought it was still getting used."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/813", "comments": ["n.b. I had to add this because the console listens on port 80. See: #847 ", "Nevermind, this didn't work. I backed out the console change for this release."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/810", "comments": ["which uses the [dex open source project] ... This issue may be related to ...", "question - if this AND that are true? or if this OR that is true?\r\n\r\nThis happens only if the following two conditions are true:\r\n\r\nor \r\n\r\nThis may happen if one of the following two conditions is true:", "change 'Background' to 'Issue'", "Issues will be marked 'resolved' and listed in the release notes when appropriate.", "remove blank line.", "change 'Resolution' to 'Workaround'", "maybe 'Running multiple Terraform commands with etcd' ?", "I think if you're going to include a 'Known Issues' section you should link to anchors in the known-issues.md doc.\r\n\r\nadd\r\n\r\nRunning multiple Terraform commands with etcd\r\n\r\n", "This doesn't have anything to do with etcd, it just presents itself when you deploy etcd in this way.", "its an AND", "The this links to it under \"more info\". Did you mean to link the \"known issues\" header to the page?", "you added the one topic, but not the other.", "Issues deploying etcd with multiple Terraform commands? \r\n\r\nThe title implies that it's any instance of running multiple Terraform commands - I think the title should be more focused.", "then the former - This happens only if the following two conditions are true:", "The long version of the title is this, how would you shorten it?\r\n\r\n```\r\nIf you deployed etcd in a certain way you will encounter seemingly unrelated issues with running Terraform commands, only after the first instantiation, regardless of whether or not you are mutating anything related to etcd\r\n```", "crazy. ok. maybe try something even more ambiguous:\r\n\r\nRunning Terraform with previously deployed etcd  ?\r\n\r\nI just think it should be clear that it's not a Terraform issue, it's a Terraform + etcd issue.", "Why was this section removed entirely? It should just go below the latest one.", "No longer needed in our planned release of 1.6.4", "Instead users should download the official terraform 0.9.6 release.\r\nhttps://releases.hashicorp.com/terraform/0.9.6/"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/808", "comments": ["Note that this will ignore all files or directories named \"generated\", including vendored stuff. You probably want to use `/generated/`."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/807", "comments": ["I think @kans is refering to this spot. Should also use \"-\" instead of \"_'.", "Same here."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/796", "comments": ["Services of type `oneshot` cannot restart. This is only valid for `simple`, `forking` etc"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/793", "comments": ["# Running Kubernetes API server from etcd snapshot", "First, locate the `member/snap/db` file, which is a backup of the etcd data directory. This file is usually stored in `/var/etcd`, `/var/lib/etcd`, or a backup server. Then, use this file to generate a new data-dir that can be run locally.", "First, use etcdctl to create a copy of your data directory."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/792", "comments": ["alignment for the structure-check test", "can run `terraform fmt`", "same here", "is there a way we can squash by using `template_dir` instead? In other words, templating the whole folder (recursively if needed) rather than individual files. ", "we have something in bootkube.sh that moves manifests for them to be used or not. i'd like to see the less template_file/local_file as possible."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/790", "comments": ["\"...to troubleshoot at the host level.\"", "These should be reference links as specified in the style guide"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/789", "comments": ["Technically not an \"installer upgrade\", it is a \"cluster upgrade\".", "...may result in inability to perform a cluster upgrade.", "... _may_ prevent cluster control plane components from functioning.", "... may result in the inability to start pods or failed communcation between cluster components.", "@sym3tri - which are one or two Container Linux channels that people are most likely to want to modify?", "Stable is default. So stable->beta or stable->alpha.", "ah - thank you.", "Should we have a 3rd section detailing infrastructure changes?\r\nThings to highlight there would be the likes of:\r\n\r\nNever safe to modify (could lead to invalid clusters):\r\n- security group modifications\r\n- IAM role permissions modifications\r\n- EC2 block device mapping\r\n- EC2 AMIs\r\n\r\n", "We have syntax checks on the terraform templates which will fail the PR checker for non-standard formatted code.\r\nWe should also mention the `terraform fmt` command to align the template syntax.", "Don't we have PRs in flight that are all about IAM changes/BYO?", "also maybe links to terraform docs and terraform examples? https://github.com/s-urbaniak/terraform-examples etc", "Perhaps revise to `IAM role permissions must meet and exceed documented requirements` ?", "questions: 1) these are all specific to AWS, correct? If so, this info maybe goes under AWS, rather than here with generic information. 2) We should list 'Always safe to modify - for consistency. 3) if IAM role permissions must exceed doc'd requirements, we should link out to that information. I don't think it's explicitly called out here: https://coreos.com/tectonic/docs/latest/tutorials/creating-aws.html", "@alexsomesan can you give me the specific line for the `terraform fmt` command, please? is it simply 'Use `terraform fmt` to align the template syntax.'? (and I'll link to https://www.terraform.io/docs/commands/fmt.html)", "we should make it more generic to fit all clouds but reference the terms `eg. AWS IAM and Azure blah`", "linking out is a great idea", "I've been running `make structure-check`, which identifies files that doesn't meet the canonical format and style and let's me know to run `terraform fmt .` in the folder. \r\nI usually also run `make docs examples` to auto generate examples and variables files"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/788", "comments": ["This mixing of snake and camel case is a little funny", "is this used?", "You don't need this `else`.", "This goes away if you remove the `else` in clusterconfig."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/785", "comments": ["Just so we're super clear with customers, is this an IAM role name? or an ID?", "We use the policy ID when we have to customize our installer: \r\nhere as mine: doesn't create either.. and just requires the \r\n```\r\narn:aws:iam::982404467199:instance-profile/demo-cluster-master-profile\r\n```", "@everydaynerd Appreciate your input here.\r\n\r\nI've been torn about what is the easiest input to request from users in this case. \r\nSeemed to me like *role* is the concept users might be most accustomed to, whereas instance profiles are immutable and usually just a \"shadow copy\" of said role in EC2.\r\nSo in that sense, asking the user for a role made the most sense to me. That way they don't have to struggle with the difference between a role and instance profile and we just create the instance profile for them.\r\n\r\nI'd appreciate your POV on this convention, from the perspective of a user.", "@robszumski \r\nThat is certainly a **role name**, as per the IAM API's apparent preference for using \"names\" as identifiers (as opposed to ARNs or IDs).\r\nSee my comment above about the convention we're proposing to users with this change.", "My suggestion is to emphasize this is being a role name in the description and also give an example.", "Same comment as above: I would emphasize this is a role name including an example."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/780", "comments": ["Why the change appears in this PR?", "I removed merge commits on this branch similar to one on bootkube (I wasn't rebasing\r\n from upstream)", "nit: might want to make the file name more explicit, e.g. `aws-experimental-networkpolicy.tfvars`", "@abhinavdahiya We usually do rebase on the upstream master to fix the conflicts instead of merging, that will keep your commit history clean.", "what about the other platforms (metal, openstack, azure, vmware)?", "Shouldn't be any different for other platforms too. I will have to add similar options to other platforms too as this support requires change to kubelet service.", "yes. please rebase from master", "should probably not be \"debug\" for production.", "In comments can you please explain what this is doing & link to docs about the config file?", "Also comment on when this should change.", "Should probably be templated in.", "Add comment that links to docs on these flags", "While you're in here, this needs to be templateable. And it should defafult to a mirror on quay.io/coreos", "> And it should defafult to a mirror on quay.io/coreos\r\nCouldn't find an alpine mirror in quay.io/coreos ???\r\n", "Also commented on bootkube PR - but this makes me nervous and I would think we need to ship a container image with the release binaries instead (and this side-car simply copies files from container image to host mount)", "nit: do we actually want this to be configurable? If this was changed then for this to work the deployer would also need to know that they may need to add a new mount to the kubelet.service. Given that in most cases a change to this value won't work - i'd lean toward just removing the option.", "In our \"default\" case (calico is not installed) this gets set to an empty string, and will just have the line continuation - if possible I'd prefer that our default case doesn't necessarily change the rendering of the kubelet unit.", "Wouldn't this just be set to `/var/lib/cni/bin` but have no flag prefix?", "Hmm, never mind - it looks like in the `platforms/metal` case this is set to the full flag (but looks like in other cases that is expected to be `cni_bin_dir`?", "Maybe we add something like:\r\n\r\n> Enabling an alpha feature means that future updates may become unsupported. This should only be enabled on clusters that are meant to be short-lived to begin validating the alpha feature.\r\n\r\n/cc @robszumski ", "I'm a little unclear on the use of `cni_bin_dir` vs `kubelet_cni_bin_dir`.\r\n\r\nIt looks like `cni_bin_dir` is actually the full flag+ path (a night might be to rename to something like `cni_bin_dir_flag` =)\r\n\r\nThen if I'm reading correctly, `kubelet_cni_bin_dir` is a bit inconsistent (mostly just path, but sometimes flag+path).", "Sure", "just followed how `node_taints_param` gets handled in master and worker kubelet.sevice file.", "I was just trying to keep the convention used for `node_taints` and `kubelet_node_taints`.", "all the platforms eg. `platform/aws` use `kubelet_cni_bin_dir` to define the path and the corresponding module eg. `modules/aws/ignition` use `cni_bin_dir` to parse dir path to flag for kubelet.service file.\r\n\r\nbut `platform/metal` has all its code in `plaftorm/` dir, hence this inconsistency ...", "sgtm", "Hm, I'm curious why this has to be specified now. We already deploy cni binaries via the Flannel daemonset, and that expects a specific path...", "@squeed  The flannel daemonset https://github.com/coreos/tectonic-installer/commit/db6839a0b5cebff1b04fc3ce152e1130ab5e43da installs the cni binaries to /opt/cni/bin on host (which @philips suggested we change to /var/lib/cni/bin)\r\n\r\nBut the kubelet by default expects the cni binaries to be present in /opt/cni/bin unless you provide --cni-bin-dir flag.", "So, will we be in trouble if this is set? Or is the flannel daemonset consuming this flag somehow? (Sorry, not super familiar with the whole terraform setup). If it works, I'm happy to believe you. Just making sure.", "Of course, the kubelet will successfully start even if it can't find the CNI binaries - it will just fail to launch pods that don't use host networking.", "flannel doesn't actually care where the CNI binaries end up (to my knowledge). Only the kubelet does. So we're essentially supporting two modes here:\r\n\r\n- Existing setup where flannel CNI binaries are expected to exist in the hyperkube container filesystem. The kubelet will look for them in the default location (/opt/cni/bin) in the hyperkube filesystem. The flannel daemonset will also copy CNI binaries into /var/lib/cni/bin on the host (exposed to the daemonset via /host/opt/bin/cni mountpoint). However these CNI binaries just sit there and are unused.\r\n\r\n- \"new\" / with calico setup: kubelet will set cni bin dir to /var/lib/cni/bin (this dir was used because it is already mounted from the host into kubelet via kubelet-wrapper). Then the flannel/calico daemonsets will copy their CNI binaries to that location and the kubelet will actually make use of them.\r\n\r\nIn both cases the flannel daemonset can be deployed the same. The only difference should be the addition of a flag on kubelet, and the addition of the calico assets.\r\n\r\n@abhinavdahiya does all of the above sound right?", "@abhinavdahiya can we add that description (or something like it) here?", "Also not sure if it's better to have that here, or in the tfvars examples, or both", "ack", "ack", "I'd really prefer this wasn't necessary. This should be auto generated during CI runs. ", "Yup", "why is this change necessary?", "these seem to have trailing tabs.", "This can be one line.", "Nesting modules is something we avoided as of now due to the inability of terraform to optionally switch on/off modules and thus due to composability restrictions.\r\n\r\nI suggest we create top-level `modules/net/flannel-vxlan` and `modules/net/calico-network-policy` and leave the composition of those modules to the platforms (that's exactly their purpose).\r\n\r\nAdditionally by renaming `net/flannel` to `net/flannel-vxlan` we could introduce more backends like `net/flannel-hostgw` et al.", "`null_data_source`s are an undocumented feature of Terraform so we try to avoid it as much as we can, as we have been bitten by this. I see that this interpolation function is only used once, in the output. So I suggest to get rid of `null_data_source` here and use it in outputs directly.", "same here, I suggest to squash those lines.", "see comment above regarding `null_data_source`.", "Agreed, we'll follow up with this across all platforms.\r\n/cc @mxinden ", "@aaronlevy Good catch! This is tackled for azure once PR #1154 is merged, but is still missing on all other platforms.", "Created an issue for this. #1367", "This needs one more `../` since the platform for openstack has `neutron` in the path as well.", "This needs one more `../` since the platform for openstack has `neutron` in the path as well.", "@coreypobrien Fixed it. thanks for pointing that out!"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/779", "comments": ["On latest master of the tectonic-installer this is `v1.6.3`, but judging from how this is used later in this PR I think you can just omit the tag and use the variable without it and name it `prometheus_base` or something like that (naming is @s-urbaniak's call here).", "This change would be removed by the tectonic prometheus operator on the next reconcile loop so we can't do this today, the next release of the tectonic prometheus operator will allow this to be configurable though, then we can introduce this.", "effectively yes, we are just referencing the name. nevertheless I think it is ok to have it like this for the sake of consistency. We already have `tectonic_versions` (which I want to get rid off) which serves the opposite, declaring the versions. Sometimes we need only the former, sometimes the latter. My suggestion would be to declare the `name:version` tuple always.", "in my observations, this commit stacked on 1.6.1 release did have the end effect of allowing the prometheus pods to come up successfully and remain so for over an hour.", "@brancz we are attempting to use this image list in the field as a canonical manifest of all image dependencies required for an install. Either in `tectonic_versions` or here, all the image tags needs to be state explicitly in the tf file.", "@colhom I cannot 100% infer which setup you are referring to as k8s and Prometheus are in the same major/minor right now. But it doesn't really matter because this is touching a manifest which is automatically synced from a tectonic-prometheus-operator release and should not be edited manually. \r\n\r\nThis brings us back to the question we had on why we vendor everything deployed by tectonic-x-operators. Every week someone inevitably comes in and makes changes across those vendored YAMLs, which are overwritten again either at runtime or through our vendoring process.\r\nIf lucky, one of us sees it before it gets merged, but that often doesn't happen with time zone differences.\r\n\r\n@aaronlevy @yifan-gu I think we should revisit this decision and rather rely on the AppVersion task status fields to determine the initial rollout of a tectonic-x-operator-controlled sub-system succeeded.", "In general, we cannot have both \u2013 either we give control over sub-systems to tectonic-x-operators XOR we have tectonic-installer as the central registry where we pin versions and images for everything.\r\nThe vendoring approach we are taking right now somewhat works, but not as a two-way-binding that is often assumed. \r\n\r\nThat's not to say we don't want to allow customization of things such as the base image. That's actually one of the next things we'll work on but it has to happen through a tectonic-prometheus-operator feature and not tectonic-installer. At least if we are committed to that model.\r\nIt will happen through a configmap read by tectonic-prometheus-operator at runtime. That configmap can initially be assembled as part of the install process but can be mutated at runtime by cluster admins.", "@fabxc that seems like a good plan- I'm going to back out the monitoring stuff for now then. Do we have an issue to track adding the flags to the operator and templating in the terraform image strings?", "@fabxc I'm assuming that this flag is OK to leave in place?", "Unfortunately no =/ The prometheus-operator is also deployed by tectonic-prometheus-operator. So this has to go into its configuration as well.", "@fabxc\r\n\r\n> This brings us back to the question we had on why we vendor everything deployed by tectonic-x-operators\r\n\r\nI think revisiting this assumption is reasonable. Likely can still be on a per-operator basis, but in the case of monitoring I don't see any big issue that we assume the operator will roll out all sub-components - and the only thing that is \"vendored\" is the top-level operator.\r\n\r\n>  I think we should revisit this decision and rather rely on the AppVersion task status fields to determine the initial rollout of a tectonic-x-operator-controlled sub-system succeeded\r\n\r\nWe could do this - or we could punt on this as well and assume if the top-level operator has been installed, that is \"success\". I don't have immediate strong feelings here.", "@s-urbaniak I abbreviated this simply so the `terraform fmt` step did not pollute the entire diff for this block by re-indenting all the images. Makes rebase-ing to keep up with master more difficult, can un-abbreviate immediately prior to merge if desired.", "I suppose all the other plarforms need to be updated as well?", "I think that is ok, the abbreviated variables does not read badly.", "My plan initially was to do AWS and baremetal for now, with eventual support planned for the rest of the platforms at a subsequent PR.", "ack, ok. Please let's only ensure that the changes here are compatible with the other platforms, i.e. they still can be deployed.", "ack"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/766", "comments": ["I think @mxinden depends on this docker image for monitoring e2e testing.\r\nIs there any particular reason for deleting it?", "@alexsomesan I only depend on `https://quay.io/coreos/tectonic-builder` which I think is not build from this Dockerfile. I was planning to replace it (See #689).\r\n\r\nThanks for the notice!", "It's a little confusing that it `requires version 0.9.6`, but links `0.9.4`. I assume that's because `0.9.6` is not yet released upstream?", "Note that we are also about to extend tectonic-builder to be used for every single builds by the Makefile (local/jenkins/release).", "Good point, let me change the link to point to the main download page! Thanks."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/759", "comments": ["This doesn't make sense. You either delete the pod OR trigger a rolling update. Not both.", "Rolling upgrade is already present in the doc. I was confused with the defect description and thought we need both. I am closing this PR as this is not applicable. Please confirm."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/756", "comments": ["silly question: what is this magic date about?", "Amazon's terrible versioning scheme...", "What Rob said.\r\nIt's the date that particular IAM API version was released."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/751", "comments": ["See above \"DO NOT PLACE SECRETS IN USER-DATA\"", "Agreed, this is still WIP, but thanks a lot for pointing out the criticality in the context of baremetal.\r\n\r\nI believe in the case of baremetal the distribution of those can be accomplished the same way as with the kube secrets, namely scp'ing them to the master nodes, being the distribution method I was thinking about.", "These variables shouldn't be required for bare-metal", "What about always enabling TLS when self-hosted etcd is in use? I don't see a case where a user would opt not to use TLS and this adds another confusing variable. ", "Can you consider accepting the ca_cert rather than the path, which assumes a file is read from disk? Looking through the other variables in use in Tectonic, many of the _path variables probably need to go that way.", "Seems like the client (user writing terraform.tfvars, module users, or the GUI) would pick whether the use a \"${file(\"path\")}\" or provide the contents directly.", "Putting materials like certs inline in the tfvars is not a direction we want to go in.\r\n\r\nWe have to account for the fact that users, in real production environments, may want to use specialized tools to manage distribution of secrets (for example Vault + VaultFS).\r\nI can see how this issue may not be apartment during development, but we should be mindful about taking this flexibility away from production users.\r\n\r\n/cc: @coresolve might have more real-world input on this topic", "For real world usage, there needs to be a broader discussion about how Tectonic's generated assets can be cleanly split into non-secret infrastructure declarations (which get checked into infra repos) and secret generated files (which go into a secret store). For concerns like that, you may want to consider how the pure bootkube module does this by generating secrets into a target location (which works well for secret storage systems). https://github.com/coreos/matchbox/blob/master/examples/terraform/modules/bootkube/variables.tf#L60. This design powers several colocations and clouds using a declarative repo and separate secret store, no need to remind me about real-world usability :P\r\n\r\nA separate problem and followup is how to input user-define certificates (which come from a secret store) as variables.  I agree its a good idea to pull from a path, but I think that's done in the calling config, not in the module (context: this stuff is about to move to be a module).", "On second though, the distinction btw doing it in the module vs at the top level config will become much clearer once bare-metal is a module. Or chat with me in person. Feel free to use a path for now.", "You have a good point. /cc @sym3tri @robszumski whether we want to make this configurable at all.\r\n\r\nPS: This PR does not cover self-hosted etcd (using the operator in experimental) but the dedicated self-provisioned etcd use case (non-experimental).", "ah, right, good catch!", "Let's move this (very good!) discussion over to https://github.com/coreos/tectonic-installer/issues/710, being the umbrella issue for these questions.", "To add my 5 cents to the concrete implementation detail for this PR: In my very first iteration I indeed generated the certs as files in the bootkube module, but I was hitting the problem though that Terraform did not give me enough guarantees that this file was being fully generated before subsequent modules ran. I ran into race conditions constantly.\r\n\r\nThat was the main motivation to pass the cert content as internal TF state between modules which did not confuse TFs internal dependency resolution any more.", "Thanks for the clarification that this PR is for on-host etcd only.", "Here you copy files to /etc/ssl/etcd, but in the Container Linux config, a different path is used (e.g. `ETCD_CERT_FILE=/etc/ssl/certs/client.crt`). Am I missing something?", "Ah, nvm. Inside the etcd-wrapper script, ETCD_SSL_DIR is read to control the volume mounting into /etc/ssl/certs. Looks good.", "Is there a reason for using the same certs for peer and client communication? In general I believe it's recommended that you use separate ones, and I don't see a strong reason not to.\r\n\r\ncc @xiang90 ", "I talked to @dghubble about this exact thing today. @dghubble wants to reuse the certs for easier management. The best way is to separate them and also generate client certs from the trusted CA for other component consumption.", "@dghubble Or maybe a different thing? It is not the bare metal one after my second look.", "I answered below, that was a different thing for https://github.com/coreos/matchbox/pull/566", "I believe this will require ignition_config resource to change from\r\n```\r\n  systemd = [\r\n    \"${data.ignition_systemd_unit.locksmithd.id}\",\r\n   ...\r\n```\r\nto \r\n```\r\n  systemd = [\r\n    \"${data.ignition_systemd_unit.locksmithd.*.id[count.index]}\",\r\n   ...\r\n```", "good catch, that change is necessary indeed, thanks!", "@Quentin-M question: is this safe given the following comment? https://github.com/coreos/tectonic-installer/blob/47f4f81/tests/smoke/bare-metal/smoke.sh#L11-L13\r\n\r\nI am unsure about the invariants guaranteed by the Jenkins executor. The PR is green, so it worked, most probably because those bare-metal tests have been executed on different nodes. But does Jenkins always ensure this invariant for parallel tests?", "We'll need this to be `\"${data.ignition_systemd_unit.etcd3.*.id[count.index]}\"`", "Ah, good to know, thanks for the hint!", "All good :)", "Is there a reason we would test this on bare-metal as well?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/730", "comments": ["Shouldn't the entire PR just be these two lines?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/714", "comments": ["instead of a, we could do \"tectonic-\" ?", "Every character we add to that prefix is a character taken away from the cluster name. Using \"tectonic-\" would limit cluster names to 22 chars.", "yeah I figured"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/708", "comments": ["do we still need to pass these counts if we already give the list of custom subnets? we can still do the exact same (new) conditional you are doing here but in the module."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/690", "comments": ["This value has to be treated as a secret.\r\nPutting it into configuration forces the whole configuration file to have to be treated as a secret. This is not a path we want to force users onto.\r\n\r\nWe need to find an alternative to injecting this value through configuration.", "We want to avoid anything but modules and data-sources in the toplevel templates.\r\nCan we find a place for these resources inside a module?\r\nPotentially they could go into the `resource_group` module and we'll try to find a more suitable name for it.", "Same idea about top-level resources.", "Current master already includes a `create_dns_zone` variable in this module.\r\nCan you switch to using that one instead?", "Current master already provides a variable called `tectonic_azure_create_dns_zone` that implements this toggle.\r\nCan you please switch to using that one?", "I personally use the environment variable override to set this instead of setting it in the file. The environment variable can only be used if terraform declares the variable tough. It could come from a file, but that then breaks the usage of the environment variable.", "Yeah, it just didn't exist when this was written.", "But this is a module, a new one called cloud-config. I need to look at the recent work on cloud configuration created by @discordianfish in #999 or defer to it.", "Yep, same comment as before on external dns. When I merge in the current master this should go away."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/688", "comments": ["nit: We don't use this formatting anywhere else in our markdown docs. Please be consistent with the others.", "What about elements that are missing from actualJson?", "If a Makefile has \"../..\" peppered throughout, it should probably live two directories up.", "You could pass the callback to`.then()` instead of declaring a new function.", "Would you move the exports to the top of the file?", "1. This just ignores files named \".log\", not files ending in that extension.\r\n\r\n2. Do you need to ignore log files in the top directory or just /installer? Either way, one of these rules should be deleted.", "Again this just ignores files named \".pid\". You want \"*.pid\"", "JSZip should be const.", "Why does `all` depend on `clean`? Also: `launch_installer_guitests` depends on `launch_installer`, so there's no need to put the dependency in `all`.", "The err should be handled by the callback which is otherwise never called in this case.", "It would probably make more sense for `getTerraformTfvars` to return JSON instead of a string.", "You should call `fs.writeFileSync` if you don't want to handle the error.", "Instead of yet another place where we have TFvars that we have to keep up to date, can we use/tweak the examples in `installer/frontend/__tests__/examples/`?", "Would you add `engines` so we know what version of node to use?", "I think you can write these with the new short hand syntax if you want:\r\n\r\n```module.exports = {readAwsTestDataJson,awsRegion, ...```", "Instead of living in its own directory, I think all this should be in `installer/frontend/` and the test code in `__tests__/` or another directory in frontend. That would give us one `package.json` file, one `node_modules` directory, and one way to install all js dependencies.", "It looks like quite a few of these functions aren't used.", "If the launchUrl param is unused, it should be removed.", "This require is never used by anything in this file.", "Missing semicolon.", "Missing semicolon.", "Ok, this code needs to be run through eslint.", "Would be nice for this variable to match the standard variable name used by AWS tools and recognized by terraform, i.e. AWS_ACCESS_KEY_ID", "Same here, make this AWS_SECRET_ACCESS_KEY for consistency", "This isn't used. Does it have side effects?", "This means we have to set fewer different variables for different tasks", "None of your files have newines. Plz check your editor settings", "~90% of the statements in this file are missing semicolons", "Please check all your return statements. ~50 are missing semicolons. ", "Agreed! @gopilal: this is what I mentioned during our last meeting as well.", "nit for all the selectors you are using: These selectors needs to be more specific so that the tests are not fragile. You could use the xpath with text.", "We should discuss where these tests going to live. Under frontend we have unit tests and these are integeration tests. That will solve some of the problems common package.json & makefile . ", "We definitely want eslint as a dev dependency.", "This function does not need a callback.", "You can get rid of the `else`.", "Is there a loadsync version?  It would make the code much easier to follow.", "[writeFileSync](https://nodejs.org/api/fs.html#fs_fs_writefilesync_file_data_options) does not take a callback - it `throws()`.", "`aws.json` should be an argument to path.join (instead of string interpolation). ", "We should lock down the version of all our dependencies.", "\ud83d\udcaf ", "Maybe use the same xpath selector here as well!", "Where are all these methods getting used?", "Better to use relative paths than prefix everything with CURRENT_DIR.", "Better version: `bin/$(OS)/installer $(INSTALLER_OPTS) & echo $$! > frontend/ui-tests/reports/installer.pid`\r\n", "It's async-only: https://github.com/Stuk/jszip/issues/281", "This line is unnecessary. launch_installer depends on build which rebuilds frontend code if it has changed.", "pskill isn't a program on mac or linux.", "its pkill. will update", "Fixed.", "MacOS only...", "Did you mean `nightwatch.json`?  Also, this is quite different.", "It would be nice to not read this file 6? times, but I guess its OK for now."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/681", "comments": ["Just curious, but why is this line different and what's different about it? The key looks the same.", "yesssssss", "Probably want to delete this line.", "white space :-/"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/673", "comments": ["can we rename this to `bill-of-materials.json` for consistency?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/662", "comments": ["I'm surprised you didn't code-golf this to something shorter. :)", "React doesn't like anonymous components."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/661", "comments": ["define rescue pod maybe? \r\n\r\n\"Executing this command creates the following rescue pod, **which is our temporary instance of the scheduler**:\"", "can we show the output of this? and then use it below?", "can this match the above?", "sure - if we get a cluster up and running. is there a default master-node name for clusters created with Tectonic Installer? if not, it's not too useful to just use some random name here.", "nope, but im thinking that a real value will at least show you what format, that something like `ip-10-0-117-76.us-west-1.compute.internal` is the \"name\" and not something like \"node1\"", " ah, ok. you provide, and i will add and plug in below. I may have to get some redbeard time to get it working on this machine.\r\n"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/652", "comments": ["Bare Metal", "maybe:\r\nAWS using a GUI\r\nAWS using Terraform CLI"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/639", "comments": ["We don't render the `Required` column anymore, as its semantics are dubious. Do you mind to regenerate this with a newer version of `terraform-docs` as outlined in https://github.com/coreos/tectonic-installer/blob/master/Makefile#L40-L45 ?", "I suggest to call this `tectonic_vmware_ssh_authorized_key`", "I believe you added this manually. Since we are auto-generating this, I suggest to add a HEREDOC in the variable declaration below.", "We mask locksmith in favor of CLUO.", "Additionally if `experimental` is enabled, we deploy self-hosted etcd, hence etcd nodes don't need to be created in this case.", "This is misaligned, I suggest to invoke `terraform fmt` on all files.", "Thanks @s-urbaniak , this is also enabled in AWS; https://github.com/coreos/tectonic-installer/blob/master/modules/aws/etcd/ignition.tf#L25-L37 . Also I believe CLUO is deployed to master& worker nodes, not etcd nodes?", "I've used the variable without \"vmware\" prefix because of the usage in metal; https://github.com/coreos/tectonic-installer/blob/master/platforms/metal/variables.tf#L179-L187 . Happy to make the change if there are no plans to roll `tectonic_ssh_authorized_key` into global variables.", "ah, you are right and I was blind ;-) Indeed, etcd nodes are not under control of CLUO.", "`experimental` flag is handled via; https://github.com/alekssaul/tectonic-installer/blob/vmware-1.6/platforms/vmware/main.tf#L3 within the platform instead of the module. This I believe is similar to AWS; https://github.com/coreos/tectonic-installer/blob/master/modules/aws/etcd/nodes.tf#L26 and https://github.com/coreos/tectonic-installer/blob/master/platforms/aws/main.tf#L56 ", "correct, my blindness is quite shocking at this point ;-)", "you call it blindness, I call it Mondays :)", "Is there any possibility to reference this and potentially the username outside of terraform? Currently we generally reference these sorts of credentials outside of terraform itself.\r\n\r\nThe discussion per se is in flux (see https://github.com/coreos/tectonic-installer/issues/710 is the umbrella issue) but as long as the discussion is going we would be more flexible referencing outside credentials first."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/627", "comments": ["That is a good catch, thanks! Since this file is generated, do you mind to change the source of this example in https://github.com/coreos/tectonic-installer/blob/6216d54/config.tf#L207 and regenerate Documentation and variables using `make docs examples` after installing https://github.com/segmentio/terraform-docs and https://github.com/s-urbaniak/terraform-examples?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/626", "comments": ["Do you mind to give some examples in the documentation using heredoc format? Additionally I suggest to mark this as `(optional)` so the `terraform-examples` binary will mark it as such in the generated tfvars examples.\r\n\r\nHere is a suggested desription snippet:\r\n```\r\ndescription = <<EOF\r\n(optional) List of additional security group IDs for etcd nodes.\r\n\r\nExample: `[\"123\", \"456\"]`\r\nEOF\r\n```\r\n\r\nAlso please install https://github.com/segmentio/terraform-docs and https://github.com/s-urbaniak/terraform-examples, and execute `make docs examples` and add them to this PR.", "Done."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/625", "comments": ["just a concern relating recent discussion. this private key will end up in the state file, rendering its security useless.", "Hrm, yeah that gets into a more broad discussion of secrets in the state file. Terraform has been wrestling with that issue for a bit: https://github.com/hashicorp/terraform/issues/9556\r\n\r\nSince we are already storing secrets like the [private keys for the CA](https://github.com/coreos/tectonic-installer/blob/f860913/modules/bootkube/outputs.tf#L34-L36), seems like a good discussion to have for the whole repo.\r\n\r\nI will go ahead an add a note in the description that the private key will be stored in the state and potentially shared wherever the cluster state is stored.", "I suggest we use the [file](https://www.terraform.io/docs/configuration/interpolation.html#file-path-) interpolation function and only configure the location of the private key. Since this is only used for bootstrap time and needs not to be persisted I don't think we need to bend the rule here as was done for the ca key.", "Is there a clean way to have an optional file? I don't know of one off the top of my head, but I know you've been looking at this as a part of https://github.com/coreos/tectonic-installer/issues/133 so thought maybe you had some insight?", "Unfortunately I didn't find a good alternative yet. I think using the `template_file` resource with no template variables defined and a `count` on it could make this work, but it seems very hacky.\r\n\r\n@alexsomesan Do you have any creative suggestion to declare \"optionally read file x\" semantics?", "@coreypobrien ok, I have a silly idea which we already leveraged, namely pointing to `/dev/null` by default ;-) We have a precedence already when providing optional etcd CA certificates: https://github.com/coreos/tectonic-installer/blob/fff91d9/modules/bootkube/assets.tf#L8-L10", "Ah, nice. I'll head down that path! Thanks!", "Updated to use a path that defaults to `/dev/null`", "based on my testing the key is required to be on PEM format. can we change the line to ~ \"Example: `/root/.ssh/id_rsa.pem`\" if that's accurate?", "I'm not super excited about that idea because `~/.ssh/id_rsa` is a well-known default name for a private key. Curious to hear other opinions, though. "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/621", "comments": ["Should this go in styles.css instead of mochi? I thought mochi was supposed to be common code."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/616", "comments": ["outdent the yaml content, please. a good example for formatting lives here: https://coreos.com/tectonic/docs/latest/tutorials/scale-app.html\r\n", "three ticks (```) and yaml\r\n (and outdent, as described earlier, please.)", "I know about triple quotes -- it doesn't work with listed items. I am investigating on fixing it.", "three ticks (```) and yaml (and outdent)", "three ticks (```) and yaml (and outdent)", "three ticks (```) and yaml (and outdent)", "plz see my previous comment. ", "three ticks (```) and yaml (and outdent)", "three ticks (```) and yaml (and outdent)", "three ticks (```) and yaml (and outdent)", "three ticks (```) and yaml (and outdent)", "three ticks (```) and yaml (and outdent)", "three ticks (```) and yaml (and outdent)", "outdent, please. see the tutorials for an example.", "outdent, please.", "outdent, please.", "outdent, please.", "outdent, please.", "three ticks (```)", "three ticks (```)", "three ticks (```)", "three ticks (```)", "three ticks (```)", "three ticks (```)", "three ticks (```)\r\n", "three ticks (```)\r\n", "three ticks (```)\r\n"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/607", "comments": ["This expression is relying on the fact that booleans (which `tectonic_vanilla_k8s` is) also evaluate to numerical `0` or `1`. It is harder to understand how this expression evaluates, if you're not aware of that fact.\r\n\r\nWould you mind turning this into a conditional expression, for better readability?\r\nThanks!"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/604", "comments": ["Seems like you should just use the etcd environment variables here and not redefine ExecStart, so something like: \r\n\r\n    Environment=\"ETCD_LISTEN_PEER_URLS=http://0.0.0.0:2380\"\r\n\r\nSee: https://github.com/coreos/etcd/blob/master/Documentation/op-guide/configuration.md", "I copied this configuration from modules/aws/etcd/ignition.tf. I guess the same suggestion holds for that implementation?", "If the ExecStart command in the CoreOS provided etcd-member.service ever changes you won't get those updates if you redefine ExecStart in the drop-in.", "@glevand I mean, should we make the same change in the AWS module, since my configuration was copied from there?", "@crawford What do you think?", "I believe you'll need to set `--name=etcd` to hostname. Otherwise all members of the cluster will attempt to register with their name etcd", "@aknuds1 \ud83d\udc4d That is a great idea, using a generic template for this. I actually went a step further and did the same for `40-etcd-cluster.conf`", "I would like to do more \"generification\" of the whole project in order to minimize code duplication between the different platforms. An idea I have in mind is to generate Terraform files from templates, through e.g. a Python script (I do this with all my Kubernetes manifests). Making generic configurations with Terraform gets pretty painful at some point I find.", "agreed, doing this in TF is not adorable, but unfortunately we can't sprinkle in another language in here, because it is used in GUI based installer. I have been thinking of introducing custom Terraform data sources for other reasons, and it could solve some of the generification problems. At least we could then use Go code then to set up more complex content data structures.", "The IPv4 address should not be indexed by count. Instead, the selected IP address should always be `0`, no?", "let's remove this sshguard service for now. It is non-standard across platforms, uses an image that is not maintained, and cutting it out for now will simplify this PR.", "Similarly, can we remove this module for now? This will greatly simplify this PR and the number of variables to maintain. We do not enable a swapfile on any other platform currently, so this behavior is a departure from that. It is very reasonable for a pre-alpha platform to simplify code at the expense of suggesting that user's deploy larger machines in order to accommodate memory needs.", "this variable should not be declared here but rather in `platforms/digitalocean/variables.tf`. This file is for common variables only. Otherwise, this change would cause ALL clusters, even those deployed to AWS, Azure, etc to declare a DO ssh key path.", "Let's remove this for now so we can merge this PR.", "Please remove this line. This PR does not need to introduce this coupling.", "This diverges from how the other platforms are created. All other platforms expect your cloud provider account to already have the `tectonic_base_domain`. Then we create etcd DNS entries like: `${var.cluster_name}-etcd-${count.index}.${var.tectonic_base_domain}`. This avoids any dependency cycle, eliminates the need for an extra domain, `etcd.${tectonic_base_domain}`, and puts this platform in line with the other platforms.", "@squat Why should the IP address not be indexed by count? The purpose here is to create a DNS record per etcd cluster member isn't it, pointing to its IP address? I mean, as far as I can tell it perfectly correlates with [the AWS implementation](https://github.com/coreos/tectonic-installer/blob/master/modules/aws/etcd/dns.tf#L7).", "Yes sorry, please disregard. I read it incorrectly.", "What is this image exactly? Can add a comment to link to docs or Dockerfile or something?", "Please add descriptions for all of these vars.", "Why was this changed? Seems unnecessary, if so please revert this.", "Please add docs or comments on what this is used for.", "It seems this is running as a `local-exec` meaning docker is required to be installed on the user's system. No other platforms require this. If absolutely necessary then it's worth adding some \"prerequisite\" docs and detecting if docker is on the system in this script to show the user a friendly message if it's not found.", "Some comments/docs on why this is required would be nice. ", "revert if not required", "This addition seems like an isolated change that deserves its own separate commit.", "I don't really like that platform-specific vars are being added to this top-level common module. Have you explored any other ways to plumb these values through?", "@sym3tri Thanks for asking, it's a tool for uploading to and downloading from DigitalOcean Spaces object storage (equivalent to S3). I'll add a link in a comment in this file and in do-pusher.sh, OK?", "@sym3tri Should I add documentation to the top of do-pusher.sh, even if this isn't the case for do-puller.sh (or s3-puller.sh/gcs-puller.sh)?", "@sym3tri You're right. I had to solve it through local-exec because Terraform doesn't support DigitalOcean Spaces. I didn't think too much about the Docker dependency.\r\n\r\nWhat do you suggest we do? Where should I put the documentation, if we stick with this approach?", "@sym3tri Where would you like to see these docs?", "@sym3tri Done, thanks for noticing.", "@sym3tri I included the addition of the `apiserver_secure_port` variable in the DigitalOcean port commit since it's necessary to implement the latter, but I'll make a separate commit for it.\r\n  ", "@sym3tri I agree it's a bit strange, but I did it this way because `data.ignition_file.s3_puller` is also defined in modules/ignition. It doesn't quite make sense to me that an S3 utility is defined in a common module (`ignition`), but I thought there might be technical reasons why this was done. Do you think the S3 puller utility should also be removed from modules/ignition?", "Also, please move this doc to \r\nhttps://github.com/coreos/tectonic-installer/tree/master/Documentation/dev\r\nlike the gcp ones.", "The more comments the better", "https://github.com/coreos/tectonic-installer/tree/master/Documentation/dev\r\n\r\nin a new directory: `digital-ocean`", "Well the s3 puller is there too, but there are no variables plumbed through to it. This is b/c the AWS EC2 nodes have their own IAM roles and don't need credentials to access the AWS API. It seems DO doesn't have anything like this. \r\n\r\nThere may be no workaround, but it's worth thinking through. \r\n\r\nMaybe @squat has some ideas?", "@sym3tri Done, I also added a comment to document do-puller.sh.", "@sym3tri Does it make sense to call the directory `digitalocean` instead, to be consistent with `platforms/digitalocean` and `modules/digitalocean`?", "@sym3tri I was able to move my DO specifics from modules/ignition to platforms/digitalocean, seemingly without any negative consequences (I tried `terraform plan` after). I'm still wondering though why one would add AWS and GCP logic to modules/ignition. There shouldn't be any technical reason for it? It doesn't directly cause new aws/gcs variables, but there are references to container images as a result (awscli and gcloudsdk).\r\n  ", "yes thanks", "@sym3tri Alright, I added Documentation/dev/digitalocean with a README that also documents the use of resolved.", "Can we add sections here explaining how to get a cluster up and running, similar to gcp:\r\n- Prerequisities. E.g: DO account link, DO spaces creation, DNS requirements, etc\r\n- Getting Started\r\n- Customize the deployment\r\n- Deploy the cluster\r\n- Access the cluster\r\n- Delete the cluster\r\n- Caveats. E.g only one master deployment is supported. By the look of spaces.tf, docker is a local dependency with the bootstrapping machine, etc", "Can we remove aws specific comments?", "Ideally,  unless this is already handled in the source code, we should enable even a basic retry mechanism similar to https://github.com/coreos/tectonic-installer/blob/master/modules/ignition/resources/bin/s3-puller.sh#L33\r\n  \r\n  ", "Ideally, we should enable at least a basic retry mechanism similar to https://github.com/coreos/tectonic-installer/blob/master/modules/ignition/resources/bin/s3-puller.sh#L33\r\n  ", "Ideally we should isolate the dns records logic under the umbrella of modules/dns/digitalocean ", "does this means docker is dependency for the bootstrapping machine, if so need to be stated in the docs under \"caveats\"", "Ideally we should isolate the dns records logic under the umbrella of modules/dns/digitalocean", "Ideally we should isolate the dns records logic under the umbrella of modules/dns/digitalocean", "@enxebre Thanks, on it.", "@enxebre Just out of curiosity, do you mind explaining why DNS logic is put beneath a module separate from the platform module?", "Yes, we depend on Docker locally unfortunately @enxebre. Do you mean in Documentation/dev/digitalocean/README.md?", "@enxebre Thanks, I just copied everything beneath `# Platform-independent variables wiring, do not modify.`, but apparently, not everything following said comment is platform independent :/", "@enxebre Done, in do-puller.sh.", "the curl request will almost always return 0, unless you use --fail, you can check the exit code with ```echo $?``` so the until loop won't work as expected. Also after deploying a cluster the load balancer show no droplets so I can't access to the console\r\n  ", "Part of the reasoning behind it is to have ability to easily swap dns approach ", "Thanks @enxebre, I have missed the `--fail` option.", "maybe add `private_networking = true ` (and for node.tf too) to create private network? ", "@ditansu It's a good point, I wasn't aware of DigitalOcean's support for this until recently. Maybe it should be an option whether to create private nodes or not?", "> Maybe it should be an option whether to create private nodes or not?\r\n\r\nWhy not, but I think a privet net need be always, because cluster it is always two or more nodes  and  it's much \"cheaper\" and secure use privet net. Especially if we take in account  privet network is don't exclude public IP e.g. node always will be have public IP in any case  - enable or disable privet IP. ", "@ditansu Pardon my ignorance, but what's the benefit of creating nodes with both private and public IPs, will it not be as insecure so long as nodes have public IPs? I do see though that Typhoon creates nodes with both private and public IPs, and was wondering what the reasoning is behind this. Is the benefit that cluster nodes will communicate with each other over the private net?\r\n\r\nI was wondering if it might be an idea to introduce an option to create nodes with private IPs only, for security purposes? Kops has an option on AWS to create nodes with private IPs and a single bastion host to allow SSH-ing into the cluster. In the case of DigitalOcean I'm not sure if there's a need for a bastion host as it doesn't have VPCs, and I would think one might as well just use any other node in one's account as the bastion. Thoughts?", "@aknuds1, I guess the benefit of public IP is only for deploy stage without bastion. So you could rollout a cluster from your laptop directly. After deploy you could wrap the cluster in firewall. By the way https://github.com/kubicorn/kubicorn/  can up cluster with DO's firewall out-of-box.   And sure you could use any DO's server as bastion in deploy time and usage time. But I don't see benefits from bastion it self, because there is a very small opportunity of hacker attack during cluster rollout time, and we have firewall   (for tagging droplet group) to protect whole our cluster. ", "@ditansu Sounds like the right approach to me with firewalling the cluster! Do you know if [Typhoon](https://github.com/poseidon/typhoon) firewalls the cluster as well?", "@aknuds1 I know about Typhoon but haven't tried it yet.  But judging this https://github.com/poseidon/terraform-digitalocean-kubernetes/blob/master/network.tf  they support firewall from out-of-box. ", "@ditansu That's awesome; I have used Typhoon, but didn't notice the firewalling :)", "@aknuds1  you are welcome ))) buy the way, what do you think regarding tectonic's future under RedHat ?", "@ditansu I am also unsure! But in my opinion it's good to have Typhoon as a second project in this space :)", "@aknuds1 absolutely agree)"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/603", "comments": ["I think eslint supports \"unused\" for the variable name.", "unused"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/602", "comments": ["Terraform supports boolean variables.\r\nhttps://www.terraform.io/docs/configuration/variables.html#booleans\r\n\r\nAny particular limitation on not using boolean here?", "If using a boolean, you can omit the comparison and clean up the expression a bit more.", "Same point about booleans (as above).", "Should the internal version not always be the azure domain? That would route all traffic over the private network instead of hitting the public ip.", "This PR is aimed at refactoring the usage of the right FQDN's for setups that operate over public networks. Private networks would need to disable public IP's on the LB's, and leverage either private IP's or DNS instead, but that is not in scope for this PR."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/594", "comments": ["@sym3tri @robszumski I get an error when running a version of this command:\r\n```\r\n$ terraform plan -var-file=terraform.tfvars platforms/aws\r\n2 error(s) occurred:\r\n\r\n* module.masters.aws_autoscaling_group.masters: : invalid or unknown key: tags\r\n* module.workers.aws_autoscaling_group.workers: : invalid or unknown key: tags\r\n```", "This happens if you're not using the correct `.terraformrc` file pointing to the installer binary as a TF plugin", "be sure you follow the same steps, prior to the `terraform destroy` command.\r\n\r\nhttps://github.com/coreos/tectonic-installer/blob/master/Documentation/install/aws/uninstall.md#destroy-the-cluster", "Let's use the example of making two clusters based off the same config, but in different regions. Basically, edit the tfvars to have a new region, domain and cluster name. Note that region is defined as an env var right now I believe.", "where does \"start installation\" appear on the screen?", "`downloads`", "I'd take region out of here, as its not in the vars file.", "If that's from my text, it's at the top of the page where the Download Assets button is included. My screen grabs are on my laptop - I'll confirm and finalize when I take a pass of this tomorrow.", "Nevermind, I see that region is in the sample aws file", "I think you'll need to add \"then edit the subnets to reflect the new region\"", "This statement is a bit confusing. Technically you can make changes to the Kubernetes manifests that the installer comes with (modules/bootkube/resources/manifests), before creating a cluster.\r\n\r\nDo you mean the installer doesn't allow to make changes to the Kubernetes components already deployed on a running cluster?", "@robszumski or @sym3tri for the answer to that one.", "@alexsomesan We're trying to steer folks away from modifying things in `kube-system` or `tectonic-system`, as we won't support those changes.\r\n\r\n@zbwright We should probably tweak that to say that changes to the Kubernetes manifests voids your ability to auto-update, with more docs to come soon that expand that out", "@robszumski That approach sounds good.", "If your mentioning multiple clusters, you'll need to mention that each cluster should have its own directory and own state file. So you'd need to make a copy of the assets.zip for each cluster you want to create.", "so - copy / paste to create multiple 'assets' folders, then edit one terraform.tfvars per folder to customize the cluster that will be created, then run terraform plan / apply on each in sequence, correct? (If this is how you use the one download to create multiple clusters, it's important to call it out correctly. I don't want to get it wrong.) ", "This is a relevant doc. https://www.terraform.io/docs/state/\r\nUltimately the reason you need multiple copies of the assets is so different states don't step on eachother. Each assets instance doesn't need to be different necessarily, just needs a different directory so each instance has it's own state.", "ok. try this:", "+1", "@zbwright what you described is correct.", "I just realized the paths in the `.terraformrc` might prevent this from working. @Quentin-M can you verify?\r\n\r\nIf not, let's just skip all mention of multiple clusters for now.", "It will work, the only thing that `.terraformrc` has is an absolute path to the installer binary. Therefore multiple asset folders will work properly, as long as they copy the whole folder and not only the visible files.", "so, we're good? or should I make this more emphatic?\r\n", "We good \ud83d\udc4d  Only thing is, they should not move their installer binary - otherwise they'd have to modify this file (but this applies to every platforms)."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/593", "comments": ["How about linking to https://github.com/coreos/bcrypt-tool instead, as this should be the main documentation page for bcrypt-tool?", "Done."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/591", "comments": ["Are destroy, apply, & plan supposed to be phony? In other words: do you want them to run if a file named `destroy` is in the current dir?", "Will my change make `destroy`, `apply` and `plan` phony? I'm not a Make expert, but I figured that only the `terraform-get` target would become phony?", "I just tested creating such files FWIW (destroy/apply/plan), it seems the targets are executed no matter what, even if they exist. I would expect Make to skip them since corresponding files exist. This behaviour is the same without my patch.", "It's always building because its dependencies also have missing outputs. I think your PR is better than what's currently in master, so I don't think it should be blocked on this.\r\n\r\nI just didn't realize the Makefile was so hacky.\r\n", "Haha thanks for clarifying this @ggreer :) I guess these targets *should* be phony.", "@aknuds1 \r\n\r\nCan you please give a bit of background on why this change is needed?\r\nWhat is your use-case where you need to run get before every apply?\r\n\r\nThe current behaviour is to invoke get only when module cache is missing.", "@alexsomesan The case is when the cache is missing one or more modules. I don't know how it came about, but I imagine it's because modules were added in the source, so that the cache became stale. It's only logical however that the cache can become out of sync with the source, we can't expect that it will stay relevant over time.", "You're right that a new module being added would not trigger a get. In that sense, your change is brings more convenience. There is also a downside because this is invisible to the user and could \"bite\" unsuspecting users into applying changes that they weren't expecting. \r\n\r\nHowever, since the cache is nothing more than a bunch of symlinks to the actual module files, changes to those could also bite in the same way with the current state of things.\r\n\r\nThings being the way they are, I think your change is useful and won't surprise with unexpected side-effects.\r\n\r\nPlease rebase and it should be good to merge.", "One more thing: there already is a .PHONY section (at the end of the file).\r\nCould you please move this over there?\r\nIt makes spotting target blocks easier when reading the Makefile."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/580", "comments": ["These are actually not maintained by team monitoring (I believe they were contributed by @chancez), so they don't need to be reverted, they can have the consistent labeling already.", "Sounds good, I un-reverted this doc change."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/557", "comments": ["I am wondering, is this not redundant with the ignition config as per [1]?\r\n\r\n[1] https://github.com/coreos/tectonic-installer/blob/1827f92aaf5537bc57e66ea48278fdb969c6e37f/modules/azure/etcd/ignition.tf#L14-L20", "see comment above", "This PR can be reduced down to just this line as the SSH key is already placed in by Ignition.\r\n\r\nAnd `master_count = \"${var.tectonic_master_count}\"` has already been addressed in https://github.com/coreos/tectonic-installer/commit/e0c2d67a559aca2d0514c537985b9ce7c0072304#diff-0106e47f11400f0434e4340687831ab7", "ok, let's get this in then, we can tackle ssh key redundancy in a follow-up PR.", "We need this in because by setting `disable_password_authentication = true`, Azure requires SSH to be specified. If not you hit this error like I just did when testing (https://github.com/coreos/tectonic-installer/pull/624):\r\n\r\n`* azurerm_virtual_machine.etcd_node: compute.VirtualMachinesClient#CreateOrUpdate: Failure responding to request: StatusCode=400 -- Original Error: autorest/azure: Service returned an error. Status=400 Code=\"InvalidParameter\" Message=\"Authentication using either SSH or by user name and password must be enabled in Linux profile.\"`"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/550", "comments": ["Suggestion: let's use HEREDOC syntax, so this does not end up in one long huge line, escaping of quotes is not necessary any more, and double new-lines will be translated to `<br>` lines in the generated markdown:\r\n\r\n```\r\ndescription = <<EOF\r\nSubnet ID within an existing VNet to deploy master nodes into.\r\nRequired to use an existing VNet.\r\n\r\nExample: the subnet ID starts with `\"/subscriptions/{subscriptionId}\"` or `\"/providers/{resourceProviderNamespace}\"'`. \"\r\nEOF\r\n```", "Additionally I suggest to add (optional) like so:\r\n```\r\ndescription = <<EOF\r\n(optional) Subnet ID within an existing VNet to deploy master nodes into.\r\n...\r\nEOF\r\n```\r\n\r\nThe terraform-examples tool will auto-detect the prefix `(optional)` and will comment out the variable in the generated examples tfvars file."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/542", "comments": ["What new features are in Dex? SAML?\r\n\r\nConsole changes too...", "it's more about having full workload separation, let me rephrase after my release.", "Switch provisioning methods on AWS/Bare-Metal to TerraForm exclusively", "Introduce experimental support for self-hosted etcd using its operator, and associated UI.", "Introduce the Container Linux Updator Operator (CLUO)\r\n\r\n(we never had it before)", "Segregate control-plane / user workloads to master / worker nodes respectively", "Terraform (sorry, let's respect their brand)", "same here"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/540", "comments": ["why do you need python? I'd rather we not introduce a new language dependency", "where do these come from?", "You can just add this to our build container and assume it exists in the PATH\r\nsee: https://github.com/coreos/tectonic-installer/tree/master/images/tectonic-builder", "I'd ignore these and just use a prepopulated list of all the repos i sent you", "this seems fragile", "Please add a comment to describe what is going on in the if-else condition.", "Any reason why this cant be declared at the top and left off for the whole file?", "Please rename this variable. json_licenses maybe?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/539", "comments": ["oh, just a second, afaik baremetal does not recognize `tectonic_master_count`, hence what value should we put here?", "I vote for defaulting this to `1` for the metal platform, `tectonic_master_count` is not used there, and in fact https://github.com/coreos/tectonic-installer/pull/536 does not even configure this value anymore for baremetal.", "Should probably use the length of var.tectonic_metal_controller_names instead.\r\n\r\n```\r\n\"${length(var.tectonic_metal_controller_names)}\"\r\n```"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/536", "comments": ["`AWS`", "`Azure`", "I know these are generated, but is there anyhting we can do to make this `bare metal`?", "`Openstack/Neutron`", "`Openstack/Nova`"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/532", "comments": ["nit: Extra <code>and</code>", "I copy-pasted that from the old baremetal page. It's not the best sentence, but I think it's grammatically correct. eg, with parens to differentiate the clauses:\r\n\r\n> End users can run applications using (the API, CLI and Tectonic Console) and typically don\u2019t need SSH access.\r\n"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/531", "comments": ["if `tectonic_experimental` is set to `true`, we deploy a self-hosted etcd environment, hence it is not necessary to create those record in this case. Also if the user brings an existing etcd infrastructure, we skip the creation of those records too.\r\n\r\nAs a reference please see https://github.com/coreos/tectonic-installer/blob/a9b1e4c/modules/aws/etcd/dns.tf and https://github.com/coreos/tectonic-installer/blob/a9b1e4c264d370679adc7a4d9432872b3032456c/platforms/aws/main.tf#L74.", "as far as I see this creates exactly one etcd node? If so, we should make this configurable taking `tectonic_etcd_count` into account. Also if `tectonic_experimental` is set to true (self-hosted etcd), this node doesn't need to be created.", "locksmith is masked in favor of the container linux update operator which was introduced in #366, hence you can mask it as [here](https://github.com/coreos/tectonic-installer/blob/1827f92/modules/aws/ignition/ignition.tf#L31-L34).", "This can be removed in favor of directly to etcd passing the etcd endpoints directly into the bootkube module, see https://github.com/coreos/tectonic-installer/blob/47ab62d/modules/bootkube/assets.tf#L38.", "Added in dd0cbbc", "Added in dd0cbbc", "Per input from @philips - for Alpha he suggested trying to get a single etcd node working. IIRC, the plan is to move to self-hosted so he didn't think it was a priority to get a cluster working."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/529", "comments": ["So you want to print the script being executed here? not just the output of it?", "In general, it's handy to see exactly what commands `make` is running, and in what order.", "Completely reasonable, just making sure that's why you're doing it."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/523", "comments": ["maybe add something about how it needs to be long running", "also .. open source ... on-premise environments that match bare metal machines to profiles ...", "... bare metal ... \r\n\r\n(we aren't hyphenating)", "I believe Matchbox as a service should be capitalized throughout the doc. But I'm going off the yocto project style, and I'm not certain that's the original source: https://www.yoctoproject.org/tools-resources/projects/matchbox ", "Tectonic Installer", "... set up ... check out ...", "added up top", "fixed", "fixed", "Yes, I believe it was decided it should be capitalized. The vast majority of existing docs don't yet ut I think we wanna move toward it"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/521", "comments": ["fedora and bare-metal", "CLUSTER could just be the default \"demo\" here. The executor creates one cluster and deletes it at the end, there are not simultaneous uses of the same executor.", "You're calling aws, not bare-metal. Also, you need to set ASSETS_DIR. https://github.com/coreos/matchbox/blob/master/Jenkinsfile#L43", "This seems far too long", "Can you add this to setupSSH please", "Please parallelize this with AWS before merge.", "Indent the block like the other blocks"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/518", "comments": ["I think Uninstall Tectonic, please.", "I feel like this is unclear..\r\n\r\nIt does not clearly say what's the assets.zip and where do I get it. the `Installer download` is a big unclear too.\r\n\r\nThen like I dont clearly understand how I will have a magical `tectonic` folder in `Downloads`.", "`cluster state directory` --> not sure they will know what that is at first. Would be better to say that they gotta change directory to what they unzipped from assets.zip, that they downloaded?", "...Tectonic cluster ...\r\n\r\nopen a Terminal and navigate to the cluster state directory for the target cluster within the Tectonic Installer directory. This directory is named with the name given the cluster during the install process, suffixed with ...", "I'd reverse the two terms. Otherwise it might use their outdated/newer TerraForm.", "To be safe, I'd use `TERRAFORM_CONFIG=$(pwd)/.terraformrc`", "This still need to be here otherwise the route53 zone will fail to be deleted.", "No, https://github.com/coreos/tectonic-installer/pull/509 will fix that.", "Note that they still need to export their AWS credentials for now!", "still needed", "These resources may include ELBs ... Route 53 ...", "a a", "not needed if they export the PATH as done above, right?", "got it, it's down below.", "got it, it's down below.", "I would either remove this section, or change it to more clearly state - use the assets to build a similar cluster:\r\n\r\n## Reinstall using previous configuration\r\n\r\nUse the `tectonic.progress` progress file found in your existing [assets bundle][assets] to create a new cluster based on configuration options from an previous cluster. Follow the [AWS: Installation][install-aws] guide to create a new cluster and deploy your applications and services.\r\n", "we don't provide the progress file in there.", "it can be only be saved from the GUI, but this is more like a dev feature than anything else", "now that i've done it, I understand. will take a look at your new version, when it's ready.", "These keys were generated as part of the AWS setup process, as described in [Creating AWS access keys][https://coreos.com/tectonic/docs/latest/tutorials/creating-aws.html].", "<ACCESSKEYID>", "pass on expanding this here", "fixed", "Terraform only destroys objects that it has created. Don't worry blah blah...", "https://github.com/coreos/tectonic-installer/pull/518/files#diff-218c509e40308277813cb75996ba94d6R38", "any reason to combine this env var on one line, but not the path one? might be more understandable", "might be nice here to include a little bit of sample output:\r\n\r\n```\r\n$ TERRAFORM_CONFIG=$(pwd)/.terraformrc terraform destroy --force\r\nprovider.aws.region\r\n  The region where AWS operations will take place. Examples\r\n  are us-east-1, us-west-2, etc.\r\n\r\n  Default: us-east-1\r\n  Enter a value: us-west-1\r\n\r\ntls_private_key.ingress: Refreshing state... (ID: 38aaae42623d255797e70602cf81b27574496fdf)\r\ntls_private_key.identity-server: Refreshing state... (ID: 4b4d568965570a3d88acb7ab8121cb6afa587fae)\r\ntls_private_key.identity-client: Refreshing state... (ID: 5dc4dd159f5de9318a3cd9ca4c13c89801f749b8)\r\ntemplate_dir.bootkube-bootstrap: Refreshing state... (ID: 7b3b54f349160ff1eefad8ce1a01c4d62b02cae8)\r\nrandom_id.console_secret: Refreshing state... (ID: 74U0bR3MQMztiz1sasRRMw)\r\ntls_private_key.kube-ca: Refreshing state... (ID: a93dbf10de4297cbb03f65dfbc551d3abc0280c3)\r\n...snip....\r\nmodule.vpc.aws_security_group.master: Destroying... (ID: sg-33693754)\r\nmodule.vpc.aws_security_group.worker: Destroying... (ID: sg-0b66386c)\r\nmodule.vpc.aws_security_group.worker: Destruction complete\r\nmodule.vpc.aws_security_group.master: Destruction complete\r\n\r\nDestroy complete! Resources: 41 destroyed.\r\n```", "double \"not\" is kinda hard to parse", "The idea was avoiding doing any exports, and thus leaving the environment as we found it. However, that was before I added the AWS creds so is maybe less compelling now", "Seems reasonable -- I'll mock in output that doesn't ask for region"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/517", "comments": ["@ericchiang these seem a bit redundant -- do you want to keep both?", "I think we're fine removing the second. cc @rithujohn191 ", ":+1: ", "@pbx0 nothing under `/installer/assets` is used anymore and will all be deleted soon."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/513", "comments": ["`existing`", "is any of this specific to SAML or is it just an overview of dex?", "I'd like to not refer to this by assets.zip because its confusing to reference it by file name. can we just say \"that you downloaded during installation\"", "the format of this is a little hard to guess, we should consider showing an example", "is this LDAP mention a stray copy/paste?", "Is it ok if I use \r\n```\r\n   connectors:\r\n    - type: saml\r\n      id: okta\r\n      name: Okta\r\n      config:\r\n        ssoURL: https://dev-791588.oktapreview.com/app/coreosdev791588_tectonic_1/exkadb8hqlmcAsvX90h7/sso/saml\r\n        redirectURI: https://do.dev.coreos.systems/identity/callback\r\n        usernameAttr: name\r\n        emailAttr: email\r\n        groupsAttr: groups\r\n        caData: \r\n```\r\n", "the complete authentication flow: Tectonic Console -> Dex -> SAML IdP. Requested Boo Book for a diagram to beautify the doc.", "copy/paste :/ i have fixed it ", "Should we include an example SAML XML file (will that help our customers in some way ?) Some documentation online shows an example file.", "sorry I should have been more specific, I was talking about the `caData` field", "probably should be example.com just to make it clear that we don't host anything for you", "probably should be example.com just to make it clear that we don't host anything for you", "you mean something like.... \r\n`kjndkjfho99000-amnjni343435&*...` wouldn't this confuse the reader? or do you have any specific idea in mind?", "questions that we could answer for a user by providing an accurate example (IMO):\r\n - is this the name of a kubernetes secret?\r\n - do I stick the raw contents in here?\r\n - do I need to indent it?\r\n - do I need to base64 encode it?", "we can truncate it so we don' t have a ton of junk", "could you check the table under the `Prerequisites and guidelines` section in the document. Probably I should edit the description of CA there.", "Maybe note the relationship between identity and RBAC? e.g. that identity determines the user's identity and RBAC enforces access based on that information.", "I'd omit a lot of the x509 details since they're not actually relevant to an admin setting this up. Maybe just stick to things like \"sign the response\" and \"verifies the response signature.\"", "> Tectonic Identity sends the initial login request, `AuthnRequest`, and validates the response's `InResponseTo` value. The `AuthnRequest` message indicates to the IdP how the operation should be executed. Tectonic Identity doesn't process unprompted authentication responses.\r\n\r\nTectonic Identity constructs a SAML `AuthnRequest` and sends the user to the SAML provider. Once the provider verifies the user it constructs an `AuthnResponse` and Tectonic Identity which verifies the response and pulls various user information such as email, username, and groups.", "These instructions for updating dex's config already exist elsewhere. Can we just refer the reader to them?", "Talk about what this is and how you'd construct it.", "This will always be \"https://( tectonic domain )/identity/callback\" Can we call that out?", "Probably doesn't need to be its own section. Just a note in the one above.", "Where's this role coming from?", "Group membership is on the provider side. E.g. on the okta side. Not the tectonic side. ", "I don't get this example. Can we just show how to give the user admin then defer to the larger RBAC doc?", "this is `https://dex.tectonic.com/identity/callback` Also it's odd that this includes \"dex\" since we've been referring to identity this whole time.", "I don't get these columns. We only actually care about what the field name in the dex config is and what the expected value is.", "Doesn't the content in the table answer to this question ? I included the table to describe what each parameters are - how does it map to the items we pick from IdP side (Okta  etc.)", "i need to create an independent RBAC doc and point LDAP/SAML docs to it. Right now it's part of LDAP doc. I will be doing it so that we do not need to repeat for every identity provider description.", "Picked up from RBAC section of the LDAP docs", "that would be convoluted. let me think about something more solid and clear that pertains to this particular section - say for the user, jane.doe@coreos.com", "Can we defer this section until we figure that out then? I think it'd be good to keep this PR as focused as possible so we can get _something_ merged then iterate on it from there.", " the term IdP has been used to identify the SAML provider. Do you think I should use SAML provider instead of IdP ? Or rather use SAML IdP (that's kind of redundant!) across the doc. any suggestion?", "Either one. But yeah, being consistent is good.", "As an admin, I am copying the ca data from IdP, encoding it , and entering into the config file. My intention was here to make it crystal clear. Do you think I should omit info on X509 details?", "Well, technically it's a XML signature using the private key of the x509 certificate. My point is just saying \"Tectonic Identity verifies the response signature using the x509 cert\" or \"the provider signs the response\" might be good enough.", "here at https://www.pivotaltracker.com/n/projects/1902233/stories/143919343, the description states to highlight this issue - so I called out this in a separate section.", "I still don't get why we need these first two columns. @joshix or @zbwright can you make a call on this?", "Why do we also have this section? It's already covered in the previous one.", "I think we could eliminate this section with very little impact to the end user.", "and @ElijahCaine.  Feel free to dissect my doc.\r\nHow would be then communicate the common entries to the users ? SAML IdP (Okta) and the parameters in the config file we edit on the Tectonic Identity side ?", "Oh it should be editing an existing one. my mistake.", "you mean the workflow ? I fall under the camp that  vote for giving detailed instruction. But I am fine as long as our customers are not worried about knowing SAML workflow in simplest terms.", "... mapped to a SAML service to ensure that RBAC role bindings ...", "I think that anyone looking to use SAML for user auth with Tectonic will know what SAML is. I would move the first sentence - Tectonic Identity supports SAML ... - to the top of the Overview section, and remove the rest.", "... IdP constructs an `AuthnResponse` to send to  ...\r\n... 2 spaces \"Tectonic  Console.\"", "... is provided access to the Tectonic cluster. ", "Parameters must be configured on both Tectonic Identity and the SAML IdP to enable them to pass user information to one another. Tectonic Identity uses the config-dev.yaml file to set these parameters, which must be mapped directly to those configured on the IdP side. ", "If these two fields map 1-1 to one another, listing them is helpful. That is, if the same value must be added to the listed fields on both sides, the two first columns are helpful. (name changes between products / platforms is always confusing to users, and the source of many calls to tech support.) If there isn't a 1-1 alignment, the columns should be removed.", "Tectonic Identity assumes that this value is both unique and constant. Be certain to configure your SAML IdP to provide an appropriate format. If Tectonic Identity requests a NameID format for which IDP is not configured, authentication will fail. Select the default value, `unspecified`, unless your system requires a specific format.", "Your SAML IdP sends the security token with SAML assertion containing user information to this URL.\r\n\r\nquestion: is it required that the URL take the format https://tectonic-domain/identity/callback ? If so, state that, please. if not, remove the sentence 'Replace `tectonic-domain` with your Tectonic domain address.'\r\n", "This one's a little confusing. It doesn't follow the format of the other field descriptions, in that it doesn't define what goes in the field first. Do users enter a path here? in which case it's maybe:\r\nThe path to your Certificate Authority Data. Used to validate the signature of the SAML response, CA Data is the base64 value of X.509 Certificate.\r\nor something like that.", "... The attribute in the returned assertion, used to map to ID token ...", "Tectonic application? or Ensure that Tectonic is configured ... ?", "would you help me rephrase ? The URL should be https://tectonic-domain/identity/callback. <tectonic-domain> should be replaced with customer's Tectonic domain address. For example in my case it's doc.coreos.systems. \r\nhttps://doc.coreos.systems/identity/callback\r\n\r\nIs that sentence unclear ?", "sure. there is 1-1 alignment. I will add the value / example.", "Tectonic Identity pulls its configuration options from a configuration file stored in a `ConfigMap`, which admins can view and edit using `kubectl`. To prevent misconfiguration, use `kubeconfig` (downloaded during installation) to edit Tectonic Identity's `ConfigMap`.", "... subject to change ...\r\n\r\nand maybe link out to the IdP doc?", "there are multiple IdPs, one is Okta which has been used to have a setup for doc purpose. Customer can use any Identity Providers. so we cannot provide links to all the IdP docs.", "Create role bindings to allow SAML users access to Kubernetes resources through both Tectonic Console and kubectl.", "ok, then See your provider's documentation for more information their SAML configuration options.", "In Okta, we must configure a corresponding \"application\" to set up identity federation. So I called out as \"Tectonic application\"", "The callback URL from Tectonic Identity. Your SAML IdP must send the security token with SAML assertion containing user information to https://<tectonic-domain>/identity/callback. Replace <tectonic-domain> with your Tectonic domain address.\r\n\r\nJust take out 'Example' - that was the confusing part. I wasn't sure which part of it was an example, and which, if any, was the specific URL to be used.", "This renders poorly. Please reformat it to render how it looks in the raw markdown (`--subcommands` on newlines, etc.", "Navigate to 'My Account'.", "`KUBECONFIG`. I believe we've been making environment variables code-style.", "https://tectonic-domain/identity/callback  is an example URL. We replace `tectonic-domain` with our own tectonic domain.\r\n\r\nAnd it's not \"must send security token\" - the IdP will send the security token - that's the process.", "@zbwright \r\n<img width=\"754\" alt=\"screen shot 2017-05-15 at 4 54 58 pm\" src=\"https://cloud.githubusercontent.com/assets/3285001/26084196/47e77112-398f-11e7-80de-687fe7d35950.png\">", "Need to include instructions for downloading this kubeconfig.", "\"Tectonic Identity authenticates clients, such as `kubectl` and Tectonic Console, for access to the Kubernetes API and, through it, to Tectonic cluster services. All Tectonic clusters use Role Based Access Control (RBAC) to govern access to cluster services. Tectonic Identity authenticates a user's identity, and RBAC enforces authorization based on that identity. Tectonic Identity can map cluster RBAC bindings to an existing Security Assertion Markup Language (SAML) Identity Provider (IdP) over a secure channel.\"", "delete -- integrated into graf above", "\"This document describes managing Tectonic users, groups, and access control in concert with a SAML IdP.\"", "s/the Tectonic Identity/Tectonic Identity/\r\n\r\nQuestion: \"pulls\"? Does \"pulls\" mean \"retrieves from the SAML IdP\"?", "s/pass user information to one another/exchange user data/\r\nSecond sentence: \"These parameters are defined for Tectonic Identity in the `config-dev.yaml` file.\"", "\"Once configured, a SAML IdP exchanges security tokens with Tectonic Identity, acting as a SAML consumer, to exchange user authentication data.\"", "\"The table below describes the parameters that configure Tectonic Identity federation with IdPs:\"", "General comment: Aim for consistency with \"identity provider,\" \"Identity Provider\", \"IdP\" -- you use all three in the course of this document. I think it should be capitalized in expansion, because it is a term of art.", "\"Ensure the Identity Provider has been configured for access by Tectonic. Okta and some other IdPs refer to these clients as *applications*. See [*Prerequisites and Guidelines*][link].\"", "s/Perform the identity configuration:/Configure Tectonic Identity:/", "Do not make this an email quote. Remove `>`", "Complex formatting failure: \r\n\r\n<img width=\"896\" alt=\"screen shot 2017-05-18 at 9 56 26 am\" src=\"https://cloud.githubusercontent.com/assets/72905/26214189/503a8020-3bb0-11e7-889f-fc5bbd8543a6.png\">\r\n", "This sentence seems to belong under point 5, instead of 4. (Sequence: Trigger the update (4); Check the update success by watching pods (5); and restore backup if failed", "connector or connectors? (literal strings should be literal)", "Don't format with email block quote. Remove `>`. \r\nreference links are preferred\r\nlink should be to `#configuring-rbac`", "This graf is very confusing.\r\nCan it be shortened to something like:\r\n\"Since access tokens can expire or be inapplicable to new resources, users must acquire a *refresh token* from the IdP, to in turn acquire a new access token and regain access to the cluster.\" \r\n\r\nIf so, can it be integrated above instead of being in its own section, as in @ericchiang previous comment?", "despite the errant line break, this is part of line 147 and my comment there obtains", "also what does kubeconfig have to do with it? (Confusion of graf)", "@radhikapc again, what is the resolution of this discussion? Is there a discrete RBAC doc, or a plan for one, or was a decision taken to leave this information in place?", "@joshix what's currently there will continue. I made other changes that Eric suggested.", "Retrieves from 'AuthnResponse'. retrieve is a better wording.", "My mistake. it should be IdP :-/", "<img width=\"927\" alt=\"screen shot 2017-05-19 at 10 29 30 am\" src=\"https://cloud.githubusercontent.com/assets/3285001/26259482/16bb8406-3c7e-11e7-9ea0-b47fcf2e6483.png\">\r\nThere is an extra tick mark(which i will remove), rest looks as it is on the existing user management doc :-/\r\n<img width=\"609\" alt=\"screen shot 2017-05-19 at 10 36 00 am\" src=\"https://cloud.githubusercontent.com/assets/3285001/26259693/fe717e86-3c7e-11e7-8dc9-3f5b23dccaaf.png\">\r\n ", "kubeconfig that we download from *My Accounts* will have our authentication data, but refresh token. So after the grace period of kubeconfig, we need to log in again (implies we are re-authenticated, whereas if refresh token is available in kubeconfig we do not need to re-authenticate) to access clusters. Hope it's clear. @ericchiang please correct me if I've misinterpreted the concept.", "we have the following issue:\r\n\r\nhttps://www.pivotaltracker.com/n/projects/1902233/stories/143457267", "Or should I just say that user has to log in again to access the clusters (because the grace period of kubeconfig, which has the authentication details, will expire after 24 (?) hours) or something in those lines.", "@radhikapc Where did 24 hours (and the second sentence) come from?\r\n@ericchiang Could you specifically confirm or correct this paragraph about refresh tokens? (Last thing, I almost promise)"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/510", "comments": ["Why would not need the <code>platformType</code> anymore?", "There were custom messages for old baremetal & old aws, but all terraform platforms had the same message. See lines 68-76.", "Oh ok"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/509", "comments": ["What region is most popular with our users? We might want to default to the most common one (us-east-1?)."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/500", "comments": ["do we want to link to the \"manual boot\" doc from here?", "ha! we can now."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/496", "comments": ["It's a semver, so should just be `0.2.6` without `v`", "same here", "done", "done", "0.3.1 is out now"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/490", "comments": ["Can you consolidate the script you've placed below and the Jenkins AWS process into a `make aws-smoke` target, similar to the original Jenkins pipeline?", "You might just remove this. Its no longer possible to run the installer app as a container service across platforms. All platforms except AWS have to connect to hosts to transfer secrets using the SSH_AGENT or key file.", "interesting, this would start to tie this makefile to the other. while this one never builds this one, why would it clean it?", "we need to be in the installer folder for all these commands, I don't see it being mentioned anywhere?", "we are not keeping this container image, yeah. it's not even pushed as part of the releases anymore.", "`make vendor` is the way to go, it does some additional stuff. no one should be using glide directly in any case.", "It does build it. See the other invocation of `make -C`", "Out of scope for this PR. See: https://github.com/coreos/tectonic-installer/issues/485\r\n\r\nJust wanted to surface this so it's not a mystery", "f32e492e95a8cf4fb30c68f2192f51623794c9da", "d265a18", "https://github.com/coreos/tectonic-installer/commit/f32e492e95a8cf4fb30c68f2192f51623794c9da", "im blind."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/481", "comments": ["From https://developer.mozilla.org/en-US/docs/Web/API/Element/scrollTop\r\n\r\n> If set to a value greater than the maximum available for the element, scrollTop settles itself to the maximum value.\r\n\r\nLooks like browsers obey that, so this is safe. \ud83d\udc4d", "I reverted back this change, it was working fine. "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/477", "comments": ["Maybe note that the long term fix will be preventing pods from talking to the AWS metadata service through network policies? cc @Quentin-M ", "I agree that this should be fixed ASAP. Pods should probably not be able to talk to the AWS API using the creds used for the cluster.", "I'm not clear here. Should I add a (temporary) note that users should prevent this access? add:\r\n\r\n... pull down cluster credentials from AWS S3. To prevent pods from talking to the AWS metadata service, create network policies which deny them access.", "@zbwright we should add a note that we plan to address this in a later release since it's a pretty serious issue. I don't believe there's a fix that user's can apply today.", "ok. I will leave the planned fix vague. Is this a serious enough issue that it should be bumped to the top of the page? "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/474", "comments": ["Kubelet will start once `kubeconfig` is copied to the machine and crash loop until `kubelet-env.service` creates `kubelet.env`", "Starts on boot and crash loops until the control plane is available."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/469", "comments": ["I'm not really sure if anything in Kubernetes actually *uses* the owned vs. shared values at the moment, but in any case, it might make more sense to mark subnets as shared. That was actually one of the main use cases for moving to this style of tagging -- being able to share subnets between clusters."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/468", "comments": ["Is there a potential race here?", "Afaik we handle this the same way as all the other tpr setups. The kubectl function will loop until the tpr is available.", "Just as a side note: I also spawned it up a couple of times.", "why not `tectonic_etcd_count`?", "I am happy to map this to `tectonic_etcd_count` but #448 requested an explicit setting.", "Just FYI, this broke all other platforms besides aws.", "oops", "oops my bad", "also mine :-("]}, {"url": "https://github.com/coreos/tectonic-installer/pull/443", "comments": ["Just to re-assure ourselves that we are doing the right thing here:\r\n\r\n1. If experimental mode is enabled (self-hosted etcd), then use `var.etcd_service_ip`.\r\n2. Else if **no** etcd TLS certificates are provided, i.e. we bootstrap etcd nodes ourselves (using `http`), then use insecure http `var.etcd_endpoints`.\r\n3. Else (if etcd TLS certific _are_ provided), then use the secure https `var.etcd_endpoints`.", "That would be a good comment to put in the code", "Yes, any endpoint computation should be done by the caller. Ideally, the etcd module of each platform should always output the right set of endpoints depending on the situation - it has all the required data. This avoids repeating the logic at any other places and simplify our implementation overall.", "Will keep it as is now and add a comment."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/442", "comments": ["Just curious, but why was this timeout increased?", "Jenkins executors are waaaaayyy to slooowwww sometimes and fails to execute TerraForm within a second, which usually takes about 100ms.", "It is actually on master already, we made the change at the same time with Dan. Just need to rebase for it to be gone."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/438", "comments": ["Sorry, I think my suggestion to combine this method caused this bug. Do you still need this check?\r\nhttps://github.com/ggreer/tectonic-installer/blob/bb32aa72d844c58f58705f8f7b1aacad4ec49eec/installer/frontend/cluster-config.js#L97", "Yes, for legacy cloudformation stuff."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/437", "comments": ["Releases has never been zips: https://github.com/coreos/tectonic-installer/blob/master/installer/scripts/release/make_release_tarball.sh", "how does this work without `export`ing the variable? does this work?", "this set of instructions is doing so many things at once that its confusing:\r\n1. choose your platform\r\n1. update the path to binary\r\n2. copy the sample and rename it\r\n", "Maybe add a `cp` step and then the `sed` after? This would give us an opportunity to say that you shouldn't share your `.terraformrc` as its specific to your machine.", "Depending on your shell it may work. I'll add an `export` just to make sure.", "Should be able to reference it now from the download :) https://github.com/coreos/tectonic-installer/pull/498"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/436", "comments": ["Won't compile. You need to add this variable to https://github.com/coreos/tectonic-installer/blob/a9b1e4c264d370679adc7a4d9432872b3032456c/modules/bootkube/assets.tf#L67.", "Won't compile. You need to add this variable to https://github.com/coreos/tectonic-installer/blob/a9b1e4c264d370679adc7a4d9432872b3032456c/modules/bootkube/assets.tf#L67."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/431", "comments": ["Separate imports so standard library comes first, ie:\r\n```go\r\nimport (\r\n\t\"encoding/json\"\r\n\t\"io/ioutil\"\r\n \t\"os\"\r\n \t\"strconv\"\r\n \t\"testing\"\r\n \t\"path/filepath\"\r\n\r\n\t\"github.com/aws/aws-sdk-go/aws\"\r\n\t... <rest of imports>\r\n)\r\n```\r\n", "Change to retrieve credentials from configuration [JSON](https://github.com/coreos/tectonic-installer/blob/05096c0/installer/server/aws_cluster.go#L41).", "Use cluster name from configuration JSON.", "Move name of tag key to constant at top of file", "Remove commented out logging before merge", "Use cluster name from configuration JSON.\r\n", "Instead of having the what's returned be determined by an argument, could we return a struct that included size, iops, and type? This way we could catch mismatches on specific volumes.\r\n\r\nie.:\r\n```go\r\ntype TestVolume struct {\r\n\tSize int\r\n\tIOPS int\r\n\tType string\r\n}\r\n```", "Have load path be determined by environment variable", "What if we returned a struct with each of the wanted pieces of information. Ie.\r\n```go\r\ntype TestVolume struct {\r\n\tSize int\r\n\tIOPS int\r\n\tType string\r\n}\r\n```", "Unmarshal into [CreateOperation](https://github.com/coreos/tectonic-installer/blob/05096c0/installer/server/create.go#L16) ", "The `aws.json` file will not have the actual credentials . How do you suggest we deal with that.", "nvm i realized our idea of keeping the json file on the server and loading it through env.", "As per our last discussion on slack, since there have been some changes to frontend/backend contract. I will hold on implementing all these changes."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/424", "comments": ["Perhaps;\r\n\"Our examples will use Elasticsearch as our logs\" -> \"Our examples will use Elasticsearch for log aggregation\"", "consider revise. \r\n\"based on metadata such as container name\"", "...locking stack for you. Instead, we provide recommended examples which you can use and customize for your organization's requirements.", "is configured using a configmap containing Fluentd config files which define how to collect the logs.", "Elasticsearch", "Installing the x-pack plugin for your nodes enables authentication to Elasticsearch by default.", "Modify the configuration to include the `user` and `password` fields:", "Then, set up all the service accounts and roles ...", "Next, deploy Fluentd:", "add a period at the end of the sentence.   / ... sections of the configmap.", "... Debian based Docker images ... \r\nI don't think docker repo gets capitalized. if you're referring to a file repo, it doesn't, but it gets ticks `docker`", "... check out their docs ...", "... done based on tags.\r\nI don't think tags needs ticks, and it certainly doesn't need an apostrophe.", "configuration defined ... tags records", "... logs ... Docker engine's logs ...", "This filter sets its `key_name` param ...", "... frontend component's logs\r\n\r\nor components' logs, depending on whether there are one or more components.", "do you want to leave the 'TODO' line here?", "Whoops, I meant to write `as our log storage destination`. Elasticsearch doesn't actually do \"log aggregation\", it just stores logs, so I don't want to mix up the terminology.", "either Elasticsearch or `elasticsearch`", "This part was actually copy and pasted from the comments in the upstream parser config for it, so I can probably can remove it.", "I'll update to `..will use Elasticsearch for log storage`", "I want to use the ticks, or something to call out the fact that `tag` is a concept of fluentd, and something that's part of the config file itself generally. What do you think?", "Actually, I think I found a better way to phrase it. ", "Spelling error? Should be recommended instead of recommend, or you can remove the word recommend. \"We provide examples which you can...\" or \"We provide recommended examples which you can...\".", "add `$` to all of these", "If we're not setting up auth, can we move this section down to the bottom?", "age old question of whether we should reference these web links which are convenient vs relative references for folks using via Github...", "Can we describe a bit of what is going on here?", "what does `reserve_data true` mean? Why do I have to explicitly turn this on?", "how involved is it to cover how to use each one of these in a section?", "Many setups of ES setup auth by default, especially in newer versions where `x-pack`, the plugin for enabling auth is installed. I think it's worth calling out since we're not making assumptions about how your ES is setup, except that we're expecting you to use ES.\r\n\r\nBased on our discussion OOB, I think moving these output related portions into separate file should help.", "It basically means, keep the original field around, even after parsing it. By default it would remove the original field, and you would be left with just whatever data it parsed out as new fields. http://docs.fluentd.org/v0.12/articles/filter_parser#reservedata. ", "\"The [customizing log destinations][customizing-log-destination] document explains how to configure where logs are sent.\"", "paragraphs are preferred to one sentence per line: https://github.com/coreos/docs/blob/master/STYLE.md#one-sentence-per-line-deprecated", "s/your//", "\"Fluentd routes events based on tags.\"", "\"For details on Fluentd post-processing, check out the Fluentd [fliters][fluentd-docs-filter] and [parsers][fluentd-docs-parser] documents.\"", "\"### Targeting a specific application's logs\"", "Prefabricated?", "s/pre-built/prefabricated/\r\ns/you can use//\r\ns/docker repository/registry/\r\ns/you can use//", "\"To change where logs are sent, change the image in [fluentd-ds.yaml][] to an image providing the necessary output plugin.\"", "The `output.conf` stanza in [fluentd-configmap.yaml][] must be updated to match the new output plugin.\"", "s/for you//", "\"Tectonic recommends several example logging configurations that can be customized for site requirements.\"", "s/Our/The/\r\ns,//\r\ns/your preferred/a/", "\"The Tectonic examples use Elasticsearch for log storage. Elasticsearch can be replaced by any storage mechanism Fluentd supports with an Output plugin.\"\r\n", "s/comprehensive//", "s/tectonic installer/Tectonic Installer/", "s/is run/runs/\r\ns/configmap Fluentd/ConfigMap of Fluentd/", "Ouch. I hate the diffs that result in this approach, but I'll do it. I'll do that all at once. After these other review items.", "I feel like the verb should be `built`, since the docker ecosystem is all about `builds`. What do you think?", "The technically correct term would still be repository, the registry is quay.io, repository is quay.io/coreos/fluentd-kubernetes.\r\n\r\nWhat about`repository` or `image repository` instead of `docker repository`.", "stray  \"'s\" - s/Fluentd's/Fluentd/"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/423", "comments": ["Leave as Tectonic FAQ -- despite the repo name, all tectonic documentation lives here, and this file contains non-installer info (about identity) already.", "this section might below in some of the admin/*.md ldap and auth oriented docs @radhikapc ", "version explanation should be retained", "license exceeded should be retained here or somewhere", "You've restored the text containing the links these labels define, so you need these lines again as well"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/418", "comments": ["To avoid having issues if those are modified in config.tf, you can keep the values blank. So you'd only care if they are renamed in templates.", "please use `cat /dev/urandom` \u2622\ufe0f \ud83d\ude44", "do you need the function?", "good idea", "Removed", "no badass code", "Why so silent?", "@marineam There is a lot of terraform messages printed to the stdout, which is noisy, I made debugging message print to the stderr, so it's ok.", "The distance to all the other terraform sources is pretty big, down in `installer/scripts/update-payload`. As maintaining `*.tf` source code is not as convenient as go-code (or any statically typed/compiled language) I suggest to move this to `/modules/update-payload` as we are doing most of the work using awk/ag/grep there.", "The indentation seems to be inconsistent (1 vs 2 spaces)", "Same comment as above", "@s-urbaniak I have the same impression. Will do", "Good catch", "needs to be: `1.6.2-tectonic.1`\r\n\r\nhttps://coreos.com/tectonic/docs/latest/troubleshooting/faq.html#tectonic-release-versioning", "https://coreos.com/tectonic/docs/latest/troubleshooting/faq.html#tectonic-release-versioning", "@sym3tri It's generated from the config.tf, we need to change there.", "We discussed with Rithu already. No problem. RC.1 will be cut without it, since KVO/TCO will need to be updated anyways too."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/417", "comments": ["Unrelated to this PR, but did anyone fix this for openstack yet? I think that's the last platform that was broken by https://github.com/coreos/tectonic-installer/pull/397", "It is not fixed yet for Openstack; the etcd-operator implies a bigger overhaul of the openstack module.\r\n\r\nAs a stop-gap solution I will submit a quick-fix PR to at least be able to deploy, but we will tackle feature-parity as a general overhaul after the release which involves the following TODOs if the etcd operator is enabled:\r\n\r\n- optional provisioning of etcd nodes\r\n- optional provisinioning of etcd A-records\r\n- optional provisioning of etcd security groups", "Just a small comment: I use a not-yet-merged feature from terraform-docs [1] to omit the `Required` column. See [1] for the rationale. Do you don't mind to use a version of `terraform-docs` with my patch applied?\r\n\r\n[1] https://github.com/segmentio/terraform-docs/pull/28"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/416", "comments": ["_an_ AWS private domain name, perhaps?", "If this is a document describing how to use the installer using the CLI, they don't need to run the GUI at all.", "Oh right, this is a good point.", "I thought the whole point of the installer was that it was launched and accessible in a browser. I also thought the move to this installer was to make setup easier for the less technical people, who could progress from easy GUI to full CLI use as they wish. Is there a way to run through the installer using the CLI only?", "actually, with my better understanding now, let me edit this a little. ", "Discussed offline."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/415", "comments": ["Won't this break if there are fewer AZs used for masters than for workers? Is this case possible?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/412", "comments": ["v0.6.0 doesn't have a link defined", "I _think_ we can actually link here to `https://github.com/coreos/matchbox/blob/master/Documentation/network-setup.md` and get rewritten properly\r\n\r\n/cc @crawford ", "(not a blocking comment)", "woops, fixed", "At the moment it points to https://coreos.com/tectonic/docs/latest/install/bare-metal/network-setup.html, which is the network-setup.md I deleted in this PR. The upstream of it is matchbox https://coreos.com/matchbox/docs/latest/network-setup.html which has some nice improvements.\r\n\r\nWe either want to delete Tectonic's duplicate of network-setup and link out or keep syncing it with the upstream.", "Linking to the matchbox repo will get rewritten properly.", "Should I link to https://github.com/coreos/matchbox/blob/master/Documentation/network-setup.md \r\n or you're just saying it would work. I'm not sure of the docs team's convention here? ", "yes, that link"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/409", "comments": ["s/On the Tectonic UI/In Tectonic Console/", "delete extra tab or spaces after \"see\"", "s/attache/attach/", "Aren't steps 2 and 3 saying the same thing? Should they be combined?\r\n\r\nAlso, \"Verify the pods are patched.\" seems to belong _after_ the `kubectl patch` command below. And once moved there, it just repeats what the reader is told. So I think  \"Verify the pods are patched\" could be deleted.", "s/log in back/log in again/", "replace with: \"Configuring RBAC\"", "s/in the Tectonic UI/in Tectonic Console/", "s/the Tectonic UI/Tectonic Console/", "s/log in back/log in again/", "s/the Tectonic console/Tectonic Console/ (sorry for missing this)"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/407", "comments": ["make it singular", "need a space between `__beta__` and `support` for bold to work", "`__master_` has two underscores on one side and one on the other", "@squat (using this PR as a communication mean): we should have that 'no' gone - is it being considered/worked on at all?", "`control plane` for consistency", "I think we need an overview of these terms since they are a little confusing at first...you don't see them typically used to describe infrastructure. How about something like this:\r\n\r\n> Taints are an attribute or marker applied to a node that describe a special property. Before a pod is scheduled to this node, it must tolerate the taint. Tolerations are supplied with the pod object.", "It might be good to hint that most users aren't affected by this. Why? Because your users didn't change their pod specs, nor should they have to.\r\n\r\nRewrite to make it a bit simpler and imply answers to these questions:\r\n\r\n> Every Tectonic _master_ node registers themselves to the cluster tainted. Since most pods will not tolerate this taint, they will be scheduled only to worker machines. This behavior includes pods generated from Deployments, ReplicaSets, and [DaemonSets][ds-tolerations].", "We don't use the word \"pinned\" in a lot of docs. Is there another way we can describe this?", "Every Tectonic master node registers itself to the cluster tainted.", "The following table can serve as a reference for scheduling the control-plane's components, as of Tectonic 1.6.2.", "Every Tectonic master node registers itself to the cluster tainted.", "The following table provides a reference for scheduling the control plane's components, as of Tectonic 1.6.2.", "Should link to https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#taints-and-tolerations-beta-feature in here somewhere", "Anti-affinity is on here. See: https://github.com/kubernetes-incubator/bootkube/issues/488", "Yes as it seems so, regardless of what kubectl says."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/403", "comments": ["Do we actually need to list all the subpackages?", "Just copied from glide.lock, perhaps not"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/397", "comments": ["Why not true by default?", "It is quite idiomatic not to set default values in modules, as per recommendation from @alexsomesan. It can become difficult to debug where default values come from. Therefore we decided to declare defaults in platforms only.", "I think this line broke terraform apply for all platforms except AWS. It's been fixed in bare metal (https://github.com/coreos/tectonic-installer/pull/411) but not openstack or azure."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/385", "comments": ["Should be `Standard_DS2_v2`, there is no `Standard_DS2_v2_v2`", "Heh, whoops, find and replace gone amuck"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/383", "comments": ["\"an official release\" from coreos.com/tectonic", "I wanted to avoid linking to this until we had an official release that is backed with Terraform", "makes sense"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/381", "comments": ["i think these need to be `\"false\"` with quotes.", "Thanks. Fixed."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/380", "comments": ["This ignores all directories named bin in the repo. Is there a specific bin directory you want to ignore? If so, it's best to prefix with /"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/377", "comments": ["Nitpick: If you have an else, why invert the conditional? Just swap the bodies.", "I think errCtx check can be moved out of the if/else, reducing repetition. Code golf! \u26f3\ufe0f", "Yeap but typically had the exact opposite review on projects like Clair for readability reasons.", "Just to have the usual case first. Can swap if you want."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/376", "comments": ["This guide uses `make`... (drop \"of\")"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/372", "comments": ["Do you think you could make it so we only unzip once? Can we use the `cmd1 | tee >(cmd2) >(cmd3) | cat` pattern maybe? Not so sure because Make makes things weird.", "You don't need to use a globbing rule here. `/build/` will ignore the build directory. `build/**` will ignore things you might not want to. eg: `vendor/whatever/build/something`\r\n", "It's pretty ugly as it is. Actually `unzip -Z1` only outputs the archive index (zipinfo) so it's not a full-weight unzip operation. Doesn't really feel like a bottleneck. But maybe we can get rid of this altogether (like discussed here).", "good point! i'll fix that.", "yes, we had so much trouble with vendors and that."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/370", "comments": ["why add optional when we have a required column?", "Right, this does look strange indeed.\r\n\r\nWe have a general issue though: Terraform implies a variable being required if you don't specify a default value, see [1]. Only if you leave out a default value the above \"Required\" column becomes a meaning.\r\n\r\nThe reality is, we specify a lot of default values for variables that are indeed required but for whom we provide a sane default, like i.e. default CIDR values.\r\n\r\nFurthermore we also specify quite some default empty string values `\"\"` for variables which indeed are required, but we still cannot leave them out to mark them as required because of a limitation in terraform where those values are being used in ternary operators.\r\n\r\nLong story short: My suggestion is to patch `terraform-docs` to simply not output the \"Required\" column, because its meaning does not bring any value in reality. Does that sound reasonable/acceptable?\r\n\r\n[1] https://www.terraform.io/intro/getting-started/variables.html#defining-variables", "Sure, that sounds good to me", "\"none\" might be more clear here, but I don't feel really strongly about it"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/360", "comments": ["Here too.", "I think you need to change the temporary secrets mounts since we did https://github.com/kubernetes-incubator/bootkube/pull/437\r\n\r\ncc @dghubble ", "With the way Tectonic is doing this, updating https://github.com/coreos/tectonic-installer/blob/master/modules/bootkube/resources/bootkube.sh#L9 would be the way to go", "updated to stop mounting /tmp and use the new location", "Testing on bare-metal, this file could not be found, though it is present in the host's /etc/kubernetes directory.", "the `path` under `hostPath` in the volumes below wasn't indented properly. Just pushed up a fix."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/359", "comments": ["Before, I think the backend was probably adding http:// + endpoint", "I would really replace all these by:\r\n\r\n```\r\ncmd.Env = os.Environ()\r\ncmd.Env = append(cmd.Env, fmt.Sprintf(\"TERRAFORM_CONFIG=%s\", ex.configPath))\r\nfor k, v := range ex.envVariables {\r\n  cmd.Env = append(cmd.Env, fmt.Sprintf(\"%s=%s\", strings.ToUpper(k), v))\r\n}\r\n```\r\n\r\nSeems way saner.", "It's not clear whether we want to import all env vars. Eg: My personal AWS creds or region, or terraform-related environment vars that the user might happen to have set. (https://www.terraform.io/docs/configuration/environment-variables.html)\r\n\r\nI erred on the side of safety and only passed-through variables that I needed.", "They might be set, it should not really matter if they are in our use-case- they will be overwritten by `ex.envVariables` if necessary. I don't want to end up with 15 lines of obscure/barely documented env passthroughs that we will never be able to get rid of. I'd rather either have them all passed, or at least have a non-exported global variable that will whitelist them, with the exact documentation of which provider / use-case they are for.", "For now, I think we should pass just what is needed to fix terraform SSH execution and get this PR to work.", "Passing all environment variables would practically guarantee breakage for some users in the future. I just tried your patch with TF_LOG and TF_LOG_PATH set in my zshrc, and I didn't see some logs in the installer GUI.\r\n\r\nEven if we blacklisted those variables today, Terraform can add new vars that change its behavior without us knowing. We'd have to play whack-a-mole blacklisting them whenever we updated terraform. Likely, we'd only notice when some user complained about the installer not working for them.\r\n"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/334", "comments": ["@Quentin-M @squat any idea why we're not seeing any Pods in the `tectonic-system` namespace during the smoke test?\r\n\r\n/cc @ericchiang\r\n\r\n**[Smoke Logs](https://jenkins-tectonic-installer.prod.coreos.systems/job/coreos%20-%20tectonic-installer/job/tectonic-installer/job/PR-334/20/console):**\r\n```\r\n[TerraForm: AWS]     \tk8s_test.go:133: Failed to get Pod logs with error:  failed to find tectonic-identity pod (found pods in tectonic-system: )\r\n[TerraForm: AWS]     \tk8s_test.go:140: Failed to gather logs for tectonic-system/tectonic-identity* in 3m0s\r\n```", "should be there", "Sounds flaky. I'd rather we remove flaky tests and add them back later once we figure out the causes.", "Right now we are skipping this but it seems to be a misconfigured pull secret, I'll fix in a later PR.", "I was able to test it locally but it just doesn't work on jenkins.", "what does that involve? you can easily grep it out of the tfvars file!", "RBAC?", "I'll add that for now but I'd like to have a more defined way of doing this eventually", "The most straight forward way to see that is to `journalctl -u {tectonic,bootkube}` on the the master instance of the lowest Instance ID.", "Updated.", "@Quentin-M I think it's just a bad credential in Jenkins:\r\n\r\nTectonic logs from bootkube instance:\r\n```\r\nThe Secret \"coreos-pull-secret\" is invalid: data[.dockerconfigjson]: Invalid value: \"<secret contents redacted>\": invalid character 'e' looking for beginning of value\r\nMay 02 22:46:57 ip-10-0-28-10 bash[4033]: [  274.027778] hyperkube[5]: kubectl failed, retrying in 5 seconds\r\n```", "Definitely! Your secret is invalid. Your `tectonic_pull_secret_path` file has has to contain something such as:\r\n\r\n```\r\n{\r\n  \"auths\": {\r\n    \"quay.io\": {\r\n      \"auth\": \"<redacted>\",\r\n      \"email\": \"\"\r\n    }\r\n  }\r\n}\r\n```\r\n\r\nThe format changed between the legacy installer and this one.", "@Quentin-M Going to enable checks in another PR to give them some soak time and get these checks in."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/333", "comments": ["This account is going to be a fun ride to clean up :)\r\nBut I guess it's the best we have so far."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/325", "comments": ["This creates a circular dependency. `assets/bindata.go` is in `assets/`", "Why did you delete this test? We were using this!", "All of these example progress files were used by our front end tests.", "I thought this was only for comparing with the JSON examples to the backend's create endpoint, which we don't use anymore.", "I see, I can follow up to grep this one out.", "Just like the progress files, we needed these for the front end tests.", "Prefixing with an `@` doesn't echo the command, making it harder to debug what's going on.\r\n\r\nIf doc.go & assets.go are ignored by go-bindata, shouldn't they also be removed from Makefile dependencies? Right now, `shell find \u2026` will catch them.\r\n", "This broke downloading assets. The HTTP method for that is GET, not POST. Fixed in https://github.com/coreos/tectonic-installer/pull/674"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/324", "comments": ["I think that regardless of whether they are used once or not, we were having them in common.env.sh to ease bumping."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/304", "comments": ["maybe add a `-p` just to be safe?", "-p should only be needed is workspace is not clean and bin exists. In that case, if the dir already exists then medir exits non zero and cause the whole script (with set -e) to fail. also, touch will fail if bin/sanity already exists"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/294", "comments": ["Do you mind to change the corresponding line in https://github.com/coreos/tectonic-installer/blob/1b4c579/modules/tectonic/resources/tectonic.sh#L130?\r\n\r\nJust replace:\r\n```\r\nkubectl create -f monitoring/prometheus-k8s.json\r\n```\r\nwith\r\n```\r\nkubectl create -f monitoring/prometheus-k8s.yaml\r\n```", "The same comment as above applies here regarding https://github.com/coreos/tectonic-installer/blob/1b4c579/modules/tectonic/resources/tectonic.sh#L167.", "done", "done"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/287", "comments": ["we need to start migrating terminology s/controller/master/", "so this creates a map that looks like:\r\n```json\r\n{\r\n    \"az1\": \"172.16.0.0/27\",\r\n    \"az2\": \"172.16.0.32/27\",\r\n    ...\r\n}\r\n```", "Correct. That's the format that terraform wants.", "I almost think we should hardcode `instanceCIDR` rather than pass it as an argument to `toSubnetObj`. How abstract is this function really?", "Sometimes 'instanceCIDR' is passed in, sometimes 'id' is. This code will become cleaner once we remove cloudformation stuff (which needs the different keys)."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/285", "comments": ["Where does this come from?", "Should there be a separate check if the customer is using the old installer?", "@amrutac This is an hardcoded value in the coreupdate server.", "Hmm... I'm not sure what you mean. This function (`toAWS_TF()`) is only called if using the terraform installer. The old cloudformation behavior remains the same.", "Oh OK, just wanted to make sure this doesn't apply for the old cloudformation clusters.", "OK."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/283", "comments": ["Can't `$(eval echo ${TERRAFORM_BIN_URL})` just be `\"$TERRAFORM_BIN_URL\"`?", "Both $TERRAFORM_SOURCES and $TECTONIC_RELEASE_TOP_DIR should be in double-quotes to prevent globbing or undesired behavior due to spaces in them.", "It can't (late evaluation).\r\n\r\n```\r\n\u279c TERRAFORM_BIN_VERSION=0.8.8\r\n\u279c TERRAFORM_BIN_URL='https://releases.hashicorp.com/terraform/${TERRAFORM_BIN_VERSION}/terraform_${TERRAFORM_BIN_VERSION}_${os}_amd64.zip'\r\n\u279c os=darwin\r\n\u279c echo \"$TERRAFORM_BIN_URL\"\r\nhttps://releases.hashicorp.com/terraform/${TERRAFORM_BIN_VERSION}/terraform_${TERRAFORM_BIN_VERSION}_${os}_amd64.zip\r\n\u2717 eval echo $TERRAFORM_BIN_URL\r\nhttps://releases.hashicorp.com/terraform/0.8.8/terraform_0.8.8_darwin_amd64.zip\r\n```", "Ah. That makes sense.", "Well actually adding the quotes around $TERRAFORM_SOURCES broke the script. It contains multiple paths on purpose."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/279", "comments": ["Probably label this as \"1.5.6-tectonic.1\" too", "This has to fit in a dropdown, so it can't be much longer than it currently is. I updated it to 'Amazon Web Services (CloudFormation, legacy v1.5)'\r\n\r\nAny better ideas to express to the user \"this will install old k8s/terraform\"?\r\n", "SGTM. Abbreviating as `AWS` is also fine if you need more space."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/277", "comments": ["Add version?", "what is our minimum version requirement?", "=0.8.8", "thanks. updated.", "It's actually locked to `0.8.8` exactly.", "Might want to link to https://releases.hashicorp.com/terraform/?_ga=1.63881647.1040612097.1492717955 for older releases.", "thanks, updated"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/276", "comments": ["Is it intentional you've stopped running these containers on Kubernetes?", "For now until we can get the executors running correctly"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/273", "comments": ["extra", "Won't lines 12 & 13 still match all kinds of stuff that we probably don't want to match?", "I think these names are pretty specific?", "Any directory named \"generated\" or any directory named \"bin\"? I could see those existing in vendor.", "this takes care of line 3 in installer/.gitignore. the other is unnecessary.", "I don't think any of these besides `/matchbox` should have the `/` prefix."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/272", "comments": ["can we call this something related to \"etcd\"? or do you see it being used for other intermediaries?", "Since this doesn't have any variables (vars block of template_file) to interpolate, I wouldn't use a template_file. It looks kind of abusive here :)\r\nYou could just use the expression from template directly wherever is need. ", "Just bending the rules ;-)\r\n\r\nBut agreed, I was envisioning more redundancy here, I can copy the expression for the `bootkube-bootstrap` and `bootkube` `template_folder`s.", "good catch, I used to call it `etcd` a few iterations back, but I will revert to that, thanks!", "self-note: this won't work for azure"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/267", "comments": ["The above interpolation (and the following ones) is pretty complex. I suggest we add a comment explaining what this does, especially the `list(\"padding\")` workaround which makes the `element` function happy in case `worker_subnets` is empty and the `cidrsubnet` logic.", "The same applies here, I suggest we add a doc comment above.", "My plan is to move these expressions on the module inputs.\r\nIt would spread out the verbosity and make the resources read more cleanly.\r\n\r\nI will then add documentation on the module inputs, which would all be in one place."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/266", "comments": ["should be templated from vars", "This is called out in non-goals. I see there are lots of values you guys are trying to template in which I haven't switched over to variables yet. I'd like to do this in a followup", "There are also quite a few bare-metal specific things that should be exposed as variables which are not yet (install_disk /dev/sda, etc)", "ack", "`kubeconfig.path`?", "make sure to run `make structure-check`\r\n\r\nI think your templates won't pass because you do not align the `=`.", "The name is supposed to match the systemd service that it activates.", "kubeconfig is an output of the bootkube module. Generally speaking, `depends_on` is to avoid in TerraForm. Instead, I would use the bootkube's kubeconfig output as the `content` parameter in the file provisioner. Thus, TerraForm will smartly determine the earliest time it can run your null_resource (as soon as both the output and the controller/worker domains are available - rather than waiting for the full tectonic module (should be bootkube anyways).", "Ok, I can add that. Though this scp isn't going to succeed until ~10 minutes later when the nodes have booted, installed, and rebooted.", "Similarly here, instead of using a `depends_on`, could maybe leverage archive_file and any of its output (e.g. `output_sha`) - that you could use as a trigger even.", "Should we have the unit enabled but waiting for the assets to be there? So it would not block the execution. But I guess it does not really matter anyways for now because we are blocked until the assets can be uploaded.", "You can here the HEREDOC format and save you (and the users) the trouble.", "(see below)", "ack", "gotcha yeap", "Fixed", "Fixed to remove the depends_on.", "I added a comment and fixed this depends_on. Its pretty important that it happens after null_resource.kubeconfig so I think this use is justified.", "Fixed", "I figured I'd follow the pattern from azure and openstack and it seems to work ok. Splitting that logic btw terraform remote calls and on-host units might make bare-metal harder to read so I didn't want it to differ from the others.", "`--working-dir` has been introduced in rkt 1.19.0 (see https://github.com/rkt/rkt/commit/1468df88578d4f4b6fff3a0d9242570b865c10f0) and after digging through https://coreos.com/releases/ I see that 1235.12.0 (Feb 23 2017) is the last CL version being on rkt 1.18.0. Are you using an older CoreOS version?\r\n\r\nAnyways, I am fine with removing this directive here to keep things backwards-compatible as we are `cd`ing into the assets directory in `tectonic.sh`.", "Just to add a little salt to this discussion, I am also currently fine with this solution, as it is easier to read. The way we solved it in AWS, namely enabling but enforcing at-most-once execution using `/opt/tectonic/init_tectonic.done` files, is a bit fragile.", "Ah, now I see why `--working-directory` might have not worked for you, see my comment above.", "We already have a variable named `tectonic_cl_channel` in `config.tf`, this seems to be in conflict.", "I believe this is also in conflict with `tectonic_base_domain` in `config.tf`.", "Sounds fine! We mainly did that for AWS for other reasons (we don't know anything about the instances in the ASG).", "As this is a matchbox specific configuration, I suggest to prefix this as `tectonic_matchbox_cl_version`.", "Generally, we follow the convention of using `tectonic_cl_.*` rather than `tectonic_coreos_.*`, so I suggest to rename those variables.", "The current convention is to use the concatenation of `tectonic_cluster_name`.`tectonic_base_domain` for the ingress.", "We switched the general convention `master` rather than `controller`.", "Also, if this is a `matchbox` only setting, I suggest to prefix this and the variables below as `tectonic_matchbox_.*`.", "Yeah, CI deploys at 1235.9.0 and I bet plenty of users have different versions cached in the provisioner node too. This flag doesn't seem needed so let's not require it since that limits compatible CL versions.", "They're used for different purposes, but I can rename. This is the channel which contains the version listed above, from which to do the install to disk.", "Yeah, I noticed this. Tectonic Installer kinda copied the Tectonic GUI AWS implementation, but there are various cloud-centric aspects of that. On bare-metal, there is no zone name such as \"mydomain.com\" where subdomains like \"cluster-k8s.mydomain.com\" and \"cluster-tec.mydomain.com\" and \"etcd-0.mydomain.com\" are created.\r\n\r\nTwo FQDN's are provided, one for controllers, one for Tectonic Ingress which RR's between workers. There is no requirement for them to be the same base domain. Described [here](https://coreos.com/tectonic/docs/latest/install/bare-metal/index.html#networking).\r\n\r\nMaybe we call these `tectonic_metal_controller_domain` and `tectonic_metal_ingress_domain` (or master, depending on below)? base_domain is listed at the bottom as unused.", "Sure", "See note above", "In the GUI installer, the names were \"aws\" and \"metal\" so I'm for prefixing with `tectonic_metal_` so as not to confuse fields with matchbox, the service and its fields client_key, client_cert, etc.\r\n\r\nMaster instead of controller? The other clusters from CoreOS standardized on controller (coreos-kubernetes, matchbox/examples, bootkube, Tectonic GUI installer). Why the reversal?", "Updated to 1298.7.0, but I still think we want the flag removed", "Using tectonic_cl_channel, I'll add a note about how on metal this MUST correspond to the channel of the tectonic_metal_cl_version for the disk install.", "Updated to tectonic_metal_controller_domain", "Updated to tectonic_metal_cl_version", "Updated to tectonic_metal_ingess_domain\r\n\r\nI think this new platform surfaces the idea that the inputs to the tectonic module should be the controller/master FQDN and the Tectonic Ingress FQDN and its a platform decision how those are constructed. But I've tried to minimize changes to existing modules.", "tectonic_metal_controller_names and awaiting response about master vs controller. I don't think its likely the other projects will switch back, but maybe for Tectonic Installer its fine ", "Note this means when you guys get your CI setup again, that's the version to cache", "Is the new `Type` column implied by Terraform 0.9? I suggest that we align the format with the other config markdown files (can be done in a follow-up PR).", "As this PR moved the variables to `tectonic_metal_.*`, does it make sense to move these too?", "Hm? This is what the doc generator produces", "Yeah, it would match the others", "Don't worry, I can regenerate those as a follow-up. May indeed be an implied column picked up by a tf 0.9 present in `GOPATH`.", "Fixed"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/259", "comments": ["Note that this is a bit inconstant since we normally leave the fields empty instead of un-commenting them."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/256", "comments": ["Maybe we could also call this \"root_volume_iops\", to keep all of them aligned?\r\n\r\nAlso goes for the correspondents inside the modules.", "I am adhering to the upstream naming conventions which calls them `volume_type`, `volume_size` and `iops`, but I can make it consisten here."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/251", "comments": ["It'll fail if the file does not exist right? Should we add a dependency to avoid that?", "I thought the plan was to move away from using the kubelet.env file? Or maybe I'm mistaken, I missed the plan and saw the bootkube changes cc @yifan-gu ", "The kubelet will crash-loop until init-asset is done, and a general dependency on it will hurt on reboot, because init-asset is started during installation only. There could be a more elegant general solution, but until then I am fine with this dependency on the envelope file.", "A nit might be to clean up `/etc/kubernetes/kube.version` file if it is never expected to be used again", "`kubelet.env` will be prepared either by `init-assets.sh` (on the leader master node), or `kubelet-env.service` (all other nodes, including non-leading master nodes).\r\n\r\n`kubelet.service` will crashloop until the `kubelet.env` is prepared. \r\n\r\nI am not using a dependency because it will make `kubelet.service` fail permanently if the service that `kubelet.service` depends on fails.\r\n"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/246", "comments": ["Can we also bump heapster from 1.3.0-beta.0 to 1.3.0; https://github.com/kubernetes/kubernetes/blob/v1.6.1/cluster/addons/cluster-monitoring/standalone/heapster-controller.yaml", "Thanks :) Addressed.", "this should be unnecessary since all beta API groups are enabled by default", "We should remove this since we are not enabling any alpha API groups and do not want to unknowingly depend on them.", "Smart! I didn't know that. Let me remove that line then.", "I agree. I simply copy-pasted whatever is in bootkube here without modifications but for templating purposes. Generally want to stay as close as their manifests as possible. Do you think we should still drop it?", "@aaronlevy Is there a specific reason this is here?", "Yes I think so. We had a story that explicitly asks to disable allowing all alpha features by default. If a user really wants to use alpha API features then they can always modify this daemonset.\r\n\r\nhttps://github.com/coreos-inc/tectonic/blob/master/docs-internal/alpha-features.md\r\nhttps://www.pivotaltracker.com/story/show/137556789", "Only exists for flexibility - but I am 100% for removing this.", "We may need to explicitly allow TPRs though -- that is still technically an alpha feature", "We should update this to the upstream recommended list: https://github.com/kubernetes-incubator/bootkube/issues/438", "Added issue to track this generally: https://github.com/coreos/tectonic-installer/issues/249", "@aaronlevy TPR is v1beta1", "https://github.com/kubernetes-incubator/bootkube/pull/440", "Addressed.", "Addressed.", "Can we just use `operator: \"Exists\"` here?", "`operator: Exists`", "`operator: Exists`", "`operator: Exists`", "`operator: Exists`", "`operator: Exists`", "Was just using what you guys have in https://github.com/kubernetes-incubator/bootkube/blob/85036e7/pkg/asset/internal/templates.go. Fixed.", "Was just using what you guys have in https://github.com/kubernetes-incubator/bootkube/blob/85036e7/pkg/asset/internal/templates.go. Fixed.", "Was just using what you guys have in https://github.com/kubernetes-incubator/bootkube/blob/85036e7/pkg/asset/internal/templates.go. Fixed.", "Was just using what you guys have in https://github.com/kubernetes-incubator/bootkube/blob/85036e7/pkg/asset/internal/templates.go. Fixed.", "Was just using what you guys have in https://github.com/kubernetes-incubator/bootkube/blob/85036e7/pkg/asset/internal/templates.go. Fixed.", "Was just using what you guys have in https://github.com/kubernetes-incubator/bootkube/blob/85036e7/pkg/asset/internal/templates.go. Fixed."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/226", "comments": ["I don't see `dexAPIHost ` in https://github.com/coreos/tectonic-installer/blob/660bf8b/modules/tectonic/resources/manifests/config.yaml?", "yes you are right. we need an entry in this file similar to what we have in the tectonic repo:\r\ndata[\"dexAPIHost\"] = fmt.Sprintf(\"%s:5557\", tectonicIdentityAPIService)", "the tectonicIdentityAPIService variable will have to be defined in https://github.com/coreos/tectonic-installer/blob/master/modules/tectonic/assets.tf#L7 as well", "Variables to that file come from https://github.com/coreos/tectonic-installer/blob/660bf8b/modules/tectonic/assets.tf#L7", "As discussed online, I'd rename the `kube_apiserver_url` variable to `kube_apiserver_endpoint`, remove the scheme/port in the tectonic module's callers, and add it back in the templating - so you can also create the dex URL with that variable."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/225", "comments": ["Looks like the format of this is changing.\r\n\r\n@squat will this affect any of the assumptions in the spartakus work?", "This will work fine and does. It violate any assumptions. We generate random UUIDs to ensure no PII was leaked; for all other reasons the cluster_id could just as well be `aleks_cluster`."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/219", "comments": ["?", "?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/207", "comments": ["@ethernetdan If you check the Tectonic repo's Jenkinsfile, there is a tip about avoiding writing logic like this in the Jenkinsfile directly. Can you place this in a script which gets invoked please?", "You can use the Jenkins declarative pipeline `post` feature as well, to ensure a certain cleanup script or task is always run at the Jenkins level.", "@ethernetdan thanks! Will need this for the prometheus operator e2e tests. :)", "That's a good point! We should make use of the post step for cleanup."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/196", "comments": ["Tag?", "Done"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/195", "comments": ["In AWS we set these with a variable `--node-labels=${node_label}` who's value comes from `kubelet_node_label` that you already added below.", "whoops, good catch!", "also seems to have conflicts :("]}, {"url": "https://github.com/coreos/tectonic-installer/pull/188", "comments": ["do the AWS sec groups need to be updated too?", "not yet, but I am already taking the 4789 port into account for the current AWS SG refactorings."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/175", "comments": ["This should be dropped, no?", "I discussed this with @s-urbaniak earlier as well, and this is currently the way to go. I still eventually see only the tectonic-prometheus-operator being created, and that in turn populates the cluster with everything, so we don't include any monitoring related things in these templates anyways.", "Ah right, my bad \u2013 we discussed already that we create a stock setup regardless."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/163", "comments": ["Discussed offline, looks like `.*` is not required. The resource will exist anyways. The FQDN might be an empty string but that's fine.", "This is an Azure-specific variable. It should not be in that configuration file but in `platforms/azure/variables.tf`. Can we fix that please? It should also be named `tectonic_azure_...`."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/159", "comments": ["nit: Double space then LGTM."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/157", "comments": ["whoops :)", "Openstack uses Route53? I get that its valid, but..."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/137", "comments": ["@s-urbaniak can you take a look at this? this worked in my testing, but what do you think about including this by default, instead of commented out?", "Why pin to a specific tag? I thought the point of this is so that people can use the latest version as it will be evolving quickly. Also supported versions will skew by platform.", "Why not put these descriptions inline in the example vars file too?", "I was hesitant to do that for this initial sync until we get our testing process down more, but I guess that is the entire point..", "We could. I also don't know what the future of the other variable docs that are already out of date. seems like we should remove them.", "How do we sync that up with the customized binary?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/135", "comments": ["this is fixed on 1.6. we can get rid of it."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/128", "comments": ["s/ressources/resources"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/124", "comments": ["you can just use $2, same below $got_name so the script works without templating.", "can you use escape sequences instead? can't read `contains(\"'\"'\"$${1}\"'\"'\"))` :1st_place_medal: "]}, {"url": "https://github.com/coreos/tectonic-installer/pull/121", "comments": ["\ud83d\udcaf  \ud83d\udcaf  \ud83d\udcaf  \ud83d\udcaf  \ud83d\udcaf  \ud83d\udcaf  \ud83d\udcaf  ", "Do you still need this with the new trick?", "These are new top-level variables for AWS? I'll add them to the upstream installer's var gen. Great catch. ", "Can you add them to the Documentation.md too?", "Also, `terraform.tfvars.example`.", "Yeah, those are needed to import existing subnets. I noticed the installer is asking for them if you choose to install in an existing VPC.\r\n\r\nI'll ad them to the docs, too.", "Nope, not needed. I have to revert those lines.", "It seems that we expect to have subnet IDs here, right? Could you either add `_ids` (e.g. `tectonic_aws_external_master_subnet_ids`) or document it where we can at least?\r\n\r\nThis will become harder and harder overtime if we don't clearly specify the expected format (just like for etcd endpoints.. spent time yesterday figuring out). \r\n\r\nTell me what you decide for the name, and I'll finish wiring them upstream. Thank you! ", "You're right. Variable names should contain some kind of hint (such as suffixes) as to what \"type\" of data is expected.\r\nI like the idea. Let's stick to it for the future and also document it somewhere."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/108", "comments": ["This is entirely broken anyways.", "It has to be:\r\n\r\n```\r\n  value = [\"${split(\",\", join(\",\", var.external_endpoints) == \"\" ? join(\",\", aws_route53_record.etc_a_nodes.*.fqdn) :  join(\",\", var.external_endpoints))}\"]\r\n```", "We used `compact()` on the module input parameter `external_endpoints` ([here](https://github.com/coreos/tectonic-installer/pull/108/files#diff-9324b17a8ee19fe53479ca78a83caad7R23)) to turn it into a \"true\" empty list, so now the length() returns zero as expected.\r\nApparently others have hit this and there was a recommendation in that sense in one of the historic issues of Terraform.", "Oh. You are changing the type of the return from a list to a string, and use split elsewhere. I see."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/92", "comments": ["on master we have a couple of retry options now set to curl, see https://github.com/coreos-inc/tectonic-installer/blob/b56906f/modules/tectonic/resources/tectonic.sh#L17. Is this still necessary to bump to 15 seconds given that?", "I know, this was just for the test. Thanks.", "Just a nice to have for future stuff.\r\nWould be cool to have changes like this, when unrelated to the topic of PR in a different PR. It helps going through both of them faster and ultimately allows us to move on faster.", "We should avoid nesting modules inside modules. In the past I've seen this to cause 'destroy' actions to misbehave.\r\n\r\n@bison also mentioned beeing bitten by this thing\r\n\r\nCan we not call the ignition module in main.tf and pass outputs into the master and worker modules?", "Calling this just 'count' can be confusing as there also is a built-in variable of Terraform with the same name.\r\n\r\nCan we do worker_count instead?", "Same comment about nesting as for master.", "What's the reason for dropping the standalone DNS module?", "To be more homogeneous as etcd creates its own records, the master\r\nmodule should do so too, and to to simplify a bit because the master modules creates ELBs that are then assigned to records in the DNS modules, which is kinda overkill.", "Sure, if you are worried about it, I can change it :) Thanks!", "What about `instance_count`? I'd like to avoid repeating context. We are already in the master/worker modules.", "`instance_count` sound perfect. Anything but `count`, actually.", "Sounds good that way too.\r\nActually the reason why the etcd records are in the `etcd` module and not in `dns` is because they are consumed back by etcd itself for discovery.\r\nThe same actually goes for the API endpoints, so using the same logic they are better placed in the master module, like you suggest.", "Was this rebased the other way around?\r\nThe rest of the module seems to use the `length(var.external_endpoints) == 0 ? ` type of condition."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/89", "comments": ["I feel like we should just drop this section of TODOs. I don't know what is gained by having them here.", "should be platforms/aws/README.\r\n\r\nAlthough, I feel like we should move these into Documentation/", "shouldn't these go into Documentation/\r\n\r\nAlso, give it the title AWS with Terraform?", "I did this locally to triage the openstack networking options. I needed only to change a couple of options in the apiserver (mainly remove the oidc settings) to make this work. I'll set up a PR for this.", "I think those links need to be `platforms/<platform>/README.md`", "I think we should put these docs in the Documentation folder so it can be pulled up to coreos.com/something easily in the future.", "agreed :+1: ", "code --> features?\r\n\r\ninstaller code has been imported --> has been integrated fully?", "Yes, I don't understand this at all either. Plus, the links are confusing. Why don't we talk about the different platforms that are being integrated/are supported by the TerraForm installer, with a link to their folder/README/something instead and then have a separated link for the current upstream and stable installer?", "Is this correct?", "Need `make terraform-download`", "I thought the goal was to \"package\" everything in the Tectonic Installer tarball. To avoid confusion. If we don't care about people using this repo directly then I'm fine removing it.", "ok, i hadn't considered this a blocker for open-sourcing though", "Are we ok with checking in a skeleton file?", "This is wrong.", "Wrong too.", "i donno. i can remove", "i havent updated the platform specific READMEs. I just want to merge this and clean those up later."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/81", "comments": ["Not sure if there is any kind of validation right now, but this needs to be within the service-ip-range and not conflict with any other pre-assigned service IPs. There has been an assumption that this is service-ip-range +15 (e.g. if service CIDR= 10.3.0.0/24, the etcd-service-ip will be 10.3.0.15). Not totally sure if that is hard-coded right now. /cc @hongchaodeng @xiang90 ", "/cc @Quentin-M might know more. I am not sure how tectonic generates the value.", "Missing `$` in front of `{experimental_self_hosted_etcd}` ?", "There is no validation in place for this kind of stuff, right now.\r\nIt's not very easy to do with Terraform alone, but could be at least validated in the UI.", "Left to their own devices - people are going to get this wrong a lot. We should at minimum have comments describing of how it all works together (something akin to: https://github.com/coreos/coreos-kubernetes/blob/master/multi-node/generic/controller-install.sh#L13-L30)", "Let's keep the format we have for the other manifests.", "This should be a variable: `${etcd_operator_image}`, sourced from `container_images[\"etcd_operator\"]` (see existing manifests).", "Not much we can do at this point except some documentation. We don't yet have much of it, we don't even yet document the process in general. The TFvars will usually be generated by the Tectonic UI anyways. Otherwise, we consider users to know what they are doing.", "will change.", "ok. will change.", "could you use an underscore, sorry..", "sure.", "you use underscore in assets.tf, which is the way to go", "fixed."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/67", "comments": ["ha?", "ha indeed. that was for my testing. forgot it commented."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/65", "comments": ["Not needed anymore, right?", "Will systemd complain about the lack of newline? Or even forget about that line?", "It didn't for me ;) I can add one.", "oh right .. good catch", "what is openstack specific about this service file?", "Why is the etcd-wrapper used?", "It's just how we picked it up from the current installer.", "currently indeed nothing, I copied it over from the `platform-aws-asg` module and (as of now) only removing `--cloud-provider=aws`. We could consolidate this to a top-level `ignition` module.", "This also was taken from `platform-aws-asg` for consistency.", "That's fine for now. We need to address bigger changes. We should consolidate this but maybe as a follow-up.", "That's how it's done in Tectonic upstream as Alex said."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/64", "comments": ["Would it be more descriptive to call these something like OS and ARCH?", "While I do see the need for the new targets that build Terraform, I'm not seeing new alternatives to the \"apply / destroy\" operations which get dropped here. Their main purpose is convenience for both user and developer. They also serve as a starting example for customizations, should a user need that.\r\nWe're degrading to a more clunky user experience by dropping them and asking the user to figure out how to invoke Terraform."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/62", "comments": ["Can we add **Generates HA / Cross-AZ infrastructure** here?", "good call. updated."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/47", "comments": ["no changes here, just moved to bottom of file to separate from the common ones.", "![Giphy](http://media3.giphy.com/media/3o6ZtkhSlz6UQIDC5G/giphy.gif)", "what's this space flying mid-variable?", "Where is this used? Should be included in `tectonic_versions`.", "prefix?", "PREFIX?", "^ twice here, twice in config.tf"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/45", "comments": ["With Quentin's stuff this will be decided internally between modules.\r\nWe should remember to remove this input (or do it now if it doesn't break things)."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/44", "comments": ["Should this be `**/*.tf`?", "Oh, I guess this is for top-level stuff only.", "No b/c this is only for the top-level `config.tf` file. All the subdirs are handled by the platform-specific section."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/43", "comments": ["Would `cd plugins && make all` work ?", "It looks like the `Makefile` creates its own `$GOPATH` now, so this seems easier for now.", "sgtm."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/31", "comments": ["What's the reason for keeping a copy of this rather than importing directly from the terraform repo?", "Why is there a cloudinit config data source copy here?", "What's the dependency chain that brings in a complete AWS Go SDK in here?", "no clue, glide figured it out automatically (see Makefile).", "Every single functions in the existing plugin are non-exported. If we want to use the same validation/rendering mechanism, we need some of these functions (e.g. validateVarsAttribute, execute). It's either we create an entire plugin altogether and vendor these functions manually, or we copy-paste the whole plugin and add our provider using the required functions. The second solution allows us to use the plugin just like it was the original template plugin, with an additional function and will allow us to upstream it very easily.", "^"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/27", "comments": ["According to the [variables doc](https://docs.google.com/document/d/1TuCmnCASBeFn1wPgonVSk-U4X6x0X3MBEM2gybztC1c/edit?ts=58bfcf25#heading=h.75gz6yid25lu), I think the decision was to prefix everything with `tectonic_` and then optionally with `openstack_` where the setting is exclusive to the openstack platform.\r\nDid I understand that correctly?", "oh right, I had the wrong regex set up, good catch!"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/26", "comments": ["Since this is used in more than 1 place, should probably make a variable.", "`tectonic_etcd_servers`?", "https://github.com/coreos-inc/tectonic-installer/blob/master/config.tf#L86", "unclear what needs to be there.. ?", "maybe should not be postfixed by `-k8s` if we let users define it", "fixed\r\n", "this is the correspondent of the extra dns name required by tectonic 1.5.4 to decouple the DNS names from the cluster name."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/21", "comments": ["I don't think this is required. IIRC if omitted will use the ssh-daemon.", "any reason for this to be a variable?", "Is it possible to use this same pattern elsewhere? If so could we load all config from ConfigMaps/Secrets?", "All of this repetition sucks (not your fault, just how TF works). Maybe later we can create a simple Go program to generate this.", "This is just copy-pasta from bootkube. That is not a TF variable (`${}`) but an env variable replacement (`$()`).", "Yeah. Definitely not required at the moment, I even define an empty string as the default. The reason I exposed it is simply in case we - or some Open Source user - would like to use it. Same for the user really.", "Just to make the module more generic. By default, we write in `/home/core/bootkube` as it's where the `core` user has permission in. Any external user might want to overwrite this alongside with the user variable, if they don't use CoreOS for example.", "Definitely. This repetition, and the `template_file` one, bother me quite a bit and I was really tempted to start creating a Go app that would expose various plugins for us. For the sake of keeping it TF idiomatic and understanding the drawbacks of TF, I kept it this way for now.\r\n\r\nWe have over 70 manifests in total in Tectonic. This'll be painful.", "Eventually we should have a Go app that would expose the various plugins that we need but it'll require us to compile that, have it distributed where terraform runs, etc. Would like to avoid doing that for now, as it's not strictly required. Squashing this code to use a plugin will be straight-forward in due time.", "fwiw we use self-generated ssh keys currently for the other PoCs", "(at least in openstack)", "we should make this configurable", "All this repetition can be avoided, because it just reads a file from one place on disk and puts it in some other place. There is no need for all of this to go through Terraform for the files that need no modification. All that copying can be done in one operation using a `local-exec` provisioner and some `cp` commands between the right paths.\r\n\r\nDoes having a Go app involved in this workflow not sound like what we are trying to avoid? Bootkube? :)\r\nMore generally, if declarative templating is not enough, I would raise the flag that maybe Terraform is not the right place to do certain things (according to TF authors).", "I would advise that we don't this kind of thing at all in this module.\r\nIt hints slightly of mixing separated concerns, but that's not the most important aspect.\r\nI'm anticipating a few raised eyebrows around the use (and management) of SSH keys to provision the cluster in general. I would put effort into getting rid of the SSH requirement altogether.\r\nMay I alternatively suggest that we deliver the assets via ignition? I believe it makes for a more secure and flexible provisioning flow. I'll explain my point in more detail when we meet.\r\n", "Agreed, this will introduce yet another layer of abstraction (which terraform already is).", "Do we need master node IPs / hostnames or the load-balanced FQDN in here as well?", "It is idiomatic in Terraform to put outputs of a module in their own file called `outputs.tf`, although unfortunately not specifically mentioned in the documentation.\r\nYou can have a look at [terraform-community-modules](https://github.com/terraform-community-modules) for some nice examples of idiomatic modules.", "@alexsomesan work is already being done to accomplish that\r\n\r\nhttps://github.com/coreos-inc/tectonic/pull/1494", "I know, but it looks like a way for us to reduce the number of templates. I'll talk to you IRL.", "That works fine for static assets (but will be a problem for windows users).\r\n\r\nThis will continue to be a problem for templates.", "@alexsomesan does a style guide exist somewhere? If not maybe we should add one to this repo?", "I didn't know we eventually decided to stop scp'ing the assets but use S3/Ignition instead.\r\n\r\nThe reason the current Tectonic Installer stops using SCP and starts uploading them to S3/Ignition today is due to the nature of the Tectonic Installer being a web application with a stateless backend, that might even be hosted. Storing temporarily the assets and transmitting them multiple times to the backend is pretty nasty. \r\n\r\nHowever, TerraForm is somewhat a glorified tool that let you automate CLI / SSH commands. I believe it still makes sense to have the assets uploaded. Regarding to the separation of concern, I believe that having a single platform-independent module that executes a specific version of bootkube end-to-end with little assumptions is better than having a module that would generate assets, then having a probably platform-specific way of getting them on the host and then executing bootkube with lot more assumption. It is more contained, more defined, reusable, and easier to maintain/test overall.\r\n\r\nAlso, is there a size limit on Ignition templates?", "If we'd like the bootkube module to simply output assets, could you give me some advices regarding to how we could get one output out of all these generated assets properly? `ARCHIVE_FILE` seems to only work with a single content/file/directory. Would it be useful for all use-cases to have them returned as a map maybe? I don't want them to be handled individually by external modules, as it would break the whole idea of having that module isolated and versioned independently.", "This is what we currently have in Bootkube and Tectonic.", "should be a map", "Good point! Similar to Go, Terraform has an `fmt` command which formats the entire tree of templates in the current dir to the canonical form.\r\nI'm using Visual Studio Code + the Terraform plugin to edit this repo, which automatically does and `fmt` on every save.", "@Quentin-M I'm with you that having a TF plugin to render the assets is a viable future option. It would reduce verbosity AND keep in line to TF native workflow.\r\nWhat I'm actually trying to avoid is having some random external tool that we'd somehow have to glue in to Terraform.\r\nConsider my \ud83d\udc4d  for a TF plugin to do the equivalent of a `bootkube render`. Maybe we could even reuse some of the existing bootkube code?", "So, since all the rendered stuff and also the copied manifests eventually end up in the `var.assets_path` location with a \"well known\" layout, I would just output that path to be picked up by consumers, who'd then respect the folder layout contract and thus expect things to be in the right places in there.\r\n\r\nFor example, a consumer of the kubelet certificate would just reference it with \"${module.bootkube.assets_path}/tls/kubelet.crt\"", "Got ya! But for my own understanding, how does TLS verification succeed when nodes call the bootkube API via hostname?"]}, {"url": "https://github.com/coreos/tectonic-installer/pull/20", "comments": ["Are we actually using images off of ECR for anything? Or is this one of those thug requirements of K8S?", "Tectonic doesn't use ECR directly. I think these are just there because it's likely Tectonic users may store private images in ECR.", "Cool, let's keep them in then."]}, {"url": "https://github.com/coreos/tectonic-installer/pull/18", "comments": ["I would follow the current convention and\r\n1. Specify a count on the number of master instances.\r\n1. Specify the name as: `name = \"${var.tectonic_cluster_name}_master_node_${count.index}\"`\r\n\r\nSee https://github.com/coreos-inc/tectonic-platform-sdk/blob/master/platform-openstack-novanet/master.tf#L2-L3 for a reference.", "As mentioned below, I would remove this variable.", "As mentioned below, I would remove this variable.", "Is this a vsphere specific setting? If so I suggest to name this `tectonic_vsphere_coreos_template`", "Similarly I suggest to call this `tectonic_vsphere_network` as I think this is vsphere specific.", "I think this is also vsphere specific, hence I suggest to call this `tectonic_vpshere_tectonic_cluster`.", "I believe this conflicts with https://github.com/coreos-inc/tectonic-platform-sdk/pull/18/files#diff-ce759cddaecf76cecf96d6a2e60bac91R9 and hence can be removed at all?", "I would remove these defaults ;)", "similarly, I would remove this default and force the user to specify it.", "Is this because ignition metdadata doesn't know how to do vmware?", "would be great to use the aws module directly.", "I believe that's copy paste from Openstack, will remove that on next pass", "Indeed, we should avoid this hack here if possible. We had to do this in openstack, as https://github.com/coreos/coreos-metadata/pull/33 landed just very recently."]}]}, {"url": "https://github.com/dwp/dataworks-aws-kickstart-adg.git", "pull_requests": []}, {"url": "https://github.com/ken-matsui/poac-infrastructure.git", "pull_requests": []}, {"url": "https://github.com/chad-russell-git/terraform-oci-cis-landing-zone.git", "pull_requests": []}, {"url": "https://github.com/jamesvsshark/twenty-nineteen-iac.git", "pull_requests": []}, {"url": "https://github.com/ralwani/sap-oracle.git", "pull_requests": []}, {"url": "https://github.com/ministryofjustice/modernisation-platform.git", "pull_requests": [{"url": "https://github.com/ministryofjustice/modernisation-platform/pull/7024", "comments": ["this should be: `source  = \"github.com/terraform-aws-modules/terraform-aws-vpc?ref=25322b6b6be69db6cca7f167d7b0e5327156a595\" # v5.8.1`", "and this one: `source  = \"github.com/terraform-aws-modules/terraform-aws-vpc//modules/vpc-endpoints?ref=25322b6b6be69db6cca7f167d7b0e5327156a595\" # v5.8.1`", "Missed this one. I will correct it\r\n", "Also corrected"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/6956", "comments": ["Should this rule number be 6000?", "As above.", "Are the network firewall rules in place that prevent hopping between vpcs?", "Yes and no. Traffic inside a \"domain\" like prod/preprod and dev/test hits the MP Transit Gateway and goes directly to the destination VPC.\r\nEG. `laa-test` can send to `platforms-development` without being passed through the `core-network-services[\"external-inspection\"]` VPC.\r\nEG. `laa-development` can send to `core-network-services[\"non_live_data\"]` without being passed through the `core-network-services[\"external-inspection\"]` VPC.\r\n\r\nWhen traffic wants to move between those domains - `laa-development` to `laa-production` or `core-shared-services[\"live_data\"]` then it would move through the MP Network firewall in the `core-network-services[\"external-inspection\"]` VPC.", "No; it's limited only to the VPC traffic range. Rules in the 6000 range were an unused feature defined here: https://github.com/ministryofjustice/modernisation-platform/blob/main/terraform/modules/vpc-nacls/data.tf#L39\r\n\r\nThe intent was that a customer could pass in an extra range that their VPC required, and it could dynamically be added into the firewall rules.", "As above, this would again cover traffic moving internally in the VPC."]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/6833", "comments": ["What does \"checks their access information\" mean?  Does it not scan their contents for certain data?", "This is to do with manual set up isn't it so can be removed?", "What is the pre-requisite?", "I don't think this line is needed", "I don't think we need to tell people to google it, this can be removed", "Was this set up in cooker or example?  It would be good to have it in example with a link to the code", "This role is defined on a platform level, so if this has been done following this POC this won't be needed again and this section can be removed.  If it's not been done it should be.", "Has this been determined yet?  We can't publish user documentation with unknowns in.", "I think this whole section of code could just be linked to instead of being written out here if the code exists in example?", "This is manual steps again which should be remove from the document, we do not want users doing things manually and they won't be able to do this in any environment other than sandbox.", "I'm not sure. I will double check and amend this as needed.", "It is manual set up. I could mention that in the documentation if you would prefer. If not I will remove it ", "It's mentioned with the code. I will remove this here and try to highlight it a little more in the comments below", "I have removed this line. As you say it isn't needed", "Correct. It was something I added when I initially set up the document before I realised that the code could be used instead. It has now gone", "It is currently only in cooker. When I tried to create it in example it wanted to create about 150 items and there were a number of issues when running it. I can add it to be code but we might be better not running it. \r\nCurrently there are 15 buckets in example but I could set the data to only access a couple.", "No. It is needed in the main code. There's currently no change to do this so I could create a new one and then this can all be removed. Let me know (here or slack) if you want this to be done", "Removed \r\n\"The full details of the \"finding_publishing_frequency\" and \"job_type\" can be seen in the terraform links listed above.\" as it was a little pointless and didn't add much.\r\nThe bit about the code being in cooker is, currently, accurate.", "Not in example at present, see notes above.\r\nIf it's needed in example, which I suspect it will be, this can all be amended to replace cooker with example", "These need to be created manually unfortunately. \r\nUsers will need to amend these based on their requirements. \r\nThe account code bit has since been amended (and comments added about this) but other manual changes may be needed.", "I have now added it to Example and put in comments to state it's in both places in the documentation (cooker or example or the other way around)", "Steve, this should read ....'it need**s** to be done '....", "should this be ace?", "I think, where we are talking about accounts, we should capitalise Example and Cooker \r\nminor but should 'this shown below ..' include 'is'?", "This hasn't been resolved the same comment still stands", "I still don't understand this comment about yet to be fully determined", "you create, rather than 'crete'", "The memberinfrastructureaccess role is one all accounts have and is controlled centrally by us, if it doesn't have the permissions it should have, there is nothing users can do to make sure it has the required permissions", "I don't think you need this line, users will know how to add data sources if needed. It can be removed.", "You can remove mention of cooker in this as it's one of our test accounts and you can link to the example code.\r\n\r\nFrom `The appropriate environment...` etc onwards isn't needed and adds confusion, it can be removed.", "I was sure it has been removed. It has now.", "I don't think you need to duplicate this code here, a link to the code in example will be fine, this can be removed", "This is not needed, it is just duplicating Terraform documentation", "As above link to the example code is enough", "I've removed the line", "This section onwards is console instructions which we don't want users to do so please can it be removed.", "Corrected", "Not sure about this comment.\r\nThe lines has been left as is\r\n", "This has all been amended/tidied slightly to explain it a little more.\r\nHave a look at the new version (which will be uploaded later) to see the change.", "Corrected", "I will put a quick request up to get this set up for all accounts. The comment can then be removed.", "Removed", "I think that was tidied above. Again check when the next version is uploaded", "Removed the middle line as above", "Make sure that the role for **MemberInfrastructureAccess has ace \"macie2:*\"** set. \r\nare we asking a member to do something here? I wondered whether 'ace' was a typo - as it seems like a strange parameter - but that might be the way it works", "Code has been amended to set the account to cooker or example. This is to make them more obvious.", "I thought that might be needed to keep track of creating jobs if users want to.\r\n\r\nI did notice we have no details in there of setting up the access to the S3 bucket macie uses and generating the KMS key needed. I suppose this is a \"you should know how to that\" option for us", "Yes please this should be done otherwise users won't be able to use Macie.  How did you get this working in cooker without it?", "I didn't notice this at first but it has now been amended. Not entirely sure what this was originally now.", "Following slack conversation we decided to remove the console reference all together.", "It's a quick job to amend it in the whole of the code but I think it should be done as another routine/request/issue to get it done completely. This code could then be amended or we could do it in advance and then amend this before it goes live.\r\n", "This has an extra ( which means the link doesn't work when rendered", "```suggestion\r\nThere is an AWS video explaining the set up and use of macie [demo](https://www.youtube.com/watch?v=8piwEQJJXdo) which you can watch.\r\n```", "```suggestion\r\nStarting Macie with Terraform is possible and the instructions are shown below. I have also listed the details of setting up jobs. The example only shows a few of the many items that can be included. Details from Terraform are shown below the example code.\r\n```", "```suggestion\r\n```\r\n\r\nI don't think this is needed, and how they reference the S3 bucket will depend on their code, it might not be via a data call", "```suggestion\r\n```", "```suggestion\r\n```", "```suggestion\r\n```", "```suggestion\r\n```", "```suggestion\r\n```", "```suggestion\r\n```", "```suggestion\r\n```", "```suggestion\r\n```", "```suggestion\r\n```", "```suggestion\r\n```"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/6748", "comments": ["Do you specifically need to use the GitHub CI User PAT, or can you use automatic token authentication? (https://docs.github.com/en/actions/security-guides/automatic-token-authentication)\r\n", "I tried both `github.token` and `secrets.GITHUB_TOKEN`, but neither of them worked."]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/6742", "comments": ["```suggestion\r\n      \"kms:DescribeKey\"\r\n    ]\r\n```", "```suggestion\r\n```"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/6549", "comments": ["`only complete` rather than `only completed`?", "I think the original wording was fine here - \"`Which environments you wish to use`.", "nice catch, thanks. ", "agreed, reverted to the original wording."]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/6485", "comments": ["Could these secrets be refactored to use a for_each declaration? You might need to think about how to supply it with values, but it would make for cleaner code.", "Not a big issue should this say \"non-live\" rather than \"_line_\"?"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/6380", "comments": ["At this point it is worth mentioning, that the issue could be isolated to one application only and if other applications cannot afford an outage, then another approach should be taken (perhaps looking at NACLs on the MP side and elaborating on it and/or LB/WAF/SG on the application side, requiring to work closely with the application team)", "```suggestion\r\nThis document lists the steps needed to stop access to and from the internet and prevening the system from being accessed from or accessing other applications on the MoJ.\r\n```", "```suggestion\r\nAll changes are to be made manually on the relevant environment (for example core-vpc-production) and are not made through the code. If a way of reverting back to baseline is required the terraform code can be run and this will reset everything.\r\n```", "This sentence needs rewriting, as it is not entirely correct (you do not remove VPC application area, but you detach an IGW from a VPC to disable an entry point from internet to the whole VPC)", "At this point it would be good to mention (perhaps in a warning NOTE format) all the risks that the manual changes carry, see the [slack thread ](https://mojdt.slack.com/archives/C013RM6MFFW/p1709552392385159)for more information", "Probably just an oversight. I will adjust it", "Yes. I missed this", "Is this acceptable?\r\n\r\n> [CAUTION]\r\n> The changes listed in this document will impact all applications connected to a particular NACL. If you were to amend, for example, hmpps-production-data-nacl, everything that connects via that NACL will be impacted. Nothing that connects from HMPPS through this NACL will have access. ", "The following are not regions but NACLs for each subnet type set and there are only 3 regions per NACLs).", "This is not true and the and the linked documentation is irrelevant here, as it is related to the firewall changes and not NACLs.\r\nSee [this documentation ](https://docs.aws.amazon.com/vpc/latest/userguide/vpc-network-acls.html) on the evaluation order of the rules and update the documentation to reflect it.\r\nThink about a smarter way to implement it given the rule evaluation behaviour, updating every single rule in each NACL sounds like a lot of manual work.", "You're mixing NACLs with firewall again.", "`from the MOJ` sounds a bit broad, I assume here you mean MOJ WAN, but this needs clarifying and the documentation needs to be clear", "Is that right? Would it not be better to block the firewall?", "The same comment as above, controlling the access through NACLs requires more work in this scenario, but the same can be achieved through the firewall rules or TGW changes (or possibly route table changes)", "Mistakenly added to the previous thread\r\nhttps://github.com/ministryofjustice/modernisation-platform/pull/6380#discussion_r1511242225\r\n", "The documentation so far addresses (although in some cases it is not correct)\r\n\r\n-  Blocking access for something entering via the internet\r\n-  Blocking access for something leaving via the internet\r\n-  Blocking access for something leaving via an internal route (eg, TGW)\r\n-  Blocking access for something entering via an internal route (again, eg TGW)\r\n\r\n \r\n but it is still missing:\r\n\r\n-   Blocking access for something moving internally inside the Modernisation Platform\r\n\r\n  and ignores looking at the problem from the other angle:\r\n   - isolating a single service/app or an environment (or even worth considering isolating a business unit as oppose to as single service/app)\r\n   -  blocking ingress/egress in multiple or all services/environments\r\n\r\n  \r\n  ", "this is still not addressed", "this is still not addressed", "Your warning is regarding the changes impact (which is already covered in this documentation), but I am looking for a warning about the risks that manual changes (vs code changes) carry, since we are doing it through click-ops and not through code.", "No more than 10 rules to amend in each. Sounds like a lot but changing from allow to deny isn't too much effort", "This caution is not needed as it's already covered (see the other thread).\r\nThis sentence just needs rewriting so that it makes sense.", "Corrected\r\n", "See my previous comment, as what you are saying about the NACLs rule evaluation is incorrect.", "Added a section about reducing access to a single application\r\n", "This has been amended\r\n", "This has been corrected", "Amended", "This has been corrected\r\n", "Can you clarify this please? \r\n", "We have reviewed this again and have amended the documentation to add a new line to the rules to add a global deny. I have listed the current section as an option.\r\n", "Blocking at the firewall would be a lot more work than it would look like at the outset: the short version is that the `permits` all get applied before the `denies` are looked at, so you'd need to prune what you permit first before then setting the denies, or consider changing to use `alert` instead of `permit` for traffic passing through a network firewall (alert allows traffic, but logs it. permit allows traffic and doesn't log it).", "Amended a little to ## Stopping access from the MOJ to an application on the Modernisation Platform Transit Gateway", "We discussed this and decided it was better to do it through this route rather than letting something bypassing here and hitting the firewall. It would also make this \"quick fix\" temporary measure a lot more complex.", "As above", "I may have covered this with my other changes. They will be posted later.", "Regarding isolating a single business unit, that ought to be covered by the guidance on detaching an internet gateway, and putting a deny rule at the top of the ingress/egress NACL rules. In theory you could also do this by removing the TGW route table association in `core-network-services` but that would only cover part of the routing (enough to break TCP sessions, but not to stop UDP traffic coming in).", "What I was after and what was already discussed in the [slack thread](https://mojdt.slack.com/archives/C013RM6MFFW/p1709559726905539?thread_ts=1709552392.385159&cid=C013RM6MFFW) is something along the lines of: \r\nThese manual changes mean that:\r\n- there is no history of changes in code and therefore if there are additional changes done that are not part of current IaC (e.g. introducing a new route table), these will need noting\r\n- there is a danger of unintentionally undoing these changes with a pipeline run, hence for the time when the manual changes are in place, no pipeline relevant to the networking bits that were updated can be run\r\n\r\n", "There are 5 NACLs sets per each business unit's environment and there are 3 subnets associated with each NACL set. This needs rewriting to be accurate.", "```suggestion\r\n3. Add a new Deny rule for 0.0.0.0/0, rule number 4999, which will prevent access to the items listed after this point. All internet rules are 5000 and above.\r\n```", "you can probably skip the transit gateway subnets, but need all: data, private, protected and public", "This sentence makes no sense.", "Fair enough @dms1981 this would be challenging (hence originally suggested changes in code), but Steve's suggestion was to amend every Allow rule to Deny, which would not only mean that we would block all the traffic (which in case of blocking MOJ internal traffic only, was not desired), but it also meant a large number of manual changes (e.g. 10 NACL rules in each subnet type, such as data, private, public, protected then multiplied by 3 regions, never mind making changes for multiple business units or multiple environments).\r\n\r\nit's the other way around Steve, incoming traffic from MOJ, coming through the MP TGW will be first filtered through the firewall in core-network-services VPC then routed to the core-vpc-<env>", "This should say rules >= 4000 and < 5000 rather than list specific rules, as they can vary between each NACL and they can be expanded in the future. You could also mention at the beginning that we dedicate these rules to private CIDR ranges (hence only looking to amend the rules within this rule range).", "I don't think `protected` subnets are going to be relevant in this case as they never hold customer infrastructure and should only host VPC endpoints.", "Amended in code and will be pushed with next commit\r\n", "The rules are set as part of the code but, as you say, they may change in the future. I will amend so they are not specifically listed.", "So for the avoidance of doubt @SteveLinden , this could be met by adding a [blockquote](https://www.markdownguide.org/basic-syntax/#blockquotes-1) in near the top of the document that says those things.", "All good points @ewastempel - I'll work with @SteveLinden to firm up his understanding here.", "Additional comment added", "Understood. I have amended the code to add a new rule, prior to the ones we want to deny, which will alleviate the need to amend all the rows.", "I have added additional code to list what to do to remove the transit gateway. This will prevent an environment routing around through others.", "This has been reduced to the 3 (data, private, public) as per David's suggestion.", "Moved and corrected.", "true, although is there anything stopping users from hosting infrastructure there? If you were the bad actor, you could deploy your infra app anywhere that is allowed (and suits).", "```suggestion\r\nAll changes are to be made manually on the relevant environment (for example core-vpc-production) and are not made through the code. If a way of reverting back to baseline is required the terraform code can be run and this will reset everything. All of the steps listed will be performed on the core-vpc-<environment> location unless otherwise specified.\r\n```", "```suggestion\r\n> All networking changes via terraform should be stopped while this work is ongoing. No MP terraform runs should be permitted while there is work going on to prevent unauthorised access to the environments.\r\n```", "Is this necessary since you've already mentioned it at the start of this section?", "```suggestion\r\n## Stopping access to/from a single application\r\n```", "```suggestion\r\nThis work is carried out from the core-vpc-<environment> account, e.g. core-vpc-production.\r\n```", "also am I OK to assume that nothing can be deployed in the transit subnet if the TGW attachment is in place? or should we worry about that subnet too?", "```suggestion\r\n```", "Mention it somewhere why we are amending only >= 4000 and <5000 rules, so that it is clear that we rely on our good practices (such as using >= 4000 and < 5000 rules for private address ranges only) being followed", "This sentence does not read right again.", "```suggestion\r\nThis work is carried out from the core-vpc-<environment> account, e.g. core-vpc-production\r\n```", "```suggestion\r\nThis work is carried out from the core-vpc-<environment> account e.g. core-vpc-production\r\n```", "```suggestion\r\nThis work is carried out from the core-vpc-<environment> account, e.g. core-vpc-production\r\n```", "These instructions are not clear to me.", "Is it just me or somehow you managed to change the text colour? Is it only visible in the PR (but won't be visible in the user guide)?", "or below?", "```suggestion\r\n## Blocking access for something moving internally on MP\r\n```", "I tried to use <> initially and they didn't show up in the review of the document. I can add them again but we may just see core-vpc  without the environments word", "As mentioned above with the <> is does not resolve correctly when opened.", "As above", "As above", "Tidied again. For some reason a section I thought I had removed re-appeared", "Changed", "The TGW subnets are not shared across the whole system. We should not have issues. A bad actor would also need access to the code and be able to amend and deploy it.", "I can't see this line in my code now", "I had amended it but the old version is still showing. It has been amended again", "Removed the initial comment about accessing the protected route.", "OK in my code.", "Amended. I think I was pointing out it was as done in the previous version", "Applied but still showing here?", "See above\r\n", "See above", "It looks like it was related to something I had installed as an extension. This has been removed and the code appears OK with the <> now.\r\nI have manually amended it in place rather than through the commit here.", "See above", "I've added a footnote (according to the writing on github code) so this may be in place.", "After having a discussion in slack, this is now to extend the list of NACLs, for `core-*` accounts", "Resolving this one, I think it's a GH PR feature (something that was commented on, got amended, hence a different colour, although I have not found a doc on it yet)", "I can see it as plain text with bold NOTE underneath the instructions, but that will do.", "To include the protected network this has been included in the list so there are now 4 shown. \r\nThe transit gateway is shown in 4 other locations so these will be listed too.\r\n", "The footnote didn't seem to appear in my testing so I added the note to compensate.", "` [Revoke Network Access](runbooks/revoke-network-access.html)`", "This document lists the steps required to revoke internet access, and isolate the compromised infrastructure from other applications.\r\n\r\nMaybe?\r\n", "a warning", "Should deny be capitalised? "]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/6349", "comments": ["permissions", "will need to app approved by the team name provided. - Is this what you meant?"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/6340", "comments": ["```suggestion\r\n - The Analytical Platform will build a new production LLM service\r\n```"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/6339", "comments": ["I don't think this is necessary. It should be stated at the start of the document that this document assumes the need to block network connectivity has been identified."]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/6300", "comments": ["You can set it up at first to test it, but I think it could be spammy to have it there permanently (but see what others think, I did not set up an email notification for the instance scheduler and all other cloudwatch alerts are also not set up with an email notification)", "I wonder if it makes sense to define the sns topic here, rather than in the module (since it's not doing anything there anyway)", "Good point, I have it in there just to test the creation but going forward I could easily remove it!"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/6295", "comments": ["Needs a comma here", "Added the comma"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/6280", "comments": ["This was probably fine as it was. It reads a little clunkily now; it mostly just repeats the same thing in different ways."]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/6256", "comments": ["are we losing this permission? \ud83e\udd14 ", "Line 339 should cover this permission", "I think this might be causing an issue for me. Today I've started to get a `not authorized to perform: glue:StartJobRun on resource` error when I try to run Glue jobs using the modernisation-platform-data-eng SSO role"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/6224", "comments": ["can the CIDR ranges to be narrowed down?", "this is a bit open", "Was it not possible to bake it into an AMI? or is it because it's not going to be a long lived solution?", "Not really because the user-data script will join the server to the domain.  It's actually much less hassle overall to use base image here.  The user-data just calls a powershell script in modernisation-platform-configuration-management repo in similar way to ansible on linux instances.", "Rules here are mirroring the domain controller NSGs in Azure.  The Domain Controller ports allow 10/8 - so any end user device connected onto our network can talk to the DC, and also the DOM1 DCs can reach as well for the forest trust.  Outbound we allow everything to keep things simple - in fact, this is what we have for all our EC2s in all our applications.  Assumption is there is another layer of control, e.g. firewall, gating the outbound access to internet.", "I think the firewall rules are a bit open actually, but let me check.", "Yep, fair enough,", "Just checked and they are not as open as these SG :) I think there is enough balance there though."]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/6210", "comments": ["S3ReadOnly ? ", "Ah, good spot @ASTRobinson. Have just corrected it.", "is this comma required? ", "is this comma required? ", "is this comma required? ", "is this comma required? ", "is this comma required? ", "is this comma required? "]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/6193", "comments": ["```suggestion\r\n    }\r\n```"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/6190", "comments": ["```suggestion\r\nThere may be occasions where there is a network attack on Modernisation Platform environments that could require a way of stopping access. This document lists two possible solutions to the issue.\r\n```", "I'm not sure it is obvious, how would people know what an attack looks like?  Is that something we want to go into here or should this doc be about how to shut down network access rather than how to identify an attack?", "Which environment from which VPC?", "I think we would want to explore all ways of blocking access, so not just through the console, but also through code (which in some cases would be quicker than through the console)", "I agree, I think for the purpose of this guide, let's stick to `how to do block network access` only.", "what other issues? the impact/risk needs documenting in more details ", "also when would you chose to detach an environment from VPC and how would you do that (e.g. in console do this and that or in code see this line/code block and set it to such and such)?", "More about how to stop network access than detailing what constitutes an attack. I couldn't actually find any examples which showed an attack (or unwanted access for that matter) so it's difficult to show examples here.\r\n", "It does mention that above the line. I will include an example to make it clearer.", "I did notice on place where that may be quicker and made a note about it. I have not, however, included the details and location on what would need to change. I will look into this to make sure it can be included.", "Made a note. It will stop all applications using the VPC from accessing the platform. This is because we have VPCs that just attach to the like of hmpss so everything on hmpps will become inaccessible.", "Deleting any VPC is not desired.", "Maybe put that as the last - if everything else fails - option?", "There may be occasions where there is a network attack on the Modernisation Platform and its accounts that could require blocking networking access / connectivity. This document lists the steps to follow.", "Youve capitalised some but not others at the start, small thing though! ", "Capitalisation was based on the actual statements in AWS rather than me randomly adding them. Maybe I should put quotes around these bits?\r\n", "Changed this", "this is still not addressed"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/6181", "comments": ["What roles can be assumed by this type of user (perhaps a link to code, as it's a moving target), what is the session duration for each role (is it specified in code? NOTE, session duration is set per role basis).\r\n\r\nHow do we revoke current session (NOTE it can be done in the console and probably through aws cli)?", "ignore this comment, I've noticed you have described roles and revoking session in later points.", "Some of the headers need a space added in \ud83d\udc7e \ud83d\ude48 ", "Thanks @connormaglynn - sorted that now "]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/6179", "comments": ["this is ldaps rather than kerberos", "this needs to be all ports 49152 - 65535", "this is ADWS (active directoy web services)", "Updated to correct name", "Updated port range", "Updated to correct name"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/6131", "comments": ["I think this was meant to be a port number", "thanks! corrected"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/6106", "comments": ["```suggestion\r\n          \"access\": \"security-audit\"\r\n```"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/6105", "comments": ["`permanent` instead of `permenant`, `temporary` instead of `tempoary`", "`severity` instead of `serverity`, also there's a trailing space at the end of the link.", "Which channel?", "I don't think this is the best idea. I think that GitHub Actions should still be the method we use for deploying. It allows visibility, and access to logs for review.", "\"If this occurrence is in hours\" or maybe if this occurs in hours ", "typo - \"Escalation\"", "typo \"foreseeable\"", "typo \"policies\"", "typo \"references\"", "typo \"keys\"", "priority", "referenced", "engaging", "engaging", "\"if this occurs in hours\" - delete the \"is\"", "do you mean to have \"**fill in here** \"?", "how do we update pager duty and the external status page?", "I agree, but should we have a commitment here to update every x minutes/hours - even if we are still waiting?", "again, should we mention our commitment to regularly update status", "was it suppose to be this?\r\n`#ext-aws`", "```suggestion\r\n- If this occurs during working hours, create a huddle / meet. Outside of hours, if you have been called out, call the second member of staff that is on call and post to the channel. With the PagerDuty alerts, incident channels will be created. If there are too many channels to follow, make a lead channel to coordinate.\r\n```", "Add #modernisation-platform-update and `#modernisation-platform-alerts` does not exists.\r\n\r\nLet's link the incident user guide here: https://user-guide.modernisation-platform.service.justice.gov.uk/runbooks/manage-an-incident.html#incident-process\r\n\r\nI think Edd was looking at, who do we need to inform: Steve, Martyn (app business owners etc.)", "Gangsta style! :) ", "Click here links are not working?", "Ive added a line to say this needs to be filled in", "Ive added a line to say this needs to be filled in", "How exactly would you create an account manually? I don't think our roles allow us to create an account, so it would need to be done as part of the account creation workflow I believe.\r\n\r\nThis documentation should then mention migration of the code of that account to the new account and running the terraform in MP repo first and then doing the same in the env repo.\r\n\r\n\r\nIf the whole account was lost, what do you suggest for backups? Even if the backups were replicate across regions, if a single account is gone, so are the backups.", "I think the confusion is that it reads a bit that we wouldn't engage with users until we know how long it will take for the issue to resolve.", "Do we mean compute infrastructure here? If so, we probably shouldn't say all infra, as it can be confusing.", "- Backups", "I think it would be good to add a note, that if the decision it to rebuild then follow the [Running outside of London DR steps](#disaster-recovery-running-outside-of-london).", "this channel does not exist and we should also post it in the `#modernisation-platform-updates` channel", "| Dynamo Disable | Check ???", "what about other resources like RDS, EC2, ECS, EKS, SG? or are we ignoring them as they are member's?", "```suggestion\r\n| DNS (Route53) | Across all regions. | - | - |\r\n```", "what about IAM roles and users?", "This list is also missing CA", "there is no list of repos", "```suggestion\r\n```", "One large PR is when things usually go wrong. I think breaking it into smaller step by step, easily revertible PRs is what we are after.", "Not sure I agree we should use `0.0.0` as a tag, but it's an interesting concept, worth discussing within the team.", "Now I see the repo list, perhaps it makes sense to move it up where the list of repos is mentioned?", "Only looking at resources for the platform, not the members infrastructure. The list was generated from work Mark and Aaron did.", "Where? ", "If we only change some to the correct region, the apply will fail.", "Creating a whole account manually would be a pain, but also trying to troubleshoot just using workflows would be more time consuming than running plans locally when things fail. \r\n\r\nThe environments repo code I can mention, but I havent so far in this because its platform focused?\r\n\r\nBackups would be in the old account just not accessible if all is down, not sure what I would recommend. ", "Raised with the team, no other ideas mentioned.", "Just to jump onto Ewa's point. Would we inform the users first (via a slack channel or directly?) that we are aware that there is an incident and we are looking into it with AWS. Just so we are notifying them before we ask AWS.", "I'm not sure it's possible but could the account be created in another environment first so it kind if sits there unloved and unused until needed. Hopefully it will never be needed.", "My point was, it would be impossible to create an account manually using our roles as it calls the root account as part of it.\r\n\r\nYou need the workflows to provision the skeleton account (to create the resources and files in both mp and env repos, it's just part of the account creation) prior running the existing code. This is still bare minimum, as it creates the standard files and infra that are part of account creation. Then for the migration of the old code, you can skip the env repo part, as the bare minimum will be created with the workflow, but don't forget the MP repo part, as this completes the account recovery.\r\n\r\nUnderstanding of the account creation process is easier and less prone to error when done using automation. ", "Agree, and it's also impossible, unless you have a root account access.", "this is still not addressed", "CA is part of the platform, the list is incomplete, hence the review.", "Good point, there will be obvious dependencies such as VPC and subnets, transit GTW, route tables, etc. but you could group the resources and apply only one area at the time (e.g. IAM roles, networking, logging, security baseline)", "I've noticed the Image Builder (AMI repo) missing", "ignore me, it's there", "The list is below", "Changed to be IAM in general, not just the policies. ", "Added", "`Needs works` - is it not finished? or have you forgotten to remove this", "```suggestion\r\nPeer the new Transit gateway build in eu-west-1 to the MOJ transit gateway that is in eu-west-2.\r\n```", "Updated", "Yes, not sure on that one, if our TGW is down due to a regional disaster, so is MOJ's TGW. This will require more coordinating with the network ops team and with the service owners. There will need to be other workarounds done for this.\r\nWorth capturing it that there are dependencies on other teams and that peering with another TGW will be most likely impossible here.", "I wonder if we should not specify the region we migrate to, as we do not know for sure it will be `eu-west-1`.\r\nWe could mention somewhere at the top that our preference will be `eu-west-1`, but it may not be possible to migrate to there at the time, hence for the sake of documentation we will call the new region `secondary region` or `other region` (or similar).", "```suggestion\r\n|Core-Shared-Services|Creates the core shared services account resources, AMIs, KMS, S3 and other shared services customers require are based in here. |\r\n```", "```suggestion\r\n|Core-Logging|Creates the core logging account resources, not essential for operational function but a part of the platform. As well as for troubleshooting, logging is required for audit purposes and therefore should also be prioritised. |\r\n```", "This is a nice breakdown of stages, but it only focuses on networking (and is missing IAM, security baseline, etc.). I think once the networking is recovered, we then need to add other steps of recovering all of the accounts that sit on top of the platform (like for the single account recovery, but skip the part of account creation). Also, will you be even able to run the networking bit, if the IAM roles and policies are not created/updated first?\r\nWhat about the modernisation-platform account, resources there will need recovering first, won't they?", "Core accounts need to be created first, then the modernisation platform account. I imagine some parts are joined (understatement of the century) thats why I advise manually running plans when errors occur to debug this. \r\n\r\n Core acounts\r\n Modernisation platform account\r\n member accounts\r\n \r\n The only problem is, the networking will never work currently. ", "Removed", "I'll reword what I have put, ", "Rebuilding an account entirely through workflows would be the next step, and in an ideal scenario this would work first time, however when errors occur, debugging terraform plans and applies locally saves a lot of time. \r\n\r\nScenarios are never as cut and dry as \u2018all infrastructure has vanished from one account\u2019, so working and debugging the issues that occur will be quicker locally.\r\n", "Only when we have a decision can we update users on what is next. \r\n\r\nWe can totally tell them theres an issue being looked at, there will be an incident, a lead one etc. I just meant, we cant make promises or speculations and tell users they will be happening until we have a decision. \r\n\r\nHow would you word it?", "`- Don't forget the statefile, this could cause issues when rebuilding and generating plans.`", "```\r\n| Account | Information |\r\n|----------------- | ------------------------------------------------ |\r\n| Core-Shared-Services | Creates the core shared services account resources. |\r\n| Core-Network-Services | Creates the core networking account resources; this is the highest priority. |\r\n| Core-Logging | Creates the core logging account resources. |\r\n| Core-Security | Creates the core security account resources. |\r\n| Cloud-Platform-Transit-Gateways | Across all regions. |\r\n| Core-VPC-* | Creates the core VPC resources in the VPC accounts, needed after the core-networking-services. |\r\n| Modernisation-Platform | Creates key resources such as S3 state buckets for the platform. |\r\n```", "`1.) In the modernisation-platform repo, run a Terraform plan against the production workspace.`", "`4.) In the modernisation-platform-environments repo, run Terraform against the correct account.`", "`| Secrets Manager | Contains platform secrets. | Yes | eu-west-1 |`", "```\r\nUse the version number stated so these changes are easily recognisable. The version of these modules will then need to be updated on our\r\n`Modernisation Platform` repository, along with any variables changed that are needed. This should go in one large PR with many reviewers.\r\n```", "`| ConfigurationManagement | https://github.com/ministryofjustice/modernisation-platform-configuration-management | This repository contains configuration management of the ec2 infrastructure hosted on the ModernisationPlatform. Requires hardcoded eu-west-2 to be changed. | Yes |`", "`| Instance Scheduler | https://github.com/ministryofjustice/modernisation-platform-instance-scheduler | A Go lambda function for stopping and starting instances, RDS resources and autoscaling groups. | Yes |`", "`Once the modules have been updated, and tagged, as well as the PR merged to change any variable or hardcoded mentions of the region in `Modernisation-Platform` we will need to begin the rebuild of the platform, starting with networking. The steps below outline which order to follow.`", "`This is a large undertaking and has not been tested but discussed within the team.`", "`Rather than rebuilding the platform through workflows, I would run steps manually to easier debug issues, however, technically, you could start to run the account creation process with our GitHub workflows.`", "`1. Clone the modernisation-platform repo, and change the region in the code. Whilst it's as simple as a find and replace, modules are called and need changing, either locally and referenced locally, or in the module and pushed to GitHub.`", "`3. Core Networking would be the next to run Terraform on, checking the code and modules it uses for region references and changing them.`", "`Using the admin role, run a Terraform plan and apply. This hasn't been done from scratch since the platform's creation, so expect to debug issues.`", "```\r\n| Account | Information |\r\n|----------------- |------------------------------------------------ |\r\n| Core-Shared-Services|Creates the core shared services account resources, AMIs, KMS, S3 and other shared services customers require are based in here. |\r\n| Core-Network-Services | Creates the core networking account resources, and contains the transit gateway Terraform, as well as firewall rules. |\r\n| Core-Logging | Creates the core logging account resources, not essential for operational function but a part of the platform. As well as for troubleshooting, logging is required for audit purposes and therefore should also be prioritised. |\r\n| Core-Security | Creates the core security account resources. |\r\n| Cloud-Platform-Transit-Gateways | Across all regions. |\r\n| Core-VPC-*| Creates the core VPC resources in the VPC accounts. |\r\n| Modernisation-Platform | Creates key resources such as S3 state buckets for the platform. |\r\n```", "`Once Terraform has been run against these accounts, member accounts can be next, as technically, all that is required for the platform should now exist.`", "`- Find out what is expected from us, and update the doc. How often do we need to update customers? What downtime will require a migration to another region?`", "`| GitHub OIDC Role | https://github.com/ministryofjustice/modernisation-platform-github-oidc-role | | No |`", "`| GitHub OIDC Provider | https://github.com/ministryofjustice/modernisation-platform-github-oidc-provider | This module allows users to create an OIDC Provider and the associated IAM resources required to make use of the connect provider. | No |`", "`Rebuilding an account entirely through workflows would be the next step, and in an ideal scenario this would work first time, however when errors occur, debugging Terraform plans and applies locally saves a lot of time.`", "`| S3 | Contains the platform's Terraform state files. | Yes | eu-west-1 |`", "`| Main Repo | https://github.com/ministryofjustice/modernisation-platform | Houses all of the Terraform that builds the platform, many modules will be referenced in here and will need the variables changed. | Variable |`", "`### Running the Terraform`", "`After the networking has been completed, the core accounts created, and the modernisation platform itself built, the next step is creating member-accounts. Start with cooker, example and sprinkler, building from the mod-platform repo and then applying the Terraform in the environments repo. This will allow us to test the steps required for our customers to follow when recreating their infrastructure from the environments repo.`"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/6067", "comments": ["```suggestion\r\n          \"github_slug\": \"modernisation-platform-security\",\r\n```\r\nThe github slug needs to match the github slug for the team"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/6065", "comments": ["Hi @haitchison! I think you're actually after this:\r\n```\r\n    \"source_ip\": \"${hmpps-preproduction}\",\r\n    \"destination_ip\": \"${dom1-domain-controllers}\",\r\n```\r\nAs I understand the flow, the source will be your instances in the `hmpps-preproduction` VPC. Also the local that generates the platform CIDR ranges produces them as `$business_unit-$environment` so I've trimmed the VPC name down a bit in my example.", "As above - I think you're actually after this:\r\n```\r\n    \"source_ip\": \"${hmpps-preproduction}\",\r\n    \"destination_ip\": \"${dom1-domain-controllers}\",\r\n```", "Updated! :)"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/6054", "comments": ["should 'example_attachment' be replaced with something more descriptive? "]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/5977", "comments": ["Will need a newline above this, otherwise markdown will not introduce a line break.", "Can we put this in a codeblock, and use a generic name instead of an existing team?", "This is a bit unwieldy to read. Maybe something like... \"this will restrict code approval to only the GitHub team slugs listed in the `codeowners` block.\" ", "Needs a newline above to prevent this from being wrapped onto the same line.", "Done", "Amended and put in <owner-name> and stated this should be replaced with modernisation-platform, for example", "Amended", "Completed", "```suggestion\r\nBy default the codeowners for the application teams folder in the `modernisation-platform-environments` repository will be the GitHub teams defined in the access block.\r\n\r\nYou can over write this by defining codeowners as an attribute for that application.\r\n```", "```suggestion\r\n'\"codeowners\": [\"<owner-name>\"],'  Replace <owner-name> with a GitHub team such as `modernisation-platform`.\r\n```", "```suggestion\r\nThis will restrict code approval to only the GitHub team slugs listed in the 'codeowners' attribute.\r\n```", "Change made"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/5953", "comments": ["Hi @mikereiddigital if this is v15.2.0 you ought to update the comment to say that too?", "Thanks @richgreen-moj - I thought those were updated automatically but I'll amend them :)"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/5942", "comments": ["I think we would want to cut the below block where we attempt to populate with a value, otherwise the actual value we wish to set would be overwritten every time someone merges to this codebase", "Same as above"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/5937", "comments": ["I'd expect to see `cloudwatch:GenerateQuery` as a required permission here - otherwise the JML extract will not be able to query the correct logstreams.", "I'm not sure I understand why this has been made a separate policy? The lambda is not set up to do multiple role assumption in its current form. If there's a good reason (which I can believe there may be) we'll need to see adjustments to the lambda code to allow it to pick up different roles for the different actions.", "I added cloudwatch:GenerateQuery and secrets policy"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/5936", "comments": ["Is this needed?\r\n```suggestion\r\n```", "This would include creating tasks as well, is this needed?", "As above is this needed?"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/5900", "comments": ["Could we add a link to the Slack channel if possible?"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/5804", "comments": ["You could remove the 's3:PutObject' line as you have added in s3:*Object"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/5797", "comments": ["Missing the `/32` at the end here.", "Also missing the `/32` at the end here.", "Amended and repushed", "Amended and repushed"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/5781", "comments": ["cica-copilot"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/5719", "comments": ["just double checking the version shouldn't be... \"github.com/ministryofjustice/modernisation-platform-terraform-lambda-function?ref=a4392c1cc00014a274680d160e75464dce4ba919\" #v2.1", "there is no release of the lambda yet (I want to test it first and update unit tests), hence it's the latest commit, but no new tag", "and should we update this to use the commit hash? \r\n\"github.com/ministryofjustice/modernisation-platform-terraform-pagerduty-integration?ref=0179859e6fafc567843cd55c0b05d325d5012dc4\" #v2.0.0", "I'll update it with my next PR.", "I will address it with the next PR"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/5718", "comments": ["Needed to work, uncomment it please", "Im pretty sure we tested this and it didnt work? ", "Replied in slack", "Replied in slack"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/5653", "comments": ["is this requirement still valid if you've removed the install for the dependency? "]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/5631", "comments": ["this is a bit pedantic of me, but I noticed you are defining env vars globally and then in the job itself... you could argue that all of the vars are global or all of them are local to the job...there is only one job, so it probably does not matter much, but what hurts my eyes is env vars are defined in two places :) \r\nas I said... a bit pedantic of me :D ", "That's OK - this is a symptom of me having borrowed from other jobs and examples! I will tidy that up."]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/5614", "comments": ["could this be updated to v4? \r\nactions/checkout@b4ffde65f46336ab88eb53be808477a3936bae11 # v4.1.1", "bump to version 20?", "Amended", "Amended\r\n"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/5515", "comments": ["```suggestion\r\n\r\n```", "```suggestion\r\n          \"level\": \"instance-management\"\r\n```"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/5496", "comments": ["These are not secrets so don't need to be mentioned here or rotated", "This one is already mentioned above", "I don't think this really adds anything and can be removed", "They are listed as secrets on the https://eu-west-2.console.aws.amazon.com/secretsmanager/listsecrets?region=eu-west-2 page. The GITHUB ones were in the documentation as is - https://user-guide.modernisation-platform.service.justice.gov.uk/runbooks/rotating-secrets.html#introduction", "We have 3 pagerduty ones stored. They are listed as different.", "I'll remove the terraform code if not needed but it does say how to rotate secrets so I thought it may be useful", "Hey, so my comment is just referring to line 25, github just shows the lines above for context.  Ok we can keep them here then but these should not be rotated, also this text can be removed I think `CAUTION: Any account ID you add here will be automatically nuked!`", "It does, but we don't use this method to rotate any of these secrets", "Hmm looks like there are 2 api tokens, I would have though there should only be one.  Could you try to track down where they are used in code and what the difference is please?\r\n", "```suggestion\r\n| PagerDuty Modernisation Platform Team user |  | Used for dead-end notifications as all schedules need a user | MoJ PagerDuty Account | Use password reset process if needed |\r\n```\r\nThis is currently incorrect, pagerduty_integration_keys is a separate secret", "That's what was in place beforehand. I just copied and pasted that to the end of the list.\r\n", "Here's what's in the current documentation \r\n\"ModernisationPlatformOrganisationManagement IAM user in MoJ root account\"", "Again, that was in place before I amended the document. I can remove it though.", "I'll try but we do try to build them from code.\r\n", "All 3 pagerduty codes are used although the first (pagerduty_userapi_token) I checked was in uppercase in a couple of places which probably means it wouldn't work but not 100% certain of that.", "Thanks but I'm not sure what you mean with ModernisationPlatformOrganisationManagement I'm referring to and making a suggestion for line 19, I appreciate this was incorrect before but it make sense to fix it now", "What is the difference between this token and the token on line 18?  Do we need 2 tokens or can one of these be removed from secrets?", "I do not know. Both are used but this one slightly less than the other. In just 4 places and in two of those it is in uppercase. It can probably be replaced by the one above.e.g\r\n\r\ndata \"aws_secretsmanager_secret\" \"pagerduty_user_token\" {\r\n\r\nname = \"pagerduty_userapi_token\"\r\n }\r\n\r\n", "We don't have many secrets on stored on the Modernisation Platform, but ones deemed 'secret' are rotated every 180 days.", "Removed", "Additional line added to explain the issue. Additional code is needed", "Additional note added to explain why this is needed", "Terraform code was removed", "This was already added so not sure why it didn't show in here. ", "```suggestion\r\n| Organisation Level PagerDuty Token | pagerduty_token | Used by PagerDuty Terraform to manage most PagerDuty resources|AWS Secrets Manager | Contact Operations Engineering to issue a new token and update the secret. | 180 |\r\n```", "```suggestion\r\n| PagerDuty Modernisation Platform Team user | N/A | Used for dead-end notifications as all schedules need a user | Not stored | Use password reset process if needed | N/A |\r\n```", "```suggestion\r\n| Environment Management | environment_management | A Map of account names to IDs, and data for environment management, such as organizational unit IDs | Does not need rotating, not really a secret and regenerated on each account creation | N/A |\r\n```", "```suggestion\r\n| Nuke ID List | nuke_account_ids | Account IDs to be auto-nuked on weekly basis. This secret is used by GitHub actions job nuke.yml inside the environments repo, to find the Account IDs to be nuked. |\tNot really a secret, should not be rotated | N/A |\r\n```", "```suggestion\r\n| Nuke Block List | nuke_account_blocklist | Account IDs to be excluded from auto-nuke. AWS-Nuke (https://github.com/rebuy-de/aws-nuke) requires at least one Account ID to be present in this blocklist, while it is recommended to add every production account to this blocklist. | Not really a secret, should not be rotated | N/A |\r\n```", "Could you move this to be next to the other PagerDuty secrets please?", "```suggestion\r\n| Circle CI ID | mod-platform-circleci | CircleCI organisation ID for ministryofjustice, used for OIDC IAM policies | Not really a secret, should not be rotated | N/A |\r\n```", "```suggestion\r\n| PagerDuty user level api | pagerduty_userapi_token | PagerDuty api user level token, used to link services to Slack channels.  A valid PD and Slack user needed (to authorise against a slack user), needed in addition to the org level api | Log in to PagerDuty as your user, create the token and authorise it against Slack | 180 |\r\n```", "```suggestion\r\n```\r\nMoved to the in line descriptions with more detail", "```suggestion\r\n```", "Github didn't want to do this so I have manually changed it\r\n", "Done\r\n"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/5481", "comments": ["We already have providers for cooker here https://github.com/ministryofjustice/modernisation-platform/blob/main/terraform/environments/cooker/providers.tf\r\n\r\n", "we don't create infra resources such as EC2 in this repo, this should go into here https://github.com/ministryofjustice/modernisation-platform-environments/tree/main/terraform/environments/cooker if you want to play around "]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/5470", "comments": ["Would people prefer a `rebuild` "]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/5469", "comments": ["> until they were either modernised and moved to the Cloud Platform, or decommissioned or replaced with newer applications.\r\n\r\nMaybe instead put this as:\r\n\r\n> until they were modernised and moved to the Cloud Platform, replaced with newer applications, or decommissioned.\r\n\r\nThat way, it removes \u201ceither\u201d (there are three options), and goes from most to least favourable.", "Should be:\r\n\r\n> New team required to build and maintain", "Maybe reframe this as \u201cservices\u201d instead of applications, and make it clear above that when you say services, you mean both user-facing apps _and_ platforms?", "Thanks I prefer this, I've replaced throughout"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/5447", "comments": ["```suggestion\r\nSee here our [general incident runbook](manage-an-incident.html)\r\n```", "```suggestion\r\nFollow the [general incident guidance](manage-an-incident.html) to record the incident and gather information.\r\n```"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/5442", "comments": ["Typo", "We should use the variable provided and not hardcode the range.", "Fixed", "fixed"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/5388", "comments": ["```suggestion\r\nIf there is an incident you will need to update the external status page for the modernisation platform [modernisation platform status page](https://status.modernisation-platform.service.justice.gov.uk/) this guide will show you how to do this.\r\n```", "```suggestion\r\nIncidents and associated status updates can be created in two ways, the first way is by logging on to the PagerDuty site and the other is by using the PagerDuty incident creation app within slack via the /PD command.\r\n```", "typo \"ot\" ", "corrected typo", "Can you create a status without an incident?", "```suggestion\r\nThe next way you change change the status on the status page is by logging in to the pager duty site via the following [Link](https://moj-digital-tools.pagerduty.com/). Once logged in hover over the status menu option at the top right of the page then click on external status.\r\n```", "```suggestion\r\nWhen this page loads there will be two options to choose from, click on the Modernisation Platform, from here you can click on post new incident, and will be presented with a form to fill in.\r\n```", "```suggestion\r\nOn the form you will need to select the incident status add an incident title and also a description, once you have done that you will also need to select which business service is impacted and also the impact to that service. The last item that needs to be selected is the amount of time until the next update, if you are happy with the information inputted click on the Post button.\r\n```", "```suggestion\r\nThis will then need to be approved before the status page is updated.\r\n```", "```suggestion\r\nApprovers will be notified of the new incident once it has been raised, approvers will then need to log in to PagerDuty to review the incident.  Once they are happy they can click on the publish button and the incident page will be updated.\r\n```", "```suggestion\r\nIn the event of an incident you can subscribe to the incident for email updates additionally you can also subscribe to the whole page if you want to be informed of future updates.\r\n```", "changes implemented", "talked about this in standup", "or planned... outage?", "```suggestion\r\nThe next way you change the status on the status page is by logging in to the pager duty site via the following [Link](https://moj-digital-tools.pagerduty.com/). Once logged in hover over the status menu option at the top right of the page then click on external status.\r\n```", "there is a missing word maintenance should be there ", "how will they be notified?", "new commit added ", "added how approvers get notified", "```suggestion\r\nThe other way you change the status on the status page is by logging in to the pager duty site via the following [Link](https://moj-digital-tools.pagerduty.com/). Once logged in hover over the status menu option at the top right of the page then click on external status.\r\n```"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/5312", "comments": ["Is this value derivable through a data call?", "So I had it hard code before and was calling it from there which worked great, but having it in code is not allowed, had to scrub it as its classed as sensitive. \r\n\r\nThis is how cloud platform do it, I'm open for better options though!", "If there's no better option than, say, a blank string, then it's going to have to suffice \ud83e\udd37\ud83e\udee0"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/5267", "comments": ["Is this the same as the CICD user policy?  These permissions seem quite open?", "They're similar, and actually as this is just for one team currently they could be less, it's hard to get exactly what the team require though, will chase them again."]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/5194", "comments": ["Is this removal intentional?", "No it's not - I'll rebase from main and see what happens!"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/5159", "comments": ["Can we check that this is relevant? I know that's the CCMS-EBS go live date, but I don't think this is directly part of CCMS, more that it's an area for them to do R&D on upgrade activities", "It's not relevant so I will remove it", "Thank you!"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/5069", "comments": ["Would this work better as a checkbox? or should it stay as a text box so additional requirements could be added? \ud83e\udd14 "]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/5057", "comments": ["Could we change this to...\r\n```\r\ndescription: \ud83d\udcd6 Create Modernisation Platform story\r\n```\r\nI think this would read a bit better. The `new` feels redundant, and it's not exclusively going to be a DevOps story that gets raised.", "yep not a problem", "`description` not `descripyion`", "`attributes` not `attribures`", "corrected", "corrected"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/5050", "comments": ["No apostrophe needed in `SME's` - `Subject Matter Expert` would do fine here.", "Personally I'd just write `Definition of Done` here as it's not previously described and shown as an acronym."]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/5009", "comments": ["This should be set to administrator for unrestricted accounts", "Non needed for unrestricted account", "Should be administrator"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/5003", "comments": ["```suggestion\r\n  \"github-oidc-team-repositories\": [\"ministryofjustice/performance-hub\"],\r\n```", "Thanks - I assumed `ministryofjustice` was assumed (like CP)  \ud83d\udc4d"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/4871", "comments": ["you have two view only's should one of them not be developer?", "you have two view only's should one of them not be developer?", "you have two view only's should one of them not be developer?", "Corrected", "Corrected", "Corrected"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/4862", "comments": ["Copied base from `example.json`, not sure what to do with these two fields: `go-live-date` and `github-oidc-team-name` \ud83e\udd14 ", "Set go live to today's date and removed the github-oidc-team-name", "Sorry, thats my work currently , the \"github-oidc-team-name\" can be taken out"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/4846", "comments": ["If this is blank, does it serve any purpose? Could we just set the same go-live date as other platform accounts here?", "If we're potentially having multiple OIDC values, maybe something like...\r\n```\r\n  \"oidc\" : {\r\n    \"github-team-name\": \"github-oidc-repositories\"\r\n  }\r\n``` ", "Well, it's not live so doesn't have a go live date, same with example. ", "Ive gone with github-oidc-team-repositories\""]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/4814", "comments": ["i am a little lost in what this paragraph is trying to say\r\n\r\nis it something on the lines of configuration management  will add this?", "again first sentence does not read right to me whats automated would it not read better with something like an automated solution that keeps  ", "also maybe replace which works with that works", "don't move the comma just change simpler to simple", "may required change to require ", "So it's kind of a pros and cons statement, but in a paragraph, so I could have also written like:\r\n\r\n**Pros**\r\n - Automated\r\n - Everything in one place\r\n \r\n**Cons**\r\n - Mixes infrastructure and configuration management\r\n - Adds to already large repository\r\n\r\nI was trying to keep it short but happy to do either way?"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/4812", "comments": ["We're using this hosted zone to maintain the same URL as the legacy environment. We will delegate DNS to this hosted zone and add a helpdesk.jitbit... record here"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/4804", "comments": ["`[deploying your infrastructure]` instead of `[deploying you infrastructure]`?", "FWIW, markdown will still display this in numerical order even if the source doesn't.", "Good spot! Sorted \ud83d\ude01"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/4799", "comments": ["What purpose do these VPNs serve?", "Assuming we only want to check against a single host in devtest, according to the story comments we only need `10.102.1.79/32`, so we don't need to make any changes to this local.", "LGTM - you'll need to route this through both the `NOMS-Transit-Live-VPN-VNG_1` and `NOMS-Transit-Live-VPN-VNG_2` VPNs."]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/4763", "comments": ["\u261d\ufe0f I'm an Organisation owner, so I need to be on the maintainers' list \ud83d\udd27", "ok"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/4754", "comments": ["would we not keep it line with the rest ie ${aws_route_53.dev.legalservices.gov.uk.id}\r\n"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/4653", "comments": ["`Private` not `privaye`", "`private DNS zones. This` instead of `private DNS zones this`?\r\nAlso a bit of duplication here `to be done in to be done in`.", "`below`, not `bellow`?", "`example.gov.uk`, not `exmaple.gov.uk`?", "How about...\r\n> `local.private-application-zones` should contain a mapping of business units to private Route53 hosted zones. This local is supplied to a module that configures the VPC-to-zone association.", "corrected", "corrected", "corrected", "corrected", "corrected", "Probably don't need to comment out the code in an example :)", "corrected"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/4604", "comments": ["Personally I'd prefer `private-application-zones` here.", "This is better done in the module - that way you can supply the name of the zone (eg, `each.value`) and dynamically get the zone_id", "It feels like there's too much here - i'll add more detail in the module review but you're missing the core-network-services provider, and the rest of this would be reworked from the module.\r\nHowever, the `for_each` is wrong (local.private-application-zones is what you want), and I don't see what purpose `environment` serves here.", "I don't think you need to define this here.", "I think you should be doing the data call for the zone here, based on a variable (eg, `var.private_zone_name` or something like that) that you pass in when using the module.", "What value does this output serve? Is it just for test purposes?", "This looks fine, but I'd harmonise the names (EG. `private_zone_*` or `private_zone_vpc_*`)", "As below I'd pass the zone ID in from the output of the data call commented out below.", "If this isn't used it should be deleted.", "If this isn't used it should also be deleted.", "Is this variable type right? It looks like it's being treated as a string. Also, is it necessary?", "Where is this variable being used?", "LGTM! \ud83c\udf89", "removed", "removed", "removed", "variable removed", "variable changed", "this has now been corrected to be passed from the data entry within the module", "changed the name so that they match", "output removed", "data source reinstated", "environment removed  for_each updated", "removed data entry from vpc and placed in module", "reference updated", "Are these values needed in this PR?", "Do we need the module if we're not creating any private zones that need associating across accounts?", "You can remove the comments from the variables and supply them as a `description = \"example\"` in each variable block", "Similarly, this comment isn't necessary", "If the `for_each` isn't needed, it can be removed", "This comment can be safely removed :)", "```suggestion\r\nresource \"aws_route53_zone\" \"private_application_zones\" {\r\n```\r\nCould you use snake case for Terraform names please? ", "removed", "code changed", "already removed", "removed and description added", "comment removed", "removed examples", "commented out the call for the module for now until needed", "`passing account` instead of `passingaccount`?", "`description` instead of `escription`? Also, `\"Variable...\" instead of `\"variable...`?", "corrected", "corrected"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/4600", "comments": ["nope, we want it to be an additional role added and not a replacement for developer", "re-added developer level. "]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/4599", "comments": ["Did you mean to remove the ability for the instance scheduler to stop instances?", "Edd put together this release while I was off. I assumed this is added as part of the later release when the IAM changes are made but not 100% sure\r\n"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/4596", "comments": ["is this blockquote intentional?", "Basically I missed that when i originally created the document (well copied it from CP), and CP has that blockquote."]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/4583", "comments": ["The policy attachment will need a different name :) ", "just noticed, when running it locally :) thanks!"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/4524", "comments": ["Not in alphabetical order like the rest, tiny, but might as well match the rest!", "resolved with latest PR"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/4520", "comments": ["this should be something like `github-oidc-repositories`", "This attribute is used for managed policy ARNs, eg the readonly managed policy", "The policy here should be the member ci-cd policy (this will need to be duplicated for now as it currently is in different Terraform module here - https://github.com/ministryofjustice/modernisation-platform/blob/main/terraform/modules/iam_baseline/main.tf#L13)", "this should be something like \"github-oidc-cicd-repositories\""]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/4507", "comments": ["I don't think it needs to be ordered alphabetically, but since we've kept it that way so far, it's probably worth continuing", "updated alphabetically"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/4435", "comments": ["Can you add the version tag as a comment after the ref?\r\n`#v3.0.0`", "As above - can you add a comment with the tag version for readability?", "As above - can you add a comment with the tag version for readability?", "As above - can you add a comment with the tag version for readability?", "As above - can you add a comment with the tag version for readability?", "As above - can you add a comment with the tag version for readability?", "As above - can you add a comment with the tag version for readability?", "As above - can you add a comment with the tag version for readability?\r\neg - `# v5.0.0`", "As above - can you add a comment with the tag version for readability?\r\nEG. `# v7.0.0`", "As above - can you add a comment with the tag version for readability?", "As above - can you add a comment with the tag version for readability?", "As above - can you add a comment with the tag version for readability?", "As above - can you add a comment with the tag version for readability?", "As above - can you add a comment with the tag version for readability?\r\nPS - if you're still reading these, well done.", "As above - can you add a comment with the tag version for readability?", "As above - can you add a comment with the tag version for readability?", "Version tag please!", "Version tag as comment please", "Por favor, one version tag as a comment please", "As above - can you add a comment with the tag version for readability?", "As above - can you add a comment with the tag version for readability?", "As above - can you add a comment with the tag version for readability?", "Are you sure this will work? Since it's a direct reference to something in the module registry a version tag might not be appropriate (and isn't in line with the other registry modules in this commit)", "As above - can you add a comment with the tag version for readability?", "As above - can you add a comment with the tag version for readability?", "As above - can you add a comment with the tag version for readability?", "As above - can you add a comment with the tag version for readability?", "As above - can you add a comment with the tag version for readability?", "As above - can you add a comment with the tag version for readability?"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/4422", "comments": ["Can you change this one to reference `${cloud-platform}` for the destination please?", "addressed\r\n"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/4420", "comments": ["This line isn't necessary - in fact this file isn't strictly speaking necessary as we don't flow internet traffic through the central firewall, just the inline inspection ones.", "Removed my addition to this file. Will let someone else remove the file as it's mentioned in the Readme"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/4399", "comments": ["```suggestion\r\n          \"github_slug\": \"laa-aws-infrastructure\",\r\n```"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/4390", "comments": ["```suggestion\r\n```\r\nCould we remove the StopLogging action please?  I'm wary of giving permission to turn off Cloudtrail logs! Thanks", "removed \r\n\r\n      \"cloudtrail:StopLogging\","]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/4273", "comments": ["```suggestion\r\nIf the environment is being created for an account type of member-unrestricted it will not create the PR in the modernisation-platform-environments repository and this step can be ignored.\r\n```"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/4260", "comments": ["```suggestion\r\n  \"cp_to_platforms_development_icmp\": {\r\n```"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/4255", "comments": ["This should be member unrestricted"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/4245", "comments": ["```suggestion\r\n```", "```suggestion\r\n```", "```suggestion\r\n```", "```suggestion\r\n```", "```suggestion\r\n```", "```suggestion\r\n```", "```suggestion\r\n\r\n  slack_workspace_id = \"T02DYEB3A\"\r\n```"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/4210", "comments": ["This permission set needs to be created here first https://github.com/ministryofjustice/aws-root-account/blob/main/management-account/terraform/sso-admin-permission-sets.tf#L129"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/4172", "comments": ["```suggestion\r\n```", "```suggestion\r\n          \"level\": \"instance-management\"\r\n```"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/4162", "comments": ["is it not logs rather than log? ", "you are correct"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/4153", "comments": ["nice, thanks for adding it there"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/4140", "comments": ["```suggestion\r\n          \"hmpps-oem-preproduction\"\r\n```", "added missing quote in latest commit"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/4087", "comments": ["How about...\r\n```AWS [Network Firewalls](network-firewall.html) provide additional controls to traffic entering and exiting the Modernisation Platform.```", "yep sounds good to me\r\n"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/4064", "comments": ["this change needs removing;"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/4046", "comments": ["You can remove this provider block and use the default provider", "Same here, provider block can be removed"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3958", "comments": ["can we have a reasoning why we are suppressing this message, please? like in the previous file:\r\n`# checkov:skip=CKV_AWS_356: \"Cannot restrict by KMS alias so leaving open\"`", "```suggestion\r\n  #checkov:skip=CKV_AWS_356: Needs to access multiple resources\r\n```", "```suggestion\r\n  #checkov:skip=CKV_AWS_356: Needs to access multiple resources\r\n```", "```suggestion\r\n  #checkov:skip=CKV_AWS_356: Needs to access multiple resources\r\n```", "```suggestion\r\n  #checkov:skip=CKV_AWS_356: Needs to access multiple resources\r\n```", "```suggestion\r\n  #checkov:skip=CKV_AWS_356: Needs to access multiple resources\r\n```", "```suggestion\r\n    #checkov:skip=CKV2_AWS_356: Needs to access multiple resources\r\n```", "```suggestion\r\n    #checkov:skip=CKV2_AWS_356: Needs to access multiple resources\r\n```", "```suggestion\r\n# Following AWS recommended policy\r\n#tfsec:ignore:aws-iam-no-policy-wildcards\r\n```"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3942", "comments": ["Sorry nitpicking on naming, could this be `parole_board_to_mp_hmpps_production_https`"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3923", "comments": ["Multiple spelling errors in this line", "Not sure if I would mention this as the coding examples relate to user code rather than module code, unless you make the suggestion that they update the example code with any changes they make to the module?", "These are not modules but files, I don't think we need to mention these as you state we'd prefer if they weren't amended.", "I don't think you need the tf docs here", "```suggestion\r\nThe purpose of this document is to show contributors to the Modernisation Platform code the best practises and testing that should be undertaken. Code should be in Terraform and tests, if coded, in Go.\r\n```", "I was going to suggest that. Please leave alone unless if's something that could be of use elsewhere, type of comment. Might also mention about the module option in the earlier comments.", "It doesn't check spelling :-( \r\nI will include your other suggestion.", "Removed", "Is there a link to the Service Standard? As it's capitalised I presume it's an important document.", "How is the documentation relevant to contributors? If it's not relevant - eg, it's relevant to *users* - then do we need to mention it to people looking to write terraform or terratests?", "A few spelling mistakes here, but personally I would point customers at our module template, and a module that you think is particularly worthwhile. The code in `ministryofjustice/modernisation-platform-environments` is relevant to modernisation-platform users and is specific to that repository.", "Not sure on this. It's useful advice, but again is geared towards users of the `ministryofjustice/modernisation-platform-environments` repository. Maybe something instead here that covers writing / running tests and their importance?", "Is this relevant? As above, this is useful for `ministryofjustice/modernisation-platform-environments` customers but a `CONTRIBUTING.md` is intended to inform prospective contributors to a repository on the owner/maintainer's expectations.", "Copied and pasted from another document. It does bring up a link to the web page when selected based on the section in brackets.", "Again copied from another contributing document.", "This is kind of mentioned in the coding section below this but I have put a comment in place", "So just put in a following the usual git commands comment and remove the working in Github reference?", "How about adding a link to it? I believe the service standard in question is this one: https://www.gov.uk/service-manual/service-standard", "I understand that this has come from a contributing document, but I question the relevance - this file is around helping people contribute to our code, but this feels relevant to users and I don't think that's the purpose of this document.", "I'll amend it and add the one you suggest to the service standard heading", "This is more relevant to users than to people contributing, I think this should say something along the lines of if creating a module and want to show it working or if you wish to provide and example of code which can be used on the platform, this folder can be used to do that, and mention about keeping the code in distinct sections so that they can be run independantly.", "It may be better to just say you can plan your Terraform code locally if you need, guidance on how to do this is here (and link to the guidance on this) otherwise it's repeating ourselves and will need changing in multiple places.", "Typo in git, but I don't think you need to say how to raise a PR people should know how to do this so this can be removed.", "This should say that these files are generated by templates, so if the templates are changed all of the files should be changed.", "I think this guidance is more for end users using the platform than contributing and can be removed.", "Again this is guidance for end users doing their normal stuff rather than for contributors contributing to modules or our code base.", "@davidkelliott So should I be concentrating on the modules side or the \"platform\" code section?\r\nI'll try to include something related to requesting a new repo but I think that's more of a niche case (only one team has needed it)"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3917", "comments": ["could we use more meaningful name here?"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3906", "comments": ["```suggestion\r\nOur [Networking Diagram](../concepts/networking/networking-diagram.html) shows a high level view of how shared\r\n```", "```suggestion\r\nOur [Networking Approach](../concepts/networking/networking-approach.html) discusses and \r\n```", "```suggestion\r\n- [How VPCs access the internet](runbooks/how-vpcs-access-the-internet.html)\r\n```", "```suggestion\r\nOur shared VPCs have private subnets and data subnets. These subnets have [restrictive NACLS](../concepts/networking/networking-approach.html#nacls)\r\n```", "```suggestion\r\nto the private and data subnets contain a default route to the internet via a [Transit Gateway](../concepts/networking/networking-approach.html#what-we-decided-transit-gateway)\r\n```", "```suggestion\r\nOur `core-network-services` VPCs contain [Network Firewall](../concepts/networking/network-firewall.html)\r\n```"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3837", "comments": ["This record isn't needed, this is creating a name server record which would send all DNS queries to the ns records detailed in this record.  We don't need to do this here as we want to have control of the domain.  What we do need to do is once this hosted zone is created, get the NS records for this new zone and give them to ops engineering so that they can create a record like this one to forward queries on to us"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3729", "comments": ["just checked and NOMS-Live CIDR range is 10.40.0.0/18"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3722", "comments": ["all of these azure cidr ranges belong to hmpps, so perhaps worth mentioning it", "Good point I'll update now...", "I can't see this one in the list of cidr-ranges, or do I need glasses?", "I can't see this one being defined", "can't see it defined in the cidr ranges", "can't see it defined in the cidr ranges", "can't see it defined in the cidr ranges", "These are defined here - https://github.com/ministryofjustice/modernisation-platform/blob/a4fd7fefa73992c4e8c7beaaea41136f0da9037a/terraform/environments/core-network-services/cidr-ranges.tf#L7 these are our MP ranges, and are generated from the environments-networks files so they are not repeated, also they won\u2019t need to be updated if we add more business units.\r\nThey always follow the same format eg laa-development businessunit-environment so it should be fairly easy to work with (or check the environment-network files if not sure)\r\n", "I would only suggest a comment above this line, to give examples of what the end product is of the for loop, e.g. This will produce vpc CIDR ranges for each business/env, e.g. `hmpps-development = \"10.26.24.0/21\""]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3721", "comments": ["```suggestion\r\n      \"acm:AddTagsToCertificate\",\r\n```\r\nSmall typo :) "]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3703", "comments": ["Love moving this into a folder \u2764\ufe0f much cleaner", "Thanks! It wasn't so bad with four files, but now that there's seven, it's gotten a bit out-of-hand!"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3688", "comments": ["Naming: to_hmpps_preproduction", "Naming: to_hmpps_preproduction", "Naming: to_hmpps_preproduction", "Naming: to_hmpps_preproduction", "Naming: to_hmpps_preproduction", "Naming: to_hmpps_preproduction", "Naming: to_hmpps_preproduction", "Naming: to_hmpps_preproduction", "Naming: to_hmpps_production\r\nSame with the other rules", "```suggestion\r\n  \"nomisapi_preprod_root_to_mp_hmpps_production\": {\r\n```", "```suggestion\r\n  \"aks_studio_hosting_live_1_to_mp_hmpps_production\": {\r\n```", "```suggestion\r\n  \"noms_mgmt_live_to_mp_hmpps_production\": {\r\n```", "```suggestion\r\n  \"noms_live_dr_to_mp_hmpps_production\": {\r\n```", "```suggestion\r\n  \"noms_live_to_mp_hmpps_production\": {\r\n```", "```suggestion\r\n    \"destination_ip\": \"10.27.8.0/21\",\r\n```", "```suggestion\r\n  \"nomisapi_prod_root_vnet_to_mp_hmpps_production\": {\r\n```", "```suggestion\r\n  \"analytical_platform_to_mp_hmpps_production\": {\r\n```"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3663", "comments": ["this one could be renamed to hmpps as well", "and this one as well could rename nomis to hmpps"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3660", "comments": ["Are able to include the slack channel info?"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3629", "comments": ["What is this used for? Should we be using our token here?", "Good spot, this is for posting comments in a PR (tf plan/apply output) I believe (that's what we used it for in DSO in the past)", "this PAT is global to organisation, I would be tempted to re-use it (once AL goes away, it would be nice to keep it), but if we have one as well then it makes sense to use ours", "see our new shiny secret please :)", "this token is updated now to MODERNISATION_PLATFORM_CI_USER_ENVIRONMENTS_REPO_PAT"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3627", "comments": ["you're missing the closing bracket here `}`", "this comma is causing issues", "the bracket isn't a problem, but the json isn't formatted well"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3619", "comments": ["This block of code will add a new repository and archive it. However, such resource already exists and needs updating. Do a search in code for the repo name and you will find it."]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3573", "comments": ["This is incorrect"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3560", "comments": ["little hiccup Used mebers should be Used members", "or used by as well", "again i think used by would sound better"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3504", "comments": ["Should this be preproduction?", "Perhaps, but from the LAA perspective, the VPC is their staging environment and named as such in other places so I felt it better to be consistent"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3486", "comments": ["Isn't \"servicediscovery:TagResource\" needed here too as per above file?"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3484", "comments": ["nope, that's not gonna work, you need the slug not a team name"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3447", "comments": ["seem a bit of a wide range can we not lock it down to a shorter range?", "missing end },", "missing end },", "Not without going back to the customer and asking them to narrow it down; this was the range they supplied. It covers PSN addresses and belongs to DWP.", "fixed! thanks!", "fixed! thanks!", "ok"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3402", "comments": ["```suggestion\r\n   service = pagerduty_service.jitbit_nonprod.id\r\n```"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3367", "comments": ["This should be developer access", "This should be developer access", "role updated", "role updated"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3363", "comments": ["```suggestion\r\n  alias  = \"us-east-1\"\r\n```"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3355", "comments": ["This provider isn't needed, the boot strapping won't be creating any resources in us-east-1, also I think this would create a dependancy loop if you used this provider as you are creating a role then trying to assume it in the same terraform", "```suggestion\r\n```", "@davidkelliott Yeah I was looking at the output and realised that now, thanks"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3347", "comments": ["look at the details in the ticket, they have not requested a sandbox", "@ewastempel Amended"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3330", "comments": ["this should not be enabled by default", "Will remove the nuke", "Should this be `nomis-data-hub`?", "@dms1981 That's what it says in the request.", "@dms1981 amended and pushed up again\r\n"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3316", "comments": ["I'm not sure where you mean by bottom of the left hand menu, could you either add more details, or remove this paragraph as the above paragraph may be enough.", "Could you specify which values to change please - (Desired capacity, Minimum capacity and Maximum capacity) thanks", "Change made and pushed through\r\n", "Change made and pushed through\r\n"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3285", "comments": ["Did you mean `files` here, rather than `folders`?", "Yes. D'oh\r\n", "New issue pushed", "We can probably remove this line"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3219", "comments": ["Could you remove `image` from the name so it's a bit more generic please?", "I think this will need a different name so it doesn't clash with the above module", "module name changed", "bucket name changed"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3193", "comments": ["You'll want `tipstaff-development` here", "You'll want `tipstaff-production` here", "Bloomin typo. I'll sort it\r\n", "As previous comment"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3179", "comments": ["I have a feeling this needs to be added in an alphabetical order...", "The indentation/formatting looks a bit funny here. I think it is correct in terms of the syntax, but it's difficult to review. \r\n\r\nI know we have a formatter that runs nightly now, but in the future you can format your JSON code in VSC with `Ctrl+Shift+I`. It's a good habit to have anyway.", "I'll amend\r\n", "This looks fine in the editor (copied and pasted from another environment) so not sure why it isn't here. I'll leave as it is."]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3177", "comments": ["Close! You'll want something like this:\r\n```\r\nname = format(\"%s-%s\", var.fw_policy_name, random_id.policy_id.id)\r\n```", "ok cool will make that change"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3165", "comments": ["The `SECURITY` contact is already managed by [aws-root-account](https://github.com/ministryofjustice/aws-root-account/blob/main/management-account/terraform/alternate-contacts.tf#L10) for _all_ AWS accounts, so you won't need this here.\r\n\r\nIt is periodically run (manually) to capture any new accounts created \ud83d\udc4d\ud83c\udffc ", "Thanks! Removed :D "]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3157", "comments": ["I notice this will change the location of the state file, but looking in the S3 bucket it's already in this location and last accessed in November, so Im not sure if it was changed accidentally to it's current location, but either way this should be fine.  You may want to delete the file in the old location to tidy up.", "oh yes, well noticed, weird, but this looks like the correct path, so yes, I will delete the other state and keep this one;\r\nthanks Dave!"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3154", "comments": ["Alternatively you could test if the account_type != \"member\"", "thanks Dave, good to know"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3122", "comments": ["Could we use `fw_allowed_domains` to stay consistent with the naming of the other variables? We should probably have a `description` in the variable block too.", "The `capacity` value seems low to me. Should this be supplied with a variable, with a greater default value? The documented maximum for a rule group is `30000`, but the implied limit for a policy is `30000`, and that would be a combination of all the associated rule groups."]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3115", "comments": ["or you could leave that block there, but set it to: `DEFAULT_ACTION_ORDER`\r\n\r\nthis way it will be obvious from the code what the order is, just a better readability (in my opinion)", "very good point and amended to suite"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3114", "comments": ["perhaps it's worth creating a data.tf for data", "same, as my previous comment RE data.tf file", "Perhaps `var.vpc_name` could be a more user friendly name? Although I think that would require more changes", "It would be friendlier, yeah. I think I can accommodate that. It should be a matter of supplying it through the `for_each` that I have in place."]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3106", "comments": ["if needed, this should go to providers.tf\r\n\r\nthis change on its own will not have the desired effect. Note, you will need to reference it in your resources for it to have an effect ", "Made amendments and pushed back up"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3105", "comments": ["You may want to add the release in a comment after the hash (dependabot will update this as well) to help easily see what version is running\r\n\r\n```suggestion\r\n        uses: oxsecurity/megalinter/flavors/terraform@8fd433c675d27ceca5a61ace53177c1bbfbf7f49 #v6.18.0\r\n```", "keep the version number pls: # v3.3.0", "OK! All done in my most recent commit - [7b900a9](https://github.com/ministryofjustice/modernisation-platform/pull/3105/commits/7b900a94535a641690adfd05539e5df4da96219a)"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3104", "comments": ["This provider is not used it can be removed", "Done and re-pushed"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3098", "comments": ["Looking at the available log groups in the core-logging account, I think you wanted to use: `modernisation-platform-r53-resolver-logs` log group.\r\n\r\nso it would be something like this\r\n`resources = [\"arn:aws:logs:*:*:log-group:modernisation-platform-r53-resolver-logs:*\"]`\r\n\r\nHowever, I think it would be better if you narrow it down to that account as well, so this is not a complete answer, but a pointer", "@ewastempel - I think a condition that includes only accounts in our OU might be the best way to do this.", "Also this _might_ be incorrect, as we're asking to allow the route53resolver to do the logging, so `route53resolver.amazonaws.com` might be the appropriate thing here.", "I'll amend it and post the update", "Apologies! I didn't spell it quite right - `route53resolver.amazonaws.com` should be what we're after, and I've amended my original comment to show this"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3090", "comments": ["The /terraform/modules folder is for users to create their own modules without needing approval from us, so that can be left as it is with no codeowner", "updated"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3087", "comments": ["There are too many permissions in this policy, the policy should be only the additional permissions stated in the card, then also the AWS managed read only policy attached", "I think we should avoid abbreviations where possible, how about `instance-management` as it allows management of EC2s and RDS instances?", "```suggestion\r\n|database-mgmt|Role for use by instance management with permissions for EC2 and RDS instances | Used by database or EC2 administrators  to migrate services and perform tasks.\r\n```", "The SSO plan is failing as the name is too long, maybe rename to mp-instance-management ?", "I think this statement should be removed as it's probably too excessive for this role", "Is this change intentional?"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3076", "comments": ["`protect resources` rather than `protecte reources`", "`with general AWS resources` rather than `with a general aws resources`", "This just reads like a copy-paste from an AWS docs page. Does it add any value to a reader, or should we just have a link to the AWS document?", "Maybe turn the *_rules.json text into a bullet pointed list with each one hyperlinked to the file in our GitHub project?", "`things easier` instead of `thing easier`, `I have` instead of `i have`, `Modernisation Platform CIDR ranges` instead of `MP cid`?", "`how to add rules` instead of `how add rules`. Also there's no example in the document.", "yep it was i'll change for a link instead", "changed file names  to links and changed them to bullet points", "example pr added as a hyper link to the bottom of the document", "Still has a mis-spelling - protecte reources instead of protect resources", "```suggestion\r\nWe currently have setup in our core-network account AWS Network Firewall to monitor and control network traffic on a layer 3 level for transit gateway connection and cross account VPCs to protect reources\r\n```", "```suggestion\r\nTo learn more about AWS firewall please follow the link bellow\r\n```", "```suggestion\r\nThe rule files are broken down to environment and not account to make thing easier to keep track of, see below our CIDR ranges to help with forming new rules.\r\n```", "```suggestion\r\nRules are made up of a rule description and an action which would either be the DROP, PASS or ALERT, which would block, allow or monitor traffic based on the source IP or CIDR range then a destination IP or CIDR range, the port number is required next finally the protocol used. This can be IP or UPD.\r\n```", "Should this be TCP or UPD?", "This doesn't format very well currently. If you add a code block it will look better - \r\n3 back ticks\r\n```", "```suggestion\r\nBelow is an example of PR of how add rules. In this example there is one additional rule to be added for the network firewall.\r\n```", "connection or connections", "Technically speaking this will be inaccurate after this sprint - we're going to start reading FQDNs which is going to be a layer 7 function (hostname in a HTTP header)", "changed to connections", "updated so that it mentions layer 3-7", "You've got a rogue space, and below you use `destination cidr ip` so would you want `source ip` here?", "I'd probably go with...\r\n```\r\n\"destination_port\": \"<destination port, but can also be ANY>\"", "Close! There's quite a range that are available, and it's not worth repeating them here: https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/networkfirewall_rule_group#protocol", "`These` not `thes`, and `below` not `bellow`.", "these have now been replaced with an actual example rule", "these have now been replaced with an actual example rule", "link added into the example section", "`along with` rather than `along with a`", "spelling corrected", "`in the terraform/environments/core-network-services directory` rather than `from the core-network-services in the terrafrom environments folder`", "`start by cloning the repository` rather than `start by pulling down the latest copy of the repo using git pull`.\r\nShould probably have `appropriate json` instead of `appropriate Json` for consistency", "`Change` rather than `changing`?", "`commit your change and create a pull request` rather than `save and commit your change and then do a git push to the repo to create a pull request`", "`Terraform documentation` rather than `Terraform site`", "corrected", "Changed", "amended", "spelling corrected", "amended", "line changed"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3051", "comments": ["have you already created a follow on story to look at it then?\r\nI am worried we will skip them checks and then never look at it; so I would say, if you don\u2019t think it\u2019s resolved, don\u2019t skip them", "removed line 11  as we can't restrict access to resources"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3049", "comments": ["Tags don't need to be supplied in a module, and won't work in this format. Consider having a variable that tags a map here instead.", "`tags` map is empty and will need to be supplied with something. Perhaps a variable?", "Hard coding the ARN here will fail since this resource isn't created in this module, so Terraform will have no way to retrieve it.", "Comments here should either be removed, or the regex should be fixed as this isn't relevant to the purpose of this PR", "There's no need to create a new route53 zone is there?", "The provider here won't work", "Does a provider need to be hardcoded? Isn't the default provider sufficient?", "What purpose does this provider fill? If it's needed it ought to be created in `providers.tf` for consistency / ease of comprehension", "I was going to add the ones I put in the variable list. I'll have a think", "My plan is to build that first. Once it is in place I could then find the actual arn and use that. Not entirely sure that will work how I want but that was my thought process\r\n", "That's the section I commented out to get the plan to run. We need to look at it to see if the code can be amended to work correctly.\r\n", "Forgot to remove this code\r\n", "Copy and pasted the resource from terraform but forgot to remove the provider", "Copy and paste from the original location. Will add a providers.tf for this\r\n", "Here's some examples of how tags are applied in different modules:\r\n\r\nhttps://github.com/ministryofjustice/modernisation-platform/blob/main/terraform/modules/kms/main.tf#L7\r\n\r\nhttps://github.com/ministryofjustice/modernisation-platform/blob/main/terraform/modules/vpc-nacls/main.tf#L5\r\n\r\nhttps://github.com/ministryofjustice/modernisation-platform/blob/main/terraform/modules/ec2-tgw-attachment/main.tf#L44\r\n\r\nYou can see in all these examples that tags are passed in as a variable.", "Hardcoding the ARN won't pass a pull request review; you'll want to supply it to the module via a variable", "You'll want to either remove the comments to return it to its original state or fix the regex prior this pull request being reviewed", "Can we come up with a more intuitive name? How about...\r\nname = \"modernisation-platform-r53-resolver-logs\"\r\n?", "Still not convinced we need this here! It should work fine with the default, or `provider = aws.modernisation-platform`", "These comments will need to be removed. I understand that the AMI lookup doesn't work, but that's better handled in a separate PR / as a separate issue", "Having these in the file but commented out doesn't serve a purpose so they ought to be removed", "Can you update the resource name here to something like `\"route53-resolver-logs\"`?", "As previously noted, this file doesn't need to be part of the commit. Can you remove the comments from the start of the lines here and raise an issue to fix this data call / take it on as a separate task?", "Put in variables", "Amended to sort that", "Amended to aws_route53_logs I think", "Left for the time being. May be removable.", "Will do", "Amended", "Agree this is just a duplicate of the provider on line 10 and can be removed and aws.modernisation-platform can be used", "+1 needs to be removed", "Agree it's better to split this out and fix separately, then once fixed and merged rebase against main, otherwise it adds confusion the PR and it makes it harder to back out if we want to revert it.", "Since these locals are getting external things would it be better to pass what is needed into the module?  The could then be passed in when the module is called and don't need to be duplicated here.", "I would add this code under a route54_logging.tf, this file is used for monitoring code", "I would pass this value in to make the module more flexible", "I'm still seeing commented out code", "Name changed but the plan was to move this out of this PR. I've created a new one which will contain, hopefully, ny other changes made to that.\r\n", "Change made in another PR so it won't show in this one\r\n", "Commented out code removed", "Comments removed. Will raise an issue to fix this. Uses a very old version of linux so may no longer be available\r\n", "Removed the above from the PR so the original will stay in place.", "Removed the above from the PR so the original will stay in place.", "Removed from the PR", "The above changes have been made so this is resolved now", "New routine (in the other PR) has been added and this have been moved", "Changes made to this to pass in a variable which will be made available from the call in core-vpc (in another PR)"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3012", "comments": ["I think this needs to be 64522", "I think this needs to be 64522"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/2950", "comments": ["Could we get this list dynamically so we don't need to manually update it?  It might need to be a concat of a few different things"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/2935", "comments": ["Formatting looks strange, but I think that's just in my head.", "Yes it does! I had to do a double take then it's the conditional test which makes it look odd."]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/2888", "comments": ["Should this guidance slightly change to something akin to \"this role should be removed once used for the migration\"? It currently reads as `production` _environments_ should not have this role - but if you're migrating a production database, you probably wouldn't want to copy it to a lower environment first?", "For a future PR, is it worthwhile refactoring the `Deny` statements which are the same across `view-only, developer, sandbox, administrator, migration`, to use [source_policy_documents](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/data-sources/iam_policy_document#example-using-a-source-document)?"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/2885", "comments": ["```suggestion\r\n`@modernisation-platform-incident`\r\n```"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/2871", "comments": ["@davidkelliott I missed the arn here and supplied json... even though it said arn... not sure what I was thinking!", "Could you rename the trust-relationship-policy data so it's clear it relates to SSM please, thanks", "Are the cloudformation permissions needed? (in the json above, sorry didn't review this one before :) )", "Is this the correct name?  Looks like a copy and paste from above", "As above copy and paste"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/2839", "comments": ["This field is the account id of the account that'll be chiefly assuming this role. If I understand this right, that should be `core-shared-services-production` You need to pass it the id and then the module will turn it into arn like so `arn:aws:iam::account_id:root`  ", "This will give this role admin permissions in the account. That's ... alot. Can it be narrowed down?", "Yeah, sorry, building it up, I know it's hardcoded right now, and the account number wont change, but I shall make it less hardcodey", "Ah, it adds root on the end regardless. \r\n\r\n                + AWS = \"arn:aws:iam::763252494486:role/AWS-SSM-AutomationAdministrationRole:root\"\r\n                \r\n               ", "Please could you remove the hard coded account number, thanks"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/2786", "comments": ["did you mean it to be `2.`?"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/2706", "comments": ["Might as well add `docs/` cause I think these are the three main ones we use.\r\n\r\n\r\n", "ok, will do"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/2701", "comments": ["Could you add back in the explanation of what DoR means? I've not recently seen DoR used before, so was slightly confused.", "Is this line missing a `*`?", "it is explained earlier on in the doc, hence I removed it", "it's a continuation of the previous line"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/2654", "comments": ["What's the best way to know if it's legitimate?", "It's something to be judged on a case by case basis, but I'll put an example of a legitimate trigger and a false positive in if that helps?", "It would really help thank you!"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/2651", "comments": ["Based on the error Hari's having, I think this needs to go into MemberInfrastructureAccess role policy. I believe this is adding it to the collaborator developer role.", "This is the policy it should be in: https://github.com/ministryofjustice/modernisation-platform/blob/2e9230ba53ae225bcb0d6b956a4c5f975a7677c6/terraform/environments/bootstrap/delegate-access/iam.tf#L45"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/2609", "comments": ["\"}\" is this an extra bracket? or just funny formatting..."]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/2589", "comments": ["Comma at the end needed?", "Yes, comma in the end is on purpose, here is the relevant documentation: https://github.com/ministryofjustice/modernisation-platform-instance-scheduler#configuration"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/2583", "comments": ["`in **your** application directory`\r\nMaybe instead of referring the the folders, inform them that they can look at the codeowners file?", "I have added a reference to the codeowners file."]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/2570", "comments": ["this line (30) fails the pipeline actually; it's the indentation that needs fixing", "this is not needed again, probably a copy/paste error?", "Done", "```suggestion\r\n      - name: Checkout Repository\r\n```", "this needs to be defined outside of the job", "you can also define these outside of the job so that it is global (although it is not necessary at this stage, since there is only one job)", "wrong indentation here (as it is inside the job)\r\n\r\nyou can also move it out of the job and define it globally for a neater code (although it is not necessary at this point, since there is only one job)", "Amended the indentation. Didn't realist yal was so picky\n", "Moved and re-pushed", "unwanted changes I believe"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/2557", "comments": ["As part of further refinement, would be good to use the s3 module for this bucket. "]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/2552", "comments": ["Probably want to change this to refer to the correct bucket.\r\nHave you considered maybe using the output of a data call to populate this, to keep you from needing a hard coded reference in the policy?", "Are these key values correct? I suspect we're not using `myorg-terraform-states/myapp` in the DynamoDB config.", "Bucket name corrected.\r\n", "May be corrected with \"modernisation-platform-terraform-state/global-resources/terraform.tfstate\" and \"modernisation-platform-terraform-state/global-resources/terraform.tfstate-md5\"", "Change made and pushed"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/2529", "comments": ["Perhaps it could go under a new section called something like: Shared services and tools?"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/2503", "comments": ["Will this still work with the main repo workflow?", "Ignore, the main workflow uses the other provider"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/2502", "comments": ["I don't think this is needed here, the OIDC provider you will be using is here - https://github.com/ministryofjustice/modernisation-platform/blob/main/terraform/environments/core-shared-services/iam.tf#L203", "Ah I see you have it below, I think this change can be removed", "I wasn't sure, since it's going to iterate through other accounts... ?", "I shall remove it then. I can always raise another PR :D "]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/2445", "comments": ["I'd just add the arn of the specific function here rather than enabling it for all lambdas in the account."]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/2438", "comments": ["Is this permission needed for pulling images?", "Same here. Does lambda need upload permissions?", "Same here, upload permissions. If these are needed that's fine, but are theu#", "Again, uploading. Is lambda likely to do this\r\n?", "We are looking to get image not put it I don't think. "]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/2436", "comments": ["A few comments here...\r\n* Can this be standardised in terms of case?\r\n* Can `address_definition` be changed to reflect if it is the source or destination address that we're supplying here?\r\n* Are you sure about the use of `from_port` and `to_port`? The reference for a firewall rule refers to a destination port, and a source port. These names suggest a range, rather than a source port (which is likely to be an ephemeral port) and a destination port.\r\n* Also, regarding protocols, in this example I think you're asking for OracleDB traffic, but telling the firewall to treat it like HTTP, which won't work.", "Will discuss these. Initial layout and settings so I will amend the source and destination ports. Current code is copied from terraform so it will require some amendments\r\n"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/2435", "comments": ["Should this be named `azure-fixngo` now?", "Good point! Yes, I think that's actually what was described in the ticket so I'll amend that now.\r\n", "`azure-fixngo-live` probably better. Sorry for late breaking change requests."]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/2425", "comments": ["Sorry George, I just looked up how we can restrict this. Could you please change this * to what I posted in slack?"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/2417", "comments": ["Would it be worth adding content of the patching we are doing, meaning a brief list of what gets updated? It might be just me, but I feel like I am guessing if we update a version of software here or a version of our code and I think it is different per item.", "Thanks for the review! Could you give an example please I'm not sure I understand correctly :) "]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/2390", "comments": ["can we lock the version more? what do we use in other scripts?", "latest tag should be default, but ideally we want to pass this as a variable, don't we?", "I don't think we can. According to https://docs.aws.amazon.com/lambda/latest/dg/API_CreateFunction.html#SSS-CreateFunction-request-Runtime at the moment `go1.x` seems to be the only valid value for the runtime configuration for the Go language.", "We use terraform variables to pass different values to terraform modules. In this case, the lambda is not part of a module and only deployed as a single instance in core-shared-services. I don't see why we would be using a variable here, but let me know if you could point me to an example in the existing code.", "thanks for the explanation George", "ok, let's tackle it in the future"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/2387", "comments": ["Could we change the names of these to reflect what they are please? eg:\r\npublic_mp_core\r\npublic_mp_dev_test\r\npublic_mp_preprod_prod\r\n", "Could we move the CIDR ranges to a local (probably outside the module) so that we can change them centrally if needed?  Eg have locals like:\r\n```\r\ncore_cidr = 10.20.0.0/16\r\ndev_test_cidr = 10.26.0.0/16\r\npreprod_prod_cidr = 10.27.0.0/16\r\n```\r\nThis way it's clear what range each resource is referring to and also if we have one central point for this range it's easy to update if we need to change them or rebuild in another region.", "out of scope for this"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/2380", "comments": ["I would remove the commented-out code", "I would to, but I think if I do I'll forget that I can filter it to one account easily here \ud83d\ude02 "]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/2378", "comments": ["Test is commented out, but not preprod and prod.  Just thinking which is best, comment out everything except dev, as nearly all applications start with just a development environment.  Or to have everything uncommented and have the MP eng comment as part of the new env set up process..."]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/2374", "comments": ["What is this range?  I see the core account range 10.20 above, and 10.26 is dev and test but I'm not familiar with this one should it be 10.27?  Is it worth adding a comment so we know what each of the ranges are?  ", "You're totally right! I've pushed a fix for this. Good catch!"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/2341", "comments": ["```suggestion\r\n  cp core-repo/terraform/templates/service_runbook_template.md $1/README.md\r\n```\r\nI think you can do this in one step like so?", "Could we put the explanations in comment blocks <!-- --> so that users editing the page have instructions but they don't need to delete them?", "Could we have each entry as a heading and the explanation in a comment so that users just have to add their info in please?", "```suggestion\r\n```\r\nThis line can be deleted now as the above cp does the rename", "```suggestion\r\n\r\nModernisation Platform\r\n\r\n```", "```suggestion\r\n<!-- Describe the steps someone might take to resolve a specific issue or incident, often for use when on call. This may be a large amount of information, so may need to be split out into multiple pages, or link to other documents.-->\r\n```"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/2335", "comments": ["```suggestion\r\n  description = \"A Go lambda function for stopping and starting instance, rds resources and autoscaling groups\"\r\ntype         = \"core\"\r\n```"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/2333", "comments": ["Description is for the template file", "```suggestion\r\n    module.modernisation-platform-configuration-management.repository.name\r\n```\r\nThe plan is failing with the name attribute missing", "```suggestion\r\n  repository = module.modernisation-platform-configuration-management.repository.id\r\n```\r\nThis would need to refer to the new repo", "updated", "updated"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/2328", "comments": ["```suggestion\r\nlast_reviewed_on: 2022-09-21\r\n```"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/2302", "comments": ["Is this being used anywhere? I can't seem to find the usage. Same for the below.", "It's a built in Terraform feature, any environmental variable which starts TV_VAR_ will be picked up by Terraform as a variable - https://www.terraform.io/cli/config/environment-variables#tf_var_name"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/2277", "comments": ["This one should be 10.26.80.0", "This one should be 10.26.88.0", "This one should be 10.26.112.0"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/2273", "comments": ["Sort out the conflict, maybe you forgot a git pull after I made the change!"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/2269", "comments": ["```suggestion\r\n  max_session_duration = 3600\r\n```\r\nSince this role will only be used for pipelines shall we reduce the session duration to 1hour max?", "This will need to be for all member accounts, so the trust policy might have to have `*` as the principal and a condition similar to:\r\n```\r\n    condition {\r\n      test     = \"ForAnyValue:StringLike\"\r\n      variable = \"aws:PrincipalOrgPaths\"\r\n      values   = [\"${data.aws_organizations_organization.root_account.id}/*/${local.modernisation_platform_ou_id}/*\"]\r\n    }\r\n```", "I think this should be false as the Github role won't have MFA.", "I'm not sure if the module supports passing in of policies or conditions? If not it might have to be created using individual resources rather than the module."]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/2245", "comments": ["This shouldn't be removed", "It doesn't exist in the list of accounts on the repo. I'll add it and re-merge\r\n"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/2237", "comments": ["```suggestion\r\n          \"digital-prison-reporting-development\",\r\n```"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/2163", "comments": ["`create accounts` or `create an account`?", "Also while I think about it, you'll want some consistency between this title and the title of the document it links to (ideally).\r\nYou could title this `Creating AWS Accounts for Teams` or change the title of the linked document to `Creating accounts for end-users`.", "This doesn't actually link to the document template; maybe something along the lines of `Customers will fill out the new-environment template via our public repository`?", "This links to the workflow, not an example commit.", "`To kick off` reads better without the redundant `so` at the start."]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/2151", "comments": ["```suggestion\r\n  count  = local.account_data.account-type == \"member\" 1 : 0\r\n```\r\nYou can create this role in the testing-test account as well so that the scheduler can also be tested in there if needed", "I think the additional_trust_roles would need to give permissions to the lambda running the scheduler in the shared services account, is that right @dms1981 ?", "This seems like quite a lot of permissions, would it not only need describe and start stop EC2 permissions?", "I don't thing this is needed as the role will just be doing the starting and stopping, it won't be assuming any other roles", "As above I don't think this is needed", "This role is being called by the lambda so I don't think it needs any permissions to read/write to logs", "This and the following statement look to be a copy and past of the original role and are not needed here", "Do you mean the lambda in the Modernisation Platform account? Like \"arn:aws:lambda:eu-west-2:${local.environment_management.account_ids[\"modernisation_platform_account_id\"]}:function:golang-instance-scheduler\"? I cannot find a lambda resource in the core-shared-services account.", "It also needs permissions to read tags if we want to pick instances for starting / shutting down based on tags. I'd thought the following permissions would be appropriate:\r\n```\r\nec2:DescribeInstances\r\nec2:DescribeInstanceStatus\r\nec2:DescribeTags\r\nec2:StartInstances\r\nec2:StopInstances\r\n```", "The goal for this ticket should be that the lambda function has a role that allows it to assume a role in a separate account (or, I suppose, in the same account).\r\nThat assumable role should be the one that has both the permissions to start / stop instances, and a trust relationship statement allowing the lambda function to assume the role.\r\nSo... @davidkelliott , yes. and @gfou-al , also yes. But the plan is, in future, to run the lambda from `core-shared-services`.", "```suggestion\r\n]\r\n```\r\nThis is the member-access role, no changes need to be made here", "```suggestion\r\n  additional_trust_roles = [format(\"arn:aws:iam::%s:role/github-actions\", local.environment_management.account_ids[terraform.workspace])\r\n```", "```suggestion\r\n```\r\nNo additional trust roles needed if the lambda is currently running in the core-mp account as this trust is covered by default using the account_id above in the module.", "Added \"ec2:DescribeInstanceStatus\",\r\n            \"ec2:DescribeTags\"", "```suggestion\r\n  additional_trust_roles =\r\n```\r\nGithub actions role doesn't need permissions to this role"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/2140", "comments": ["Code looks good but the member account terraform assumes the `MemberInfrastructureAccess` so it should go on that role :) ", "The above code should go on this role"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/2119", "comments": ["```suggestion\r\nAfter completing this, you will need to delete the terraform workspaces in the following:\r\n```", "I'd prefer delete as the word destroy could be confused with Terraform destroy command", "```suggestion\r\n\r\n`modernisation-platform-environments/terraform/environments/<application-name>`\r\n\r\n`modernisation-platform/terraform/environments/<application-name>`\r\n```", "I would add these in here as well to the workspace delete section for clarity as the previous step is about destroying"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/2091", "comments": ["So this is the right code but in the wrong place...this is going to be a little more complex than we initially thought.\r\n\r\nThis code is for the MemberInfrastructureAccess role created only in the testing-test account.\r\n\r\nWe actually need to add this line in the role created in all the other member accounts which is here - \r\n\r\nhttps://github.com/ministryofjustice/modernisation-platform/blob/main/terraform/environments/bootstrap/delegate-access/iam.tf#L33\r\n\r\nBut that is created by an external module which assigns the assume role here:\r\nhttps://github.com/ministryofjustice/modernisation-platform-terraform-cross-account-access/blob/main/main.tf#L2\r\n\r\nAnd that is used in multiple places...so we would need to either pass in the policy or do some sort of conditional logic.  I seem to remember this is why I didn't use this module for the role in the testing-test account because there was no way I could allow the testing-ci user to assume it.", "Looks good, I think we can lock this down further to the member ou, but we don't have that stored as a secret, so I think it's best to go with this for now and then lock it down further as part of that other issue.", "Actually thinking about this, if we've already allowed any of the accounts to assume the role with the statement on line 265, I don't think we need this do we?", "It's probably superfluous. 265 will expand out to something like `arn:aws:iam::111111111111:root` which ought to allow any user or role to assume the `member-delegation-$business_unit-$env` role.", "OK! I've address this through this PR: https://github.com/ministryofjustice/modernisation-platform-terraform-cross-account-access/pull/7\r\nThis allows me to supply `additional_trust_roles` through which I can pass the relevant `github-actions` role."]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/2056", "comments": ["Looks like you're missing a comma here @zuriguardiola ?"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/2047", "comments": ["Could this be moved to the `Terraform modules - used by the core platform` section please as we wouldn't expect members to be directly using this module, thanks!"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/2007", "comments": ["Need to change title to: Out of hours support"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/1973", "comments": ["You could probably drop this block as your below range will include it, unless you want it specifically included?", "NB - this comment is meant to refer to lines 148 - 158."]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/1961", "comments": ["Do you want to add in a name here to be consistent with the other kms alias resources?", "I do! Good spot!"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/1940", "comments": ["Shouldn't this read `Shakeel Quader` as Sean has moved on to a different position?", "@dms1981 that change is in https://github.com/ministryofjustice/modernisation-platform/pull/1939."]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/1833", "comments": ["```suggestion\r\n`core-vpc-development`\r\n`core-vpc-test`\r\n```"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/1733", "comments": ["```suggestion\r\n    \"application\": \"example\",\r\n```"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/1713", "comments": ["This rule number already exists so the plan is failing", "done"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/1618", "comments": ["What do you mean by \"text files with the certificate data\" - is this just the public key for the cert being requested?", "This is a PEM-formatted identity certificate that has been digitally signed using the private key of the certificate authority.\r\n\r\nTo clarify on the above, I have now replaced the comment with the following note:\r\n\r\nNote these will be plain text files with the body of the PEM-formatted server certificate from your certificate authority - no private key, and no certification chain (this is important later). The body of the PEM-formatted server certificate is an identity certificate that has been digitally signed using the private key of the certificate authority.\r\n\r\nI hope this makes it somehow clearer."]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/1540", "comments": ["`equip-development` here maybe?", "\ud83e\udd26\u200d\u2642\ufe0f "]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/1514", "comments": ["Should this be `my-application`?", "Thanks! Amended"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/1459", "comments": ["```\r\nError: Invalid index\r\n\r\n  on iam.tf line 93, in data \"aws_iam_policy_document\" \"member-ci-policy\":\r\n  93:       \"arn:aws:iam::${local.environment_management.account_ids[terraform.workspace]}:role/MemberInfrastructureAccess\",\r\n    \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\r\n    \u2502 local.environment_management.account_ids has a sensitive value\r\n    \u2502 terraform.workspace is \"default\"\r\n```"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/1457", "comments": ["I don't think this condition is needed is it? ", "Pulled the condition as discussed", "Just thinking...this data look up will fail if we ever rebuild this from scratch as the user won't exist yet.  Would it be possible to get the arn from the module where it is created on line 20 please?  You'll have to add an output for the arn to the module.", "@davidkelliott - I had considered that as an alternative, yes. I will explore that now. Should have a PR up that covers that change shortly."]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/1442", "comments": ["This file should be in a separate PR and merged in first to ensure the AWS account is created before any networking takes place.", "Actually these 2 blocks and associated tests should have been removed, we now allocate transit gateway and protected subnets from the general subnet set, we used to have to do this manually hence the need to check them, but this is no longer required.", "Those parts have been removed from the latest commit - thanks for the comment!", "That's also been cleaned up as it's not relevant for this stage - thanks for the comment!"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/1411", "comments": ["Actually this answers my question about if we can leave hmpps-development VPC, we have to as it is being used by dex-ta"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/1396", "comments": ["If I understand correctly, this configuration allows any unprivileged source port in the range 1024-65535. Just wondering if this might be too open or if there's any reference on why we need it it be so open. Is this to allow NAT-ports?", "Because we don't know ahead of time what port will be used as the client source port, we have to set a wide range of potential source ports."]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/1378", "comments": ["If this block is commented out the whole module is disabled, right?\r\nMight be worth putting a comment here for that. Rather than someone butchering the code to disable the temp access. ", "How does the module react to the user list being empty?", "I expect it will fail, but I think this will be temporary code and removed after the health check (famous last words \ud83d\ude02 )"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/1377", "comments": ["```suggestion\r\nan AWS account. The portal will allow them to log in to the AWS console with the relevant privileges, or to retrieve an\r\n```\r\nWe have different levels, admin/developer/readonly/etc depending on the persons role and the account"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/1284", "comments": ["\ud83d\ude0d"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/1241", "comments": ["This whole file can be deleted as the development environment is the last one", "File deleted"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/1231", "comments": ["I read this as every minute past 7am, Mon-Fri. Should this not be: 0 7 * * 1-5", "\ud83e\udd26 you are 100% correct, I'll get it updated in a few", "cron expression updated"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/1227", "comments": ["```suggestion\r\n    module.terraform-module-aws-vm-import.name,\r\n```\r\n```suggestion\r\n    module.terraform-module-aws-vm-import.repository.name,\r\n```"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/1225", "comments": ["Just curious - are you seeing ImageBuilder instances talking out on 80?", "I'd imagine most connections will use https, though some may rely on redirects from http. I'll check the logs\r\n", "VPC Flow Logs show connections to port 80"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/1195", "comments": ["tiny thing: probably worth following the pattern around terraform module name that the others use, e.g. modernisation-platform-blah? wouldn't affect the repo name, just a consistency thing. as I said, not a biggy :-)", "Interestingly, the older repositories seem to lack the `modernisation-platform` prefix in the module name, but the repository does have the prefix. For example, in the below, the module is named terraform-module-bastion-linux but the repository modernisation-platform-terraform-bastion-linux.\r\n\r\n```\r\nmodule \"terraform-module-bastion-linux\" {\r\n  source      = \"./modules/repository\"\r\n  name        = \"modernisation-platform-terraform-bastion-linux\"\r\n  description = \"Module for creating Linux bastion servers in member AWS accounts\"\r\n  topics = [\r\n    \"aws\",\r\n    \"bastion\",\r\n    \"linux\"\r\n  ]\r\n}\r\n```\r\n\r\nalso\r\n\r\n```\r\nmodule \"hello-world\" {\r\n  source      = \"./modules/repository\"\r\n  type        = \"core\"\r\n  name        = \"modernisation-platform-hello-world\"\r\n  description = \"A sample application configuration within the Modernisation Platform\"\r\n  topics      = [\"sample-code\"]\r\n}\r\n```\r\n\r\nHowever, it seems that the above convention was compromised later on, for example\r\n\r\n```\r\nmodule \"modernisation-platform-environments\" {\r\n  source      = \"./modules/repository\"\r\n  name        = \"modernisation-platform-environments\"\r\n  description = \"Modernisation platform environments\"\r\n  topics = [\r\n    \"aws\",\r\n    \"environments\"\r\n  ]\r\n  required_checks = [\"run-opa-policy-tests\"]\r\n  secrets = nonsensitive(merge(local.member_ci_iam_user_keys, {\r\n    # Terraform GitHub token for the CI/CD user\r\n    TERRAFORM_GITHUB_TOKEN = \"This needs to be manually set in GitHub.\"\r\n  }))\r\n}\r\n```\r\n\r\nI personally prefer Ade's suggestion, therefore, will do the suggested update.", "\ud83d\udc4d "]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/1185", "comments": ["This still needed even if we're not setting up bucket replication?", "Discussing further, see that its a required provider within the module. So needs to be provided even if replication is disabled for the bucket."]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/1184", "comments": ["Is this just for informational purposes? Or there a reason we can't just use terraform data to retrieve kms key attributes? (I fear I'm missing something there \ud83d\ude04 )", "Didn't think about using data sources to retrieve attributes. Good point, I'll close this PR and use data on the Image Builder side instead"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/1176", "comments": ["Just a check - is GenerateDataKey required to just decrypt the key and use it to get at the secret?", "I like the role name core-vpc (member_delegation_read_only), just wondering if we should use the same here for consistency or if there are good reasons for it to be different?", "There's no good reason \ud83d\ude02 , I think it was because for the dns one it only needed read only to dns, so I described what the role did, where as the other role needed a few ec2 permissions as well and was harder to describe what it did so named it after it's purpose instead. I'll leave how it is for now to get things moving but if it causes confusion in the future we can change :)", "No actually good spot I don't think it is, I was following the guidance here for permissions https://docs.aws.amazon.com/secretsmanager/latest/userguide/security-encryption.html#security-encryption-authz\r\nBut the section a bit further up the document states only the decrypt is needed for decryption.  I'll test removing it and create a new PR if it works."]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/1171", "comments": ["I don't think you need this as this was in place before as the root users needed access to the terraform state account.  In this example only the core-shared-services account needs to be able to manage the key I think.", "See comment below I don't think root users need access to this just the current account.  (I think you might actually get kms:* permissions as the account that created the key anyway so you might not even need this statement, double check though as I may be confusing with S3 bucket policies)", "Yep, good point. Removed.", "Yep, good point. Did a little test on whether we need the root account specified. When deploying kms key programmatically, AWS does add the default account policy (which allows IAM policies) with full mgmt access. However, if you then add a statement to a key policy to say control user access, Terraform sees that single policy statement as desired state and so attempts (and fails) to remove account-level mgt access. Short story, the root account access needs to stay :-)"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/1160", "comments": ["I hope this will not re-start xhibit onboarding. If yes, then I guess reverting would not make any difference.", "No this shouldn't have any impact"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/1155", "comments": ["Any particular reason for removing the Bastion option from the template? Considering that environments like Nomis needed bastion and I would guess a lot of the new ones might also need it. ", "This was just because it's a module that can be added at any point in time now, originally it was in here as we had it as an option on the environment json file (the option is still there and needs removing actually)"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/1133", "comments": ["\ud83d\udc4f  thanks for the comment on the dataset transformation, these are always a nightmare to look back at \ud83d\ude04 "]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/1078", "comments": ["Looks good. Just to note, this article https://vaneyckt.io/posts/safer_bash_scripts_with_set_euxo_pipefail/ recommends the use of `set -Eeuo pipefail`. As stated in the above: `set -e` by itself is far from enough. We can further improve upon the behavior created by set -e by combining it with set -o pipefail. "]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/1076", "comments": ["I don't mind the existing approach but I would prefer to use the terraform fileexists function to determine whether the application_variables.json exists before reading it: https://www.terraform.io/docs/language/functions/fileexists.html This way we would not need to programmatically comment it out in the provision-environment-directories.sh script. Other that that, the code changes seem fine."]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/1046", "comments": ["Just curious, did this not work?", "That change didn't throw an error on terraform plan, but when it came to applying it, it gave the error \"The new key policy will not allow you to update the key policy in the future\".\r\n\r\nBased on this page [here](https://docs.aws.amazon.com/kms/latest/developerguide/key-policies.html) it looks like only the asterisk is allowed in the resource section of a key policy.\r\n\r\n`Resource \u2013 (Required) In a key policy, the value of the Resource element is \"*\", which means \"this KMS key.\" The asterisk (\"*\") identifies the KMS key to which the key policy is attached.`"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/950", "comments": ["Might need an extra space."]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/923", "comments": ["Does this need to be platforms-test?"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/866", "comments": ["Should this not be the performance hub team slug?"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/857", "comments": ["Could we flip the logic so that it's `local.account_data.account-type == \"member\"` ? I'm just thinking it makes it a bit clearer as to which type of accounts we want this to apply to", "yeah - no probs, will update", "updated to count = local.account_data.account-type == \"member\" ? 0 : 1"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/837", "comments": ["Should this line start with 'Modernisation Platform Member Unrestricted'", "Good spot thanks"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/742", "comments": ["Could add that NACL rules should not be applied to Transit Gateway subnets, as this would break the networking model", "could mention that egress traffic is allowed by a centralised NAT in network services account"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/711", "comments": ["I think the script will treat each target block as a separate parameter unless we quote them all together"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/636", "comments": ["Is this number correct ?", "Just changed it to the correct CIDR "]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/539", "comments": ["environment is now available via locals.tf if we update the 'core' folders"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/343", "comments": ["Is it worth using the output of `terraform-plan.sh` here, as it already has the correct flags set and redacts the output? It means we'd only need to update `terraform-plan.sh` rather than this file too for the same output?", "You'll need to add a `terraform init` here otherwise it'll fail because of uninstalled providers \ud83d\udc4d\ud83c\udffc ", "You can use `if: ${{ github.event.pull_request.merged == 'true' }}` to check if the PR has been merged into main, rather than checking the `ref`, if easier.", "GitHub Action jobs spin up new containers so you'll need to redo `terraform init` (and maybe `terraform plan`?) here too.", "You'll also want to have a `uses: hashicorp/setup-terraform@v1.3.2` to install Terraform on the container \ud83d\udc4d\ud83c\udffc ", "ok - will add it to the yaml steps \r\n", "updated to reference scripts/terraform_plan.sh", "updated ", "updated", "updated", "`./scripts/terraform_plan_comment_update.sh` might need to be `./scripts/update-pr-comments.sh` which is in this PR \ud83d\udc4d\ud83c\udffc ", "fixed"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/322", "comments": ["This should be `main` \ud83d\udc4d\ud83c\udffc ", "Is it worth adding a `workflow_dispatch` trigger ([example](https://github.com/ministryofjustice/modernisation-platform/blob/main/.github/workflows/check-links.yml#L4)) so we can run this manually via GitHub actions?", "added", "updated to main"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/294", "comments": ["Great first PR @seanprivett \ud83d\udc4d\ud83c\udffc\r\n\r\nCould we expand out MoJ to Ministry of Justice and add a full stop?"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/173", "comments": ["How about something like:\r\n\r\n> Alternative ways for end users to access applications that can't be accessible over the internet"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/48", "comments": ["This spacing substr is to output the generated file with the correct spacing, so `terraform fmt` doesn't try to reformat the file every time, and also so `terraform plan` doesn't output that the file needs updating to revert `terraform fmt` each time."]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/26", "comments": ["This looks like a mistake?", "I used to be all about lining up `=`, but now I'm not sure it's that useful\u2026 Was this you doing it, or a tool you use?", "Oh, these are both the GitHub action\u2026\u00a0That's a really weird formatting choice, but OK I guess? \u00af\\_(\u30c4)_/\u00af", "This is automatically done by [ministryofjustice/codeformatter](https://github.com/ministryofjustice/github-actions/tree/main/code-formatter) :)"]}, {"url": "https://github.com/ministryofjustice/modernisation-platform/pull/3", "comments": ["Some of these look like things that would be covered by [our tagging guidance](https://ministryofjustice.github.io/technical-guidance/documentation/standards/documenting-infrastructure-owners.html).", "MoJ have tagging guidelines that we should follow - https://ministryofjustice.github.io/technical-guidance/documentation/standards/documenting-infrastructure-owners.html#tags-you-should-use"]}]}, {"url": "https://github.com/guilhermerenew/infra-cost.git", "pull_requests": []}, {"url": "https://github.com/UriKatsirPrivate/gcp-landing-zone.git", "pull_requests": []}, {"url": "https://github.com/AJarombek/global-aws-infrastructure.git", "pull_requests": []}, {"url": "https://github.com/gudlyf/TerraformOpenVPN.git", "pull_requests": []}, {"url": "https://github.com/y-myk/terraform.git", "pull_requests": []}, {"url": "https://github.com/cloudchacho/terraform-google-hedwig-subscription.git", "pull_requests": []}, {"url": "https://github.com/ohoareau/terraform-modules.git", "pull_requests": [{"url": "https://github.com/ohoareau/terraform-modules/pull/3", "comments": ["You need to use an other form here, because, here is an example of what is expected:\r\n\r\n```\r\ncors_configuration {\r\n    allow_credentials = true\r\n    allow_methods     = [\"*\"]\r\n    allow_origins     = [\"HTTP://WWW.EXAMPLE.ORG\", \"https://example.io\"]\r\n    expose_headers    = [\"X-Api-Id\"]\r\n    max_age           = 500\r\n  }\r\n```\r\n(see here: https://github.com/terraform-providers/terraform-provider-aws/pull/12452/files#diff-e2c65f155d769374b9e204efc738b6ddR737)\r\n\r\nand:\r\n\r\n```\r\ncors_configuration = ...\r\n```\r\n\r\nis not the same as:\r\n\r\n```\r\ncors_configuration {\r\n    ...\r\n}\r\n```\r\n\r\nThe right form is:\r\n\r\n```\r\n  cors_configuration {\r\n      allow_credentials = var.cors.allow_credentials\r\n      allow_headers      = var.cors.allow_headers\r\n      allow_methods     = var.cors.allow_methods\r\n      allow_origins        = var.cors.allow_origins\r\n      expose_headers  = var.cors.expose_headers\r\n      max_age              = var.cors.max_age\r\n  }\r\n\r\n```\r\n\r\nBe careful to \"align\" the `=` on each variable assignment, and preferrably to have blank line between block of variable assignments and sub block like `cors_configuration {`", "I would prefer `cors` instead of `cors_config` to shorten the variable (personal opinion ;)).", "Concerning the structure, be careful to have the types (not all are strings), and to have a default value to avoid breaking compatibility with code that already use this module (reminder: all variables are required if no default provided).\r\n\r\nHere is my proposal:\r\n\r\n```\r\nvariable \"cors\" {\r\n  type = object({\r\n    allow_credentials = bool\r\n    allow_headers     = list(string)\r\n    allow_methods     = list(string)\r\n    allow_origins     = list(string)\r\n    expose_headers    = number\r\n  })\r\n  default = {\r\n    allow_credentials = true\r\n    allow_methods     = [\"*\"]\r\n    allow_origins     = [\"*\"]\r\n    expose_headers    = []\r\n    max_age           = 300\r\n  }\r\n}\r\n```", "Where did you see the type of the variables? I didn't find it.", "Also didn't know that if no default provided, then it's mandatory", "Isn't `var.cors` an object? how can you do a for each?", "> Where did you see the type of the variables? I didn't find it.\r\n\r\nIt is not written in the official documentation, unfortunately :(. I was required to go to the ... Go source code :( => https://github.com/terraform-providers/terraform-provider-aws/pull/12452/files#diff-e2c65f155d769374b9e204efc738b6ddR737", "> Isn't `var.cors` an object? how can you do a for each?\r\n\r\n`for_each` is on `[var.cors]` not on `var.cors`."]}]}, {"url": "https://github.com/albclim/PayHub.git", "pull_requests": []}, {"url": "https://github.com/freeyourscience/infrastructure.git", "pull_requests": []}, {"url": "https://github.com/structurefall/jamulus-builder.git", "pull_requests": []}, {"url": "https://github.com/alphagov/govuk-aws.git", "pull_requests": [{"url": "https://github.com/alphagov/govuk-aws/pull/1829", "comments": ["It's wild the variations we have in this file on these different values, what you've set makes sense though. Although not sure this user needs to configure the queue since we'd expect to do it all from Terraform right? (though I don't know enough about rabbit to be sure)", "```suggestion\r\n      \"routing_key\": \"*.bulk.govuk_chat_sync\",\r\n```\r\n\r\nSorry this is my bad when writing the card. It looks like there's a strong convention everywhere else here to be separating by underscores rather than dashes.", "Yeah I wasn't too sure, following the principle of least privilege the user should only need to read its own queue, but since a lot of users had configure access to their own queues I figured what's the harm?\r\nBut yeah probably don't need it."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1823", "comments": ["Is this the EFS filer that we're still using for temporarily storing uploaded attachments while they're scanned with Clam? Might need to remember to import it somewhere afterwards :)", "I think this one's still in use too so gonna need to import it somewhere at some point.", "Ah yes, I thought we were using a new efs volume for this but turns out it's still using the old one. I'll put it on the list of things that need moving across", "Oh yeah, this needs adding to the list too. When I looked on the AWS dashboard earlier it wasn't showing any documentdb clusters. Odd"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1803", "comments": ["```suggestion\r\n  default_tags                               = map(\"Project\", var.stackname, \"aws_migration\", \"apt\", \"aws_environment\", var.aws_environment, \"Environment\", var.aws_environment, \"Product\", \"GOV.UK\", \"Owner\", \"govuk-platform-engineering@digital.cabinet-office.gov.uk\")\r\n```", "```suggestion\r\n  default_tags                               = map(\"Project\", var.stackname, \"aws_migration\", \"apt\", \"aws_environment\", var.aws_environment, \"Environment\", var.aws_environment, \"Product\", \"GOV.UK\", \"Owner\", \"govuk-platform-engineering@digital.cabinet-office.gov.uk\")\r\n```", "```suggestion\r\n  default_tags                      = map(\"Project\", var.stackname, \"aws_stackname\", var.stackname, \"aws_environment\", var.aws_environment, \"aws_migration\", \"apt\", \"aws_hostname\", \"apt-1\", \"Environment\", var.aws_environment, \"Product\", \"GOV.UK\", \"Owner\", \"govuk-platform-engineering@digital.cabinet-office.gov.uk\")\r\n```", "```suggestion\r\n    Product         = \"GOV.UK\"\r\n    Owner           = \"govuk-platform-engineering@digital.cabinet-office.gov.uk\"\r\n```", "```suggestion\r\n    \"Product\"         = \"GOV.UK\"\r\n    \"Owner\"           = \"govuk-platform-engineering@digital.cabinet-office.gov.uk\"\r\n```", "```suggestion\r\n  default_tags               = map(\"Project\", var.stackname, \"aws_stackname\", var.stackname, \"aws_environment\", var.aws_environment, \"aws_migration\", \"backend-redis\", \"Environment\", var.aws_environment, \"Product\", \"GOV.UK\", \"Owner\", \"govuk-platform-engineering@digital.cabinet-office.gov.uk\")\r\n```", "```suggestion\r\n  tags = map(\"Name\", \"${var.stackname}-ci-agent-1\", \"Project\", var.stackname, \"aws_environment\", var.aws_environment, \"aws_migration\", \"ci-agent\", \"Environment\", var.aws_environment, \"Product\", \"GOV.UK\", \"Owner\", \"govuk-platform-engineering@digital.cabinet-office.gov.uk\", \"System\", \"CI agent\")\r\n```", "```suggestion\r\n  default_tags                  = map(\"Project\", var.stackname, \"aws_stackname\", var.stackname, \"aws_environment\", var.aws_environment, \"aws_migration\", \"ci_agent\", \"aws_hostname\", \"ci-agent-1\", \"Environment\", var.aws_environment, \"Product\", \"GOV.UK\", \"Owner\", \"govuk-platform-engineering@digital.cabinet-office.gov.uk\")\r\n```", "```suggestion\r\n    Product         = \"GOV.UK\"\r\n    Owner           = \"govuk-platform-engineering@digital.cabinet-office.gov.uk\"\r\n```", "```suggestion\r\n    Product         = \"GOV.UK\"\r\n    Owner           = \"govuk-platform-engineering@digital.cabinet-office.gov.uk\"\r\n```", "```suggestion\r\n  tags = map(\"Name\", \"${var.stackname}-ci-agent-2\", \"Project\", var.stackname, \"aws_environment\", var.aws_environment, \"aws_migration\", \"ci-agent\", \"Environment\", var.aws_environment, \"Product\", \"GOV.UK\", \"Owner\", \"govuk-platform-engineering@digital.cabinet-office.gov.uk\", \"System\", \"CI Agent\")\r\n```", "I think it's ok to add `System` to the defaults here.\r\n```suggestion\r\n  default_tags                  = map(\"Project\", var.stackname, \"aws_stackname\", var.stackname, \"aws_environment\", var.aws_environment, \"aws_migration\", \"ci_agent\", \"aws_hostname\", \"ci-agent-2\", \"Environment\", var.aws_environment, \"Product\", \"GOV.UK\", \"Owner\", \"govuk-platform-engineering@digital.cabinet-office.gov.uk\", System = \"CI Agent\")\r\n```", "```suggestion\r\n    Product         = \"GOV.UK\"\r\n    Owner           = \"govuk-platform-engineering@digital.cabinet-office.gov.uk\"\r\n```", "```suggestion\r\n    Product         = \"GOV.UK\"\r\n    Owner           = \"govuk-platform-engineering@digital.cabinet-office.gov.uk\"\r\n```", "```suggestion\r\n  default_tags                  = map(\"Project\", var.stackname, \"aws_stackname\", var.stackname, \"aws_environment\", var.aws_environment, \"aws_migration\", \"ci_agent\", \"aws_hostname\", \"ci-agent-3\", \"Environment\", var.aws_environment, \"Product\", \"GOV.UK\", \"Owner\", \"govuk-platform-engineering@digital.cabinet-office.gov.uk\", \"System\", \"CI Agent\")\r\n```", "```suggestion\r\n    Product         = \"GOV.UK\"\r\n    Owner           = \"govuk-platform-engineering-team@digital.cabinet-office.gov.uk\"\r\n```", "```suggestion\r\n    Product         = \"GOV.UK\"\r\n    Owner           = \"govuk-platform-engineering@digital.cabinet-office.gov.uk\"\r\n```", "```suggestion\r\n  tags = map(\"Name\", \"${var.stackname}-ci-agent-4\", \"Project\", var.stackname, \"aws_environment\", var.aws_environment, \"aws_migration\", \"ci-agent\", \"Environment\", var.aws_environment, \"Product\", \"GOV.UK\", \"Owner\", \"govuk-platform-engineering@digital.cabinet-office.gov.uk\", \"System\", \"CI Agent\"))\r\n```", "```suggestion\r\n  default_tags                  = map(\"Project\", var.stackname, \"aws_stackname\", var.stackname, \"aws_environment\", var.aws_environment, \"aws_migration\", \"ci_agent\", \"aws_hostname\", \"ci-agent-4\", \"Environment\", var.aws_environment, \"Product\", \"GOV.UK\", \"Owner\", \"govuk-platform-engineering@digital.cabinet-office.gov.uk\", \"System\", \"CI Agent\")\r\n```", "```suggestion\r\n  tags = map(\"Name\", \"${var.stackname}-ci-agent-5\", \"Project\", var.stackname, \"aws_environment\", var.aws_environment, \"aws_migration\", \"ci-agent\", \"Environment\", var.aws_environment, \"Product\", \"GOV.UK\", \"Owner\", \"govuk-platform-engineering@digital.cabinet-office.gov.uk\", \"System\", \"CI Agent\"))\r\n```", "```suggestion\r\n  default_tags                  = map(\"Project\", var.stackname, \"aws_stackname\", var.stackname, \"aws_environment\", var.aws_environment, \"aws_migration\", \"ci_agent\", \"aws_hostname\", \"ci-agent-5\", \"Environment\", var.aws_environment, \"Product\", \"GOV.UK\", \"Owner\", \"govuk-platform-engineering@digital.cabinet-office.gov.uk\", \"System\", \"CI Agent\")\r\n```", "```suggestion\r\n  tags = map(\"Name\", \"${var.stackname}-ci-master\", \"Project\", var.stackname, \"aws_environment\", var.aws_environment, \"aws_migration\", \"ci_master\", \"Environment\", var.aws_environment, \"Product\", \"GOV.UK\", \"Owner\", \"govuk-platform-engineering@digital.cabinet-office.gov.uk\", \"System\", \"CI Master\")\r\n```\r\n`var.stackname` is `govuk` so not super descriptive", "```suggestion\r\n  tags = map(\"Name\", \"${var.stackname}-ci-master-internal\", \"Project\", var.stackname, \"aws_environment\", var.aws_environment, \"aws_migration\", \"ci_master\", \"Environment\", var.aws_environment, \"Product\", \"GOV.UK\", \"Owner\", \"govuk-platform-engineering@digital.cabinet-office.gov.uk\", \"System\", \"CI Master\")\r\n```", "```suggestion\r\n  default_tags                  = map(\"Project\", var.stackname, \"aws_stackname\", var.stackname, \"aws_environment\", var.aws_environment, \"aws_migration\", \"ci_master\", \"aws_hostname\", \"ci-master-1\", \"Environment\", var.aws_environment, \"Product\", \"GOV.UK\", \"Owner\", \"govuk-platform-engineering@digital.cabinet-office.gov.uk\", \"System\", \"CI Master\")\r\n```", "```suggestion\r\n  default_tags                  = map(\"Project\", var.stackname, \"aws_stackname\", var.stackname, \"aws_environment\", var.aws_environment, \"aws_migration\", \"content_data_api_db_admin\", \"aws_hostname\", \"content-data-api-db-admin-1\", \"Environment\", var.aws_environment, \"Product\", \"GOV.UK\", \"Owner\", \"govuk-platform-engineering@digital.cabinet-office.gov.uk\", \"System\", \"Content Data API DB Admin\")\r\n```", "```suggestion\r\n  default_tags          = map(\"Project\", var.stackname, \"aws_stackname\", var.stackname, \"aws_environment\", var.aws_environment, \"aws_migration\", \"content_data_api_postgresql_primary\", \"Environment\", var.aws_environment, \"Product\", \"GOV.UK\", \"Owner\", \"govuk-platform-engineering@digital.cabinet-office.gov.uk\", \"System\", \"Content Data API PostgreSQL RDS instance\")\r\n```", "```suggestion\r\n  tags = map(\"Name\", \"${var.stackname}-db-admin\", \"Project\", var.stackname, \"aws_environment\", var.aws_environment, \"aws_migration\", \"db_admin\", \"Environment\", var.aws_environment, \"Product\", \"GOV.UK\", \"Owner\", \"govuk-platform-engineering@digital.cabinet-office.gov.uk\", \"System\", \"DB Admin\")\r\n```", "```suggestion\r\n  default_tags                  = map(\"Project\", var.stackname, \"aws_stackname\", var.stackname, \"aws_environment\", var.aws_environment, \"aws_migration\", \"db_admin\", \"aws_hostname\", \"db-admin-1\", \"Environment\", var.aws_environment, \"Product\", \"GOV.UK\", \"Owner\", \"govuk-platform-engineering@digital.cabinet-office.gov.uk\", \"System\", \"DB Admin\")\r\n```", "```suggestion\r\n  tags = map(\"Name\", \"${var.stackname}-deploy\", \"Project\", var.stackname, \"aws_environment\", var.aws_environment, \"aws_migration\", \"jenkins\", \"Environment\", var.aws_environment, \"Product\", \"GOV.UK\", \"Owner\", \"govuk-platform-engineering@digital.cabinet-office.gov.uk\", \"System\", \"Deployment\")\r\n```", "```suggestion\r\n  tags = map(\"Name\", \"${var.stackname}-deploy-internal\", \"Project\", var.stackname, \"aws_environment\", var.aws_environment, \"aws_migration\", \"jenkins\", \"Environment\", var.aws_environment, \"Product\", \"GOV.UK\", \"Owner\", \"govuk-platform-engineering@digital.cabinet-office.gov.uk\", \"System\", \"Deployment\")\r\n```", "```suggestion\r\n  default_tags                  = map(\"Project\", var.stackname, \"aws_stackname\", var.stackname, \"aws_environment\", var.aws_environment, \"aws_migration\", \"jenkins\", \"aws_hostname\", \"jenkins-1\", \"Environment\", var.aws_environment, \"Product\", \"GOV.UK\", \"Owner\", \"govuk-platform-engineering@digital.cabinet-office.gov.uk\", \"System\", \"Deployment\")\r\n```", "```suggestion\r\n  tags = map(\"Name\", \"${var.stackname}-docker_management_etcd\", \"Project\", var.stackname, \"aws_environment\", var.aws_environment, \"aws_migration\", \"docker_management_etcd\", \"Environment\", var.aws_environment, \"Product\", \"GOV.UK\", \"Owner\", \"govuk-platform-engineering@digital.cabinet-office.gov.uk\", \"System\", \"Docker Management\")\r\n```", "```suggestion\r\n  default_tags                  = map(\"Project\", var.stackname, \"aws_stackname\", var.stackname, \"aws_environment\", var.aws_environment, \"aws_migration\", \"docker_management\", \"aws_hostname\", \"docker-management-1\", \"Environment\", var.aws_environment, \"Product\", \"GOV.UK\", \"Owner\", \"govuk-platform-engineering@digital.cabinet-office.gov.uk\", \"System\", \"Docker Management\")\r\n```", "```suggestion\r\n  default_tags                               = map(\"Project\", var.stackname, \"aws_migration\", \"gatling\", \"aws_environment\", var.aws_environment, \"Environment\", var.aws_environment, \"Product\", \"GOV.UK\", \"Owner\", \"govuk-platform-engineering@digital.cabinet-office.gov.uk\", \"System\", \"Gatling\")\r\n```\r\n\ud83e\udd14 Platform Security and Reliability owns https://github.com/alphagov/govuk-load-testing but I think Platform Engineering still owns the infrastructure for it.", "```suggestion\r\n  default_tags                      = map(\"Project\", var.stackname, \"aws_stackname\", var.stackname, \"aws_environment\", var.aws_environment, \"aws_migration\", \"gatling\", \"aws_hostname\", \"gatling-1\", \"Environment\", var.aws_environment, \"Product\", \"GOV.UK\", \"Owner\", \"govuk-platform-engineering@digital.cabinet-office.gov.uk\", \"System\", \"Gatling\")\r\n```", "```suggestion\r\n  tags = map(\"Name\", \"${var.stackname}-graphite-external\", \"Project\", var.stackname, \"aws_environment\", var.aws_environment, \"aws_migration\", \"graphite\", \"Environment\", var.aws_environment, \"Product\", \"GOV.UK\", \"Owner\", \"govuk-platform-engineering@digital.cabinet-office.gov.uk\", \"System\", \"Graphite\")\r\n```", "```suggestion\r\n  tags = map(\"Name\", \"${var.stackname}-graphite-internal\", \"Project\", var.stackname, \"aws_environment\", var.aws_environment, \"aws_migration\", \"graphite\", \"Environment\", var.aws_environment, \"Product\", \"GOV.UK\", \"Owner\", \"govuk-platform-engineering@digital.cabinet-office.gov.uk\", \"System\", \"Graphite\")\r\n```", "```suggestion\r\n  default_tags                  = map(\"Project\", var.stackname, \"aws_stackname\", var.stackname, \"aws_environment\", var.aws_environment, \"aws_migration\", \"graphite\", \"aws_hostname\", \"graphite-1\", \"Environment\", var.aws_environment, \"Product\", \"GOV.UK\", \"Owner\", \"govuk-platform-engineering@digital.cabinet-office.gov.uk\", \"System\", \"Graphite\")\r\n```", "```suggestion\r\n  tags = map(\"Name\", \"${var.stackname}-jumpbox\", \"Project\", var.stackname, \"aws_environment\", var.aws_environment, \"aws_migration\", \"jumpbox\", \"Environment\", var.aws_environment, \"Product\", \"GOV.UK\", \"Owner\", \"govuk-platform-engineering@digital.cabinet-office.gov.uk\", \"System\", \"Jumpbox\")\r\n```", "```suggestion\r\n  default_tags                  = map(\"Project\", var.stackname, \"aws_stackname\", var.stackname, \"aws_environment\", var.aws_environment, \"aws_migration\", \"jumpbox\", \"aws_hostname\", \"jumpbox-1\", \"Environment\", var.aws_environment, \"Product\", \"GOV.UK\", \"Owner\", \"govuk-platform-engineering@digital.cabinet-office.gov.uk\", \"System\", \"Jumpbox\")\r\n```", "```suggestion\r\n  default_tags                  = map(\"Project\", var.stackname, \"aws_stackname\", var.stackname, \"aws_environment\", var.aws_environment, \"aws_migration\", \"mongo\", \"aws_hostname\", \"mongo-2\", \"Environment\", var.aws_environment, \"Product\", \"GOVUK\", \"Owner\", \"govuk-replatforming-team@digital.cabinet-office.gov.uk\", \"System\", \"${var.stackname} Mongo\")\r\n```\r\n```suggestion\r\n  default_tags                  = map(\"Project\", var.stackname, \"aws_stackname\", var.stackname, \"aws_environment\", var.aws_environment, \"aws_migration\", \"mongo\", \"aws_hostname\", \"mongo-2\", \"Environment\", var.aws_environment, \"Product\", \"GOV.UK\", \"Owner\", \"govuk-platform-engineering@digital.cabinet-office.gov.uk\", \"System\", \"${var.stackname} Mongo\")\r\n```", "```suggestion\r\n  default_tags                  = map(\"Project\", var.stackname, \"aws_stackname\", var.stackname, \"aws_environment\", var.aws_environment, \"aws_migration\", \"mongo\", \"aws_hostname\", \"mongo-3\", \"Environment\", var.aws_environment, \"Product\", \"GOV.UK\", \"Owner\", \"govuk-platform-engineering@digital.cabinet-office.gov.uk\", \"System\", \"${var.stackname} Mongo\")\r\n```", "```suggestion\r\n  tags = map(\"Name\", \"${var.stackname}-monitoring\", \"Project\", var.stackname, \"aws_environment\", var.aws_environment, \"aws_migration\", \"monitoring\", \"Environment\", var.aws_environment, \"Product\", \"GOV.UK\", \"Owner\", \"govuk-platform-engineering@digital.cabinet-office.gov.uk\", \"System\", \"${var.stackname} Monitoring\")\r\n```", "```suggestion\r\n  tags = map(\"Name\", \"${var.stackname}-monitoring\", \"Project\", var.stackname, \"aws_environment\", var.aws_environment, \"aws_migration\", \"monitoring\", \"Environment\", var.aws_environment, \"Product\", \"GOV.UK\", \"Owner\", \"govuk-platform-engineering@digital.cabinet-office.gov.uk\", \"System\", \"${var.stackname} Monitoring\")\r\n```", "```suggestion\r\n  default_tags                  = map(\"Project\", var.stackname, \"aws_stackname\", var.stackname, \"aws_environment\", var.aws_environment, \"aws_migration\", \"monitoring\", \"aws_hostname\", \"monitoring-1\", \"Environment\", var.aws_environment, \"Product\", \"GOV.UK\", \"Owner\", \"govuk-platform-engineering@digital.cabinet-office.gov.uk\", \"System\", \"${var.stackname} Monitoring\")\r\n```", "```suggestion\r\n  var.aws_environment, \"aws_migration\", \"prometheus\", \"aws_hostname\", \"prometheus-1\", \"Environment\", var.aws_environment, \"Product\", \"GOV.UK\", \"Owner\", \"govuk-platform-engineering@digital.cabinet-office.gov.uk\", \"System\", \"Prometheus\"))\r\n```", "```suggestion\r\n  default_tags    = map(\"Project\", var.stackname, \"aws_migration\", \"prometheus\", \"aws_environment\", var.aws_environment, \"Environment\", var.aws_environment, \"Product\", \"GOV.UK\", \"Owner\", \"govuk-platform-engineering@digital.cabinet-office.gov.uk\", \"System\", \"Prometheus\")\r\n```", "```suggestion\r\n  default_tags                  = map(\"Project\", var.stackname, \"aws_stackname\", var.stackname, \"aws_environment\", var.aws_environment, \"aws_migration\", \"puppetmaster\", \"aws_hostname\", \"puppetmaster-1\", \"Environment\", var.aws_environment, \"Product\", \"GOV.UK\", \"Owner\", \"govuk-platform-engineering@digital.cabinet-office.gov.uk\", \"System\", \"Puppet\")\r\n```", "```suggestion\r\n  tags = map(\"Name\", \"${var.stackname}-transition-db-admin\", \"Project\", var.stackname, \"aws_environment\", var.aws_environment, \"aws_migration\", \"transition_db_admin\", \"Environment\", var.aws_environment, \"Product\", \"GOV.UK\", \"Owner\", \"govuk-platform-engineering@digital.cabinet-office.gov.uk\", \"System\", \"${var.stackname} Transition Database\")\r\n```", "```suggestion\r\n  default_tags                  = map(\"Project\", var.stackname, \"aws_stackname\", var.stackname, \"aws_environment\", var.aws_environment, \"aws_migration\", \"transition_db_admin\", \"aws_hostname\", \"transition-db-admin-1\", \"Environment\", var.aws_environment, \"Product\", \"GOV.UK\", \"Owner\", \"govuk-platform-engineering@digital.cabinet-office.gov.uk\", \"System\", \"${var.stackname} Transition Database\")\r\n```", "```suggestion\r\n  default_tags          = map(\"Project\", var.stackname, \"aws_stackname\", var.stackname, \"aws_environment\", var.aws_environment, \"aws_migration\", \"transition_postgresql_primary\", \"Environment\", var.aws_environment, \"Product\", \"GOV.UK\", \"Owner\", \"govuk-platform-engineering@digital.cabinet-office.gov.uk\", \"System\", \"${var.stackname} Transition Database\")\r\n```", "```suggestion\r\n  default_tags               = map(\"Project\", var.stackname, \"aws_stackname\", var.stackname, \"aws_environment\", var.aws_environment, \"aws_migration\", \"transition_postgresql_standby\", \"Environment\", var.aws_environment, \"Product\", \"GOV.UK\", \"Owner\", \"govuk-platform-engineering@digital.cabinet-office.gov.uk\", \"System\", \"${var.stackname} Transition Database\")\r\n```", "```suggestion\r\n  default_tags              = map(\"Project\", var.stackname, \"Environment\", var.aws_environment, \"Product\", \"GOV.UK\", \"Owner\", \"govuk-platform-engineering@digital.cabinet-office.gov.uk\", \"System\", \"Networking\")\r\n```", "```suggestion\r\n  default_tags               = map(\"Project\", var.stackname, \"Environment\", var.aws_environment, \"Product\", \"GOV.UK\", \"Owner\", \"govuk-platform-engineering@digital.cabinet-office.gov.uk\", \"System\", \"Networking\")\r\n```", "```suggestion\r\n  default_tags               = map(\"Project\", var.stackname, \"aws_migration\", \"elasticache\", \"Environment\", var.aws_environment, \"Product\", \"GOV.UK\", \"Owner\", \"govuk-platform-engineering@digital.cabinet-office.gov.uk\", \"System\", \"Elasticache Networking\")\r\n```", "```suggestion\r\n  default_tags               = map(\"Project\", var.stackname, \"aws_migration\", \"rds\", \"Environment\", var.aws_environment, \"Product\", \"GOV.UK\", \"Owner\", \"govuk-platform-engineering@digital.cabinet-office.gov.uk\", \"System\", \"Database Networking\")\r\n```", "```suggestion\r\n  default_tags = map(\"Project\", var.stackname, \"Environment\", var.aws_environment, \"Product\", \"GOV.UK\", \"Owner\", \"govuk-platform-engineering@digital.cabinet-office.gov.uk\" \"System\", \"Network\")\r\n```", "```suggestion\r\n    Product     = \"GOV.UK\"\r\n    Owner       = \"govuk-platform-engineering@digital.cabinet-office.gov.uk\"\r\n    System      = \"Licensify Frontend\"\r\n```", "```suggestion\r\n    Product         = \"GOV.UK\"\r\n    Owner           = \"govuk-platform-engineering@digital.cabinet-office.gov.uk\"\r\n```", "```suggestion\r\n    Product         = \"GOV.UK\"\r\n    Owner           = \"govuk-platform-engineering@digital.cabinet-office.gov.uk\"\r\n    System          = \"Licensify Apt Package Storage\"\r\n```", "```suggestion\r\n    Product     = \"GOV.UK\"\r\n    Owner       = \"govuk-replatforming-team@digital.cabinet-office.gov.uk\"\r\n    System      = \"Licensify Apt Package Storage\"\r\n```", "```suggestion\r\n    Product         = \"GOV.UK\"\r\n    Owner           = \"govuk-platform-engineering@digital.cabinet-office.gov.uk\"\r\n```", "```suggestion\r\n    Product         = \"GOV.UK\"\r\n    Owner           = \"govuk-platform-engineering@digital.cabinet-office.gov.uk\"\r\n    System          = \"Licensing Frontend\"\r\n```", "```suggestion\r\n    Product         = \"GOV.UK\"\r\n    Owner           = \"govuk-platform-security-reliability@digital.cabinet-office.gov.uk\"\r\n    System          = \"Content Data CSVs\"\r\n```", "```suggestion\r\n    Product         = \"GOV.UK\"\r\n    Owner           = \"govuk-platform-security-reliability@digital.cabinet-office.gov.uk\"\r\n```", "```suggestion\r\n    Product         = \"GOV.UK\"\r\n    Owner           = \"govuk-platform-security-reliability@digital.cabinet-office.gov.uk\"\r\n```", "```suggestion\r\n    Product         = \"GOV.UK\"\r\n    Owner           = \"govuk-platform-security-reliability@digital.cabinet-office.gov.uk\"\r\n```", "```suggestion\r\n    Product         = \"GOV.UK\"\r\n    Owner           = \"govuk-platform-security-reliability@digital.cabinet-office.gov.uk\"\r\n```", "```suggestion\r\n    Product         = \"GOV.UK\"\r\n    Owner           = \"govuk-platform-security-reliability@digital.cabinet-office.gov.uk\"\r\n```", "```suggestion\r\n    Product         = \"GOV.UK\"\r\n    Owner           = \"govuk-platform-security-reliability@digital.cabinet-office.gov.uk\"\r\n```", "```suggestion\r\n    Product         = \"GOV.UK\"\r\n    Owner           = \"govuk-platform-security-reliability@digital.cabinet-office.gov.uk\"\r\n```", "```suggestion\r\n    Product         = \"GOV.UK\"\r\n    Owner           = \"govuk-platform-security-reliability@digital.cabinet-office.gov.uk\"\r\n```", "```suggestion\r\n    Product              = \"GOV.UK\"\r\n    Owner                = \"govuk-platform-security-reliability@digital.cabinet-office.gov.uk\"\r\n```", "```suggestion\r\n    Product     = \"GOV.UK\"\r\n    Owner       = \"govuk-platform-security-reliability@digital.cabinet-office.gov.uk\"\r\n```", "```suggestion\r\n    Product     = \"GOV.UK\"\r\n    Owner       = \"govuk-platform-security-reliability@digital.cabinet-office.gov.uk\"\r\n    System      = \"Database Backups\"\r\n```", "```suggestion\r\n    Product         = \"GOV.UK\"\r\n    Owner           = \"govuk-platform-security-reliability@digital.cabinet-office.gov.uk\"\r\n```", "```suggestion\r\n    Product         = \"GOV.UK\"\r\n    Owner           = \"govuk-platform-security-reliability@digital.cabinet-office.gov.uk\"\r\n```", "```suggestion\r\n    Product         = \"GOV.UK\"\r\n    Owner           = \"govuk-platform-security-reliability@digital.cabinet-office.gov.uk\"\r\n```", "```suggestion\r\n    Product         = \"GOV.UK\"\r\n    Owner           = \"govuk-platform-security-reliability@digital.cabinet-office.gov.uk\"\r\n```", "```suggestion\r\n    Product         = \"GOV.UK\"\r\n    Owner           = \"govuk-platform-security-reliability@digital.cabinet-office.gov.uk\"\r\n```"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1799", "comments": ["You've got some obsolete `\"${}\"` syntax there and what looks like a typo in the domain name.\r\n```suggestion\r\n    for_each = [for s in [compact(list(var.domain, var.aws_environment == \"production\" ? \"https://staging.data.gov.uk\" : \"\")), \"https://find.eks.${var.aws_environment}.govuk.digital\"] : {\r\n```", "ok, I'll fix it"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1755", "comments": ["Interesting... I was stumped as to why reverting the refactor commit fixes the `A managed resource \"fastly_info\" \"state\" has not been declared in the root module.` error, as they both reference `fastly_info.state` in exactly the same way.\r\n\r\nHowever, it looks like `fastly_info.state` is [provided by the Fastly Terraform provider](https://developer.fastly.com/reference/vcl/variables/miscellaneous/fastly-info-state/) and is \"available in\r\nall subroutines\".\r\n\r\nI imagine when `s3logging`'s `format` is evaluated, `fastly_info.state` is inside a subroutine, and it works. But I imagine that calling `join` requires that the value of `fastly_info.state` is known at compile time, and it's not available yet, so errors.\r\n\r\nReverting the refactor as you've done is fine, but it might be worth exploring whether you can [create a structure at the top of the file](https://stackoverflow.com/a/64202586) that references `fastly_info.state`, and you can then refer to that variable instead \ud83e\udd14 ? See also https://saturncloud.io/blog/terraform-resolving-a-managed-resource-has-not-been-declared-in-the-root-module/", "Thanks @ChrisBAshton , I'll look into this in a separate PR \ud83d\udc4d "]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1742", "comments": ["Presumably these two `Condition` blocks together produce something like this in the output policy?\r\n\r\n```json\r\n            \"Condition\": {\r\n                \"StringEquals\": {\r\n                    \"kms:ViaService\": \"rds.eu-west-1.amazonaws.com\",\r\n                    \"kms:CallerAccount\": \"<our account id>\"\r\n                }\r\n            }\r\n```\r\n\r\nIf so then that looks right to me, from comparing with the baked-in key policies on the AWS-managed keys for other RDS stuff and my reading of https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_multi-value-conditions.html#reference_policies_multiple-conditions-eval \ud83d\ude35\u200d\ud83d\udcab", "Yup - replicated the managed key's policy for maintaining access to RDS. ", "Does this (also?) need to match `docdb-elastic.*.amazonaws.com`?", "According to [this table](https://docs.aws.amazon.com/kms/latest/developerguide/conditions-kms.html#viaService_table) that's not a valid service to use within the condition.\r\n\r\nI had just used `rds.*.amazonaws.com` as that's what was in a default policy when tried creating new cluster with a new key. \r\n"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1739", "comments": ["Nit: v minor - might be worth referring the arn attribute directly, just for consistency with how we reference other resource types in IAM policies.\r\n\r\n```suggestion\r\n    resources = [\"${aws_s3_bucket.assets_backup[0].arn}/*\"]\r\n```", "Nit: Couple places you've got this - wondering if you can just reference the role arn directly instead of using a local?\r\n```suggestion\r\n      identifiers = [aws_iam_role.replication.arn]\r\n```", "Nit: Might be easier to follow if we put the statement directly here instead of a local (which doesn't seem to be used elsewhere?)", "Ooh well spotted! Yeah the indirection is unnecessary here cos it's all in the same (prod) account. (Copy-pasto from replication.tf I think.)\r\n\r\nFixed.", "Good catch, thanks! Done.", "Yeah was wondering about this one myself. (At one point I had two places that used it, otherwise wouldn't have bothered hoisting it out of there, but OTOH it perhaps adds a bit of self-documentation? Then again, maybe it just looks odd if you're used to seeing these inline.) \ud83e\udd14", "Tried reverting it and yeah I think the local isn't really adding much. Done!"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1721", "comments": ["Yep, this looks like the approach recommended in the [docs](https://registry.terraform.io/providers/integrations/github/latest/docs) \ud83d\udc4d ", "Technically these changes should be in the \"Change the way we express list of list.\" commit, but don't bother if the rebase is going to be too painful.", "Hmm, the `[0][0][count.index]` looks odd here - do we really have a triple nested array?\r\nReading the [`element` documentation](https://developer.hashicorp.com/terraform/language/functions/element) I'd expect the equivalent `element(var.nat_gateway_ids, count.index)` to be simply `var.nat_gateway_ids[count.index]` \ud83e\udd14 ", "LGTM - the `create_internal_zone` is [already a boolean](https://github.com/alphagov/govuk-aws-data/search?q=create_internal_zone), so nothing to change in govuk-aws-data.", "Ideally you'd rebase against `main` rather than have this extra merge commit.", "Yeah this one looks a bit weird, I'll have another look at it", "fixed in https://github.com/alphagov/govuk-aws/pull/1721/commits/46027bc790971c95e6ef5b94019799b811a94114", "rebase done"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1716", "comments": ["Shouldn't it just be this?\r\n\r\n```suggestion\r\n      identifiers = var.database_backups_access_list\r\n```\r\n\r\n(Might not be possible in the current version of Terraform, but worth a `plan` to see. Otherwise it looks like we're setting a string, not an array)", "Due to the formatting of the version, the change gives a linting error"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1706", "comments": ["Looks like this slipped into the `Fix \"Invalid template directive\" error` commit instead of the `Reformat projects` commit.", "Ditto", "This is the only change that's got me nervous - are you confident the s3 logging format doesn't change as a result? \ud83e\udd14 It's also pretty hard to read, with all the percentage chars and backslash escapes. \ud83e\udd2e \r\n\r\nLooks like fastly-datagovuk is the only place this formatting is used, so we have no other prior art to refer to. It's also not been changed since it was [introduced 5 years ago](https://github.com/alphagov/govuk-aws/commit/5dc766a5bbab31f6388b602e0c985a15f08d37e5#diff-e10270142e05a904ebb7942a41ca3e5a0427ac65cadf924b689f26699508b1dbR56). So digging deeper...\r\n\r\nWe're on [Fastly Terraform v0.26.0](https://github.com/alphagov/govuk-aws/blob/c7385343ea4248f2b4c7c815fdba28780c507195/terraform/projects/fastly-datagovuk/main.tf#L56), and here are the corresponding [docs for `fastly_service_v1`](https://registry.terraform.io/providers/fastly/fastly/0.26.0/docs/resources/service_v1):\r\n\r\n> format (String) Apache-style string or VCL variables to use for log formatting (default: `%h %l %u %t \"%r\" %>s %b`)\r\n\r\nScope creep maybe, but could the formatting of our formatting be simplified? \ud83d\ude4f  Maybe making use of [heredoc strings](https://developer.hashicorp.com/terraform/language/expressions/strings#heredoc-strings), or [moving the expression into a separate file](https://stackoverflow.com/a/59414568), or even using something like [terraform `join`](https://developer.hashicorp.com/terraform/language/functions/join) to do something like:\r\n\r\n```suggestion\r\n    # Apache log format documentation: https://www.loggly.com/ultimate-guide/apache-logging-basics/\r\n    format             = join(\"\\t\",\r\n      [\r\n        \"%h\",\r\n        \"%{%Y-%m-%d %H:%M:%S}t.%%{msec_frac}t\",\r\n        \"%m\",\r\n        \"%U%q\",\r\n        \"%>s\",\r\n        \"%B\",\r\n        \"%{tls.client.protocol}V\",\r\n        \"%${fastly_info.state}V\",\r\n        \"%\\\"Referer\\\"i\",\r\n        \"%\\\"User-Agent\\\"i\",\r\n      ]\r\n    )\r\n```\r\n\r\nTotally appreciate this could be a separate PR, so feel free to push back on this if it's too much work \ud83d\ude05 ", "Not sure how this ever worked! But it looks like `aws_security_group` [should just return a single id](https://registry.terraform.io/providers/hashicorp/aws/2.56.0/docs/resources/security_group#:~:text=The%20ID%20of%20the%20security%20group), so this seems fine", "Hmmm strictly speaking, the change from `element()` to `[]` syntax isn't _needed_... or is it? It looks like a preference thing, rather than a required syntax change, whereas the actual fix here is the `flatten()` on the `instance_elb_ids`?\r\n\r\nNot that removing `element()` is necessarily a bad thing, it just introduces a bit more change and a bit more risk. What if we do in fact need the wraparound feature? I don't know enough about the code to know if it's needed or not, so I'd be tempted to just do the `flatten` change and then leave it alone if it appeases the compiler.", "This `Reformat projects` commit is by far the largest one. The changes look good, I'm just wondering how necessary it is - the commit message doesn't suggest the build was failing beforehand (though I guess `terraform fmt` must have been?)\r\n\r\nThese all look like whitespace changes so I wouldn't expect anything to break, might just be worth elaborating a bit more about why we're changing so many files.", "Yeah, it was the `terraform fmt` failing in the CI. I included this info in the commit message as suggested.\r\n\r\n<img width=\"568\" alt=\"Screenshot 2023-02-13 at 10 00 16\" src=\"https://user-images.githubusercontent.com/38078064/218439524-2ec6dcea-4f15-49f2-bd19-f5b29c2f02a0.png\">\r\n", "Good point, it does just need `flatten`. ", "I think we still need to do all the escaping \u2013 I included a link to the docs in the commit message. I also added a separate refactor commit (to minimise the diff). ", "Nitpick: Interestingly I can't see any `create_external_elb = false` in govuk-aws-data, so this extra logic is probably [YAGNI](https://martinfowler.com/bliki/Yagni.html) and could be deleted.", "Does this `plan` OK in Jenkins? Feel free to split it out into its own PR if it's risky. But if it is error-free, it should give the same `plan` output as the earlier commit that introduces the double `%`. \ud83d\udc4d ", "yeah, it was used for some [\"training jumpbox\"](https://github.com/alphagov/govuk-aws-data/blob/b12b9fb4ae62c428521eb7cb013f385fb4728a5c/data/app-jumpbox/training/common.tfvars).\r\nI didn't want to go too far in this PR given it already has a few commits. I'll remove it while I'm here \ud83d\ude09 ", "Compared the plans and they look the same"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1705", "comments": ["Why does it have to be compatible with both?", "Can these be changed to TF 0.12+ syntax or is there something preventing that?\r\n\r\ne.g.\r\n```suggestion\r\n  security_groups = flatten(var.instance_security_group_ids)\r\n```", "Ah is it sharing a values file with the old 0.11 stuff?", "Caution, really - I know there's other terraform projects which use the `node_group` module, and I want to try and avoid forcing this upgrade on others if possible. ", "Ugh sorry, I hadn't read the PR description properly - thanks for explaining there!", "sorry ignore me, makes sense now that I've read the description properly!", "See the [previous comment](https://github.com/alphagov/govuk-aws/pull/1705#discussion_r1101243875) - there will be other projects using `node_group` which may still be using 0.11. ", "Makes total sense, sorry for the noise! I'll go have another coffee \ud83d\ude48"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1701", "comments": ["There's [prior art](https://github.com/alphagov/govuk-aws/blob/1bc9826/terraform/projects/infra-artefact-bucket/main.tf#L314) for building the lambda zip using Terraform archive_file.\r\n\r\nAlso you can avoid all the pyenv/pip faff in return for foregoing `requests` (which is convenient but comes at the cost of needing a whole build pipeline here) and sticking with the Python standard library, which is turns out really [isn't so bad for this](https://stackoverflow.com/a/4188709).\r\n\r\nI can pretty much guarantee otherwise that people will update the `.py` and forget to rebuild, or remember to rebuild but fail to check in the rebuilt binary, etc. etc.", "Worth having some restriction on the domain name in `url`, just for defence-in-depth?", "The SG rule only allows egress to destinations within the same rabbitmq_access SG, so it's already protected to some degree. I could restrict it to, say, domains ending with 'mq.(region).amazonaws.com' , if you think that would be useful", "Agreed, it is a bit cumbersome and feels like a release process from the 1990s.\r\nI'll have a go with `urllib` - if it proves trickier than expected I'll move it to a separate PR.", "Yeah I was assuming there'd be SG/firewall rules as well but just seems like a good idea to eliminate any chance of this ending up being used as a general proxy.\r\n\r\nI think all it'd need is something like:\r\n\r\n```python3\r\nimport re\r\n\r\nurl = event['url']\r\nif !re.fullmatch(r'.*\\.mq\\.[a-z0-9_-]+\\.amazonaws\\.com', url):\r\n    raise ValueError(f'url failed validation: {url}')\r\n```", "I've added this in 97ad6b8", "Done, in [f773bec](https://github.com/alphagov/govuk-aws/pull/1701/commits/f773bec82587af970660fea3942a2dbe87735a53)"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1694", "comments": ["It's unusual to have a data resource looking up a resource that elsewhere in the same module is being referred to via remote state. I'm guessing it's needed here because our `infra-networking` module is only exporting the subnet ids and not the addresses? If so then fair enough.", "Wow \ud83d\ude15 Prob worth raising this with Amazon if you haven't already.", "Agreed, it's a bit awkward, but you're right - it looks like the CIDR blocks are only defined in govuk-aws-data as input variables to the `infra-networking` module, and not exposed as outputs. That makes a lookup via ID the least-worst option I could think of for retrieving them in a different project. ", "Good idea, thanks. I'll hang on until I've tried it with a HA cluster on staging though, so I can make a better-scoped report of the issue"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1679", "comments": ["I assume you copied the contents from [govuk-lambda-app-deployment/send_public_api_events_to_ga](https://github.com/alphagov/govuk-lambda-app-deployment/tree/909072dfa2976553d5e0010eb0ca6803d72ff8fb/send_public_api_events_to_ga)? If so, can you link to the original in the commit message?\r\n\r\nThat said, these files seem to differ slightly (no `.python-version` file, no `test_requirements.txt` nor `binary_requirements.txt`), so please also explain how this commit is different to what exists in the other repo.", "Same here - please [link to the repo you've copied it from](https://github.com/alphagov/govuk-lambda-app-deployment/tree/909072dfa2976553d5e0010eb0ca6803d72ff8fb/download-lambda-logs).\r\n\r\nAlso could you ensure every README has a h1 heading, i.e.\r\n\r\n```suggestion\r\n# Lambda: DownloadLogsAnalytics\r\n\r\nUploads fastly asset logs to Google analytics.\r\n```", "```suggestion\r\n# Grant permissions for accessing the S3 bucket\r\n```", "This change seems unrelated to the `Add configuration for send_public_events_to_ga function` commit?\r\n\r\n", "What were these changes for? They look like syntax changes associated with a different Terraform version - again it feels like this should be a separate commit \ud83e\udd14 ", "Worth expanding on the commit message a bit, I initially thought the `terraform/lambda/SendPublicAPIEventsToGA/send_public_events_to_ga.zip` file being committed was a mistake, but now I see it was deliberate.\r\n\r\nEDIT: looks like it _was_ a mistake, as I can see you generate all the zips in the last commit (agree that is neater). So worth going back to the `Add configuration for send_public_events_to_ga function` commit and removing the zip file.", "This all gets deleted in the `Add lambda trigger when an S3 object is created` commit - feels like some commit squashing is needed?", "Yes, this shouldn't be here. I mismatched things a bit after a rebase. "]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1677", "comments": ["Looks like this has lost a column rather than gained one", "Argh, good spot. I got sidetracked mid-change and then must have lost my place!"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1655", "comments": ["optional: the current major version is 4, so consider targeting that (if you haven't already) since this is a new module", "Shouldn't this be conditional on var.deployment_mode? Alternatively you could make it the caller's problem and just expect the right subnet(s) to be passed in, but I expect in this case it's neater to have this module figure it out.\r\n\r\nE.g. something like:\r\n\r\n```suggestion\r\n  subnet_ids = var.deployment_mode == 'SINGLE_INSTANCE' ? [data.terraform_remote_state.infra_networking.outputs.private_subnet_ids[0]] : data.terraform_remote_state.infra_networking.outputs.private_subnet_ids\r\n```", "optional: consider formatting this so that it'll be picked up by terraform-docs, for discoverability\r\n\r\ne.g. by putting it in the module header that terraform-docs looks for\r\n```\r\n/**\r\n * Module app-amazonmq creates an Amazon MQ instance or cluster for GOV.UK.\r\n * It uses remote state from the infra-vpc and infra-security-groups modules.\r\n *\r\n * The Terraform provider will only allow us to create a single user, so all other users must be added from the Amazon web UI.\r\n */\r\n```\r\n\r\n(has to be at the start of the file, afaict - perhaps there's an inline syntax though?)", "Consider generating this (using the `random` provider) instead of passing it in. Would that eliminate the nasty `sop` secrets stuff?", "Consider using the existing security group that controls access to RabbitMQ. Wouldn't we always want the same principals to have access during transition? (i.e. using a single ACL ought to reduce the space of possible config mistakes, no?)\r\n\r\nIt's safe and easy to have your new module add rules to an SG that's owned by an existing module, and you could easily move ownership of the SG into here later.", "Is there a reason for scraping the hostname out of the `console_url` attribute vs just using the `instances[].endpoints` attribute?", "This regex simplifies to `\"://([^/:]+)\"` (because Terraform's `regex()` is a partial match i.e. there's no implicit `^` anchor). ~(But I suspect you don't need the regex at all - see previous.)~", "I wouldn't bother with this extra level of indirection, since the stacks thing is disused and won't be used for the remaining lifetime of the system (which is only a few months).", "This could use a description to say what form this \"endpoint\" takes (e.g. as a new user to this module I don't know if this is an AMQP URL or a comma-separated list of node hostnames or something else)", "Will there be just the one endpoint in the high-availability config in staging/prod, or would this need to become a list?\r\n\r\nSimilarly for console_url etc.", "Yes, the endpoints are of the form `amqps://(host):(port)/`, whereas the console_url doesn't include the port - so there's one less thing to strip out. It's awkward, I know, and I'm totally open to suggestions for better ways to do it, this is just the least-worst I've found  ", "Ah fair enough. If it makes sense to do this here rather than at the caller then that seems reasonable then. (Though I would have thought every user of the provider would have the same problem, which suggests there might be something weird/unexpected about our setup that could be improved/simplified \ud83e\udd37 Without spending a bunch of time looking into it, I don't know exactly what that'd be, if anything)", "Oh I just realised the weird/unexpected thing about our setup is probably those clunky homegrown env vars that https://github.com/alphagov/govuk_message_queue_consumer/ expects, right? \ud83d\ude05 That'd explain why (for now) we want a list of hostnames rather than a more usual AMQP URL.", "good call, thanks :+1: ", "I like the idea of generating the password, will give that a go.\r\n\r\nIt will mean we can get rid of the encrypted `amazonmq_root_password` secret, which is definitely a plus.\r\n", "The only drawback I can see is that we'll need to output the root password in order for whoever's running it to log in to the web admin UI, which means it will be in the console output for builds in the CI. Could that be a security issue? \r\nI guess that question is roughly equivalent to \"are there any users who have access to our CI who we would not be comfortable having the root RabbitMQ password?\"", "The 'proper' way of doing a custom domain would be to also create a Network Load Balancer that balances between the MQ instances via their IPs, and point the route53 entry at the NLB (there's an [AWS article about it](https://aws.amazon.com/blogs/compute/creating-static-custom-domain-endpoints-with-amazon-mq-for-rabbitmq/) ). \r\n\r\nBut frankly that's a bit of complexity that I was hoping to not have to deal with at this stage - I wanted to keep this initial `integration` implementation as simple as possible, and deal with the multi-instance issues when I'm ready to set it up on `staging`. This might well be the 'something weird about our setup' that you suspected, of course...\r\n\r\nAre you OK if I do that as a separate PR later?", "Good spot, thanks", "You're right, I think this will become a list of endpoint URLs for a HA setup. Not sure yet about the `console_url`. \r\n\r\nLike in the [previous comment](https://github.com/alphagov/govuk-aws/pull/1655#discussion_r1034139630) I was planning to deal with that at the point of setup on `staging`, to try and keep this initial `integration` setup as simple as possible. I'm  iterating towards the final state, essentially.  ", "Some C+P left behind", "With calling this \"app-amazonmq\", would the intention be to use this for future AmazonMQ usages (so publishing and the crawler)? I felt like there\u2019s perhaps a bit of a smell that the name seems generic but the inputs are specifically publishing queue, and I wonder if life would be simpler to give it a specific name like publishing-amazonmq to not leave an impression of reuse/extensibility for other apps.", "Some C+P left behind", "With calling this \"app-amazonmq\", would the intention be to use this for future AmazonMQ usages (so publishing and the crawler)? I felt like there\u2019s perhaps a bit of a smell that the name seems generic but the inputs are specifically publishing queue, and I wonder if life would be simpler to give it a specific name like publishing-amazonmq to not leave an impression of reuse/extensability for other apps.\r\n", "I guess there isn\u2019t a way we can grab this from the data input? ", "should there be an office_ips reference here? no worries if that\u2019s being deferred until later.", "Is there an advantage to having variables.tf and outputs.tf distinct from main.tf - I notice there\u2019s only a couple of projects that use them as separate files aside from this with the majority including them in main.tf. I\u2019m guessing they\u2019re normally only separate to collate multiple terraform files.", "Is this something that\u2019ll have to be in sync with the `\"rabbit_version\": \u201c3.6.15\u201d` from the rabbitmq definition config? (currently in https://github.com/alphagov/govuk-aws-data/pull/1127)\r\n", "Just need to specify `sensitive = true` when you define the Terraform output for the password and it won't show in stdout/stderr. Authorised people can look up the password using Terraform if/when they need it.", "Oof, classic Amazon. Sure, no probs with this being a non-prod solution for now \u2014 though don't forget to signpost that with a TODO in the module description/comments/readme or whatever, and update the PR and commit messages. (I've seen non-prod-ready stuff go into prod by mistake so many times here it's unreal \ud83d\ude05)", "done", "oops, good spot - fixed", "That's a good call. I'd based it on the other project names in the repo (e.g. `app-rabbitmq`) but happy to change it.", "yep, agreed, see previous comment on the README", "Yes, I originally had it as `office_ips` - expanded it to allow HTTPS from anywhere (although it's in a private subnet so 'anywhere' is effectively 'anywhere inside the VPC or VPN') when I couldn't get the connectivity working. Since figuring out the [port-forwarding](https://github.com/alphagov/govuk-connect/pull/78) I may be able to revert back to office_ips - will have a try  ", "Just clarity really - I find once the main.tf gets over a couple of hundred lines or so, it's easier (for me) to split outputs and variables out.", "only to a degree - and hopefully that degree is 'major version' if they're using semver properly.\r\nI've tried posting the 3.6.15 definition to the 3.9.16 broker and it works fine, so it looks like they are.", "not sure which data input you mean? I can easily make this a variable though, if that helps", "My thinking on this was to keep this as separate and isolated as possible from anything existing, for a few reasons:\r\n\r\n* I'm iterating rapidly, making lots of mistakes, and tearing things down/recreating them constantly at this stage. Didn't want to risk affecting anything already there if I could easily avoid it.\r\n* It feels a bit jarring to me to have an existing SG named '...rabbitmq...' give access to '...amazonmq...' as well\r\n* At the point where we've done the live migration, it seems cleaner to destroy all the rabbitmq stuff and delete the `app-rabbitmq` project entirely rather than move and rename an SG as part of that.\r\n\r\nThat being said, this is far more your domain than mine, and I'm happy to take your steer if you still think that's the right thing to do?", "done", "What about using AWS Secrets Manager? If that's how we're managing secrets on the new K8s platform, could we use that here too?", "Ah yes I can see the logic you followed. I think that one was given the name as that's what the machine class of puppet is named, so it corresponds with: https://github.com/alphagov/govuk-puppet/blob/main/modules/govuk/manifests/node/s_rabbitmq.pp\r\n\r\nI think that was optimistic naming back then since that isn't the only rabbitmq cluster in the stack.", "Sure, I was wondering if this was information that exists in the JSON config of https://github.com/alphagov/govuk-aws-data/pull/1127 and something that might need to be kept in sync between them.", "Great stuff, yeah it just caught me eye as we had the office_ips variable but didn't seem to use it.", "Good stuff", "I've got rid of the dedicated SG and added rules to the existing SG, as you suggested", "I've put this back to only allowing HTTPS ingress from anything in the management SG (effectively, all EC2 instances). This still allows connection from a dev laptop via the remote port-forward", "No, as far as I can tell this name is purely for description", "yep, will change the name", ".....and I've also now tested that publishing-api on integration can connect to the broker over AMQPS", "We'd only want to use Secrets Manager if this were a secret that we had to set manually, i.e. if it can't be automated. Basically, first preference is to eliminate a secret entirely, second preference is to generate it automatically, last resort is to use Secrets Manager (because it creates toil).", "Awesome, thanks!", "no probs \ud83d\udc4d ", "done :+1: ", ">  Authorised people can look up the password using Terraform if/when they need it.\r\n\r\nCould you slack me at some point with details of how to do this? I'd be keen to eliminate stored secrets if I can make this work", "Just to summarise our Slack convo just now: basically folks can do something along the lines of `tf init -backend-config integration.govuk.backend && tf state show random_password.amazonmq_root` (or whatever we end up calling it).", "This comment seems out of date now, I'm guessing it was added prior to the change to `-auto-approve` below?", "True, I've updated the comment ", "I'm experimenting with this method now, and unfortunately it's not working as we thought - you can't retrieve a sensitive value with `terraform state show`:\r\n\r\n```\r\n**$ terraform state show random_password.root\r\n# random_password.root:\r\nresource \"random_password\" \"root\" {\r\n    bcrypt_hash = (sensitive value)\r\n    ...\r\n    result      = (sensitive value)\r\n    ...\r\n}\r\n```\r\n\r\nThere's a few threads on the [terraform forums](https://github.com/hashicorp/terraform-provider-random/issues/168) about this. will try the [proposed workaround](https://github.com/hashicorp/terraform-provider-random/issues/168#issuecomment-956688443)", "I've got this working, [#afc5b9b](https://github.com/alphagov/govuk-aws/pull/1655/commits/afc5b9bf6d20481e78edbd0f5fd37cda331d9859) removes all dependence on sops-encrypted secrets and generates all passwords. Thanks for the idea!"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1652", "comments": ["Could this be updated to nodejs14.x ?", "discussed with Murilo and is ok as the PR is to update each runtime to the next major version and check for issues. eventually it will be updated to nodejs16.x. ", "I went down a rabbit hole while trying to answer the question: \"what's the best way of testing that this doesn't break\"?\r\n\r\nThe [lambda code](https://github.com/alphagov/govuk-aws/blob/main/terraform/lambda/CloudfrontUrlRewrite/index.js) this refers to basically rewrites the URL to append a `.html`, so that the requested file can be found in the S3 bucket (a request for `/foo` may work on GOV.UK, but the 'mirrored version' is saved as `/foo.html`).\r\n\r\nThis duplicates logic that lives in our [VCL for Fastly](https://github.com/alphagov/govuk-cdn-config/blob/3b8471bfacb3356442201a0b47a964d723b4f9b1/vcl_templates/www.vcl.erb#L302-L332), where if Fastly doesn't have something cached, it makes a request to Origin, and if Origin times out or returns a 5xx error, it will send a request to AWS -> Cloudfront -> S3 instead, and Fastly does the hard work of adding `.html` to the request.\r\n\r\nSo where does this Lambda get used? I believe it's in the failover scenario, i.e. Fastly goes down, so we update GOV.UK's DNS and point it to AWS (Cloudfront) instead. Currently, Cloudfront serves mirrored content from the S3 bucket.\r\n\r\nWithout Fastly doing the work of converting `/foo` to `/foo.html`, then requests go through to Cloudfront directly as `/foo`, and so Cloudfront needs to do the `.html` appending, which is why this Lambda exists.\r\n\r\nSome thoughts:\r\n\r\n1. Why do we need URL rewriting inside both Fastly _and_ Cloudfront? We could remove it from Fastly and just leave it to Cloudfront to do. I suspect the Cloudfront lambda is already being invoked anyway, but ends up doing noop because Fastly has already ensured there's a `.html` suffix.\r\n\r\n2. We're changing our failover so that Cloudfront routes requests to Origin, not the mirrors. In which case, we don't _want_ to add the `.html` suffix at the Fastly level, because that would break the routing at Origin. So that's another reason to remove it from the Fastly VCL. (Our config for our primary CDN shouldn't know the internals of our config for the secondary CDN).\r\n\r\nWe're in a slightly awkward situation where we're about to change our Cloudfront distribution for an improved failover plan, but we still need the existing failover & mirror fallbacks to work in the meantime.\r\n\r\nI note that this lambda is invoked on the `Default (*)` Behaviour on Production's Cloudfront (which serves mirrored content) but we don't have that on Staging (probably removed while testing).\r\n\r\nI think we should get Staging's Cloudfront back to how it was (serving mirrored content), update this lambda, then it should be easy enough to try viewing a `/foo` Cloudfront URL and ensuring Cloudfront serves the `foo.html` version.\r\n\r\nMay need some coordination with @rtrinque \ud83d\udc40 \r\n\r\nEventually there'll be a different setup for the mirror fallback, but we're not there yet. I imagine something involving multiple Cloudfront distributions, something like:\r\n\r\nIf Origin is down, point to mirrors:\r\n\r\n* Fastly -> Origin Cloudfront -> ~~Origin~~\r\n* Fastly -> Mirror Cloudfront -> S3\r\n\r\nIf Fastly is down, switch to dynamic Cloudfront:\r\n\r\n* ~~Fastly~~ Origin Cloudfront -> Origin\r\n\r\nIf Fastly is down AND Origin is down, automatically retry a fetch from the mirrors\r\n\r\n* ~~Fastly~~ Origin Cloudfront -> ~~Origin~~ -> Mirror Cloudfront -> S3\r\n\r\n(In this case, we would be able to manually test the URL rewrite works by accessing the Mirror Cloudfront.)", "Several points:\r\n- yes the lambda exists purely for the failover scenario\r\n- there is no failover cloudfront in staging as it was deemed non essential, the cloudfront distributions you see there are most likely part of the tests for the new cloudfront infra\r\n \r\n", "Thanks for confirming \ud83d\udc4d so my suspicion was that this lambda may not be needed once the 'dynamic origin' cloudfront has been enabled. It sounds like that's the case.\r\nSo the best course of action would be to:\r\n\r\n1) Ignore this lambda\r\n2) Implement dynamic origin cloudfront\r\n3) Delete the (now unused) lambda\r\n4) One day, in the future, perhaps create a variant of the lambda again, for a fallback 'mirror cloudfront' if needed\r\n\r\nDoes that sound about right? @rtrinque ", "So the new cloudfront will indeed replace the current one.\r\nThe new cloudfront will be able to serve from two origins, cache LB, and S3 mirrors.\r\nSo we sill still need the rewriting lambda in the scenario where we lost fastly and origin", "@MuriloDalRi @rtrinque we've discussed this offline - sounds like Roch is going to attempt to copy the lambda, update its Node version, and get it working with the new Cloudfront distribution?\r\n\r\nThough in the meantime, I think we'd still need to update this lambda because Fastly will continue to request content from the mirrors when Origin is unavailable, and that uses this lambda.\r\n\r\n@rtrinque can you confirm we still expect this lambda to be needed, and therefore that it should be updated?\r\nCan you advise on how best to test it, given Staging is being used to test the new Cloudfront?\r\n\r\nThanks!"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1639", "comments": ["Can you add an inline comment to a URL that describes this requirement?", "\ud83d\udc4d  And have added a line to the commit message quoting the actual instructions."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1638", "comments": ["The signon login page itself looks like a phishing site, since it's:\r\n- Styled like GOV.UK\r\n- Is on a Non-GOV.UK domain\r\n- Asks the user for sensitive credentials (username / password / MFA)\r\n\r\nI wonder if this is worth noting if we're including \"an authentication method such as Signon\" in the definition of \"Authenticated\". I think it's fine if the publishing apps are publically routable, but redirect to Signon for non-authenticated users, so long as Signon itself is either Authenticated in a way that isn't styled as GOV.UK or is Privately Routable.", "I think we need to be careful about any wording that might encourage the proliferation of IP-based ACLs. Trusting the network is seriously poor practice these days and causes real incidents and problems.\r\n\r\nI'd be ok with just removing the VPN example and going with \"not available on the public Internet\".", "Signon is on a GOV.UK domain, so I don't see an issue here?\r\nThe EKS version of Signon is different, but I note that in the Consequences section of this document.\r\n\r\nEDIT: also happy to remove the reference to Signon on line 15 if it's confusing things.", "I agree, however this statement contains a circular reference since Signon is itself supposed to provide user authentication and authorisation. I'd suggest\r\n\r\n```suggestion\r\nThe `signon.eks.integration.govuk.digital` site would be in violation of this proposal, and would need to be either be made Authenticated, made unavailable to the public Internet, or moved to a `gov.uk` domain.\r\n```", "These all work for the general public right now:\r\n\r\nhttps://signon.staging.govuk.digital/\r\n\r\nhttps://signon.integration.govuk.digital/\r\n\r\nhttps://signon.production.govuk.digital/", "nit/opinion: I'm not convinced that the use of this type of formal language is helpful in this context. We're not actually writing a standards document here, just documenting the rationale for a decision. Using overly formal language tends to have a chilling effect on discussion, in my experience.", "Oh and the same thing applies to all the `signon.*.govuk.digital` domains :)", "Ah ok - I missed that! I was referring to https://signon.publishing.service.gov.uk etc.\r\nThanks for clarifying \ud83d\udc4d I'll amend the Consequences section.", "https://github.com/alphagov/govuk-helm-charts/pull/604", "Thanks - I've tweaked (though lost all reference to EKS signon as that is no longer available over public internet).", "Renamed term to \"Unavailable to the Public Internet\" and removed the definition altogether (as it is self explanatory).", "I've changed the Consequences section accordingly. I think this is ready to go now?\r\n\r\nWhat I haven't done is say \"Signon can be publicly visible and on a non-GOV.UK domain, provided it isn't styled like a GOV.UK page\". I _guess_ that would be OK, but feels a lot riskier (at what point is a page 'sufficiently styled' to look like a phishing site?)", "I think the existence of Signon became problematic the day that Sign In was launched to the public. Probably best dealt with as a separate issue though?", "+1 - I think having a prober to check for regressions is a good idea. (Especially while we still have so many darned IP allowlists \ud83d\ude2d)", "Fair enough - it does feel a little over the top, though I don't think that's justification enough to undo it. There are pros and cons to going formal. FWIW I was following the [template in govuk-rfcs](https://github.com/alphagov/govuk-rfcs/blob/main/rfc-000-template.md)."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1630", "comments": ["Because these bucket names are different in the different environments, I think we'll need to either do something with variables or scope all of the resources in this file down so they only appear in integration.\r\n\r\n(For context, the infra-security terraform deployment needs to apply in integration / staging and production)\r\n\r\nI'd suggest putting something like:\r\n\r\n```\r\ncount = \"${var.aws_environment == \"integration\" ? 1 : 0}\"\r\n```\r\n\r\nOn each of the resources to stop terraform from trying to create them in non-integration environments. I'm think infra-security already has a variable for aws_environment.", "There might be a nicer syntax to do that if infra-security is on a newer version of terraform.", "Thanks for spotting that and suggesting the fix.  Done in ee0c629ae37c53aeb0744d8ca7b9125bb4cead7e."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1623", "comments": ["Did the contents of this file get copied and pasted from somewhere? If so, could you link to the original source in the commit?", "Yep, good point - it came from https://github.com/alphagov/govuk-aws/blob/main/terraform/projects/infra-public-wafs/default_rule.tf, but will amend the commit \ud83d\udc4d "]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1615", "comments": ["Not sure whether relevant, but this was renamed to `content_store_backup_bucket_name` in the connected PR [build_knowledge_graph_data](https://github.com/alphagov/govuk-knowledge-graph/pull/384/files#)", "It's not a problem: `database_backups_bucket_name` in `main.tf` is passed to `userdata.tpl`, which uses it in\r\n```\r\n./build_knowledge_graph_data [...] -b \"${database_backups_bucket_name}\"\r\n```\r\nSo `build_knowledge_graph_data` retrieves as a command line parameters and assigns it to a variable called `content_store_backup_bucket_name` -- different name, but it doesn't matter as they're independent"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1608", "comments": ["Why is this once called `_lab_` instead of `_dev_`?", "Why does this name need to change?", "I compared this section with the production section using linediff.vim, and I think `-dev` was suffixed in all the necessary places, except where noted below.", "Why does the `sandbox` branch need to be checked out?", "```suggestion\r\n./provision_knowledge_graph_dev -i $${instance_id} -d ${data_infrastructure_bucket_name} -r ${related_links_bucket_name} 2>&1\r\n```", "Why is this one `lab` instead of `dev`?", "yes, but not only we're no longer called Labs, but also I think `dev` is clearer in its intent", "because theres a stupid limit of 32 characters :(", "So did this line never work before?  I'm a bit confused about how it relates to the rest of this PR.", "Because we might do some work that we only want to see on the dev graph, while normal bug repairs happen on the main branch and make it to the production graph directly.\r\nCan you think of a better alternative?\r\nObviously the name's wrong and it should be `dev`", "That should be called `provision_knowledge_graph` anyway, since we're taking it from a different branch", "I just missed it.", "Cross-referencing https://github.com/alphagov/govuk-knowledge-graph/pull/378, which would create `provision_knowledge_graph_dev`.", "It did but they'd removed '-elb-' to fit within the character limit. I'd readded it before realising that was the reason, and I shortened it again, but in a different way.\r\nBut I don't mind either way.\r\n"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1607", "comments": ["Didn't we say we should always opt for `apt-get`?", "And will `python-pip` get us the right python3-pip? No need to specify `python3-pip` explicitly?", "This old code is using default python (2.7, here), which still worked.", "This is just for my own learning :D how do you know `/usr/local/bin/aws` is the right directory here?", "I check on the running govgraph, where I followed the script manually, leading to \r\n```\r\nubuntu@ip-10-1-1-105:~$ ls -l `which aws`\r\nlrwxrwxrwx 1 root root 37 Jun 24 07:31 /usr/local/bin/aws -> /usr/local/aws-cli/v2/current/bin/aws\r\n```\r\n"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1605", "comments": ["Is this meant to have an `e` at the end?", "(reposting other comment because the email reply feature doesn't join it up)\r\n\r\nYep - because it's a VPC \"e\"ndpoint. There are some similar (though\r\ninverse) examples here:\r\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/example-bucket-policies-vpc-endpoint.html#example-bucket-policies-restrict-accesss-vpc-endpoint\r\n\r\n(I also tried it out on staging with curl to verify that it works)"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1593", "comments": ["I don't think any of the links in the tables in the readme really work. I assume they're supposed to open the folder?", "All of the values match up, and you don't seem to have made any copy and paste errors, so I assume it's ok. I don't know terraform though.", "They're autogenerated by /tools/update-docs.sh which uses [terraform-docs](https://github.com/terraform-docs/terraform-docs). Perhaps we need to tweak that to be more useful \ud83e\udd14 . One for the backlog", "Thanks!"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1588", "comments": ["Commit 1: is the lambda you refer to a built-in, AWS-maintained thing, or is there an alphagov repo for it?", "Commit 2: can you edit the commit message to link to the Smokey check you refer to?", "It's in this repo. I'll add a link, good call, thanks"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1568", "comments": ["Any reason why this (`line 317`, time 19:29) did not need being brought backward as well?", "Well spotted! I thought it wouldn't hurt to leave it running an hour later in the summer.", "Haha Fine with me. Albeit summer time is when, hopefully, govGraph users will clock out earlier to enjoy some evening lights :D "]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1557", "comments": ["I think you do not want line 14-15\r\n```pip install --upgrade pip```\r\nas you are getting pip via APT now (line 17-18)\r\n```sudo apt install -y python-pip```", "I think you do not want line 14-15\r\n```pip install --upgrade pip```\r\nas you are getting pip via APT now (line 17-18)\r\n```sudo apt install -y python-pip```", "Final thought, you may need \r\n```python3-pip``\r\nin Linux/Ubuntu\r\n\r\nhttps://stackoverflow.com/a/57266972", "I wouldn't do that at this point. The current version is indeed 2.7 but that's ok since `awscli` is pinned to a specific version. It's currently working so I'd rather not play with it, until we need to change the `awcli` version."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1545", "comments": ["I wonder the security groups/rules should not be added there: https://github.com/alphagov/govuk-aws/tree/master/terraform/projects/infra-security-groups", "should you add these security groups to this PR?", "I've added that, does it look ok to you?", "Removed that line", "I don't see an equivalent in publishing-api or email-alert-api, so suspect this isn't needed. See my comment on `instance_elb_ids` below.", "Any reason why this is `m5.2xlarge`? Looking at [what other apps have set](https://github.com/alphagov/govuk-aws/search?q=%22m5.%22&type=code), they mostly seem to be `m5.large`, which is the [smallest & cheapest instance size available](https://aws.amazon.com/ec2/instance-types/). I suspect we'll want to do the same, given the heavily cached Locations API should need minimal resources.", "Looking at other examples, I think this needs to use the hyphenated name. I don't think we need the `sg_aws-vpn_id` security group either, as that only seems to be used on the `backend` machine.\r\n\r\n```suggestion\r\n  instance_security_group_ids   = [\"${data.terraform_remote_state.infra_security_groups.sg_locations-api_id}\", \"${data.terraform_remote_state.infra_security_groups.sg_management_id}\"]\r\n```", "We seem to use a range of values throughout govuk-aws, but Publishing API and Email Alert API both use `50`. Mapit, which this is replacing, only uses 20, as does Router, but neither of these are Rails apps, so I wonder if we historically need the bigger volumes for our Rails apps. To be on the safe side I'd suggest setting this to 50 rather than anything lower.", "Hmm, [email-alert-api sets this to 1](https://github.com/alphagov/govuk-aws/blob/7fad0ad1298c92c58eb6f668090bf8a5cd6d9734/terraform/projects/app-email-alert-api/main.tf#L134-L135) and Publishing API [ranges from 1-2](https://github.com/alphagov/govuk-aws/blob/7fad0ad1298c92c58eb6f668090bf8a5cd6d9734/terraform/projects/app-publishing-api/main.tf#L229-L230) and, as you've taken inspiration from here, [backend sets it to 0](https://github.com/alphagov/govuk-aws/blob/7fad0ad1298c92c58eb6f668090bf8a5cd6d9734/terraform/projects/app-backend/main.tf#L109-L110).\r\n\r\nPresumably it comes down to whether the node should use an ALB or an ELB. Based on the [Account API config](https://github.com/alphagov/govuk-aws/commit/82c9dcf61b8c1c8e55e58b81b90f08107ef1f8e5), which is the most recent app we've built, we're going the ELB route, meaning this should be set to `1` and you can remove all the `locations_api_internal_alb` stuff.\r\n\r\nThat said, I'd appreciate an SRE pair of eyes on this!", "50 sounds fine to me. Logs only get rotated once a day, which is why some of these were raised to from 20 to 50 (after we had some bugs which caused logspew).", "`instance_elb_ids` and `instance_elb_ids_length` default to `[]` and `0` respectively, so there's no need to specify them here. They are indeed only for Classic ELB and therefore obsolete; see [the module docs for `aws/node_group`](https://github.com/alphagov/govuk-aws/tree/master/terraform/modules/aws/node_group).", "Oh, definitely don't use a Classic ELB for anything new. Use an ALB. Here's [an example](https://github.com/alphagov/govuk-aws/blob/master/terraform/projects/app-licensify-frontend/main.tf#L98).", "Thanks for the info, @sengi!", "Is there an external load balancer for Locations API? This SG looks redundant.", "I'll remove that"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1535", "comments": ["Shall we remove the explanatory comments from the copied rule?"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1519", "comments": ["LGTM, though it might be nice to put in a comment to say which AMI this is, e.g. `# Ubuntu Focal 20.04 (20211129), amd64, hvm-ssd, AMI for eu-west-1`.\r\n\r\nThe benefits to using `data.aws_ami` here is that this info is documented outside of the comment, and we get a valid AMI regardless of the region we are deploying to. At the moment this AMI would only be valid for the eu-west-1 region. Additionally, I think this would enable AWS to patch the image for us automatically (giving us a new AMI for our query) rather than requiring us to update the AMI manually. If you do a search for `focal 20220104 eu-west` on https://cloud-images.ubuntu.com/locator/ you can see there is a different AMI for each region (and duplicate AMIs for the same version, since _I believe_ AWS has issued a patched AMI for our region).", "Ah good shout, using the AMI ID directly was a lack of my understanding about `data.aws_ami` - definitely makes sense to use it. I've updated the commit."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1511", "comments": ["I think this is the only thing that needs to be unique across the AWS region. The resource names (`\"bar\"` in `resource \"foo\" \"bar\"`) only have to be unique to the terraform module. No great harm in having them like this though, other than more characters to type.", "yes, the names are a bit long here, but I think it's good practice generally. Thanks."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1510", "comments": ["I think you need to refer to this policy document inside an `aws_iam_policy` resource too (this data block literally just creates the text of the policy, it doesn't upload it to the AWS API).", "A bit like https://github.com/alphagov/govuk-aws/pull/1510/files#diff-a220c9a1f8e8811c6899b696c984f41224fcdfdc80f1ffd4749ebd6df1b8f6daR112-R115 for the sagemaker policy.\r\n\r\nAnd then you also need to attach your new policy to a role like https://github.com/alphagov/govuk-aws/pull/1510/files#diff-a220c9a1f8e8811c6899b696c984f41224fcdfdc80f1ffd4749ebd6df1b8f6daL110-L113", "ah, yes, thansk. And I nee to supply the actual name of the secret, obvs -- as found in the [related links tf config](https://github.com/alphagov/govuk-aws/blob/give-bigquery-creds-to-data-science-app/terraform/projects/app-related-links/main.tf#L54)"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1507", "comments": ["I tried a splat expression here (`aws_db_instance.instance[*].id`) but it complained about the `id` attribute being invalid"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1502", "comments": ["Does setting this while we have https://github.com/alphagov/govuk-aws/blob/d562361ed6edbd22de7821ad511f2d34b178ffcb/.terraform-version cause any oddities? \r\n\r\nI wondered if it caused any terraform formatting oddities? - Since I guess we format against 0.11 syntax?", "I guess not since it looks like this is formatted with newer terraform syntax.", "For the cloudwatch alarms I think it'd be good to explain where these came from and what their thresholds are - basically to try help the next person who wonders what the logic was for the setting of alerts like you've experienced.", "If I've understood this right, we'd have a hash of engine_params like:\r\n\r\n```\r\n{ \"log_min_duration_statement\": \"10000\", \"log_statement\": \"all\" }\r\n```\r\n\r\nwhich gets mapped into parameter name and value?\r\n\r\nIf so that'll cause a problem with the additional params such as apply_method: https://github.com/alphagov/govuk-aws/blob/32131365cb04566dd7e11f7034ea0300e78a9f08/terraform/projects/app-postgresql/main.tf#L134\r\n\r\ncould it be that engine params is an array and the item value is a hash of keys with properties - that could allow it to deal with any new keys too I'd have thought?", "Does our looping mean we don't get to use the node_group definition: https://github.com/alphagov/govuk-aws/blob/32131365cb04566dd7e11f7034ea0300e78a9f08/terraform/modules/aws/node_group/main.tf - just wondering if we needed to inline it as well, since it's quite heavy on config", "Might be good to say somewhere what these mean - I have no idea myself.", "Yeah, it uses the terraform version for the project for formatting", "These came from the rds module, I'll add some comments", "It looks like `name`, `value`, and `apply_method` are the only arguments a `parameter` block can take - so I'll add `apply_method` and make it default to `immediate` if not specified in the `engine_params`.\r\n\r\nI'll also change the data format to  `name = { value = \"...\", [apply_method = \"...\"] }`", "I did inline the `node_group` module, but could drop much of it because I just used the values that the db-admin project specified.", "There's a hard limit of 50 `aws_db_parameter_group`s per account:\r\n\r\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Limits.html\r\n\r\nPretty sure we'll still be fine, since we're only talking about ~17 databases with 1 parameter group each. If we need to we can always consolidate them later (e.g. by creating one parameter group per unique combination of parameters, instead of one per database). Keeping it simple is good for now.", "ok cool - I don't feel fully in the loop on all the logic of inlining and not inlining, but I don't think I need to be. It'd be good to capture the why though in commits.", "We're reusing the security groups from the old, Big database instances.\r\n\r\nThis will mean:\r\n* All the mysql databases will be in both the mysql security group and the postgres security group\r\n* All the postgres databases will be in both the mysql security group and the postgres security group\r\n* We'll be able to write security group rules like \"instances in the ckan security group can make requests to databases in the postgres security group\"\r\n* Those rules will be looser than they would be in an ideal world (ideal world - ckan instances can talk to ckan database, but not all the other databases)\r\n\r\nThis situation won't be much worse than the situation we're in now (all the databases are on the same instance, so there's no way to say which server can talk to which database at the network level).\r\n\r\nI guess the options are:\r\n\r\n* Keep things the way this is coded - all the databases get both security groups\r\n* Separate things out so all the postgres DBs go in the postgres group, all the mysqls go in the mysql group (closest to what we have now, but a bit odd)\r\n* Have this terraform create one security group per database, output the IDs, and then have `app-ckan` and co read the security group ids from this project's remote state and set up rules that say \"ckan can talk to ckan db\" etc.\r\n\r\nI'm on the fence as to what the right thing to do is.", "I think the reason is that we can't use the modules we currently have without updating them to the new terraform syntax, and also the old version of terraform most of this repo uses doesn't support the `for_each` syntax.  We wouldn't want to create RDS instances with `count`, because we have problems currently with (eg) updating or removing something in the middle of a list affecting later entries.\r\n\r\nAnd if we can't use `count` or `for_each`, we just have to repeat the resource definitions for every copy we want - so this file would be N times as long, where N is the number of different databases.", "I think we could probably do this more simply now that we're on a modern version of terraform.\r\n\r\n`var.user_data_snippets` is always set to `[\"00-base\", \"10-db-admin\", \"20-puppet-client\"]` (it's a variable, but I don't see why we'd ever want to override it in this module).\r\n\r\nYou could drop the `null_resource` entirely and do this:\r\n\r\n```hcl\r\nuser_data = join(\r\n  \"\\n\\n\",\r\n  concat(\r\n    [\"#!/usr/bin/env bash\"],\r\n    [for f in [\"00-base\", \"10-db-admin\", \"20-puppet-client\"]: file(\"../../userdata/${f}\")]\r\n  )\r\n)\r\n```\r\n\r\nI'm also not sure we need the extra `#!/usr/bin/env bash` line, because 00-base has `#!/bin/bash` - is that maybe not where bash is on this AMI?", "I guess all the DB admin machines will be able to access all the databases. That's probably okay, but not perfect.", "Would probably be nicer to create an NLB (or maybe an ALB if we can get away with it?). In a perfect world, maybe we'd have one load balancer which routes traffic to all the db_admin machines, instead of one load balancer per machine. So you'd create the load balancer outside the loop, then create target groups (or whatever) inside the loop.\r\n\r\nNot a hill I want to die on, but worth considering.", "I think we _might_ be able to use the old module in the loop (modern terraform has module foreach, not sure if it works with modules using the old syntax though).\r\n\r\nPersonally, I still prefer things to be inlined - it makes it more obvious to me all the things we're creating in this deployment. Because modules like `node_group` get used for lots of different things (db_admin machines, app machines, rabbitmq machines etc.) the module ends up sprouting dozens of conditionals, and it can be hard to tell what it's actually doing. Inlining the resources means we can keep an eye on what we're actually doing, and we can address things like \"should we be creating one load balancer per EC2 instance\" which the module might otherwise obfuscate.", "This file ended up pretty big. I wonder if we should split it up into:\r\n\r\n- `main.tf` - contains only the `terraform` and `provider` blocks\r\n- `variables.tf` - contains all the variables\r\n- `rds.tf` - contains all the stuff that's to do with the RDS instance (maybe including cloudwatch alarms and subscriptions?)\r\n- `db_admin.tf` - contains all the stuff that's to do with DB Admin", "Looks like this was added to the app-db-admin machines in bdb9c2bc208b3ed1405b8c48c114c7621458b857 to support pbbouncer.\r\n\r\nDo we actually use pgbouncer? If not, can we drop this listener?", "Maybe answering my own question: https://github.com/alphagov/govuk-puppet/pull/11029\r\n\r\nLooks like we removed pgbouncer when we moved to AWS.", "Or maybe... do we even want a load balancer in the first place?\r\n\r\nLooks like we've got two listeners - 22 lets ssh traffic to the instance, 6432 lets pgbouncer traffic through (which we don't need).\r\n\r\nCould we just let traffic go straight from the jumpbox to the db-admin instances, and skip the load balancer entirely?", "I'm probably straying too far from established patterns here. And I'm not an AWS expert by any means.\r\n\r\n~But I think the objectively simplest thing would be to:~\r\n\r\n* ~Create an `aws_instance` (i.e. without all the autoscaling group stuff)~\r\n* ~Put it in a security group~\r\n* ~Change the `db_admin_service_record` Route53 record so it points at the [private_dns](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/instance#private_dns) name for the instance, instead of the ELB~\r\n* ~Make sure there's a security group rule that lets traffic flow from the jumpbox to the db_admin instance.~\r\n\r\n~... I might be oversimplifying though. It might not be worth shaving this yak right now.~\r\n\r\nEdit: I think the above is a big oversimplification. I don't think it covers things like \"what happens if an instance crashes\", which are important. The ASG / load balancer setup does solve those use cases, even if it's complicated.", "I've fully talked myself out of this now. Resolving the comment thread. Apologies for the noise.", "Although still maybe one NLB per app would be better than one Classic ELB per app...", "... sorry, still flogging this horse ...\r\n\r\nWe don't actually use the load balancers for ssh:\r\n\r\n```\r\ngds govuk connect -e integration ssh db_admin\r\nThere is one machine to connect to\r\n\r\nRunning command: ssh -J richardtowers@jumpbox.integration.publishing.service.gov.uk richardtowers@ip-10-1-6-102.eu-west-1.compute.internal\r\n```\r\n\r\n`ip-10-1-6-102.eu-west-1.compute.internal` is the private DNS name of the EC2 instance, not the load balancer.\r\n\r\nSo I guess all this load balancer is doing for us is the healthcheck for the autoscaling group \ud83e\udd14 ", "> Have this terraform create one security group per database, output the IDs, and then have app-ckan and co read the security group ids from this project's remote state and set up rules that say \"ckan can talk to ckan db\" etc.\r\n\r\nWould that work? As in, could we use the `data.terraform_remote_state.app_govuk_rds.output_name[\"database_name\"]` syntax in an older terraform project?", "```\r\nmichaelswalker@ec2-staging-blue-db_admin-ip-10-12-6-111:~$ which bash\r\n/bin/bash\r\n```\r\n\r\n\ud83e\udd37 \r\n\r\nThat's much better, I'll change it.", "Great, I wondered if that port was needed", "> Create an `aws_instance` (i.e. without all the autoscaling group stuff)\r\n\r\nI started by doing that, then went back to the ASG approach as I think that would mean we have to re-run terraform if the instance gets terminated (see message of e5423502ae2b22197c1df355daa9edcd014d9c0b).\r\n\r\nIf you don't think the ELB is needed, we could drop it entirely.", "Resolved in slack: the ELB gives us the port 22 healthcheck, so it is needed for the ASG.", "Yeah, I think if we're on terraform pre-0.12.30 we probably can't access the remote state written by this terraform version (source: https://github.com/hashicorp/terraform/blob/v0.12.30/CHANGELOG.md#01230-january-06-2021)\r\n\r\nWe could still get the IDs of the security groups by looking them up by name using a [security_group `data` thing](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/data-sources/security_group) though.", "Ok, I think my preference would be to keep things as they currently are in the PR, so we can get the new databases up and running sooner rather than later, and then to introduce new security groups to tighten up security later, as we'll have to make changes to our other Terraform projects to do that.\r\n\r\nAccess to our new databases will be slightly more relaxed than access to our old ones (as we're putting them in both the postgres and mysql groups), but it's still all in a VPC so things aren't wide open, and access is still somewhat restricted.\r\n\r\n", "There's now a unique security group for each RDS instance", "And a unique security group for each db-admin", "I'll split this up in one commit at the end, after we're happy with everything else here.", "This one looks like an oopsy\r\n```suggestion\r\n  security_group_id        = \"${aws_security_group.whitehall-rds.id}\"\r\n```", "```suggestion\r\n  security_group_id        = \"${aws_security_group.whitehall-rds.id}\"\r\n```", "I wonder if we should filter this on engine = \"postgres\".\r\n\r\nSomething like:\r\n\r\n```suggestion\r\n  for_each = {for name, config in var.databases : name => config if config.engine == \"postgres\"}\r\n```\r\n\r\n... and then we don't need to give all the postgres databases access to the myql ports and vice versa. Maybe that's too fancy - it's not really an issue if they have access to one more port which isn't even open.", "No, that's good, I actually wanted to do that but didn't know you could", "It looks like they're IDs of official Amazon things, and one of them isn't needed here: https://github.com/alphagov/govuk-aws/commit/5e89e967c76844e52c1481a3721e2e124fcefcd9 - I'll remove the deep learning one.", "It's probably a bit surprising to have this here, instead of in infra-public-services. But it would be pretty painful to do this there (given the old version of terraform etc.), and it's nice having everything in one place. So I think this is okay."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1501", "comments": ["From [the docs](https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Source.MySQL.html#CHAP_Source.MySQL.AmazonManaged):\r\n> - Set the `binlog_row_image` parameter to `\"Full\"`.\r\n\r\nShould this value be capitalised? Not sure if it's case sensitive.\r\n\r\n```suggestion\r\n    value = \"Full\"\r\n```", "Ooh - great catch. Thanks.\r\n\r\nInterestingly in the AWS UI it's in lowercase with the available options provided as lowercase:\r\n![Screenshot 2021-12-14 at 10 37 29](https://user-images.githubusercontent.com/282717/145982731-dcccdc5c-ef33-46e1-a8e8-a64d6f6d7fff.png)\r\n\r\nIt seems better to have it as per the docs though. I'll set that and try a terraform plan on it - I somewhat expect though that a Terraform plan doesn't actually validate it with AWS so I might not know for sure until we apply it.\r\n"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1497", "comments": ["nit: since Terraform resources are namespaced by type (i.e. to refer to this resource you'd write `aws_iam_role_policy_attachment.related_links_jenkins_iam_role_policy_attachment`) it's slightly more readable to omit the suffix, like this:\r\n\r\n```suggestion\r\nresource \"aws_iam_role_policy_attachment\" \"related_links_jenkins\" {\r\n```\r\n\r\n(definitely don't worry about changing any pre-existing ones though!)", "optional: it's probably slightly quicker (and equally readable since there's only 3 of them) to do this with one apt-get operation. The error messages on failure will be equally good as well.\r\n```suggestion\r\nsudo apt-get install -y awscli jq gnupg2\r\n```\r\n(and similarly in the generation template, if you want)", "nit: the `-R` here is unnecessary and slightly confusing (since bigquery.json is an ordinary file and not a directory)\r\n```suggestion\r\nchown ubuntu:ubuntu /var/tmp/bigquery.json\r\n```", "Good point, thanks \ud83d\udc4d ", "Thanks, another good point. I was following past precedent and also my own past precedent, but totally makes sense what you suggest here."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1495", "comments": ["I'm fairly sure Terraform is robust to this, but there's a missing line ending at the end of this file. (Editor config issue maybe? We could add a fixer for this if it happens often.)", "Since this is ye olde crufty Terraform 0.11, the type system is quite tricksy. There's no boolean type for `variable`; it'll actually use string. The docs also [recommend using string literals \"true\" and \"false\" in this context](https://www.terraform.io/docs/configuration-0-11/variables.html#booleans), because TF 0.11 will coerce the bool literal to a string.\r\n```suggestion\r\n  description = \"Whether to create the bucket, in production we're expecting to use a bucket in a different AWS account\"\r\n  default     = \"false\"\r\n```", "nit: I'd put the count hack right at the top for readability (I guess it's sort of a convention?)", "Thank you! - Ironically I used an unfamiliar text editor for this as my vim does a terraform fmt that's far newer than our version of terraform causing massive diffs.", "Great thanks. Would you mind giving this a quick review: https://github.com/alphagov/govuk-aws-data/pull/942 I merged the govuk-aws-data PR before checking this one \ud83e\udd26\u200d\u2642\ufe0f ", "Done"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1482", "comments": ["I haven't looked up what `origin_ssl_protocols` actually does, but I doubt we want SSLv3 in there, and we probably want \"TLSv1.3\" if that's a thing...", "Looks like it's the protocols cloudfront is allowed to use to contact the origin.\r\n\r\nI don't see any reason to allow it to use anything less than TLSv1.2. It looks like it doesn't support TLSv1.3 yet.\r\n\r\nSo:\r\n\r\n```suggestion\r\n      origin_ssl_protocols   = [\"TLSv1.2\"]\r\n```", "Thanks Richard. Makes sense \ud83d\udc4d "]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1481", "comments": ["How did you determine this? (It sounds quite short to me given how long some of our Puppet / deployment automation stuff often takes, but if you've based this on measuring some actual startup times then no probs.)", "I would probably put a comment here explaining that this is essentially a whack-a-mole type of workaround for an unsolved intermittent issue with these instances (and link to the Trello card that tracks the issue, if there is one)."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1476", "comments": ["```suggestion\r\n  cidr_blocks      = [\"${data.github_ip_ranges.github.hooks_ipv4}\"]\r\n  ipv6_cidr_blocks = [\"${data.github_ip_ranges.github.hooks_ipv6}\"]\r\n```\r\n\r\nFrom [this doc](https://github.com/integrations/terraform-provider-github/blob/8a197474b6f5ec265b6ad426c0ed11cc25ffa8d8/website/docs/d/ip_ranges.html.markdown#attributes-reference) the `hooks_ipv4` returns a subset, but I suspect we want _all_ IPs in case some of the servers use an IPv6 address.\r\n\r\nReference: https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/security_group_rule#example-usage", "I think this is fine, IPv6 is not enable on gov.uk as far as I know."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1450", "comments": ["This is interesting, No office IPs anymore?", "This security group was actually unused (because we didn't have a public load balancer), so they weren't used.\r\n\r\nAnd `0.0.0.0/0` is the entire IPv4 space, so the office IPs are a subset of that."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1441", "comments": ["```suggestion\r\n    print(\"Copying %s from bucket %s to bucket %s ...\" % (key, source_bucket, target_bucket))\r\n```"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1412", "comments": ["I think this could be done slightly more neatly with [`setproduct`](https://www.terraform.io/docs/language/functions/setproduct.html).\r\n\r\nSomething like:\r\n\r\n```terraform\r\n  list_user_and_policy_arns = [\r\n    for pair in setproduct(var.role_user_arns, var.role_policy_arns):\r\n      {\r\n        user_arn: pair[0],\r\n        policy_arn: pair[1]\r\n      }\r\n  ]\r\n```", "Not necessarily the end of the world, but I worry that the names terraform gives these resources in the statefile are going to be horrible if they've got two ARNs as the key...\r\n\r\nI haven't checked the plan though - does it do something clever?", "I don't think this description makes it clear that this module will create _multiple_ roles, one for every combination of user and policy.", "```\r\n# module.gds_role_user.aws_iam_role_policy_attachment.gds_user_role_policy_attachments[\"arn:aws:iam::622626885786:user/roch.trinque@digital.cabinet-office.gov.uk.arn\r\n:aws:iam::aws:policy/ReadOnlyAccess\"] will be created\r\n```\r\n... so, a little bit gross. I don't think it will cause any issues, but it's not great.", "Maybe one step further, you could regex out the user name and policy name at this point, and then you could use them in your keys further down.\r\n\r\nSo:\r\n\r\n```terraform\r\n  list_user_and_policy_arns = [\r\n    for pair in setproduct(var.role_user_arns, var.role_policy_arns):\r\n      {\r\n        user_arn: pair[0],\r\n        policy_arn: pair[1],\r\n        user_name: regex(\"^.*/(.+)@.*$\", pair[0])[0],\r\n        policy_name: regex(\"^.*/(.+)$\", pair[1])[0],\r\n      }\r\n  ]\r\n```", "Thanks, I was planning to do that after your first set of comments. ", "using the above new tuple, we can sort this out.", "I can update that to make it clearer"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1410", "comments": ["Gosh, this is complicated...\r\n\r\nI'm not sure when it was added, but modern terraform fmt has a -recursive flag which probably does what you want without all these shenanigans (https://github.com/alphagov/govuk-infrastructure/blob/main/.github/workflows/ci.yml#L31)", "The reason we're doing this is because `tfenv` is going to magically pick-up the correct Terraform version based on the presence of a `.terraform-version` file located in the directory into which we're `cd`ing. Previously we were just pulling out all of the Terraform files with the `find` command, but this isn't going to work now that we are using multiple versions of Terraform within the repo, as each version requires slightly different syntax."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1399", "comments": ["There's a duplicate of `s3:PutObjectVersionAcl` here. Is it meant to be GetObjectVersionAcl?\r\n```suggestion\r\n                \"s3:GetObjectAcl\",\r\n                \"s3:GetObjectVersionAcl\"\r\n```", "\ud83e\udd85 \ud83d\udc41\ufe0f - good catch!"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1397", "comments": ["The trailing comma here turns out to be what's causing the extremely unhelpful `Resource 'aws_iam_policy.ask_export_s3_writer' not found for variable 'aws_iam_policy.ask_export_s3_writer.arn'` error message.\r\n\r\n```suggestion\r\n                \"s3:PutObject\"\r\n```", "Are you sure you want to pass the bucket name in as a var? If the bucket name only depends on the environment then it would be clearer just to substitute the environment name in here. I don't know what the actual bucket names are but for the sake of an example: `bucket = \"govuk-ask-export-${var.aws_environment}`. Otherwise the configuration is effectively split between three completely different places over two different repos, which seems a bit over the top.", "I think you'll need to generate the files for the other environments as well (integration and staging).", "Actually since you mentioned that the bucket only exists in prod, I'd also be fine with not bothering with the other environments - it's maybe a bit of a departure from how the other modules work but it'd still be quite clear that the module isn't supposed to apply to any of the non-prod accounts \ud83e\udd37 ", "OTOH if you want to keep the bucket name private (not usually necessary but you're better placed to judge that than I since I don't know the app) then you'd need the var in order to pass it in from govuk-aws-data.", "Yup - so I've kept the only the prod backend (to be clear that these resources are only available in prod) . But added a comment to the readme to explain why.", "Going to keep the bucket name private in govuk-aws-data to err the side of cation.", "Link to the corresponding PR - https://github.com/alphagov/govuk-aws-data/pull/835"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1396", "comments": ["Do you need an underscore rather than a dash?\r\n\r\n```suggestion\r\n  target_group_health_check_path = \"/_healthcheck_content-store\"\r\n```\r\n\r\nE.g. https://github.com/alphagov/govuk-aws/blob/master/terraform/projects/infra-public-services/main.tf#L1225", "Oh good spot, thanks! I've amended the last commit \ud83d\udc4d."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1394", "comments": ["I'm just going to rename this to memcahced, as the other names have `redis` in the name, so it feels more consistent."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1388", "comments": ["```suggestion\r\n      - run: bundle install --deployment\r\n      - run: bundle install --jobs 4 --retry 3 --deployment\r\n```\r\n\r\nWill make it just a bit more consistent and a little faster. "]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1351", "comments": ["```suggestion\r\n  instance_subnet_ids           = \"${matchkeys(values(data.terraform_remote_state.infra_networking.private_subnet_names_ids_map), keys(data.terraform_remote_state.infra_networking.private_subnet_names_ids_map), list(var.mapit_8_subnet))}\"\r\n```", "I knew there would be one!"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1331", "comments": ["IIRC there's a size limit for user-data, so too many more of these and we might have a problem. But it's alright for now. Might be worth a comment to say who's key is the Yubikey one - just for when we come to do leavers tickets?", "Thanks Issy. I remember you saying this previously, and my intention is to actually use the `90-data-science-base` file which I included as a var to the userdata script but haven't actually used it yet. Ideally we don't have this in different places but in only a single place to make it easier for joiners/leavers as you point out.", "Will address this in a separate PR, as the problem exists in a few other projects also."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1315", "comments": ["Did you consider putting this stuff in the app-whitehall-backend project [1]? That at least seems quite related in name.\r\n\r\n1: https://github.com/alphagov/govuk-aws/tree/master/terraform/projects/app-whitehall-backend", "Ah, I missed that \u2014 I just copied and renamed files from a previous PR that had done the same thing for specialist-publisher."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1285", "comments": ["Needs either enclosing in triple-backticks or indenting by 4 spaces to preserve the ascii art :)", "Worth mentioning also that this traffic is currently going over the Internet between Carrenza and AWS, so this proposal is still much better than what we currently have.", "Hi @sengi - I've fixed up the ASCII formatting \ud83d\udc4d \r\n\r\nCan you confirm whether or not this proposal was implemented? If so, I suggest we go ahead and merge this ADR. If not, let's close it.", "There's gotta be an achievement badge for review necromancy \ud83d\ude00\ud83d\udc7b\r\n\r\nIt doesn't look like this was implemented in the end. I'm seeing two load balancers `govuk-backend-public` and `blue-backend-internal` and they both see significant traffic according to the monitoring tab in AWS.\r\n\r\n![backend prod ALB traffic sparklines 2022-09-30-nq8](https://user-images.githubusercontent.com/1170635/193227584-fbc14f17-38da-4e27-b668-ff9dbcc8b7f0.png)", "Thanks!"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1284", "comments": ["Minor: do we need this? I'm not sure what we want people to read.", "I took the same approach as we did with the AWS command. \ud83e\udd14 I can remove it, though. We've got a bunch of examples here."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1264", "comments": ["Is this just going to change the production database? Or is this going to touch Integration / Staging as well?", "It'll change Production and Staging. Integration is [not quite as big](https://github.com/alphagov/govuk-aws-data/blob/master/data/app-postgresql/integration/common.tfvars#L3).", "And [\"training\"](https://github.com/alphagov/govuk-aws-data/blob/09e99e0b688880e7760f221a92c478096e330a3a/data/app-postgresql/training/common.tfvars)? Is that still a thing?", "The training environment isn't currently running.", "Also, is it worth an extra $13k / month to upgrade Staging's database?\r\n\r\nDo we just keep them the same for parity reasons?\r\n\r\nStaging's not sending millions of emails a day, so it probably doesn't need an 8xlarge instance (note: I haven't looked at the metrics).", "We keep them the same for parity reasons yeah.", "We've pinned staging now: https://github.com/alphagov/govuk-aws-data/pull/700"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1263", "comments": ["Leaving aside the question of the default, I do think we should make the max several times bigger than the current, otherwise we only get the downsides of autoscaling without the benefit.\r\n\r\n```suggestion\r\n  max_allocated_storage      = \"500\"\r\n```"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1259", "comments": ["Can we do this in a single line?"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1253", "comments": ["There's a [size limit to cloud-init userdata](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instancedata-add-user-data.html), so adding many more of these might push you over it. Just something to be aware of.", "Thanks for this Issy \ud83d\udc4d "]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1244", "comments": ["I've got a stylistic/learning question: I've used both `heredoc` and [`aws_iam_policy_document`](https://www.terraform.io/docs/providers/aws/d/iam_policy_document.html) for policies. \r\n\r\nIs there a best practice/accepted approach in the govuk-aws codebase?\r\n", "I found examples of both, so I went for inline because it's easier to see what's going on \u00af\\_(\u30c4)_/\u00af", "Sounds reasonable \ud83d\udc4d "]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1229", "comments": ["Might be worth making these variables now that they're in two places, just so that they can't get out of sync if they're changed in future.", "Additional variables implemented. Thanks Roch"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1228", "comments": ["You can use `Dir.entries` to simplify this.", "I only want to return directories (without \".\" and \"..\") and for that, I use `File.directory?(f)` which must receive the absolute path to work. So it's either that or\r\n```\r\nDir.entries(\"#{Dir.home}/govuk/govuk-aws/terraform/projects\").select {|entry| File.directory? File.join(\"#{Dir.home}/govuk/govuk-aws/terraform/projects\", entry) and !(entry =='.' || entry == '..') }.freeze\r\n```\r\n\ud83d\ude31\r\n\r\nUnless you were suggesting something else? \ud83e\udd14", "Ohhh 'cuz you want directories! Sorry, I misunderstood."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1226", "comments": ["Can we make this `brew install terraform-docs` and add a few lines of description above it? Or link to https://github.com/alphagov/govuk-aws/blob/master/doc/guides/styleguide.md? (Though that in itself is pretty old and needs some work.)", "I thought of writing `brew install terraform-docs` in there but then I preferred to link to the repo instead because there's more info than simply the command to install it (which is still present).", "@issyl0 I added a link to https://github.com/alphagov/govuk-aws/blob/master/doc/guides/styleguide.md too.", "Ah, you just deleted that file! \ud83d\ude05", "Yeah sorry I had second thoughts and thought I'd bin it instead as it was wholly out of date.", "Are you ok with just linking to the repo then?\r\nI'd rather have that than only the command to install it."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1225", "comments": ["I think we can leave the draft stack as 2 as the traffic level isn't very high compared to the live stack.", "I saw `cache` and `draft-cache` were the same so - since it wasn't specified in the card - I changed both.\r\nBut yeah, I'll change it back to 2."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1200", "comments": ["```suggestion\r\n          run:\r\n            user: linuxbrew\r\n```", "Thanks!", "Didn't work. I resorted to some `sed` to include `garden` in the allow list.", "This doesn't currently work. I think I mis-adapted from the Jenkins config.", "Thanks, @barrucadu!", "Should this be indented?", "\ud83d\ude2c ", "We should make sure to change this when Homebrew gets released!", "Good spot. Done!"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1181", "comments": ["Do we need this for the Bouncer logs? \ud83e\udd14"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1179", "comments": ["I'm not too clear on what the desired capacity of an ASG is, and the amazon docs didn't really help.  Does this (+ the rule above) mean:\r\n\r\n- At 9:00am every day, the ASG is scaled to 1 instance\r\n- At 9:55am on Saturday and Sunday, the ASG is scaled to 0 instances", "Yes, that's correct. I'm not sure if this explains it any better: https://www.terraform.io/docs/providers/aws/r/autoscaling_schedule.html#desired_capacity/\r\n\r\nThe reason it's scaled up for 55 minutes at the weekend is so that we can continue to generate our base data, which can then be put together later on without needing to run queries over external sources, such as BigQuery, and incur cost again."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1169", "comments": ["```suggestion\r\n  description = \"Whether replication is Enabled or Disabled\"\r\n```"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1166", "comments": ["```suggestion\r\n  description = \"Whether to enable or disable TLS for the DocumentDB cluster. Must be either 'enabled' or 'disabled'.\"\r\n```", "```suggestion\r\n  description = \"Encryption key for Shared DocumentDB\"\r\n```", "will fix and above too", "Will fix"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1158", "comments": ["I think you should specify in the description that it is in GB", "Good idea, changes made"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1144", "comments": ["```suggestion\r\n   Carrenza) to AWS and use MongoDB should be evaluated for compatibility with\r\n```", "```suggestion\r\n   their DocumentDB cluster. More information is available\r\n```", "```suggestion\r\n   [here](https://docs.aws.amazon.com/documentdb/latest/developerguide/security.managing-users.html).\r\n```"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1096", "comments": ["Should `var.search_api_public_service_names` have a `c` before `names` to make it `cnames`?", "This looks right to me, but I'm wondering how other implementations can use a direct property rather than the first item in an array (eg `data.aws_autoscaling_group.cache.name`)", "It probably should for consistency, but the code using `names` is already in place - changing it would require a corresponding change in govuk-aws-data", "infra-public-services isn't defining the ASG(s), so it has to find them somehow.  This is done in two ways:\r\n\r\nFind an array, which we know is only going to have one element, eg:\r\n\r\n```\r\ndata \"aws_autoscaling_groups\" \"frontend\" {\r\n  filter {\r\n    name   = \"key\"\r\n    values = [\"Name\"]\r\n  }\r\n\r\n  filter {\r\n    name   = \"value\"\r\n    values = [\"blue-frontend\"]\r\n  }\r\n}\r\n```\r\n\r\nFind the one thing, eg:\r\n\r\n```\r\ndata \"aws_autoscaling_group\" \"backend\" {\r\n  name = \"${var.app_stackname}-backend\"\r\n}\r\n```\r\n\r\nI'm not sure why there are two different ways of doing the same thing"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1095", "comments": ["What about setting the password much earlier? so there's a smaller window when the password isn't set? ", "There's a password by default which is the instance id - always a password set \ud83d\udc4d ", "\ud83d\udc4d \ud83d\udd10 "]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1092", "comments": ["It's better to change the data in govuk-aws-data, rather than the default here."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1090", "comments": ["My understanding of the govuk infrastructure is to lockdown integration and staging to us only (this does not preclude allowing other services to access as long as they restrict access upstream to us only. E.g. allow fastly to access staging and integration where appropriate because staging and integration fastly services have their own access control).", "see my comment above", "(edit) This PR isn't changing anything about who can access what. Also, the existing config here is consistent with other backend apps in GOV.UK. We can have a separate discussion about what the access should be, though.", "Yes I know but I think we should change that. It is true that these backend are usually protected by signon etc.", "Ok, but I think it's a separate matter. I strongly think we should do it in a separate PR so as not to confuse matters.", "ok, cool"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1088", "comments": ["Is there supposed to be a description here?", "Some other outputs have descriptions here too.  Worth adding?", "Will do \ud83d\udc4d ", "Thanks Chris, I'll add this \ud83d\udc4d "]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1087", "comments": ["```suggestion\r\n  description = \"Whether we do RabbitMQ federation or not\"\r\n```"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1069", "comments": ["should it still be elb when it has not changed to a alb?", "should it still be elb when it has not changed to a alb?", "should it still be elb when it has not changed to a alb?", "Changes made, also replied on slack."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1061", "comments": ["We already have identical policies, s3_backup_replica_role.tpl for example.\r\nOur policies should be more generic and reusable rather than one project/one policy"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1047", "comments": ["I think these need unique names for each security group.", "and also the `tags { Name = \"` a few lines below?"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/1024", "comments": ["name should be `training_read_integration...` i.e. use `integration` rather than `production`", "same again: name should be training_read_integration... i.e. use integration rather than production", "Changes made :) Can I get another review?\r\n https://github.com/alphagov/govuk-aws/pull/1024/files#diff-4b9ff14de6aafd57c64e1d5f69612ec8R421\r\nhttps://github.com/alphagov/govuk-aws/pull/1024/files#diff-4b9ff14de6aafd57c64e1d5f69612ec8R427\r\n"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/982", "comments": ["The name for this is clashing with the es5 one, so I think it'll need a `custom_suffix` (of `-es6`?) to fix it.", "Specifying the ES version twice in the name is a bit unfortunate, but it's probably better to do it here than to do it in the `elasticsearch6_application_log_exporter.log_group_name` and have the names not match...", "Thanks, fixed", "Remove the commented out bits and this is good to go"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/944", "comments": ["If you update the alias, I think you need to update the line where it's referenced ", "Does this variable exist in the file?", "I believe this change was me just getting a rebase wrong, I've changed the commit to just change the version now. Good spot though!", "Likewise, I believe this change was me just getting a rebase wrong, I've changed the commit to just change the version now. "]}, {"url": "https://github.com/alphagov/govuk-aws/pull/935", "comments": ["Where is var.stackname defined in this case? Is it central for all of training, now?", "Hi Sebastian, \r\n\r\nThe stackname we've been using for training is  \"govuk\". We've been passing this as an argument when running  the \"build-terraform-project.sh\" (https://github.com/alphagov/govuk-aws/blob/master/tools/build-terraform-project.sh). For example:\r\n\r\n   ./tools/build-terraform-project.sh -d ../govuk-aws-data/data -s govuk -e training -p app-mongo -c plan\r\n\r\n", "Sounds good. Also confirmed with @schmie \ud83d\udc4d "]}, {"url": "https://github.com/alphagov/govuk-aws/pull/925", "comments": ["Keep the original record name \"publishing-api-db-admin\"", "var.aws_region, so it works for all the environments"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/924", "comments": ["The name of the record still needs to be \"email-alert-api-db-admin\"", "We want to use var.aws_region so it works for all the environments"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/918", "comments": ["I think this comment is for `monitoring_external_elb`?", "yes, sorry. trying to do too many things at same time."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/899", "comments": ["checked", "checked", "checked", "checked", "checked", "checked", "checked", "checked", "checked", "checked", "checked", "checked", "checked", "checked", "checked", "checked", "checked", "checked", "checked", "checked", "checked", "checked", "checked", "checked", "checked", "checked", "checked", "checked", "checked", "checked", "checked", "checked", "checked", "checked", "checked", "checked", "checked", "checked", "checked", "checked", "checked", "checked", "checked", "checked", "checked\r\n", "checked", "checked", "checked", "checked", "checked", "checked", "checked"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/897", "comments": ["STACKNAME would be \"govuk\" in this new environment, we want to move away from blue/green. Actually we could remove this variable and the bit bellow that uses it, as we'll be removing stack specific datafile from Hieradata", "eu-west-2"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/896", "comments": ["From the week notes, I understood there being one training environment, similar to `integration`, rather than it being a new hybrid Carrenza/AWS environment. So you might just need the `training` context, rather than a `training` and `training-aws` context?", "Ah you are quite right, thanks"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/877", "comments": ["I don't know whether this should just be 60 without the quotes, well we will see in staging."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/873", "comments": ["you could use `grep -oE \"\\b([0-9]{1,3}\\.){3}[0-9]{1,3}\\b\"` which will match IPv4 addresses.\r\nRef: https://unix.stackexchange.com/questions/296596/how-to-check-if-any-ip-address-is-present-in-a-file-using-shell-scripting", "Opted for a full match of IPv4 addresses. It's much better to do a positive instead of inverted match."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/826", "comments": ["we are going to commit into master so remove this?", "is this ok? looks like 22 is usually used for ssh", "why is this name different from the directory name?", "I'm not use about the tag postgresql_primary, maybe prepend the `content-data-api` to it.", "awkward the linting did not detect and fix these: `=` not aligned and empty between parameters", "same comment as before about tags: `\"postgresql_standby\"`", "Yeah, this was only so I could test on Integration. I've removed it now.", "I realise it isn't exactly set out in the Terraform configuration, but as the DB Admin machine is used for administration, SSH is really the only service it provides.\r\n\r\nI'm not certain, but I think you might be able to SSH through the ELB, to the actual DB Admin machine.\r\n\r\nIn reality, this is here because I copied it from the app-warehouse-db-admin project. ", "Good spot :) This is just me not putting the correct name in when copying/pasting.", "Indeed, I'm not sure where that came from. I've changed it to `content_data_api_postgresql_primary` now.", "I'm guessing that the linter perhaps only considers blocks of parameters without newlines between them. I'll remove the newline, and correct the indentation.", "Same as above, I'll remove the newline and correct the indentation.", "cool. So the users of the db_admin machines of content-api will use the load balancer as the entry point to run commands via ssh on those. I guess you have more than 1 db_admin machines for content-api?", "Did you miss this tag update here for : `postgresql_standby` to `content_data_api_postgresql_standby`?", "Ah, yeah, I didn't read your comment here [1] properly, and thought it was about the `source = ` indentation issue. I'll fix this now...\r\n\r\n1: https://github.com/alphagov/govuk-aws/pull/826#discussion_r263439166", "There's just one, and I think that's ok. I think for the other RDS instances, they also only have one DB Admin instance.\r\n\r\nI've made sure with the Content Data API, that this DB Admin instance is only used for administration tasks (e.g. data syncs), so I think it's fine just having the one instance.\r\n\r\nI'm not entirely sure why there's an ELB, that's just copied from the warehouse configuration."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/810", "comments": ["Should that be capitalised?", "Yes, this is the \"default\" config you get through the AWS console\r\n<img width=\"422\" alt=\"screen shot 2019-02-20 at 11 05 14\" src=\"https://user-images.githubusercontent.com/6329861/53087610-7540da00-34ff-11e9-834d-270d874abbfd.png\">\r\n\r\nAlso documented in the Terraform docs: https://www.terraform.io/docs/providers/aws/r/cloudwatch_log_resource_policy.html\r\n"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/807", "comments": ["Is it possible to refer to the `domain_name` directly here, rather than `${var.stackname}-elasticsearch5-domain`?", "Hmm, maybe not, as then there would be a cyclic dependency between the resource for the domain and the resource for the log group..."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/754", "comments": ["This needs **draft_** as well\r\n`${element(var.draft_whitehall_frontend_internal_service_names count.index)}`", "hi this is fine. \r\nwe want draft_whitehall_frontend to point to whitehall_frontend so satisfy Kevin's requirements."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/738", "comments": ["`db-admin` => `gatling`"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/735", "comments": ["This provokes an error in AWS prod: \r\n```\r\nError: Error running plan: 1 error(s) occurred:\r\n\r\n* aws_s3_bucket.assets: \"replication_configuration.0.rules.0.destination.0.bucket\" doesn't look like a valid ARN (\"^arn:[\\\\w-]+:([a-zA-Z0-9\\\\-])+:([a-z]{2}-(gov-)?[a-z]+-\\\\d{1})?:(\\\\d{12})?:(.*)$\"): \"govuk-assets-backup-production\"\r\n```\r\nThe syntax looks correct to me (a bug in the .arn method?!)... I assume using `arn:aws:s3:::${aws_s3_bucket.assets_backup.id}` is a viable work around.", "Interesting - we don't get this error. Just to check: do you have the most recent pull of govuk-aws-data?", "Runs fine for me with last pull"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/720", "comments": ["Does this policy file already exist, or is it generated somewhere?", "My bad, I forgot to copy it across!", "Is `s3:ListBucket` needed here?  Isn't this covered by the section above?", "Should this be capitalised?", "I think so. I've removed it from here but may need to add it back in.", "Nope, copy and paste from someone else's code!"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/718", "comments": ["I think the script should terminate here if this returns a nonzero status code", "I think we should instead explicitly set the needed environment variables (and bail out if not present in the output), rather than just copy cross all `AWS_` outputs.", "Is it worth printing all the parameters and asking the user for confirmation before starting the job?", "I've added a confirmation around the start of the script", "Done", "This now explicitly sets the three AWS related env vars"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/712", "comments": ["the health check path may be incorrect, i.e. `/_healthcheck` -> `/healthcheck`", "I'm not a big fan of using an index in the listener because it assumes than no one has changed the order in the load-balancer list but terraform is hard to do a proper filter.\r\n\r\nMight be better to just add the header block to all listeners, even the http ones? I guess it will require a convoluted way to implement an inner `for` loop?", "I wonder: if a `403 Forbidden` is not more appropriate", "yep, I was thinking the same but the healthcheck endpoint for the backend machines is /_healthcheck.... you can see this on the existing alb targetgroup: tf-20181016132533359600000002  (for production)", "just checked there is only a https listener on this load balancer.", "good catch... that force pushed...\r\n", "I wonder if we should not rename this variable to `load_balancer_ssl_listeners`, easier to get the meaning when using the variable in other modules. I know the `listener` was kept so that terraform does not destroy  and re-create the listeners when ssl and non-ssl listeners were introduced.", "good catch... the name and description has been changed...\r\n"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/709", "comments": ["Please remove office IPs from here. Drafts do potentially contain secret information (eg budget) and have to be accessed authenticated via signon, ie the draft-frontend, only...", "We have taken the office IPs ranges out of this security group, which meant we needed to tie the security group in a count, as for integration this security group will no longer exist.", "^that has been force pushed up", "Changes are in place now."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/706", "comments": ["`used`, not `use` in this context"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/690", "comments": ["an improvement would be to put in the description cell of this row:\r\n\"this variable specifies the CNAME subdomain to be associated with the service names specified in `monitoring_internal_service_names `\"", "I think this may be auto generated by https://github.com/segmentio/terraform-docs\r\n\r\nIt is essence takes a the full variable or resource and prints that in to the markdown file.\r\n\r\n```\r\n./tools/update-docs.sh\r\n```"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/688", "comments": ["The link doesn't work.", "This isn't  required, it's in the repo so it's concerning the repo.", "`redirects`", "will fix this", "will fix ", "will fix"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/680", "comments": ["Is there a missing word between \"theory\" and \"should\"?", "I'm not sure... we have the same line in the warehouse https://github.com/alphagov/govuk-aws/blob/master/terraform/projects/infra-wal-e-warehouse-bucket/writer.tf#L26\r\n\r\nI think there probably is a word missing, but I'm not sure what...", "My guess is\r\n\r\n> In theory referencing the bucket ARN should work but it doesn't so use * instead\r\n\r\nWhat do you think?", "That seems likely", "Do we need to archive wal-e logs off for long term storage?", "It's not something we do at the moment, but I thought it would be worth having for parity with the warehouse WAL-E logs (which do archive them off to long term storage)."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/650", "comments": ["[I can't find this permission on the docs page](https://docs.aws.amazon.com/AmazonS3/latest/dev/using-with-s3-actions.html)? I was wondering because I think to me it would apply to the `bucket` resource not the `bucket/*` resource.", "Ah apparently `ListObjects` was a documentation error that has now been removed!"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/635", "comments": ["Is it worth specifying that these values are in `govuk-aws-data`, given at no point are we specifying a default value per project here?", "I can do, although I assumed that was implicit with the way things were set out, as other variables are lacking defaults.", "Keep it like it is then. \ud83d\udc4d "]}, {"url": "https://github.com/alphagov/govuk-aws/pull/631", "comments": ["This does not end in newline where the others do.. "]}, {"url": "https://github.com/alphagov/govuk-aws/pull/625", "comments": ["Can we put this query in a separate file maybe?", "Can we get Terraform to generate this file?", "We could, but the other lambda functions have zips checked into the repo as well", "\ud83d\ude22", "I'm not familiar with Athena but the resource specifiers in this policy seem very broad. Is there a way to tighten them up?", "https://github.com/alphagov/govuk-terraform-provisioning/pull/46#issuecomment-213586214 - Terraform maintainer :)", "I based it on the [`AmazonAthenaFullAccess` policy](https://docs.aws.amazon.com/athena/latest/ug/access.html#amazonathenafullaccess-managed-policy), which is a generic policy, so that'll be why it's so broad.  I'll try to work out what it actually needs.", "I don't think Athena and Glue do resource specifiers.  There's nothing about ARNs for them here: https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html and I can't find things in their own docs.  But I should be able to restrict the logs resource.", "Although I've just noticed that other policies in this repo use the same log permissions:\r\n```\r\n$ git grep '\"Resource\": \"arn:aws:logs:'\r\nterraform/policies/govuk_artefact_policy.tpl:     \"Resource\": \"arn:aws:logs:*:*:*\"\r\nterraform/policies/lambda_logs_to_firehose_policy.tpl:            \"Resource\": \"arn:aws:logs:*:*:*\"\r\nterraform/policies/lambda_rds_logs_to_s3_policy.tpl:            \"Resource\": \"arn:aws:logs:*:*:*\"\r\nterraform/policies/transition_executor_policy.tpl:      \"Resource\": \"arn:aws:logs:*:*:*\",\r\n```", "@deanwilson Do you still want me to try to restrict the log resources?", "If we do it already then I suppose follow that prior art. It'd be nice to know if there was a reason for it, back in the midsts of time. Maybe it's because they have *all* logs from a service (eg Lambda)? Which I suppose Athena does too. \ud83e\udd14 ", "I *think* the logs here are just for the Lambda function, but because there's no separation between the permissions the actual code of the Lambda needs and the permissions the Athena execution needs it's all a bit blurred together."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/624", "comments": ["The aws_migration tag needs to reflect a new class as well\r\nThe above requires ```aws_migration\", \"email_alert_api_db_admin\"```\r\n"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/620", "comments": ["I commented about this in https://github.com/alphagov/govuk-aws-data/pull/194/files/e76ceae4ebae5f54ac90a2f0941ae087010916d0#diff-918c78288dbda688eddedd845898f9aa", "Bouncer doesn't talk to Email Alert API. This has been left over from Transition. :-)", "Have we upgraded to 9.6 everywhere now? I thought some things were still on 9.3?", "hi @issyl0 , agreed", "thank you , will remove", "`./app-warehouse/main.tf:  engine_version      = \"9.6\"`\r\n`./app-postgresql/main.tf:  engine_version      = \"9.6\"`\r\n`./app-transition-postgresql/main.tf:  engine_version      = \"9.6\"`\r\n\r\nSeems to be 9.6 if I am not missing something. Please feel free to correct me.", "You're right. I was thinking of Carrenza."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/617", "comments": ["Looks like we also need a DeleteObject permission here as per: https://edgeguides.rubyonrails.org/active_storage_overview.html#amazon-s3-service I also imagine there's a pretty good chance we'll do some stuff with ACL to allow temporary access but can adapt this when/if we come to it.", "Should we make this a little more generic as just file uploads rather than image assets? Since it seems very likely it'll also be used for attachments?", "Same point as above re more generic", "Could even call a spade a spade and call it activestorage since we intend for it to be to coupled to that.", "I was thinking we would have multiple buckets, but actually ActiveStorage doesn't seem to support that. So I think you're right that 'content-publisher-activestorage' makes more sense, and we'll just have to hope that if we have multiple kinds of attachment that they're (a) clear and (b) won't conflict.", "This should be \"Version\": \"2012-10-17\", reference: https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_elements_version.html"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/609", "comments": ["Is it worth naming this something like `datascrubber_policy_attachment` rather than a generic `iam_role_policy_attachment`?", "I guess, I just followed the general trend, we call most (all?) our policies like that", "OK then."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/608", "comments": ["I guess this is one of the things that needs a `govuk-aws-data` PR?", "Yes I have made one of these now:\r\n\r\nhttps://github.com/alphagov/govuk-aws-data/pull/189\r\n\r\nBut I wonder if I should add these for Integration and Production before we merge this PR..?", "Yes please, otherwise we'll be blocked on deploying these changes to those environments because `var.carrenza_vpn_endpoint_ip` won't exist. Do we need a VPN in integration though?", "Ok I'll do that. We can create the config for Integration even if we don't end up connecting it to anything."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/604", "comments": ["It opens the Terraform deployment Jenkins job in your browser, prefilled with your AWS credentials.", "The `environment` dropdown doesn't get pre-populated with the environment in my testing, if `govukcli get-context` = `staging-aws` as per the example list of contexts that's in the help text of `govukcli set-context`.", "I also get\r\n\r\n```\r\n$ govukcli terraform-jenkins\r\nawk: invalid -v option\r\n```\r\n\r\non the first run before it prompts me for an MFA code, although I don't know if that's me not having `govukcli` set up correctly in the first place.", "Bah, I have gawk installed. I'll have to test with BSD awk."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/599", "comments": ["Further up in this guide, we set the `ENVIRONMENT`, `DATA_DIR` and `STACKNAME` environment variables to avoid re-specifying everything every time - and to avoid copy/pasting commands running against the wrong environment (eg, you've specified `production` here).\r\n\r\nCould we use the same pattern, eg just have `tools/build-terraform-project.sh -p app-puppetmaster -c plan` as in other occurrences, instead of all of the options?"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/593", "comments": ["I think this policy also needs attaching to the user", "@boffbowsh I took this setup from a terraform example I found here: https://github.com/cloudspinners/terraform-aws-codecommit-repository/blob/master/committer_group.tf I'm not sure the `govuk_code_commit_user` policy is necessary if we're already attaching the managed policy `policy/AWSCodeCommitPowerUser` ...? ", "Yeah I think you're right, you can delete this block if you're using the managed policy.", "@boffbowsh updated https://github.com/alphagov/govuk-aws/pull/593/commits/ec3124866367caf8252a5ce05f23924ee3df4764"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/590", "comments": ["Revert this fragment once https://github.com/alphagov/govuk-puppet/pull/7731 is merged", "We agreed to rename the parameters to remove the string `staging`, this means that the script will just use the same name in each environment but the key material will differ (given that they run in different AWS accounts)."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/581", "comments": ["Lately we have used govuk-${var.aws_environment}-bucket-name as naming convention", "+1", "+1\r\n"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/576", "comments": ["Shall we say \"CKAN\" as it is an acronym \"Comprehensive Knowledge Archive Network\"?!", "Do these descriptions need trailing whitespace?", "It's lowercase as it's the name of the ELB, which is lowercase.", "This is a description though?", "Yes but it's explicitly a description of which ELB it's pointing to, not what the ELB is used for. \r\n", "Fair enough \ud83d\udc4d ", "Fixed"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/566", "comments": ["This just increases the size for the volume attached to `mongo-1`, but there are three instances (further down in this file, lines 189 and 231). Is the dump pinned to just one of the instances, or could it be any of them (given instances in AWS are dynamic)?", "Good spot - I was too happy after finding the place to change it ;-)"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/561", "comments": ["Typo: `puppeddb` => `puppetdb`.", "I love the word `myriad`. It might be worth mentioning that the other errors are mostly expected due to old versions of things?", "thank you done\r\n", "agreed, done"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/532", "comments": ["Typo: \"t\" => \"to\".", "Typo: \"aa\" => \"an\".", "Maybe \"is\" rather than \"gets\"?", "Typo: \"build\" => \"built\".", "Maybe \"copies objects\" rather than \"is capable of copying objects\"?", "Typo: \"a **ObjectCreate** event\" => \"an **ObjectCreate** event\".", "corrected", "corrected", "corrected", "corrected", "corrected", "corrected"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/522", "comments": ["This needs to be the same as lines 102-113, but with the `source_security_group_id` pointing at the security group for `db_admin`", "Updated"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/517", "comments": [":100: "]}, {"url": "https://github.com/alphagov/govuk-aws/pull/509", "comments": ["As noted this was an incorrect change."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/502", "comments": ["I wonder if it's worth considering `io1` type as we're mounting a database off it? Additional cost, but better performance.", "We have prior art for this in [app-graphite](https://github.com/alphagov/govuk-aws/blob/master/terraform/projects/app-graphite/main.tf#L209)."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/500", "comments": ["Should this literal (`integration`) be there?"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/499", "comments": ["does this also need a `type`?", "Please remove these and add them as variables. This is a public repository.", "Unless there is a good reason for this to be inline, we should stick with convention and use `template_file`.", "Unless there is a good reason for this to be inline, we should stick with convention and use `template_file`.", "create_sns_topic - This is a boolean. I have set a default value as false.  I believe this would suffice. https://www.terraform.io/docs/configuration/variables.html", "Good point. Done.", "In Terraform there is no real Boolean type (they are converted to strings of either `0` or `1`). I think you're correct that it does work, but to have consistent code we should consider specifying the type for each variable.", "agreed, done.", "agreed, done.", "you are correct. I didn't read that attentively and used as boolean.  I have now set the variable type to string."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/494", "comments": ["Do we know what instances need access to email-alert-api? It would be good not to open up everything up if we can decide at this stage what needs access.", "The ones I can think of are `backend` and `publishing-api` at the moment...", "Also `frontend`, and of course we have the publicly-accessible API endpoint too. Does that mean we have to allow all access?", "If we can open up the internal load balancer to specific instances that would be useful, and then we have the external facing load balancer for the API endpoint. "]}, {"url": "https://github.com/alphagov/govuk-aws/pull/483", "comments": ["This `variable` block will need to live inside of each project rather than the module itself, so at the top of `terraform/projects/app-backend/main.tf`, for example. No logic inside the module is using this variable.", "This doesn't need to be here. The module only accepts the three variables below ([ref](https://github.com/alphagov/govuk-aws/blob/master/terraform/modules/aws/node_group/README.md)), but we can still just pass in the same value as defined in the `asg_size` variable.", "Sorry just noticed, we probably want the default to be `2` here as we do not override this variable for Integration."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/478", "comments": ["I think you made a typo. This should be:\r\n\r\n```\r\ncurl url | sudo bash\r\n```"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/477", "comments": ["I think this role is already created in `infra-security`, so this may not work and we'll have to do some data shuffles. I'll wait for you to come up and we can pair on it.", "Already managed here: https://github.com/alphagov/govuk-aws/blob/master/terraform/projects/infra-security/main.tf#L94", "It doesn't need to be a template, nothing to interpolate. You can do file() in the aws_iam_policy below", "Actually ... You want to interpolate the environment in the name. If we don't want to grant this group access to the backups on all the environments, we need more logic", "Probably better keep infra-security standalone, we can use this to avoid remote state file: https://www.terraform.io/docs/providers/aws/d/iam_role.html", "Moved this to infra-security to avoid dependancy and make use of existing role object", "as discussed", "done"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/456", "comments": ["This comment probably doesn't need to be here? `office_ips` is defined in https://github.com/alphagov/govuk-aws-data/blob/5716300dfe66dcada0efdcd344bbae5ca9cda4c1/data/common/integration/common.tfvars#L11-L18 so should never be blank?", "Yep, you're right."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/451", "comments": ["Can we put this rule next to \r\n\r\n```\r\nresource \"aws_security_group_rule\" \"graphite-internal-elb_ingress_monitoring_https\" {\r\n```\r\n\r\nIt think it's easier to read if they are group by the source"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/446", "comments": ["Is it worth mentioning about the [docs tool](https://github.com/alphagov/govuk-aws/blob/master/tools/update-docs.sh)? I always forget it exists.", "Done in 5cb5fd6.", "The filename is actually `styleguide.md` (singular)."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/436", "comments": ["the internal and external zones are created only when 'create_*_zone' is set to true, so there could be a case when the resource is not created and the output would error. Same as the rds_module, I think it's better to do something like this in the outputs\r\n\r\n```\r\n  value = \"${join(\"\", aws_route53_zone.internal_zone.*.zone_id)}\"\r\n```\r\n\r\n", "Should I do this for every change here?", "@afda16 Fixed, I hope! Thanks."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/432", "comments": ["I think from_port is 443 (in the monitoring-internal-elb resource the lb listerner port is 443)", "I'll change it now.", "Name of the rule is the other way around: whitehall-frontend-elb_ingress_management_https"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/419", "comments": ["Not that its really a problem, but this will create a new backup file for every iteration of the loop, that gets overwritten except the last iteration, which will leave a file containing all the hosts except the last one - think you could change it to `sed -i ''` to avoid this", "That's a good point.", "A file like your normal hosts file with one additional host in it"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/391", "comments": ["What's the extra `/./` for the in the command execution?"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/383", "comments": ["What is \"service\" in this case?", "It's OK, the example answered my question: \"NRPE\", etc (eg for Icinga)."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/369", "comments": ["I found this a little confusing to read, but I think I understand what's going on:\r\n\r\n```\r\nlistener_target_groups {\r\n  \"apt-http-80\" => \"apt-http-80\",\r\n  \"apt-https-443\" => \"apt-http-80\"\r\n}\r\n```\r\n\r\nI wonder if it would make it more readable by naming what the resource is? Something like:\r\n\r\n`apt-http-80-listener`\r\n`apt-http-80-target`", "yes that sounds good, I'll update", "Why is this outside the `locals` block above?", "No specific reason, just keep the block next to the place where it's used so it's easy to understand what it's doing. That's what it looked to me", "This should be `name` singular. "]}, {"url": "https://github.com/alphagov/govuk-aws/pull/368", "comments": ["Should this be a variable? Is there any case where we might want to enable this? ", "From the docs: \"The type of routing action. The only valid value is forward.\"\r\n\r\nIt really upsets me this has to be specified. ", "I feel like this is something that we may wish to change later on, so may be worth having a variable with a sensible default.", "I think most elements of the health check we would probably want to change depending on the type of application. I personally would set interval to a lower threshold for applications, so it may help in the long run to set variables with sensible defaults.", "enable_deletion_protection is false by default, setting it to true prevents TF from removing the LB so probably we don't want to do that. I could remove it from the code", "updated", "updated", "If it's false by default I think we should remove to avoid confusion. ", "updated"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/366", "comments": ["I think this needs to be `443` as well."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/357", "comments": ["I updated the docs for the network modules in https://github.com/alphagov/govuk-aws/pull/358 , I didn't realise this change.\r\n\r\nSome modules need to include a blank line before the first `output` resource to avoid that \"Outputs -------------------------------------------------------------- \" description, that is getting from the comment right before `output`. The VPC module was also missing output descriptions.\r\n\r\nWe could update this PR or remove the network modules from here and use my changes instead."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/356", "comments": ["It would be good to enable the replicaLag alarm, same as https://github.com/alphagov/govuk-aws/blob/master/terraform/projects/app-postgresql/main.tf#L110"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/352", "comments": ["Why do we specify the `lambda_filename` here rather than specifying in the module itself? Is there a case of using a different lambda function for different uses of RDS?", "I was looking at this and wondered the same thing", "I think the module should be generic, no knowledge about local paths. In this case the lambda function is always going to be the same, it's similar to the way in which it's done in cloudwath_log_exporter.\r\n\r\nI agree it's not nice, If instead of a filename we were using S3 then we could make it nicer.", "Similarly for the role - I guess this might be to do with passing data between modules?", "Yes, the role resources are managed in infra-aws-logging and reused in the module. Other option would be to create the role/policies inside the module itself, we would have a role/policy for each lambda function created, instead of reapplying the same one", "Agreed the module shouldn't know about local file paths outside of the module - I wonder but dont feel strongly if the lambda file should be encapsulated within the module, rather than being in a shared area for lambda files", "Yes I see, better to have one role rather than one per lambda created I think", "I guess it depends what the use of making it generic is. If we want to allow other people to use it to quickly ship RDS logs, then shipping the lambda function along with the module makes a certain amount of sense, but if we're using modules more like frameworks than all-purpose pieces of code, then keeping it separate makes sense (and could almost argue to have an even more generic function).\r\n\r\nEither way, I do not feel that strongly about it, so happy to approve. I think it may be worth writing a styleguide for the way that we write and use our modules.", "We can have a wider discussion about how we want to manage lambda, maybe? I don't like the filename parameter but would like to have a common approach for Lambda", "Sure, seems like a good idea. I have approved, anyway!"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/349", "comments": ["It looks a little bit like a hack, to use other remote_state variable to refer to the backups stack. It breaks the way we've been doing remote states", "I think this was a mistake rather than intentional, and I pinched it from where it had been set previously. I will update all of them.", "Oh, maybe it was intentional because that variable isn't set. Interesting.", "`element` needs 2 arguments, it's missing `count.index`\r\n\r\nhttps://www.terraform.io/docs/configuration/interpolation.html#element-list-index-", "Thanks, updated!", "I didn't realise this before ... `remote_state_infra_artefact_bucket_stack ` and `remote_state_infra_database_backups_bucket_stack`\r\n\r\nI personally would call everything `_key_stack` because it refers to the bucket key, same as the rest of remote state variables. We could change it later", "I'll update it now as pushing this stuff down the line is just going to get worse and won't take me a moment. Good spot."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/348", "comments": ["https://www.terraform.io/docs/configuration/variables.html#booleans\r\n\r\nHave you tried passing the variable with `-var` ? Maybe we should just use \"0\" and \"1\"", "Now I know why the values appear as `0` or `1` when I look for the tags!"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/344", "comments": ["I wonder if its worth sending to Glacier - from [the docs](http://docs.aws.amazon.com/AmazonS3/latest/dev/lifecycle-transition-general-considerations.html)\r\n\r\n> Number of days you plan to keep objects archived \u2013 Amazon Glacier is a long-term archival solution. Deleting data that is archived to Amazon Glacier is free if the objects you delete are archived for three months or longer. If you delete or overwrite an object within three months of archiving it, Amazon S3 charges a prorated early deletion fee."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/340", "comments": ["Will the prefix add \"-\" before the random part? If not maybe could could use var.name-"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/327", "comments": ["Remove default from docs as it's given in the code.", "\"from any other state\" isn't needed"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/321", "comments": ["does this work when the module is applied on the master? I remember having to add the conditional because otherwise the resource does not exist and the output value can't be evaluated", "I ran it against a module that doesn't use a replica, and it didn't change anything related to DNS records or the outputs. \r\n\r\nI think the resource will always exist, albeit with a `count` of `0` which means that nothing is outputted. I did not receive any errors with an empty output."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/303", "comments": ["Log message still says volume"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/291", "comments": ["Can we make the default medium? ", "of course"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/289", "comments": ["I think content-store itself is fine to be available externally, but AFAIK draft-content-store should not be available to the public, so should be limited (perhaps to office IPs only?)"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/278", "comments": ["Actually, don't think you need to have the `.` on the end.", "I didn't know that. Should I change all other occurrences of `:.` in these docs to just `:` then?", "Nah, both are fine. "]}, {"url": "https://github.com/alphagov/govuk-aws/pull/271", "comments": ["The `aws_migration` value should be `transition_db_admin` to match the Puppet node class.", "I think this should be `transition-db-admin` as we never use underscores in host names", "I would have been surprised if I hadn't missed one. \ud83d\udc4d "]}, {"url": "https://github.com/alphagov/govuk-aws/pull/269", "comments": ["I think this needs to be associated with the public subnets, not the private ones."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/263", "comments": ["Should `\"aws_route53_record\" \"assets_service_record\"` also be an output or is that DNS record unneeded?", "It should probably be an output, but I don't think it's required by anything.", "@deanwilson updated."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/262", "comments": ["Is router-backend connecting directly with the cache instances?", "... Got it"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/260", "comments": ["Is there a reason for providing a default variable with a default value and an override variable?", "It is just to help controlling a final default value that is going to be set independently of how the override parameter is used. Because we always want to pass a override value to avoid issues with patch versions, we can expect the projects to always set a default one (in which case we can leave node_group unmodified), or we can no trust the projects and make sure we always apply a non-empty default value in node_group with the two parameters and coalesce function. Either option I think is fine, it just depends on how flexible and simple we want to be and how much we want to trust things", "I think the simpler option is probably the one we want to take "]}, {"url": "https://github.com/alphagov/govuk-aws/pull/259", "comments": ["Are there any known limitations on the AWS version of Elasticache? E.g. config options we have less control over, lack of an actual super user (such as having to use `rds_superuser` for RDS which isn't an actual superuser).", "I'll defer to @deanwilson and @afda16 who set this up. I don't have enough experience with Elasticache.", "Yes,  there are some options we can't use under Elasticache. Mostly these are things we wouldn't want in an AWS environment but if we hit any that are actual issues for us we can amend the ADR and move back to a server/container.", "Thought so, might be worth making a note of this in the ADR? (sorry @surminus)", "This has been updated."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/258", "comments": ["This looks OK for a general guide, but if someone joins the team, that person won't be able to understand from this guide which certificates are following this. I still think we should document somewhere (maybe in a private space) our specific cases.  For instance, in which account a domain has been configured, which email address it's using, for how long we are creating certificates, etc", "certiicate=\"certificate\"", "I agree that we need to store this information somewhere; that might be a suitable use of our wiki page or the ops manual. I'm not sure it's appropriate to have that info in the repo. \r\n\r\nThis was mostly a braindump to help me remember what we did; we should automate it in the future."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/257", "comments": ["Out of interest, what's the thing on calculators-frontend that needs mongo?", "licencefinder apparently"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/241", "comments": ["Can this use a [policy doc data resource](https://www.terraform.io/docs/providers/aws/d/iam_policy_document.html) so there's some amount of verification before it hits AWS?"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/238", "comments": ["I thought this was now accepted?", "We should update what we decided"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/228", "comments": ["Can we add a sentence or two about why we want data separate from code and how creds being public is \"bad, M'kay\" please? The context is a little thin atm."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/222", "comments": ["you could probably just use 31.210.245.96/28  "]}, {"url": "https://github.com/alphagov/govuk-aws/pull/220", "comments": ["missing a comma ", "The last entry in the existing data files does not have a comma. So it's either not allowed or I'm being consistent. Pick an excuse ;)", "That's not the last entry though"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/217", "comments": ["this value should be _external_elb", "what's sg_whitehall-backend_external_elb_id? do we need it?", "backend_external_elb"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/203", "comments": ["ARN?"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/184", "comments": ["are these required if they're in common?"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/182", "comments": ["Would it be worth clearing out any 'terraform.tfstate.backup' files as well?", "Good point"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/169", "comments": ["If it's external, it should use external_zone_id and external_domain_name"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/168", "comments": ["PostgreSQl should be PostgreSQL", "\"The application configuration will need to be updated to connect to the correct database.\"\r\n", "Can we bump this to a db.m4.large please? 8GB would be better in integration.\r\n"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/167", "comments": ["We should purge any previous terraform config, so:\r\n```\r\nrm -rf ${dir}/.terraform\r\nrm -f ${dir}/terraform.tfstate.backup\r\n```", "Also, does an init require exporting of credentials?\r\n\r\nIf so, then this may break Jenkins tests.", "As discussed, I removed the pre-commit hook trigger from the Jenkinsfile because of the above (context in commit message)."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/163", "comments": ["Update the key to delana"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/156", "comments": ["we should only ever have one of these", "need to change this to the same port range that we are allowing from the security groups: 6514-6516\r\n", "It needs to be the same hostname that we set in the instance tag", "this and the outputs need to be put at the headers at the top of this file"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/145", "comments": ["Can we turn this in to a heredoc please? It's quite dense now.", "We now build this project as the \"govuk\" stack rather than a specific stack. This is so resources are shared to enable blue/green style deployments. Certainly worth mentioning."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/143", "comments": ["This is now a default policy, sorry!", "This is incorrectly described (probably in logs-elasticsearch, too)", "Removed!", "I think we need to go through everything - there must be so much that's mistakenly copy/pasted.", "As an example: https://github.com/alphagov/govuk-aws/blob/d9db0d750bf194b8f2be2f3864889ab40eb41494/terraform/projects/app-elasticsearch/main.tf#L3, and that's also in `logs-elasticsearch` 'cause I copied that directory."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/124", "comments": ["this should just be the puppet class and with a hyphen (copying previous apps), so \"exception-handler\"."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/119", "comments": ["Adding an erroneous line"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/116", "comments": ["Can you add an example to explain \"overlapping domain names\", please?", "Also I think the second part may be clearer as \"so there will only be one internal DNS zone per VPC, which is shared between stacks\""]}, {"url": "https://github.com/alphagov/govuk-aws/pull/92", "comments": ["As discussed I'll clear these bringing up the issam stack"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/88", "comments": ["You need to `init` the first time you run a terraform project", "We changed the bucket name during the refactoring to \r\n```terraform/projects/<project name>/<environment>.<stack name>.backend```", "At the moment we are not managing the root domain entries, so far the user has to navigate to \r\n\r\n```\r\ndeploy.<stackname>.<aws_environment>.govuk.digital\r\n```", "I think this is a little bit confusing, isn't this the \"project\"? We use stack to name the project implementation", "We use aws_environment in the rest of the code to represent what your \"Account\"\r\n\r\nI think the terms in this document should refer to the same things that we have in the rest of the repository"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/82", "comments": ["I think hiera_config needs to point to hiera_aws.yml", "Good catch", "I think this needs to be `hieradata_aws` too"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/80", "comments": ["This breaks the vhost because it doesn't match: (ref: https://github.com/alphagov/govuk-puppet/blob/master/modules/icinga/templates/nginx.conf.erb#L2)\r\n\r\nIf we set this to \"alert\" singular we would be able to correctly browse to it without worrying about the graphite vhost.", "Fixed"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/79", "comments": ["Description is incorrect"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/77", "comments": ["Do we need this? `aws_region` is used nearly everywhere else", "Backends are configured before evaluating variables, it needs explicit configuration"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/76", "comments": ["It's inside a loop, so it'll be added for each TAG"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/75", "comments": ["I personally wouldn't make the files presence mandatory, it's not probable but maybe a project doesn't require tfvars. Apart, is  $PROJECT_DIR/$STACK_COMMON_DATA the right path?", "Didn't the script check if there were tfvars before?", "I think one of them has to exist if only to make sure that the stackname is defined somewhere.\r\n\r\nI've added a comment explaining the odd path, it's because all the commands are executed from inside the terraform project directory but at this point it's not yet been `cd`d to.", "yes, I'll get rid of this."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/71", "comments": ["This sentence reads a little strange. ", "Can we list some examples to make this clearer when we need to propagate changes using LC rather than Puppet?"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/70", "comments": ["Is it possible to add this logic to the node group module?", "Should the `instance_user_data_file` variable be removed and the same minimal header always used?", "'SThe' -> 'The'.\r\n\r\nIf they're passed by a list shouldn't they be concatenated correctly anyway?\r\nAlso what happens if, later, we want to add a script second in some cases?\r\nIs there a way to template these files (e.g. change LVM attachment point)?", "To make the module more generic, I still think there should be a variable to override the default one. We are currently only implementing a bash user_data, someone else may want a different language", "this should be very lightweight logic, and would keep the module more generic", "Fair enough. Am I right in assuming that only the instance_user_data_file will be templated?", "They should be concatenated correctly, but we haven't tested this yet. Keeping the logic in the app-* project would enable us to use templates or whatever we need. Using tags to discover volumes would enable the script to attach any available volume for the instance, not sure this would be a good example for a template. In my experience, if we have Puppet configuring the boxes afterwards, there would be very few cases where we would need a template.", "concatenated rather than concatenate", "wen need to check the node_group module and see if it makes sense to template there or not. We could move the responsibility of templating/interpolating values to the code that calls the node_group module, so node_group remains generic", "fixed\r\n", "fixed 'SThe' -> 'The'"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/68", "comments": ["We can't use curly brackets as that because Terraform thinks we are interpolating a variable.\r\n\r\nMaybe we should change the node_group module to stop managing the additional_user_data as\r\npart of a template, as this behaviour is not clear when people are updating additional user_data scripts ...", "I'm happy to remove the brackets, but will close this if we want to move the management of this elsewhere entirely."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/66", "comments": ["With this order, will  common_project_data_file variables override stack_data_file variables?"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/59", "comments": ["This description is in-accurate", "The changes for mirrorer need to be moved into `infra-security-groups`"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/16", "comments": ["You can explicitly state the version now use the `required_version` parameter. We could set that later: https://www.terraform.io/docs/configuration/terraform.html", "I'm going to be picky and ask to update the headers so we have a consistent layout", "is this correct (the double `$`)?", "yep"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/15", "comments": ["\"There are two methods of defining security groups for AWS in Terraform and they are distinguished by how you add rules: in-line and separate.\"", "This should be 8140.", "Also, this says that the Puppet clients will always be connecting *from* port 8140 which I don't think is the case. I don't think you need to specify the from_port", "Ah scrap that. It's a range. Boo.", "Unfortunately you have to specify both, yeah", "Now I read it back I wonder if we should be more explicit with resource names. I suspect there will be instances where instances will be need to communicate with each other via SSH, so it may be good to be explicit for the resource names to avoid ambiguity. ", "This is a description for a specific rule, not the group itself.", "\"It's\""]}, {"url": "https://github.com/alphagov/govuk-aws/pull/12", "comments": ["The backup and restore solutions will remain the same, tested, processes."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/11", "comments": ["Especially rather than specially.", "\ud83d\udc4d ", "Should this link to the ADR on Terraform modules? https://github.com/alphagov/govuk-aws/pull/8", "Implies not implicates"]}, {"url": "https://github.com/alphagov/govuk-aws/pull/9", "comments": ["\"involve manual intervention\" - remove the a."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/7", "comments": ["Too many 'a's", "Can you reword this insight please."]}, {"url": "https://github.com/alphagov/govuk-aws/pull/6", "comments": ["This doesn't format as intended when the page is viewed."]}]}, {"url": "https://github.com/vmware-archive/terraforming-aws.git", "pull_requests": [{"url": "https://github.com/vmware-archive/terraforming-aws/pull/118", "comments": ["Looks like this is throwing an error: \r\n```\r\nError: Error refreshing state: 2 error(s) occurred:                                                                                                                                     \u2502 23\r\n                                                                                                                                                                                        \u2502 24 [[constraint]]\r\n* module.pas.aws_security_group.tcp_lb: cannot parse \"false\" as an integer                                                                                                              \u2502 25   name = \"github.com/onsi/ginkgo\"\r\n* module.pas.aws_lb.tcp: cannot parse \"false\" as an integer\r\n```", "Looks like this is throwing an error:\r\n\r\n```\r\nError: Error refreshing state: 2 error(s) occurred:                                                                                                                                     \u2502 23\r\n                                                                                                                                                                                        \u2502 24 [[constraint]]\r\n* module.pas.aws_security_group.tcp_lb: cannot parse \"false\" as an integer                                                                                                              \u2502 25   name = \"github.com/onsi/ginkgo\"\r\n* module.pas.aws_lb.tcp: cannot parse \"false\" as an integer\r\n```"]}, {"url": "https://github.com/vmware-archive/terraforming-aws/pull/99", "comments": ["This seems like it's unintentional in this PR, are you hard-coded the role to a pre-existing out-of-band created policy?", "throw this PR out: we were merging to our own forked \"master\" and must have pushed the \"create PR\" button on the upstream instead. Sorry about that.", "closing the PR!"]}, {"url": "https://github.com/vmware-archive/terraforming-aws/pull/12", "comments": ["There are many versions of Ops Manager and the user should provide the version that want so lets keep the `ops_manager_ami` required.", "Please add your description the existing line. There is also a typo in your spelling of \"Pivotal Network\" (it currently says \"Povital Network\").", "The bosh director listens on port `25555`. This change is opening port `8443` on the security group applied to the Ops Manager VM. Can you explain why this is needed?", "We cannot assume that users deploying RDS want a logical DB named \"bosh\". Please remove.\r\n\r\nWe have upcoming work that will allow users to opt-in to creating DBs like bosh or ones that are need for products like the ERT (cloud controller db, uaa db, etc).", "It's about connectivity to BOSH Director's UAA which listens on port 8443 as what I explained in the conversation.\r\nFor example:\r\n`$ uaac target --ca-cert /var/tempest/workspaces/default/root_ca_certificate https://10.0.0.10:8443`\r\n", "Okay, will remove it accordingly"]}]}, {"url": "https://github.com/joshuaspence/infrastructure.git", "pull_requests": []}, {"url": "https://github.com/openinfrastructure/terraform-google-gitlab-runner.git", "pull_requests": []}, {"url": "https://github.com/codeopensrc/workbench.git", "pull_requests": []}, {"url": "https://github.com/ashlineldridge/k1s.git", "pull_requests": []}, {"url": "https://github.com/zoitech/terraform-aws-saml.git", "pull_requests": []}, {"url": "https://github.com/koshkin-ccna/afac.git", "pull_requests": []}, {"url": "https://github.com/clingen-data-model/architecture.git", "pull_requests": [{"url": "https://github.com/clingen-data-model/architecture/pull/599", "comments": ["\"external-secrets controller\"?", "bad copy paste"]}, {"url": "https://github.com/clingen-data-model/architecture/pull/494", "comments": ["If we're not sure yet what the limits should be, then it's probably fine to leave them out for now. However, it's probably a good idea to set limits here if we know what they should be set to.", "One thing I might set on this storage class is `allowVolumeExpansion: true` ; the gce-pd provisioner supports growing volumes online if that's set. In a case where we need more disk space in a pinch, you can increase the `spec.resources.requests.storage` attribute on the PVC and it'll resize the volume. Might be worth configuring the genegraph PV with the same setting if you think that running out of disk space will be a possibility at any point.\r\n\r\nhttps://kubernetes.io/docs/concepts/storage/storage-classes/#allow-volume-expansion", "Thanks, that could be nice to have, I'll add that.\r\n\r\nIs it necessary to change the `apiVersion` of this? That doc says it needs `v1.11`", "Nope, the storageclass API should stay V1 -- the v1.11 note in the docs is talking about the kubernetes cluster version."]}, {"url": "https://github.com/clingen-data-model/architecture/pull/460", "comments": ["vscode recently started auto-formatting YAML files on save... this is from that, and is not a functional change."]}, {"url": "https://github.com/clingen-data-model/architecture/pull/457", "comments": ["Just a note here, I think the default reclaim policy is 'Delete'. The data here will be persistent across pod restarts, but the underlying volume gets deleted if you delete the Claim, as would be the case if you deleted the entire deployment (either via a helm uninstall or an argo cascading delete).\r\n\r\nIf you actually want to retain the data volume after you totally delete the deployment, you'll want to set the reclaim policy to Retain -- otherwise this is fine as-is, and the volume will stick around as long as the claim object exists.", "Is this script, and the others like it, one that's only intended to be run locally? Or is it something that'll need to be run automatically at any point?", "I will leave it as-is for now. I think if the whole deployment is deleted, the assumption can be that any re-deployment is intended to start from scratch.", "These `pre-deploy` scripts are intended to be run locally before running a helm install, in order to configure the confluent topic and group offset."]}, {"url": "https://github.com/clingen-data-model/architecture/pull/410", "comments": ["@sjahl I'm sure you meant to add this, but I wasn't clear on why this change had any impact on the mondo function. Is this because it was a missing artifact that you wanted to add as an after thought?", "oh, this was me forgetting to update the name of the resource after copy/pasting from elsewhere, will fix."]}, {"url": "https://github.com/clingen-data-model/architecture/pull/388", "comments": ["Where is this `gcp-creds.json` coming from?", "The service account key itself is generated via terraform at https://github.com/clingen-data-model/architecture/blob/master/terraform/dev/main.tf#L8-L12\r\n\r\nCreating the actual k8s secret is unfortunately manual, since it has to be \"Secret Zero\" for getting the syncing started. That's documented here, but I'll drop a readme in a place that makes more sense once the old external-secrets thing is gone: https://github.com/clingen-data-model/architecture/tree/master/helm/values/external-secrets#create-a-namespace-and-secret\r\n\r\nLonger term, we'll want to use workload identity: https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity, which will remove the need for a key. Instead, we would just specify which service account a pod/deployment should be associated with, and GKE handles the authn/z that way."]}, {"url": "https://github.com/clingen-data-model/architecture/pull/146", "comments": ["for production, this needs to be `server: https://kubernetes.default.svc`\r\n\r\ncluster URLs can be found in: https://argocd.prod.clingen.app/settings/clusters", "for staging, this needs to be `server: https://35.185.65.146`\r\n\r\ncluster URLs can be found in: https://argocd.prod.clingen.app/settings/clusters", "I think we can go ahead tracking `HEAD` and using a manual sync policy for now (particularly since we're deploying staging first with this PR).\r\n\r\nGoing forward, we might want to think about using a specific commit SHA or git tag here. I think doing this would reduce the chance of accidentally releasing prod if someone clicks the prod sync button when there's changes that aren't ready to ship yet. There's a bit of a chicken-and-egg problem here since the targetRevision in this file is referencing a git commit of the architecture repo that it lives in. Git tags might make this a little less awkward, but we should think about the best way to keep the commit SHA in sync.", "Fixed", "Fixed", "Good to know. Once we get things pushed out we can revisit as we gain experience."]}, {"url": "https://github.com/clingen-data-model/architecture/pull/138", "comments": ["Not critical, feel free to merge if you've left it off intentionally: you may want `set -u` here since you're dynamically setting `cluster_id`. This will cause any variables that end up undefined as errors, in the case that something goes wrong while listing kafka clusters.\r\n\r\nWe're in posix `#!/bin/sh` here, so `set -o pipefail` isn't available as far as I know, but if we were in bash, i might set that one too in this case.", "same `set -u` suggestion here as in the combined pre-deploy.sh", "depending on your style preference, I think another way to do this instead of toggling `-e` would be to just `|| true` at the end of the `ccloud` command."]}, {"url": "https://github.com/clingen-data-model/architecture/pull/133", "comments": ["I think this may be problematic -- `genegraph_configure_ingress` is set to `true` in the default values.yaml file, so the Ingress will get provisioned in this case. But, that will fail if we don't generate a tls cert, since the ingress requires a certificate.\r\n\r\nI think the solution here is one of:\r\n\r\n- If you want a https endpoint with a cert that can be accessed via genegraph-dev.clingen.app, then `genegraph_tls_cert` needs to be true\r\n- If you don't want an https endpoint, then `genegraph_configure_ingress` should be set to false here\r\n- Since the https managedcertificate and the Ingress are coupled, maybe the same boolean should be used to determine if both the ingress and managedcertificate should be provisioned\r\n\r\nI think the right long term solution might be to detangle the managedcertificate and ingress and put them behind the same boolean. But, I'm interested in your thoughts on whether that feels cleaner.", "Another thing that just came to mind when thinking about Ingress configuration: I think in the case where we have an Ingress, the service type should be NodePort. I don't think a LoadBalancer service type is compatible when an ingress is sitting in front (technically speaking, both a LoadBalancer and an Ingress are a Google Cloud Load Balancer and having both of them doesn't make much sense). In the case where we want an externally accessible genegraph with no TLS cert (i.e. the way the current staging genegraph is configured), that's when the LoadBalancer service type is appropriate.", "@toneillbroad I think I see the issue here; it's a difference between configuring an Ingress and a LoadBalancer. Ingress objects need to be told the `name` of the static IP that you want to associate with the Ingress. LoadBalancers want to be given the IP address directly. So this value will want to be an IP address.\r\n\r\nThat can be found in the GCP DNS console. I think we can also add that as something terraform will print out after provisioning, if we wanted to reduce the number of trips to the GCP console."]}, {"url": "https://github.com/clingen-data-model/architecture/pull/83", "comments": ["\ud83d\udc4d this is probably a good thing to comment in our values files. Less paging back and forth to the readme", "Just a general comment here, as I think fixing this requires a little more effort than this PR warrants: Would it be worth consolidating our GCR repos into a single one, and then promoting releases with just tags? I feel like this might be a lot cleaner if we weren't juggling different versions of the clingen-dev and -stage images, and just using the same one throughout.", "Yeah, I had a 'gee, I wish this info was right here moment' and decided to actually do something about it this time.", "Yeah--this is a little messy as it stands. I think that this will come out in the wash when we're automating builds on releases though."]}, {"url": "https://github.com/clingen-data-model/architecture/pull/79", "comments": ["This repository is obsolete and the trigger can be removed. I'll remove it from the project in the console too.", "Not sure what happened to the line selection. This comment is referring to the `clinvar-raw-stage-build` trigger on the `clinvar-scv` repo"]}, {"url": "https://github.com/clingen-data-model/architecture/pull/72", "comments": ["You can include your chartLabels snippet from the _helpers.tpl file to reduce some of the label duplication in the various pieces of the chart.", "If we're planning on deploying this to stage/prod soon, it probably also makes sense to add corresponding configs to the stage and prod helmfiles so that we can get linting.", "Is this port exposed to the outside world? Just want to make sure an internet rando can't hit it :)", "I think this will work fine if we intend to only run one replica -- If we ever need to run more than one replica, I think you may need a volumeclaimtemplate instead. I haven't looked into this a ton yet, but this is my understanding of the statefulset docs: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#stable-storage"]}, {"url": "https://github.com/clingen-data-model/architecture/pull/35", "comments": ["@sjahl we should probably change this to `/mnt/disks/ssd0/genegraph` especially now that we're putting multiple things on the local SSDs, so that each application's storage space is separated to a different sub-directory on the device and can be easily deleted if needed", "Cool -- I've updated the volume mount in the deployment template to use \"/mnt/disks/ssd0/{{ .Release.Name }}\", which should resolve to `/mnt/disks/ssd0/genegraph` for genegraph, `/mnt/disks/ssd0/genegraph-clinvar` for genergaph-clinvar, etc. https://github.com/clingen-data-model/architecture/pull/35/commits/079c915af73516f895cc263d642069eb3715a941"]}, {"url": "https://github.com/clingen-data-model/architecture/pull/34", "comments": ["Interesting, I have never seen this YAML feature before", "Those are YAML anchors: https://support.atlassian.com/bitbucket-cloud/docs/yaml-anchors/\r\n\r\nI've found them useful in a few cases so far where I need to re-use a string value. In this case, I'm defaulting to keeping the docker image tag in sync with the seqrepo version, but still allows the image tag to be overridden if needed.", "Are these just required to be added in order for helm to recognize the deployment once it's in the kubernetes cluster?", "I don't think they're required, but it's a best practice to help determine which components are part of which chart. I might actually be able to create a helper that sets these on everything, which should help reduce some of the repetitiveness."]}]}, {"url": "https://github.com/dexterchan/Terraform_Webserver.git", "pull_requests": []}, {"url": "https://github.com/ONSdigital/eq-terraform-dynamodb.git", "pull_requests": [{"url": "https://github.com/ONSdigital/eq-terraform-dynamodb/pull/15", "comments": ["~~Is this on demand?~~\r\nOn demand isn't an option - weirdly.\r\nhttps://www.terraform.io/docs/providers/aws/r/dynamodb_table.html#billing_mode"]}, {"url": "https://github.com/ONSdigital/eq-terraform-dynamodb/pull/9", "comments": ["This can be low if not nothing as we don't read.\r\nWill it allow `0`?", "We should add TTL to this table", "Won't allow 0, have set it to 1", "can this not come from the `aws_dynamodb_table` resource?", "`dynamodb`", "Is 2 minutes too late for the alarm?", "Pass the ARN into the module", "Maybe `Maximum` so we get the warning earlier?", "Yup, was still working on it", "This metric is actually the per request consumed capacity, I had to change it to `Sum`", "I was torn, I've known these alarms to be a bit jumpy to temporary spikes in traffic.  Maybe lets start it at one minute and tune it if it gets noisy?", "I based this off the pattern in `survey-runner-database` and `survey-runner-queue`.  Would you prefer passing in the ARN to it being consistent? (or should I refactor the others too?)", "i think passing the ARN is the preference like we have started doing with other resources.\r\nmight as well refactor as its the same repo", "ah ok, if its per request then the period will have a huge impact.", "I would set these a lot higher as they are production default", "5000?\r\ndefault account limit is 20,000 read 20,000 write so will give even split across tables.\r\nwe can tune and request more once its in", "You should prefix these alarms with EQ as per the session alarms. as in preprod and prod they go to an SDC wide ops channel", "Same comment re EQ prefix", "Here too", "typo `eq_sessio`"]}, {"url": "https://github.com/ONSdigital/eq-terraform-dynamodb/pull/2", "comments": ["- The resource name should be `submitted_responsestable` rather than `submitted-responses-table`\r\n- The filename should be submitted_responses.tf "]}, {"url": "https://github.com/ONSdigital/eq-terraform-dynamodb/pull/1", "comments": ["i think to make this name look more consistent with the env prefix it should be `${var.env}-submitted-responses`", "we don't need this file", "We don't need this in this module, we we are not using autoscaling", "we should make these variables and default them to 25 in the global vars", "You should also add Name and Environment tags for this table too. e.g. \r\n```\r\ntags {\r\n    Name        = \"${var.env}-submitted-responses\"\r\n    Environment = \"${var.env}\"\r\n  }\r\n```\r\n\r\nThis is just a best practice that you can use for cost allocation etc", "`terraform fmt` again. The `=` should always be vertically aligned", "I would add the table name to this variable. so it won't need changing if we add more tables."]}]}, {"url": "https://github.com/DoSomething/infrastructure.git", "pull_requests": [{"url": "https://github.com/DoSomething/infrastructure/pull/299", "comments": ["We run this per-workspace now (from each directory, rather than the root), so we'll just use the CLI directly.", "The `-recursive` flag allows us to run this from the root level & automatically format any files in this repo!", "I added directions for installing this repo's [githook](https://github.com/DoSomething/infrastructure/blob/main/.githooks/pre-commit) (that automatically checks formatting pre-commit). I also updated these instructions to suggest `make format`, which uses the `-recursive` flag to run this formatter on the whole repository (rather than just the current shallow directory).", "As noted above, we run this from with Terraform's CLI from individual workspace directories now!", "Noice! \u2728 "]}, {"url": "https://github.com/DoSomething/infrastructure/pull/298", "comments": ["Not a huge deal, but maybe switch this to use a current example since `Longshot` is no more? Maybe `identity.dosomething.org`?", "Should this be `log_archive` or something else? I think this may be a copy-pasta mistake \ud83e\udd14 ?", "Again, not a big deal but maybe update this to `dosomething-northstar` since Rogue has been archived.", "Changed in 961fcd1!", "Changed in 961fcd1!", "Oof! Fixed this to be an example for `iam_app_user` in b3abf80.", "\ud83d\udc4d "]}, {"url": "https://github.com/DoSomething/infrastructure/pull/296", "comments": ["This attaches these domains to this Fastly property (so Fastly knows what do with incoming traffic).", "This will redirect any traffic to `importer.dosomething.org` to the equivalent path at `identity.dosomething.org/admin/imports` (and likewise for QA)."]}, {"url": "https://github.com/DoSomething/infrastructure/pull/295", "comments": ["This says that, by default, we don't have any temporary paths. If we set this variable, it has to be an array of strings.", "Hmm, I'd added this because (as far as I remembered) this argument was required in the past! When I went to link to that documentation, though, it says it's optional! I'm going to try omitting and see how it goes.", "Because of how this `aws_s3_bucket` resource was built by Hashicorp/AWS, we have to configure this lifecycle rule as a dynamic \"property\" on the `aws_s3_bucket` (rather than as it's own optional resource that we could point to the bucket it's being attached to, like we do with a lot of other things).\r\n\r\nTerraform's dynamic blocks are described in more detail [here](https://www.terraform.io/docs/language/expressions/dynamic-blocks.html).", "Since we have versioning enabled on this production bucket, we'd end up with a lot of \"deleted\" version markers inside this `temporary/` directory. I figured it made sense to clean these up 90 days after the file itself is deleted. (We'll continue to retain other old versions indefinitely for safe-keeping).", "What does this mean?", "What does the `prefix` do? Where does this value come from? Sorry still not super used to some of this syntax!", "We have versioning enabled on our production bucket, so when we delete a file (or overwrite it, or whatnot) S3 keeps historical copies in case we need to roll back. This gives us extra peace of mind that we never lose user data from a bug! However, it'd also mean we'd keep these temporary files indefinitely unless we add a rule to remove those old versions too.", "I made this change in d675657 (including removing other `id` values that should no longer be necessary).", "Ah missed this comment on my first pass!", "No worries, it's a little hard to follow!! The `prefix` argument \"filters\" which objects in the S3 bucket this rule applies to (so by default, it'd apply to everything & this argument limits it to only things that match a given file/folder prefix). The `lifecycle_rule.value` is the \"iterator\" for this dynamic block & comes from the `var.lifecycle_rule` input variable that we're iterating over.", "So, in this case for Northstar, we're iterating over `[\"temporary/\"]` and so we'd loop a single time where `lifecycle_rule.value` would be `\"temporary/\"` (and thus we'd only enforce these automatic deletion rules for files that were inside that folder).", "So in the case of Northstar this limits to stuff in `temporary/`?", "Yup! Here's what this turns into (from the plan) after Terraform does all it's fancy looping:\r\n\r\n```hcl\r\nlifecycle_rule {\r\n  enabled = true\r\n  prefix  = \"temporary/\"\r\n\r\n  expiration {\r\n    days = 14\r\n  }\r\n\r\n  noncurrent_version_expiration {\r\n    days = 90\r\n  }\r\n}\r\n```", "Ideally we'd be able to just create this as a standalone `aws_s3_lifecycle_rule` resource in the Northstar module that looked exactly like that & deal with any looping funny-business to build this into the `s3_bucket` module but alas! \ud83d\ude43", "SO HELPFUL!! Thanks for spelling it out much much appreciated! I follow now!", "Yay, that worked!! It automatically generated a `tf-s3-lifecycle-20210517211330135300000001` ID for this lifecycle rule when it created it. That makes these a lot easier to work with. \ud83d\ude0c"]}, {"url": "https://github.com/DoSomething/infrastructure/pull/293", "comments": ["I removed this override because, based on our low storage utilization on these instances, the extra storage afforded by `premium-1` is giving us no benefit over what we get from `premium-0` (at half the cost)!", "Are these Rogue changes I'm seeing just residual cleanup since merging it into Northstar?", "Yup! The build for the `shared` module failed because the pipeline no longer exists (since we deleted the apps), and so I removed this to get that workspace back to \u2705!"]}, {"url": "https://github.com/DoSomething/infrastructure/pull/291", "comments": ["I remember this `count` is a workaround way to do something but I need a refresher on what's happening here!", "My understanding is that Terraform will create [`count`](https://www.terraform.io/docs/language/meta-arguments/count.html#basic-syntax) amount of this resource. So it's our way of \"turning it on\" only for QA since on prod it would be `0`.\r\n\r\ncc @DFurnes I could be completely misunderstanding!", "Ah that makes sense in this context to me!", "Yes, that's exactly it!"]}, {"url": "https://github.com/DoSomething/infrastructure/pull/290", "comments": ["What are the `#`s here for? I see some of our redirects have that and some don't and I'm not familiar with that syntax!", "@katiecrane  it's a hacky lil workaround for making sure different paths that have the same origin location like `vote.dosomething.org` and `vote.dosomething.org/xyz` end up redirecting to the same place because the # breaks the path. We definitely need it for the VR pages but figured it couldn't hurt to add in on the other redirects as well in case someone tries to go to a different path. cc @DFurnes ", "Oh that's cool! Nice that there is an easy way to get that behavior and agreed that it couldn't hurt on the others too."]}, {"url": "https://github.com/DoSomething/infrastructure/pull/286", "comments": ["This is necessary since the bucket's name (e.g. `dosomething-rogue`) will no longer match the application name (e.g. `dosomething-northstar`). We can consider cleaning this up later, but it'd be a timely migration since you can't rename existing buckets.", "This is a variable we used to provide to Rogue to allow us to configure our cross-region backup bucket in production. Since this bucket is now living under Northstar, we provide this variable here instead!", "Since we're removing the S3 bucket module, which used to provide these, I've hard-coded them under `extra_config_vars` for now to make everything continues to function exactly the same way.", "I replaced the [`module.s3_bucket`](https://github.com/DoSomething/infrastructure/tree/main/components/s3_bucket) module here with a [`s3_bucket` data resource](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/data-sources/s3_bucket) (which _reads_ from an existing bucket by name, rather than creating/modifying it).\r\n\r\nThis allows us to continue to reference the bucket that we've moved into Northstar's application module. I then created a `aws_iam_user_policy.s3_policy` that allows Rogue's IAM user to continue to access this bucket (since the relocated module will now default to granting access to Northstar).", "Using a data resource for something that's defined elsewhere is probably a bad practice (as opposed to defining the bucket elsewhere and passing it in as a variable to each app that shares it), but I think this the cleanest way to handle this during this \"transition period\".", "This is a simple copy-paste from the [`s3_bucket`](https://github.com/DoSomething/infrastructure/blob/main/components/s3_bucket/iam-policy.json.tpl) module (because each module only has access to it's own folder scope)."]}, {"url": "https://github.com/DoSomething/infrastructure/pull/282", "comments": ["Can you remind me of how this works? This will just set it up in Heroku for us, but we can still edit it via Heroku?", "We will still be able to edit it via Heroku, but we probably won't want to outside of an emergency. Instead, we'd want to let Terraform manage these environment variables, both to set them initially & to \"reset\" them if they're edited by hand (so we can avoid [configuration drift](https://www.hashicorp.com/resources/how-can-i-prevent-configuration-drift)).", "Awesome!"]}, {"url": "https://github.com/DoSomething/infrastructure/pull/281", "comments": ["Is the thought on this bump that if we were gonna see issues, we would have seen them with 5 minutes? So it's okay to jump straight to a week? What kind of errors would we have seen if there were issues?", "Yeah, I went back and forth on whether to try something like a day or 3 days before hopping to a full week... this is just following Google's [deployment recommendations](https://hstspreload.org/#deployment-recommendations) from [hstspreload.org](https://hstspreload.org/).\r\n\r\nIf this didn't work, we'd be seeing Zendesk or staff reports of errors (like a \"cannot connect\" Chrome tab or something) where users couldn't load a `*.dosomething.org` subdomain that didn't support HTTPS. I don't know any off the top of my head, so I _think_ this unlikely though!", "@DFurnes ah okay so 5 minutes to 1 week is standard practice then! I'm okay with that, just was hesitant since we can't undo it", "Yeah, same! I think this should hopefully be pretty low-risk, and we'll wait a while before we bump it to a month. \ud83e\udd1e"]}, {"url": "https://github.com/DoSomething/infrastructure/pull/280", "comments": ["I was thinking this might be a helpful section to add to our README template - links to tutorials or documentation that might be relevant when onboarding to or working in an application! I always find myself going back to these same pages when working in Terraform & they're not all super easy to find!"]}, {"url": "https://github.com/DoSomething/infrastructure/pull/279", "comments": ["Context: As far as I know, I can't cleanly make the data resources (to read the username/password from SSM) optional, and so it's easiest to just plop the QA credentials onto the dev environment & disable via feature flag.", "Is the feature flag happening in this file? I would have thought `DS_ENABLE_GAMBIT_RELAY` would be false for dev?", "OH I see, you only added the Gambit url to prod and QA yeah?", "Yep!"]}, {"url": "https://github.com/DoSomething/infrastructure/pull/278", "comments": ["We talked about putting these in `dosomething-archive` at one point. I can see good arguments for keeping everything in the same place, and also for keeping stuff a bit more segmented in a Quasar-specific `dosomething-quasar-achive` bucket like this too. How are you looking at this?", "How does this work making a transition into both IA & Glacier at the same time?", "Does this mean that these archived objects will be deleted after 60 days?", "I think we can add `block_public_policy = true` here too (which prevents bucket policies from accidentally \"opening up\" this bucket's contents if we'd made a mistake there).", "```suggestion\r\n  # archived files to be marked with \"public\" ACLs.\r\n```", "Based on the name of this module, I wonder if it should _just_ have the role in it?\r\n\r\nWe could potentially use our `s3_bucket` module to create the Glacier bucket and set up archive rules:\r\n\r\n```hcl\r\nmodule \"quasar_archive\" {\r\n  source = \"../components/s3_bucket\"\r\n\r\n  application = \"dosomething-quasar\"\r\n  name        = \"dosomething-quasar-archive\"\r\n  environment = \"production\"\r\n  stack       = \"data\"\r\n\r\n  versioning = true\r\n  archived   = true\r\n  private    = true\r\n}\r\n\r\nmodule \"rds_export_role\" {\r\n  source = \"../components/quasar_s3_export_role\"\r\n  \r\n  arn = module.quasar_archive.arn\r\n}\r\n```", "Yes, they'll expire after 60 days. Would you prefer a longer time period?\r\n", "I think I'd misunderstood this task, since I'd assumed the reason we were putting these into Glacier was for long-term storage. Is this something you're planning on using for RDS's daily snapshots?", "I was thinking that we'd push the snapshots into s3 daily and then push them into Glacier after a set period, and eventually expire them since we already have the backup in Glacier if we really need to pull it out.", "I believe the Glacier lifecycle rule \"moves\" those objects into Glacier (as their storage class in S3), but the objects themselves are still represented as S3 items. So in this case, these rules would be moving the objects into Glacier and then deleting them (from both S3 & Glacier) 30 days later.", "If we want to store these indefinitely in Glacier, we don't need an `expiration` rule here. If we _do_ want to expire these so these backups don't pile up over time, we should set an `expiration` rule of [at least 90 days](https://docs.aws.amazon.com/AmazonS3/latest/dev/lifecycle-transition-general-considerations.html#before-deciding-to-archive-objects) or else it looks like we'll be charged an \"early deletion fee\".", "On some further reflection, I think it does make sense to put these in a separate bucket since these files will be parquet files and may end up being the beginning of our data lake. If we want to query the snapshots we'll probably use something like Athena, so it would make sense to separate the snapshot files from other types of backup files.", "Ah, that makes great sense to me!"]}, {"url": "https://github.com/DoSomething/infrastructure/pull/275", "comments": ["This `response_condition` is what ties the two together? Not super familiar with the syntax of this", "Yep, exactly! By default, changes like this are applied to all requests. The `condition` block allows us to segment something on a subset of requests/responses, and then we can attach that to other behavior.\r\n\r\nWe use this same approach to [avoid caching authenticated responses](https://github.com/DoSomething/infrastructure/blob/daec9a076a6f4f5370f0d4d2adc182ac753c50f2/components/fastly_frontend/main.tf#L71-L84) and to [conditionally route traffic to different backends](https://github.com/DoSomething/infrastructure/blob/daec9a076a6f4f5370f0d4d2adc182ac753c50f2/components/fastly_backends/main.tf#L79-L91) based on `req.host` in our backend property.", "Ah those examples are helpful, thanks!"]}, {"url": "https://github.com/DoSomething/infrastructure/pull/274", "comments": ["To explain the funky quotes: by default Fastly interprets these values as variable references (like `client.geo.country_code` above). To set a literal string, we provide a quoted value (which, since strings in Terraform are themselves quoted, needs an escaped `\\\"` set of quotes inside the string).", "Since this can't easily be undone once someone receives this header, we'll want to test this with a short TTL for a while, and then increase until we reach 2 years long following [these best practices](https://hstspreload.org/#deployment-recommendations). (And we can consider submitting our domain for HSTS preload then, too!)", "These are all identical to what's set in the `fastly_backend` module above! I think it's reasonable to keep these not-so-DRY, since we may eventually have differing security needs for backends and frontends.", "Does this mean the header is only like active for 5 minutes? I'm a little confused about this", "It's sort-of like a cache header \u2013 this header, as written here, will be sent on all responses from www.dosomething.org. When a user's browser sees it on a response, it'll make a note that it's _only_ allowed to visit our site via HTTPS for the next five minutes. (So if someone tries to visit `http://` directly or omits a protocol, it'll force that to `https://`).\r\n\r\nAfter five minutes, it'll revert to default behavior (defaulting to `http://`) until it sees this header on another response & once again forces HTTPS traffic for the next five minutes. (And hence why we'll want to bump this up after testing.)", "Ah got it! So if something does end up not working, it'll only be borked for five minutes?", "Correct!"]}, {"url": "https://github.com/DoSomething/infrastructure/pull/273", "comments": ["I renamed the `backends` argument provided to `applications` for two reasons:\r\n\r\n1. It's odd to provide a \"backends\" object that itself is composed of name, domain, and backend(!) properties. I think calling this `applications` makes it much clearer what these actually are.\r\n2. I wanted to follow the same convention (`applications = [\u2026]` and `application = \u2026`) for both these Fastly modules! It would feel somewhat awkward to pass a `backend` argument to the frontend module!\r\n", "Following the same pattern established in #270, you can just pass in an application module here (as long as it has these named outputs). So we can just say `application = module.phoenix` for example, rather than needing to pass each piece separately! \ud83d\ude0c", "Like in #270, I've inlined this here since we always want the same log format regardless of what environment we're in. (We may, however, eventually want different log formats between frontend & backend properties).", "After inlining this into the backend module in #270 and the frontend module here, this is no longer used!", "I'd accidentally prefixed these `Fastly:` in my previous PR... which, duh! Of course they're Fastly! I'm not sure how important it is anymore, but the reason I'd prefixed these with `Terraform:` originally was to indicate to anyone logged into the web console that they should make edits there (not via the GUI)!", "I just remembered to add this in ff77c81! \ud83d\ude48 This keeps our same \"deny all\" `robots.txt` in development and QA to prevent those environments from showing up in Google search results. \r\n\r\nTerraform doesn't have a simple \"conditional\" syntax for blocks so, [like we do with the `count` attribute for resources](https://github.com/DoSomething/infrastructure/blob/13f1ec7367067a89746f605e75704aaa95eb397d/components/s3_bucket/main.tf#L113), we use a zero/one item \"for loop\" to make this conditional on `var.environment`.", "Oh smart prefixing there!", "Generally I was seeing one file moved into a common folder and the two other copies deleted - for this one I only see two copies deleted, was that intentional?", "Seeing same pattern with the takeovers, just two files removed", "Oh I totally goofed (on including that file & properly testing the conditional)! Fixed in 7e02dfa.", "What's up with these takeover files that were removed, are they just no longer needed?", "Yep! They were for an old takeover we ran for the 2018 midterm elections.\r\n\r\nI'd removed the config that referenced these in [`4fc0a59`](https://github.com/DoSomething/infrastructure/pull/270/files/4fc0a59fec55b0a62df45658bc6b7fd7dd3dda7e#diff-78e34551875d9e35121e22997ec0db55) but forgot to remove the files themselves."]}, {"url": "https://github.com/DoSomething/infrastructure/pull/271", "comments": ["This is extracted from the production `fastly-frontend` module (below). Since we now only handle one domain in each of these two properties, we no longer need request conditions for backends/headers.", "Since we consume the S3 bucket \"backend\" inside the module, it no longer makes sense to output these.", "This now exists within the `agg` instance of the `static` module, below.", "I don't see anything about `assets.dosomething.org` specifically referenced here like I do in `fastly-frontend` down below, can you explain this a little more?", "Yeah, totes! We read the domain that the Fastly property & S3 bucket will be configured for using the `var.domain` variable in this module (declared at the top of this file, and used in the Fastly `domain { \u2026 }` block & bucket config).\r\n\r\nWhen using this module to create resources in `voting-app/main.tf` and `dosomething/main.tf`, we can then pass a different domain (either `athletesgonegood.com` or `assets.dosomething.org`) to customize each \"instance\".", "Ah I think I see now, and I do see those being passing through elsewhere!"]}, {"url": "https://github.com/DoSomething/infrastructure/pull/270", "comments": ["This is from an old homepage takeover. \r\n\r\nIt's something that we could re-add (from Git history) if we were to run again.", "These were all just renamed for clarity.", "This allows us to pass \"backend\" modules as long as they have `name`, `domain`, and `backend` output variables! Now we don't need to tediously define `northstar_name`, `northstar_domain`, `northstar_backend`, `rogue_name`, etc. but can just pass in a list of backends like `module.northstar, module.rogue`.", "Whoops - fixed this not to be hard-coded in 8b21e4f.", "It's awkward to read with how the diff is broken up, but this basically replaces individual `domain { \u2026 }`, `condition { \u2026 }` and `backend { \u2026 }` blocks for each application with a \"dynamic\" block that builds all of these based on the provided `var.backends` variable.", "I moved up this from the bottom of the file since it's relevant to the `shield` arg on the backend above.", "Likewise, moved the `response_object` here up so it's next to the condition it relies on.", "Since we're now re-using the same `fastly_backends` service across all environments, I don't think it's as useful to pass in the `papertrail_log_format` variable here like we did before.", "@DFurnes so this string is dynamically building what would have previously been saved as `var.papertrail_log_format`?", "Yep, I've just directly copied in the string value we used to send for this (as `var.papertrail_log_format`) from `dosomething/main.tf`, `dosomething-qa/main.tf`, and `dosomething-dev/main.tf`. I think it makes more sense to keep here now, since we can define it one place for all three environments.", "Here's, for example, where we used to grab this [for the production environment](https://github.com/DoSomething/infrastructure/blob/13f1ec7367067a89746f605e75704aaa95eb397d/dosomething/main.tf#L56).", "So here is where we leverage [this work](https://github.com/DoSomething/infrastructure/pull/270/files#r490504424)?", "Yes! We send in the set of backend modules each place we use this (so e.g. `identity-dev.dosomething.org` and `activity-dev.dosomething.org`'s variables would be passed in here). We read this provided variable on the line you linked, and then iterate over that array to configure the Fastly property below.", "Makes sense to me, love having this long thing just in one place!"]}, {"url": "https://github.com/DoSomething/infrastructure/pull/269", "comments": ["Do we still want this deprecated flag?", "It had originally been a way to tear down the database (since you first need to delete users & disable \"deletion protection\" by \"deprecating\" that resource before actually deleting it). At this point, it's no longer being used."]}, {"url": "https://github.com/DoSomething/infrastructure/pull/268", "comments": ["Since there's just one API key (rather than application-specific keys, like we're able to do for things like Contentful or Algolia), I'd placed this in a top-level `/airtable/api-key` parameter:\r\n\r\n```suggestion\r\n  name = \"/airtable/api-key\"\r\n```"]}, {"url": "https://github.com/DoSomething/infrastructure/pull/266", "comments": ["Is the old Bertly still somewhere using `dosome.click`?", "Yep! I'm going to detach that mapping before I apply this. :link: ", "Ah so that one is outside of terraform?", "Sounds good though - now I'm just curious!", "Yes! Originally, Bertly was managed with [CloudFormation](https://aws.amazon.com/cloudformation/), Amazon's configuration-as-code tool. It had some nice integrations in the AWS web GUI, but also only worked with AWS services which was a deal-breaker for a lot of our stuff."]}, {"url": "https://github.com/DoSomething/infrastructure/pull/263", "comments": ["I wasn't sure what to put here \u2013 since Papertrail is sort-of a \"catch all\". Open to suggestions!", "This is Papertrail's AWS account ID, referenced from [this documentation](https://help.papertrailapp.com/kb/how-it-works/automatic-s3-archive-export/#alternative-define-sharing-policy-with-iam).", "So this line and the `policy.json.tpl` file are saying that the Papertrail AWS user can put and delete things in this bucket?", "Yep!"]}, {"url": "https://github.com/DoSomething/infrastructure/pull/257", "comments": ["Just want to make sure it's fine to not have in env var ;)"]}, {"url": "https://github.com/DoSomething/infrastructure/pull/255", "comments": ["Note that deleting this resource will [automatically take a final snapshot](https://github.com/DoSomething/infrastructure/blob/fe48a2ebe17fff8630ded7b5f151c7191434250c/components/mariadb_instance/main.tf#L136).", "Since this is applied with a lifecycle policy, objects will be moved into Glacier after 30 days."]}, {"url": "https://github.com/DoSomething/infrastructure/pull/254", "comments": ["This is just reverting the deletion of these lines in #253.", "Despite being named \"force destroy\", I do not believe this will force destruction on its own (it just forces it along if it already is going to destroy the resource for another reason). This is similar to a setting we have to use on our [Fastly properties](https://github.com/DoSomething/infrastructure/blob/fe6fac17c57d1179261a6333d2753483b389b9cf/dosomething/fastly-backend/main.tf#L23) to ensure that Terraform can delete them if it needs to.\r\n\r\nI'll apply this change to Longshot, dev, and QA properties first to double-check that assumption! \ud83c\udf35 "]}, {"url": "https://github.com/DoSomething/infrastructure/pull/252", "comments": ["This is just to address a deprecation warning \u2013 this is a reference to the `aws.west` provider resource, not a string."]}, {"url": "https://github.com/DoSomething/infrastructure/pull/250", "comments": ["Is this file copyrighted? \u00a9\ufe0f", "This variable seems to be unused. (We default to `us-east-1` in our provider [here](https://github.com/DoSomething/infrastructure/blob/5d59c6309a0cd661c5a0933838f970c6ba08bc0d/quasar/main.tf#L13)).", "This is Fivetran's AWS account ID, right? Can we add a comment on this line noting that?", "Since we're not doing any string interpolation here, the wrapping double-quotes can be removed. While these will technically work, they'll be flagged as \"warnings\" on our Terraform builds, like this:\r\n\r\n```\r\nWarning: Interpolation-only expressions are deprecated\r\n\r\n  on main.tf line 659, in resource \"aws_iam_policy\" \"fivetran_cloudwatch_integration\":\r\n 659:   policy = \"${data.aws_iam_policy_document.fivetran_cloudwatch_integration.json}\"\r\n\r\nTerraform 0.11 and earlier required all non-constant expressions to be\r\nprovided via interpolation syntax, but this pattern is now deprecated. To\r\nsilence this warning, remove the \"${ sequence from the start and the }\"\r\nsequence from the end of this expression, leaving just the inner expression.\r\n\r\nTemplate interpolation syntax is still used to construct strings from\r\nexpressions when the template includes multiple interpolation sequences or a\r\nmixture of literal strings and interpolations. This deprecation applies only\r\nto templates that consist entirely of a single interpolation sequence.\r\n\r\n(and 3 more similar warnings elsewhere)\r\n```\r\n\r\n```suggestion\r\n      values = [\r\n        var.fivetran_cloudwatch_integration_external_id,\r\n      ]\r\n```", "Same here:\r\n\r\n```suggestion\r\n  policy = data.aws_iam_policy_document.fivetran_cloudwatch_integration.json\r\n```", "```suggestion\r\n  assume_role_policy = data.aws_iam_policy_document.fivetran_cloudwatch_integration_assume_role.json\r\n```", "```suggestion\r\n  role       = aws_iam_role.fivetran_cloudwatch_integration.name\r\n  policy_arn = aws_iam_policy.fivetran_cloudwatch_integration.arn\r\n```", "```suggestion\r\n  value       = aws_iam_role.fivetran_cloudwatch_integration.arn\r\n```", "This module requires a `fivetran_cloudwatch_integration_external_id ` argument (see `variables.tf` above):\r\n\r\n```hcl\r\nmodule \"fivetran_logging\" {\r\n  source = \"../components/fivetran_cloudwatch_role\"\r\n  fivetran_cloudwatch_integration_external_id = \"...\"\r\n}\r\n```"]}, {"url": "https://github.com/DoSomething/infrastructure/pull/247", "comments": ["It might be nice to re-write these to make units clearer (is it KB?) and how we got here... e.g:\r\n\r\n```hcl\r\nvalue = \"${12 * 1000 * 1000}\" # 12GB.\r\n```", "Also curious what the units are here... is this seconds? If so, let's just add an inline comment:\r\n\r\n```hcl\r\nvalue = \"1000\" # 16 minutes\r\n```", "Is this a new thing we're testing? If not, did we see an improvement before? If there's a ticket, let's link it here.", "Ooh, love this! Yah, will definitely change this!", "Millseconds, will document. ", "This was part of some performance work we tested out about a year ago, when investigating some performance gremlins in the machine. Tried to look for a ticket attached to this, but couldn't find it. We didn't see a measurable performance improvement either way, so happy to remove it. Thoughts? ", "Yeah, let's remove this if we didn't find any improvement."]}, {"url": "https://github.com/DoSomething/infrastructure/pull/239", "comments": ["Your markdown link is borked. Replace closing `)` with `]`.", "Also just reads weird as \"Setup Nginx setup guide...\" Maybe just \"Setup Nginx...\"?", "`filname` should be `filename`", "`cerbot` should be `certbot`", "Fix is [here](https://github.com/DoSomething/infrastructure/pull/240).", "Gah, sorry @DFurnes! I accidentally re-introduced this after fixing it locally for some reason. \ud83e\udd26 Fix is [here](https://github.com/DoSomething/infrastructure/pull/240)."]}, {"url": "https://github.com/DoSomething/infrastructure/pull/238", "comments": ["The build (which can be found by clicking the :x: on the commit) is failing with this error:\r\n\r\n```\r\nError: Reference to undeclared input variable\r\n\r\n  on main.tf line 507, in module \"iam_user\":\r\n 507:   name   = var.name\r\n\r\nAn input variable with the name \"name\" has not been declared. This variable\r\ncan be declared with a variable \"name\" {} block.\r\n```\r\n\r\nThat's because you don't have a [variable](https://www.terraform.io/docs/configuration/locals.html) named `name` in this module (you'd see a `variable {}` block at the top if you did). You could define a [local value](https://www.terraform.io/docs/configuration/locals.html) so you could reference the same \"name\" for both of these resources, or just provide an inline string here. This will be used as the name of the S3 bucket & user:\r\n\r\n```suggestion\r\n  name   = \"quasar-cio\"\r\n```", "Woohoo! Setting a local value worked! Thanks @DFurnes!"]}, {"url": "https://github.com/DoSomething/infrastructure/pull/237", "comments": ["Any ideas why this went up? I'd have thought it would be roughly cut in half.", "Yeah, I was curious about that as well, and re-ran the numbers on the current instance specs before this PR went in, and looks like we had a bad copy/paste from a configuration based on double the `max_connections` we actually use. \ud83d\ude2c ", "Yikes! Good to catch it now."]}, {"url": "https://github.com/DoSomething/infrastructure/pull/226", "comments": ["Can you update this to read `9.`? Then \ud83d\udcaf to merge!", "Haha, yep! Updated! Thanks for the catch."]}, {"url": "https://github.com/DoSomething/infrastructure/pull/225", "comments": ["Here's an example of why `app_name.vcl` now needs to be duplicated in each individual module \u2013 we can't (for security reasons, I assume) reach outside the \"root\" of the workspace's module to load files & so this needed to be swapped to `path.module` and moved within the `dosomething-dev/fastly-backend` directory.", "This could also easily be `name = \"dosomething-dev\"`, but this eases us into a future where we have a single `dosomething` module that gets applied to `-dev`, `-qa`, and `-prod` workspaces with different variables.", "I'll tackle that in a follow-up ticket since this already got so much heftier than I'd imagined it would.", "We should maybe just remove this (an old static HTML takeover from the election)! But didn't want to make any changes in this PR that'd result in an actual configuration change.", "Yeah... is there a ticket regarding removing it? If not we should defs add one!", "I need to make one! \ud83d\udcdd ", "Created [#170936349](https://www.pivotaltracker.com/story/show/170936349) for this."]}, {"url": "https://github.com/DoSomething/infrastructure/pull/223", "comments": ["If the `TEST_APP_KEY` in this PR looks good, we'll be able to remove this manual step!", "This is also something we can automate with Terraform in a future revision."]}, {"url": "https://github.com/DoSomething/infrastructure/pull/220", "comments": ["We had to remove these references in order to avoid errors on Fastly QA. We should perhaps see if we can find a way to make these two modules less tightly coupled."]}, {"url": "https://github.com/DoSomething/infrastructure/pull/218", "comments": ["How come this was set to a different value than production before?", "It might also be worth looking into [storage auto-scaling](https://www.terraform.io/docs/providers/aws/r/db_instance.html#storage-autoscaling) in the future.", "We had smaller data sets in QA vs Prod so didn't justify the additional cost. ", "> It might also be worth looking into [storage auto-scaling](https://www.terraform.io/docs/providers/aws/r/db_instance.html#storage-autoscaling) in the future.\r\n\r\nOOOOO sweet, will add a backlog ticket!"]}, {"url": "https://github.com/DoSomething/infrastructure/pull/209", "comments": ["Just noting for future reference \u2013 these were added because the Terraform provider now supports dictionaries in [version 0.9.0](https://github.com/terraform-providers/terraform-provider-fastly/blob/master/CHANGELOG.md#090-august-07-2019), which is very cool but also means it'll _delete_ them if they don't exist in the Terraform plan! Yikes!", "\ud83d\ude31 "]}, {"url": "https://github.com/DoSomething/infrastructure/pull/207", "comments": ["Zoinks! Let's add some validation for this so we don't accidentally forget to read the comments. \ud83d\ude09 \r\n\r\n```sh\r\n#!/bin/bash\r\n\r\nVPN_SERVER_CERTIFICATE_ARN=\"$1\"\r\nVPN_CLIENT_CERTIFICATE_ARN=\"$2\"\r\n\r\nif [[ -z \"$VPN_SERVER_CERTIFICATE_ARN\" ]] || [[ -z \"$VPN_CLIENT_CERTIFICATE_ARN\" ]]; then\r\n  echo \"Usage: ./scripts/generate-vpn-certs.sh <vpn_server_certificate_arn> <vpn_client_certificate_arn>\" 1>&2\r\n  exit 1\r\nfi\r\n```", "Hmm, this seems scary to `rm -rf` two folders in the user's home directory. \ud83d\ude31 \r\n\r\nCan we instead use [`mktemp`](https://code-maven.com/create-temporary-directory-on-linux-using-bash) to create a temporary directory and then do everything in there?", "Should we check out a release (like `git checkout v3.0.6`) rather than running the master branch?", "I see a lot of `nopass` arguments floating around, what's up with that? Any security concerns?", "This is based on the [AWS directions](https://docs.aws.amazon.com/vpn/latest/clientvpn-admin/authentication-authorization.html#mutual). I'm guessing they want to keep latest release to maintain security updates merged to master instead of pinning to a release.", "Same as above comments instructions [as provided by AWS](https://docs.aws.amazon.com/vpn/latest/clientvpn-admin/authentication-authorization.html#mutual), which specify `nopass`, which essentially which is the same as creating a HTTPS cert with no password that we keep on servers or other places. \r\n\r\nSo no extra security concerns beyond that.", "Got it. Let's pin to a version in our script, since [using `master` is not recommended](https://github.com/OpenVPN/easy-rsa#branch-structure):\r\n\r\n> Please note that, at any given time, master may be broken. Feel free to create issues against master, but have patience when using the master branch. It is recommended to use a release, and priority will be given to bugs identified in the most recent release.", "Oh dear gods, good job Amazon \ud83d\ude44 . Will pin to v3.0.6", "[Added](https://github.com/DoSomething/infrastructure/pull/207/files#diff-ae4dd165d7748ad84f3f391beb927595R8-R15)!", "[Added](https://github.com/DoSomething/infrastructure/pull/207/files#diff-ae4dd165d7748ad84f3f391beb927595R18)!", "Let's use the named variables (that we created above) here too.", "Gah, thought I'd caught them all! Thanks for the catch! [Updated](https://github.com/DoSomething/infrastructure/pull/207/commits/787b846da1f0645667a4e39b6f7a59ba702f12a2)."]}, {"url": "https://github.com/DoSomething/infrastructure/pull/205", "comments": ["Huh\u2026 weird that this is required, but can be left blank! \ud83e\udd14I'm having a hard time understanding what this is supposed to be used for, based on the module's documentation...", "Yeah, same. The one thing [I think](https://github.com/joshuamkite/terraform-aws-ssh-bastion-service/blob/9a61e7c1f1c228951d5297083c5341b0b7de9260/sts_assumerole_example/policy_example.tpl) it might be is allowing role assumption at a certain point of the process, but it's a bit unclear to me what exactly. \r\n\r\nI'm definitely taking test-as-we go approach, due to lots of working parts stitched together. Reason PR took this long to get in was I was reading/following the docs trying to understand all the components, but I think testing/firing it up will provide more insight in a controlled environment. "]}, {"url": "https://github.com/DoSomething/infrastructure/pull/200", "comments": ["We can remove this override, since this isn't making a MySQL password, right?", "AD passwords have a funky history of limits and complexity, you know [like this announcement from this year](https://techcommunity.microsoft.com/t5/Azure-Active-Directory-Identity/Removal-of-the-16-character-limit-for-passwords-in-Azure-AD/ba-p/565275) \ud83d\ude44. I think 24 character length with no special characters makes sense, but can definitely get into the password complexity limits/details if you think it's worth it. ", "Okay, sure. If the goal is to include no special characters, could you change this to `special = false` and remove the comment referencing MySQL?", "Can do!"]}, {"url": "https://github.com/DoSomething/infrastructure/pull/188", "comments": ["We'll want these to be different, so let's rename `importer_api_key` to `random_string.callpower_api_key` above & then create a new `random_string.softedge_api_key` to generate the secret for `SOFTEDGE_API_KEY`.", "ah sorry about that @DFurnes ! I thought that would be called twice and generate two different strings each time. Updated! "]}, {"url": "https://github.com/DoSomething/infrastructure/pull/176", "comments": ["I think the `parameter_group_name` here needs to be `\"${aws_db_parameter_group.quasar-qa-pg11.id}\"`. ", "Let's not use `apply_immediately` in our Terraform config, since it's nice to be able to safely queue up a change and let it get \"committed\" during the maintenance window if it requires downtime. If you want to \"force\" a change, you can use the AWS CLI to apply queued changes immediately after running `make apply`:\r\n\r\n```\r\naws rds modify-db-instance --db-instance-identifier quasar-qa --apply-immediately\r\n```", "@DFurnes What's the best place to document this (if we haven't already)? I mistakenly told Morgan we should put that config in, then remove it in another PR once the upgrade was complete, but totally makes sense what you're saying. I think we've had this conversation before and I'd like to make sure we can capture this somewhere for future DB updates!", "I think this would make sense to document [once we extract a `postgres_warehouse` component](https://www.pivotaltracker.com/story/show/165499203) for these resources (following the example of how [`api_gateway`](https://github.com/DoSomething/infrastructure/tree/master/components/api_gateway) and [`lambda_function`](https://github.com/DoSomething/infrastructure/tree/master/components/lambda_function) are documented.)"]}, {"url": "https://github.com/DoSomething/infrastructure/pull/175", "comments": ["Just wondering this comment should point to [CHAP_Source.PostgreSQL.RDSPostgreSQL](https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Source.PostgreSQL.html#CHAP_Source.PostgreSQL.RDSPostgreSQL) instead. This section holds the recommendation to use this parameter. Sorry If I'm missing context, just lurking and poking to learn more \ud83d\ude42 .", "Just curious if you think we should document the assumptions we input in this tool to get the recommendations.", "We can add some more nuance here, but the assumption I think started out as \"we don't know what the hell we're doing, this is a good starting point.\" I think we've noted that in the original setup ticket for this in Pivotal which I think is a better place for extended comments. We could possibly link to that ticket?\r\n", "The original link pointed to the Postgres 10 link, so might be worth an update, but we're deprecating DMS soon, so we'll probably remove the code. leaving it up to Morgan.", "That 10.x link points to the documentation for version 10 and later, so we can leave that for the moment."]}, {"url": "https://github.com/DoSomething/infrastructure/pull/169", "comments": ["what's an `arn`? \ud83e\udd14 \r\n", "Amazon's [silly name for IDs](https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html). \ud83e\udd37\u200d\u2642\ufe0f ", "ah! \ud83e\udd2a"]}, {"url": "https://github.com/DoSomething/infrastructure/pull/163", "comments": ["Let's make these updates on the Development & QA frontend properties as well! (And do we want to test them there first, just to be safe?)", "I think we still need to keep the parenthesis group around the `us/` prefix in all of these so this whole section is marked optional (instead of just the `/`)!", "Thanks for catching this\u2014restored to dev/QA/prod.", "Updated! Thanks."]}, {"url": "https://github.com/DoSomething/infrastructure/pull/159", "comments": ["We'd previously routed `www-dev.dosomething.org` through the backend property, which doesn't make a ton of sense (hence why this is being removed). I'll set up redirects for `www-dev.dosomething.org` and `staging.dosomething.org` to point to `dev.dosomething.org` once this is applied."]}, {"url": "https://github.com/DoSomething/infrastructure/pull/136", "comments": ["It'd be nice to outline the manual steps for setting this up here, e.g:\r\n\r\n```\r\n- Head to <https://git.io/fh9DS> and hit \"Deploy to Heroku\" to provision the app.\r\n- Set the required environment variables via Heroku's admin panel. <https://git.io/fh9Dy>\r\n- Set the `SLACKBOT_S3_BUCKET`, `AWS_ACCESS_KEY_ID` & `AWS_SECRET_ACCESS_KEY`\r\n  environment variables from the resources we've provisioned in this module.\r\n```\r\n\r\nWe also probably don't want to lock down public access here, since this is used for file hosting.", "Ah, good point. We can remove that S3 instruction entirely, can't we?", "Yep!"]}, {"url": "https://github.com/DoSomething/infrastructure/pull/131", "comments": ["Instead of three separate error codes, what if we shared `800` for all of these and passed a parameter? I haven't tested this out before, but I think it might work...\r\n\r\n```vcl\r\nif (req.url ~ \"(?i)^\\/((us|mx|br)\\/)?actnow\\/\") { error 800 \"/us\"; }\r\n```\r\n\r\n```\r\nif (obj.status == 800) {\r\n  set obj.http.Location = obj.response;\r\n  set obj.status = 301;\r\n  return (deliver);\r\n}\r\n```", "\ud83e\udd14 yeah, potentially. Does having the separate codes help in terms of knowing what's getting requested a lot? If not I guess that could make it easier?", "@DFurnes ended up just going for it and trying this out. Ultimately it'll make adding more legacy redirects easier in the future! Lemme know if all looks good and works in a dry-run \ud83d\ude09 ", "One potentially small gotcha: since this regex ends in the `/`, this won't match on [`/about/team`](https://www.dosomething.org/us/about/team).\r\n\r\nAre we getting any hits there?", "Not that I saw, but also don't want to target for not ending in `/` since we may have some page in the future that begins with team and is hyphenated. We can just do an Aurora redirect for this one.", "Oh sure, Aurora redirect works for me! \ud83d\udc4d ", "Added the redirect to Aurora to help :)"]}, {"url": "https://github.com/DoSomething/infrastructure/pull/122", "comments": ["Whoop, these have a syntax error in them:\r\n\r\n```\r\n* fastly_service_v1.frontend-qa: [ERR] Invalid configuration for Fastly Service (5I35is1gX0tbds1VfNmBIb): Syntax error: Expected `{`, got `error`\r\nat: (input Line 657 Pos 3)\r\n  error 779 \"Not Found\";\r\n--#####-----------------\r\n```\r\n\r\nWe need to add an opening `{` on the if conditional above!", "doh!", "Oops, another sneaky syntax error here:\r\n\r\n```\r\n* module.dosomething-qa.module.fastly-frontend.fastly_service_v1.frontend-qa: 1 error(s) occurred:\r\n\r\n* fastly_service_v1.frontend-qa: [ERR] Invalid configuration for Fastly Service (5I35is1gX0tbds1VfNmBIb): Syntax error: Expected variable, string or semicolon got `set`\r\nat: (input Line 1079 Pos 3)\r\n  set obj.status = 302;\r\n--###------------------\r\n```\r\n\r\nWe need a semi-colon on the line above here (after `\"/us\"`)."]}, {"url": "https://github.com/DoSomething/infrastructure/pull/119", "comments": ["@DFurnes So, in this example, you would first need the Lambda build packaged up locally as a zip?", "Ah, that comment is a lie! My hope is that we can push up a \"default\" function (stored in `example.zip`) when provisioning the new resource and then manage uploading new releases via a separate IAM \"deploy\" role without invalidating state.", "Assuming this is the standard copied from AWS grants permissions groups console? ", "![368635-20](https://user-images.githubusercontent.com/4562565/51919384-4d9f9b80-23b1-11e9-8f45-f9cfb261f22a.jpg)\r\n\r\nWhy might we have different `dev` vs `development`? Is this local vs Heroku hosted? ", "Yeah, UPGRADE!", "This is cool, just looked up what `locals` does.", "![roll eyes](https://media.giphy.com/media/PprHjp7DCw4BW/giphy.gif)", "The GraphQL app expects this environment variable to be provided as `dev`. We store environment as the full string `development` everywhere else in Terraform.\r\n\r\nWe should reconcile these so it's consistent everywhere!", "[Yup](https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_examples_dynamodb_specific-table.html).", "> Is this local vs Heroku hosted?\r\n\r\nNo, local apps would have `APP_ENV=local`. Our [development environment](http://docs.dosomething.org/engineering/overview#environments) is what developers connect their locals to when working on code (since we don't have a convenient way to spin up & maintain an entire local environment for folks, e.g. with Docker Compose)"]}, {"url": "https://github.com/DoSomething/infrastructure/pull/111", "comments": ["Are there no instances by default where we'll use caching for express apps? Pretty sure *no* since this is to setup GraphQL, but it's only notable diff I've noticed, so asking, just in case. :)", "Stack, framework, \ud83e\udd37\u200d\u2642\ufe0f Naming is hard.", "We actually do use Redis caching in most (or all?) of our Express apps, but it's not configured with a swappable driver. This `CACHE_DRIVER` is a Laravel-specific setting.", "Framework could also make sense! I don't have a strong preference either way.", "Renamed to `framework` in efb5ff4!", "\ud83d\udc26 "]}, {"url": "https://github.com/DoSomething/infrastructure/pull/109", "comments": ["Just want to confirm we're good with these no longer working (two Mexican international campaigns that had accidentally been created on the `/campaigns` prefix instead of `/voluntario`).", "And depending on the answer to this, do we want to stop `/voluntario` routing to Ashes as well at some point? What's the deprecation plan for these old campaigns?", "I don't see either of these on [their campaigns listing](https://www.dosomething.org/mx/campaigns), so I think we're okay to kill them.", "`rom` \ud83e\udd16\r\n\r\n![image](https://user-images.githubusercontent.com/105849/51199990-38614200-18c6-11e9-95b6-150de61f0202.png)\r\n", "`rom`: I had one of these, and it was awesome. Amazing that they're $100+ now! https://www.ebay.com/i/264107562226?chn=ps", "Sorry, that is out of the scope of the current PR.", "\ud83d\ude02 "]}, {"url": "https://github.com/DoSomething/infrastructure/pull/106", "comments": ["What's the necessity to provide a version here? Tracking with MySQL/MariaDB version?", "This is pretty damn cool \ud83d\ude04. Will this change existing RO passwords for Longshot/Rogue, or do we plan to?", "This pins the version of the Terraform provider, and is suggested so that we don't accidentally pull in a major version upgrade with breaking changes.", "It won't at first, since those are stored under different user names (`longshot_readonly` and `rogue_readonly` respectively). Once I've confirmed these new users are working, I'll update  Lastpass and notify folks to update their credentials before removing them."]}, {"url": "https://github.com/DoSomething/infrastructure/pull/99", "comments": ["Is this not recommended, since we don't want the S3 URI's to be directly accessible, except for from `rogue` domain serving them?", "Right! We want Rogue to be able to enforce access-control for these images (e.g. don't let anybody but admins view unapproved/rejected reportbacks). I think I'd also generally favor letting the app set ACLs per-object [when creating files](https://laravel.com/docs/5.7/filesystem#file-visibility) rather than sneakily making everything public via a bucket policy.", "\ud83d\udc79Totally agree. \ud83d\udcaf "]}, {"url": "https://github.com/DoSomething/infrastructure/pull/88", "comments": ["I think this needs to be `ashes_about` to match the change in `ashes_init.vcl` \ud83d\udc7e ", "Yeah, that was stinky. Updated!"]}, {"url": "https://github.com/DoSomething/infrastructure/pull/74", "comments": ["@sheyd The comment refers to Premium-5, but on the [Heroku Postgres docs](https://devcenter.heroku.com/articles/heroku-postgres-plans#premium-tier) I see 120 MB associated with the Premium-6 tier. Am I missing something?", "@mshmsh5000 Do you mean 122GB RAM size? I'm not seeing the param stats published on the page you linked, and I did a `show all` on a Premium-5 Heroku DB earlier this morning, and the `work_mem` Postgres parameter was `120MB` \ud83e\udd14 \r\n"]}, {"url": "https://github.com/DoSomething/infrastructure/pull/69", "comments": ["Did we want to add `deletion_protection  = true` as a default value, or keep as `false`, and specify `true` manually for Prod instances?", "Ah yes!! Let me add that in a follow-up PR so this one stays as a no-op."]}, {"url": "https://github.com/DoSomething/infrastructure/pull/67", "comments": ["What's `gp2`? Would it be worth adding a comment here?", "Do we want this to be `false` for if we do ever delete this?", "What's this tag used for?", "It's default config, so removing this line.", "\ud83e\udd14 yeah, probably, even though it'll change the value.", "Honestly, no clue, but I don't remember adding it to the RDS instance creation, so in case something referred to it, I left it in just in case.", "Looks like it's [automatically added by AWS](https://forums.aws.amazon.com/thread.jspa?threadID=208410). If we're not using it for anything, let's remove.", "Removed in commit below.", "Do we need to set [`vpc_security_group_ids`](https://www.terraform.io/docs/providers/aws/r/db_instance.html#vpc_security_group_ids) on this instance with the security groups you created above?", "Security groups are for \ud83d\udc38. All ports open all the time!\r\n\r\nGood catch, and added it into config via latest commit.", "One last nit-pick \u2013 let's use actual booleans for these even though Terraform doesn't care:\r\n\r\n```suggestion\r\n  deletion_protection    = true\r\n```", "`Suggested change Beta` boolean update complete."]}, {"url": "https://github.com/DoSomething/infrastructure/pull/62", "comments": ["I wonder if there's a good way to take `name` on resources that have it and automatically create a tag... \ud83e\udd14 ", "This means all protocols? Should we make an inline comment explaining that?"]}, {"url": "https://github.com/DoSomething/infrastructure/pull/59", "comments": ["Thought from something in you mentioned in another PR related to this issue the other day. Is this module maybe better put in `shared` module, if we want to use it across properties? Or are we not sure we want to stick with New Relic, and this is our first test to see how we like it on Heroku? ", "Sorry, which module are you referring to here? The overall `longshot/application` module?", "Chatted this through IRL. For anyone else who's following along \u2013 the `with_newrelic` variable here is just an argument for the module (think of it as a parameter you'd pass a function in other languages), so it's inherently tied to this module and isn't something we could reasonably extract.\r\n\r\nWe could definitely extract pieces of this `longshot/application` module into more reusable chunks for elsewhere (so say, bundling the `aws_ssm_parameter` & `heroku_addon` into a `shared/heroku-newrelic` module that exports the expected config values) and I'm planning on tackling that further in #28 after this app is wrapped up."]}, {"url": "https://github.com/DoSomething/infrastructure/pull/52", "comments": ["does this mean we trust everything?", "Yup, since we don't know the IP addresses for Heroku's load balancer. If we were hosting this behind a service with a known IP address (like we used to do in AWS), we could have set that here instead.", "And if so, would having the HA Proxy IP address be listed here be a better solution? Or is this a requirement for HTTPS to work properly at all?", "@sheyd I don't believe we can do that, since requests still pass through Heroku's load balancer which does not have a static IP. Happy to dig into this together if you're uncomfortable!", "That's a good point. No, just confirming I understand what this does. Heroku LB provides it's own layer of protection, and restricting large content blocks from accessing the site isn't really a huge priority for this app. Let me know if you want to setup the HA Proxy setup together before EOD."]}, {"url": "https://github.com/DoSomething/infrastructure/pull/51", "comments": ["@DFurnes Checking that we don't have any special parameter groups for the RDS instance we need to specify here? ", "Is `database_scale` a Terraformism, or can we control the name of this var? ", "For clarity, the name seems unclear at a glance, and something like `database_storage_size` or something like that would be clearer, I think. ", "That's a fair point! I'd just used `scale` for consistency with other variables here.", "Nope, this instance is just using the default parameter & option groups for MariaDB 10.0.", "Good to double-check! \ud83d\udc4d ", "Renamed `database_scale` to `database_size` and added a description to clarify!", "this is music to my ears!", "\ud83c\udfb8 \ud83d\udd08 \ud83c\udfb9 ", "Hey Dave, is this file a copy of some other .tf in DS codebase with minor modifications?", "who checks this email?", "was \"version\" this auto-generated or manual?", "This is used to differentiate between [versions of AWS's policy schema](https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_elements_version.html). Not super clear why they don't just use `v1` and `v2`, haha. \ud83e\udd37\u200d\u2642\ufe0f ", "This is an email group that currently consists of Matt, Morgan, Gleb, and myself. Dave, did we add you to this? If not, we should.", "I believe the `devops@dosomething.org` address forwards to Matt, Sena, and Morgan. It actually may be worth removing this environment variable in Longshot, since I believe this \"from\" address is actually set by a value stored in the application's database in most cases.", "Sort of. I'd previously configured each application instance independently (for example, [northstar](https://github.com/DoSomething/infrastructure/blob/22bbb8a7c0b901dde3269d509589b91ea48525a1/dosomething/northstar/main.tf) and [northstar-dev](https://github.com/DoSomething/infrastructure/blob/master/dosomething-dev/northstar/main.tf)). This is a first stab at standardizing this configuration into reusable modules that we can share amongst environments or similar apps.", "Oh, @sheyd beat me to it! Nope, I don't think I'm on this group but may just not have noticed.", "@DFurnes we still need an email set in the environment because that is what the password reset via Laravel pulls from", "\ud83d\udca1 ", "@katiecrane Ahhh, that explains it! \ud83d\ude47 ", "General suggestion, not necessary to address in this PR: it is good to branch/clone whatever the existing file so that we get a diff in git. I think this reduces cognitive burden on the reader and in the absence of templates .tf files allows to see which sections are shared among apps. I would imagine one possible option: northstar being copy of northstar-dev. ", "And another nit, once you do create a common template, it might make sense to add comments around parts that are not self-explanatory.", "Thank you! and hey Kathie! Might be worth adding a comment with Katie's explanation.", "ty!", "maybe add a header comment saying this is a template and you expect instantiations of this template to initialize variables you listed in the beginning and didn't assign any value.  It might make sense to group all the unassigned values together, to help the reader out. Also might be good to separate required and optional (with comments)", "nit: add a comment with units (GB).", "is \"_dev\" indicates _dev environment? if so, it shouldn't be hardcoded in template and be taken as a var.", "are all these defaults assume prod instance? maybe specify what defaults are good for. It might also be good to have separate templates with defaults for different environments: qa, dev, staging, prod.", "I don't know enough about this. But will the username always be in rds? if you can see it changing, consider declaring it as a const in the beginning of the file.", "region should be a parameter for template", "env should be a parameter", "debug should be conditional on env, if prod then false if dev then true.", "if there are constants in tf, might make sense to define the constant in the beginning of the file.", "We'll likely use the same values here for all instances of this application.", "Yep! This \"data resource\" loads the configuration variable from [AWS's Parameter Store](https://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-paramstore.html), so this can basically be considered a constant.", "Good idea! I've updated documentation for these in #55.", "Renamed this variable to `database_size_gb` for clarity in #55.", "Good point, renamed to `papertrail_destination_fastly` in both places in #55.", "I don't think we'll be creating applications in non-US regions anytime soon (even when we re-open global traffic, we'll likely let Fastly handle local POPs for us), so this seems safe to leave as a hard-coded string to me.", "We want to enforce this setting for `APP_DEBUG` on all instances that are publicly accessible, since Laravel uses this to determine whether to display full stack traces & environment dump on errors. If we set `APP_DEBUG` to \"true\", we'd give away secrets!", "Yep, Terraform has [local values](https://www.terraform.io/docs/configuration/locals.html) which act as constants. Since this value won't be used elsewhere, I'm going to just add a comment to this line to better explain it's usage in #55.", "We've tended to just set this to `production` across the board, but definitely could be useful to use actual environment names here. I've updated this in #55."]}, {"url": "https://github.com/DoSomething/infrastructure/pull/45", "comments": ["I get the GMT conversion, but what does the `(-1)` do? I see reference to it in Fastly docs too, but I don't get it. ", "Yeah, it's awkward isn't it? I believe that just creates an \"invalid\" date, which signals that the fallback parameter for `std.time` is unused (since a compile error is thrown if you assume it's optional and leave that second parameter empty).", "Ah wow \ud83d\udc4d \ud83e\udd14 \u2796 1\ufe0f\u20e3 \ud83e\udd14 \ud83e\udd14 \ud83e\udd14 emoji"]}, {"url": "https://github.com/DoSomething/infrastructure/pull/43", "comments": ["This is so funny! Terraform's formatter seems to get confused by the commented out block above and removes spacing between all subsequent parts of this resource. Doesn't seem to cause any issues besides an ugly diff."]}]}, {"url": "https://github.com/graymeta/terraform-aws-platform.git", "pull_requests": [{"url": "https://github.com/graymeta/terraform-aws-platform/pull/196", "comments": ["Check your format here", "Maybe backtick the 'Single Sign-On with SAML'", "fixed", "fixed"]}, {"url": "https://github.com/graymeta/terraform-aws-platform/pull/181", "comments": ["Can you make it more explicit that the reindex is to be run after:\r\n* the database has been upgraded to 11.5\r\n* terraform apply has been run to deploy the new version\r\n\r\n", "Just pushed a change.  Let me know if that makes more sense."]}, {"url": "https://github.com/graymeta/terraform-aws-platform/pull/180", "comments": ["s/is not/is now/"]}, {"url": "https://github.com/graymeta/terraform-aws-platform/pull/179", "comments": ["set the default to `20s`. It uses a time.Duration, so will parse that correctly."]}, {"url": "https://github.com/graymeta/terraform-aws-platform/pull/163", "comments": ["s/paltform/platform/", "s/amazone/amazon/"]}, {"url": "https://github.com/graymeta/terraform-aws-platform/pull/128", "comments": ["s/setup a internal/setup an internal/", "s/credits and slates was/credits and slates were/\r\ns/now they are separate module/now they are separate modules/\r\n\r\nwhat does it mean that the \"module does not change\"?", "should this soccer reference be removed since it's discussed below in the `All the other extractors` section?", "Let me rephrase s/module does not change/module name does not change/.\r\nAs long as the module name does not change the RDS will not have to be destroyed and recreated.", "soccer?  Are you asking about the \r\n```\r\n  # (Optional) Graymeta ML Services\r\n  mlservices_endpoint = \"${module.ml_network.endpoint}\"\r\n```\r\nSo that ml_services_endpoint is what goes into the no_proxy on services and ecs.  Let my try something different here."]}, {"url": "https://github.com/graymeta/terraform-aws-platform/pull/117", "comments": ["Previously we had the usage bucket ARN as a variable, now we're also requiring the bucket id/name to be passed in (instead of using the existing ARN). Is there a way to just use the existing ARN so they don't have to specify the same input parameter twice?", "I was looking at how to do that also.  The only way I found is the parse the bucket name out of the arn.  Which I can do.  They have a way to look up the arn by using the id, but not a way to look up the id from the arn.  ", "do you actually need just the bucket name though? it looks like you're only ever using the ARN?"]}, {"url": "https://github.com/graymeta/terraform-aws-platform/pull/106", "comments": ["Should this be port 8443?", "Can we name_prefix and port to 7009"]}, {"url": "https://github.com/graymeta/terraform-aws-platform/pull/99", "comments": ["s/ECS instance are recreate./ECS instances are recreated./", "Once they're output, what does someone do with them?", "what happened to the port 80 listener? What redirects from :80 -> :443?", "Right now I have ECS and Services connecting to faces on http port 10336, credits on http port 10337, and slates on http port 10338.  Which connect directly to the api.  I did not install nginx with basic auth since these servers are all internal with a internal loadbalancer.  Let me know if you want me to change that.", "Before I had 80 -> going to 10336"]}, {"url": "https://github.com/graymeta/terraform-aws-platform/pull/66", "comments": ["IMO we should just make this the default.\r\n\r\nDoes this mean that if I had an s3 bucket in a different region that I'd still be routing through the NAT gateways to get there? Example: platform deployed in us-west-2 but bucket in us-east-1.", "I agree to make it the default which I did.  I will remove the option to turn it off.  No real reason not to have it.\r\n\r\nIt does not work cross region, so it will go through the NAT gateway to get there.  So it is only beneficial if your buckets are in the same region. "]}, {"url": "https://github.com/graymeta/terraform-aws-platform/pull/65", "comments": ["Should we only echo the values to the file then run a `sysctl -p` to pick them up?"]}, {"url": "https://github.com/graymeta/terraform-aws-platform/pull/35", "comments": ["Does one even need the curly braces?", "I am pretty sure the answer is yes"]}, {"url": "https://github.com/graymeta/terraform-aws-platform/pull/28", "comments": ["please keep this list in alphabetical order", "keep alphabetical order", "maintain alphabetical order", "Let's add a default of an empty string to these two variables, that way existing deployments won't have to change anything unless they opt-in for box support."]}]}, {"url": "https://github.com/wri/gfw-aws-core-infrastructure.git", "pull_requests": [{"url": "https://github.com/wri/gfw-aws-core-infrastructure/pull/95", "comments": ["I see you parameterised this at the postgresql module level but hard-coded it at the top level here. If the intention is to enable environment specific version (saw that in commit message unless I misunderstood), we should parameterise it at this level as well.", "Good catch, @solomon-negusse. Yes, I can very well imagine that different versions will be needed for different environments. I'll make that change. \ud83d\udc4d ", "@solomon-negusse, the change is in commit: 3fd31b36e90e858433ca89646951ef3493506a13"]}, {"url": "https://github.com/wri/gfw-aws-core-infrastructure/pull/85", "comments": ["can you please add my id_rsa.pub to the list. \r\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQDI3Vd+ksZNDpkxKLdwgHD5FZ8ngUk7Xvj9cV9nlGQ90ti77d+QtqRjGYpCmechizl5BEaaT9xi1DH8W7h3Isu85CnuAQqwb5lZMKDGsEzQTzxZ7h3AuMFkMNrN3d7PupwFifLVXmQF5R7E9I0EIGTrtnrINrzWMuU4VxVu3N0z3VDdkAvOAPDARaggr9K5zvmxB8NQ0iXCafNFk5bsddour/yxmWXxT7M3+qDB3CcHVzFqtMKVPyAs9HSuEfNBpenSTyNCMw78Bn7uvTzZdVlLIfmvz4H17pwKnoQTf3TEzTmpKg8A3XaqbHVrFODr7zl11tVxykA5nsy+FdeRu2z8quUji/qK0tStAd/1F6a19bLZ1rvlZp5uGbQnMuqNqiuEJs0F90VqcaEZ1wZe7d6EFPr++Yby2hUEo/eh3X8aSg50uog5S4f3pnbzB6RTB1dwLZWMo/tTx0UW/SavrbTcQlCOm31uKfJWkOgVW/lVikPq0O7k903OMIPPMSkCJ3U= iuripopov@Iuris-MacBook-Pro.local"]}, {"url": "https://github.com/wri/gfw-aws-core-infrastructure/pull/47", "comments": ["I would name this variable just `suffix` since in this context we use as for the topic name.\r\n\r\nThis leads to my other querstion: do we need the suffix at all? Do topic names need to be unique across all accounts? Otherwise you can just give it the same name in all environments.", "It's a good question. I guess we don't really, I was just trying to stick with what seemed like a convention (with S3, for example). Including the env in the name makes it slightly less convenient but slightly harder to succeed when accidentally doing things in the wrong environment. I'll remove it.", "For S3, bucket names have to be unique across all accounts. Other than that we only use suffixes for feature branch deployments. In the core repo everything will be deployed to the default workspace and their will be only one resource per account."]}, {"url": "https://github.com/wri/gfw-aws-core-infrastructure/pull/43", "comments": ["think you need to move the policies to the module folder"]}, {"url": "https://github.com/wri/gfw-aws-core-infrastructure/pull/23", "comments": ["Route for fire tile cache. Commenting out for now as this is still in dev. I plan to move the tile cache distribution out of the core repo and move it into the gfw-tile-cache repo"]}, {"url": "https://github.com/wri/gfw-aws-core-infrastructure/pull/17", "comments": ["what's this giant commented out block? ", "In dev I created a lambda function which works like a file browser. It reads all the files in the current folder and renders a HTML page.\r\nI deactivated it for now, since I am not 100% sure if we actually need that. But didn't want to get rid of the code."]}, {"url": "https://github.com/wri/gfw-aws-core-infrastructure/pull/12", "comments": ["usually the standard root volume size is 8GB.\r\nThat should be more than enough.\r\n\r\nAll other data should be written to the ssd drives", "If we can only pick 2 families I would go for r5d and c5d. \r\nThe i family has extra storage, but this is usually not the bottleneck and when scheduling a job, we cannot specific this metric.\r\n\r\nWith r and c family we can choose between compute vs memory optimize.\r\nWhat is odd is that I could specify all listed families when creating the compute environment via the console"]}, {"url": "https://github.com/wri/gfw-aws-core-infrastructure/pull/5", "comments": ["small typo on \"secrets\"", "why was this commented out?", "so is this just a policy other resources can use to access the token?", "yes, you can attach this policy to the role which needs access to the secret. Do this instead of giving wildcard permissions to read all secrets", "for this repo, we don't want to have separate workspaces for feature branches.  Here we manage s3 buckets, cloud front destributions etc. Having multiple versions of these resources in dev would make things overly complicated", "caution!\r\nbranch `develop` == staging environment \r\nThe way it was was correct", "I commented this out, b/c we don't need to plan for pull requests from dev environments to dev environemnts"]}]}, {"url": "https://github.com/bulentyuce/OkeTerraform.git", "pull_requests": []}, {"url": "https://github.com/hashicorp/terraform-azurerm-terraform-enterprise.git", "pull_requests": [{"url": "https://github.com/hashicorp/terraform-azurerm-terraform-enterprise/pull/216", "comments": ["```suggestion\r\n  to redirect requests for the installation's FQDN to the instance's internal IP address.\r\n```"]}, {"url": "https://github.com/hashicorp/terraform-azurerm-terraform-enterprise/pull/213", "comments": ["This looks like a bigger change than it is. I'm just alphabetizing here."]}, {"url": "https://github.com/hashicorp/terraform-azurerm-terraform-enterprise/pull/209", "comments": ["```suggestion\r\n```\r\nSince the root module already defaults to `Default`, let's leave the default value off of this module.", "```suggestion\r\n```\r\nSame here. Let's leave it to the root module to default the values."]}, {"url": "https://github.com/hashicorp/terraform-azurerm-terraform-enterprise/pull/199", "comments": ["```suggestion\r\n  tunneling_enabled = var.bastion_sku == \"Standard\" ? var.bastion_tunneling_enabled : false\r\n```"]}, {"url": "https://github.com/hashicorp/terraform-azurerm-terraform-enterprise/pull/176", "comments": ["```suggestion\r\n1. For instances requiring an SSH proxy you must have a local copy of the bastion\r\n   SSH private key.\r\n```"]}, {"url": "https://github.com/hashicorp/terraform-azurerm-terraform-enterprise/pull/171", "comments": ["```suggestion\r\nlocation                             = \"East US\"\r\n```", "You changed this to external, right?", "Since we don't know which image they will use, we should add both paths.\r\n\r\n```suggestion\r\n        - for Red Hat - `/usr/share/pki/ca-trust-source/anchors/tfe-ca-certificate.crt`\r\n        - for Ubuntu - `/usr/local/share/ca-certificates/extra/tfe-ca-certificate.crt`\r\n```", "I don't believe these are needed here.\r\n```suggestion\r\n```", "```suggestion\r\n# Run TFE root module for Standalone Airgapped External Mode\r\n# ----------------------------------------------------------\r\n```\r\n\r\nfor consistency w/AWS module", "```suggestion\r\n# Create files for SSH config\r\n# ---------------------------\r\n```", "```suggestion\r\nlocation                = \"Central US\"\r\n```", "```suggestion\r\n# EXAMPLE: Standalone External Airgapped Installation of Terraform Enterprise\r\n```\r\nThis is external, right?", "```suggestion\r\n# EXAMPLE: Standalone External Airgapped Installation of Terraform Enterprise\r\n```", "Should this be external?", "Usually we wouldn't have both of these true, as you only need one or the other.", "Would you mind alphabetizing these for consistency's sake?", "```suggestion\r\n# Create files for SSH config\r\n# ---------------------------\r\n```", "```suggestion\r\nlocation                       = \"Central US\"\r\n```", "```suggestion\r\nlocation                       = \"Central US\"\r\n```", "updated", "updated", "done!", "for other examples, we decided to use \"region\" instead of explicit locations. ", "Oh darn, can you change them to a specific region example?", "okay, np!\r\n", "```suggestion\r\n# Standalone, External Mode, Airgapped Installation Example\r\n# ---------------------------------------------------------\r\n```", "```suggestion\r\n# Create files for SSH config\r\n# ---------------------------\r\n```", "I'm curious why you chose to use SSH instead of the Azure Bastion for this example. Seems like Azure Bastion would be the more secure option, and we only suggest SSH for dev environments.", "```suggestion\r\n                           Description = \"Standalone, External Mode, Airgapped scenario\"\r\n```", "Again, this should be an actual example value.", "Here, I can see why you chose SSH over Azure Bastion, because we clearly call it out as a dev environment.", "you are right, removing ssh", "Oh I'm sorry, this was my bad. I didn't realize it was in the middle of the block (which wouldn't need the underlining. \r\n```suggestion\r\n  # Standalone, External Mode, Airgapped Installation Example\r\n```", "```suggestion\r\nlocation                       = \"Central US\"\r\n```"]}, {"url": "https://github.com/hashicorp/terraform-azurerm-terraform-enterprise/pull/170", "comments": ["Just adding a return between blocks for consistency.\r\n\r\n```suggestion\r\n\r\nprovider \"azurerm\" {\r\n```", "Something I didn't catch in the AWS examples was that the `active-active` example had a proxy. Ideally, we'd have an `active-active` without proxy, but that's okay because we need a proxy example, too, so this will not go to waste. Can you rename it to `active-active-proxy`, and then add another `active-active` example that resembles the `public-active-active` test?", "Also, can you do the same for the AWS examples?", "@anniehedgpeth  AWS already covers public-active-active as part of \"existing-image\", is that enough ? [Task](https://app.asana.com/0/1200681690870921/1202269644028418/f) added for Azure", "Ah perfect, thanks!!"]}, {"url": "https://github.com/hashicorp/terraform-azurerm-terraform-enterprise/pull/169", "comments": ["It's a little confusing when we use `<generic_variable_name>` sometimes and `my-rg` (for example) in the same variable example. I would like to see these consistently one way or the other. Both are valid, but it should be consistent.\r\n\r\nChoice 1:\r\n\r\n```\r\nkey_vault_id                         = \"/subscriptions/<subscription_id>/resourceGroups/<resource_group_name>/providers/Microsoft.KeyVault/vaults/<key_vault_name>\"\r\n```\r\n\r\nChoice 2:\r\n```\r\nkey_vault_id                         = \"/subscriptions/01234-abcde-5678/resourceGroups/my_resource_group/providers/Microsoft.KeyVault/vaults/my_key_vault\"\r\n```\r\n", "Last thing! This should be an example of a region instead of the word \"region\".\r\n```suggestion\r\nlocation                             = \"East US\"\r\n```"]}, {"url": "https://github.com/hashicorp/terraform-azurerm-terraform-enterprise/pull/166", "comments": ["Since the `backend_address_pool` is now a set instead of a list, we need to iterate over the set and find the ID for the backend address pool that matches the backend address pool name we created. Since the literal `for` syntax is wrapped in `[]`, our result is a list of strings (IDs), we use `[0]` to get the first string (ID) in that list.", "Is there a reason to pin the patch and not the minor? We'd prefer minor patching on all things.", "In this file no there's no reason. The actual workspace where the tests execute was using 1.0.9, the Setup Terraform action was using 0.14.8, and the version constraint here was using `>= 0.13`. Now they all use 1.0.9.\n\nI can loosen this to `>= 1.0`.", "Cool, can we do that in the providers, too?", "Providers are already done. They are using the pessimistic version constraint (`~>`) which allows the rightmost version number to increment. So `~> 1.0.9` would allow `1.0.9`, `1.0.10`, etc but not `1.1.X`.", "I updated the provider version constraint to allow newer minor versions. The Terraform CLI version constraint still only allows patch releases so it'll stay on `1.0.X`.", "Cool, thanks. I'll test one more time before merging."]}, {"url": "https://github.com/hashicorp/terraform-azurerm-terraform-enterprise/pull/161", "comments": ["Would you mind lining this up with the beginning of `description` for consistency's sake? "]}, {"url": "https://github.com/hashicorp/terraform-azurerm-terraform-enterprise/pull/159", "comments": ["```suggestion\r\n\r\n# Create a subnet for proxy\r\n```", "Don't forget to change this to your branch name instead of `main` when you run your tests.", "Can you update this for Azure?", "Can you update this for Azure?", "done", "done"]}, {"url": "https://github.com/hashicorp/terraform-azurerm-terraform-enterprise/pull/155", "comments": ["Can it just be `local.disk_mode ? 0 : 1` does a string value `\"true\"` not translate to an int?  ", "Yep! It can be `count = local.disk_mode ? 0 : 1`.\r\n\r\nI left it as `count  = local.disk_mode == true ? 0 : 1` because it's consistent with the rest of the codebase. For example, `count  = local.active_active == true ? 1 : 0`.", "Alright that's fair, consistency! ", "It's on the backlog! \ud83d\ude2c ", "```suggestion\r\n  source = \"git::https://github.com/hashicorp/terraform-random-tfe-utility//modules/settings?ref=main\"\r\n```"]}, {"url": "https://github.com/hashicorp/terraform-azurerm-terraform-enterprise/pull/146", "comments": ["These are the certificate and key for the VM, not for a CA, as the application gateway requires its backend to also have a trusted TLS certificate.", "Just to keep things more flexible:\r\n```suggestion\r\n      version = \"~> 3.0\"\r\n```", "Same comment here about being for the VM, not of a CA."]}, {"url": "https://github.com/hashicorp/terraform-azurerm-terraform-enterprise/pull/143", "comments": ["This line should be split up for improved gitability \ud83e\ude98 "]}, {"url": "https://github.com/hashicorp/terraform-azurerm-terraform-enterprise/pull/142", "comments": ["Note for posterity: we still need to determine how and when to use objects over primitive variables.", "I've opened https://github.com/hashicorp/terraform-random-tfe-utility/pull/5 to remove this argument and instead infer `redis_port` from `redis_use_tls`. I think we can standardize this module on the `use_tls` argument to align with the settings.", "Outputs should use attributes of resources when possible, rather than returning variable inputs, as using variables won't affect the dependency graph as one may expect.\r\n\r\nMore generally, I think it would be preferable to have a single output of the entire `azurerm_redis_cache` resource, but it's not necessary to address at this point.", "Hey @aaron-lane, take a look at the latest commit and lmk if that's more in line with what you're thinking. If so, I'll test again (just don't want to run the tests if there are more changes I need to make)."]}, {"url": "https://github.com/hashicorp/terraform-azurerm-terraform-enterprise/pull/136", "comments": ["I suggest that we make the empty values `null` if possible, to align with the \"no special strings\" approach.", "```suggestion\r\n  description = \"The Key Vault secret value which will be used for the vm_key_secret variable in the root module.\"\r\n```", "What do you think about making the interface consistent in terms of expecting file contents rather than pathnames? It generally makes things more flexible to not hardcode `file()` type calls around module variables, even if the license does seem like an obvious one for being a pathname.", "It looks like this \"wildcard\" reference is leftover:\r\n\r\n```suggestion\r\n  private_key_pem = {\r\n    name  = \"my-private-key-pem\"\r\n    value = file(\"/path/to/private-key.pem\")\r\n  }\r\n  chained_certificate_pem = {\r\n    name  = \"my-chained-cert-pem\"\r\n    value = file(\"/path/to/chained-certificate.pem\")\r\n  }\r\n```", "We should remove the \"mitmproxy\" language. The CA certificate could be unrelated to the proxy.", "Oh certainly. I went back and forth on that, but if you're thinking it, too, then I'll do it.", "On second thought, this is not ideal since we'd be entrusting the user to Base64 encode the file. The current way ensures that it is properly encoded."]}, {"url": "https://github.com/hashicorp/terraform-azurerm-terraform-enterprise/pull/126", "comments": ["Since this `var.user_data_installation_type == \"poc\" ? null` check is already used on `module.object_storage.count`, we can DRY this logic by checking the length of the module collection:\r\n\r\n```suggestion\r\n  value       = length(module.object_storage) > 0 ? module.object_storage[0].storage_account_name : null\r\n```", "I forgot to include a comment to this logic when it was added to the `service_accounts` module \ud83d\ude0a \r\n\r\n```suggestion\r\n  # Ensure the name is 24 alphanumeric characters as required by Azure.\r\n```\r\n\r\n", "We should avoid adding new defaults to submodule variables since we ultimately want to remove them all.", "The result of this string equivalency check should be captured as a local value to mitigate against special string spelling bugs.", "Logic like this could be simplified by defining a local like\r\n\r\n```hcl\r\ndatabase = length(module.database) > 0 ? module.database[0] : { \r\n  name = null\r\n  address = null\r\n  administrator_login = null\r\n  administrator_password = null\r\n}\r\n```\r\nwhich allows us to avoid repeating the same check for every field. Ideally, we should also change submodule interfaces to accept objects so that we don't have to decompose other submodules and resources in the root module.", "I think this logic should be internalized within the `user_data` submodule, similar to how `placement` is determined.", "What was the motivation for this change?", "Same question about why this is changing. I assume it's related to the change of the local value.", "I think this string should be adjusted for consistency with the directory name:\r\n\r\n```suggestion\r\n    Environment = \"${local.friendly_name_prefix}-test-standalone-poc\"\r\n```", "Since this is required to ensure that both the dedicated subnetwork and private DNS zone are created, could we manage this dependency internal to the `network` submodule?", "I can change it back and see if it's okay, but I did get another NGINX error about the url length being too long.", "Right", "Ah okay. We should double check that Nginx fix was released \ud83d\ude05", "Yeah, this was fixed with v202110-1 so we should be fine to revert this.", "Added a dependency on the VNET by the database's private DNS zone \ud83e\udd1e ", "This was accidentally included in #127 but it's not needed:\r\n\r\n```suggestion\r\n```", "This logic will always trigger as there are elements in both lists.\r\n\r\n```suggestion\r\n    for_each = var.create_bastion == true ? [1] : []\r\n```", "Shoot, I thought I removed this.", "I think we can safely add a default of `\"production\"` for this variable.\r\n\r\n```suggestion\r\nvariable \"user_data_installation_type\" {\r\n  default     = \"production\"\r\n```"]}, {"url": "https://github.com/hashicorp/terraform-azurerm-terraform-enterprise/pull/121", "comments": ["```suggestion\r\n  via `az keyvault secret set`). Uploading them manually through the Azure\r\n```", "Are you still waiting on this?", "Oh, thanks!", "Fixed with https://github.com/hashicorp/terraform-azurerm-terraform-enterprise/pull/121/commits/6933980fe0d34749134ae98f6bb680605c7e16a8."]}, {"url": "https://github.com/hashicorp/terraform-azurerm-terraform-enterprise/pull/118", "comments": ["Does this need to be the admin user? [bastionuser](https://github.com/hashicorp/terraform-azurerm-terraform-enterprise/blob/main/tests/private-active-active/bastion_vm.tf#L88)?", "Right you are! Fixed with https://github.com/hashicorp/terraform-azurerm-terraform-enterprise/pull/118/commits/e989f9b5c9ff836981ccc95cbbee8bc3e7f8f296"]}, {"url": "https://github.com/hashicorp/terraform-azurerm-terraform-enterprise/pull/114", "comments": ["This is great additional context for the users!\r\n\r\n```suggestion\r\nAs stated in the [prerequisites](##Pre-requisites), there are a number\r\nof variables concerning certificates and secrets. This section provides \r\nadditional context on\r\n```\r\n", "> It will also be placed on the Application Gateway if that is your load balancing option\n\nI think using this same certificate input on app gateway and the VMSS worked because we tested with a wildcard certificate, but we can't assume this same input will be valid to use in both places simultaneously. Assuming that's correct, we will need two optional inputs to manage the app gateway and VMSS certificates separately (though continue passing the same wildcard certificate to both in the tests).", "> If you do not need to customize your certificates to add an intermediate or root, then you will not need to use the `TlsBootstrap*` variables\n\nMost of the `TLSBootstrap*` configuration settings are presently hard-coded so I think this statement can be removed for clarity.", "The `service_accounts` module does not have a `certificate` output. `terraform validate` seems to miss this issue because of the ternary operator.", "Same issue here about `module.service_accounts.certificate`. Also, should this be the key fingerprint rather than also the certificate fingerprint?", "We need to consider reconcile the `user_data_ca` input and the `proxy_cert*` inputs. The latter two are named a bit misleading, as they are actually inputs for a CA certificate bundle, and currently `proxy_cert_name` causes the value of `ca_certs` defined by `user_data_ca` in `user_data` HCL to be overwritten later in `tfe.sh.tpl`. I think they were conflated with the concept of a proxy because we were originally testing with untrusted certificates for mitmproxy. \n\nI suggest that we replace these three inputs with a single `ca_cert_secret_name` that we can use in the existing `proxy_cert` shell function (which would also be renamed). `proxy_ip` would remain unchanged as that is a separate concept.", "Good catch. The logic changed, and this was supposed to have been taking the values from `certificate_name`, but I'll need to change the output to the whole certificate, not just the name.", "It's the certificate thumbprint, and the same one is used for both.", "Agreed. I didn't want to make any major changes to this until we added the `private-active-active` example."]}, {"url": "https://github.com/hashicorp/terraform-azurerm-terraform-enterprise/pull/109", "comments": ["Just a thought, not sure if we want to echo log here", "Never mind, i understood now why it's needed"]}, {"url": "https://github.com/hashicorp/terraform-azurerm-terraform-enterprise/pull/105", "comments": ["Suggestion to fix a couple of capitalization issues and attempt to clarify how the license must be provided.\r\n\r\n```suggestion\r\n- A Terraform Enterprise license file is required, and it must be provided as either a Base64 encoded secret in Azure Key Vault OR a file on the local filesystem. An empty placeholder `license.rli` file exists in each example within a `./files` directory and serves as a reference `tfe_license_filepath = \"${path.module}/files/license.rli\"`.\r\n```", "If we changed `var.key_vault_name` to `var.key_vault_id`, I think it would align with the format of ID inputs that the network submodule accepts and remove the abstraction that motivates the use of a key vault data source in this and other submodules. The only caveat seems to be the `user_data` submodule which on first glance does require the name, but perhaps we can obtain the key vault's name or base URL from some of the resources in this submodule.", "It seems reasonable to rename this submodule to `key_vault` or `secrets` given that it is no longer solely focused on certificates.", "```suggestion\r\n  description = \"Name of the secret under which the Base64 encoded Terraform Enterprise license is (or will be) stored in the Azure Key Vault.\"\r\n```", "```suggestion\r\n  - Base64 encoded TFE license (secret)\r\n```", "```suggestion\r\n  description = \"Name of the secret under which the Base64 encoded Terraform Enterprise license is stored in the Azure Key Vault.\"\r\n```", "```suggestion\r\n  - Base64 encoded TFE license (secret)\r\n```", "```suggestion\r\n  description = \"Name of the secret under which the Base64 encoded TFE license is stored in the Azure Key Vault.\"\r\n```", "```suggestion\r\n  - Base64 encoded TFE license (secret)\r\n```", "```suggestion\r\n  description = \"Name of the secret under which the Base64 encoded TFE license is stored in the Azure Key Vault.\"\r\n```", "```suggestion\r\n  description = \"Name of the secret under which the Base64 encoded TFE license is (or will be) stored in the Azure Key Vault.\"\r\n```", "The description for `var.key_vault_name` should be updated to clarify what the vault holds."]}, {"url": "https://github.com/hashicorp/terraform-azurerm-terraform-enterprise/pull/101", "comments": ["This variable `proxy_cert_secret_name` as well as `proxy_cert_name` are both commented out. Should they just be removed from here and the example README?", "Let's take this opportunity to DRY the definition of `certificate` since it is the same for both distributions.", "Honestly, this example is probably broken now. What do you think about removing the example and adding it to the backlog to fix it later?", "https://app.asana.com/0/1200094219584695/1200573545455801/f ", "Sounds good to me!", "Since we have to rely on a publicly accessible bastion host, I think we can reuse the logic from the AWS tests to [obtain the runner IP address](https://github.com/hashicorp/terraform-aws-terraform-enterprise/blob/main/.github/workflows/handler-test.yml#L72-L75) and restrict this accordingly. For now, that would just mean leaving this as a variable."]}, {"url": "https://github.com/hashicorp/terraform-azurerm-terraform-enterprise/pull/100", "comments": ["Might it be good to leave the variables in place for these values or does this not matter for the example?", "I thought so at first, too, but for the tests, because we don't intend for these to be used as examples, we don't really need variability for things like this that we don't intend on changing. The task states: \r\n\r\n> Because the test module will be used in a very specific manner, we can remove any aspects of the design that aren't relevant to the most optimal implementation for our CI purposes; this consideration includes things like optional variables and resources."]}, {"url": "https://github.com/hashicorp/terraform-azurerm-terraform-enterprise/pull/63", "comments": ["```suggestion\r\n  prefix           = \"${var.resource_prefix}-${random_string.install_id.result}\"\r\n```"]}, {"url": "https://github.com/hashicorp/terraform-azurerm-terraform-enterprise/pull/61", "comments": ["'Are there anything atypical' sounds awkward... maybe 'Is there anything atypical' instead?", "```suggestion\r\n<!--- Is there anything atypical about your accounts that we should know? For example: Running in EC2 Classic? --->\r\n```"]}, {"url": "https://github.com/hashicorp/terraform-azurerm-terraform-enterprise/pull/59", "comments": ["since we already export no_proxy above does it make more sense to build this off the existing one?\r\n\r\nalso looks like there's a typo here on the 0.0.0.0/8 instead of the 10.0.0.0/8\r\n`export no_proxy=10.0.0.0/8,127.0.0.1,169.254.169.254,$repl_cidr`\r\n```suggestion\r\n      export no_proxy=$no_proxy,$repl_cidr\r\n```"]}, {"url": "https://github.com/hashicorp/terraform-azurerm-terraform-enterprise/pull/49", "comments": ["I believe this will not plan properly.\r\n\r\nWhen performing this on my own, I had to update \"lb_port\" variable to be a dynamic type.\r\n\r\nHere is the declaration, the references will have to change a bit too.\r\n```\r\nvariable \"lb_port\" {\r\n  description = \"Expects map with format `name: [frontend_port, protocol, backend_port]` for all routes.\"\r\n  type = list(object({\r\n    name          = string\r\n    frontend_port = string\r\n    protocol      = string\r\n    backend_port  = string\r\n  }))\r\n}\r\n```\r\n\r\nAssigned:\r\n```\r\nlb_port = [\r\n    {\r\n      name          = \"cluster_api\"\r\n      frontend_port = \"6443\"\r\n      protocol      = \"Tcp\"\r\n      backend_port  = \"6443\"\r\n    },\r\n    {\r\n      name          = \"assist\"\r\n      frontend_port = local.assistant_port\r\n      protocol      = \"Tcp\"\r\n      backend_port  = local.assistant_port\r\n    },\r\n    {\r\n      name          = \"app\"\r\n      frontend_port = \"443\"\r\n      protocol      = \"Tcp\"\r\n      backend_port  = \"443\"\r\n    },\r\n    {\r\n      name          = \"console\"\r\n      frontend_port = \"8800\"\r\n      protocol      = \"Tcp\"\r\n      backend_port  = \"8800\"\r\n    }\r\n  ]\r\n```", "You are correct, but `lb_port` is `list(map(string))`, which should plan correctly. I have deliberately left setting this (and others like it) to `object` for the later iterations. \r\n\r\nI will change them to objects in a bit.\r\n", "Totally agree, baby steps.\r\n\r\nThis one in particular gave me issues with the plan and forced me to upgrade.\r\n"]}, {"url": "https://github.com/hashicorp/terraform-azurerm-terraform-enterprise/pull/48", "comments": ["I'm not sure if this is specifically needed. right now as the configs submodule doesn't create any Azure resources to be tagged.", "same comment as with https://github.com/hashicorp/terraform-azurerm-terraform-enterprise/pull/48/files#r357280123"]}, {"url": "https://github.com/hashicorp/terraform-azurerm-terraform-enterprise/pull/41", "comments": ["`False` needs to be `\"False\"`, ditto with True and the other instance of this."]}, {"url": "https://github.com/hashicorp/terraform-azurerm-terraform-enterprise/pull/31", "comments": ["At some point we may want to move these logs to a more standard location like `/var/log/`", "That's a really good point, agreed. "]}, {"url": "https://github.com/hashicorp/terraform-azurerm-terraform-enterprise/pull/26", "comments": ["is this going to cause issues in an airgap mode? (ie. accessing github directly)", "Hrm... yes... alternative is to variablize the url and set that as the default, I guess. That would allow an airgap customer to provide the package from another location. "]}, {"url": "https://github.com/hashicorp/terraform-azurerm-terraform-enterprise/pull/14", "comments": ["Can we add a comment along side this resource with the why? With a hard coded value we could very well come back and not recall the context for this."]}, {"url": "https://github.com/hashicorp/terraform-azurerm-terraform-enterprise/pull/8", "comments": ["Hey @erindatkinson I thought adding the CA var here, would allow me to create the file in the `cloud-init.yaml` ", ":point_up: "]}]}, {"url": "https://github.com/Ivani451/terragoat.git", "pull_requests": []}, {"url": "https://github.com/ivandelic/oci-devops-functions-blue-green.git", "pull_requests": []}, {"url": "https://github.com/offensive-terraform/terraform-aws-ebs-snapshot-publicly-exposed.git", "pull_requests": []}, {"url": "https://github.com/MartinFeineis/terraform.git", "pull_requests": []}, {"url": "https://github.com/IanDCarroll/StookyBill.git", "pull_requests": []}, {"url": "https://github.com/stuartellis/stuartellis-org-tf-modules.git", "pull_requests": []}, {"url": "https://github.com/greenbrian/musical-spork.git", "pull_requests": [{"url": "https://github.com/greenbrian/musical-spork/pull/33", "comments": ["vault login", "similarly for this one, if you wanted to display/demo in a terminal you could do\r\n`watch wget $(terraform output fabio | sed  -e 's/9999/9998/g'`", "don't have the source for this container, but is there a way to make this look more production like? source `VAULT_TOKEN` env variable?", "Old habits die hard"]}]}, {"url": "https://github.com/fahdr/asz-dbz.git", "pull_requests": []}, {"url": "https://github.com/kmalkin/tf-aws-pi-hole.git", "pull_requests": [{"url": "https://github.com/ev1lbunny/tf-aws-pi-hole/pull/14", "comments": ["not hyperlink"]}, {"url": "https://github.com/ev1lbunny/tf-aws-pi-hole/pull/10", "comments": ["Where do you store the remote state, which created the remote state bucket? ;)", "Would like to see both pi-hole and open-vpn optional", "should be using a query to find the AMI id, unless you need to pin it to a specific version of the AMI?", "Or pass it in as a variable.", "Same as previous comment with AMI ids", "specific versions. the scripts dont work on older 18 versions of ubuntu. \r\nBecause of how the silent installs work and the \"assumptions\" that the silent --unattended installs work it needs to be maintained away from a consumers control in order to maintain \"out the box working\"\r\n", "i looked at doing this... you cant have \"optional\" modules though. You cant use count : 0?! args etc in a module declaration. only option i looked at which wasnt all that neat. Was pass a bool into each module ..... and then add a count check in every resource inside the module. but that causes some issues with having to [0] array append resource refs. so it became really un-neat and ugly", "open to suggestions\r\n", "as per readme.. If you want to use remote state. then you have to run the `backend-state` content first if you want it to work out the box. again i looked at complex bool approach to turn on / off remote state usage.. but couldnt figure out a way of creating a logical switch inside the `terraform {}` definition", "I thought you could use count in version 0.13 modules now?\r\nhttps://www.hashicorp.com/blog/announcing-hashicorp-terraform-0-13", "Well at least pass it in as a parameter (default to the current working AMI ID) so it is flexible to change if required?", "R53 zone probably needs to be at the higher level or separate module to set it up.\r\nThink it would be unlikely to have a zone just for pihole and vpn?", "Just don't like hard coded IDs in the TF files.", "that makes sense.. i will variablise with defaults and description. that sounds like a gd plan", "will try this again .. I am definitely on the new 0.13 of tf.... and i tried a module based count call. and it didnt validate. count argument unexpected here ... error was thrown each way i tried it.. Hmmmm. I will re implement and have a look at the docs and see since i really did want this optional setup too", "might be introduced in the new 0.13.4 instead of 0.13.3\r\n", "Looks like it was released yesterday\r\nhttps://github.com/hashicorp/terraform/blob/v0.13/CHANGELOG.md", "i got module optionals working. now i just have the issue that if you choose not to have either ec2 instance the \r\n\r\n```\r\noutput \"pi_hole_r53_entries\" {\r\n  description = \"Pi Hole DNS Entries\"\r\n  value       = module.open_vpn[0].r53_entry\r\n}\r\n```\r\n\r\nreferences like this that use the module ouputs all blow up \r\n\r\ni have tries a `join(\"\", module.open_vpn[0].r53_entry)` but that also doesnt work as it still tries to evaluate [0] \r\n", "probably .. will raise new Feature request to pull route53 out into another module\r\n", "will now make the backend-state and optional module call and then variablise the bucket and dynao name etc so that user can use their own existing backend if they want\r\n", "This should be\r\n\r\n`  template = file(\"${path.module}/templates/open-vpn-init.tpl\")`", "This should be\r\n\r\n`template = file(\"${path.module}/templates/pi-hole-init.tpl\")`", "yeah already spotted them and updated. ", "yeah already spotted them and updated. "]}]}, {"url": "https://github.com/poseidon/terraform-google-kubernetes.git", "pull_requests": []}, {"url": "https://github.com/rotemavni/smart_terravni.git", "pull_requests": [{"url": "https://github.com/rotemavni/smart_terravni/pull/12", "comments": ["```suggestion\nresource \"aws_cloudtrail\" \"cloudtrail_needs_kms_key_id\" {\n  name                          = \"tf-cloudtrail\"\n  s3_bucket_name                = \"bucket\"\n  kms_key_id = \"arn:aws:kms:us-east-1:000000000000:key/key4\"\n}\n```\n<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/medium.svg\" alt=\"MEDIUM\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure AWS CloudTrail logs are encrypted using CMKs</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/rotemavni/smart_terravni/blob/rotemavni-patch-1/fail1.tf#L1-L4\">aws_cloudtrail.cloudtrail_needs_kms_key_id</a> |  ID: <code>BC_AWS_LOGGING_7</code>\n            <br></summary>\n<h4>Description</h4>\nAWS CloudTrail is a web service that records AWS API calls for an account, and makes those logs available to users and resources in accordance with IAM policies. AWS Key Management Service (KMS) is a managed service that helps create and control the encryption keys used to encrypt account data. It uses Hardware Security Modules (HSMs) to protect the security of encryption keys. CloudTrail logs can be configured to leverage server-side encryption (SSE) and KMS customer created master keys (CMK) to further protect CloudTrail logs. \n\nWe recommend that CloudTrail logs are configured to use SSE-KMS, providing additional confidentiality controls on log data. A given user must have S3 read permission on the corresponding log bucket and must be granted decrypt permission by the CMK policy.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>FEDRAMP (MODERATE) SC-28, AU-9</li>\n<li>CIS AWS V1.3 3.7</li>\n<li>CIS AWS V1.2 2.7</li>\n<li>ISO27001 A.12.4.2</li>\n<li>NIST-800-53 AC-17</li>\n<li>HIPAA 164.312(D) Person or entity authentication</li>\n<li>PCI-DSS V3.2 10, 3</li>\n<li>PCI-DSS V3.2.1 10.5.1</li>\n<li>SOC2 CC6.3.3</li>\n</ul>\n</details>\n<p>:magic_wand: Smart Fix - </p> Fix based on undefined% passing policies across your account, <a target=\"_blank\" href=\"http://bridgecrew-app-619572639823-ravni2.s3-website-us-west-2.amazonaws.com/projects?repository=rotemavni/smart_terravni&branch=12_rotemavni-patch-1&runId=latest\"> click for more fix suggestions</a>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/medium.svg\" alt=\"MEDIUM\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure CloudTrail trail is integrated with CloudWatch Log</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/rotemavni/smart_terravni/blob/rotemavni-patch-1/fail1.tf#L1-L4\">aws_cloudtrail.cloudtrail_needs_kms_key_id</a> |  ID: <code>BC_AWS_LOGGING_27</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```tf\nresource \"aws_cloudtrail\" \"aws_cloudtrail_ok\" {\n  name                          = \"tf-trail-foobar\"\n  cloud_watch_logs_group_arn = \"${aws_cloudwatch_log_group.example.arn}:*\"\n}\n```\n\n<h4>Description</h4>\nAWS CloudTrail is a web service that records AWS API calls made in a given AWS account. The recorded information includes the identity of the API caller, the time of the API call, the source IP address of the API caller, the request parameters, and the response elements returned by the AWS service. CloudTrail uses Amazon S3 for log file storage and delivery, so log files are stored durably. In addition to capturing CloudTrail logs within a specified S3 bucket for long term analysis, realtime analysis can be performed by configuring CloudTrail to send logs to CloudWatch logs. For a trail that is enabled in all regions in an account, CloudTrail sends log files from all those regions to a CloudWatch logs log group. It is recommended that CloudTrail logs be sent to CloudWatch logs.\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure AWS resources that support tags have Tags</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/rotemavni/smart_terravni/blob/rotemavni-patch-1/fail1.tf#L1-L4\">aws_cloudtrail.cloudtrail_needs_kms_key_id</a> |  ID: <code>BC_AWS_GENERAL_26</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```tf\nresource \"aws_security_group\" \"sg\" {\n  name = \"my-sg\"\n  ...\n+ tags = {\n+   Environment = \"dev\"\n+   Owner = \"apps-team\"\n+ }\n}\n```\n\n<h4>Description</h4>\nMany different types of AWS resources support tags. Tags allow you to add metadata to a resource to help identify ownership, perform cost / billing analysis, and to enrich a resource with other valuable information, such as descriptions and environment names. While there are many ways that tags can be used, we recommend you follow a tagging practice.\n\nView AWS's recommended tagging best practices [here](https://d1.awsstatic.com/whitepapers/aws-tagging-best-practices.pdf).\n\n</details>", "```suggestion\n  is_multi_region_trail = true\n}\n```\n<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/critical.svg\" alt=\"CRITICAL\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure AWS CloudTrail is enabled in all regions</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/rotemavni/smart_terravni/blob/rotemavni-patch-1/fail1.tf#L1-L4\">aws_cloudtrail.cloudtrail_needs_kms_key_id</a> |  ID: <code>BC_AWS_LOGGING_1</code>\n            <br></summary>\n<h4>Description</h4>\nAWS CloudTrail is a web service that records AWS API calls for your account and delivers log files to you. The recorded information includes: the identity of the API caller, the time of the API call, the source IP address of the API caller, the request parameters, and the response elements returned by the AWS service. CloudTrail provides a history of AWS API calls for an account, including API calls made via the Management Console, SDKs, command line tools, and higher-level AWS services such as CloudFormation. \n\nThe AWS API call history produced by CloudTrail enables security analysis, resource change tracking, and compliance auditing. AWS CloudTrail provides additional multi-region security:\n\n* Ensuring that a multi-regions trail exists will detect unexpected activity occurring in otherwise unused regions. \n* Ensuring that a multi-regions trail exists will enable Global Service Logging for a trail by default, capturing records of events generated on AWS global services. \n* For a multi-regions trail, ensuring that management events are configured for all types of Read/Write operations, results in the recording of management actions performed on all resources in an AWS account. \n\n<h4>Benchmarks</h4>\n<ul>\n<li>FEDRAMP (MODERATE) AU-12(a)(c), AU-3, AU-2(a)(d), AC-2(g), AC-2(4)</li>\n<li>CIS AWS V1.3 3.1</li>\n<li>CIS AWS V1.2 2.1</li>\n<li>ISO27001 A.12.4.1</li>\n<li>NIST-800-53 CA-3, AU-2, AC-17, AC-2</li>\n<li>HIPAA 164.312(B) Audit controls</li>\n<li>PCI-DSS V3.2 10</li>\n<li>PCI-DSS V3.2.1 10.3.6, 10.3.4, 10.3.1</li>\n<li>SOC2 CC6.3.3</li>\n</ul>\n</details>", "```suggestion\n  enable_log_file_validation = true\n}\n```\n<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/high.svg\" alt=\"HIGH\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure AWS CloudTrail log validation is enabled in all regions</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/rotemavni/smart_terravni/blob/rotemavni-patch-1/fail1.tf#L1-L4\">aws_cloudtrail.cloudtrail_needs_kms_key_id</a> |  ID: <code>BC_AWS_LOGGING_2</code>\n            <br></summary>\n<h4>Description</h4>\nCloudTrail log file validation creates a digitally signed digest file containing a hash of each log that CloudTrail writes to S3. These digest files can be used to determine whether a log file was changed, deleted, or unchanged after CloudTrail delivered the log. It is recommended that file validation be enabled on all CloudTrails. \n\nWe recommend enabling log file validation to provide additional integrity checking of CloudTrail logs. \n\n<h4>Benchmarks</h4>\n<ul>\n<li>FEDRAMP (MODERATE) SI-7</li>\n<li>CIS AWS V1.3 3.2</li>\n<li>CIS AWS V1.2 2.2</li>\n<li>ISO27001 A.12.4.2</li>\n<li>HIPAA 164.312(B) Audit controls</li>\n<li>PCI-DSS V3.2.1 10.5.5, 10.5.2</li>\n</ul>\n</details>", "```suggestion\n  is_multi_region_trail = true\n}\n```\n<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/critical.svg\" alt=\"CRITICAL\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure AWS CloudTrail is enabled in all regions</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/rotemavni/smart_terravni/blob/rotemavni-patch-1/fail1.tf#L1-L4\">aws_cloudtrail.cloudtrail_needs_kms_key_id</a> |  ID: <code>BC_AWS_LOGGING_1</code>\n            <br></summary>\n<h4>Description</h4>\nAWS CloudTrail is a web service that records AWS API calls for your account and delivers log files to you. The recorded information includes: the identity of the API caller, the time of the API call, the source IP address of the API caller, the request parameters, and the response elements returned by the AWS service. CloudTrail provides a history of AWS API calls for an account, including API calls made via the Management Console, SDKs, command line tools, and higher-level AWS services such as CloudFormation. \n\nThe AWS API call history produced by CloudTrail enables security analysis, resource change tracking, and compliance auditing. AWS CloudTrail provides additional multi-region security:\n\n* Ensuring that a multi-regions trail exists will detect unexpected activity occurring in otherwise unused regions. \n* Ensuring that a multi-regions trail exists will enable Global Service Logging for a trail by default, capturing records of events generated on AWS global services. \n* For a multi-regions trail, ensuring that management events are configured for all types of Read/Write operations, results in the recording of management actions performed on all resources in an AWS account. \n\n<h4>Benchmarks</h4>\n<ul>\n<li>FEDRAMP (MODERATE) AU-12(a)(c), AU-3, AU-2(a)(d), AC-2(g), AC-2(4)</li>\n<li>CIS AWS V1.3 3.1</li>\n<li>CIS AWS V1.2 2.1</li>\n<li>ISO27001 A.12.4.1</li>\n<li>NIST-800-53 CA-3, AU-2, AC-17, AC-2</li>\n<li>HIPAA 164.312(B) Audit controls</li>\n<li>PCI-DSS V3.2 10</li>\n<li>PCI-DSS V3.2.1 10.3.6, 10.3.4, 10.3.1</li>\n<li>SOC2 CC6.3.3</li>\n</ul>\n<b>Dependent Resources</b>\n<br>\n<br><p>Calculating...</p>\n</details>", "```suggestion\n  enable_log_file_validation = true\n}\n```\n<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/high.svg\" alt=\"HIGH\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure AWS CloudTrail log validation is enabled in all regions</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/rotemavni/smart_terravni/blob/rotemavni-patch-1/fail1.tf#L1-L4\">aws_cloudtrail.cloudtrail_needs_kms_key_id</a> |  ID: <code>BC_AWS_LOGGING_2</code>\n            <br></summary>\n<h4>Description</h4>\nCloudTrail log file validation creates a digitally signed digest file containing a hash of each log that CloudTrail writes to S3. These digest files can be used to determine whether a log file was changed, deleted, or unchanged after CloudTrail delivered the log. It is recommended that file validation be enabled on all CloudTrails. \n\nWe recommend enabling log file validation to provide additional integrity checking of CloudTrail logs. \n\n<h4>Benchmarks</h4>\n<ul>\n<li>FEDRAMP (MODERATE) SI-7</li>\n<li>CIS AWS V1.3 3.2</li>\n<li>CIS AWS V1.2 2.2</li>\n<li>ISO27001 A.12.4.2</li>\n<li>HIPAA 164.312(B) Audit controls</li>\n<li>PCI-DSS V3.2.1 10.5.5, 10.5.2</li>\n</ul>\n<b>Dependent Resources</b>\n<br>\n<br><p>Calculating...</p>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/medium.svg\" alt=\"MEDIUM\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure CloudTrail trail is integrated with CloudWatch Log</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/rotemavni/smart_terravni/blob/rotemavni-patch-1/fail1.tf#L1-L4\">aws_cloudtrail.cloudtrail_needs_kms_key_id</a> |  ID: <code>BC_AWS_LOGGING_27</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```tf\nresource \"aws_cloudtrail\" \"aws_cloudtrail_ok\" {\n  name                          = \"tf-trail-foobar\"\n  cloud_watch_logs_group_arn = \"${aws_cloudwatch_log_group.example.arn}:*\"\n}\n```\n\n<h4>Description</h4>\nAWS CloudTrail is a web service that records AWS API calls made in a given AWS account. The recorded information includes the identity of the API caller, the time of the API call, the source IP address of the API caller, the request parameters, and the response elements returned by the AWS service. CloudTrail uses Amazon S3 for log file storage and delivery, so log files are stored durably. In addition to capturing CloudTrail logs within a specified S3 bucket for long term analysis, realtime analysis can be performed by configuring CloudTrail to send logs to CloudWatch logs. For a trail that is enabled in all regions in an account, CloudTrail sends log files from all those regions to a CloudWatch logs log group. It is recommended that CloudTrail logs be sent to CloudWatch logs.\n<b>Dependent Resources</b>\n<br>\n<br><p>Calculating...</p>\n</details>", "```suggestion\nresource \"aws_cloudtrail\" \"cloudtrail_needs_kms_key_id\" {\n  name                          = \"tf-cloudtrail\"\n  s3_bucket_name                = \"bucket\"\n  kms_key_id = \"arn:aws:kms:us-east-1:000000000000:key/key4\"\n}\n```\n<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/medium.svg\" alt=\"MEDIUM\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure AWS CloudTrail logs are encrypted using CMKs</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/rotemavni/smart_terravni/blob/rotemavni-patch-1/fail1.tf#L1-L4\">aws_cloudtrail.cloudtrail_needs_kms_key_id</a> |  ID: <code>BC_AWS_LOGGING_7</code>\n            <br></summary>\n<h4>Description</h4>\nAWS CloudTrail is a web service that records AWS API calls for an account, and makes those logs available to users and resources in accordance with IAM policies. AWS Key Management Service (KMS) is a managed service that helps create and control the encryption keys used to encrypt account data. It uses Hardware Security Modules (HSMs) to protect the security of encryption keys. CloudTrail logs can be configured to leverage server-side encryption (SSE) and KMS customer created master keys (CMK) to further protect CloudTrail logs. \n\nWe recommend that CloudTrail logs are configured to use SSE-KMS, providing additional confidentiality controls on log data. A given user must have S3 read permission on the corresponding log bucket and must be granted decrypt permission by the CMK policy.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>FEDRAMP (MODERATE) SC-28, AU-9</li>\n<li>CIS AWS V1.3 3.7</li>\n<li>CIS AWS V1.2 2.7</li>\n<li>ISO27001 A.12.4.2</li>\n<li>NIST-800-53 AC-17</li>\n<li>HIPAA 164.312(D) Person or entity authentication</li>\n<li>PCI-DSS V3.2 10, 3</li>\n<li>PCI-DSS V3.2.1 10.5.1</li>\n<li>SOC2 CC6.3.3</li>\n</ul>\n<b>Dependent Resources</b>\n<br>\n<br><p>Calculating...</p>\n</details>\n<p>:magic_wand: Smart Fix - </p> Fix based on undefined% passing policies across your account, <a target=\"_blank\" href=\"http://bridgecrew-app-619572639823-ravni2.s3-website-us-west-2.amazonaws.com/projects?repository=rotemavni/smart_terravni&branch=12_rotemavni-patch-1&runId=latest\"> click for more fix suggestions</a>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure AWS resources that support tags have Tags</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/rotemavni/smart_terravni/blob/rotemavni-patch-1/fail1.tf#L1-L4\">aws_cloudtrail.cloudtrail_needs_kms_key_id</a> |  ID: <code>BC_AWS_GENERAL_26</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```tf\nresource \"aws_security_group\" \"sg\" {\n  name = \"my-sg\"\n  ...\n+ tags = {\n+   Environment = \"dev\"\n+   Owner = \"apps-team\"\n+ }\n}\n```\n\n<h4>Description</h4>\nMany different types of AWS resources support tags. Tags allow you to add metadata to a resource to help identify ownership, perform cost / billing analysis, and to enrich a resource with other valuable information, such as descriptions and environment names. While there are many ways that tags can be used, we recommend you follow a tagging practice.\n\nView AWS's recommended tagging best practices [here](https://d1.awsstatic.com/whitepapers/aws-tagging-best-practices.pdf).\n\n<b>Dependent Resources</b>\n<br>\n<br><p>Calculating...</p>\n</details>", "```suggestion\nresource \"aws_cloudtrail\" \"cloudtrail_needs_kms_key_id\" {\n  name                          = \"tf-cloudtrail\"\n  s3_bucket_name                = \"bucket\"\n  kms_key_id = \"arn:aws:kms:us-east-1:000000000000:key/key4\"\n}\n```\n<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/medium.svg\" alt=\"MEDIUM\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure AWS CloudTrail logs are encrypted using CMKs</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/rotemavni/smart_terravni/blob/rotemavni-patch-1/fail1.tf#L1-L4\">aws_cloudtrail.cloudtrail_needs_kms_key_id</a> |  ID: <code>BC_AWS_LOGGING_7</code>\n            <br></summary>\n<h4>Description</h4>\nAWS CloudTrail is a web service that records AWS API calls for an account, and makes those logs available to users and resources in accordance with IAM policies. AWS Key Management Service (KMS) is a managed service that helps create and control the encryption keys used to encrypt account data. It uses Hardware Security Modules (HSMs) to protect the security of encryption keys. CloudTrail logs can be configured to leverage server-side encryption (SSE) and KMS customer created master keys (CMK) to further protect CloudTrail logs. \n\nWe recommend that CloudTrail logs are configured to use SSE-KMS, providing additional confidentiality controls on log data. A given user must have S3 read permission on the corresponding log bucket and must be granted decrypt permission by the CMK policy.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>FEDRAMP (MODERATE) SC-28, AU-9</li>\n<li>CIS AWS V1.3 3.7</li>\n<li>CIS AWS V1.2 2.7</li>\n<li>ISO27001 A.12.4.2</li>\n<li>NIST-800-53 AC-17</li>\n<li>HIPAA 164.312(D) Person or entity authentication</li>\n<li>PCI-DSS V3.2 10, 3</li>\n<li>PCI-DSS V3.2.1 10.5.1</li>\n<li>SOC2 CC6.3.3</li>\n</ul>\n<b>Dependent Resources</b>\n<br>\n<br><p>Calculating...</p>\n</details>\n<p>:magic_wand: Smart Fix - </p> Fix based on 40% passing policies across your account, <a target=\"_blank\" href=\"http://bridgecrew-app-619572639823-ravni2.s3-website-us-west-2.amazonaws.com/projects?repository=rotemavni/smart_terravni&branch=12_rotemavni-patch-1&runId=latest\"> click for more fix suggestions</a>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/medium.svg\" alt=\"MEDIUM\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure CloudTrail trail is integrated with CloudWatch Log</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/rotemavni/smart_terravni/blob/rotemavni-patch-1/fail1.tf#L1-L4\">aws_cloudtrail.cloudtrail_needs_kms_key_id</a> |  ID: <code>BC_AWS_LOGGING_27</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```tf\nresource \"aws_cloudtrail\" \"aws_cloudtrail_ok\" {\n  name                          = \"tf-trail-foobar\"\n  cloud_watch_logs_group_arn = \"${aws_cloudwatch_log_group.example.arn}:*\"\n}\n```\n\n<h4>Description</h4>\nAWS CloudTrail is a web service that records AWS API calls made in a given AWS account. The recorded information includes the identity of the API caller, the time of the API call, the source IP address of the API caller, the request parameters, and the response elements returned by the AWS service. CloudTrail uses Amazon S3 for log file storage and delivery, so log files are stored durably. In addition to capturing CloudTrail logs within a specified S3 bucket for long term analysis, realtime analysis can be performed by configuring CloudTrail to send logs to CloudWatch logs. For a trail that is enabled in all regions in an account, CloudTrail sends log files from all those regions to a CloudWatch logs log group. It is recommended that CloudTrail logs be sent to CloudWatch logs.\n<b>Dependent Resources</b>\n<br>\n<br><p>Calculating...</p>\n</details>", "```suggestion\n  enable_log_file_validation = true\n}\n```\n<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/high.svg\" alt=\"HIGH\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure AWS CloudTrail log validation is enabled in all regions</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/rotemavni/smart_terravni/blob/rotemavni-patch-1/fail1.tf#L1-L4\">aws_cloudtrail.cloudtrail_needs_kms_key_id</a> |  ID: <code>BC_AWS_LOGGING_2</code>\n            <br></summary>\n<h4>Description</h4>\nCloudTrail log file validation creates a digitally signed digest file containing a hash of each log that CloudTrail writes to S3. These digest files can be used to determine whether a log file was changed, deleted, or unchanged after CloudTrail delivered the log. It is recommended that file validation be enabled on all CloudTrails. \n\nWe recommend enabling log file validation to provide additional integrity checking of CloudTrail logs. \n\n<h4>Benchmarks</h4>\n<ul>\n<li>FEDRAMP (MODERATE) SI-7</li>\n<li>CIS AWS V1.3 3.2</li>\n<li>CIS AWS V1.2 2.2</li>\n<li>ISO27001 A.12.4.2</li>\n<li>HIPAA 164.312(B) Audit controls</li>\n<li>PCI-DSS V3.2.1 10.5.5, 10.5.2</li>\n</ul>\n<b>Dependent Resources</b>\n<br>\n<br><p>Calculating...</p>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure AWS resources that support tags have Tags</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/rotemavni/smart_terravni/blob/rotemavni-patch-1/fail1.tf#L1-L4\">aws_cloudtrail.cloudtrail_needs_kms_key_id</a> |  ID: <code>BC_AWS_GENERAL_26</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```tf\nresource \"aws_security_group\" \"sg\" {\n  name = \"my-sg\"\n  ...\n+ tags = {\n+   Environment = \"dev\"\n+   Owner = \"apps-team\"\n+ }\n}\n```\n\n<h4>Description</h4>\nMany different types of AWS resources support tags. Tags allow you to add metadata to a resource to help identify ownership, perform cost / billing analysis, and to enrich a resource with other valuable information, such as descriptions and environment names. While there are many ways that tags can be used, we recommend you follow a tagging practice.\n\nView AWS's recommended tagging best practices [here](https://d1.awsstatic.com/whitepapers/aws-tagging-best-practices.pdf).\n\n<b>Dependent Resources</b>\n<br>\n<br><p>Calculating...</p>\n</details>", "```suggestion\n  is_multi_region_trail = true\n}\n```\n<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/critical.svg\" alt=\"CRITICAL\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure AWS CloudTrail is enabled in all regions</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/rotemavni/smart_terravni/blob/rotemavni-patch-1/fail1.tf#L1-L4\">aws_cloudtrail.cloudtrail_needs_kms_key_id</a> |  ID: <code>BC_AWS_LOGGING_1</code>\n            <br></summary>\n<h4>Description</h4>\nAWS CloudTrail is a web service that records AWS API calls for your account and delivers log files to you. The recorded information includes: the identity of the API caller, the time of the API call, the source IP address of the API caller, the request parameters, and the response elements returned by the AWS service. CloudTrail provides a history of AWS API calls for an account, including API calls made via the Management Console, SDKs, command line tools, and higher-level AWS services such as CloudFormation. \n\nThe AWS API call history produced by CloudTrail enables security analysis, resource change tracking, and compliance auditing. AWS CloudTrail provides additional multi-region security:\n\n* Ensuring that a multi-regions trail exists will detect unexpected activity occurring in otherwise unused regions. \n* Ensuring that a multi-regions trail exists will enable Global Service Logging for a trail by default, capturing records of events generated on AWS global services. \n* For a multi-regions trail, ensuring that management events are configured for all types of Read/Write operations, results in the recording of management actions performed on all resources in an AWS account. \n\n<h4>Benchmarks</h4>\n<ul>\n<li>FEDRAMP (MODERATE) AU-12(a)(c), AU-3, AU-2(a)(d), AC-2(g), AC-2(4)</li>\n<li>CIS AWS V1.3 3.1</li>\n<li>CIS AWS V1.2 2.1</li>\n<li>ISO27001 A.12.4.1</li>\n<li>NIST-800-53 CA-3, AU-2, AC-17, AC-2</li>\n<li>HIPAA 164.312(B) Audit controls</li>\n<li>PCI-DSS V3.2 10</li>\n<li>PCI-DSS V3.2.1 10.3.6, 10.3.4, 10.3.1</li>\n<li>SOC2 CC6.3.3</li>\n</ul>\n<b>Dependent Resources</b>\n<br>\n<br><p>Calculating...</p>\n</details>"]}, {"url": "https://github.com/rotemavni/smart_terravni/pull/11", "comments": ["<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/medium.svg\" alt=\"MEDIUM\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure CloudTrail trail is integrated with CloudWatch Log</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/rotemavni/smart_terravni/blob/rotemavni-patch-1/fail1.tf#L1-L4\">aws_cloudtrail.cloudtrail_needs_kms_key_id</a> |  ID: <code>BC_AWS_LOGGING_27</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```tf\nresource \"aws_cloudtrail\" \"aws_cloudtrail_ok\" {\n  name                          = \"tf-trail-foobar\"\n  cloud_watch_logs_group_arn = \"${aws_cloudwatch_log_group.example.arn}:*\"\n}\n```\n\n<h4>Description</h4>\nAWS CloudTrail is a web service that records AWS API calls made in a given AWS account. The recorded information includes the identity of the API caller, the time of the API call, the source IP address of the API caller, the request parameters, and the response elements returned by the AWS service. CloudTrail uses Amazon S3 for log file storage and delivery, so log files are stored durably. In addition to capturing CloudTrail logs within a specified S3 bucket for long term analysis, realtime analysis can be performed by configuring CloudTrail to send logs to CloudWatch logs. For a trail that is enabled in all regions in an account, CloudTrail sends log files from all those regions to a CloudWatch logs log group. It is recommended that CloudTrail logs be sent to CloudWatch logs.\n</details>", "```suggestion\n  enable_log_file_validation = true\n}\n```\n<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/high.svg\" alt=\"HIGH\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure AWS CloudTrail log validation is enabled in all regions</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/rotemavni/smart_terravni/blob/rotemavni-patch-1/fail1.tf#L1-L4\">aws_cloudtrail.cloudtrail_needs_kms_key_id</a> |  ID: <code>BC_AWS_LOGGING_2</code>\n            <br></summary>\n<h4>Description</h4>\nCloudTrail log file validation creates a digitally signed digest file containing a hash of each log that CloudTrail writes to S3. These digest files can be used to determine whether a log file was changed, deleted, or unchanged after CloudTrail delivered the log. It is recommended that file validation be enabled on all CloudTrails. \n\nWe recommend enabling log file validation to provide additional integrity checking of CloudTrail logs. \n\n<h4>Benchmarks</h4>\n<ul>\n<li>FEDRAMP (MODERATE) SI-7</li>\n<li>CIS AWS V1.3 3.2</li>\n<li>CIS AWS V1.2 2.2</li>\n<li>ISO27001 A.12.4.2</li>\n<li>HIPAA 164.312(B) Audit controls</li>\n<li>PCI-DSS V3.2.1 10.5.5, 10.5.2</li>\n</ul>\n</details>", "```suggestion\nresource \"aws_cloudtrail\" \"cloudtrail_needs_kms_key_id\" {\n  name                          = \"tf-cloudtrail\"\n  s3_bucket_name                = \"bucket\"\n  kms_key_id = \"arn:aws:kms:us-east-1:000000000000:key/key4\"\n}\n```\n<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/medium.svg\" alt=\"MEDIUM\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure AWS CloudTrail logs are encrypted using CMKs</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/rotemavni/smart_terravni/blob/rotemavni-patch-1/fail1.tf#L1-L4\">aws_cloudtrail.cloudtrail_needs_kms_key_id</a> |  ID: <code>BC_AWS_LOGGING_7</code>\n            <br></summary>\n<h4>Description</h4>\nAWS CloudTrail is a web service that records AWS API calls for an account, and makes those logs available to users and resources in accordance with IAM policies. AWS Key Management Service (KMS) is a managed service that helps create and control the encryption keys used to encrypt account data. It uses Hardware Security Modules (HSMs) to protect the security of encryption keys. CloudTrail logs can be configured to leverage server-side encryption (SSE) and KMS customer created master keys (CMK) to further protect CloudTrail logs. \n\nWe recommend that CloudTrail logs are configured to use SSE-KMS, providing additional confidentiality controls on log data. A given user must have S3 read permission on the corresponding log bucket and must be granted decrypt permission by the CMK policy.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>FEDRAMP (MODERATE) SC-28, AU-9</li>\n<li>CIS AWS V1.3 3.7</li>\n<li>CIS AWS V1.2 2.7</li>\n<li>ISO27001 A.12.4.2</li>\n<li>NIST-800-53 AC-17</li>\n<li>HIPAA 164.312(D) Person or entity authentication</li>\n<li>PCI-DSS V3.2 10, 3</li>\n<li>PCI-DSS V3.2.1 10.5.1</li>\n<li>SOC2 CC6.3.3</li>\n</ul>\n</details>\n<p>:magic_wand: Smart Fix - </p> Fix based on 100% past actions in this repo", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure AWS resources that support tags have Tags</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/rotemavni/smart_terravni/blob/rotemavni-patch-1/fail1.tf#L1-L4\">aws_cloudtrail.cloudtrail_needs_kms_key_id</a> |  ID: <code>BC_AWS_GENERAL_26</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```tf\nresource \"aws_security_group\" \"sg\" {\n  name = \"my-sg\"\n  ...\n+ tags = {\n+   Environment = \"dev\"\n+   Owner = \"apps-team\"\n+ }\n}\n```\n\n<h4>Description</h4>\nMany different types of AWS resources support tags. Tags allow you to add metadata to a resource to help identify ownership, perform cost / billing analysis, and to enrich a resource with other valuable information, such as descriptions and environment names. While there are many ways that tags can be used, we recommend you follow a tagging practice.\n\nView AWS's recommended tagging best practices [here](https://d1.awsstatic.com/whitepapers/aws-tagging-best-practices.pdf).\n\n</details>", "```suggestion\n  is_multi_region_trail = true\n}\n```\n<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/critical.svg\" alt=\"CRITICAL\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure AWS CloudTrail is enabled in all regions</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/rotemavni/smart_terravni/blob/rotemavni-patch-1/fail1.tf#L1-L4\">aws_cloudtrail.cloudtrail_needs_kms_key_id</a> |  ID: <code>BC_AWS_LOGGING_1</code>\n            <br></summary>\n<h4>Description</h4>\nAWS CloudTrail is a web service that records AWS API calls for your account and delivers log files to you. The recorded information includes: the identity of the API caller, the time of the API call, the source IP address of the API caller, the request parameters, and the response elements returned by the AWS service. CloudTrail provides a history of AWS API calls for an account, including API calls made via the Management Console, SDKs, command line tools, and higher-level AWS services such as CloudFormation. \n\nThe AWS API call history produced by CloudTrail enables security analysis, resource change tracking, and compliance auditing. AWS CloudTrail provides additional multi-region security:\n\n* Ensuring that a multi-regions trail exists will detect unexpected activity occurring in otherwise unused regions. \n* Ensuring that a multi-regions trail exists will enable Global Service Logging for a trail by default, capturing records of events generated on AWS global services. \n* For a multi-regions trail, ensuring that management events are configured for all types of Read/Write operations, results in the recording of management actions performed on all resources in an AWS account. \n\n<h4>Benchmarks</h4>\n<ul>\n<li>FEDRAMP (MODERATE) AU-12(a)(c), AU-3, AU-2(a)(d), AC-2(g), AC-2(4)</li>\n<li>CIS AWS V1.3 3.1</li>\n<li>CIS AWS V1.2 2.1</li>\n<li>ISO27001 A.12.4.1</li>\n<li>NIST-800-53 CA-3, AU-2, AC-17, AC-2</li>\n<li>HIPAA 164.312(B) Audit controls</li>\n<li>PCI-DSS V3.2 10</li>\n<li>PCI-DSS V3.2.1 10.3.6, 10.3.4, 10.3.1</li>\n<li>SOC2 CC6.3.3</li>\n</ul>\n</details>"]}, {"url": "https://github.com/rotemavni/smart_terravni/pull/10", "comments": ["<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/medium.svg\" alt=\"MEDIUM\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure CloudTrail trail is integrated with CloudWatch Log</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/rotemavni/smart_terravni/blob/rotemavni-patch-1/fail1.tf#L1-L4\">aws_cloudtrail.cloudtrail_needs_kms_key_id</a> |  ID: <code>BC_AWS_LOGGING_27</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```tf\nresource \"aws_cloudtrail\" \"aws_cloudtrail_ok\" {\n  name                          = \"tf-trail-foobar\"\n  cloud_watch_logs_group_arn = \"${aws_cloudwatch_log_group.example.arn}:*\"\n}\n```\n\n<h4>Description</h4>\nAWS CloudTrail is a web service that records AWS API calls made in a given AWS account. The recorded information includes the identity of the API caller, the time of the API call, the source IP address of the API caller, the request parameters, and the response elements returned by the AWS service. CloudTrail uses Amazon S3 for log file storage and delivery, so log files are stored durably. In addition to capturing CloudTrail logs within a specified S3 bucket for long term analysis, realtime analysis can be performed by configuring CloudTrail to send logs to CloudWatch logs. For a trail that is enabled in all regions in an account, CloudTrail sends log files from all those regions to a CloudWatch logs log group. It is recommended that CloudTrail logs be sent to CloudWatch logs.\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure AWS resources that support tags have Tags</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/rotemavni/smart_terravni/blob/rotemavni-patch-1/fail1.tf#L1-L4\">aws_cloudtrail.cloudtrail_needs_kms_key_id</a> |  ID: <code>BC_AWS_GENERAL_26</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```tf\nresource \"aws_security_group\" \"sg\" {\n  name = \"my-sg\"\n  ...\n+ tags = {\n+   Environment = \"dev\"\n+   Owner = \"apps-team\"\n+ }\n}\n```\n\n<h4>Description</h4>\nMany different types of AWS resources support tags. Tags allow you to add metadata to a resource to help identify ownership, perform cost / billing analysis, and to enrich a resource with other valuable information, such as descriptions and environment names. While there are many ways that tags can be used, we recommend you follow a tagging practice.\n\nView AWS's recommended tagging best practices [here](https://d1.awsstatic.com/whitepapers/aws-tagging-best-practices.pdf).\n\n</details>", "```suggestion\n  is_multi_region_trail = true\n}\n```\n<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/critical.svg\" alt=\"CRITICAL\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure AWS CloudTrail is enabled in all regions</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/rotemavni/smart_terravni/blob/rotemavni-patch-1/fail1.tf#L1-L4\">aws_cloudtrail.cloudtrail_needs_kms_key_id</a> |  ID: <code>BC_AWS_LOGGING_1</code>\n            <br></summary>\n<h4>Description</h4>\nAWS CloudTrail is a web service that records AWS API calls for your account and delivers log files to you. The recorded information includes: the identity of the API caller, the time of the API call, the source IP address of the API caller, the request parameters, and the response elements returned by the AWS service. CloudTrail provides a history of AWS API calls for an account, including API calls made via the Management Console, SDKs, command line tools, and higher-level AWS services such as CloudFormation. \n\nThe AWS API call history produced by CloudTrail enables security analysis, resource change tracking, and compliance auditing. AWS CloudTrail provides additional multi-region security:\n\n* Ensuring that a multi-regions trail exists will detect unexpected activity occurring in otherwise unused regions. \n* Ensuring that a multi-regions trail exists will enable Global Service Logging for a trail by default, capturing records of events generated on AWS global services. \n* For a multi-regions trail, ensuring that management events are configured for all types of Read/Write operations, results in the recording of management actions performed on all resources in an AWS account. \n\n<h4>Benchmarks</h4>\n<ul>\n<li>FEDRAMP (MODERATE) AU-12(a)(c), AU-3, AU-2(a)(d), AC-2(g), AC-2(4)</li>\n<li>CIS AWS V1.3 3.1</li>\n<li>CIS AWS V1.2 2.1</li>\n<li>ISO27001 A.12.4.1</li>\n<li>NIST-800-53 CA-3, AU-2, AC-17, AC-2</li>\n<li>HIPAA 164.312(B) Audit controls</li>\n<li>PCI-DSS V3.2 10</li>\n<li>PCI-DSS V3.2.1 10.3.6, 10.3.4, 10.3.1</li>\n<li>SOC2 CC6.3.3</li>\n</ul>\n</details>", "```suggestion\nresource \"aws_cloudtrail\" \"cloudtrail_needs_kms_key_id\" {\n  name                          = \"tf-cloudtrail\"\n  s3_bucket_name                = \"bucket\"\n  kms_key_id = \"arn:aws:kms:us-east-1:000000000000:key/key4\"\n}\n```\n<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/medium.svg\" alt=\"MEDIUM\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure AWS CloudTrail logs are encrypted using CMKs</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/rotemavni/smart_terravni/blob/rotemavni-patch-1/fail1.tf#L1-L4\">aws_cloudtrail.cloudtrail_needs_kms_key_id</a> |  ID: <code>BC_AWS_LOGGING_7</code>\n            <br></summary>\n<h4>Description</h4>\nAWS CloudTrail is a web service that records AWS API calls for an account, and makes those logs available to users and resources in accordance with IAM policies. AWS Key Management Service (KMS) is a managed service that helps create and control the encryption keys used to encrypt account data. It uses Hardware Security Modules (HSMs) to protect the security of encryption keys. CloudTrail logs can be configured to leverage server-side encryption (SSE) and KMS customer created master keys (CMK) to further protect CloudTrail logs. \n\nWe recommend that CloudTrail logs are configured to use SSE-KMS, providing additional confidentiality controls on log data. A given user must have S3 read permission on the corresponding log bucket and must be granted decrypt permission by the CMK policy.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>FEDRAMP (MODERATE) SC-28, AU-9</li>\n<li>CIS AWS V1.3 3.7</li>\n<li>CIS AWS V1.2 2.7</li>\n<li>ISO27001 A.12.4.2</li>\n<li>NIST-800-53 AC-17</li>\n<li>HIPAA 164.312(D) Person or entity authentication</li>\n<li>PCI-DSS V3.2 10, 3</li>\n<li>PCI-DSS V3.2.1 10.5.1</li>\n<li>SOC2 CC6.3.3</li>\n</ul>\n</details>\n<p>:magic_wand: Smart Fix - </p> Fix based on 100% past actions in this repo", "```suggestion\n  enable_log_file_validation = true\n}\n```\n<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/high.svg\" alt=\"HIGH\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure AWS CloudTrail log validation is enabled in all regions</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/rotemavni/smart_terravni/blob/rotemavni-patch-1/fail1.tf#L1-L4\">aws_cloudtrail.cloudtrail_needs_kms_key_id</a> |  ID: <code>BC_AWS_LOGGING_2</code>\n            <br></summary>\n<h4>Description</h4>\nCloudTrail log file validation creates a digitally signed digest file containing a hash of each log that CloudTrail writes to S3. These digest files can be used to determine whether a log file was changed, deleted, or unchanged after CloudTrail delivered the log. It is recommended that file validation be enabled on all CloudTrails. \n\nWe recommend enabling log file validation to provide additional integrity checking of CloudTrail logs. \n\n<h4>Benchmarks</h4>\n<ul>\n<li>FEDRAMP (MODERATE) SI-7</li>\n<li>CIS AWS V1.3 3.2</li>\n<li>CIS AWS V1.2 2.2</li>\n<li>ISO27001 A.12.4.2</li>\n<li>HIPAA 164.312(B) Audit controls</li>\n<li>PCI-DSS V3.2.1 10.5.5, 10.5.2</li>\n</ul>\n</details>"]}, {"url": "https://github.com/rotemavni/smart_terravni/pull/9", "comments": ["<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure AWS resources that support tags have Tags</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/rotemavni/smart_terravni/blob/rotemavni-patch-1/fail1.tf#L2-L5\">aws_cloudtrail.cloudtrail_needs_kms_key_id</a> |  ID: <code>BC_AWS_GENERAL_26</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```tf\nresource \"aws_security_group\" \"sg\" {\n  name = \"my-sg\"\n  ...\n+ tags = {\n+   Environment = \"dev\"\n+   Owner = \"apps-team\"\n+ }\n}\n```\n\n<h4>Description</h4>\nMany different types of AWS resources support tags. Tags allow you to add metadata to a resource to help identify ownership, perform cost / billing analysis, and to enrich a resource with other valuable information, such as descriptions and environment names. While there are many ways that tags can be used, we recommend you follow a tagging practice.\n\nView AWS's recommended tagging best practices [here](https://d1.awsstatic.com/whitepapers/aws-tagging-best-practices.pdf).\n\n</details>", "```suggestion\nresource \"aws_cloudtrail\" \"cloudtrail_needs_kms_key_id\" {\n   enable_log_file_validation = true\n```\n<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/high.svg\" alt=\"HIGH\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure AWS CloudTrail log validation is enabled in all regions</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/rotemavni/smart_terravni/blob/rotemavni-patch-1/fail1.tf#L2-L5\">aws_cloudtrail.cloudtrail_needs_kms_key_id</a> |  ID: <code>BC_AWS_LOGGING_2</code>\n            <br></summary>\n<h4>Description</h4>\nCloudTrail log file validation creates a digitally signed digest file containing a hash of each log that CloudTrail writes to S3. These digest files can be used to determine whether a log file was changed, deleted, or unchanged after CloudTrail delivered the log. It is recommended that file validation be enabled on all CloudTrails. \n\nWe recommend enabling log file validation to provide additional integrity checking of CloudTrail logs. \n\n<h4>Benchmarks</h4>\n<ul>\n<li>FEDRAMP (MODERATE) SI-7</li>\n<li>CIS AWS V1.3 3.2</li>\n<li>CIS AWS V1.2 2.2</li>\n<li>ISO27001 A.12.4.2</li>\n<li>HIPAA 164.312(B) Audit controls</li>\n<li>PCI-DSS V3.2.1 10.5.5, 10.5.2</li>\n</ul>\n</details>", "```suggestion\nresource \"aws_cloudtrail\" \"cloudtrail_needs_kms_key_id\" {\n  name                          = \"tf-cloudtrail\"\n  s3_bucket_name                = \"bucket\"\n   kms_key_id = \"arn:aws:kms:us-east-1:000000000000:key/key4\"\n}\n```\n<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/medium.svg\" alt=\"MEDIUM\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure AWS CloudTrail logs are encrypted using CMKs</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/rotemavni/smart_terravni/blob/rotemavni-patch-1/fail1.tf#L2-L5\">aws_cloudtrail.cloudtrail_needs_kms_key_id</a> |  ID: <code>BC_AWS_LOGGING_7</code>\n            <br></summary>\n<h4>Description</h4>\nAWS CloudTrail is a web service that records AWS API calls for an account, and makes those logs available to users and resources in accordance with IAM policies. AWS Key Management Service (KMS) is a managed service that helps create and control the encryption keys used to encrypt account data. It uses Hardware Security Modules (HSMs) to protect the security of encryption keys. CloudTrail logs can be configured to leverage server-side encryption (SSE) and KMS customer created master keys (CMK) to further protect CloudTrail logs. \n\nWe recommend that CloudTrail logs are configured to use SSE-KMS, providing additional confidentiality controls on log data. A given user must have S3 read permission on the corresponding log bucket and must be granted decrypt permission by the CMK policy.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>FEDRAMP (MODERATE) SC-28, AU-9</li>\n<li>CIS AWS V1.3 3.7</li>\n<li>CIS AWS V1.2 2.7</li>\n<li>ISO27001 A.12.4.2</li>\n<li>NIST-800-53 AC-17</li>\n<li>HIPAA 164.312(D) Person or entity authentication</li>\n<li>PCI-DSS V3.2 10, 3</li>\n<li>PCI-DSS V3.2.1 10.5.1</li>\n<li>SOC2 CC6.3.3</li>\n</ul>\n</details>\n<p>:magic_wand: Smart Fix - </p> Fix based on 100% past actions", "```suggestion\nresource \"aws_cloudtrail\" \"cloudtrail_needs_kms_key_id\" {\n   is_multi_region_trail = true\n```\n<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/critical.svg\" alt=\"CRITICAL\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure AWS CloudTrail is enabled in all regions</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/rotemavni/smart_terravni/blob/rotemavni-patch-1/fail1.tf#L2-L5\">aws_cloudtrail.cloudtrail_needs_kms_key_id</a> |  ID: <code>BC_AWS_LOGGING_1</code>\n            <br></summary>\n<h4>Description</h4>\nAWS CloudTrail is a web service that records AWS API calls for your account and delivers log files to you. The recorded information includes: the identity of the API caller, the time of the API call, the source IP address of the API caller, the request parameters, and the response elements returned by the AWS service. CloudTrail provides a history of AWS API calls for an account, including API calls made via the Management Console, SDKs, command line tools, and higher-level AWS services such as CloudFormation. \n\nThe AWS API call history produced by CloudTrail enables security analysis, resource change tracking, and compliance auditing. AWS CloudTrail provides additional multi-region security:\n\n* Ensuring that a multi-regions trail exists will detect unexpected activity occurring in otherwise unused regions. \n* Ensuring that a multi-regions trail exists will enable Global Service Logging for a trail by default, capturing records of events generated on AWS global services. \n* For a multi-regions trail, ensuring that management events are configured for all types of Read/Write operations, results in the recording of management actions performed on all resources in an AWS account. \n\n<h4>Benchmarks</h4>\n<ul>\n<li>FEDRAMP (MODERATE) AU-12(a)(c), AU-3, AU-2(a)(d), AC-2(g), AC-2(4)</li>\n<li>CIS AWS V1.3 3.1</li>\n<li>CIS AWS V1.2 2.1</li>\n<li>ISO27001 A.12.4.1</li>\n<li>NIST-800-53 CA-3, AU-2, AC-17, AC-2</li>\n<li>HIPAA 164.312(B) Audit controls</li>\n<li>PCI-DSS V3.2 10</li>\n<li>PCI-DSS V3.2.1 10.3.6, 10.3.4, 10.3.1</li>\n<li>SOC2 CC6.3.3</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/medium.svg\" alt=\"MEDIUM\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure CloudTrail trail is integrated with CloudWatch Log</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/rotemavni/smart_terravni/blob/rotemavni-patch-1/fail1.tf#L2-L5\">aws_cloudtrail.cloudtrail_needs_kms_key_id</a> |  ID: <code>BC_AWS_LOGGING_27</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```tf\nresource \"aws_cloudtrail\" \"aws_cloudtrail_ok\" {\n  name                          = \"tf-trail-foobar\"\n  cloud_watch_logs_group_arn = \"${aws_cloudwatch_log_group.example.arn}:*\"\n}\n```\n\n<h4>Description</h4>\nAWS CloudTrail is a web service that records AWS API calls made in a given AWS account. The recorded information includes the identity of the API caller, the time of the API call, the source IP address of the API caller, the request parameters, and the response elements returned by the AWS service. CloudTrail uses Amazon S3 for log file storage and delivery, so log files are stored durably. In addition to capturing CloudTrail logs within a specified S3 bucket for long term analysis, realtime analysis can be performed by configuring CloudTrail to send logs to CloudWatch logs. For a trail that is enabled in all regions in an account, CloudTrail sends log files from all those regions to a CloudWatch logs log group. It is recommended that CloudTrail logs be sent to CloudWatch logs.\n</details>"]}, {"url": "https://github.com/rotemavni/smart_terravni/pull/8", "comments": ["<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure AWS resources that support tags have Tags</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/rotemavni/smart_terravni/blob/rotemavni-patch-2/fail1.tf#L1-L4\">aws_cloudtrail.cloudtrail_needs_kms_key_id</a> |  ID: <code>BC_AWS_GENERAL_26</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```tf\nresource \"aws_security_group\" \"sg\" {\n  name = \"my-sg\"\n  ...\n+ tags = {\n+   Environment = \"dev\"\n+   Owner = \"apps-team\"\n+ }\n}\n```\n\n<h4>Description</h4>\nMany different types of AWS resources support tags. Tags allow you to add metadata to a resource to help identify ownership, perform cost / billing analysis, and to enrich a resource with other valuable information, such as descriptions and environment names. While there are many ways that tags can be used, we recommend you follow a tagging practice.\n\nView AWS's recommended tagging best practices [here](https://d1.awsstatic.com/whitepapers/aws-tagging-best-practices.pdf).\n\n</details>", "```suggestion\n  enable_log_file_validation = true\n}\n```\n<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/high.svg\" alt=\"HIGH\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure AWS CloudTrail log validation is enabled in all regions</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/rotemavni/smart_terravni/blob/rotemavni-patch-2/fail1.tf#L1-L4\">aws_cloudtrail.cloudtrail_needs_kms_key_id</a> |  ID: <code>BC_AWS_LOGGING_2</code>\n            <br></summary>\n<h4>Description</h4>\nCloudTrail log file validation creates a digitally signed digest file containing a hash of each log that CloudTrail writes to S3. These digest files can be used to determine whether a log file was changed, deleted, or unchanged after CloudTrail delivered the log. It is recommended that file validation be enabled on all CloudTrails. \n\nWe recommend enabling log file validation to provide additional integrity checking of CloudTrail logs. \n\n<h4>Benchmarks</h4>\n<ul>\n<li>FEDRAMP (MODERATE) SI-7</li>\n<li>CIS AWS V1.3 3.2</li>\n<li>CIS AWS V1.2 2.2</li>\n<li>ISO27001 A.12.4.2</li>\n<li>HIPAA 164.312(B) Audit controls</li>\n<li>PCI-DSS V3.2.1 10.5.5, 10.5.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/medium.svg\" alt=\"MEDIUM\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure CloudTrail trail is integrated with CloudWatch Log</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/rotemavni/smart_terravni/blob/rotemavni-patch-2/fail1.tf#L1-L4\">aws_cloudtrail.cloudtrail_needs_kms_key_id</a> |  ID: <code>BC_AWS_LOGGING_27</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```tf\nresource \"aws_cloudtrail\" \"aws_cloudtrail_ok\" {\n  name                          = \"tf-trail-foobar\"\n  cloud_watch_logs_group_arn = \"${aws_cloudwatch_log_group.example.arn}:*\"\n}\n```\n\n<h4>Description</h4>\nAWS CloudTrail is a web service that records AWS API calls made in a given AWS account. The recorded information includes the identity of the API caller, the time of the API call, the source IP address of the API caller, the request parameters, and the response elements returned by the AWS service. CloudTrail uses Amazon S3 for log file storage and delivery, so log files are stored durably. In addition to capturing CloudTrail logs within a specified S3 bucket for long term analysis, realtime analysis can be performed by configuring CloudTrail to send logs to CloudWatch logs. For a trail that is enabled in all regions in an account, CloudTrail sends log files from all those regions to a CloudWatch logs log group. It is recommended that CloudTrail logs be sent to CloudWatch logs.\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/medium.svg\" alt=\"MEDIUM\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure AWS CloudTrail logs are encrypted using CMKs</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/rotemavni/smart_terravni/blob/rotemavni-patch-2/fail1.tf#L1-L4\">aws_cloudtrail.cloudtrail_needs_kms_key_id</a> |  ID: <code>BC_AWS_LOGGING_7</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```tf\nResources:\n\tmyTrail: \n  \tType: AWS::CloudTrail::Trail\n\t\tProperties: \n\t\t\t...\n+\t\t\tKMSKeyId: alias/MyAliasName\n```\n\n<h4>Description</h4>\nAWS CloudTrail is a web service that records AWS API calls for an account, and makes those logs available to users and resources in accordance with IAM policies. AWS Key Management Service (KMS) is a managed service that helps create and control the encryption keys used to encrypt account data. It uses Hardware Security Modules (HSMs) to protect the security of encryption keys. CloudTrail logs can be configured to leverage server-side encryption (SSE) and KMS customer created master keys (CMK) to further protect CloudTrail logs. \n\nWe recommend that CloudTrail logs are configured to use SSE-KMS, providing additional confidentiality controls on log data. A given user must have S3 read permission on the corresponding log bucket and must be granted decrypt permission by the CMK policy.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>FEDRAMP (MODERATE) SC-28, AU-9</li>\n<li>CIS AWS V1.3 3.7</li>\n<li>CIS AWS V1.2 2.7</li>\n<li>ISO27001 A.12.4.2</li>\n<li>NIST-800-53 AC-17</li>\n<li>HIPAA 164.312(D) Person or entity authentication</li>\n<li>PCI-DSS V3.2 10, 3</li>\n<li>PCI-DSS V3.2.1 10.5.1</li>\n<li>SOC2 CC6.3.3</li>\n</ul>\n</details>", "```suggestion\n  is_multi_region_trail = true\n}\n```\n<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/critical.svg\" alt=\"CRITICAL\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure AWS CloudTrail is enabled in all regions</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/rotemavni/smart_terravni/blob/rotemavni-patch-2/fail1.tf#L1-L4\">aws_cloudtrail.cloudtrail_needs_kms_key_id</a> |  ID: <code>BC_AWS_LOGGING_1</code>\n            <br></summary>\n<h4>Description</h4>\nAWS CloudTrail is a web service that records AWS API calls for your account and delivers log files to you. The recorded information includes: the identity of the API caller, the time of the API call, the source IP address of the API caller, the request parameters, and the response elements returned by the AWS service. CloudTrail provides a history of AWS API calls for an account, including API calls made via the Management Console, SDKs, command line tools, and higher-level AWS services such as CloudFormation. \n\nThe AWS API call history produced by CloudTrail enables security analysis, resource change tracking, and compliance auditing. AWS CloudTrail provides additional multi-region security:\n\n* Ensuring that a multi-regions trail exists will detect unexpected activity occurring in otherwise unused regions. \n* Ensuring that a multi-regions trail exists will enable Global Service Logging for a trail by default, capturing records of events generated on AWS global services. \n* For a multi-regions trail, ensuring that management events are configured for all types of Read/Write operations, results in the recording of management actions performed on all resources in an AWS account. \n\n<h4>Benchmarks</h4>\n<ul>\n<li>FEDRAMP (MODERATE) AU-12(a)(c), AU-3, AU-2(a)(d), AC-2(g), AC-2(4)</li>\n<li>CIS AWS V1.3 3.1</li>\n<li>CIS AWS V1.2 2.1</li>\n<li>ISO27001 A.12.4.1</li>\n<li>NIST-800-53 CA-3, AU-2, AC-17, AC-2</li>\n<li>HIPAA 164.312(B) Audit controls</li>\n<li>PCI-DSS V3.2 10</li>\n<li>PCI-DSS V3.2.1 10.3.6, 10.3.4, 10.3.1</li>\n<li>SOC2 CC6.3.3</li>\n</ul>\n</details>"]}]}, {"url": "https://github.com/zner0L/serverless-donations.git", "pull_requests": []}, {"url": "https://github.com/cmendible/azure.samples.git", "pull_requests": []}, {"url": "https://github.com/felixonmars/installer.git", "pull_requests": []}, {"url": "https://github.com/CloudWright/terraform-google-cloudwright-deployment-zone.git", "pull_requests": []}, {"url": "https://github.com/austin1237/clip-stitcher.git", "pull_requests": []}, {"url": "https://github.com/ockev/TFC_Demo.git", "pull_requests": []}, {"url": "https://github.com/JamesWoolfenden/terraform-aws-budget.git", "pull_requests": []}, {"url": "https://github.com/giantswarm/giantnetes-terraform.git", "pull_requests": [{"url": "https://github.com/giantswarm/giantnetes-terraform/pull/752", "comments": ["Is it intentional that we upgrade Cilium (v1.13.x to v1.14.x)?", "yeah"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/744", "comments": ["You moved this policy to the top, and now the diff is all lost. :rofl: ", "Oh it was too far from th\u00e9 bucket though"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/708", "comments": ["Btw. you haven't bumped cilium-app in this PR", "But I see, this was already merged previously. I guess it's just a note \ud83d\udc4d\ud83c\udffb ", "yes it was a failed merge, thanks for spotting it"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/688", "comments": ["why no resource filter here?", "this is about S3 access points, not s3 buckets itself. Currently we are not using any Access Points in our VPCs so I cannot filter by anything.\r\n\r\nIts mentioned by loki that these permissions are needed, it might fail if we don't add it."]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/661", "comments": ["no this is plain wrong. just remove the `nodeSelector` field completely. The default will be used which is to run on master nodes"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/656", "comments": ["Adds the /* at the end so objects can be updated (important for auditing)", "Why are we changing this ? I prefer to avoid unnecessary changes.", "Are we sure the bucket name format will always follow this `*-giantswarm-*/*` ?", "I think it's the aim of the PR. If there is no \"-giantswarm-\" in the bucket name, access is forbidden.\r\nI updated the top message for better clarity, because I only understood after reading the origin PR ;)", "Yes, Vodafone uses account-id-giantswarm-audit-logs and I think it makes sens\u00e9 that we en force that in the future", "I'll revert it on monday. It just makes non sense that this rule does not end with -Rule when all the others do", "Might I ask that this be made even more clearly specific to audit logs? Like `*-giantswarm-audit-logs-*/*`? So that the role doesn't accidentally have access to other buckets which could understandably be named with `-giantswarm-`", "@stone-z I thing I did not express the issue properly, I;m sorry.\r\nWhat this changes does is to not block access to s3 buckets containing giantswarm from our management clusters at the VPC level ([s3 gateway endpoint](https://docs.aws.amazon.com/vpc/latest/privatelink/vpc-endpoints-s3.html) that ensure network access goes through the internal amazon network and not the internet) but there are still iam roles that prevents any action on buckets that is not authorized. The role for fluent-bit at customers is limited to s3 calls to this bucket anyway :)\r\n\r\nBut I agree we can enforce that the buckets should contain giantswarm-audit-logs.\r\n\r\nI would like in a near future to have this bucket using crossplane so we provide audit logs by default but that's a far away dream", "Done"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/624", "comments": ["Do we want to go for 1.11.2? Adresses also a CVE\r\n\r\nImprovement - https://github.com/aws/amazon-vpc-cni-k8s/pull/1991 \r\nImprovement - https://github.com/aws/amazon-vpc-cni-k8s/pull/1996 \r\nImprovement - https://github.com/aws/amazon-vpc-cni-k8s/pull/1997 ", "Do I need more changes than just bumping the image as far as you remember?", "ok bumped", "Nope everything should be already done \ud83d\udcaa\ud83c\udffb "]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/600", "comments": ["I don't want to be a pain in the butt but do you think you could rename it to CAPA-Rule to match the pattern of the other policies?"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/588", "comments": ["Needed by the default storage class change", "How come we need custom builds for all these components?", "it's not custom builds, I'm using the same versioningstrategy as we do for cluster-autoscaler.\r\nI'm using the upstream version, but with `-gs<n>` suffix to allow us to version our helm charts.\r\nDoes it make sense?", "yes I understand now."]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/578", "comments": ["should this be 1?", "This will go away complete in the next release so it doesn't really matter"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/572", "comments": ["azurerm_virtual_machine_scale_set is deprecated, azurerm_linux_virtual_machine_scale_set is the newer alternative and I need it for enabling termination events"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/566", "comments": ["we override what ever is in app catalog here"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/555", "comments": ["LGTMIIWFY.\r\n\r\nI think the indent is a bit ahead vs line 16 and below.", "nevermind I saw that wrong \ud83e\udd26\ud83c\udffb "]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/554", "comments": ["Still need this manifest on azure because we need to cleanup old resources before we switch to policy-only"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/551", "comments": ["checked resource names, none of them overlap with the managed app.\r\nIf you still think it's insecure we might add a check as we did with the coredns app", "the naming is different from the app?", "otherwise same comment as with coredns", "yeah see my other comment. There is no overlap, but nothing ensures it'll never happen.\r\nThe goal should be to remove those delete commands from a future release, as soon as all MCs will be upgraded to this release.\r\nOpen to hear your opinions about"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/550", "comments": ["what happens if this is rerun after the app is installed?", "maybe some if that will check if the app exists and delete only if it does not exists yet?", "removing nginx as well in same PR? accident or purpose?", "accident", "restored", "very good point. I thought of this while doing nginx ingress controller (PR coming), didn't check for coredns.\r\nChecking", "how about this?", "looks good if it works as expected :p "]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/548", "comments": ["v1beta1 was removed in 1.22", "Copied from k8scloudconfig", "Copied from k8scloudconfig"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/539", "comments": ["so you gave up on this?", "yeah, it does not work for some reason and I just want to close the whole thing for now and maybe came back later"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/534", "comments": ["```suggestion\r\n# think another pod is able to be scheduled where it's not.\r\n```"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/508", "comments": ["Just in case I grepped installations and didn't find it being set anywhere."]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/482", "comments": ["Can we configure the docker mirroring here? If not, maybe we can use ACR instead of quay here, since this is just for azure? https://portal.azure.com/#blade/Microsoft_Azure_ContainerRegistries/TagMetadataBlade/id/%2Fsubscriptions%2F1be3b2e6-497b-45b9-915f-eb35cae23c6a%2FresourceGroups%2Fgiantswarm-container-registry%2Fproviders%2FMicrosoft.ContainerRegistry%2Fregistries%2Fgiantswarm/repository/giantswarm%2Fazure-disk-attacher", "good catch, let me check how we deal with images in MCs", "According to biscuit we don't have registry mirroring in MCs, so this is not making nodes any less reliable than they already are. Does it work for you @fiunchinho ?", "I'm fine merging it as it is. But if we don't have mirroring, is there a reason NOT to use the azure registry, given that the image is already there?", "I guess the reason is consistency to the other units that use quay.io?", "I'd argue reliability > consistency.\r\n\r\nAnyway, your call."]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/467", "comments": ["Won't it replace existing EBS volumes?", "yes it will, but all the volumes except for `etcd` are ephemeral and any machine roll will create a new disk so it's not an issue"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/466", "comments": ["this kind force that the template is Flatcar and no other OS. is this expected?", "for the moment yes, it made sense to stick with what we already use. unless there's any particular reason to use another OS it doesn't make sense to have more OSes to manage (at least in my eyes anyway).\r\n\r\nit can always be changed in the future if necessary.", "ok. for me at the current time is impossible to say for what this giantnetes-terraform will be used  in the VMware realm. TBH the master, vault and worker modules are even incomplete so this is why I raised this question. But yeah at the end of the day we need to make some choice here and stick with that.", "I'm a bit lost for what this is used. if you pass the template as variable to the module, then you are making the assumption that the template is already uploaded into VMware VSphere.", "good point - i meant to remove this (accidentally carried it over from another manifest)", "fixed.", "small change - not needed", "also sorted."]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/456", "comments": ["That's funny. We also have `Enable DynamicAuditing feature gate` in the same changelog. Should we remove both entries instead since it wasn't released?", "cc @stone-z ", "removed"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/453", "comments": ["`terraform fmt`  would be nice :trollface: ", "![download (11)](https://user-images.githubusercontent.com/1071648/106579874-e097e100-6549-11eb-8ee2-263e66d2604e.png)\r\n\r\ndid that before your comment :)", "yeah saw it after posting :p I bet it was my slow badwitdh"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/447", "comments": ["potentially VM name could have spaces in it, maybe it is better to put double quotes around this variable\r\n\r\n```suggestion\r\nvm_name=\"$(curl -s -H Metadata:true \"http://169.254.169.254/metadata/instance?api-version=2017-08-01\" | jq -r '.compute | .name')\"\r\n```", "I see you removed the `{{if eq .Provider \"aws\" }}` elsewhere, why do we still need this unit for azure only?", "vm names are master/worker. So we don't have spaces there for sure. But just to be safe - sure", "aws unit us above this one. I just duplicated it to not mess with conditions in the unit body. ", "ok"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/442", "comments": ["Looks ok but how was it working so far? Also may be a step backwards when it comes to multi-region support if we are planning to ever do that.", "when the aws command fails the   main  `ExecStart` command exits with 0 (due to the last command  doing just echo) thus silently falining", "We can replace with `/bin/bash -Oe -c '\\`", "It is a new service. We didn't have it before. Also multi-region support has nothing to do with this service.", "Do you know what is this region used for? I quickly checked https://www.vaultproject.io/docs/auth/aws but it didn't make much sense to me. I thought IAM is global service.", "China uses a different STS endpoint, therefore, requires setting a corresponding region explicitly", "And there is example on the page you've referenced\r\n\r\n```\r\nThe region used defaults to us-east-1, but you can specify a custom region like so:\r\n\r\n$ vault login -method=aws region=us-west-2 role=dev-role-iam\r\n\r\nWhen using a custom region, be sure the designated region corresponds to that of the STS endpoint you're using.\r\n```"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/436", "comments": ["why did we change this? To comply with AWS?", "removed. I've used it for few installations where 3 nodes is not enough. But didn't want to merge as I hope autoscaler will solve this on its own"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/433", "comments": ["load balancer and SSH probe with ports 65000  and 22 seems like total cluster fuck to me,  I have no die what is that :p\r\n\r\ncan we add some comment that explains why it configured that way?", "And it also fails during rollout \r\n\r\n```\r\nError: Creating/Updating Load Balancer \"ghost-ingress-lb\" (Resource Group \"ghost\"): network.LoadBalancersClient#CreateOrUpdate: Failure sending request: StatusCode=400 -- Original Error: Code=\"CannotRemoveRuleUsedByProbeUsedByVMSS\" Message=\"Load balancer rule /subscriptions/1be3b2e6-497b-45b9-915f-eb35cae23c6a/resourceGroups/ghost/providers/Microsoft.Network/loadBalancers/ghost-ingress-lb/loadBalancingRules/ingress-lb-fake-rule-for-node-health cannot be removed because the rule references the load balancer probe /subscriptions/1be3b2e6-497b-45b9-915f-eb35cae23c6a/resourceGroups/ghost/providers/Microsoft.Network/loadBalancers/ghost-ingress-lb/probes/ssh-probe that is used as health probe by VM scale set /subscriptions/1be3b2e6-497b-45b9-915f-eb35cae23c6a/resourceGroups/ghost/providers/Microsoft.Compute/virtualMachineScaleSets/ghost-workers. To remove this rule, please update VM scale set to remove the reference to the probe.\" Details=[]\r\n```", "So. The problem is how to rollout changes in VMSS instances.\r\nSince we don't have one resource to be tainted for each worker, but only one VMSS object, I decided to rely on the `Rolling` upgrade mode feature.\r\nThat feature automatically reimages one node at a time (configurable how many in parallel) and waits for it to come back healthy before it goes on with other nodes.\r\nTo understand when a node is healthy, a load balancer probe has to be set. I decided to add a probe on port 22 (not ideal, but does the job for now).\r\nProblem: azure requires the probe to be associated with a load balancer the VMSS belongs to and has to be referenced by an active forwarding rule.\r\nSince I don't want to expose SSH through the load balancer, I used a random port, 65000.\r\nConfusing? Hell yeah.\r\nAlternatives? I don't think so.", "Sure but let's put that as a comment above this :p SO someone reading it later can understand", "added comment"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/427", "comments": ["small thing: below we pin providers, here no. is this wanted? should we pin providers everywhere? "]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/424", "comments": ["```suggestion\r\n  resource_group_name       = var.resource_group_name\r\n```\r\n"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/417", "comments": ["Shouldn't' this be 3.0.0?", "why?", "There are breaking changes like removed `route53_enabled`."]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/397", "comments": ["How do we cleanup the \"legacy\" ingress controller if we drop this line?", "I'll cleanup them manually before merging app into appcollections"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/387", "comments": ["```suggestion\r\n      ExecStartPre=-/usr/bin/docker pull $IMAGE\r\n```", "```suggestion\r\n      ExecStartPre=-/usr/bin/docker stop -t 10 $NAME\r\n      ExecStartPre=-/usr/bin/docker rm -f $NAME\r\n      ExecStartPre=-/usr/bin/docker pull $IMAGE\r\n```", "Not sure if the order matters, but just to be consistent.", "Fine with me :+1:", "```suggestion\r\n### Fixed\r\n```"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/384", "comments": ["not sure why this was an issue only now, but somehow kube-proxy was not scheduled on not-ready nodes and it caused  deadlock since  aws-cni needed access to k8s api in order install CNI", "so adding global `ignore all taints`"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/383", "comments": ["fixed typo"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/381", "comments": ["Can't we hardcode `dex.g8s` here? What's the point of extracting `var.oidc_issuer_dns`?", "Don't like to have it here in case we change issuer"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/380", "comments": ["How about `giantswarm.io/cluster`?", "It's already there in `local.common_tags` https://github.com/giantswarm/giantnetes-terraform/blob/master/modules/aws/vpc/vpc.tf#L11"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/376", "comments": [" I was  testing something and had to spent 2 hours hunting this wrong indentation\r\n\r\nk8s-addons never finished\r\n```\r\n parsing /srv/calico-policy-only.yaml: error converting YAML to JSON: yaml: line 130: did not find expected '-' indicator\r\n```\r\n\r\nwhen you change something like that its a good idea to check if it really did something or not, the change could never be applied", "I apologize. I tested it on godsmack so only the calico-all got applied and not this one as this is only for AWS installations. I will be more careful"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/374", "comments": ["impossible to do via cli? that's sad :p"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/370", "comments": ["I would rather set the value to `false` explicitly here.", "Done"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/352", "comments": ["can we go straight to 1.0.1 ?\r\n", "I've been testing 1.0.1 - i must've overwritten my changes whilst sorting some syntax issues i introduced. I've updated it to 1.0.1 :+1: "]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/347", "comments": ["how will this work for CI?", "I guess we need to add the variable to conveyor jobs.\r\nWill test that scenario before I merge.", "Addressed with https://github.com/giantswarm/conveyor/pull/87"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/342", "comments": ["I think the right name is `m5.xlarge`", "Sorry my bad, typo x.x"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/338", "comments": ["Note it's fired only on first boot.", "I checked it isn't run on reboots and k8s-kubelet still starts."]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/336", "comments": ["Is this comment still valid?", "yep"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/331", "comments": ["Note to myself: I need to add `;;` at the end.", "@calvix because this thing alwas appends we'll have a new line after each restart. Like:\r\n\r\n```\r\nWARNING: CONTROL-PLANE MASTER | giantswarm@ip-10-0-5-45 ~ $ cat /etc/kubelet-environment\r\nMAX_PODS=24\r\nMAX_PODS=24\r\n```\r\n\r\nShould the file be removed just before this line? Like:\r\n\r\n```suggestion\r\nrm -f ${env_file}\r\necho \"MAX_PODS=${MAX_PODS}\" >> ${env_file}\r\n```"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/327", "comments": ["Shouldn't have `transit_` prefix?", "Would be cool to align those.", "Does it mean all the traffic from `cluster_vpc_{public,private}` will go trough VPN? What is there?", "No, it is no transit. It is just a regular virtual private gateway, which can be attached to any VPC (in this case it is attached tp VPCs in China).", "No, it means that we create this rule in all routing tables. And rule itself means that traffic, where the destination is `destination_cidr_block` at line below (in our case it is transit VPC CIDR) is routed via specified gateway", "fixed"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/326", "comments": ["fixing conflicting rules priorities", "aligning naming with aws"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/317", "comments": ["I don't think this works for AWS china, correct?", "No, that's true. For China we don't push this file format. I have probably to create it in flatcar-china.", "Going to add also the use case for China by pushing to S3 `version.txt`", "```suggestion\r\n  if [ \"$AWS_REGION\" != cn-* ]; then\r\n```", "Unfortunately regex in the shell does not work in that way but thank you anyway for the suggestion.", "fyi https://www.networkworld.com/article/2693361/unix-tip-using-bash-s-regular-expressions.html", "I didn't realise you're using sh here."]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/314", "comments": ["we can remvoe lachlan as well"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/308", "comments": ["using VPC cird block association to be as close to TC as possible ( also  increasing VPC size is not really possible so this could be a problem for already existing installations)"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/305", "comments": ["Why do we need this `plan` block now?", "It is related to Kinvolk providing licensed versions of Flatcar via marketplace. @whites11 can give more details", "In theory we should not need this (this is normally used on Azure to get access to paid images, but this one is free).\r\nWe got in touch with Kinvolk to get that fixed, but they didn't solve it yet.\r\nTherefore we need to keep pushing that block in all our API requests that use the flatcar linux free image."]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/300", "comments": ["that might come too late, as new installation platypus is already with /28\r\nhttps://github.com/giantswarm/installations/blob/master/platypus/terraform/bootstrap.sh#L39-L42", "I know\r\nI\u2019m setting up new adidas installation with bigger subnets.\r\nFor others we will need to go through migration "]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/290", "comments": ["why having CF here?", "We had the same CF for workers, I think the reason was that CF is handling the ASG update somehow better than terraform but maybe it was due to some old bug", "I will try use ASG directly", "so I tried to use ASG directly but somehow the change of ignition does not trigger ASG rolling update, no idea why.\r\n\r\nSo that is probabbly reason why we use CF which does the magic of rolling machines for us"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/287", "comments": ["decided to go back to tags, as we don't have version tag created by default and this would mean someone has to do taht manually in china and that would probably get forgotten"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/285", "comments": ["This resource is the one that creates a DNS zone in the installation's resource group and needs to be created always.\r\nUsing the `root_dns_zone_name` variable to enable or disable the creation of this delegated zone is wrong and leads to an error during the terraform execution.\r\nThe variable should be used to just control the creation of the NS records in the delegating zone (such as `azure.gigantic.io`)."]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/279", "comments": ["What is the intention behind of using pod2daemon-flexvol? \r\nIn the comment says to allow Dikastes communicate with Felix but I don\u00b4t see dikastes images.\r\n\r\nIf it is all intended, it could be great to add some info or link in the PR description about new things to understand what are we changing\r\n", "Honestly I have no idea.\r\nThe pod and the comment come from the official .yaml: https://docs.projectcalico.org/v3.9/manifests/calico-etcd.yaml", "I think this should be checked and documented/communicated. It's not fully clear what this or Dikastes does, but what I can find from scarce resources in Calico documentation and Google searches, it seems to be a side-car container used with Envoy in Istio setups and potentially related to network policy configurations. I'm not sure if we should have something like this enabled out of the box, but I'm also wondering if this is requirement when customer wants to run Istio on top of our clusters.\r\n\r\nPing @pipo02mix - do you potentially know more about this wrt. Istio?", "Here is well explained https://github.com/projectcalico/app-policy\r\n\r\nSo it is not only for IStio (you can use to add policies at layer 7 for your apps) but Istio makes it easier to use. I would like to have it, but I would do it in a different story (PR)"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/275", "comments": ["I would still rather have this under `/var/lib/kubelet/plugins/volume/exec` as that is the place where rest of kubelet files are and its also separate volume than root volume", "Done, let's see if the e2e tests pass once again"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/266", "comments": ["Is it because it's potentially deployed before calico?", "Yes, its static pod it needs to run without k8s-api  at all"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/263", "comments": ["this will be added into bootstrap.sh in installations repository. I didn't find any other way how to overcome this.", "Not stopper, but can we use ${path.module} instead of ../../../ ?\r\nSeems cleaner and we protect us against any modification in the code structure"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/262", "comments": ["```suggestion\r\n  # Do not fail on pipefails/errors in bootstrap\r\n```", "```suggestion\r\n  # Do not fail on pipefails/errors in bootstrap\r\n```"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/260", "comments": ["is this still a thing?", "Frankly speaking, I don't know. It was deployed into CP so I'm taking currently running state"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/259", "comments": ["I guess this is start and will be adjusted later", "Yep, this is just a base for tests", "This one is tricky a bit. For services of type `NodePort` or `LoadBalancer` filtering works only with `Local` external traffic policy. In this mode source IP is not changed. That in general affects traffic balancing as requires  nginx ic on every worker. But in case of control-plane that is the case - every worker has IC pod. So no harmful impact here. Onprem we don't need all of this as customers anyway have network access to control-plane API.\r\n\r\nJust bringing this for awareness of @giantswarm/sig-infrastructure "]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/250", "comments": ["`if` again."]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/242", "comments": ["this flag does not exist anymore\r\n\r\nwe did not even have it on KVM so its probably not needed"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/239", "comments": ["we do have `IAM` in aws china, why do you want to disable it?", "same for s3. I think it is completely fine to provision vault in the same way as in other regions", "same as above", "same as above", "Here the reason why I disable this for China. \r\n\r\nI've seen in a past commit that these TF resources have been created during the KMS Auto Unseal feature. \r\n\r\nHence I thought that in case auto unseal is disabled like it must be in China these resources are not necessary and hence can be disabled.\r\n\r\nIf it is not the case then please can you provide here which is the case to have IAM Role when Auto Unseal is disabled?", "Yes, those resources are not required. But all of them were added non because of autounseal, but because cloudconfig size was increased (auto-unesal vault config part was added). And that required using same approach for user-data of the vm as with other nodes. So I think it is good to keep this aligned even if user-data is not going beyond size limit. Otherwise we will need to bring those resources back in case we added any other small piece of configuration for vault nodelater", "Now it makes more sense. \ud83d\udc4d for the insights. Then I made again the change"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/238", "comments": ["no need for uppercase for whole name :P", "```suggestion\r\n- [installation guide for Azure](docs/installation-guide-azure.md).\r\n```\r\nDrop accidental drive-by space :slightly_smiling_face: "]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/235", "comments": ["Why wouldn't we switch to jumbo frames in all installations?", "Not all providers allow Jumbo frames, only AWS so far.\r\n\r\nIt could be also a hypothetical case where a customer workload wouldn\u00b4t be a perfect match (thinking on latency when you need to complete a full 9000 package). Not sure if it is a real scenario but I guess it is worth to be prepared.", "where is this comes from?", "I saw this in calico docs:\r\n\r\n> Note: If using Kubernetes self-hosted manifests, you should modify the veth_mtu value in the Calico ConfigMap instead, and leave \"mtu\" here set to __CNI_MTU__.\r\n\r\nAnd it is configured here for azure (for aws was already defined)\r\nhttps://github.com/giantswarm/giantnetes-terraform/blob/enable_configurable_mtu/templates/master.yaml.tmpl#L37", "So how about setting jubmo for all AWS installations?\r\n\r\nI personally believe that we should only create knobs when we need them and not other way around.", "ack, thx", "I guess maybe we will probably change it in all aws installations but I thought It is better to extract this value to a variable and make it configurable in just one place for all environments instead of requiring going into the template.Then if it is the case, change the default value.\r\n\r\nI had in mind also that when enabled CP with Jumbo frames will cohabit with not upgraded tenant clusters using common MTU. This should not be a problem but not 100% sure.\r\n\r\n@giantswarm/sre", "~~Actually you are right. It's better than changing it it multiple places.~~", "Sorry. This is in single place :P \r\n\r\nIt isn't a blocker for me. I think if this is a value used in a single place it's better to keep it like it was. I'll leave the decision to the guys working more with terraform."]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/233", "comments": ["Did we exceed the limit?", "Yes, with 100 bytes :D", "Is it in GB?\r\n\r\nWhat will happen when this volume becomes full?", "Yes, it is in gigabytes. If it is full - result will be the same as previously - vault will fail.", "So why separate partition? So we can SSH?\r\n\r\nDo you want to make it bigger afterwards?", "Yes, we can adjust it later. But keeping logs separately is good idea in general. "]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/229", "comments": ["Before merging / propagating this, I think we need to take care of current uses of `role=master`. I for example just created one node selector based on this for tenant last week (and yes, I understand this is for CP, but consistency)."]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/220", "comments": ["What's the thing here with `*` and having `[count.index]` in the end? Could this be like following:\r\n```suggestion\r\n  id = \"${aws_vpn_gateway.vpn_gw.[count.index].id}\"\r\n```\r\n\r\n...below in untouched part there seems to be a second occurance of this.", "`0` or `1`?\r\n```suggestion\r\n  gateway_id             = \"${aws_vpn_gateway.vpn_gw[1].id}\"\r\n```", "This block should be dropped completely. It is not in use", "No, it should be `0` here. `vpn_gw` has only one resource. But new terraform explicitly asks for list references. So if vpn vpc route should be created - it will always have same gateway. "]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/218", "comments": ["Is it possible to remove this flag ? and therefore only having the proxy-mode configured in one place (`kube-proxy.yaml`).", "I guess this will be temporary until ipvs gets stable, I guess makes sense to keep that in order to make easier future change to ipvs."]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/214", "comments": ["Which will be the version that will be deployed?", "Yep make sense now. you replied with that https://github.com/giantswarm/installations/pull/670/commits/ce532fd5fe6769b4be8f8f025d224806bfe86473", "in general, the latest is deployed but we keep the version per installation in the `bootstrap.sh` file"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/213", "comments": ["Will it work on german cloud (if we still support it)?", "Nope. But I'll add conditionals for aws china and azure german/stack in separate PR"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/212", "comments": ["Typo", "Look very hackish. Which is the reason for that? The reference is pretty explicit in the `aws_instance.vault` in the line\r\n\r\n```hcl\r\n  iam_instance_profile = \"${aws_iam_instance_profile.vault.id}\"\r\n```\r\n\r\nso Terraform will care about that.", "copy past from worker"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/208", "comments": ["Just to understand here. Why here would `kubectl` fail?", "Dunno. Flapping api, flapping network, etc"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/202", "comments": ["we don't  use these variables", "I have moved the etcd migration to separate file as its same for both cloud providers"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/196", "comments": ["etcdctl is part of CoreOS distribution so I am not so sure we really need to download yet another etcdctl", "do we need to install it automatically? from a security perspective, it  would be best to just have an install file that we can run on demand, but that just opinion, not a blocker", "true", "That's an additional context you should know. But also no strong opinion on this"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/194", "comments": ["I understood that default path for this would be `/var/run/dockershim.sock` - is there some reason to put it under own directory?\r\n\r\nI think that e.g. use of `kubesquash` would be easier when you don't need to know and specify the location of this socket: https://github.com/solo-io/kubesquash/blob/master/cmd/kubesquash/main.go#L44 WDYT?", "Completely agree with that However I've already done the try but kubelet doesn't start and get this error:\r\n\r\n```\r\n`Jan 23 22:17:21 ip-10-0-5-235 sh[16181]: F0123 22:17:21.188498   16208 server.go:261] failed to run Kubelet: failed to create kubelet: failed to listen on \"unix:///var/run/dockershim.sock\": failed to unlink socket file \"/var/run/dockershim.sock\": is a directory`\r\n```\r\n\r\nthis because dockershim.sock does not exist on the host, docker thought you intention is to mount it as a directory\r\nso it created an empty directory there instead\r\n\r\nThat is the reason for this choice", "Oh, wow! Makes sense. Would be perhaps nice to check later if there's a way to get this fixed, but for now I think this is a good workaround."]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/191", "comments": ["Usually 0 is a randomly used port. Isn't that the case?", "No, in this case 0 is disabled"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/190", "comments": ["Definitely, I'm missing here some previous discussion about the architecture, but why etcd must be load balanced and reachable from the external? ", "This could be an improvement for the future may be a discussion for the SIG Infra.\r\n\r\nWe could put Masters under a separate ASG. So 3 AZs = 3 ASGs. When a new Launch Configuration is detected (a change in the user data) automatically a new ASG is created in TF. Then with a separate script we:\r\n\r\n- drain each master\r\n- terminate the instance. Automatically a new instance will be created (since we run in ASG) with a new LaunchConfiguration.\r\n\r\nThe process is automated and less error prone. WDTY?", "These resources here looks pretty redundant. Would be possible to create an unique resource `aws_subnet` and leverage interpolation?", "Same here as said about `aws_subnet`", "Not sure if you can interpolate inside the resource name.\r\n\r\nYou can create modules or one resource with count.\r\nAnyway it is always a good idea to reduce redundant code.\r\n", "> Not sure if you can interpolate inside the resource name.\r\n\r\nNo you can't. Terraform resource name should not know anything about the count of the resource. we should call it simply `worker` and then interpolate with `count` as you said ", "As you can see few lines below your comment there is `  internal = true` so this is internal loadblancer so its not reachable from external sources", "Sorry. Right. I missed that. So it is internal so not reachable. Another question is: for which use cases it is used?", "Yes, we already thought about this but the main problem with ASG is that if your instance dies, all EBS are gone, and this is a problematic for etcd cluster as its very easy to break cluster when some of your nodes are dead.\r\n\r\n with simple ec2 if the master goes down we still have ebs and rerunning terraform will start a new instance with the same data and we are 100% sure we wont break etcd cluster.\r\n\r\nAWS quite often schedule hardware for maintenance or have other events that can cause your instance to be deleted which would in our case means that etcd data on one machine is lost.\r\n\r\nIn general, it would be nice to have  ASG only, but having a very reliable etcd cluster under ASG is very complex. There is a nice blog post about it and it recommends 9 ASGs and 9 nodes in the cluster ( 3 per each AZ).", "Yep, good suggestion, I think we should be able to do that,  but we would need to move subnet values into array", " calico is connecting to etcd so its mostly for calico", "If we are planning to taint and then apply to protect the rollout maybe we can include here  create_before_destroy = true, to avoid the lose of one master if the creation fails.\r\n\r\nExtra point would be create a local-exec script in this resource to check the availability of the resource before destroying the old one. If the resource is created but the health script fail won't be destroyed either.", "Right calico need etcd endpoints in the configuration. This might be another proposal for SIG Infra. What about to remove the ELB from the equation in the future and pass to calico the DNS name of each master to the etcd port (2379 if I'm not wrong). of course, this introduces the problem to keep update the DNS record with the IP address of the master. But this should be probably easily solvable with the introduction of a bit of automation which come with a tool like external-dns. would be possible or do you find any big constraints? The reason for this proposal is because I'm always happy when I'm able to remove from the equation piece of external infra like ELB which participate to increase the bill and have a more neat infra.", "I see that's true. Thank you for the clarification. But would be an amazing improvement (and maybe not hard to implement) something like at the bootstrap of the master node look for any suitable etcd volume (if exists) to mount. Otherwise create a new one. And with this would not matter anymore if we run an EC2 instance inside or outside an ASG.", "\ud83d\udc4d Good level of automation. I like that.", "That's a good idea, But I don't want to add more complexity to this story, this would be a nice fit for a separate issue we can address later, can you create an issue to sig-infra @ferrandinand ", "ok, let\u00b4s do that.", "Agree to address this in a different PR. ", "in latest master this configuration already done with alias\r\nhttps://github.com/giantswarm/giantnetes-terraform/blob/master/templates/master.yaml.tmpl#L2686-L2691", "That's now is tricky. Alias references lb and endpoint will be overridden even if you export domain with `etcd1` dns ", "So for migration it is make sense to add mention about cleaning up alias with `alias etcdctl=` in sudo mode", "\ud83c\udf89 well done. just a small note. would be better have these variable in plural like `subnet_workers`? or better `worker_subnets`? Does it make sense for you? Usually list are plural", "Yeah naming is bad, will try to figure out something, so far I like that same thing start with the same word so when ordering  they are  at the same place:\r\n```\r\nsubnets_worker\r\nsubnets_bastion\r\nsubnets_elb\r\n```\r\n\r\n", "You put the idea into a new issue and put it into sig-infra, if you have and idea how to do this reliably than sure let's do it.", "That might work too, lets create issue fro that and we can easily adress later.", "`{{ .ETCDDomainName }}` on master is actually etcd1 or etcd2 or etcd3 depending on which master it is so we are fine", "Going to do that ;-)", "Going to do that ;-) thank you for the follow up on this. ", "oh, nice then", "typo here?", "`CLoudFormation` -> `CloudFormation`"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/187", "comments": ["this is how persistent path looks in Azure", "we don't need separate paths for mount/volume now, as we use persistent path in both cases"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/180", "comments": ["by default it's only one year, which is not enough and we don't have procedure to roll accounts at the moment.", "We use two VPN endpoints usually"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/178", "comments": ["i don't think this is realible way to check this\r\n\r\ni see in kernel log that initially eth0 is eth0\r\n\r\n```\r\nWARNING: CONTROL-PLANE MASTER | master0 waagent # journalctl -k | grep eth0\r\nNov 21 10:36:47 localhost kernel: IPv6: ADDRCONF(NETDEV_UP): eth0: link is not ready\r\nNov 21 10:36:47 localhost kernel: IPv6: ADDRCONF(NETDEV_CHANGE): eth0: link becomes ready\r\nNov 21 10:38:13 master0 kernel: docker0: port 2(veth0ce66fa) entered blocking state\r\nNov 21 10:38:13 master0 kernel: docker0: port 2(veth0ce66fa) entered disabled state\r\nNov 21 10:38:13 master0 kernel: device veth0ce66fa entered promiscuous mode\r\nNov 21 10:38:13 master0 kernel: IPv6: ADDRCONF(NETDEV_UP): veth0ce66fa: link is not ready\r\nNov 21 10:38:13 master0 kernel: docker0: port 2(veth0ce66fa) entered blocking state\r\nNov 21 10:38:13 master0 kernel: docker0: port 2(veth0ce66fa) entered forwarding state\r\nNov 21 10:38:13 master0 kernel: docker0: port 2(veth0ce66fa) entered disabled state\r\nNov 21 10:38:13 master0 kernel: eth0: renamed from veth24d21b4\r\nNov 21 10:38:13 master0 kernel: eth0: renamed from veth16184a4\r\nNov 21 10:38:14 master0 kernel: IPv6: ADDRCONF(NETDEV_CHANGE): veth0ce66fa: link becomes ready\r\nNov 21 10:38:14 master0 kernel: docker0: port 2(veth0ce66fa) entered blocking state\r\nNov 21 10:38:14 master0 kernel: docker0: port 2(veth0ce66fa) entered forwarding state\r\nNov 21 10:38:14 master0 kernel: eth0: renamed from veth0e99e68\r\nNov 21 10:38:14 master0 kernel: veth0e99e68: renamed from eth0\r\nNov 21 10:38:14 master0 kernel: docker0: port 2(veth0ce66fa) entered disabled state\r\nNov 21 10:38:15 master0 kernel: veth16184a4: renamed from eth0\r\nNov 21 10:38:15 master0 kernel: veth24d21b4: renamed from eth0\r\nNov 21 10:38:15 master0 kernel: docker0: port 2(veth0ce66fa) entered disabled state\r\nNov 21 10:38:15 master0 kernel: device veth0ce66fa left promiscuous mode\r\nNov 21 10:38:15 master0 kernel: docker0: port 2(veth0ce66fa) entered disabled state\r\n\r\n```"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/175", "comments": ["So just to make sure: This is not used anywhere atm. (i.e. no revocation/change needed)?", "Yeah, I used this when testing stuff,  but final installaion on giraffe has different password. You can easily check in installation repo by running `opsctl show secret -i terraform-secrets.yaml -k Terraform.VPNPassword`"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/173", "comments": ["this probably doesn't make sense now, but can be useful for future when route53 is available in China", "templating ipsec config and iptable rules, as this configs require the private and public ip info we don't have at time when terraform ignition is rendered\r\n\r\nthe info is fetched from AWS instance meta-data endpoint"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/172", "comments": ["I changed this so that configmap is create or updated if exists", "restarting ds to force getting updated cm"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/168", "comments": ["oh what this `apt -y install` does?", "I was also wondering what the hell is that?", "git blame shows\r\n\r\n```\r\n-  apt update && apt -y install ed\r\n+  apt update && apt -y install\r\n```\r\n\r\nwe are not using `ed` now, so we can remove it :D", "Wow\r\n", "removing\r\n"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/165", "comments": ["Maybe we can just adjust policy and not remove endpoint?", "good point, done"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/164", "comments": ["isnt this file? if you try mount file that is not there then docker will create folder instead of it\r\nAFAIK lock files are created on demand so after boot the file wont be there", "That is a mount. Volume handles this like few rows below", "do we need similar mount for kube-proxy?", "I didn\u2019t see lock errors in kube-proxy"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/158", "comments": ["we ignore comment values for computing changes, otherwise each run of TF would update the dns zone which does not make sense"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/152", "comments": ["nitpick `${var.forward_logs_enabled ? 1 : 0 }`\r\n\r\nbecause at some places you use with whitespace at some w/o", "same", "same", "sleep 8m?", "trying to debug why azure is failing"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/151", "comments": ["this is new in 3.2.2", "Part of https://github.com/giantswarm/giantswarm/issues/4173", "s/cpu/memory/", "s/cpu/memory/", "s/cpu/memory/"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/148", "comments": ["Do you know why we enable those 3 admission plugins?", "https://github.com/giantswarm/giantswarm/issues/4211#issuecomment-422751994\r\n@pipo02mix wanted them so i assume he has reasons", "ack", "I have arrived late. Yes we want to offer the possibility to configure admission webhooks (validation/mutation) to customers. For version 1.10 and newer they are recommended to be configured as default https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers#is-there-a-recommended-set-of-admission-controllers-to-use"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/145", "comments": ["Does that mean we'll run one more instance than specified? Isn't it more explicit to just add one node to all AWS control planes?", "I understand this that `min == number of workers normally`, `desired == min` and `max == desired + 1` which allows to scale by one during updates?", ">  Isn't it more explicit to just add one node to all AWS control planes?\r\n\r\nIt's more expensive to always run 4 VMs.\r\n\r\n> I understand this that min == number of workers normally, desired == min and max == desired + 1 which allows to scale by one during updates?\r\n\r\nYes.", "Ah, yes. Me dumb."]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/143", "comments": ["os-hardening should be present imo", "I this we also can get rid of this one?"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/137", "comments": ["`stage-debug || true` \r\n\r\nwe also need to survive failure if any, otherwise it won't run `terraform destroy`"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/134", "comments": ["Do we really need `nf_conntrack_ipv4`? it's loaded by default afaik", "I just took a list of modules from official k8s blog post. Maybe it is not required there, but it is idempotent from the CoreOS version", "oki :)"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/131", "comments": ["isn't this more like general things rather than aws specific?", "You probably want to switch back to latest before the merge.", "You probably want to switch back to latest before the merge.", "sure", "Yes, it is general. But used only on AWS as we are overriding default for China"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/120", "comments": ["Do we really need all these settings? Can they be defaults?", "Same here", "Why we don't have kubeproxy config for Azure? Files for AWS and Azure should be almost the same imo, except calico.", "Same here changes from aws worker.yaml should be here too, right?", "That is how default config file looks", "That is how default config file looks", "But why do we need everything specified here? can we only have settings that we override in config?"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/117", "comments": ["We either:\r\n1. call module twice (like here) and module uses some suffixes for resources it creates. But we need to remove hard coding with `_0` `_1` from inside module (module does not know that there are two VPNs at the same time).\r\n2. or just call module once and always have two gateways (module by default creates two vpn gateways)\r\n\r\nI like the first one as this is actual purpose of modules.\r\n\r\nCurrently you have this knowledge (about two vpns) both inside module and when calling module.", "nitpick edit in comment too `aws_customer_gateway_id_0` ", "nitpick, remove `Leave blank to disable VPN setup and enable public access for bastions.` as this is only true for `_0`"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/115", "comments": ["I don't see the `NAME` being used at all and I think we can assume everybody has installations repo in this path.", "Khm, i don't store installations repo in GOPATH", ":D I assumed wrong"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/111", "comments": ["Because `record` is deprecated.", "this `concat` `list` is just workaround, becase element does not support empty list.", "Shouldn't we reference this page here ? https://github.com/giantswarm/giantswarm/wiki/Giant-Swarm-VPN \r\nBastion cidr should be unique across that table", "`Basic` only supports 10 tunnels, so use `VpnGw1` which supports up to 30 tunnels, because we will use it for BYOC guest clusters.", "I'm trying to avoid referencing any internal repos / wiki , because it's open source repo.", "Ah, ok", "Just for my information, did you understood where this recommendation of /28 came from ?", "It's my recommendation, so we can have this as baseline. No strict policy tho. `/28` is used in AWS.\r\n\r\nAny requirements from BYOC side?", "For reference https://github.com/giantswarm/giantswarm/wiki/Giant-Swarm-VPN", "Ok, for info I made it /24 on guest cluster because why not? and I could not find a reason not to.", "`/24` is also fine. In guest clusters we already by design have non-intersecting networks, so we just fine with any range.\r\n\r\nIn VPN server <=> host clusters we should be careful, because we use almost always the same range for host cluster `10.0.0.0/16` That's why i'm recommending to take `10.0.4.0/22` as range and pick up `/28` networks from it. This give us 64 potential host clusters. And we always can pick up another range if this one will be occupied."]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/108", "comments": ["we should remove  cloning from branch after stuff is tested and merged, lets use master only", "sure, was just pushing last branch"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/101", "comments": ["updating to same format as we have in KVM, as this will now do hard fail if g8s secret cannot be fetched"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/100", "comments": ["~Isn't this duplicate of `azurerm_network_security_rule` below?~"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/97", "comments": ["Use 3 workers instead of 4."]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/90", "comments": ["Naming is confusing.  Why use `mount_` and `volume_` prefixes? `device_name_xxx` pretty enough. And i think you have to remove one for `volume_device_name_etcd`.", "I'll adjust naming. Also `volume_device_name_etcd` - that is aws volume attachment. Naming was mostly based on the PR https://github.com/giantswarm/giantnetes-terraform/pull/76\r\n\r\nChanges in ignition files are also there. e.g. https://github.com/giantswarm/giantnetes-terraform/pull/90/files#diff-b3bb19fde7c1bd581f41bd9d02e41b7bR2307", "I see. Then it's fine.", "I did not know get it initially"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/89", "comments": [":heart: ", "maybe lets align the values in both aws and azure?", "Those are equal"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/82", "comments": ["`!` needed to not exit with 1 if tests are disabled. Note `set -e` above it causes failure if any command returns `exit 1`."]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/80", "comments": ["For the real clusters, should I set this var in conveyor? how can I get it from installations?", "Do we really need this here, we have a lot of variables and if we put all of them here it does not really makes sense to me. Default 365 days is fine for me.", "Just use meaningful default in variables.tf. No need to set this everywhere.", "See comments above.", "Same here.", "If it created by terraform it should be destroyed by terraform. No need to destroy it manually", "True now it should be done by Terraform", "But then if I want to setup differnent values depend on the installations, how I inject it as tf var?", "Do you have this plan now? All variables available [here](https://github.com/giantswarm/giantnetes-terraform/blob/master/platforms/aws/giantnetes/variables.tf) and there are bunch of them. \r\nI want to avoid having \"monster\" size `envs.sh`. If you will need this for `viking` you can do this, but i don't think that for every new installation we should decide on logging retention period", "Ok so, for now, we can avoid variables, and set up as default the viking desired value. In the future if there is other client wants a different policy then we can implement. WDYT?\r\n", "let's have a call i'll describe my point :)\r\n\r\ni want to remove it from `envs.sh` not from variables.tf", "You still need to pass this variable to s3 module\r\n\r\nhttps://github.com/giantswarm/giantnetes-terraform/blob/master/platforms/aws/giantnetes/main.tf#L55-L60", "And please also modify variable name e.g. `logs_expiration_days`"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/71", "comments": ["nitpick. Please start from upper case and there is typo in `fro`", "can you please move all storage related part to separate module. Like it's done for S3 buckets\r\n\r\nhttps://github.com/giantswarm/giantnetes-terraform/tree/master/modules/aws/s3", "please move ignition_blob and loader to master module. Like done for aws \r\n\r\nhttps://github.com/giantswarm/giantnetes-terraform/blob/master/modules/aws/master/master.tf#L142-L165", "Let's switch to v3 in separate PR", "may be remove `_big` suffix as you switched to `ignition_config` already.", "let's also move this to master module", "also `account_kind=BlobStorage` and `access_tier=Cold` , because we need only objects and not going to host VM disks there.\r\n", "This actually gives full anonymous access to container", "Do we really need boot diagnostics? we are experts already :trollface: ", "Well, it gives us logs for instance if something fuck ups. If nothing breaks we don't need it. \r\nI am fine with removing it.", "removed for now", "cool, can you please also remove `ed` installation above?"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/70", "comments": [":open_mouth: ", "did not find better way unfortunately :/"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/69", "comments": ["I hope we don't need this, i would like to turn insecure port off in future"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/68", "comments": ["we need that to be able to read `stdin` for `kubectl apply`. See below", "JFYI: when we will do upgrade to new version we also need to bump it here.", "`--force` allows to delete bucket with objects.", "JFYI: we also need to update version, when updating kubernetes"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/62", "comments": ["Why do we need so many information?\r\n\r\nimo we should not really care about `installations` repo here (please note this is open source repo, so link to private repo only when really necessary).\r\n\r\nplease make description small :)", "ok I will be shorter. \r\n\r\nFor the link, I will move it to wiki. But the place where we define this policy is cluster.yaml (the suggestion made by Timo)"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/61", "comments": ["please remove two spaces at the beginneing of the line"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/49", "comments": ["`$$` -> `$` ?", "`$$` -> `$` ?", "`$$` -> `$` ?", "`$$` -> `$` ?", "Noop, it's intentionally, See here https://www.terraform.io/docs/providers/template/d/file.html#inline-templates\r\n\r\n`$$` used to escape `$`", "Ok, my bad\r\nlgtm then"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/48", "comments": ["Using merge is nice"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/43", "comments": ["what does this mean? any link to docs or something like that? or is it just some magic value only AWS knows ?", "here we go https://www.iana.org/assignments/protocol-numbers/protocol-numbers.xhtml"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/38", "comments": ["So, is that one for all, or creds per account?", "per account"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/37", "comments": ["Didn't we agree to start with 0?", "everything else is starting from 0. This one is for compatibility only. People are used to use `master1`"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/36", "comments": ["I would rather make the changes towards `yaml` as we use that for most of our files in and in  other projects too.", "Makes sense. See new changes"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/25", "comments": ["do not use S3 for user data for bastion.", "I will use S3 for master and workers only as they have 16kb+ user_data", "copy/paste of one of the Timo's git comments, which is really useful", "same as for Azure. Symlink will point to cluster-specific tf state backend configuration", "this module just returns version number for \"latest\" coreos.", "find out ami ID", "Idea is to use same users (`passwd`) block for all resources.\r\n1) avoid copy/pasting\r\n2) we can generate users.yaml on the fly (e.g. with `opsctl`)", "bastion ignition template", "here is the interesting part. I've looked on possibility to use [ignition_config](https://www.terraform.io/docs/providers/ignition/d/config.html), but it does not fit well for our case. Problem is that i need to define every particular part of ignition template in terraform. e.g. how to define [systemd unit](https://www.terraform.io/docs/providers/ignition/d/systemd_unit.html#example-usage). I don't like it.\r\n\r\nSo i took alternative approach.\r\n1) generate ignition from yaml-based \"container linux configuration\" files (similar to cloud-config)\r\n2) convert to raw json ignition with `ct` provider. (`ct` is official coreos tool to convert from yaml to ignition)\r\n\r\nOne important thing: [ct terraform provider](https://github.com/coreos/terraform-provider-ct/issues/21) is still not in official terraform repos. Latest release 0.2.0 had issues with user \"groups\", but latest dev version worked fine for me.", "interesting, i have not seen `inline` in the default ignition \r\ni guess its part of `ct`", "i'm using ct. No other way to manage \"raw\" json ignition. \r\n\r\nLook here https://github.com/giantswarm/giantnetes-terraform/blob/dev/platforms/aws/giantnetes/main.tf#L71\r\n\r\nUnfortunately we need to get ct_config provider manually, because it's not in official TF repos. :(", "that sad, but atleast its working\r\nand when we will have CD we dont have to care that much as it  will be part of the CD config", "with in -> within\r\nWhy do we need to create master/workers within vault stage?", "This confuses me a bit. Why stage Vault is bounded to `platforms/aws` and stage Kubernetes - to `platforms/azure`? Such example denies idea of single state management", "In few lines below there is used  'gauss' instead of 'cluster1'  I would pick one and stay consistent", "because we have one terraform manifest for whole cluster and Vault still provisioned with Ansible.", "typo :)"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/13", "comments": ["Is this the storage?", "Do we use Typha in guest clusters?", "We still use old calico in Azure guest clusters and need to update manifests too. So Typha will be added.", "Exactly"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/7", "comments": ["Why do we need that? What uses the credentials?", "1) Storage account used to store terraform state in Azure storage (See envs.sh)\r\n2) Service Principal used by k8s Azure cloud provider to access Azure API (in the future we will use MSI, but it's not the case in near future)", "Do we need to use the cloud provider now?", "What do you mean use cloud provider?\r\n\r\nWe are using cloud provider and we need to configure it (See [here](https://github.com/giantswarm/azure-terraform/blob/master/cloud-config/master.yaml.tmpl#L902-L916)). Only way to avoid this to use MSI, which is not the case for <1.9\r\n\r\nJFYI: In AWS MSI-like stuff works \"out-of-the-box\" we just need to assign IAM policy to VM, so in AWS we don't need any AWS credentials for k8s :stuck_out_tongue_closed_eyes: ", "Yes, we need that to create LB I guess.\r\nLet's also create an follow up issue to make sure we change that.", "yep, follow up here https://github.com/giantswarm/azure-terraform/issues/5"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/2", "comments": ["Why is this specific `/17` mask?", "i'm using 10.0.0.0/16 as vnet (global address space for resource group)\r\n1) first half 10.0.0.0/17 for vms (10.0.0.0/24, 10.0.1.0/24, 10.0.2.0/24, etc.)\r\n2) second half 10.0.128.0/17 for pods\r\n\r\nThe only requirement for this subnet to be part of global vnet.", "One more thing, kubernetes by default will cut this /17 into /24 per node.\r\n\r\nnode1 - 10.0.128.0/24\r\nnode2 - 10.0.129.0/24\r\netc.\r\n\r\n`--node-cidr-mask-size int32                                         Mask size for node cidr in cluster. (default 24)`\r\n\r\nhttps://kubernetes.io/docs/reference/generated/kube-controller-manager/"]}, {"url": "https://github.com/giantswarm/giantnetes-terraform/pull/1", "comments": ["do we issue certs with ip sans 127.0.0.1 for k8s api?", "yes", "I wish we could use small go program to generate those from k8sclouldconfig.", "This reads so much easier than ARM templates...", "As in comment below, small go program it's \"hack\", i need smth like azure-operator or acs-engine to be able to compile both ARM templates and cloud-configs. I agree that it's quet easy to create PoC. But i'm more into using azure-operator for bootsrapping host cluster? Can we think from this point?\r\n\r\nAnd leave this terraform implementation as \"legacy\" kind of thing.", "definitely, but for pure ARM templates i will need some app on top like azure-operator or [acs-engine](https://github.com/Azure/acs-engine)."]}]}, {"url": "https://github.com/cloudfoundry/bosh-cpi-certification.git", "pull_requests": [{"url": "https://github.com/cloudfoundry/bosh-cpi-certification/pull/15", "comments": ["Can you please remove commented-out code?  We prefer to not have commented-out code in our configuration since it is confusing to people who read it."]}, {"url": "https://github.com/cloudfoundry/bosh-cpi-certification/pull/10", "comments": ["@demonwy this is fragile. Does the CPI automatically upsize disks which are smaller than the IaaS minimum?\r\n\r\n@cdutra would it be acceptable/normal for a CPI to automatically give a larger disk if the IaaS doesn't support the smaller, user-requested size?", "@dpb587-pivotal  thanks for your advice. \r\nI think CPI cant not change disk size without the consent of the user.\r\n@cdutra  any suggestion?", "@dpb587-pivotal @demonwy If the IaaS doesn't support that specific size it should fail if specifying smaller than acceptable size. Also it should be documented in the cpi docs on bosh.io", "HI @cdutra I have added the note for disk size. Please refer to https://github.com/cloudfoundry/docs-bosh/pull/429/commits/66ee792fb549c54090a345a7a92c13188a5ec9c1 ."]}]}, {"url": "https://github.com/kathputli/terraform-aws.git", "pull_requests": []}, {"url": "https://github.com/jinnuT/terraform.git", "pull_requests": []}, {"url": "https://github.com/CHQA-IAC/IAC-repo.git", "pull_requests": []}, {"url": "https://github.com/ravi-devarakonda/tf4oci.git", "pull_requests": []}, {"url": "https://github.com/sgordon46/terragoat-integrated.git", "pull_requests": []}, {"url": "https://github.com/lerna-stack/lerna-terraform.git", "pull_requests": [{"url": "https://github.com/lerna-stack/lerna-terraform/pull/11", "comments": ["`WorkingDirectory` \u306f\u6b21\u306e\u30da\u30fc\u30b8\u306b\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u304c\u3042\u308a\u307e\u3059\u3002\r\nhttps://www.freedesktop.org/software/systemd/man/systemd.exec.html#WorkingDirectory=", "@xirc `ExecStart` \u3067\u5b9f\u884c\u3055\u308c\u308b\u30b3\u30de\u30f3\u30c9\u3092\u30bf\u30fc\u30df\u30ca\u30eb\u3067\u5b9f\u884c\u3057\u305f\u5834\u5408\u3001\u30d7\u30ed\u30bb\u30b9\u304c\u30d0\u30c3\u30af\u30b0\u30e9\u30a6\u30f3\u30c9\u3067\u5b9f\u884c\u3055\u308c\u3066\u30b3\u30f3\u30bd\u30fc\u30eb\u304c\u3059\u3050\u8fd4\u3063\u3066\u304d\u307e\u3059\u304b\uff1f\r\n\r\n\u3082\u3057\u30b3\u30f3\u30bd\u30fc\u30eb\u304c\u8fd4\u3063\u3066\u3053\u306a\u3044\u306a\u3089\uff08\u30d7\u30ed\u30bb\u30b9\u304c\u30d5\u30a9\u30a2\u30b0\u30e9\u30a6\u30f3\u30c9\u3067\u52d5\u304f\u306a\u3089\uff09\u3001`ExecStop` \u306e\u6307\u5b9a\u306f\u4e0d\u8981\u304b\u3082\u3057\u308c\u307e\u305b\u3093\u3002`ExecStop` \u3092\u6307\u5b9a\u3057\u306a\u3044\u5834\u5408\u306f\u30c7\u30d5\u30a9\u30eb\u30c8\u3067\uff08`KillSignal` \u3092\u8a2d\u5b9a\u3057\u306a\u3044\u5834\u5408\uff09`SIGTERM` \u304c `ExecStart` \u3067\u8d77\u52d5\u3057\u305f\u30d7\u30ed\u30bb\u30b9\u306b\u9001\u3089\u308c\u307e\u3059\u3002\r\n\r\n> If this option is not specified, the process is terminated by sending the signal specified in KillSignal= or RestartKillSignal= when service stop is requested. \r\n>\r\n> **[systemd.service](https://www.freedesktop.org/software/systemd/man/systemd.service.html#:~:text=If%20this%20option%20is%20not,service%20stop%20is%20requested.)**\r\n\r\n\u3082\u3057\u8d77\u52d5\u3057\u305f\u30d7\u30ed\u30bb\u30b9\u304c\u30b7\u30b0\u30ca\u30eb\u3092\u30cf\u30f3\u30c9\u30ea\u30f3\u30b0\u3057\u306a\u3044\u5834\u5408\u306f\u3001`ExecStop` \u306e\u6307\u5b9a\u304c\u5fc5\u8981\u3067\u3059\u304c\u3001\u305d\u306e\u5834\u5408\u306f `package.json` \u306b `\"stop\"` \u306e\u5b9a\u7fa9\u304c\u5fc5\u8981\u306a\u6c17\u304c\u3057\u307e\u3059\u3002npm \u306e\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u3092\u8aad\u3080\u3068\u3001`\"stop\"` \u306b\u306f\u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u4f55\u3082\u5b9a\u7fa9\u3055\u308c\u3066\u3044\u306a\u3044\u3088\u3046\u306a\u306e\u3067\u3002\r\n\r\n> Unlike with npm start, there is no default script that will run if the \"stop\" property is not defined.\r\n>\r\n> **[npm-stop | npm Docs](https://docs.npmjs.com/cli/v7/commands/npm-stop#:~:text=Unlike%20with,.)**\r\n\r\n\u30b5\u30f3\u30d7\u30eb\u30a2\u30d7\u30ea `v1.0.0` \u306e `package.json` \u3092\u78ba\u8a8d\u3059\u308b\u3068\u3001`\"stop\"` \u306f\u5b9a\u7fa9\u3055\u308c\u3066\u3044\u307e\u305b\u3093\u3067\u3057\u305f\u3002\r\n\r\n> ```json\r\n>   \"scripts\": {\r\n>     \"start\": \"json-server index.js --middlewares middleware.js\"\r\n>   },\r\n> ```\r\n> **[lerna-sample-payment-app/package.json at v1.0.0 \u00b7 lerna-stack/lerna-sample-payment-app](https://github.com/lerna-stack/lerna-sample-payment-app/blob/v1.0.0/docker/mock-server/package.json#L6-L8)**\r\n", "@xirc \r\n\r\nSystemd \u306e\u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb\u3092\u914d\u7f6e\u3057\u305f\u3042\u3068\u306f `systemctl daemon-reload` \u3092\u5b9f\u884c\u3057\u305f\u307b\u3046\u304c\u826f\u3055\u305d\u3046\u3067\u3059\r\n\r\n> \u65b0\u898f\u306e\u30e6\u30cb\u30c3\u30c8\u30d5\u30a1\u30a4\u30eb\u3092\u4f5c\u6210\u3057\u305f\u308a\u3001\u65e2\u5b58\u306e\u30e6\u30cb\u30c3\u30c8\u30d5\u30a1\u30a4\u30eb\u3092\u5909\u66f4\u3057\u305f\u3089\u3001systemctl daemon-reload \u30b3\u30de\u30f3\u30c9\u3092\u5e38\u306b\u5b9f\u884c\u3057\u307e\u3059\u3002\r\n>\r\n> **[\u7b2c10\u7ae0 systemd \u306b\u3088\u308b\u30b5\u30fc\u30d3\u30b9\u7ba1\u7406 Red\u00a0Hat Enterprise Linux 7 | Red Hat Customer Portal](https://access.redhat.com/documentation/ja-jp/red_hat_enterprise_linux/7/html/system_administrators_guide/chap-managing_services_with_systemd#:~:text=%E6%96%B0%E8%A6%8F%E3%81%AE,%E3%81%BE%E3%81%99%E3%80%82)**", "@negokaz \r\n\r\n> ExecStart \u3067\u5b9f\u884c\u3055\u308c\u308b\u30b3\u30de\u30f3\u30c9\u3092\u30bf\u30fc\u30df\u30ca\u30eb\u3067\u5b9f\u884c\u3057\u305f\u5834\u5408\u3001\u30d7\u30ed\u30bb\u30b9\u304c\u30d0\u30c3\u30af\u30b0\u30e9\u30a6\u30f3\u30c9\u3067\u5b9f\u884c\u3055\u308c\u3066\u30b3\u30f3\u30bd\u30fc\u30eb\u304c\u3059\u3050\u8fd4\u3063\u3066\u304d\u307e\u3059\u304b\uff1f\r\n\r\n\u3042\u308a\u304c\u3068\u3046\u3054\u3056\u3044\u307e\u3059\u3002\u78ba\u8a8d\u3057\u307e\u3057\u305f\u3002\r\n\u30d7\u30ed\u30bb\u30b9\u306f\u30d5\u30a9\u30a2\u30b0\u30e9\u30a6\u30f3\u30c9\u3067\u5b9f\u884c\u3055\u308c\u307e\u3057\u305f\u3002\r\n\u505c\u6b62\u3059\u308b\u305f\u3081\u306b\u306f SIGTERM \u3092\u9001\u308b\u307b\u3046\u304c\u9069\u5207\u306e\u3088\u3046\u3067\u3059\u3002\r\nExecStop \u306e\u8a18\u8ff0\u3092\u524a\u9664\u3057\u307e\u3059\u3002", "@negokaz \r\n\r\nExecStop \u306e\u8a18\u8ff0\u3092\u524a\u9664\u3057\u3001SIGTERM \u3067\u30d7\u30ed\u30bb\u30b9\u3092\u7d42\u4e86\u3055\u305b\u308b\u3088\u3046\u306b\u5909\u66f4\u3057\u307e\u3057\u305f\u3002\r\n> Mock server should be terminated by SIGTERM \u2026 569bcbb\r\n\r\n\u4f55\u5ea6\u304b ` sudo systemctl restart mock-server` \u3092\u5b9f\u884c\u3057\u305f\u306e\u3061\u3001  \r\n`ps` \u30b3\u30de\u30f3\u30c9\u3067\u8907\u6570\u306enpm\u30d7\u30ed\u30bb\u30b9\u304c\u8d77\u52d5\u3057\u3066\u3044\u306a\u3044\u3053\u3068\u3082\u78ba\u8a8d\u3057\u307e\u3057\u305f\u3002\r\n```shell\r\n$ ps -aux | grep npm\r\nroot     18591  3.7  0.2 674436 31604 ?        Ssl  04:59   0:00 npm\r\nec2-user 18619  0.0  0.0 112816   976 pts/0    S+   04:59   0:00 grep --color=auto np\r\n```", "@negokaz \r\nsystemd \u306e \u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb\u3092\u66f4\u65b0\u3057\u305f\u3042\u3068\u306b\u3001`systemctl daemon-reload` \u3092\u5b9f\u884c\u3059\u308b\u3088\u3046\u306b\u5909\u66f4\u3057\u307e\u3057\u305f\u3002\r\n> Run `systemctl daemon-reload` after updating the systemd unit file \u2026 4f5651e"]}, {"url": "https://github.com/lerna-stack/lerna-terraform/pull/8", "comments": ["*terraform* \u306e *variable* \u306b\u8a18\u8f09\u3059\u308b *description* \u3068\u3057\u3066\u306f\u9577\u3059\u304e\u308b\u3088\u3046\u306b\u601d\u3063\u305f\u305f\u3081\u3001\r\nREADME \u306b\u3066\u8aac\u660e\u3084\u8a2d\u5b9a\u65b9\u6cd5\u306b\u3064\u3044\u3066\u8a18\u8f09\u3057\u307e\u3057\u305f\u3002\r\n\u5225\u306e\u5834\u6240\u306b\u8a18\u8f09\u3059\u308b\u65b9\u304c\u826f\u3055\u305d\u3046\u3067\u3042\u308c\u3070\u6559\u3048\u3066\u9802\u3051\u308b\u3068\u5b09\u3057\u3044\u3067\u3059\u3002", "`5min` \u3067\u5341\u5206\u3060\u3068\u306f\u601d\u3044\u307e\u3059\u304c\u3001\u3088\u308a\u826f\u3044\u30c7\u30d5\u30a9\u30eb\u30c8\u5024\u306f\u3042\u308a\u307e\u3059\u304b\uff1f", "README\u3067\u826f\u3044\u3068\u601d\u3044\u307e\u3059\u3002", "5\u5206\u3067\u5341\u5206\u3060\u3068\u601d\u3044\u307e\u3059\u3002\r\n\r\n\u9069\u5207\u306a\u30bf\u30a4\u30e0\u30a2\u30a6\u30c8\u306f\u30a2\u30d7\u30ea\u3054\u3068\u306b\u7570\u306a\u308b\u306e\u3067\u30c7\u30d5\u30a9\u30eb\u30c8\u5024\u306f\u3053\u306e\u307e\u307e\u3067\u826f\u3044\u3068\u601d\u3044\u307e\u3059\u3002"]}, {"url": "https://github.com/lerna-stack/lerna-terraform/pull/7", "comments": ["\u6b21\u306e\u30aa\u30d7\u30b7\u30e7\u30f3\u3092\u6307\u5b9a\u3057\u3066\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u30c7\u30fc\u30bf\u306e\u6a29\u9650\u3092\u4fdd\u6301\u3059\u308c\u3070\u3001 https://github.com/lerna-stack/lerna-terraform/pull/7/commits/ba88f688e083a8d5e067b7a0b7ce0cb96e18707d \u306e\u64cd\u4f5c\u306f\u4e0d\u8981\u306b\u306a\u308b\u304b\u3082\u3057\u308c\u307e\u305b\u3093\r\n\r\n> **-p, --preserve-permissions, --same-permissions**\r\n> \r\n> \u30d5\u30a1\u30a4\u30eb\u306e\u8a31\u53ef\u5c5e\u6027\u306b\u95a2\u3059\u308b\u60c5\u5831\u3092\u62bd\u51fa\u3059\u308b (\u30b9\u30fc\u30d1\u30fc\u30e6\u30fc\u30b6\u306e\u30c7\u30d5\u30a9\u30eb\u30c8)\u3002\r\n>\r\n> **[Man page of TAR](http://linuxjm.osdn.jp/html/GNU_tar/man1/tar.1.html#:~:text=%2dp%2c,%E3%81%AE%E3%83%87%E3%83%95%E3%82%A9%E3%83%AB%E3%83%88%29%E3%80%82)**", "@negokaz \r\n\r\n\u305d\u306e\u3084\u308a\u65b9\u3082\u826f\u3055\u305d\u3046\u3067\u3059 \ud83d\udc4d \r\n\u30ea\u30b9\u30c8\u30a2\u624b\u9806\u304c\u6e1b\u308b\u306e\u306f\u5b09\u3057\u3044\u3053\u3068\u3067\u3059\u306d\u3002\r\n\r\n\u300c\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u30c7\u30fc\u30bf\u306b\u542b\u307e\u308c\u308b\u30d5\u30a1\u30a4\u30eb\u306e\u30aa\u30fc\u30ca\u30fc\u3084\u30b0\u30eb\u30fc\u30d7\u304c\u6b63\u3057\u3044\u3053\u3068\u300d\u3092\u78ba\u5b9f\u306b\u4fdd\u8a3c\u3067\u304d\u308b\u306e\u304b\u3068\u3044\u3046\u70b9\u304c\u6c17\u306b\u306a\u308a\u307e\u3059\u3002\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u30c7\u30fc\u30bf\u306e\u4e2d\u8eab\u3092\u30e6\u30fc\u30b6\u304c\u5909\u66f4\u3059\u308b\u3053\u3068\u306f\u306a\u3044\u3068\u601d\u3044\u307e\u3059\u304c\u3001\u660e\u793a\u7684\u306b\u8a2d\u5b9a\u3059\u308b\u65b9\u304c\u30ea\u30b9\u30c8\u30a2\u306e\u624b\u9806\u3068\u3057\u3066\u826f\u3055\u305d\u3046\u306b\u601d\u3044\u307e\u3057\u305f\u3002\r\n\r\n\u624b\u9806\u3092\u6e1b\u3089\u3059\u305f\u3081\u306b `tar` \u306e\u30b3\u30de\u30f3\u30c9\u3092\u8abf\u6574\u3057\u305f\u65b9\u304c\u826f\u3055\u305d\u3046\u3067\u3059\u304b\uff1f\r\n\u660e\u793a\u7684\u306b\u8a2d\u5b9a\u3059\u308b\u5834\u5408\u306e\u554f\u984c\u70b9\u306f\u3042\u308a\u307e\u3059\u304b\uff1f", "@xirc \r\n\r\n\u30aa\u30fc\u30ca\u30fc\u3092\u660e\u793a\u7684\u306b\u6307\u5b9a\u3059\u308b\u65b9\u6cd5\u3067\u554f\u984c\u306a\u3044\u3068\u601d\u3044\u307e\u3059\uff01\r\n\r\n> \u300c\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u30c7\u30fc\u30bf\u306b\u542b\u307e\u308c\u308b\u30d5\u30a1\u30a4\u30eb\u306e\u30aa\u30fc\u30ca\u30fc\u3084\u30b0\u30eb\u30fc\u30d7\u304c\u6b63\u3057\u3044\u3053\u3068\u300d\u3092\u78ba\u5b9f\u306b\u4fdd\u8a3c\u3067\u304d\u308b\u306e\u304b\u3068\u3044\u3046\u70b9\u304c\u6c17\u306b\u306a\u308a\u307e\u3059\u3002\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u30c7\u30fc\u30bf\u306e\u4e2d\u8eab\u3092\u30e6\u30fc\u30b6\u304c\u5909\u66f4\u3059\u308b\u3053\u3068\u306f\u306a\u3044\u3068\u601d\u3044\u307e\u3059\u304c\u3001\u660e\u793a\u7684\u306b\u8a2d\u5b9a\u3059\u308b\u65b9\u304c\u30ea\u30b9\u30c8\u30a2\u306e\u624b\u9806\u3068\u3057\u3066\u826f\u3055\u305d\u3046\u306b\u601d\u3044\u307e\u3057\u305f\u3002\r\n\r\n\u8efd\u304f\u8abf\u3079\u305f\u3068\u3053\u308d `tar` \u306e\u30aa\u30fc\u30ca\u30fc\u306f\uff08UID \u3067\u306f\u306a\u304f\uff09\u540d\u524d\u3067\u8b58\u5225\u3055\u308c\u308b\u3068\u3044\u3046\u60c5\u5831\u304c\u3044\u304f\u3064\u304b\u898b\u3064\u304b\u3063\u305f\u306e\u3067\u3001\u4eee\u306b\u30b5\u30fc\u30d0\u30fc\u3092\u518d\u69cb\u7bc9\u3057\u305f\u308a\u3057\u3066 UID \u304c\u5909\u308f\u3063\u305f\u3068\u3057\u3066\u3082\u3001\u540c\u3058\u540d\u524d\u306e\u30aa\u30fc\u30ca\u30fc\u3067\u5c55\u958b\u3055\u308c\u308b\u3088\u3046\u3067\u3059\u3002\u306a\u306e\u3067\u4eba\u529b\u3067\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u3092\u3068\u3063\u305f\u308a\u3001\u30a2\u30fc\u30ab\u30a4\u30d6\u3092\u66f4\u65b0\u3057\u305f\u308a\u3057\u306a\u3044\u9650\u308a\u306f\u30aa\u30fc\u30ca\u30fc\u306a\u3069\u304c\u4e88\u671f\u3057\u306a\u3044\u72b6\u614b\u306b\u306a\u308b\u3053\u3068\u306f\u7121\u3055\u305d\u3046\u3067\u3059\u3002\r\n\u305f\u3060\u3001\u30a4\u30ec\u30ae\u30e5\u30e9\u30fc\u306a\u904b\u7528\u304c\u884c\u308f\u308c\u308b\u3053\u3068\u3082\u3042\u308a\u3048\u306a\u304f\u306f\u306a\u3044\u306e\u3067\u3001\u78ba\u304b\u306b\u660e\u793a\u7684\u306b\u6307\u5b9a\u3059\u308b\u65b9\u6cd5\u306e\u307b\u3046\u304c\u5b89\u5fc3\u611f\u306f\u3042\u308b\u3088\u3046\u306b\u601d\u3044\u307e\u3057\u305f\u3002\r\n\r\n[tar\u306e\u30aa\u30fc\u30ca\u30fc\u3001\u30d1\u30fc\u30df\u30c3\u30b7\u30e7\u30f3\u306e\u7dad\u6301\u306b\u3064\u3044\u3066 - \u3075\u306aWiki](https://blue-red.ddo.jp/~ao/wiki/wiki.cgi?page=tar%A4%CE%A5%AA%A1%BC%A5%CA%A1%BC%A1%A2%A5%D1%A1%BC%A5%DF%A5%C3%A5%B7%A5%E7%A5%F3%A4%CE%B0%DD%BB%FD%A4%CB%A4%C4%A4%A4%A4%C6)"]}, {"url": "https://github.com/lerna-stack/lerna-terraform/pull/6", "comments": ["[NFS \u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u306e\u8a2d\u5b9a](https://access.redhat.com/documentation/ja-jp/red_hat_enterprise_linux/7/html/storage_administration_guide/nfs-clientconfig) \u306b\u5f93\u3044 `/etc/fstab` \u3092\u8a2d\u5b9a\u3057\u3066\u3044\u307e\u3059\u3002\r\n\r\n```\r\n$ man fstab\r\n\r\n\r\n       The fourth field (fs_mntops).\r\n              This field describes the mount options associated with the filesystem.\r\n\r\n              It is formatted as a comma-separated list of options.  It contains at least the type of mount (ro or rw), plus any additional options appropriate to the filesystem type (including performance-tuning options).  For details, see mount(8) or swapon(8).\r\n\r\n              Basic filesystem-independent options are:\r\n\r\n              defaults\r\n                     use default options: rw, suid, dev, exec, auto, nouser, and async.\r\n\r\n              noauto do not mount when \"mount -a\" is given (e.g., at boot time)\r\n\r\n              user   allow a user to mount\r\n\r\n              owner  allow device owner to mount\r\n\r\n              comment\r\n                     or x-<name> for use by fstab-maintaining programs\r\n\r\n              nofail do not report errors for this device if it does not exist.\r\n\r\n       The fifth field (fs_freq).\r\n              This field is used by dump(8) to determine which filesystems need to be dumped.  Defaults to zero (don't dump) if not present.\r\n\r\n       The sixth field (fs_passno).\r\n              This  field  is used by fsck(8) to determine the order in which filesystem checks are done at boot time.  The root filesystem should be specified with a fs_passno of 1.  Other filesystems should have a fs_passno of 2.  Filesystems within a drive will\r\n              be checked sequentially, but filesystems on different drives will be checked at the same time to utilize parallelism available in the hardware.  Defaults to zero (don't fsck) if not present.\r\n\r\n```\r\n\r\n\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u30b9\u30af\u30ea\u30d7\u30c8\u3067\u306f\u3001`reactivejob` \u30e6\u30fc\u30b6\u304c\u3001\u6bce\u56de\u30de\u30a6\u30f3\u30c8/\u30a2\u30f3\u30de\u30a6\u30f3\u30c8\u3092\u5b9f\u65bd\u3059\u308b\u305f\u3081\u3001\r\n\u30de\u30a6\u30f3\u30c8\u30aa\u30d7\u30b7\u30e7\u30f3(4\u756a\u76ee\u306e\u30d5\u30a3\u30fc\u30eb\u30c9)\u306b\u306f\u3001`noauto`,`user` \u3092\u8ffd\u52a0\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\r\n\r\n5\u756a\u76ee\u30016\u756a\u76ee\u306e\u30d5\u30a3\u30fc\u30eb\u30c9\u306f\u30c7\u30d5\u30a9\u30eb\u30c8\u5024\u3067\u3059\u3002\r\n\u30b5\u30f3\u30d7\u30eb\u306e\u305f\u3081\u3001\u30c7\u30d5\u30a9\u30eb\u30c8\u5024\u3067\u5341\u5206\u3060\u3068\u601d\u3063\u3066\u3044\u307e\u3059\u3002", "\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u3084\u30ea\u30b9\u30c8\u30a2\u306f\u7279\u306b\u91cd\u8981\u306a\u4f5c\u696d\u306b\u306a\u308b\u305f\u3081\u3001\u514d\u8cac\u4e8b\u9805\u3092\u8ffd\u52a0\u3057\u307e\u3057\u305f\u3002\r\n\u8a18\u8f09\u3057\u3066\u3044\u308b\u6587\u3067\u554f\u984c\u304c\u3042\u308b\u5834\u5408\u306b\u306f\u6559\u3048\u3066\u9802\u3051\u308b\u3068\u5b09\u3057\u3044\u3067\u3059\u3002", "ssh key pair \u306f \u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u7528\u30e6\u30fc\u30b6 `reactivejob` \u56fa\u6709\u3067\u4f5c\u6210\u3057\u305f\u307b\u3046\u304c\u826f\u3055\u305d\u3046\u3067\u3059\u304c\u3001\r\n\u30b5\u30f3\u30d7\u30eb\u3068\u3057\u3066\u306e\u7c21\u6f54\u3055\u3092\u4fdd\u3064\u305f\u3081\u5171\u901a\u306e\u30ab\u30ae\u3092\u4f7f\u3063\u3066\u3044\u307e\u3059\u3002", "NFS4 \u3067\u306f portmap\u3001rpcbind\u3001nfslock \u306f\u4e0d\u8981\u3067\u3057\u305f\u3002\r\n`nfs-utils` \u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u3001`nfs-server` \u3092\u8d77\u52d5\u3059\u308b\u3060\u3051\u3067\u3059 \ud83d\ude03 \r\n\r\n## \u53c2\u8003\r\n- [NFS\u30b5\u30fc\u30d0\u30fc\u306e\u69cb\u7bc9\u3064\u3044\u3066\u7e8f\u3081\u3066\u307f\u308b](https://qiita.com/leomaro7/items/bb1b46693614b05df7bd)\r\n- [NFS \u30b5\u30fc\u30d0\u30fc\u306e\u8d77\u52d5\u3068\u505c\u6b62](https://access.redhat.com/documentation/ja-jp/red_hat_enterprise_linux/7/html/storage_administration_guide/s1-nfs-start)\r\n- [NFS \u30b5\u30fc\u30d0\u30fc\u306e\u8a2d\u5b9a](https://access.redhat.com/documentation/ja-jp/red_hat_enterprise_linux/7/html/storage_administration_guide/nfs-serverconfig)", "\u30b5\u30f3\u30d7\u30eb\u3068\u3057\u3066\u306e\u30b7\u30f3\u30d7\u30eb\u3055\u3092\u4fdd\u3064\u305f\u3081\u3001\r\n\u3053\u306e\u30b5\u30fc\u30d0\u306b\u30a2\u30af\u30bb\u30b9\u3067\u304d\u308b\u30e6\u30fc\u30b6\u306f \u8aad\u307f\u66f8\u304d \u3067\u304d\u308b\u3088\u3046\u306b\u306a\u3063\u3066\u3044\u307e\u3059\u3002", "`examples/aws_ec2/modules/nfs-instance` \u3067\u4f7f\u7528\u3055\u308c\u307e\u3059\u3002  \r\n\u500b\u5225\u306e\u30e2\u30b8\u30e5\u30fc\u30eb\u3067\u306f\u306a\u304f\u3001\u30b5\u30f3\u30d7\u30eb\u5168\u4f53\u3067\u6307\u5b9a\u3059\u308b\u307b\u3046\u304c\u826f\u3055\u305d\u3046\u3067\u3057\u305f\u3002\r\n\r\n> [Providers Within Modules](https://www.terraform.io/docs/language/modules/develop/providers.html)\r\n> A module intended to be called by one or more other modules must not contain any provider blocks, with the exception of the special \"proxy provider blocks\" discussed under Passing Providers Explicitly below.", "@xirc \r\n\r\nApache License 2.0 \u306b\u3082\u514d\u8cac\u306e\u6761\u9805\u304c\u3042\u308b\u307f\u305f\u3044\u306a\u306e\u3067\u3001\u305d\u308c\u3068\u77db\u76fe\u3057\u306a\u3044\u3088\u3046\u306b\u904e\u4e0d\u8db3\u306a\u304f\u8868\u73fe\u3067\u304d\u3066\u3044\u308b\u3068\u3088\u308a\u826f\u3044\u304b\u306a\u3068\u601d\u3044\u307e\u3057\u305f\u3002\r\n\r\n\u300cLerna Team **\u53ca\u3073 lerna-terraform \u306e\u30b3\u30f3\u30c8\u30ea\u30d3\u30e5\u30fc\u30bf\u30fc**\u306f\u3001\u672c\u30ea\u30dd\u30b8\u30c8\u30ea\u306b\u542b\u307e\u308c\u308b\u5185\u5bb9\u306b\u3064\u3044\u3066\u6b63\u78ba\u6027\u306b\u306f\u6700\u5927\u9650\u306e\u6ce8\u610f\u3092\u6255\u3063\u3066\u304a\u308a\u307e\u3059\u304c\u3001\u672c\u30ea\u30dd\u30b8\u30c8\u30ea**\u306e\u6210\u679c\u7269\u3092**\u7528\u3044\u3066\u884c\u3046\u4e00\u5207\u306e\u884c\u70ba\u306b\u3064\u3044\u3066\u3001\u4f55\u3089\u306e\u8cac\u4efb\u3092\u8ca0\u3046\u3082\u306e\u3067\u306f\u3042\u308a\u307e\u305b\u3093\u3002\u300d\r\n\r\n- \u30b3\u30df\u30c3\u30bf\u30fc\u3068\u30b3\u30f3\u30c8\u30ea\u30d3\u30e5\u30fc\u30bf\u30fc\u4e21\u65b9\u306b\u8cac\u4efb\u304c\u306a\u3044\u3053\u3068\u3092\u660e\u8a18\r\n- \u300c\u8a18\u8f09\u306e\u60c5\u5831\u300d\u306f\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306b\u9650\u5b9a\u3055\u308c\u3066\u3044\u308b\u611f\u304c\u3042\u308b\u306e\u3067\u300c\u6210\u679c\u7269\u300d\u3068\u8868\u8a18\r\n    - \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u3084\uff08\u4eca\u306f\u306a\u3044\u3067\u3059\u304c\uff09\u30d0\u30a4\u30ca\u30ea\u30c7\u30fc\u30bf\u3082\u300c\u8a18\u8f09\u306e\u60c5\u5831\u300d\u3068\u307f\u306a\u3057\u3066\u826f\u3044\u306e\u304b\u304c\u5c11\u3057\u81ea\u4fe1\u6301\u3066\u307e\u305b\u3093\u3067\u3057\u305f\r\n\r\n> 8. \u8cac\u4efb\u306e\u5236\u9650\r\n> \r\n> \u3044\u304b\u306a\u308b\u6761\u4ef6\u304a\u3088\u3073\u6cd5\u7406\u8ad6\u306b\u304a\u3044\u3066\u3082\u3001\u4e0d\u6cd5\u884c\u70ba\uff08\u904e\u5931\u3092\u542b\u3080\uff09\u3001\u5951\u7d04\u3001\u307e\u305f\u306f\u305d\u306e\u4ed6\u3044\u304b\u306a\u308b\u5834\u5408\u3067\u3082\u3001\u9069\u7528\u3055\u308c\u308b\u6cd5\u5f8b\u307e\u305f\u306f\u66f8\u9762\u3067\u306e\u540c\u610f\u306b\u3088\u3063\u3066\u547d\u3058\u3089\u308c\u306a\u3044\u9650\u308a\u3001\u30b3\u30f3\u30c8\u30ea\u30d3\u30e5\u30fc\u30bf\u30fc\u306f\u672c\u30e9\u30a4\u30bb\u30f3\u30b9\u307e\u305f\u306f\u6210\u679c\u7269\u306e\u4f7f\u3044\u65b9\u306b\u95a2\u9023\u3057\u3066\u751f\u3058\u308b\u76f4\u63a5\u640d\u5bb3\u3001\u9593\u63a5\u640d\u5bb3\u3001\u5076\u767a\u7684\u306a\u640d\u5bb3\u3001\u7279\u5225\u640d\u5bb3\u3001\u61f2\u7f70\u7684\u640d\u5bb3\u3001\u307e\u305f\u306f\u7d50\u679c\u640d\u5bb3\u3092\u542b\u3081\u3001\u55b6\u696d\u6a29\u306e\u640d\u5931\u3001\u696d\u52d9\u306e\u505c\u6b62\u3001\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u30fc\u969c\u5bb3\u307e\u305f\u306f\u8aa4\u4f5c\u52d5\u3001\u305d\u306e\u4ed6\u306e\u5546\u696d\u4e0a\u306e\u640d\u5bb3\u3084\u640d\u5931\u306a\u3069\u3001\u3044\u304b\u306a\u308b\u640d\u5bb3\u306b\u5bfe\u3057\u3066\u3082\u3001\u305f\u3068\u3048\u305d\u3046\u3057\u305f\u640d\u5bb3\u306e\u53ef\u80fd\u6027\u3092\u305f\u3068\u3048\u77e5\u3089\u3055\u308c\u3066\u3044\u305f\u3068\u3057\u3066\u3082\u3001\u3042\u306a\u305f\u306b\u8cac\u4efb\u3092\u8ca0\u308f\u306a\u3044\u3082\u306e\u3068\u3057\u307e\u3059\u3002\r\n>\r\n> **[Apache-2.0](https://licenses.opensource.jp/Apache-2.0/Apache-2.0.html#:~:text=8,%E3%80%82)** \uff08[\u539f\u6587](https://opensource.org/licenses/Apache-2.0#:~:text=8.,damages.)\uff09\r\n", "\u826f\u3055\u305d\u3046\u3067\u3059 \ud83d\udc4d ", "@xirc \r\n\r\n\u3053\u306e\u79d8\u5bc6\u9375\u306f\u30b5\u30fc\u30d0\u30fc\u4e0a\u3067\u4ed6\u306e\u30e1\u30f3\u30d0\u30fc\u304c\u30a2\u30af\u30bb\u30b9\u3067\u304d\u308b\u72b6\u614b\u306b\u306a\u308b\u53ef\u80fd\u6027\u304c\u3042\u308b\u306e\u3067\u3001\u305d\u306e\u65e8\u6ce8\u610f\u66f8\u304d\u3092 `description` \u306b\u66f8\u3044\u3066\u304a\u3044\u305f\u307b\u3046\u304c\u826f\u3055\u305d\u3046\u3067\u3059\u3002\r\n\r\n**\u4f8b\uff1a**\u300c\u3053\u306e\u79d8\u5bc6\u9375\u306f\u30b5\u30fc\u30d0\u30fc\u4e0a\u306b\u914d\u7f6e\u3055\u308c\u307e\u3059\u3002\u30b5\u30fc\u30d0\u30fc\u306b\u30a2\u30af\u30bb\u30b9\u3067\u304d\u308b\u30e1\u30f3\u30d0\u30fc\u5168\u54e1\u304c\u3053\u306e\u79d8\u5bc6\u9375\u306b\u30a2\u30af\u30bb\u30b9j\u53ef\u80fd\u306b\u306a\u308b\u305f\u3081\u3001\u5c02\u7528\u306e\u79d8\u5bc6\u9375\u3092\u65b0\u898f\u4f5c\u6210\u3059\u308b\u3053\u3068\u3092\u304a\u52e7\u3081\u3057\u307e\u3059\u3002\u300d\r\n\r\n\u307e\u305f\u3001`~/.ssh/id_rsa` \u306f `ssh_keygen` \u3067\u751f\u6210\u3055\u308c\u308b\u9375\u306e\u30c7\u30d5\u30a9\u30eb\u30c8\u540d\u3067\u3042\u308a\u4ed6\u306e\u7528\u9014\u3067\u5229\u7528\u3057\u3066\u3044\u308b\u53ef\u80fd\u6027\u304c\u9ad8\u305d\u3046\u306a\u306e\u3067\u3001`~/.ssh/id_rsa_lerna_terraform_sample`  \u306a\u3069\u3092\u30c7\u30d5\u30a9\u30eb\u30c8\u306b\u3057\u3066\u304a\u304f\u306e\u304c\u826f\u3055\u305d\u3046\u306b\u601d\u3044\u307e\u3057\u305f\u3002", "@negokaz \r\n\u3042\u308a\u304c\u3068\u3046\u3054\u3056\u3044\u307e\u3059\uff01\r\n\u306a\u308b\u307b\u3069\u3002\u30e9\u30a4\u30bb\u30f3\u30b9\u306b\u660e\u8a18\u3055\u308c\u3066\u3044\u308b\u3053\u3068\u3092\u5931\u5ff5\u3057\u3066\u3044\u307e\u3057\u305f\u3002\r\n\r\n> Apache License 2.0 \u306b\u3082\u514d\u8cac\u306e\u6761\u9805\u304c\u3042\u308b\u307f\u305f\u3044\u306a\u306e\u3067\u3001\u305d\u308c\u3068\u77db\u76fe\u3057\u306a\u3044\u3088\u3046\u306b\u904e\u4e0d\u8db3\u306a\u304f\u8868\u73fe\u3067\u304d\u3066\u3044\u308b\u3068\u3088\u308a\u826f\u3044\u304b\u306a\u3068\u601d\u3044\u307e\u3057\u305f\u3002\r\n\r\n\u540c\u610f\u3067\u3059\u304c\u3001\u3055\u3089\u306b\u8e0f\u307f\u8fbc\u3093\u3067\u3001\r\n\r\nApache License 2.0 \u306b\u514d\u8cac\u4e8b\u9805\u304c\u8a18\u8f09\u3055\u308c\u3066\u3044\u308b\u306e\u3067\u3001README \u306a\u3069\u306b\u306f**\u514d\u8cac\u4e8b\u9805\u3092\u66f8\u304b\u306a\u3044\u65b9**\u304c\u3088\u308a\u826f\u3055\u305d\u3046\r\n\u306b\u601d\u3044\u307e\u3057\u305f\u3002\u77db\u76fe\u304c\u3042\u308b\u3068\u56f0\u308b\u305f\u3081\u3067\u3059\u3002\r\n\r\n\u514d\u8cac\u4e8b\u9805\u3092\u8ffd\u52a0\u3057\u305f\u30b3\u30df\u30c3\u30c8\u3092 revert \u3057\u3088\u3046\u3068\u601d\u3044\u307e\u3059\u304c\u3069\u3046\u3067\u3057\u3087\u3046\u304b\uff1f \r\n> Add disclaimer statements 52d2f3e\r\n", "@negokaz\r\n\r\n\u305d\u3046\u3067\u3059\u306d\u3002\r\n\r\n\u30c7\u30d5\u30a9\u30eb\u30c8\u5024\u3092\u5143\u306e\u30b3\u30fc\u30c9\u304b\u3089\u5909\u3048\u306a\u3044\u3088\u3046\u306b\u8a2d\u5b9a\u3092\u79fb\u52d5\u3057\u307e\u3057\u305f\u304c\u3001\u30c7\u30d5\u30a9\u30eb\u30c8\u5024\u306f\u5909\u3048\u305f\u65b9\u304c\u3088\u3055\u305d\u3046\u3067\u3059\u3002\r\n\u307e\u305f\u3001\u30e6\u30fc\u30b6\u306e \u30db\u30fc\u30e0 `~/` \u3092\u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u53c2\u7167\u3059\u308b\u306e\u306f\u826f\u304f\u306a\u3044\u3088\u3046\u306b\u601d\u3044\u307e\u3059\u3002\r\n\u30c7\u30d5\u30a9\u30eb\u30c8\u306e\u30ab\u30ae\u306e\u5834\u6240\u306f `${path.module}/resources/id_rsa` \u306b\u79fb\u52d5\u3057\u307e\u3059\u304c\u3069\u3046\u3067\u3057\u3087\u3046\u304b\uff1f\r\n\u516c\u958b\u9375\u306e\u5834\u6240\u3082\u5408\u308f\u305b\u3066 `${path.module}/resource/id_rsa.pub` \u306b\u79fb\u52d5\u3057\u307e\u3059\u3002\r\n\u3064\u3044\u3067\u306b\u3001\u30e6\u30fc\u30b6 `reactivejob` \u7528\u306e\u30ab\u30ae\u3068\u3001\u30e6\u30fc\u30b6 `centos` \u306e\u30ab\u30ae\u3092\u5225\u306b\u3057\u307e\u3059\u3002\r\n\r\n\u6ce8\u610f\u66f8\u304d\u3082\u66f8\u3044\u3066\u304a\u304f\u65b9\u304c\u826f\u3055\u305d\u3046\u3067\u3059\u3002\r\n\u307e\u305f\u3001\u30e6\u30fc\u30b6\u306b `ssh-keygen` \u3067\u30ab\u30ae\u3092\u4f5c\u3063\u3066\u3082\u3089\u3046\u3088\u3046\u306b README \u306b\u624b\u9806\u3092\u8a18\u8f09\u3057\u307e\u3059\u3002", "@xirc \u78ba\u304b\u306b\u30b5\u30f3\u30d7\u30eb\u3067\u500b\u5225\u306b\u9375\u4f5c\u308b\u3068\u30e6\u30fc\u30b6\u30fc\u304c\u8a66\u3059\u4e0a\u3067\u624b\u9593\u304c\u5897\u3048\u305d\u3046\u3067\u3059\u306d\u3002\r\n\r\n\u305f\u3060\u3001\u3053\u306e\u30b5\u30f3\u30d7\u30eb\u3092\u6d41\u7528\u3057\u3066\u672c\u756a\u5411\u3051\u306e\u30ea\u30bd\u30fc\u30b9\u3092\u4f5c\u6210\u3059\u308b\u3053\u3068\u3082\u8003\u3048\u3089\u308c\u308b\u306e\u3067\u3001\u30b3\u30e1\u30f3\u30c8\u3067\u300c`reactivejob` \u56fa\u6709\u306e\u9375\u3092\u4f5c\u308b\u3053\u3068\u3092\u63a8\u5968\u3057\u307e\u3059\u300d\u3068\u6ce8\u610f\u3092\u4fc3\u3057\u305f\u307b\u3046\u304c\u3088\u308a\u89aa\u5207\u304b\u306a\u3068\u601d\u3044\u307e\u3057\u305f\u3002", "\u826f\u3044\u3068\u601d\u3044\u307e\u3059 \ud83d\udc4d ", "@xirc \r\n\r\nRHEL \u306e\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306b\u306f  NFS4 \u5c02\u7528\u3068\u3059\u308b\u30b1\u30fc\u30b9\u3067\u306f\u6b21\u306e\u3088\u3046\u306a\u624b\u9806\u304c\u5fc5\u8981\u3068\u8a18\u8f09\u3055\u308c\u3066\u3044\u307e\u3057\u305f\u304c\u3001\u3053\u308c\u306f\u5bfe\u8c61\u3068\u306f\u306a\u3089\u306a\u3044\u611f\u3058\u3067\u3057\u3087\u3046\u304b\uff1f\r\nRHEL \u306e\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u3067\u306f\u30b5\u30fc\u30d3\u30b9\u540d\u304c `nfs` \u306a\u306e\u3067\u3001\u305d\u3082\u305d\u3082\u30b5\u30fc\u30d3\u30b9\u304c\u5168\u7136\u9055\u3046\uff1f\r\n\r\n> /etc/sysconfig/nfs \u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb\u306b\u4ee5\u4e0b\u306e\u884c\u3092\u8ffd\u52a0\u3057\u3066\u3001NFSv2\u3001NFSv3\u3001UDP \u3092\u7121\u52b9\u5316\u3057\u307e\u3059\u3002\r\n\r\n\r\n> 8.6.7. NFSv4 \u5c02\u7528\u30b5\u30fc\u30d0\u30fc\u306e\u8a2d\u5b9a\r\n>\r\n> **[8.6. NFS \u30b5\u30fc\u30d0\u30fc\u306e\u8a2d\u5b9a Red\u00a0Hat Enterprise Linux 7 | Red Hat Customer Portal](https://access.redhat.com/documentation/ja-jp/red_hat_enterprise_linux/7/html/storage_administration_guide/nfs-serverconfig#nfs4-only)**\r\n", "@xirc \r\n\r\n> Apache License 2.0 \u306b\u514d\u8cac\u4e8b\u9805\u304c\u8a18\u8f09\u3055\u308c\u3066\u3044\u308b\u306e\u3067\u3001README \u306a\u3069\u306b\u306f\u514d\u8cac\u4e8b\u9805\u3092\u66f8\u304b\u306a\u3044\u65b9\u304c\u3088\u308a\u826f\u3055\u305d\u3046\u306b\u601d\u3044\u307e\u3057\u305f\u3002\u77db\u76fe\u304c\u3042\u308b\u3068\u56f0\u308b\u305f\u3081\u3067\u3059\u3002\r\n> \r\n> \u514d\u8cac\u4e8b\u9805\u3092\u8ffd\u52a0\u3057\u305f\u30b3\u30df\u30c3\u30c8\u3092 revert \u3057\u3088\u3046\u3068\u601d\u3044\u307e\u3059\u304c\u3069\u3046\u3067\u3057\u3087\u3046\u304b\uff1f\r\n\r\n\u78ba\u304b\u306b\u6cd5\u7684\u306b\u77db\u76fe\u304c\u306a\u3044\u304b\u691c\u8a3c\u3059\u308b\u306e\u3082\u5927\u5909\u3067\u3059\u3057\u3001\u6d88\u3057\u3066\u3057\u307e\u3063\u3066\u3082\u826f\u3055\u305d\u3046\u3067\u3059\u306d\u3002\r\n\u30c8\u30c3\u30d7\u306e README \u304b\u3089\u30e9\u30a4\u30bb\u30f3\u30b9\u306e\u6761\u6587\u306b\u30a2\u30af\u30bb\u30b9\u3067\u304d\u308b\u3088\u3046\u306b\u306a\u3063\u3066\u3044\u307e\u3059\u3057\u3001\u554f\u984c\u306a\u3044\u3067\u3057\u3087\u3046\u3002", "@xirc \r\n\r\n\u5b89\u5168\u5074\u306b\u5012\u3059\u611f\u3058\u3067\u3059\u306d\u3002\u826f\u3044\u3068\u601d\u3044\u307e\u3059\u3002\r\n\r\n`reactivejob` \u306e\u9375\u306f `resource` \u914d\u4e0b\u3067\u554f\u984c\u306a\u3044\u3068\u601d\u3044\u307e\u3059\u3002`centos` \u306e\u9375\u306f  SSH \u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u304c\u53c2\u7167\u3057\u306b\u3044\u304f\u306e\u3067\u3001`~/.ssh` \u914d\u4e0b\u306e\u307b\u3046\u304c\u3044\u308d\u3044\u308d\u4fbf\u5229\u304b\u306a\u3068\u601d\u3044\u307e\u3057\u305f\u3002Terraform \u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3092\u30ea\u30cd\u30fc\u30e0\u3057\u305f\u308a\u3059\u308b\u3068\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u304c\u9375\u3092\u53c2\u7167\u3067\u304d\u306a\u304f\u306a\u3063\u3066\u3057\u307e\u3044\u307e\u3059\u3057\u3001\u78ba\u304b Linux \u3084 Mac \u3060\u3068\u9375\u304c\u3042\u308b\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306e\u30d1\u30fc\u30df\u30c3\u30b7\u30e7\u30f3\u304c\u7de9\u3044\u3068 `ssh` \u30b3\u30de\u30f3\u30c9\u3067\u7e4b\u3050\u3068\u304d\u306b\u30a8\u30e9\u30fc\u306b\u306a\u3063\u3066\u3057\u307e\u3063\u305f\u3068\u601d\u3046\u306e\u3067\u3002", "@negokaz\r\n\r\nNFS \u306b\u306f\u8a73\u3057\u304f\u3042\u308a\u307e\u305b\u3093\u304c\u3001  \r\n\u30b3\u30e1\u30f3\u30c8\u9802\u3044\u305f\u3082\u306e\u306f NFS4 **\u306e\u307f** \u3092\u30b5\u30dd\u30fc\u30c8\u3057\u3066\u307b\u304b\u306e\u30d7\u30ed\u30c8\u30b3\u30eb\u3092\u4f7f\u7528\u3055\u305b\u306a\u3044\u305f\u3081\u306e\u624b\u9806\u306b\u8aad\u3081\u308b\u306e\u3067\u3001\r\n\u6050\u3089\u304f\u4e0d\u8981\u3060\u3068\u601d\u3044\u307e\u3059\u3002\r\n\r\n\r\n> [\u624b\u98068.2 NFSv4 \u5c02\u7528\u30b5\u30fc\u30d0\u30fc\u306e\u8a2d\u5b9a](https://access.redhat.com/documentation/ja-jp/red_hat_enterprise_linux/7/html/storage_administration_guide/nfs-serverconfig#nfs4-only)\r\n> NFS \u30b5\u30fc\u30d0\u30fc\u3092 NFS \u30d0\u30fc\u30b8\u30e7\u30f3 4.0 \u4ee5\u964d\u306e\u307f\u3092\u30b5\u30dd\u30fc\u30c8\u3059\u308b\u3088\u3046\u306b\u8a2d\u5b9a\u3059\u308b\u65b9\u6cd5\u3092\u8aac\u660e\u3057\u307e\u3059\u3002\r\n\r\n\u30b5\u30f3\u30d7\u30eb\u306b\u542b\u3081\u308b\u30d7\u30e9\u30a4\u30d9\u30fc\u30c8\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306b\u914d\u7f6e\u3059\u308b\u30b5\u30fc\u30d0\u306a\u306e\u3067\u7d30\u304b\u3044\u691c\u8a3c\u306f\u305b\u305a\u3001\r\nNFS\u30b5\u30fc\u30d0\u3068\u3057\u3066\u306e\u30d5\u30a1\u30a4\u30eb\u304c\u30db\u30b9\u30c8\u304c\u3067\u304d\u308b\u3053\u3068\u3057\u304b\u78ba\u8a8d\u3057\u3066\u3044\u307e\u305b\u3093\u3002\r\n\u8a2d\u5b9a\u9805\u76ee\u7b49\u3092\u691c\u8a3c\u3057\u305f\u307b\u3046\u304c\u3088\u308d\u3057\u3044\u3067\u3057\u3087\u3046\u304b\uff1f", "@xirc \r\n\r\n\u3053\u306e\u624b\u9806\u306f\u304a\u305d\u3089\u304f\u5168\u3066\u306e\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u304b\u3089\u306e\u63a5\u7d9a\u3092\u9589\u3058\u308b\u305f\u3081\u306e\u3082\u306e\u3060\u3068\u601d\u3044\u307e\u3059\u304c\u3001`nodetool` \u306a\u3069\u3092\u4f7f\u3063\u3066\u63a5\u7d9a\u3055\u308c\u3066\u3044\u308b\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u6570\u3092\u78ba\u8a8d\u3059\u308b\u65b9\u6cd5\u304c\u3042\u308c\u3070\u3001\u305d\u306e\u78ba\u8a8d\u3092\u3057\u305f\u307b\u3046\u304c\u78ba\u5b9f\u304b\u306a\u3068\u601d\u3044\u307e\u3057\u305f\u3002\r\n\u518d\u63a5\u7d9a\u3057\u3066\u304f\u308b\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u304c\u5c45\u305f\u3068\u304d\u306b\u3001\u305d\u308c\u306b\u6c17\u4ed8\u304b\u305a\u63a5\u7d9a\u304c\u3042\u308b\u307e\u307e\u30ea\u30b9\u30c8\u30a2\u3092\u5b9f\u884c\u3057\u3066\u3057\u307e\u3046\u3053\u3068\u306b\u306a\u308b\u306e\u3067\u3002\r\n\r\n\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u6570\u306e\u78ba\u8a8d\u65b9\u6cd5\u304c\u306a\u3044\u304b\u5c11\u3057\u8abf\u67fb\u3057\u3066\u3044\u305f\u3060\u304f\u3053\u3068\u306f\u53ef\u80fd\u3067\u3059\u304b\uff1f\r\n\u524d\u63d0\u6761\u4ef6\u306b\u300c\u30b5\u30fc\u30d3\u30b9\u3092\u5168\u3066\u505c\u6b62\u3057\u3066\u3044\u308b\u3053\u3068\u300d\u3068\u8a18\u8f09\u3055\u308c\u3066\u3044\u308b\u306e\u3067\u300110\u5206\u3050\u3089\u3044\u8abf\u3079\u3066\u898b\u3064\u304b\u3089\u306a\u3051\u308c\u3070\u7121\u3057\u3067\u3082\u554f\u984c\u306a\u3044\u304b\u306a\u3068\u601d\u3063\u3066\u3044\u307e\u3059\u3002", "@xirc \r\n\r\n\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u30b9\u30af\u30ea\u30d7\u30c8\u306f\u904e\u53bb 3 \u4e16\u4ee3 + \u6700\u65b0 1 \u4e16\u4ee3\u306e\u8a08 4 \u4e16\u4ee3\u5206\u306e\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u3092\u6b8b\u3059\u3088\u3046\u306b\u69cb\u6210\u3055\u308c\u3066\u3044\u308b\u3068\u601d\u3046\u306e\u3067\u3001\u305d\u306e\u3053\u3068\u306b\u3064\u3044\u3066\u3082\u89e6\u308c\u305f\u307b\u3046\u304c\u826f\u3044\u304b\u3082\u3057\u308c\u307e\u305b\u3093\u3002\r\n\r\n> ```bash\r\n> ###############################\r\n> #generation\r\n> ###############################\r\n> function rotate_archives {\r\n>   # \u30b3\u30de\u30f3\u30c9\u30b0\u30eb\u30fc\u30d7\r\n>   {\r\n>       if [[ ${TENANT_ID} == ${TENANT_ID_WITH_LEGACY_BACKUP_FILE_FORMAT} ]] ; then\r\n>           /bin/find ${NODE_BACKUP_DIR} -maxdepth 1 -name \"${BASE_FILE_NAME}_[0-9][0-9][0-9][0-9]*\" -or -name \"${BASE_FILE_NAME}_${TENANT_ID}_*\"\r\n>       else\r\n>           /bin/find ${NODE_BACKUP_DIR} -maxdepth 1 -name \"${BASE_FILE_NAME}_${TENANT_ID}_*\"\r\n>       fi\r\n> \r\n>   } | xargs ls -t -dF |tail --lines=+$((GENERATION_DAIRY+1)) | xargs -I% rm -rf % ;RC=${?}\r\n>   if [[ ${RC} -ne 0 ]] ; then\r\n>       log ${RC} \"generation ${EXECUTE_HOST} is abnormal end.\"\r\n>       exit 1\r\n>   else\r\n>       log ${RC} \"generation ${EXECUTE_HOST} is success.\"\r\n>   fi\r\n> }\r\n> ```\r\n> **[lerna-terraform/APP_cassandra_backup_kick.sh at yamakawa/cassandra-backup \u00b7 lerna-stack/lerna-terraform](https://github.com/lerna-stack/lerna-terraform/blob/28e4727042545938d9a165accd00d457dac8f2f0/modules/service/redhat/core/resources/cassandra/backup/APP_cassandra_backup_kick.sh#L241-L260)**", "> \u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u6570\u306e\u78ba\u8a8d\u65b9\u6cd5\u304c\u306a\u3044\u304b\u5c11\u3057\u8abf\u67fb\u3057\u3066\u3044\u305f\u3060\u304f\u3053\u3068\u306f\u53ef\u80fd\u3067\u3059\u304b\uff1f\r\n\r\n\u627f\u77e5\u3057\u307e\u3057\u305f\u3002\u5c11\u3057\u8abf\u3079\u3066\u307f\u307e\u3057\u3087\u3046\u3002", "@negokaz \r\n\u514d\u8cac\u4e8b\u9805\u306e\u8a18\u8f09\u3092\u524a\u9664\u3057\u307e\u3057\u305f \ud83d\ude04 \r\n> Revert \"Add disclaimer statements\" \u2026 1038571", "> https://github.com/lerna-stack/lerna-terraform/pull/6#discussion_r596569023\r\n\r\n\u624b\u9593\u306f\u5897\u3048\u307e\u3059\u304c\u3001`reactivejob` \u306e\u79d8\u5bc6\u9375&\u516c\u958b\u9375\u3092\u30e6\u30fc\u30b6\u306b\u4f5c\u6210\u3057\u3066\u3082\u3089\u3046\u3088\u3046\u306b\u3057\u307e\u3059\u3002", "@negokaz \r\n\r\n> Manage keypairs, individually \u2026 3130ce4\r\n\r\n`reactivejob` \u3068 `centos` \u304c\u4f7f\u7528\u3059\u308b\u9375\u3092\u5225\u306b\u3057\u307e\u3057\u305f\u3002\r\n`centos` \u3067\u4f7f\u3046\u9375\u306e\u30c7\u30d5\u30a9\u30eb\u30c8\u5024\u306f\u3053\u308c\u307e\u3067\u901a\u308a `~/.ssh/id_rsa` \u3067\u3059\u3002  \r\n`reactivejob` \u3067\u4f7f\u3046\u9375\u306f `./resources/id_rsa_cassandra_backup_user` \u306b\u3057\u307e\u3057\u305f\u3002\r\n`reactivejob` \u5411\u3051\u306e\u9375\u3092\u4f5c\u308b\u624b\u9806\u306f README \u306b\u8a18\u8f09\u3057\u307e\u3057\u305f\u3002\r\n\r\n\r\n> Add triggers to facility-cassandra-backup \u2026 03787f4\r\n\r\n\u4f75\u305b\u3066\u3001\u52d5\u4f5c\u78ba\u8a8d\u7b49\u3067\u9375\u3092\u66f4\u65b0\u3057\u3084\u3059\u3044\u3088\u3046\u306b trigger \u3092\u8ffd\u52a0\u3057\u307e\u3057\u305f\u3002", "> Add a caution about the backup user's private key 22f1ea2\r\n\r\n\u9375\u306b\u95a2\u3059\u308b\u6ce8\u610f\u4e8b\u9805\u3092 README \u306b\u3082\u8a18\u8f09\u3057\u307e\u3057\u305f\u3002", "\u6b21\u306e\u30c7\u30a3\u30b9\u30ab\u30c3\u30b7\u30e7\u30f3\u306b\u95a2\u9023\u3057\u3066\u3044\u307e\u3059\u3002\r\n\r\n> https://github.com/lerna-stack/lerna-terraform/pull/6#discussion_r596658455\r\n> reactivejob \u3068 centos \u304c\u4f7f\u7528\u3059\u308b\u9375\u3092\u5225\u306b\u3057\u307e\u3057\u305f\u3002\r\n> centos \u3067\u4f7f\u3046\u9375\u306e\u30c7\u30d5\u30a9\u30eb\u30c8\u5024\u306f\u3053\u308c\u307e\u3067\u901a\u308a ~/.ssh/id_rsa \u3067\u3059\u3002\r\n> reactivejob \u3067\u4f7f\u3046\u9375\u306f ./resources/id_rsa_cassandra_backup_user \u306b\u3057\u307e\u3057\u305f\u3002\r\n> reactivejob \u5411\u3051\u306e\u9375\u3092\u4f5c\u308b\u624b\u9806\u306f README \u306b\u8a18\u8f09\u3057\u307e\u3057\u305f\u3002\r\n\r\n\u624b\u9593\u306f\u5897\u3048\u307e\u3059\u304c\u3001`reactivejob` \u306e\u30ad\u30fc\u30da\u30a2\u3092\u30e6\u30fc\u30b6\u306b\u4f5c\u6210\u3057\u3066\u3082\u3089\u3046\u3088\u3046\u306b\u3057\u307e\u3057\u305f\u3002\r\n\u3053\u306e\u79d8\u5bc6\u9375\u306f Cassandra \u30b5\u30fc\u30d0\u9593\u3067\u5171\u6709\u3055\u308c\u308b\u3053\u3068\u3082 README \u306b\u8a18\u8f09\u3057\u307e\u3057\u305f\u3002", "@xirc \u78ba\u304b\u306b\u3001\u30b5\u30f3\u30d7\u30eb\u306a\u306e\u3067\u30d5\u30a1\u30a4\u30eb\u306e\u8aad\u307f\u66f8\u304d\u304c\u3067\u304d\u308b\u3053\u3068\u304c\u78ba\u8a8d\u3067\u304d\u3066\u3044\u308c\u3070\u554f\u984c\u306a\u3055\u305d\u3046\u3067\u3059\u3002\r\n\u8ffd\u52a0\u306e\u691c\u8a3c\u306f\u306a\u3057\u3067\u3044\u304d\u307e\u3057\u3087\u3046\u3002", "> [How to know Native Clients connected to Cassandra](https://stackoverflow.com/questions/54212510/how-to-know-native-clients-connected-to-cassandra)\r\n> `sudo lsof -i -n -P | grep 9042 | grep ESTABLISHED`\r\n\r\n`lsof` \u3084 `netstat` \u3092\u4f7f\u3048\u3070\u78ba\u8a8d\u3067\u304d\u305d\u3046\u3067\u3059\u306d\u3002\r\n\r\n> [nodetool clientstats --all](https://cassandra.apache.org/doc/latest/tools/nodetool/clientstats.html)\r\n\r\nCassandra 4.x \u306b\u306a\u308b\u3068 `nodetool clientstats` \u304c\u4f7f\u3048\u305d\u3046\u3067\u3059\u3002\r\n\r\n```shell\r\n$ netstat --tcp -a | grep 9042\r\ntcp        0      0 ip-10-0-1-61.ap-no:9042 0.0.0.0:*               LISTEN\r\ntcp        0     25 ip-10-0-1-61.ap-no:9042 10.0.1.51:44638         ESTABLISHED\r\ntcp        0      0 ip-10-0-1-61.ap-no:9042 10.0.1.51:44772         ESTABLISHED\r\ntcp        0      0 ip-10-0-1-61.ap-no:9042 10.0.1.51:44768         ESTABLISHED\r\ntcp        0      0 ip-10-0-1-61.ap-no:9042 10.0.1.51:44752         ESTABLISHED\r\ntcp        0      0 ip-10-0-1-61.ap-no:9042 10.0.1.51:44742         ESTABLISHED\r\ntcp        0      0 ip-10-0-1-61.ap-no:9042 10.0.1.51:44758         ESTABLISHED\r\ntcp        0      0 ip-10-0-1-61.ap-no:9042 10.0.1.51:44744         ESTABLISHED\r\ntcp        0     25 ip-10-0-1-61.ap-no:9042 10.0.1.51:44640         ESTABLISHED\r\ntcp        0      0 ip-10-0-1-61.ap-no:9042 10.0.1.51:44740         ESTABLISHED\r\ntcp        0      0 ip-10-0-1-61.ap-no:9042 10.0.1.51:44632         ESTABLISHED\r\n```\r\n\r\n\u30a2\u30d7\u30ea\u30b5\u30fc\u30d0\u304c `10.0.1.51` \u3067\u3001 Cassandra \u30ce\u30fc\u30c9 `10.0.1.61` \u3067\u5b9f\u884c\u3057\u307e\u3057\u305f\u3002\r\n\u3059\u3079\u3066\u306e\u30ce\u30fc\u30c9\u306b\u30ed\u30b0\u30a4\u30f3\u3057\u3066\u78ba\u8a8d\u3059\u308c\u3070\u826f\u3055\u305d\u3046\u3067\u3059\u3002", "@negokaz \r\n\r\n> Add descriptions of how to check there are no Cassandra clients bc41ff7\r\n\r\n`netstat` \u3092\u4f7f\u3063\u3066\u78ba\u8a8d\u3059\u308b\u65b9\u6cd5\u3092\u8a18\u8f09\u3057\u307e\u3057\u305f\u3002", "@negokaz \r\n> Add descriptions about a backup rotation c0c26c6\r\n\r\n\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u30d5\u30a1\u30a4\u30eb\u306e\u30ed\u30fc\u30c6\u30fc\u30b7\u30e7\u30f3\u4ed5\u69d8\u3092\u8a18\u8f09\u3057\u307e\u3057\u305f\u3002", "\u826f\u3055\u305d\u3046\u3067\u3059  \ud83d\udc4d ", "@xirc \r\n\r\n>   \u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u30b9\u30af\u30ea\u30d7\u30c8\u306b\u306f\u3001\u4f55\u4e16\u4ee3\u5206\u306e\u30ed\u30b0\u3092\u6b8b\u3059\u304b\u3092\u8a2d\u5b9a\u3059\u308b\u5909\u6570\u304c\u3042\u308a\u307e\u3059\u304c\u3001\u3053\u306e\u5909\u6570\u3092\u66f8\u304d\u63db\u3048\u308b\u3053\u3068\u306f\u975e\u63a8\u5968\u3067\u3059\u3002\r\n\r\n\u3053\u308c\u306f\u3001Terraform \u306b\u3088\u3063\u3066\u4e0a\u66f8\u304d\u3055\u308c\u308b\u53ef\u80fd\u6027\u304c\u3042\u308b\u304b\u3089\u3067\u3059\u304b\u306d\uff1f", "@xirc \r\n\r\n`generate-variables-example.sh` \u304c\u30d2\u30a2\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u8a18\u6cd5\u3092\u30b5\u30dd\u30fc\u30c8\u3057\u3066\u3044\u306a\u3044\u306e\u3067 check \u304c\u843d\u3061\u308b\u3088\u3046\u306b\u306a\u3063\u3066\u3057\u307e\u3044\u307e\u3057\u305f\u2026\r\n\r\n```\r\n\u276f bin/generate-variables-example.sh check-tfvars examples/aws_ec2/variables.tf\r\n\u30d5\u30a1\u30a4\u30eb examples/aws_ec2/terraform.tfvars.example \u3068 /dev/fd/62 \u306f\u7570\u306a\u308a\u307e\u3059\r\n\r\nexamples/aws_ec2/variables.tf \u304c\u5909\u66f4\u3055\u308c\u3066\u3044\u308b\u305f\u3081\u3001terraform.tfvars.example \u306e\u66f4\u65b0\u304c\u5fc5\u8981\u3067\u3059\u3002\r\n'generate-variables-example.sh generate-tfvars \"examples/aws_ec2/variables.tf\"' \u3092\u5b9f\u884c\u3057\u3066\u304f\u3060\u3055\u3044\u3002\r\n```\r\n\r\nCI \u3067\u306e\u30c1\u30a7\u30c3\u30af\u304c\u96e3\u3057\u304f\u306a\u308b\u306e\u3067 `cassandra_backup_user_ssh_private_key_filepath` \u306e `description` \u3092\u6539\u884c\u305b\u305a\u306b 1 \u884c\u306b\u3057\u307e\u305b\u3093\u304b\uff1f1 \u884c\u304c\u9577\u304f\u306a\u3063\u3066\u3057\u307e\u3044\u307e\u3059\u304c\u3001\u304e\u308a\u304e\u308a\u8a31\u5bb9\u7bc4\u56f2\u304b\u306a\u3068\u601d\u3044\u307e\u3059\u3002\r\n\r\n\u30c4\u30fc\u30eb\u306e\u307b\u3046\u3092\u4fee\u6b63\u3067\u304d\u308c\u3070\u7406\u60f3\u7684\u3067\u3059\u304c\u3001\u3059\u3050\u306b\u306f\u5bfe\u5fdc\u96e3\u3057\u305d\u3046\u3067\u3059\u3002", "> \u3053\u308c\u306f\u3001Terraform \u306b\u3088\u3063\u3066\u4e0a\u66f8\u304d\u3055\u308c\u308b\u53ef\u80fd\u6027\u304c\u3042\u308b\u304b\u3089\u3067\u3059\u304b\u306d\uff1f\r\n\r\n\u306f\u3044\u3001\u305d\u3046\u3067\u3059\u3002", "@negokaz \r\n\u5229\u7528\u8005\u306b\u3088\u308b\u30b9\u30af\u30ea\u30d7\u30c8\u306e\u66f8\u304d\u63db\u3048\u304c\u3042\u308b\u306e\u304b\u3001\u3092\u898b\u76f4\u3057\u3066\u307f\u307e\u3057\u305f\u3002\r\n\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u3092\u53d6\u5f97\u3059\u308b\u306b\u306f\u3001\u5229\u7528\u8005\u304c\u624b\u52d5\u3067\u30b9\u30af\u30ea\u30d7\u30c8\u3092\u66f8\u304d\u63db\u3048\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3057\u305f\u3002\r\n\r\n> https://github.com/lerna-stack/lerna-terraform/pull/6/files/28e4727042545938d9a165accd00d457dac8f2f0#diff-1c437ea2477b86000343cec75b1adcffe462c58d6c668488c383c425cc71b65bR20\r\n>  `/opt/management/bin/APP_cassandra_backup_kick.sh` \u306b\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u5bfe\u8c61\u306e Cassandra \u30b5\u30fc\u30d0\u306e IP \u30a2\u30c9\u30ec\u30b9\u304c\u5909\u6570(`PROD_HOSTS`, `DR_HOSTS`) \u306b\u30cf\u30fc\u30c9\u30b3\u30fc\u30c9\u3055\u308c\u3066\u3044\u307e\u3059\u3002  \r\n  \u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u30b9\u30af\u30ea\u30d7\u30c8\u3092\u8d77\u52d5\u3059\u308b Cassandra \u30b5\u30fc\u30d0\u306b\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3055\u308c\u3066\u3044\u308b `/opt/management/bin/APP_cassandra_backup_kick.sh` \u306e\u5909\u6570\u3092\u624b\u52d5\u3067\u66f8\u304d\u63db\u3048\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\r\n\r\n\u30ed\u30fc\u30c6\u30fc\u30b7\u30e7\u30f3\u4ee5\u5916\u306e\u7b87\u6240\u3067\u5229\u7528\u8005\u306e\u66f8\u304d\u63db\u3048\u304c\u5fc5\u8981\u306b\u306a\u3063\u3066\u3044\u308b\u3081\u3001\u6b21\u306e\u8aac\u660e\u306f\u7121\u3044\u65b9\u304c\u826f\u3055\u305d\u3046\u306b\u601d\u3048\u307e\u3059\u3002\r\n\u6b21\u306e1\u6587\u3092\u524a\u9664\u3057\u3088\u3046\u3068\u601d\u3044\u307e\u3059\u304c\u3069\u3046\u3067\u3057\u3087\u3046\u304b\uff1f\r\n\r\n> \u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u30b9\u30af\u30ea\u30d7\u30c8\u306b\u306f\u3001\u4f55\u4e16\u4ee3\u5206\u306e\u30ed\u30b0\u3092\u6b8b\u3059\u304b\u3092\u8a2d\u5b9a\u3059\u308b\u5909\u6570\u304c\u3042\u308a\u307e\u3059\u304c\u3001\u3053\u306e\u5909\u6570\u3092\u66f8\u304d\u63db\u3048\u308b\u3053\u3068\u306f\u975e\u63a8\u5968\u3067\u3059\u3002", "@negokaz \r\n> Use an one-line string instead of a here document \u2026 304a522\r\n\r\n\u5909\u66f4\u3057\u307e\u3057\u305f\u3002", "@xirc \r\n\r\n> \u30ed\u30fc\u30c6\u30fc\u30b7\u30e7\u30f3\u4ee5\u5916\u306e\u7b87\u6240\u3067\u5229\u7528\u8005\u306e\u66f8\u304d\u63db\u3048\u304c\u5fc5\u8981\u306b\u306a\u3063\u3066\u3044\u308b\u3081\u3001\u6b21\u306e\u8aac\u660e\u306f\u7121\u3044\u65b9\u304c\u826f\u3055\u305d\u3046\u306b\u601d\u3048\u307e\u3059\u3002\r\n> \u6b21\u306e1\u6587\u3092\u524a\u9664\u3057\u3088\u3046\u3068\u601d\u3044\u307e\u3059\u304c\u3069\u3046\u3067\u3057\u3087\u3046\u304b\uff1f\r\n\r\n\u306a\u308b\u307b\u3069\u3002\u826f\u3044\u3068\u601d\u3044\u307e\u3059 \ud83d\udc4d ", "@negokaz \r\n> Remove the unnecessary statement d9cab3e\r\n\r\n\u524a\u9664\u3057\u307e\u3057\u305f \ud83d\ude04 "]}, {"url": "https://github.com/lerna-stack/lerna-terraform/pull/5", "comments": ["@xirc \r\n\r\n\u3053\u308c\u3089\u306e\u30d5\u30a1\u30a4\u30eb\u3092\u30b5\u30f3\u30d7\u30eb\u30a2\u30d7\u30ea\u306e RPM \u306b\u540c\u68b1\u3057\u3066\u304a\u304f\u3068\u3044\u3046\u65b9\u5f0f\u306f\u3069\u3046\u3067\u3057\u3087\u3046\u304b\uff1f\r\n\r\n\u3059\u3067\u306b `CHANGELOG.md` \u3092 RPM \u306b\u540c\u68b1\u3059\u308b\u5b9a\u7fa9\u304c `build.sbt` \u306b\u66f8\u304b\u308c\u3066\u3044\u308b\u305f\u3081\u3001\u3053\u3053\u306b\u30e2\u30c3\u30af\u30b5\u30fc\u30d0\u30fc\u304c\u5fc5\u8981\u3068\u3059\u308b\u30d5\u30a1\u30a4\u30eb\u306e\u5b9a\u7fa9\u3092\u8ffd\u8a18\u3057\u3066\u3044\u3051\u3070\u540c\u68b1\u3055\u308c\u308b\u306f\u305a\u3067\u3059\u3002\r\n\r\n```scala\r\n        packageMapping(\r\n          (baseDirectory.value / \"CHANGELOG.md\") -> (defaultLinuxInstallLocation.value + s\"/${name.value}\" + \"/CHANGELOG.md\"),\r\n        ),\r\n```\r\n[lerna-sample-payment-app/build.sbt at main \u00b7 lerna-stack/lerna-sample-payment-app](https://github.com/lerna-stack/lerna-sample-payment-app/blob/44585f969c57d612bb4b0ee6f78745a3f1c5c3c5/build.sbt#L91-L93)", "@xirc \r\n\r\n\u30b5\u30f3\u30d7\u30eb\u3067\u305d\u3053\u307e\u3067\u3059\u308b\u306e\u304b\u3068\u3044\u3046\u8b70\u8ad6\u3082\u3042\u308a\u305d\u3046\u3067\u3059\u304c\u3001\u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u4fc2\u6570\u304c 1 \u3060\u3068 Cassandra \u30ce\u30fc\u30c9\u304c\u30af\u30e9\u30c3\u30b7\u30e5\u3057\u3066\u3082\u56de\u5fa9\u3067\u304d\u308b\u304b\u3069\u3046\u304b\u3092\u8a66\u3057\u305f\u3044\u5834\u5408\u306b\u56f0\u308a\u305d\u3046\u3067\u3059\u3002\r\n\r\n\u30c7\u30d5\u30a9\u30eb\u30c8\u306e\u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u4fc2\u6570\u3092 3 \u306b\u3057\u3066\u304a\u3044\u3066\u300cCassandra \u306e\u30ce\u30fc\u30c9\u6570\u304c 3 \u3088\u308a\u5c11\u306a\u3044\u5834\u5408\u306f\u30ce\u30fc\u30c9\u6570\u306b\u5408\u308f\u305b\u3066\u6e1b\u3089\u3057\u3066\u304f\u3060\u3055\u3044\u300d\u3068\u3044\u3046\u6ce8\u610f\u66f8\u304d\u3092\u66f8\u3044\u3066\u304a\u304f\u3068\u826f\u3044\u3088\u3046\u306a\u6c17\u304c\u3057\u307e\u3057\u305f\u3002\r\n\r\n\u307e\u305f\u3001\u3053\u308c\u3092\u5bfe\u5fdc\u3059\u308b\u5834\u5408\u306f\u3001\u2193 \u306b\u4e00\u8a00\u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u4fc2\u6570\u3092\u78ba\u8a8d\u3057\u3066\u304f\u3060\u3055\u3044\u3068\u3044\u3046\u6ce8\u610f\u66f8\u304d\u3092\u8ffd\u52a0\u3057\u305f\u307b\u3046\u304c\u826f\u3044\u304b\u306a\u3068\u601d\u3063\u3066\u3044\u307e\u3059\u3002\r\n\r\n> Cassandra \u3092\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\u3059\u308b\r\n>\r\n> [lerna-terraform/README_lerna-sample-payment-app.md at 768e11214608b0433adc3e8afa25492361b677b7 \u00b7 lerna-stack/lerna-terraform](https://github.com/lerna-stack/lerna-terraform/blob/768e11214608b0433adc3e8afa25492361b677b7/examples/aws_ec2/README_lerna-sample-payment-app.md#cassandra-%E3%82%92%E3%82%BB%E3%83%83%E3%83%88%E3%82%A2%E3%83%83%E3%83%97%E3%81%99%E3%82%8B)", "@xirc\r\n\r\n\u6b21\u306e\u30ec\u30d3\u30e5\u30fc\u89b3\u70b9\u306b\u3082\u95a2\u308f\u3063\u3066\u304d\u305d\u3046\u306a\u8a71\u3067\u3059\u304c\u3001`examples/aws_ec2` \u306f `lerna-sample-payment-app` \u3092\u30c7\u30d7\u30ed\u30a4\u3059\u308b\u524d\u63d0\u306b\u3057\u3066\u3082\u826f\u3044\u3088\u3046\u306a\u6c17\u304c\u3057\u307e\u3057\u305f\u3002`facility-lerna-stack.tf` \u306b\u3082 `lerna-sample-payment-app` \u5411\u3051\u306e\u8a2d\u5b9a\u304c\u57cb\u3081\u8fbc\u307e\u308c\u307e\u3059\u3057\u3001\u5225\u306e RPM \u3092\u30c7\u30d7\u30ed\u30a4\u3059\u308b\u3053\u3068\u306f\u8003\u3048\u306a\u304f\u3066\u3082\u3088\u3044\u306e\u304b\u306a\u3068\u601d\u3044\u307e\u3057\u305f\u3002\r\n\r\n> - \u3053\u306e\u30ea\u30dd\u30b8\u30c8\u30ea\u306bCQL\u6587\u3092\u914d\u7f6e\u3057\u3066\u304a\u304f\u306e\u306f\u3001\u9069\u5207\u306a\u65b9\u6cd5\u304b\uff1f\r\n> - \u30e6\u30fc\u30b6\u304c\u30b3\u30d4\u30fc\u3057\u3066SQL\u6587\u3092\u6e96\u5099\u3059\u308b\u306e\u306f\u3001\u9069\u5207\u306a\u65b9\u6cd5\u304b\uff1f", "\u30b5\u30f3\u30d7\u30eb\u3092\u8a66\u3057\u305f\u3044\u30e6\u30fc\u30b6\u306e\u624b\u9593\u304c\u6e1b\u308b\u305f\u3081\u826f\u3055\u305d\u3046\u306b\u601d\u3044\u307e\u3059\u3002\u5909\u66f4\u3057\u3066\u307f\u307e\u3059\u3002", "`examples/aws_ec2` \u306f `lerna-sample-payment-app` \u3092\u30c7\u30d7\u30ed\u30a4\u3059\u308b\u305f\u3081\u306e\u30b5\u30f3\u30d7\u30eb\u3068\u3057\u3066\u3082\u826f\u3055\u305d\u3046\u3067\u3059\u306d\u3002\r\n\u6b21\u306e\u5909\u66f4\u304c\u5fc5\u8981\u305d\u3046\u306a\u306e\u3067\u5bfe\u5fdc\u3057\u307e\u3059\u3002  \r\n- README \u306b README_lerna-sample-payment-app \u306e\u5185\u5bb9\u3092\u30de\u30fc\u30b8\u3059\u308b\r\n- fake-app \u3092\u524a\u9664\u3059\u308b", "@negokaz \r\n\r\n\u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30d5\u30a1\u30af\u30bf\u306e\u30c7\u30d5\u30a9\u30eb\u30c8\u5024\u30923\u306b\u3057\u307e\u3057\u305f\u3002\r\nREADME \u306bCassandra \u30af\u30e9\u30b9\u30bf\u3092\u69cb\u6210\u3059\u308b\u30ce\u30fc\u30c9\u6570\u304c3\u672a\u6e80\u306e\u5834\u5408\u306b\u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30d5\u30a1\u30af\u30bf\u3092\u30ce\u30fc\u30c9\u6570\u4ee5\u4e0b\u3068\u306a\u308b\u3088\u3046\u306b\u8abf\u6574\u3057\u3066\u307b\u3057\u3044\u65e8\u3092\u6ce8\u610f\u66f8\u304d\u3068\u3057\u3066\u8a18\u8f09\u3057\u307e\u3057\u305f\u3002\r\n> Use 3 as a default replication factor 97c6d15\r\n> examples/aws_ec2 only supports lerna-sample-payment-app 875ec2a", "@negokaz \r\n\r\n\u6b21\u306ePR \u306b\u3066\u3001RPM \u30d5\u30a1\u30a4\u30eb \u306b `docker/mock-server` \u3092\u540c\u68b1\u3059\u308b\u3088\u3046\u306b\u5909\u66f4\u3057\u307e\u3057\u305f\u3002\r\n> [Reconcile to be able to deploy using lerna-terraform](https://github.com/lerna-stack/lerna-sample-payment-app/pull/9) \r\n\r\n\u30a2\u30d7\u30ea\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u30c7\u30a3\u30ec\u30af\u30c8\u30ea `/apl/lerna-sample-payment-app/docker/mock-server` \u3092\u4f7f\u3063\u3066\u3001\r\ndocker image \u3092\u30d3\u30eb\u30c9\u3059\u308b\u3088\u3046\u306b\u3057\u307e\u3057\u305f\u3002\r\n> Don't copy mock-server files \u2026 8d36464\r\n\r\n\u3053\u308c\u3089\u306e\u5909\u66f4\u306b\u3088\u308a\u3001\u30e6\u30fc\u30b6\u304c `docker/mock-server` \u3092\u624b\u52d5\u3067\u30b3\u30d4\u30fc\u3059\u308b\u5fc5\u8981\u304c\u7121\u304f\u306a\u308a\u307e\u3057\u305f\u3002", "@negokaz \r\n`examples/aws_ec2` \u304c `lerna-sample-payment-app` \u3092\u30c7\u30d7\u30ed\u30a4\u3059\u308b\u30b5\u30f3\u30d7\u30eb\u3068\u306a\u308b\u3088\u3046\u306b\u5909\u66f4\u3057\u307e\u3057\u305f\u3002  \r\n\r\n- \u30e2\u30c3\u30af\u30b5\u30fc\u30d0\u3092\u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u6709\u52b9\u306b\u3057\u307e\u3057\u305f\r\n- `fake-app` \u306f\u4e0d\u8981\u306b\u306a\u3063\u305f\u305f\u3081\u524a\u9664\u3057\u307e\u3057\u305f\r\n- \u30c7\u30d7\u30ed\u30a4\u624b\u9806\u30921\u3064\u306e README \u306b\u307e\u3068\u3081\u307e\u3057\u305f\r\n\r\n> Enable mock-server as default e5db022\r\n> examples/aws_ec2 only supports lerna-sample-payment-app 875ec2a\r\n> Remove fake-app \u2026 c37a87b", "\u826f\u3055\u305d\u3046\u3067\u3059 \ud83d\udc4d ", "\u826f\u3055\u305d\u3046\u3067\u3059 \ud83d\udc4d ", "\u30de\u30fc\u30b8\u3057\u307e\u3057\u305f\uff1a https://github.com/lerna-stack/lerna-sample-payment-app/pull/9"]}, {"url": "https://github.com/lerna-stack/lerna-terraform/pull/3", "comments": ["@xirc RHEL \u3068 CentOS \u3067\u30e2\u30b8\u30e5\u30fc\u30eb\u3092\u5171\u6709\u3059\u308b\u3053\u3068\u306b\u95a2\u3057\u3066\u306f\u540c\u610f\u3067\u3059\u3002\r\n\r\n\u30b5\u30f3\u30d7\u30eb\u306b\u95a2\u3057\u3066\u306f\u7406\u89e3\u3057\u3084\u3059\u3044\u3088\u3046\u3067\u304d\u308b\u3060\u3051\u6761\u4ef6\u5206\u5c90\u306a\u3069\u3092\u6392\u9664\u3057\u305f\u30b7\u30f3\u30d7\u30eb\u306a\u69cb\u9020\u306b\u3057\u305f\u307b\u3046\u304c\u826f\u3044\u3088\u3046\u306a\u6c17\u304c\u3057\u307e\u3057\u305f\u3002\u30b5\u30f3\u30d7\u30eb\u306f CentOS \u3092\u5229\u7528\u3059\u308b\u524d\u63d0\u306e\u69cb\u6210\u306b\u3057\u3066\u304a\u304d\u3001RHEL \u3092\u5229\u7528\u3057\u305f\u3044\u30e6\u30fc\u30b6\u30fc\u306b\u5411\u3051\u3066\u306f\u305d\u306e\u8a2d\u5b9a\u65b9\u6cd5\u304c\u66f8\u304b\u308c\u305f\u30ac\u30a4\u30c9\u306b\u8a98\u5c0e\u3059\u308b\u3068\u3044\u3046\u65b9\u6cd5\u306f\u3069\u3046\u3067\u3057\u3087\u3046\u304b\uff1f\r\n\r\n\u30ac\u30a4\u30c9\u306e\u4e2d\u306b\u306f AMI \u306e\u5909\u66f4\u65b9\u6cd5\u3068\u3001\u305d\u306e AMI \u306e\u5909\u66f4\u306b\u3088\u3063\u3066\u4ed6\u306e\u3069\u306e\u8a2d\u5b9a\u9805\u76ee\u304c\u5f71\u97ff\u3092\u53d7\u3051\u308b\u304b\uff08ssh_user \u306a\u3069\uff09\u304c\u89e3\u8aac\u3055\u308c\u3066\u3044\u308b\u30a4\u30e1\u30fc\u30b8\u3067\u3059\u3002", "@negokaz \r\n\r\n\u30ec\u30d3\u30e5\u30fc\u3042\u308a\u304c\u3068\u3046\u3054\u3056\u3044\u307e\u3059 \ud83d\ude04 \r\n\u30b5\u30f3\u30d7\u30eb\u3092\u30b7\u30f3\u30d7\u30eb\u306a\u69cb\u9020\u306b\u623b\u3057\u3001\u4ee3\u308f\u308a\u306bRHEL\u306e\u5229\u7528\u30ac\u30a4\u30c9\u3092\u8ffd\u52a0\u3057\u307e\u3057\u305f\u3002\r\n\r\n> Revert \"aws_ec2 supports RHEL7\" \u2026 5428104\r\n> Add a document describing how to use RHEL7 9593549\r\n\r\nCHANGELOG \u306e\u66f4\u65b0\u3092\u5fd8\u308c\u3066\u3044\u305f\u305f\u3081\u3001\u3053\u306ePR\u306b\u3066\u8ffd\u52a0\u3055\u308c\u308b\u5185\u5bb9\u3092 CHANGELOG \u306b\u8a18\u8f09\u3057\u307e\u3057\u305f\u3002\r\n> Add RHEL7 support to the CHANGELOG 0c993f7", "@xirc \r\n\r\n\u5229\u7528\u30ac\u30a4\u30c9\u826f\u3044\u3068\u601d\u3044\u307e\u3059\uff01\r\n\r\n\u3055\u3089\u306b\u6539\u5584\u3059\u308b\u306a\u3089\u3001\u5834\u5408\u306b\u3088\u3063\u3066\u306f\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u30bf\u30a4\u30d7\u3092\u8abf\u6574\u3057\u305f\u3044\u30b1\u30fc\u30b9\u3082\u3042\u308b\u3068\u601d\u3046\u306e\u3067\u3001\u300c\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u30bf\u30a4\u30d7\u306e\u8a2d\u5b9a\u300d\u306e\u30bb\u30af\u30b7\u30e7\u30f3\u306b\u300c\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u30bf\u30a4\u30d7\u306f\u30de\u30fc\u30b1\u30c3\u30c8\u30d7\u30ec\u30a4\u30b9\u306b\u5217\u6319\u3055\u308c\u305f\u3082\u306e\u306e\u307f\u304c\u5229\u7528\u3067\u304d\u308b\u300d\u3068\u3044\u3046\u3053\u3068\u3092\u793a\u3057\u3066\u304a\u3044\u305f\u307b\u3046\u304c\u3001`c5` \u306a\u3069\u3092\u8a2d\u5b9a\u3057\u3066 apply \u304c\u30a8\u30e9\u30fc\u306b\u306a\u3063\u3066\u3057\u307e\u3046\u3068\u3044\u3046\u306e\u3092\u56de\u907f\u3067\u304d\u308b\u306e\u3067\u89aa\u5207\u304b\u306a\u3068\u601d\u3044\u307e\u3057\u305f\u3002\u79c1\u81ea\u8eab\u3082\u3053\u3053\u3067\u8e93\u3044\u305f\u7d4c\u9a13\u304c\u3042\u308b\u306e\u3067\u3002", "@negokaz \r\n\r\n\u79c1\u3082\u540c\u69d8\u306e\u7d4c\u9a13\u3092\u3057\u305f\u3053\u3068\u3092\u601d\u3044\u51fa\u3057\u307e\u3057\u305f :)\r\n\u30a4\u30f3\u30b9\u30bf\u30f3\u30d7\u30bf\u30a4\u30d7\u306b\u3064\u3044\u3066\u306e\u6ce8\u610f\u4e8b\u9805\u3092\u8a18\u8f09\u3057\u307e\u3059", "@negokaz \r\n\u5229\u7528\u30ac\u30a4\u30c9\u3092\u66f4\u65b0\u3057\u307e\u3057\u305f\u3002\r\n> Make the guide of RHEL7 more friendly \u2026 e66a114", "@xirc \u30d5\u30a1\u30a4\u30eb\u30d1\u30b9\u3092\u66f8\u304d\u63db\u3048\u306a\u3044\u3068\u3001\u30a8\u30e9\u30fc\u306a\u3069\u304c\u767a\u751f\u3059\u308b\u3068\u3044\u3046\u3053\u3068\u3067\u3057\u3087\u3046\u304b\uff1f\u500b\u4eba\u7684\u306b\u306f\u30e2\u30b8\u30e5\u30fc\u30eb\u306e\u65b0\u3057\u3044\u30d1\u30b9\u304c `tfstate` \u306b\u53cd\u6620\u3055\u308c\u308b\u3060\u3051\u3067\u7279\u306b\u30a8\u30e9\u30fc\u306a\u3069\u306f\u767a\u751f\u3057\u306a\u3044\u3068\u4e88\u60f3\u3057\u3066\u3044\u307e\u3057\u305f\u3002", "@negokaz \r\n\r\n`terraform.tfstate` \u306b\u3042\u308b\u30d5\u30a1\u30a4\u30eb\u30d1\u30b9\u3092\u66f8\u304d\u63db\u3048\u306a\u304f\u3066\u3082\u30a8\u30e9\u30fc\u306f\u51fa\u307e\u305b\u3093\u304c\u3001*\u30e2\u30b8\u30e5\u30fc\u30eb\u306e\u30d1\u30b9* \u304c\u542b\u307e\u308c\u308b\u30ea\u30bd\u30fc\u30b9(`management_script_global`\u3068`cassandra_conf`)\u304c`terraform plan`  \u3067\u306e\u5909\u66f4\u5019\u88dc\u306b\u51fa\u3066\u304d\u307e\u305b\u3093\u3067\u3057\u305f\u3002\u65e7\u30d1\u30b9\u304c `terraform.tfstate` \u306b\u6b8b\u3063\u3066\u3057\u307e\u3046\u3068\u3069\u306e\u3088\u3046\u306a\u554f\u984c\u304c\u3042\u308b\u306e\u304b\u4e0d\u660e\u3067\u3042\u3063\u305f\u305f\u3081\u3001\u5b89\u5168\u306e\u305f\u3081\u306b\u3001\u79fb\u884c\u624b\u9806\u306b `terraform.tfstate` \u306e\u66f8\u304d\u63db\u3048\u3092\u8a18\u8f09\u3057\u307e\u3057\u305f\u3002\r\n\r\n`terraform.tfstate` \u3092\u66f8\u304d\u63db\u3048\u305a\u306b `terraform apply` \u3092\u5b9f\u65bd\u3057\u305f\u3053\u3068\u304c\u306a\u304b\u3063\u305f\u305f\u3081\u3001\r\n\u9802\u3044\u305f\u30b3\u30e1\u30f3\u30c8\u3092\u78ba\u8a8d\u5f8c\u306b\u3001\u5ff5\u306e\u305f\u3081`terraform.tfstate` \u3092\u66f8\u304d\u63db\u3048\u305a\u306b `terraform apply`\u3092\u5b9f\u65bd\u3057\u3066\u307f\u307e\u3057\u305f\u3002\r\n`terraform plan` \u306b\u306f\u5019\u88dc\u3068\u3057\u3066\u51fa\u3066\u304d\u307e\u305b\u3093\u304c\u3001\u3082\u3057\u304b\u3059\u308b\u3068\u8a72\u5f53\u30d1\u30b9\u304c\u65b0\u3057\u3044\u3082\u306e\u306b\u7f6e\u304d\u63db\u308f\u308b\u306e\u3067\u306f\uff1f\u3068\u8003\u3048\u305f\u305f\u3081\u3067\u3059\u3002\r\n\r\n\u5b9f\u65bd\u3057\u3066\u307f\u308b\u3068\u3001\u8a72\u5f53\u30d1\u30b9\u304c `terraform` \u306b\u3088\u3063\u3066\u6b63\u3057\u304f\u66f8\u304d\u63db\u3048\u3089\u308c\u3066\u3044\u308b\u3053\u3068\u304c\u78ba\u8a8d\u3067\u304d\u307e\u3057\u305f\u3002\r\n\r\n```\r\n[***]$ grep -i 'modules/service/redhat' terraform.tfstate\r\n            \"output_path\": \"../../modules/service/redhat/core/resources/cassandra/conf.zip\",\r\n            \"source_dir\": \"../../modules/service/redhat/core/resources/cassandra/conf\",\r\n            \"output_path\": \"../../modules/service/redhat/core/resources/management-script/global.zip\",\r\n            \"source_dir\": \"../../modules/service/redhat/core/resources/management-script/global\",\r\n```\r\n\r\n\u7d50\u8ad6\u3068\u3057\u3066`terraform.tfstate` \u3092\u66f8\u304d\u63db\u3048\u308b\u4f5c\u696d\u306f\u4e0d\u8981\u3067\u3057\u305f \ud83d\ude04 \r\n`terraform.tfstate` \u3092\u76f4\u63a5\u66f8\u304d\u63db\u3048\u308b\u4f5c\u696d\u306f\u53ef\u80fd\u306a\u9650\u308a\u907f\u3051\u305f\u3044\u3082\u306e\u3067\u3042\u308a\u3001\r\n\u4e0d\u8981\u3067\u3042\u308b\u3053\u3068\u3082\u5206\u304b\u3063\u305f\u305f\u3081\u3001\u79fb\u884c\u624b\u9806\u304b\u3089\u306f\u524a\u9664\u3057\u307e\u3059\u3002", "@negokaz \u79fb\u884c\u624b\u9806\u3092\u66f4\u65b0\u3057\u307e\u3057\u305f \ud83d\ude38 \r\n> Remove the step of changing terraform state from MIGRATION guide \u2026 dccc504", "@xirc \r\n\r\nLGTM!", "@xirc \r\n\u30e2\u30b8\u30e5\u30fc\u30eb\u540d\u304c\u5909\u308f\u3063\u305f\u3053\u3068\u306b\u3088\u308a\u3001README \u3092\u8aad\u3093\u3067\u3082 CentOS \u3067\u4f7f\u3048\u308b\u3068\u3044\u3046\u3053\u3068\u304c\u8aad\u307f\u53d6\u308c\u306a\u304f\u306a\u3063\u3066\u3057\u307e\u3044\u307e\u3057\u305f\u306d\u3002\r\n\r\n`service/redhat/core` \u3068 `service/redhat/dev` \u306e\u8aac\u660e\u90e8\u5206\u306b RHEL \u3068 CentOS \u306e\u4e21\u65b9\u3092\u30b5\u30dd\u30fc\u30c8\u3057\u3066\u3044\u308b\u3068\u3044\u3046\u3053\u3068\u3092\u66f8\u3044\u3066\u304a\u304f\u3068\u3044\u3046\u306e\u306f\u3069\u3046\u3067\u3057\u3087\u3046\u304b\uff1f", "`platform/aws/ec2` \u306e\u8aac\u660e\u306b\u3082\u3001\u30c7\u30d5\u30a9\u30eb\u30c8\u306e OS \u304c CentOS \u3067\u3042\u308b\u3053\u3068\u3092\u66f8\u3044\u3066\u304a\u304f\u3068\u74b0\u5883\u69cb\u7bc9\u5f8c\u306e\u6b63\u3057\u3044\u69cb\u6210\u3092\u30a4\u30e1\u30fc\u30b8\u3057\u3084\u3059\u3044\u304b\u3082\u3057\u308c\u307e\u305b\u3093\u306d\u3002\r\n\r\n\u4e0b\u306e\u65b9\u306b\u300cRedHatEnterpriseLinux\u5229\u7528\u30ac\u30a4\u30c9\u300d\u306e\u8aac\u660e\u304c\u3042\u308b\u306e\u3067\u3001`platform/aws/ec2` \u306f\u30c7\u30d5\u30a9\u30eb\u30c8\u3067 RHEL \u3092\u69cb\u7bc9\u3059\u308b\u30e2\u30b8\u30e5\u30fc\u30eb\u306a\u306e\u304b\u306a\uff1f\u3068\u8aa4\u89e3\u3055\u308c\u308b\u53ef\u80fd\u6027\u3082\u3042\u308a\u305d\u3046\u3060\u306a\u3068\u601d\u3044\u307e\u3057\u305f\u3002", "\u78ba\u304b\u306b\u6b21\u306e2\u70b9\u304c\u4f1d\u308f\u308a\u3065\u3089\u3044\u3067\u3059\u306d\u3002\r\n- RHEL7, CentOS8 \u306e\u4e21\u65b9\u3092\u30b5\u30dd\u30fc\u30c8\u3057\u3066\u3044\u308b\u3053\u3068\r\n- \u30c7\u30d5\u30a9\u30eb\u30c8\u304c CentOS8 \u3067\u3042\u308b\u3053\u3068\r\n\r\n\u660e\u8a18\u3059\u308b\u3088\u3046\u306bREADME\u306e\u8a18\u8f09\u3092\u5909\u66f4\u3059\u308b\u307b\u3046\u304c\u826f\u3055\u305d\u3046\u3067\u3059 \ud83d\ude04 \r\n\u307e\u305f\u3001\u300cRedHatEnterpriseLinux\u5229\u7528\u30ac\u30a4\u30c9\u300d\u3092\u3069\u306e\u3088\u3046\u306a\u3068\u304d\u306b\u8aad\u3080\u306e\u304b\u3092 README \u304b\u3089\u8aac\u660e\u3059\u308b\u3068\u3001\u3055\u3089\u306b\u826f\u3055\u305d\u3046\u306b\u601d\u3044\u307e\u3057\u305f\u3002\r\n\u5909\u66f4\u3057\u307e\u3059\ud83d\ude04", "@negokaz \r\n\u6b21\u306e\u30b3\u30df\u30c3\u30c8\u3067\u5909\u66f4\u3057\u307e\u3057\u305f\u3002\r\n> Revise README \u2026 5d2e13a", "LGTM! \ud83c\udf89 "]}]}, {"url": "https://github.com/Geeks-Academy/terraform.git", "pull_requests": [{"url": "https://github.com/Geeks-Academy/terraform/pull/77", "comments": ["This is not needed\r\nhttps://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/ecr_repository_policy\r\n\r\nedit: only line 48.", "Done.", "Add this also to /mongodb/mongodb_task_definition.json", "Added."]}, {"url": "https://github.com/Geeks-Academy/terraform/pull/45", "comments": ["Misspelling in the file name `monog.env` => `mongo.env`", "Thanks.", "It doesn't solve the problem of storing username and password in repository\r\n\r\nAs a workaround I suggest uploading this file to s3 manualy. Nevertheless it should be automated somehow.", "What is the purpose of adding it here? \r\nThis is policy applied only to repository. I guess this should be added to `ECS_EC2` policy in `project-iam/roles/ec2_instance_profile.tf` ", "Please distinguish those two priviliges to separate Statement (you can add it in curly brackets after adding a comma) so it could access only desired bucket.\r\n```\r\n{\r\n            \"Effect\": \"Allow\",\r\n            \"Action\": [\r\n                \"s3:GetObject\",\r\n                \"s3:GetBucketLocation\"\r\n            ],\r\n            \"Resource\": [\r\n                \"arn:aws:s3:::programmers-only-artifacts/*\",\r\n                \"arn:aws:s3:::programmers-only-artifacts\"\r\n            ]\r\n        }\r\n```\r\n", "Added.", "Added."]}]}, {"url": "https://github.com/dbqa7/tf.git", "pull_requests": []}, {"url": "https://github.com/public-transport/infrastructure.git", "pull_requests": []}, {"url": "https://github.com/cn-terraform/terraform-aws-ec2-asg.git", "pull_requests": []}, {"url": "https://github.com/IncredibleHolg/infra-aws-code.git", "pull_requests": []}, {"url": "https://github.com/IoT-Data-Marketplace/mp-infrastructure.git", "pull_requests": []}, {"url": "https://github.com/broadinstitute/tgg-terraform-modules.git", "pull_requests": [{"url": "https://github.com/broadinstitute/tgg-terraform-modules/pull/36", "comments": ["the `default` node pool is configured in the `seqr-gke` module and already has this flag."]}, {"url": "https://github.com/broadinstitute/tgg-terraform-modules/pull/33", "comments": ["`seqr` doesn't support `hail-batch` at the moment, so this perm isn't necessary.  "]}, {"url": "https://github.com/broadinstitute/tgg-terraform-modules/pull/26", "comments": ["There's also `initial_node_count`, but the [docs](https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/container_node_pool#initial_node_count) say not to use it if you don't need it as changing it triggers a re-spin.", "The `enabled = \"false\"` is confusing, but I believe it's correct as is... as it is referring \"node auto-provisioning\", which, at the cluster level, means allowing the automatic spin up/spin down of new node pools.  ", "I opted to override `min_node_pool_count` with dual meanings here rather than keep a third `node_pool_count` variable around.  ", "yes, i would avoid the initial_node_count. It's frustrating that most the examples on the docs page use it \ud83e\udd14 "]}, {"url": "https://github.com/broadinstitute/tgg-terraform-modules/pull/24", "comments": ["```suggestion\r\n# Grant serviceusage.use permissions to Batch SA (allow SA to use project)\r\nresource \"google_project_iam_member\" \"hail_batch_service_usage\" {\r\n```"]}, {"url": "https://github.com/broadinstitute/tgg-terraform-modules/pull/23", "comments": ["Maybe update the description to be >= 6 and < 30", "Is there a use case where we wouldn't want to create a service account for a function and would instead want to use one that already exists?", "good catch, thank you", "I've bounced back and forth on this a bit. The original thinking was that it was better to leave service account creation up to the user. On one hand, this is nice because it allows for potentially sharing service accounts for functions with identical permissions.\r\n\r\nOn the other hand, in practice this has resulted in a lot of service account management outside the module, since the functions often need different sets of perms.\r\n\r\nI can see maybe a best of both worlds scenario here where we either create the service account, or allow for specifying one. This kind of logic is not what terraform is particularly good at \ud83d\ude04 -- I'll play around with it and see if I can come up with something that doesn't resemble fiendish devilry.", "OK, I still need to test it to see if this works, but I just pushed an update that should allow for conditionally managing the service accounts.\r\n\r\nIf you enable it, it manages service accounts and permissions for you. Disabled, all the IAM and workload identity bits should be skipped, and you're on your own.\r\n\r\nI can see there being a hybrid here, but maybe with more complexity in the ternary operators:\r\n\r\n1. have input variables for the runtime and deployment service account emails\r\n2. if the length of the strings providing these inputs is > 0, use that as the target for any IAM permissions / workload identity federation mappings we assign\r\n3. if the length of the strings providing these inputs is 0, create the service accounts and use those created ones as the target for IAM permissions and workload identity federation mappings\r\n\r\nDo either of these two approaches sound more appealing?", "having thought about this a little bit more, i think it's just easier to ask for/require service account IDs as inputs, and then assign the necessary permissions in the module. This will give the freedom to manage the service accounts elsewhere, and is only like ~4 lines of terraform outside the module if you need to create a function specific service account."]}, {"url": "https://github.com/broadinstitute/tgg-terraform-modules/pull/19", "comments": ["Just for my own knowledge, are there additional cidr blocks beyond the control plane block and the cluster block or just those two?", "The networks that we typically worry about in GKE deployments are:\r\n\r\n- The master (control plane) CIDR range: This is the range that IP addresses for the kubernetes API are assigned from. It's not required to set this, but we explicitly define it in gnomAD, because we need to create firewall rules to allow the master nodes to perform webhooks on the elasticsearch services running in the cluster.\r\n- The VPC subnet that the GKE node pools/nodes are deployed in: This is created with our VPC module, and then passed in as the `subnet` in the `google_container_cluster` resource\r\n- The pods CIDR range (sometimes also called the \"cluster\" ipv4 CIDR range): This is the network range where IP addresses for individual pods are assigned from.\r\n- The services CIDR range: This is the range that Service IP addresses are assigned from, when you create a kubernetes [Service](https://kubernetes.io/docs/concepts/services-networking/service/) objects."]}, {"url": "https://github.com/broadinstitute/tgg-terraform-modules/pull/13", "comments": ["what about `storage.legacyBucketWriter` (for the tmp buckets) and `storage.objectViewer`/`storage.legacyBucketReader` for other project-related buckets? (based on permissions that we granted Lily's Hail Batch SA)", "this is saying that the count is 1 if the length of `var.hail_batch_service_account` is non-zero, right? do the rest of the fields in this resource module (e.g., `role`) not assign if count == 0?", "ahh, yeah, that's probably a good idea given the weird incompatibilities we've discovered with the new `storage.object*` roles", "Yup -- Terraform doesn't have an `if` statement. So when when we have something that we only want to create under certain circumstances, we abuse the `count` parameter with a conditional expression. So, by default, that variable is a empty string (length 0), so the count gets set to 0 and the resource is not created. If the length of that variable string is more than 0, it sets the count to 1 and creates the resource.", "ohh this makes sense, thanks!"]}, {"url": "https://github.com/broadinstitute/tgg-terraform-modules/pull/10", "comments": ["How do you generate these READMEs?", "Typo: runnint -> running", "Inconsistent use of period in the description", "So the IP subnets are listed in a file in a google bucket? This is really nice. Will the file path be parameterized? Is it an option to create the infrastructure without the IP/VPN restrictions?", "I used a tool called [terraform-docs](https://terraform-docs.io/) -- I should probably add a note on how to update the readme (or, some sort of action that does it).", "That bucket and file are maintained by BITS, and theoretically they're updated regularly/programmatically somehow. The bucket and path shouldn't change, as far as I understand. Having this in here statically definitely makes the module less useful for people other than us, so I think it's probably a good idea to add a toggle for it, and perhaps another input variable that people could use to provide their own subnet ranges.", "OK, I've updated this so that you can conditionally include the BITS maintained networks list in the master_authorized_networks config (default to false, so that if anyone outside of us uses the module they don't get it added without knowing). I've added a new variable that lets you define your own networks to allow. Empty by default, and we won't typically use that, but it's there for people that need customization.\r\n\r\nIf the BITS network fetching is enabled, and you also provide a list of authorized nets, both sets of networks are added to the config. This would be useful in the case that we need to supplement the BITS networks with additional networks in the future.", "I've added a little more color to the readme here with some basic usage info, and readme update instructions at the end."]}]}, {"url": "https://github.com/mdcurran/terraform-infrastructure.git", "pull_requests": []}, {"url": "https://github.com/LeoPrivate/terraform-ansible-poc.git", "pull_requests": []}, {"url": "https://github.com/zehavit12/tergot2.git", "pull_requests": [{"url": "https://github.com/zehavit12/tergot2/pull/2", "comments": ["```suggestion\n  *_block_device {\n    encrypted = true\n  }\n}\n```\n<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/high.svg\" alt=\"HIGH\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure EBS volumes have encrypted launch configurations</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/zehavit12/tergot2/blob/zehavit/terraform/aws/ec2.tf#L34-L65\">aws_instance.web_host2</a> |  ID: <code>BC_AWS_GENERAL_13</code>\n            <br></summary>\n<h4>Description</h4>\nAmazon Elastic Block Store (EBS) volumes allow you to create encrypted launch configurations when creating EC2 instances and auto scaling. When the entire EBS volume is encrypted, data stored at rest on the volume, disk I/O, snapshots created from the volume, and data in-transit between EBS and EC2 are all encrypted.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 3</li>\n</ul>\n</details>", "```suggestion\n  monitoring = true\n}\n```\n<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/medium.svg\" alt=\"MEDIUM\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure detailed monitoring for EC2 instances is enabled</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/zehavit12/tergot2/blob/zehavit/terraform/aws/ec2.tf#L34-L65\">aws_instance.web_host2</a> |  ID: <code>BC_AWS_LOGGING_26</code>\n            <br></summary>\n<h4>Description</h4>\nTBA\n\n</details>", "```suggestion\n  ebs_optimized = true\n}\n```\n<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure that EC2 is EBS optimized</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/zehavit12/tergot2/blob/zehavit/terraform/aws/ec2.tf#L34-L65\">aws_instance.web_host2</a> |  ID: <code>BC_AWS_GENERAL_68</code>\n            <br></summary>\n<h4>Description</h4>\nTBA\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure Instance Metadata Service version 1 is not enabled</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/zehavit12/tergot2/blob/zehavit/terraform/aws/ec2.tf#L34-L65\">aws_instance.web_host2</a> |  ID: <code>BC_AWS_GENERAL_31</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```tf\nresource \"aws_instance\" \"example\" {\n  ...\n  instance_type     = \"t2.micro\"\n+   metadata_options {\n        ...\n+       http_endpoint = \"enabled\"\n+       http_tokens   = \"required\"\n+  }\n  ...\n}\n```\n\n<h4>Description</h4>\nThe Instance Metadata Service (IMDS) is an on-instance component used by code on the instance to securely access instance metadata. You can access instance metadata from a running instance using one of the following methods:\n * Instance Metadata Service Version 1 (IMDSv1) \u2013 a request/response method\n * Instance Metadata Service Version 2 (IMDSv2) \u2013 a session-oriented method\n\nAs a request/response method IMDSv1 is prone to local misconfigurations: \n * Open proxies, open NATs and routers, server-side reflection vulnerabilities.\n * One way or another, local software might access local-only data.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>FEDRAMP (MODERATE) AC-6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/high.svg\" alt=\"HIGH\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure EC2 user data does not expose secrets</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/zehavit12/tergot2/blob/zehavit/terraform/aws/ec2.tf#L34-L65\">aws_instance.web_host2</a> |  ID: <code>BC_AWS_SECRETS_1</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```tf\nresource \"aws_instance\" \"web\" {\n    ...\n    instance_type = \"t3.micro\"\n-    user_data = \"access_key=123456ABCDEFGHIJZTLA and secret_key=AAAaa+Aa4AAaAA6aAkA0Ad+Aa8aA1aaaAAAaAaA\"\n}\n```\n\n<h4>Description</h4>\n**User Data** is a metadata field of an EC2 instance that allows custom code to run after the instance is launched. It contains code exposed to any entity which has the most basic access to EC2, even read-only configurations. This code is not encrypted.\n\nRemoving secrets from easily-accessed unencrypted places reduces the risk of passwords, private keys and more from being exposed to third parties.\n\n</details>"]}, {"url": "https://github.com/zehavit12/tergot2/pull/1", "comments": ["<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure AWS access logging is enabled on S3 buckets</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/zehavit12/tergot2/blob/zeh/terraform/aws/s3.tf#L23-L44\">aws_s3_bucket.data4</a> |  ID: <code>BC_AWS_S3_13</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```tf\nresource \"aws_s3_bucket\" \"bucket\" {\n  acl    = var.s3_bucket_acl\n  bucket = var.s3_bucket_name\n  policy = var.s3_bucket_policy\n\n  force_destroy = var.s3_bucket_force_destroy\n  versioning {\n    enabled    = var.versioning\n    mfa_delete = var.mfa_delete\n  }\n\n+  dynamic \"logging\" {\n+    for_each = var.logging\n+    content {\n+      target_bucket = logging.value[\"target_bucket\"]\n+      target_prefix = \"log/${var.s3_bucket_name}\"\n+    }\n+  }\n}\n```\n\n<h4>Description</h4>\nAccess logging provides detailed audit logging for all objects and folders in an S3 bucket. \n\n<h4>Benchmarks</h4>\n<ul>\n<li>HIPAA 164.312(B) Audit controls</li>\n</ul>\n</details>", "```suggestion\n  server_side_encryption_configuration {\n    rule {\n      apply_server_side_encryption_by_default {\n        sse_algorithm = \"aws:kms\"\n      }\n    }\n  }\n}\n```\n<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure S3 buckets are encrypted with KMS by default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/zehavit12/tergot2/blob/zeh/terraform/aws/s3.tf#L23-L44\">aws_s3_bucket.data4</a> |  ID: <code>BC_AWS_GENERAL_56</code>\n            <br></summary>\n<h4>Description</h4>\nTBA\n\n</details>\n<p>:tada: &nbsp; <b>Fixed</b> by commit f145b3f4ed788736ae90fd251411c60771e56ec6 - Update terraform/aws/s3.tf</p>", "```suggestion\n  server_side_encryption_configuration {\n    rule {\n      apply_server_side_encryption_by_default {\n        sse_algorithm = \"AES256\"\n      }\n    }\n  }\n}\n```\n<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/high.svg\" alt=\"HIGH\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure data stored in the S3 bucket is securely encrypted at rest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/zehavit12/tergot2/blob/zeh/terraform/aws/s3.tf#L23-L44\">aws_s3_bucket.data4</a> |  ID: <code>BC_AWS_S3_14</code>\n            <br></summary>\n<h4>Description</h4>\nSSE helps prevent unauthorized access to S3 buckets. Encrypting and decrypting data at the S3 bucket level is transparent to users when accessing data.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>FEDRAMP (MODERATE) SC-28</li>\n<li>CIS AWS V1.3 2.1.1</li>\n<li>NIST-800-53 SC-2, AC-17</li>\n<li>PCI-DSS V3.2 3</li>\n<li>PCI-DSS V3.2.1 3.4</li>\n</ul>\n</details>\n<p>:tada: &nbsp; <b>Fixed</b> by commit f145b3f4ed788736ae90fd251411c60771e56ec6 - Update terraform/aws/s3.tf</p>", "```suggestion\n\n```\n<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/critical.svg\" alt=\"CRITICAL\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure bucket ACL does not grant READ permission to everyone</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/zehavit12/tergot2/blob/zeh/terraform/aws/s3.tf#L23-L44\">aws_s3_bucket.data4</a> |  ID: <code>BC_AWS_S3_1</code>\n            <br></summary>\n<h4>Description</h4>\nUnprotected S3 buckets are one of the major causes of data theft and intrusions. An S3 bucket that allows **READ** access to everyone can provide attackers the ability to read object data within the bucket, which can lead to the exposure of sensitive data. The only S3 buckets that should be globally accessible for unauthenticated users or for **Any AWS Authenticate Users** are those used for hosting static websites. Bucket ACL helps manage access to S3 bucket data. \n\nWe recommend AWS S3 buckets are not publicly accessible for **READ** actions to protect S3 data from unauthorized users and exposing sensitive data to public access. \n\n<h4>Benchmarks</h4>\n<ul>\n<li>NIST-800-53 AC-17</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure S3 bucket has cross-region replication enabled</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/zehavit12/tergot2/blob/zeh/terraform/aws/s3.tf#L23-L44\">aws_s3_bucket.data4</a> |  ID: <code>BC_AWS_GENERAL_72</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```tf\nresource \"aws_s3_bucket\" \"test\" {\n  ...\n+  replication_configuration {\n+    role = aws_iam_role.replication.arn\n+    rules {\n+      id     = \"foobar\"\n+      prefix = \"foo\"\n+      status = \"Enabled\"\n+\n+      destination {\n+        bucket        = aws_s3_bucket.destination.arn\n+        storage_class = \"STANDARD\"\n+      }\n+    }\n+  }\n}\n```\n\n<h4>Description</h4>\nCross-region replication enables automatic, asynchronous copying of objects across S3 buckets. By default, replication supports copying new S3 objects after it is enabled. It is also possible to use replication to copy existing objects and clone them to a different bucket, but in order to do so, you must contact AWS Support.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure S3 Bucket has public access blocks</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/zehavit12/tergot2/blob/zeh/terraform/aws/s3.tf#L23-L44\">aws_s3_bucket.data4</a> |  ID: <code>BC_AWS_NETWORKING_52</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```tf\n\nresource \"aws_s3_bucket\" \"bucket_good_1\" {\n  bucket = \"bucket_good\"\n}\n\nresource \"aws_s3_bucket_public_access_block\" \"access_good_1\" {\n  bucket = aws_s3_bucket.bucket_good_1.id\n\n  block_public_acls   = true\n  block_public_policy = true\n}\n\n\n```\n\n<h4>Description</h4>\nWhen you create an S3 bucket, it is good practice to set the additional resource  **aws_s3_bucket_public_access_block** to ensure the bucket is never accidentally public.\n\nWe recommend you ensure S3 bucket has public access blocks. If the public access block is not attached it defaults to False.\n\n</details>", "```suggestion\n  versioning {\n    enabled = true\n  }\n}\n```\n<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/high.svg\" alt=\"HIGH\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure AWS S3 object versioning is enabled</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/zehavit12/tergot2/blob/zeh/terraform/aws/s3.tf#L23-L44\">aws_s3_bucket.data4</a> |  ID: <code>BC_AWS_S3_16</code>\n            <br></summary>\n<h4>Description</h4>\nS3 versioning is a managed data backup and recovery service provided by AWS. When enabled it allows users to retrieve and restore previous versions of their buckets. \n\nS3 versioning can be used for data protection and retention scenarios such as recovering objects that have been accidentally/intentionally deleted or overwritten.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2.1 10.5.3</li>\n<li>FEDRAMP (MODERATE) CP-10, SI-12</li>\n</ul>\n</details>", "```suggestion\n  server_side_encryption_configuration {\n    rule {\n      apply_server_side_encryption_by_default {\n        sse_algorithm = \"aws:kms\"\n      }\n    }\n  }\n}\n```\n<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure S3 buckets are encrypted with KMS by default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/zehavit12/tergot2/blob/zeh/terraform/aws/s3.tf#L1-L22\">aws_s3_bucket.data2</a> |  ID: <code>BC_AWS_GENERAL_56</code>\n            <br></summary>\n<h4>Description</h4>\nTBA\n\n</details>", "```suggestion\n  versioning {\n    enabled = true\n  }\n}\n```\n<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/high.svg\" alt=\"HIGH\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure AWS S3 object versioning is enabled</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/zehavit12/tergot2/blob/zeh/terraform/aws/s3.tf#L1-L22\">aws_s3_bucket.data2</a> |  ID: <code>BC_AWS_S3_16</code>\n            <br></summary>\n<h4>Description</h4>\nS3 versioning is a managed data backup and recovery service provided by AWS. When enabled it allows users to retrieve and restore previous versions of their buckets. \n\nS3 versioning can be used for data protection and retention scenarios such as recovering objects that have been accidentally/intentionally deleted or overwritten.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2.1 10.5.3</li>\n<li>FEDRAMP (MODERATE) CP-10, SI-12</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure S3 Bucket has public access blocks</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/zehavit12/tergot2/blob/zeh/terraform/aws/s3.tf#L1-L22\">aws_s3_bucket.data2</a> |  ID: <code>BC_AWS_NETWORKING_52</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```tf\n\nresource \"aws_s3_bucket\" \"bucket_good_1\" {\n  bucket = \"bucket_good\"\n}\n\nresource \"aws_s3_bucket_public_access_block\" \"access_good_1\" {\n  bucket = aws_s3_bucket.bucket_good_1.id\n\n  block_public_acls   = true\n  block_public_policy = true\n}\n\n\n```\n\n<h4>Description</h4>\nWhen you create an S3 bucket, it is good practice to set the additional resource  **aws_s3_bucket_public_access_block** to ensure the bucket is never accidentally public.\n\nWe recommend you ensure S3 bucket has public access blocks. If the public access block is not attached it defaults to False.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure S3 bucket Object is encrypted by KMS using a customer managed Key (CMK)</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/zehavit12/tergot2/blob/zeh/terraform/aws/s3.tf#L45-L62\">aws_s3_bucket_object.data_object</a> |  ID: <code>BC_AWS_GENERAL_106</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```tf\nresource \"aws_s3_bucket_object\" \"object\" {\n  bucket = \"your_bucket_name\"\n  key    = \"new_object_key\"\n  source = \"path/to/file\"\n+ kms_key_id = \"ckv_kms\"\n\n  # The filemd5() function is available in Terraform 0.11.12 and later\n  # For Terraform 0.11.11 and earlier, use the md5() function and the file() function:\n  # etag = \"${md5(file(\"path/to/file\"))}\"\n  etag = filemd5(\"path/to/file\")\n}\n\n```\n\n<h4>Description</h4>\nThis is a simple check to ensure that the S3 bucket Object is using AWS key management - KMS to encrypt its contents. To resolve add the ARN of your KMS or link on creation of the object.\n\n\n</details>\n<p>:tada: &nbsp; <b>Fixed</b> by commit f145b3f4ed788736ae90fd251411c60771e56ec6 - Update terraform/aws/s3.tf</p>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure AWS access logging is enabled on S3 buckets</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/zehavit12/tergot2/blob/zeh/terraform/aws/s3.tf#L1-L22\">aws_s3_bucket.data2</a> |  ID: <code>BC_AWS_S3_13</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```tf\nresource \"aws_s3_bucket\" \"bucket\" {\n  acl    = var.s3_bucket_acl\n  bucket = var.s3_bucket_name\n  policy = var.s3_bucket_policy\n\n  force_destroy = var.s3_bucket_force_destroy\n  versioning {\n    enabled    = var.versioning\n    mfa_delete = var.mfa_delete\n  }\n\n+  dynamic \"logging\" {\n+    for_each = var.logging\n+    content {\n+      target_bucket = logging.value[\"target_bucket\"]\n+      target_prefix = \"log/${var.s3_bucket_name}\"\n+    }\n+  }\n}\n```\n\n<h4>Description</h4>\nAccess logging provides detailed audit logging for all objects and folders in an S3 bucket. \n\n<h4>Benchmarks</h4>\n<ul>\n<li>HIPAA 164.312(B) Audit controls</li>\n</ul>\n</details>", "```suggestion\n  server_side_encryption_configuration {\n    rule {\n      apply_server_side_encryption_by_default {\n        sse_algorithm = \"AES256\"\n      }\n    }\n  }\n}\n```\n<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/high.svg\" alt=\"HIGH\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure data stored in the S3 bucket is securely encrypted at rest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/zehavit12/tergot2/blob/zeh/terraform/aws/s3.tf#L1-L22\">aws_s3_bucket.data2</a> |  ID: <code>BC_AWS_S3_14</code>\n            <br></summary>\n<h4>Description</h4>\nSSE helps prevent unauthorized access to S3 buckets. Encrypting and decrypting data at the S3 bucket level is transparent to users when accessing data.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2.1 3.4</li>\n<li>PCI-DSS V3.2 3</li>\n<li>NIST-800-53 AC-17, SC-2</li>\n<li>CIS AWS V1.3 2.1.1</li>\n<li>FEDRAMP (MODERATE) SC-28</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure S3 bucket has cross-region replication enabled</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/zehavit12/tergot2/blob/zeh/terraform/aws/s3.tf#L1-L22\">aws_s3_bucket.data2</a> |  ID: <code>BC_AWS_GENERAL_72</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```tf\nresource \"aws_s3_bucket\" \"test\" {\n  ...\n+  replication_configuration {\n+    role = aws_iam_role.replication.arn\n+    rules {\n+      id     = \"foobar\"\n+      prefix = \"foo\"\n+      status = \"Enabled\"\n+\n+      destination {\n+        bucket        = aws_s3_bucket.destination.arn\n+        storage_class = \"STANDARD\"\n+      }\n+    }\n+  }\n}\n```\n\n<h4>Description</h4>\nCross-region replication enables automatic, asynchronous copying of objects across S3 buckets. By default, replication supports copying new S3 objects after it is enabled. It is also possible to use replication to copy existing objects and clone them to a different bucket, but in order to do so, you must contact AWS Support.\n\n</details>", "```suggestion\nresource \"aws_s3_bucket\" \"data2\" {\n  # bucket is public\n  # bucket is not encrypted\n  # bucket does not have access logs\n  # bucket does not have versioning\n  bucket        = \"${local.resource_prefix.value}-data\"\n  acl           = \"private\"\n  force_destroy = true\n  tags = merge({\n    Name        = \"${local.resource_prefix.value}-data\"\n    Environment = local.resource_prefix.value\n    }, {\n    git_commit           = \"d68d2897add9bc2203a5ed0632a5cdd8ff8cefb0\"\n    git_file             = \"terraform/aws/s3.tf\"\n    git_last_modified_at = \"2020-06-16 14:46:24\"\n    git_last_modified_by = \"nimrodkor@gmail.com\"\n    git_modifiers        = \"nimrodkor\"\n    git_org              = \"bridgecrewio\"\n    git_repo             = \"terragoat\"\n    yor_trace            = \"0874007d-903a-4b4c-945f-c9c233e13243\"\n  })\n}\n```\n<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/critical.svg\" alt=\"CRITICAL\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure bucket ACL does not grant READ permission to everyone</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/zehavit12/tergot2/blob/zeh/terraform/aws/s3.tf#L1-L22\">aws_s3_bucket.data2</a> |  ID: <code>BC_AWS_S3_1</code>\n            <br></summary>\n<h4>Description</h4>\nUnprotected S3 buckets are one of the major causes of data theft and intrusions. An S3 bucket that allows **READ** access to everyone can provide attackers the ability to read object data within the bucket, which can lead to the exposure of sensitive data. The only S3 buckets that should be globally accessible for unauthenticated users or for **Any AWS Authenticate Users** are those used for hosting static websites. Bucket ACL helps manage access to S3 bucket data. \n\nWe recommend AWS S3 buckets are not publicly accessible for **READ** actions to protect S3 data from unauthorized users and exposing sensitive data to public access. \n\n<h4>Benchmarks</h4>\n<ul>\n<li>NIST-800-53 AC-17</li>\n</ul>\n</details>\n<p>:magic_wand: Smart Fix - </p> Fix based on 100% past actions"]}]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure.git", "pull_requests": [{"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/3036", "comments": ["Where is this sns_topic created?"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/3023", "comments": ["```suggestion\r\n[# https://github.com/ministryofjustice/cloud-platform-environments/blob/6b8397d5de591c6f6f533750291117b2e78d4296/namespaces/live.cloud-platform.service.justice.gov.uk/moj-vuln-report/resources/s3.tf#L4](https://github.com/ministryofjustice/cloud-platform-environments/blob/main/namespaces/live.cloud-platform.service.justice.gov.uk/moj-vuln-report/resources/s3.tf#L4)\r\n```"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/2876", "comments": ["@jaskaransarkaria it would be good to add info on how and where these tokens and webhooks are generated", "Hmm yeah I'll write up a run book for slack bots in general \ud83d\udc4d\ud83c\udffd "]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/2870", "comments": ["is it waiting for 2 sec? ", "this is the factoring value, it'll increase the wait on each failed pass:\r\n1,2,4,8,16.\r\n\r\ntrying out AWS advice as per:\r\nhttps://repost.aws/knowledge-center/route-53-avoid-throttling-errors"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/2753", "comments": ["do we still need this?", "Removed", "```suggestion\r\nThis folder has access to the Cloud Platform terraform state (aws-accounts/cloud-platform-aws/vpc/live-1).\r\n```", "\"tgw-05acb84d26b244813\" might be misleading as the id is not the CP TGW id. Add a dummy one or enter free text"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/2597", "comments": ["These psp tests are no longer needed as we don't have a restricted PSP to test against", "See above."]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/2458", "comments": ["## An egress security group rule allows traffic to /0.\n\nSecurity group rule allows egress to multiple public internet addresses.\n\n[Show more details](https://github.com/ministryofjustice/cloud-platform-infrastructure/security/code-scanning/8)"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/2455", "comments": ["## An egress security group rule allows traffic to /0.\n\nSecurity group rule allows egress to multiple public internet addresses.\n\n[Show more details](https://github.com/ministryofjustice/cloud-platform-infrastructure/security/code-scanning/6)", "## An egress security group rule allows traffic to /0.\n\nSecurity group rule allows egress to multiple public internet addresses.\n\n[Show more details](https://github.com/ministryofjustice/cloud-platform-infrastructure/security/code-scanning/7)", "This is needed so the nodes allow outbound traffic to all public ips. ", "This is covered by the above rule, so is redundant.", "we want to keep the same configuration as the existing security group in order to perform the state mv and not recreate any of the resources. The security group needs reviewing as a seperate PR.", "They are slightly different. The above one is to communicate to each other. and this one is to communicate with the control plane\r\n"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/2433", "comments": ["Is this image already maintained by moj or something new CP added? if thats something we manage, would be good to add a comment on the dockerfile source so we know how to build it", "good point I've added the dockerfile to the test dir, so we have a copy of the source and have updated the readme with reference to it."]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/2174", "comments": ["I think this should be `logs` for the prod account", "good catch", "Just a cosmetic change. Can we name the resource as `cloud_platform_justice_gov_uk`", "good catch "]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/2169", "comments": ["node roles do not need to have access to the `security_manager` role", "Templating files like this is deprecated https://registry.terraform.io/providers/hashicorp/template/latest"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/2155", "comments": ["this is deprecated in `aws_opensearch` resources", "Removed the deprecated option"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/2138", "comments": ["## Elasticsearch doesn't enforce HTTPS traffic.\n\nDomain does not enforce HTTPS.\n\n[Show more details](https://github.com/ministryofjustice/cloud-platform-infrastructure/security/code-scanning/5)"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/1933", "comments": ["We should change the default to 1.22 also so all test clusters will be the same version ", "They will fail at components because we still have old ingress controllers in the component"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/1881", "comments": ["Should `live-2` also be `true` for `is_live_cluster?`", "Do we need to add `live-2` here in `live_workspace?`", "This flag is used to determine external-dns-annotation to serve hosts with `*.cloud-platform.service.justice.gov.uk`. I dont think we would use hosts under *.cloud-platform in live-2. So I have left the live-2 here.", "Thanks Sablu. Thats correct. Have added."]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/1734", "comments": ["This is opinionated, but is it worthwhile using `strings.HasPrefix(c.ClusterName, \"live\")` here, instead of `strings.Contains`?\r\n\r\nI'm thinking about cases where a cluster name may be `non-live`, which would run this test."]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/1656", "comments": ["Do we have an identical alertmanager check in go? ", "Do we have a identical test in go? We have ingress-controller checks. but not to check if the `default` certificate exists.", "I think we still need to check the label in eks too. It is needed so the opa can ignore the kube-system namespace.", "This particular check confirms if the correct servicemonitor exists: We do it slightly differently in Go, checking if services and servicemonitors exist in bulk\r\nhttps://github.com/ministryofjustice/cloud-platform-infrastructure/blob/main/test/config/config.go#L102-L111\r\n", "Is this still applies to having the services and serviceMontiors checks in go and enough?", "And this one as well as above? Even if there is a serviceMonitor, should we not check if the rules are present?", "New test added to cover this", "new test covers this", "new test added", "new test added"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/1578", "comments": ["@jackstockley89,\r\nmodsec test should have annotations to enable-modsec. And the tests should check for good and bad url. Can u check existing modsec for reference and update the same", "Can you change the name in the description so it is clear in the test logs", "And the description here as well", "can u change the context to say \"when ingress resource is deployed using 'default' ingress controller\""]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/1567", "comments": ["@vijay-veeranki  can u add a `:` "]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/1540", "comments": ["I think you meant to put 2.2.3, maybe?", "I wanted to see the tf plan for the branch before merging the module PR. I have amended the correct release version.\r\nCan you please check again?"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/1240", "comments": ["Out of curiosity, why the sleep change?", "This won't work on non-live-1 clusters. Ignoring the fact that we will eventually move `reports.cloud.....` onto the new cluster `live`.", "Perhaps we could use the bootstrap helloworld app? edit: and then use interpolation to assume the cluster name.", "the change is applied really fast, I saw no errors even with 5 secs", "Good point, this test is weird - it will not fail, but will not test the test cluster either; it just pings 1 live and 1 manager address", "Just to clarify: you saw no errors on live-1?", "The reason I ask is because the API usage between live-1 and everything else is VERY different.", "This is all on a test cluster. If live turns out to be slower, happy to create another PR to bump back", "helloworld app +interpolation would fail on live because. it doesn't use the 'apps.cluster' hostname"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/1236", "comments": ["this is old, we're at 1.18", "this is awscli v1, while we use v2 on our laptops and I think all the new niceties will be in v2\r\nThere is no Alpine package for it, but https://github.com/aws/aws-cli/issues/4685#issuecomment-829600284 hints at a way to get it built and keep the image small", "Can we bump this to 1.16?", "If we agree to go 1.16 we don't need to specify this as it's on by default.\r\nhttps://blog.golang.org/go116-module-changes", "To keep up to date with latest, can we use:\r\n```\r\ncurl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\"\r\n```\r\nOutlined here: https://kubernetes.io/docs/tasks/tools/install-kubectl-linux/\r\n\r\nUnless we need 1.15.1 for a specific reason.", "Regarding this, it worked!!!  Thanks for that. The image went down from 96MB to 76MB, but the amount of code added within the Dockefile doesn't feel worth :-( "]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/1198", "comments": ["@mogaal , this will enable compactor in `live` cluster. Can we enable only for manager?", "100% true, fixing it in a bit"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/1192", "comments": ["double exist", "*No rather than *None", "*daemonsets DO NOT exist rather than *daemonsets DOES NOT (because it's a collective)."]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/1184", "comments": ["This will need to be interpolated.", "The host should be randomised (as much as possible). This will save the inevitable host duplicate issue that will follow.", "I know it doesn't mean much but can we add \"rule\" here to define by \"not having an ingress rule....", "Maybe \"when an ingress rule is deployed using 'nginx' ingress controller\"", "The package names are slightly confusing here. Is the `integration_tests_test` testing the integration tests or just running the tests?", "I'd rather not have a WiP directory here. Are you able to split this off into another branch?\r\n(Sorry if it sounds like I'm being a diva) :)\r\nThis is all really good.", "Just fixed this, added support for the configuration file and environment variables. ", "It is randomised, isn't it? _host_ is interpolated with _namespaceName_ which uses `strings.ToLower(random.UniqueId()))`", "Should it be _resource_ instead of _rule_? From k8s point of view is a _resource_, isn't it?", "Fixed, with _resource_ instead of _rule_. Happy to put _rule_ also.", "Just deleted the WIP files and finished the logic implementation within the folder. It is added to the PR", "Ah yes, good point. I'll mark this one as resolved then.", "Either/or. Ingress is one of those terms that applies to a multitude of things. I'll let you choose which."]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/1179", "comments": ["@mogaal , this will set `enable_large_nodesgroup=true` for manager as the live_workspace is set to manager in here. \r\nhttps://github.com/ministryofjustice/cloud-platform-infrastructure/blob/main/terraform/aws-accounts/cloud-platform-aws/vpc/eks/components/main.tf#L69-L72", "You are 100% right, fixing it now. Thanks for that."]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/1158", "comments": ["this is already in, see main.tf from https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/1201"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/1156", "comments": ["Can you just get rid of this line?"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/1065", "comments": ["for https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/1062/files, we had to specify s3:* and set the restrictions on the AP end, it's probably the same here"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/1038", "comments": ["What does this mean in detail? If I have a set of DSD credentials (which I do), how would I need to set things up so that I can do a terraform apply?", "You can still do `terraform apply` but only targeting. It means we have some resources in DSD account and when we do full plan terraform will try to check them out. If you don't have the DSD credentials it is going to fail.", "Could you put that explanation into the README, please, @mogaal ?", "@digitalronin I added more information. Do you think is now more clear or we can add something else?", "This might just be my lack of knowledge, but I can't see from the README, *how* I would use my DSD credentials, if I had any.\r\n\r\nI understand how to supply AWS credentials to terraform, but I don't understand how to supply *multiple sets* of AWS credentials.\r\n\r\nIf that's just my limited knowledge, and it's obvious to others, then I'm happy to merge this. But if it's an unusual thing to do, I think we should have instructions on how to do it. Something like:\r\n\r\n```\r\nYou need DSD credentials to apply the terraform code, so to do a full `apply` you would run something like this:\r\n\r\nexport AWS_ACCESS_KEY_ID=[aws access key for moj-cp]\r\n...\r\nterraform apply -backend-config=...\r\n```\r\n\r\nIf you don't think that's necessary, then we can merge this as it is now."]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/1008", "comments": ["The \"owner\" value should probably be \r\n```\r\n\"Digital Prison Services: dps-hmpps@digital.justice.gov.uk\"\r\n```\r\nThat's consistent with other pathfinder stuff.", "\ud83d\udc4d "]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/1002", "comments": ["Wrong instances for the \"monitoring\" nodes"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/902", "comments": ["Per my comment above, can we identify the worker node instance groups via a label?\r\n\r\nIf we can do that, then we don't need to worry about their position in the YAML file (i.e. `last(3)`). This is less brittle, so we won't break stuff if we reorder the sections of the yaml file.", "We need to rename this method if it counts workers from multiple node groups. How about `target_worker_node_count` ?"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/877", "comments": ["Starting to think we should change the description to Testing modsec on ingress class: \"nginx\"", "The above change would mean the context would be \"when modsec is deployed\"", "Same as above", "This would be \"Testing modsec on ingress class: integration-test\"", "ditto"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/839", "comments": ["Do we have this requirement (i.e. that you must have an AWS profile called \"moj-cp\") documented anywhere?", "Yes, we do. It's in the \"create a cluster\" runbook.", "I don't think so, but it is widely used across all our terraform files. For me they don't make much sense unless we use multiple AWS Accounts, but it isn't the case. \r\n\r\nWith `AWS_*` exported should be more than enough"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/760", "comments": ["These seem very specific to the PSP tests, so I'd probably put them inline in the psp_spec.rb file. But, since the only difference is the name of the ERB file, and the name includes \"privileged\" and \"unprivileged\", I'm not sure it's worth defining methods for these.", "For the names of tests, generally you either want to use \"it\" to describe a situation, like \r\n\r\n> it \"allows root containers to run\" do ...\r\n\r\nOr, if that produces names that are too clunky, you might use \"specify\" like this;\r\n\r\n> specify \"containers run as root\" do ....\r\n\r\n", "@jasonBirchall , can we use apps/v1 as we are moving towards k8s 1.16", "I'd probably use something in here to explain that the erb template is part of what distinguishes privileged and non-privileged namespaces, e.g.\r\n```\r\ncontext \"when namespace is privileged\" do\r\n  let(:deployment_file) { \"spec/fixtures/privileged-deployment.yaml.erb\" }\r\n  ...\r\n```\r\nAnd similarly for unprivileged.\r\n\r\nThat would mean reorganising things so that it's the *context* which is privileged or not, but I think that would make the tests clearer and a little more concise.", "@jasonBirchall , same as above: replace with apps/v1", "A very good point. I'll change both. :+1: ", "I agree with this, I've now moved it to the psp spec and made the function generic.\r\n```\r\n# Creates a deplyoment using the arguments defined\r\ndef create_psp_deployment(namespace, deployment_file)\r\n  apply_template_file(\r\n    namespace: namespace,\r\n    file: deployment_file,\r\n    binding: binding\r\n  )\r\nend\r\n\r\n``` ", "Agreed. Changed the names of all descriptions.", "I originally used the organisation you outline but decided to change it to make as few function calls as possible. Reading your comment, I think you're right so I have decided to revert back."]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/758", "comments": ["I'd probably remove the \"contexts\" here.\r\n\r\nYou usually add a context when you need to have different setups for different groups of tests. But, in this case, you're just testing for the existence of some namespaces, so the contexts don't add value.\r\n\r\nAlso, I'd probably change this\r\n```\r\n    it \"Fail if namespace doesnt exist\" do\r\n      expect(namespace_exists?(\"concourse\")).to eq(true)\r\n```\r\nto this:\r\n```\r\n  specify {\r\n      expect(namespace_exists?(\"concourse\")).to eq(true)\r\n  }\r\n```\r\n\r\n`specify` and `it` are synonyms in rspec, and the code itself is simple enough that the descriptive text doesn't really make it any easier to read.\r\n", "Similarly, because you've only got one test per context here, I'd probably drop the contexts and change the tests to fetch the `pods` inside the tests, like this;\r\n```\r\nit \"runs postgresql pods\" do\r\n  pods = get_running_app_pods(\"concourse\", \"postgresql\")\r\n  expect(all_containers_running?(pods)).to eq(true)\r\nend\r\n```\r\n...and similar for the other pod tests", "done.", "done"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/729", "comments": ["You could do this like this:\r\n```\r\ntotal_hits = hash.dig(\"hits\", \"total\", \"value\")\r\n```\r\n\r\nAlthough, that will behave differently if any of those keys are missing. `fetch` will raise an error, but the `dig` version will just return nil."]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/721", "comments": ["I would try to avoid the use of ZIP files within our repo for lambda functions, it can lead to problems of versioning and add an extra step which is unnecessary. I would instead use [archive_file](https://www.terraform.io/docs/providers/archive/d/archive_file.html) function from terraform to delegate all of this to terraform"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/694", "comments": ["You don't need the \"zone_id = \" here - whatever the last value evaluated in the function is, that's what the return value will be.", "Do you need different methods to delete TXT versus A records? If you're passing the record object into the delete function, can you replace \"delete_a_record\" and \"delete_txt_record\" with a single \"delete_record\" method?", "If this method is only ever called from one place in the code, I would get rid of it and just inline `records > 2` as a boolean, with the explanatory comment next to it.", "This should probably be defined as a constant, to clarify that it's a magic value.", "you are right, it is much simpler that way."]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/663", "comments": ["policy = data.aws_iam_policy_document.offender-search-dev-delius-elastic-search-policy.json"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/620", "comments": ["@vijay-veeranki-moj you should be able to just change `context` to `xcontext` to achieve this.\r\nThat has the added benefit of reporting, in the test output, that the test is being skipped, so that we don't forget about it.", "Thanks @digitalronin, made the change , can you please review it again"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/605", "comments": ["You could just say `if gitcrypt_unlock` and `if integration_tests` here - you don't need the ` == true`\r\n\r\n`nil` is \"falsy\" in ruby, so you can also say `sleep(extra_wait) if extra_wait`\r\n\r\n\r\n", "The comment here is incorrect, it should be something like \"Don't run integration tests after creating the cluster\"", "Ahhh cool, thank you. Now improved. Please check", "Yeah sorry, copy-pasted from the above one. Fixed now."]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/599", "comments": ["You could also add calico-kube-controller.", "Only appears as a single pod however.", "There is only one of those, but it doesn't run on a master node (necessarily? it's running on a worker node right now - could it run on a master?)"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/585", "comments": ["perhaps you also might want `infrastructure-support = var.infrastructure-support` as a line here"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/549", "comments": ["Is this \"globally unique\"? If so, I'd use that phrase. If not, explain the scope within which the names must be unique."]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/543", "comments": ["this can just be hard-coded as 'good'", "For information alerts, runbook and silence buttons probably aren't necessary."]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/509", "comments": ["typo: Veleo -> Velero"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/504", "comments": ["Should we add \"is-production\" \"true\" here?", "added"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/465", "comments": ["I don't think this master_node var is required for eks.", "You are right, removed now\r\n", "Is there any way to avoid having named individuals here? Can we have something that iterates through the members of the ministryofjustice/webops team, or a set of IAM users we pull from the AWS cli?", "I suppose we will try to implement our kuberos (or kubehook, which is not deprecated) so everyone will be able to connect using auth0. Still, we will need a seed user to apply the initial set up, this seed user is the one which will be listed there.\r\n\r\nIf we are going to choose the path you mention (our IAM accounts instead of auth0) will be good to do exactly what you said. But still we're going to need a seed user though (can be a generic user, it doesn't need to be an individual or member of our team).\r\n\r\nI guess we'll realize which path will be when we start to deploy the cluster components, ", "I'll start to deploy all cluster components we have for the kops and see how it goes with the kuberos", "we'll need a solution for this", "no good reason, feel free to change", "we don't use this anymore, delete", "might want a note in the README to create smaller test cluster", "Do you have something in mind? I can see within the IAM users you've one called \"kops\", we can create a new user that can be used as a \"seed user\" to access the first time to the cluster and deploy all components. Let me know what do you think"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/447", "comments": ["Please change the cluster name in the comment, now that it's been moved to live-1"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/444", "comments": ["The differences between these methods are quite subtle.\r\n\r\nI think we need an explanatory comment above each one explaining why this method works in the way it does, and what you mean by \"cluster\", \"ingress\", \"backend\" and \"application\" in this context.\r\n\r\nAlso, the first two lines of each method are the same, so you could extract those to a method which each of these methods calls.\r\n\r\nFinally, you've got a bunch of string literals here, e.g. \"Code=\" - it would make the code easier to understand if you defined those as constants, e.g. `CUSTOM_ERROR_GENERATOR_HTML_BODY = \"Code=\"` or something like that.", "It would be easier to understand this if the `let(:host) ...` line were above the `let(:namespace_url)` line.", "It would be good here to have a comment here explaining that the http 'handler' is an app. which *raises* whichever http error we ask it for (that's not really a \"handler\").", "Would the tests be more reliable with a longer sleep?", "it would be good to have a comment here explaining how this annotation gives the namespace its own default backend.", "This might be clearer with another level of context\r\n```\r\ncontext \"ingress is annotated with an error code not from the cluster error list\" do\r\n  context \"application not serving error pages\" do\r\n    ...\r\n  end\r\n\r\n  context \"application is serving error pages\" do\r\n    ...\r\n  end\r\nend\r\n```\r\n", "If you make the context change I've suggested above, this test could move into the context \"ingress is annotated with an error code not from the cluster error list\""]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/442", "comments": ["The script can execute the `kubectl config` command, to ensure the context matches the cluster name. This is safer than requiring people to read the comments.\r\n\r\nAlso,  please remove the reference to `create-cluster.rb`", "Please add some explanation of why this is necessary.\r\n\r\nSomething like, \"The method looks for the instance group size in the kops manifest in our github repository, so it will always return the size of the live-1 cluster...\"", "line 25 doesn't do anything useful, since the logic testing the number is in `correct_number_of_workers_running?`\r\n\r\nI'd also replace `worker_instance_group_size` with a call to `get_ worker_instance_group_size` on line 29, so you can remove line 26, too", "We should use `execute` here, rather than backticks, for consistency.", "This error should say \"node was not cordoned...\"", "The variable `spec` isn't doing much, here, I'd combine these as `node.dig(\"spec\").fetch(\"unschedulable\", false)`", "We're not using the `can_fail` flag here, so you can remove that from this method, to simplify the code.", "Sorry, one more thought. If this fails (e.g. there is no such context defined in the user's .kube/config file), the script will continue executing, and could delete a node in the wrong cluster.\r\n\r\nThis should have a guard where, unless the command returns successfully, we raise an error and die.\r\n", "you can just end this method with the ``#{cmd}`` line - you don't need to assign to `result` ."]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/427", "comments": ["Why specify the path to the keyfile here? That path wouldn't work for me, whereas calling unlock without specifying a path works fine.", "This needs to be detailed separately in the runbook: when executing in a cluster, copying our private GPG keychain to the pod doesn't sound like a good idea, so instead we must export and `kubectl cp` the symmetric key. Same for AWS login credentials, a separate set not our own would be best.", "OK, but for now we're not running this in the cluster - we're just mounting our own gpg files into the local container when we run it.\r\nSo, can we remove this change and just have the upgrade stuff in this PR?\r\nWe can do the key thing separately."]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/419", "comments": ["IIRC, these were added in order to get the components to install in a single pass. \r\n\r\nWhat's the reason for removing the \"depends_on\" here? \r\n\r\n", "Good catch Took them out for testing. Added back in now "]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/406", "comments": ["I'd move this comment from here, and down in the method body, add a comment above each 'sed' invocation, explaining its effect.\r\n\r\nAlso, will these leave your working copy in a state where there are outstanding changes?\r\n", "Yes, this will change the current working copy with an outstanding change. We have to ignore the  tfvars changes when pushing to git or checkout again after building the test cluster.", "I'd suggest something like this;\r\n\r\n> This will disable high-priority pagerduty alarms for your cluster, by replacing the XXXX with a dummy value\r\n\r\n...and something similar for the slack webhook.\r\n\r\nI don't think the \"comment this to enable...\" line is necessary, as long as it's clear what effect the code has.\r\n"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/393", "comments": ["I'd do this the same way as on lines 51 - 59, just for the sake of keeping things consistent.", "Objects created by the tests should be named \"integrationtest-*\"\r\n\r\nThis makes it a lot easier to find and delete them, if anything gets left behind (e.g. because a test run crashes)", "`replicas = \"\"` implies that you should supply a string value, but it makes more sense for this to be an integer.\r\n\r\nAs someone calling this method, I think it's reasonable to always require a value here, so I'd remove the default altogether.", "This comment doesn't add anything. I'd remove it.", "This comment doesn't add anything. I'd remove it."]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/388", "comments": ["Let's just get rid of this comment. It's only going to confuse people, and make the code harder to read."]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/380", "comments": ["This method has a generic name, but the template file has several entries which are specific to external DNS, including the filename.\r\n\r\nI would either change the method name to be clear that it's only suitable for external DNS or, preferably, make everything generic so that it's clear this method can be used whenever someone needs an ingress.", "As with the create method, it doesn't seem necessary to hard-code the ingress name here.", "Typo: enpoint -> endpoint", "Also, hardcoded ingress name.", "The ruby convention is to use all lower-case for method names.", "Does this zoneid need to be hard-coded, here?", "method name to lower case, please", "You don't need the ` == true` here.", "I would add a comment here explaining the significance of the 2. Without that, it seems strange - why not 0, 1, 3...?", "This comment can go", "Since you're not using `before(:all)` I think you might be able to do this with `let` statements. Have you tried that?", "Since you mention the ingress in the context description, I'd probably put this in the before block, to keep the test easier to read", "You probably need something like `records.count > 0` here, otherwise your test might pass when it shouldn't (e.g. `[].nil? == false`", "Is this a magic zone that must exist, in order for these tests to pass? Can we do something to create these resources only if they don't already exist, so that the tests always work, even if these records have been deleted?", "See earlier comment about hard-coded values.", "For the \"sleep 1\" at the start of methods, please add a comment explaining why it's there (because it looks like it's unnecessary). I'd put something like:\r\n\r\n> \\# TODO: sleep added to avoid AWS Route53 API throttling errors. Remove once that issue is resolved.\r\n", "Where does `ZD4D7Y8KGAS4G` come from?", "Please change the method name to `delete_txt_record`, to follow ruby convention on method names", "\u261d\ufe0f ", "Can we have \"integrationtest\" in the namespace name? That matches the other tests, and will make it easy for us to identify and cleanup any leftovers (e.g. from crashed test runs)", "\u261d\ufe0f ", "Given that the context name mentions that an ingress is created, I would move the `create_ingress` call, and the associated sleep, into the `before(:all)` block", "I think these statements belong in the \"when zone matches ingress domain\" context.\r\n\r\nIdeally, the thing that makes the context different from other contexts should be done at the top of that context, to make it crystal clear to the reader what you're testing.", "It seems to be the zone where all the ELB domains are defined in eu-west-2, by AWS.\r\nhttps://docs.aws.amazon.com/general/latest/gr/rande.html"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/371", "comments": ["You don't need the inner {} here. ", "I'd probably change this comment to \"integrationtest\", for the sake of having a single, consistent, uncommon string to search for."]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/369", "comments": ["typo: intergration -> integration", "done in 2cf44c9"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/364", "comments": ["You don't need to assign to a variable and then put the variable at the end of the function, i.e.\r\n```\r\ndef foo\r\n  var = do_something\r\n  var\r\nend\r\n```\r\n...is equivalent to\r\n```\r\ndef foo\r\n  do_something\r\nend\r\n```\r\n\r\nAlso, you don't need the outermost `{}` here.\r\n`create_hosted_zone(foo: bar)` is the same as `create_hosted_zone({foo: bar})`", "You don't need `resp =` here, because you're not doing anything with `resp`", "You can drop the `{}` here.", "Do you specifically need `1.27.0`? If you change this to `1.27` you'll get point releases whenever you run `bundle upgrade`", "I don't think you need these `# required` comments. \r\n\r\nIf you try to call `create_zone` without supplying a parameter, you'll get a runtime error", "I think it would be better to move this example comment above the 'def' with the description of the method"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/344", "comments": ["put in spec helper"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/343", "comments": ["I think we need a note here, telling people how to determine the right value for ${TAG}", "The `$(IMAGE) ...cmd...` lines are continuations of the multi-line commands above, so the indentation should be the same.", "The `$(IMAGE) ...cmd...` lines are continuations of the multi-line commands above, so the indentation should be the same.", "The `$(IMAGE) ...cmd...` lines are continuations of the multi-line commands above, so the indentation should be the same.\r\n\r\nThis one was wrong in the first place ;)", "The tag value in the file smoke-tests/spec/fixtures/iam-assume-role-job.yaml.erb is 1.1", "1. Can this be moved to a `before(:all)` block, so that it is only run once, rather than for each individual test?\r\n2. The filename `spec/fixtures/namespace-annotations.yaml.erb` is misleading. Also, there are a lot of fixture files for this test - I'd recommend creating a single folder and putting all the files inside of it, to keep the fixtures directory well organised.\r\n3. It seems a bit involved to go through the whole ERB template dance just to create a namespace with one annotation. Can this be done via a `kubectl create namespace` command instead?", "This method name seems wrong. The function returns a json string.", "This code needs to be refactored and DRYed up.\r\n\r\nAlso, it might be worth creating some methods with clearer names, such as \"iam_role_exists?\", so you can have `unless iam_role_exists?(role); create_iam_role(role)`\r\n\r\nAlso, if these methods are only used by the kiam test, I would declare them in there and keep the shared helper file shorter. i.e. the helper file should only contain code which is used by multiple tests."]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/338", "comments": ["We may not need this License?", "Thanks Vijay - that's removed."]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/333", "comments": ["You'll need to cycle this webhook and store encrypted. ", "The name of this application `cp-poornima-dv-module` will need to be something fit for master. ", "This needs to be cluster agnostic.", "The name of this application `cp-poornima-dv-module` will need to be something fit for master.", "Rotated webhook and stored in tfvars. File unwanted.", "Unwanted file commit removed."]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/327", "comments": ["I might be missing something but why does it depend on prometheus?", "Thanks @jasonBirchall , fixed it to depends on \"helm_release.nginx_ingress_acme\""]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/318", "comments": ["This doesn't work for me, I get `./create-cluster.rb:131:in `block in check_software_installed': ERROR Required executable git-crypt not found. (RuntimeError)`", "```\r\n$ which git-crypt\r\n/usr/bin/git-crypt\r\n```", "How does this check required executables?", "Interesting. It does the same thing as the bash version. Lines 130 & 131 iterate through a list of required executables, and then run 'hash [whatever]' which is the same thing as the bash script does.\r\n\r\nWhat do you get for `hash git-crypt` ?", "**chat continued in another medium**. Conclusion: change `hash` to `which` "]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/295", "comments": ["Isn't this a duplicate of lines 250-253?", "It's on a different es cluster: `audit_1` vs `test`", "What was the thinking here?", "Do we no longer need to whitelist the team, or is this done via the org script now?", "We do not use this rule, I think it was in place when everything was locked down to our team. It's not defined on the tenant. ", ":+1: okay, thanks."]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/294", "comments": ["This secret is created in the environments repository. PR to follow. There is a question of whether this should exists as a Terraform resource?", "I've only added RDS metrics for now, as this would be a good starting point. ", "Since you've enabled the `ServiceMonitor` in the helm chart, we shouldn't need this extra config block here.", "Can we not provide the necessary credentials with a role, using `kiam`?", "Also, since this is only really useful for live clusters, should we add something like `count = \"${terraform.workspace == local.live_workspace ? 1 : 0}\"` ?\r\nIf not, all test clusters will hammer the cloudwatch API potentially causing throttling issues.", "A very good point. Reverted changed and padded out service monitor creation in values file. \r\n3b099f3 ", "Think this is a really good idea and is now implemented under commit 289a17e.", "Yes, changed to reflect the above comment as this should assume a role via KIAM. "]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/293", "comments": ["May I suggest simply `rm -f /tmp/${cluster_name}` to avoid any happy accidents? :)", "`KOPS_STATE_STORE` is an output of the cluster creation terraform config (`cloud-platform/`). We should be able to compute it: `KOPS_STATE_STORE=\"s3://$(terraform output kops_state_store)\"`. It shouldn't change unless we decide to move the state elsewhere but it would remove the need to have it exported beforehand. Do you think it's worth changing?", "Is this strictly required? For the cluster creation bits we should have the appropriate profiles specified in the terraform provider configuration blocks.", "Curious, why `hash` instead of `which`?", "There will be a key and a key.pub file. I'll change it to specify those explicitly.", "exit status\r\n\r\nhttps://stackoverflow.com/a/677212/794111", "I think we need it for kops anyway - I can't see any way to supply the aws profile to the kops command. If we need it for that, we may as well use it for terraform too.", "The previous cluster build process computed it. The problem is that I don't think it's possible to export an env. var from *within* a script, and have it available for sub-shells of that script. So, I specified that it should be in the environment.", "Interesting, thanks for the link that's a treasure of an answer. \r\nFWIW, my `which` returns an exit code just fine and `hash` does too on `zsh`.", "(I was more concerned about the `-r` flag, not the wildcard)", "You should be able to `export` from the parent shell but not the other way around. In any case, I don't think the value will change anytime soon so we can leave it as-is.", "Yeah, that was a mistake - just muscle memory!", "I think it's one of those things that will almost always work, but the answer also states that hash is a built-in, and which spawns a separate process, so it's arguably more efficient, and theoretically more reliable. There's very little in it. I think I'll add that link as a comment, to pre-empt future confusion!\r\n"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/281", "comments": ["You'll need to use `warning` here. As per https://github.com/ministryofjustice/cloud-platform-infrastructure/blob/master/terraform/cloud-platform-components/templates/prometheus-operator.yaml.tpl#L116"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/254", "comments": ["Can we please rename this to something a bit more descriptive? For example `opa:psp-privileged` or similar ", "Updated name to opa:psp-privileged"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/248", "comments": ["Can we make this `>=` the required version please?", "What do you think about changing:\r\n```\r\n\"${terraform.workspace == local.live_workspace ? format(\"https://prometheus.%s/oauth2/callback\", local.live_domain) : \"https://prometheus.apps.${local.cluster_base_domain_name}/oauth2/callback\"}\"\r\n```\r\nto:\r\n```\r\n\"${format(\"https://prometheus.%s/oauth2/callback\", terraform.workspace == local.live_workspace ? local.live_domain : \"apps.${local.cluster_base_domain_name}\")}\",\r\n```\r\nI believe it look much cleaner and is easier to read.", "As an afterthought, we could subsequently make `${terraform.workspace == local.live_workspace ? local.live_domain : local.cluster_base_domain_name}` another `local` variable so that it only evaluates once.", "Is this and the next one used anywhere? (the `/redirect_uri` path URLs)", "neat, shortened", "honestly don't remember", "removed"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/246", "comments": ["Can we drop `compact(list())` since we only have one element now?", "What if we re-wrote this like so:\r\n`\"${format(\"arn:aws:route53:::hostedzone/%s\", terraform.workspace == local.live_workspace ? \"*\" : data.terraform_remote_state.cluster.hosted_zone_id}\"`\r\nI think it's much easier to read? (haven't tested syntax validity!)", "Same as above.", "Removed the compact(list())", "updated the \"aws_iam_role\" \"external_dns\" resources filter as suggested", "Removed the compact(list())"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/244", "comments": ["Couldn't this be simpler?\r\n\r\n```\r\ngit-crypt status -e | sed 's/.*encrypted: //' > git-crypt-files\r\n```\r\n\r\n", "This is quite hard to read. How about this?\r\n\r\n```\r\nls .git-crypt/keys/default/0/*.gpg \\\r\n  | sed 's/.*default.0.//' \\\r\n  | sed 's/.gpg//' \\\r\n  > git-crypt-users\r\n```", "\ud83d\udc4d Bonus points for this use of xargs! One of my favourite and most overlooked unix tools.", "You don't need `-I{}` here, do you?", "Please add a note here explaining what the user should see if the file is encrypted correctly (i.e. something like `^@GITCRYPT^@<E5>\u074e^]xxY<F0><8F>PR<BE>^U/\"i5i2t^Ep^R<BB><C3><E8>B<EE><A5>bK<85><C5>^B^B<C5>@5<D8><FB>n<9F><DA>w<B3>O<D1><FF>`) instead of the cleartext.\r\n\r\nWithout that, if that output of the `git show` command is:\r\n\r\n```\r\nI AM SOOPER SEKRIT AND SHOULD NOT BE PUSHED TO GITHUB\r\n```\r\n\r\n...how does the user know this isn't OK? (admittedly, they should be able to figure it out from context, but it never hurts to be explicit).", "I don't think so. Just a habit because osx `xargs` works somewhat differently.", "As discussed, I've ended up replacing the regular expressions with simpler commands and comments for the reader. It's hopefully easier to read now. "]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/243", "comments": ["I would suggest tweaking this a little bit:\r\n\r\n> The [Open Policy Agent](https://www.openpolicyagent.org) (OPA) is a lightweight...", "> The admissionControllerRules XXXX the operations\r\n\r\nXXXX marks a missing word - maybe \"defines\" or \"specifies\"?", "Could we have an example here, or a link to one?", "I suggest adding a description of what the example does, i.e. something like;\r\n\r\n> The following RBAC definition enables listing, viewing and watching namespaces, and listing viewing watching and patching ingresses....\r\n", "This renders as a code block. Can you please remove the indentation in order to change this to a list?", "Same as above.", "To make this a bit easier to read, can you put the json blobs (here and also in the next paragraph) into code blocks please?", "Looks like this entire section is from the official document linked at the end. We shouldn't replicate upstream docs. The link itself should be sufficient (and part of the previous section, \"OPA Policies\")", "Should we merge this section into the \"kube-mgmt\" section above?\r\n\r\nI think apart from the configuration example, we can skip the rest and keep it simple.", "Let's remove this section. I don't believe we need to explain RBAC as part of OPA.", "Can we please mention the file where this entrypoint is defined?", "Agree, updated accordingly.", "Thanks corrected the missing word", "Link provided below under \"How to write policies\"", "Removed the RBAC section considering the comments from Mitch", "Thanks, updated accordingly.", "Thanks, updated accordingly.", "Thanks, updated accordingly.", "provided the link and removed remaining bits as suggested", "merged this under kube-mgmt", "removed RBAC", "mentioned the file information", "The following code block is a bit confusing (L115 - L119). It's not obvious what it refers to and what `<replicate-path>` is. I think we should remove it and just maintain teh example (L123 - L128). What do you think?", "This is a list sub-item (for lack of a better term), is this intentional?", "Remove the trailing dot please.", "Can you please move the sentence outside of the code block?", "Apart from the configuration example, skipped the rest to keep it simple ", "pointed to opa-default-system-main.yaml which contains the main OPA policy and used as an entry-point for policy evaluations.", "amended this block to keep it simple as suggested", "Fixed the format issue", "Removed the trailing dot", "moved the sentence outside of the code block", "Sweet! Love the link ^_^"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/242", "comments": ["Although we seem to be using it in most `helm_release` resources, we should avoid `recreate_pods` where possible because it disrupts the service. I think with `opa` we don't need to use it as the chart is nicely self-contained and configuration comes from configmaps.", "Should we change this to `Fail` instead?", "Do we require `namespaces` at this point? If not, can we remove it?", "Since this is a `ValidatingWebhook`, I don't think it requires `patch` on ingresses?", "Similarly here, `patch` and `update` for configmaps should be needed? Am I missing something?", "I think we should address `PATCH` and `PUT` as well here? This is for when an `Ingress` changes or I use `kubectl apply` to create it. From my notes we tried `re_match(\"(CREATE|PUT|PATCH)\", input.request.operation)` but this should be tested thoroughly to make sure we cover all cases.", "As an additional comment, it's pretty bad the the helm chart will only set up a `ClusterRole` so we end up having to give it full access to configmaps. Since it will only ever need to parse configmaps from its own namespace, do you think it's worth the effort to extract this and create a `Role` and `RoleBinding` externally?", "No we can't :(\r\n\r\nopen-policy-agent/kube-mgmt#11\r\n\r\n@vijay-veeranki-moj has tested this and it's the same behaviour on the latest versions\r\n", "Agree, removed \"recreate_pods = true\"", "Agree, Changed to \"admissionControllerFailurePolicy: Fail\"", "Agree, removed the namespace admissionControllerRules", "Agree, removed \"- patch\" for ingress resource", "We need this as configmaps will get updated with the status.", "Agree, updated accordingly"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/237", "comments": ["s/exclusively/specifically/", "s/privileged/privileges/", "s/any kind volume/any volumes/", "s/port/ports/", "s/server port/listen on port/", "s/defaults/default/", "s/the a proper workarounf/a proper workaround/"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/235", "comments": ["Remove space. ", "Done in cb4f98b.", "I find this a bit hard to parse, can't we instead do something like:\r\n```\r\n\"*.apps.${data.terraform_remote_state.cluster.cluster_domain_name},apps.${data.terraform_remote_state.cluster.cluster_domain_name}${terraform.workspace == local.live_workspace ? format(\",*.%s\", local.live_domain) : \"\"}\"\r\n```", "Is that `-` correct?", "When that ternary is false, this will contain the same zone id twice. Can we not use an empty string for false?\r\n", "Again with this, I think it's a bit hard to parse. Do we currently need to plan for other live clusters? I don't believe we plan to get any more anytime soon. Instead, the previous statement was easier to understand. Wdyt?", "yes, sadly, indenting :(", "couldn't find a way, terraform insist on sending an empty pair of quotes that breaks indenting; the duplicate is removed from the final output though so thought it'd work", "we have live-0 and live-1 maybe live-2 sometime?", "neat! changed", "I'm saying this because `live-0` is not managed from this branch and won't live long enough to try and integrate. Is `live-2` even a concern right now that would warrant complicating this?", "I think you missed committing changes to the cert template?", "Do you mean it breaks validation with the AWS API?\r\nWe could do something like this then:\r\n```\r\n[\"${compact(list(\r\n      \"arn:aws:route53:::hostedzone/${data.terraform_remote_state.cluster.hosted_zone_id}\",\r\n      \"${terraform.workspace == local.live_workspace ? format(\"%s/%s\", \"arn:aws:route53:::hostedzone\", data.terraform_remote_state.global.cp_zone_id) : \"\"}\",\r\n    ))}\"]\r\n```\r\nBut I'm not sure this reads better \ud83c\udf5d \r\nIt's just that the fact that the duplicates get pruned when you actually apply is perhaps a \"feature\" we shouldn't depend upon (couldn't find any mention of this) \ud83e\udd37\u200d\u2642\ufe0f \r\n"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/232", "comments": ["You'll need to define a local-exec with the delete command.", "I did not add it, as part of the uninstall of operator all rules get deleted including all the custom rules, so when the delete command runs, it does not find anything to delete ", "I think we should add it then with the `--ignore-not-found` flag. So when we fix that CRD issue (which might have been addressed upstream) it just works properly.\r\n\r\nAdditionally, should this be a separate `null_resource` instead? I think it would improve lifecycle management (you can `taint / apply / destroy` independently from the prom chart). Is there a reason why this should be different to the proxy, for example?"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/202", "comments": ["Does `secretName` need to be uncommented?\r\nIt was left as a comment so that the Grafana Ingress would use the default wildcard certificate. `prometheus-general-tls` is not being created anywhere?", "Hi @alkar - made changes - hopefully have got it right now?"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/200", "comments": ["This and the following value are empty, do we need them here?", "These variables should be picked up from the `cloud-platform` [state](https://github.com/ministryofjustice/cloud-platform-infrastructure/blob/live-0/terraform/cloud-platform/outputs.tf#L53-L71). There is an auth0 client created there to be used for components.\r\n\r\nHaving them as variables in this terraform configuration means we need to manually create the app for every cluster and also manually pass them in every time we need to run terraform, which is something we should avoid.\r\n", "Looking at what other people have done, they have let them blank.\r\nI will test it without the values. "]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/181", "comments": ["Is there any way to pull the values from `helm-charts/fluentd-es/config/output.conf` and use them here? \r\n\r\nAssuming we can't do that, I'd suggest changing this to; \"The Fluentd buffer limit (defined by the `chunk_limit_size` and `queue_limit_length` values in `helm-charts/fluentd-es/config/output.conf`) is full...\"\r\n\r\nThat way, the error message will still be accurate if those values are changed.", "I've had a quick chat with Mitch and we both don't think it would be possible to pull the values.\r\n\r\nBut I have updated the message. :) ", "\ud83d\udc4d I thought that might be tricky. "]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/166", "comments": ["moved to helm", "point to Sablu's README to avoid duplication?", "Removed reference to OIDC.", "As discussed. This is deliberate. "]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/155", "comments": ["Does `Runbook URL` work with a space - does this need to be `runbook_url`", "changed to match new template annotations "]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/153", "comments": ["Terraform best practice is to use `_` in resource names as per:\r\nhttps://www.terraform-best-practices.com/naming#general-conventions\r\nhttps://www.terraform.io/docs/extend/best-practices/naming.html#resource-names", "Same as above best practice.", "Is it worth keeping this populated upstream i.e. \r\n`\"${data.terraform_remote_state.cluster.oidc_client_id}\"`"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/148", "comments": ["Should we add some resources here?", "It might be a good idea to add storage to alertmanager as well - IIRC this means that it doesn't forget alerts across restarts which means no noise from alerts flipping over with every restart.", "Perhaps some resources for alertmanager as well?", "This is the new grafana sidecars for loading datasources & dashboards. I'm assuming it will just work fine with the existing bespoke setup which uses the `grafana-user-dashboards` configmap (L376) but something to keep in mind.\r\n\r\nAlso, we need to test the new design and deprecate ours.\r\n", "Brilliant!", "Do you think we should downgrade to 1.11? IIRC, officially `kubectl` supports clusters +/- one minor version (ie. 1.12 would support 1.11 and 1.13).", "Upgrade to `v2.7.1` which contains various fixes.", "Looks like a typo.", "We currently use a PV with 100Gi of storage (don't know how it got out of sync) although we don't _need_ that much. I think we should declare `100Gi` here as well for consistency.", "This is very promising! \ud83c\udf89\r\n(also the next option, `containers`!)", "Is this indented at the wrong level?", "Was this file kept for a reason?", "Should this be... `monitoring`? I can't parse the English above it :|", "Do you mean for the Prometheus-operator pod or generally across all components in this template like grafana etc?", "I have no problems with this. Will give it the same as Prometheus.", "I was thinking prometheus-operator but perhaps there's no point, I just looked at the current usage and it's really nothing, burstable should be fine.", "`v1.11.7` [is latest](https://console.cloud.google.com/gcr/images/google-containers/GLOBAL/hyperkube?gcrImageListsize=30&gcrImageListquery=%255B%257B_22k_22_3A_22_22_2C_22t_22_3A10_2C_22v_22_3A_22_5C_221.11_5C_22_22%257D%255D&gcrImageListsort=-uploaded), can we please bump that as it no doubt includes a ton of fixes! ", "fixed in ` [25ae4aa](/ministryofjustice/cloud-platform-infrastructure/pull/148/commits/25ae4aabf15d16152b53ef3da4e09d3404eb72f0)`"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/146", "comments": ["Can we rename the label now before it's much more hassle to do so (perhaps `team` or `receiver` or something else)? Perhaps it doesn't matter that much?\r\n\r\nShould we also rename ours to something like `cloud-platform-critical` and `cloud-platform-warning` ?\r\n"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/141", "comments": ["Hi Paul, can we set the tags as per:\r\nhttps://github.com/ministryofjustice/technical-guidance/blob/master/standards/documenting-infrastructure-owners.md", "No need for this to be here (even commented out), should be dictated via `main.tf`"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/128", "comments": ["Not sure you'll want to include this part. It's being taking out as of https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/127/files#diff-ad3d1a514b5db6bf91fbc0285d1e920cL173"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/127", "comments": ["We need a way to manage the expiry of these certificates. \r\nWill kiam just stop working? \r\nIs it worth pattern matching a triggered alert?\r\nWhen it expires, is it a case of re-running this Terraform file?", "Built a test cluster using this branch and the above changes. Unfortunately, `kops` doesn't ever validate. \r\nI just end up with:\r\n```\r\nUsing cluster from kubectl context: cloud-platform-kiam-test.k8s.integration.dsd.io\r\n\r\nValidating cluster cloud-platform-kiam-test.k8s.integration.dsd.io\r\n\r\nunexpected error during validation: unable to resolve Kubernetes cluster API URL dns: lookup api.cloud-platform-kiam-test.k8s.integration.dsd.io on xxx.xxx.x.x(redacted):53: no such host\r\n```", "I may have been a little haste. :)\r\n\r\nThis did eventually validate. Nothing to see here. ", "On fresh clusters the `kiam` namespace won't exist and the service creation will fail. Perhaps put a ns creation before. ", "or put a dependency allowing the Helm to run first (and create the ns if it doesn't exist). \r\n\r\nThis is the error I'm seeing. Easily remedied by creating the ns manually:\r\n`* kubernetes_service.agent-metrics: namespaces \"kiam\" not found`\r\n", "@jasonBirchall e9a4931 should fix this but I have not tested it yet", "As discussed:\r\n- `kiam` will just stop working, indeed but with it, any `Pods` using IAM roles.\r\n- We could use `blackbox_exporter` to get cert expiry in a prom metric and hook an alert on it. However, we will most likely drive this off https://github.com/ministryofjustice/cloud-platform/issues/587 so it's all done (hopefully) transparently. Should we just create a calendar event for now and raise an issue to address?\r\n- Yes, re-running tf will renew & fix it.", "This has now been tested.", "Yes, although not ideal the calendar entry will suffice. "]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/125", "comments": ["As this file doesn't exist, won't it just pass an empty values file?", "@jasonBirchall missed the file in the commit, just pushed."]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/124", "comments": ["As discussed. Will need to grab this value from upstream tf state. ", "Same as above {cloud-platform-test-8.k8s.integration.dsd.io}"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/117", "comments": ["This link doesn't work at the moment. I think it's just the naming. ", "As discussed, create a dir here `/terraform/global-resources/<dirName>` and store additional files. ", "Same here. Place in `resources` dir.", "I recommend renaming this file and running it in the same state as `/terraform/global-resources`", "Use the same variables file as `/terraform/global-resources/variables.tf`"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/113", "comments": ["Did you mean to remove the `component`s? I think it's actually good that we had those\u2026", "It's a duplicate tag, already defined by kops under `kops.k8s.io/instancegroup`"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/112", "comments": ["We recently changed the node size as memory consumption became a concern. ", "Didn't really know what to put for application name so came up with this. Any objections?"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/106", "comments": ["Please omit `namespace` as with the other resources. `helm` manages it separately.", "This should use the template as the other resources do.", "I believe `kubernetes.io/cluster-service` and `addonmanager.kubernetes.io/mode` won't do anything (the latter is probably a remnant of the past, the former might be significant for the actual `DaemonSet`). However, I suppose it's fine to leave them in for now - at least it's uniform across all resources.", "This works but on a closer read I think I mistakenly picked these two labels. I think the selector here should be the same as the `DaemonSet` selector on L98-101.\r\n\r\nI'm not sure which one is better, however, it certainly shouldn't select based on hardcoded values when `app` and `release` are both generated (also, `app` and `release` specifically are equal, see the `DaemonSet` spec below).\r\n\r\nPerhaps the following two would work nicely?\r\n```\r\n     app: {{ .Release.Name }}\r\n     version: {{ .Values.image.tag }}\r\n```\r\nThis combination seems unique enough.", "The indentation is wrong here. Can you please fix?"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/101", "comments": ["Do we actually need to define a `values` file at all?\r\n\r\nCan we just use the default values?"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/100", "comments": ["You can also use this https://www.terraform.io/docs/configuration/interpolation.html#cidrhost-iprange-hostnum-", "I still think we shouldn't veer from the default, especially looking at `obsolete`. If I understand the docs correctly it seems that when an ELB changes IP addresses, the old one will still be valid for an extra 30secs and can potentially cause issues again? (although in my experience, even after the AWS nameserver stops responding with an IP address it will still be valid at least for a few minutes)", "Bleh. `Error: variable \"dns_ip\": default may not contain interpolations`. maybe in 0.12 :D", "Yea you can't do that but you can drop the var and feed it into the template directly ;)"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/99", "comments": ["Should we have a retain `reclaimPolicy` ?", "This feels too brittle (what if we re-order elements?) - also the same for the slack configs below.\r\nShould we instead treat `values.yaml` as a template file and use terraform interpolation instead of overriding using `set {}` ?", "Do we want to run this in parallel with the existing one?", "Same as above.", "From the README:\r\n```\r\n  --set-string grafana.adminUser=$(head -c 16 /dev/urandom | xxd -p) \\\r\n  --set-string grafana.adminPassword=$(head -c 16 /dev/urandom | xxd -p)\r\n```\r\nAlthough we agreed we won't manage the extra bits yet, we still need to override these values. `hex` from [`random_id`](https://www.terraform.io/docs/providers/random/r/id.html) should be equivalent.", "Yeah, good catch. Will get a commit in now. ", "Yeah, good catch. Will get a commit in now. ", "ce51bd4 ", "ce51bd4 ", "Not sure I can set a `reclaimPolicy` in tf provider:\r\nhttps://www.terraform.io/docs/providers/kubernetes/r/storage_class.html#storage_provisioner", "I think this is fair. The set command is how Helm recommends doing interpolation but we may as well use Terraform. \r\n\r\nI have made a rather big change in 652b1b3 and 3ee0687.\r\n\r\nHelm docs:\r\nhttps://docs.helm.sh/chart_best_practices/values/#consider-how-users-will-use-your-values", "Probably worth mentioning that this is a placeholder file for `local_file` to overwrite. ", "Okay. This has been done under b88057b."]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/85", "comments": ["Can you follow how this structure for namespaces please:\r\nhttps://github.com/ministryofjustice/cloud-platform-environments/blob/master/namespaces/cloud-platform-live-0.k8s.integration.dsd.io/audit/00-namespace.yaml", "This will need to be interpolated either by the cloud-platform state store or perhaps `${terraform.workspace}`", "The same as above. ", "We do not want to manage the namespace in the chart (I don't think any chart we're using does this).", "As discussed, please use camelcase for the values.", "Please remove `NetworkPolicies` as well, we will be managing these in the environments repo.", "As discussed, please extract these config files like you've done for `system.input.conf`", "I believe we should use `image.repository` and `image.tag` as most of the other charts we use (see [here](https://github.com/helm/charts/blob/master/stable/nginx-ingress/values.yaml#L6-L8)), and provide a default value that is the \"supported\" version.", "`appVersion` should match the default value for `image.tag`", "When you create a new chart using `helm` (`helm create foo`) you'll see that the resources have a number of labels defined:\r\n```\r\n  name: {{ include \"foo.fullname\" . }}\r\n  labels:\r\n    app: {{ include \"foo.name\" . }}\r\n    chart: {{ include \"foo.chart\" . }}\r\n    release: {{ .Release.Name }}\r\n    heritage: {{ .Release.Service }}\r\n```\r\nI've not found any documentation on how these are used by `helm` but it seems they are used. `nginx-ingress` and `kube-prometheus` define them on all resources. I think we should do the same?", "Can we move the chart under `/helm-charts` please?", "Where are you referencing this from?\r\n", "Try `helm create newchart` and look at the templates.\r\nAlso [example from `nginx-ingress`](https://github.com/helm/charts/blob/master/stable/nginx-ingress/templates/controller-deployment.yaml#L4-L11)", "Regression?", "Is this used for anything?", "Please change to the [namespace attribute](https://www.terraform.io/docs/providers/helm/release.html#namespace) which is the preferred way of controlling this.", "As per helm docs, hardcoding `name` is considered bad practice.", "Again, looking at stable charts and the output of `helm create new-chart`, they don't define `namespace` for  resources. We should do the same and omit this on all resources.", "From our conversation the other day, if you run `helm create newchart` and look at the generated `Deployment` template (or look at [kuberos](https://github.com/ministryofjustice/kubernetes-investigations/blob/master/helm-charts/kuberos/templates/deployment.yaml#L4)) it uses the fullname template (defined in `_helpers.tpl`). We should use the same and keep it consistent for all resources.", "Remove hardcoded value and set as default in `values.yaml`.", "This is not required, we are using the default value (and in case of an upgrade should upgrade the default in the chart)."]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/82", "comments": ["When https://github.com/ministryofjustice/cloud-platform/issues/459 is complete we can populate the `oidc` entries. ", "I can only pass the slice via the above method, for example, `${external_subnets_id_a[0]}` doesn't work."]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/80", "comments": ["Ran `terraform plan` and it resulted in the following:\r\n```\r\nTerraform will perform the following actions:\r\n\r\n  ~ aws_lb_target_group.haproxy_alb_target\r\n      proxy_protocol_v2: \"\" => \"false\"\r\n\r\n\r\nPlan: 0 to add, 1 to change, 0 to destroy.\r\n```\r\nPerhaps:\r\n```suggestion\r\n  proxy_protocol_v2 = \"false\"\r\n```", "Can you take this out completely?", "Can you add something about any pre-req work required i.e. create a hosted zone?", "not needed anymore! \ud83d\ude04 "]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/67", "comments": ["Isn't this `audit.k8s.io/v1beta1` ?"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/62", "comments": ["Kill the apostrophe in \"URL's\" and maybe rewrite this.  It's a bit clunky when you read it out loud :) ", "Change the semi-colon to a colon, please. ", "Shouldn't you do this *before* you change the DNS? ` \r\n\r\nOk, reading through it, I'm not sure so you can ignore this remark as you see fit. ", "You don't need to title-case Load Balancer.  ", "'Load Balancer' isn't a proper noun :) ", "Where and how do I get the certificate for the failed cluster?  ", "Instructions or a link to instructions on how to do this? ", "\ud83d\udc4d Good point. Changed under last commit.", "Done.", "Cool, done. ", "I've expanded this slightly. It's just a drop down menu so really easy to find. ", "Totally agree. There's not too much to this but I've expanded it out a little. "]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/60", "comments": ["I can't imagine this particular step will age well. Could you perhaps state: switch to the current master branch (at this point in time it is `dd_dd_sqlite_db`)", "File path needs to start with ./ \r\n$ kubectl apply -f ./cluster-components/helm/rbac-config.yml", "I will remove this step. At this current moment its `dd_dd_sqlite_db` but I've been informed a PR is open to merge to master. "]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/58", "comments": ["- Homepage URL =  **'https://login.apps.clustername.dsd.io'**\r\n\r\nNote: If not admin for MoJ org, an admin will need to accept the 0Auth app.", "Settings on the repo and removing the required approval", "Put the required approval back", "export AWS_PROFILE=platform-integration", "Recovering deployments \r\n\r\nGo to application repo and kubectl apply the manifest files", "Remove commit to master as all steps will be manual in recovery", "Switch over DNS", "Use the moj-cloud-platform-dev Auth0 tenant", "Remove step and add:\r\n- Create a new application on Auth0 (regular web app) called 'your-cluster-name' Kuberos\r\n- Note down the ClientID and the Client Secret from that app.\r\n- In settings on that app, under 'Allowed callback URLs', add - https://login.apps.<cluster-name>.dsd.io/ui and save changes", "Is this actually required?\r\n\r\nI've created multiple applications without the need for an GH Oauth app.  ", "This came up yesterday when chatting with @ollieanwyll : it's only required if there's no tenant available (ie. if you're starting from scratch). We've currently been using a single tenant for all clusters so this won't be required as part of the recovery process.\r\n\r\nHowever, it might be worth discussing whether we want a different tenant per cluster (I don't see any reason unless we were to use different auth0 rules per cluster, which is not the case currently).\r\n\r\nIt might be worth splitting into a different document? I think it's cause enough confusion :)", "Perhaps this should say, if you don't, follow the steps below to create a new one (see also [this](https://github.com/ministryofjustice/kubernetes-investigations/pull/58/files#r205176209)).", "True, but this will eventually merge into master. Should we change it to read `master` and add a note that it's currently pending a merge from that branch?"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/47", "comments": ["Please avoid using initials/acronyms, even if it is something that the team commonly understands. \r\n\r\n\"use GH creds to login\" -> \"use your Github credentials to login\"", "Please avoid using initials/acronyms, even if it is something that the team commonly understands.\r\n\r\n\"use GH creds to login\" -> \"use your Github credentials to login\"", "Overall :+1:", "Please don't hardcode URLs\u2013even for use as keys\u2013this far down in the code.  Set it as a variable with a descriptive name towards the top of the function.", "This is what's breaking the CircleCI tests.  Can we change it to a `tfvars`?  @alkar thinks `terraform fmt` doesn't bother with these.", "This works for our current requirements, but we'll need to refine it soon so that we give a lower level of access to regular users. "]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/39", "comments": ["It should be safe to remove all the files under `cluster-components/kuberos/`", "The files under `concourse/` are not related to the sandbox cluster - leave it as is but in the future, it would be good to make unrelated changes in separate PRs.", "github_concourse.ini points to the sandbox cluster, and according to raz this was an investigation and its not being used", "ok", "fixed"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/35", "comments": ["Question that's occurred to me before - does it make sense to declare a specific ingress class when we've only got one ingress controller? If we change ingress controller that means we'll need to update any ingress rules that have declared a class, so is it better to not define anything and use the default controller?", "It very much depends on how we want to handle a transition in the future but I'm not sure there's a clear answer. I would rather not leave it unset since the default behaviour for ingress controller is not necessarily catch-all. At least by having a value, we can better control the transition by adjusting selector flags on the controller. On the other hand, I feel `nginx` is too specific.", "Fair enough - it's not an issue right now, so we can address it later if we switch ingress controller \ud83d\udc4d "]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/29", "comments": ["these outputs are being used in the cluster creation process, do not overwrite ", "these outputs are being used in the cluster creation process, do not overwrite "]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/28", "comments": ["Perhaps it's better to just refer to https://github.com/ministryofjustice/cloud-platform-terraform-ecr-credentials/blob/master/README.md ? Correct me if I'm wrong but this section seems to be duplicating the docs from the repo. I think it would be better to just explain how the user should handle code changes here (make a new file / expand `ecr_credentials.tf`) and leave the details in the ecr module repo.", "this is a specific usage of the module in this case for the demo app, i think that should be documented here.", "Might be worth making this bold or stand out otherwise folks might miss it.", "this was fixed"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/22", "comments": ["I don't think we need this file at all, as we'll never be creating or updating multiple clusters in one go. At a high level, we're aiming for a pipeline or automated process that creates/updates a specific cluster, and if we need to do that for multiple clusters, we'd run that pipeline multiple times - e.g:\r\n\r\n1. update cluster config\r\n2. apply cluster config to integration environment\r\n2. wait until it's ready\r\n3. run integration tests\r\n4. if tests pass, do the same for production environment", "I don't think this should be interacting with Terraform directly, as AWS infrastructure-level changes should be handled in a separate phase that will run prior to creating or updating clusters. At a high level, we should have the following phases when creating or updating environments:\r\n\r\n1. Terraform - update or create main AWS resources such as VPC, subnets, Route53, etc\r\n2. Kops - update or create cluster\r\n3. Helm/kubectl - update or create services on the cluster\r\n\r\nThe work here should be solely concerned with item no. 2 above, and at a high level do something like this:\r\n\r\n1. `terraform output -json` - get values from the current Terraform state that Kops needs to know about\r\n2. `create_cluster_config.py` - pass those values into `create_cluster_config.py` on the command line, (either as individual flags like `--availability-zones`, or the whole tf json object for simplicity's sake), combine it with a template `cluster-template.yml`, and output a final `cluster.yml`\r\n3. `kops create|replace -f cluster.yml` - apply the changes to kops remote config store\r\n4. `kops update` - apply kops remote config to the actual cluster\r\n\r\nWe don't necessarily need to wrap numbers 1, 3 and 4 above in scripts, unless it's easier to do so, as they could just be steps in our pipeline.", "I think it might be possible to also specify the SSH key in kops YAML, but I need to check the docs on that", "It looks like this is actually the bastion name, not a value for `topology` (which on the kops command line can only be `public` or `private`) - although we likely don't need to specify bastions here at all (see below)", "This doesn't seem to be used anywhere", "We should use Python 3, and it looks like this script is, so the shebang should be `#!/usr/bin/env python3`", "It's probably better to leave bastions out of this, and create those in Terraform, as bastion hosts aren't really related to the cluster, and we might want more control over them than Kops allows.", "General python best practice note - it's not necessary to use the `update` method when setting a single key in a dict - `template['metadata']['name'] = cluster_name` does the same thing, and is shorter and easier to understand. `update()` is best used for setting several dict keys at once, so you should either use one `update()` call with several values, or directly set keys individually", "The Route53 hosted zone ID is a per-environment value, so this should also be populated by the `create_cluster_config` script", "`oidcClientId` and `oidcIssuerURL` will also vary per cluster, so should be set by the script", "We should probably also have instance types and numbers as arguments in the cluster creation script, so we can deploy smaller clusters for testing and individual dev clusters", "After a very brief chat with @kalbir just now I think this probably warrants some discussion - in terms of how we handle the config of multiple clusters, how/when those configs are applied, and what testing or previewing config changes looks like. We could have individual `cluster.yml` files for each individual cluster, but then that raises the question of what should be in there and what should be passed in at YML render time - ideally we want to be able to test cluster config changes without needing to apply them to a specific running cluster, so we'd need to be careful to keep things like cluster and DNS names out of it.\r\n\r\nThe other question is if we should have a single script or process that applies all changes to all clusters in one go - that doesn't feel right to me as it'd require a one-to-one mapping between `cluster.yml` files and deployed clusters, preventing us from previewing or testing changes, but I'm open to suggestions here.", "Kerin, if you have a pipeline that creates/updates a specific cluster, you cannot run that for multiple clusters, because its designed to work with a specific cluster.\r\nYou can have however a generic pipeline that takes as an argument the cluster name and creates/updates that given cluster, and then you can reuse that pipeline for different clusters.\r\nwe dont want to reuse the same pipeline code over and over because that will generate code duplication.\r\n\r\nthe one to one mapping between cluster.yaml and the deployed clusters is what we already have on this repo (sandbox cluster and non-prod cluster), inside kops, so that is why is used that approach for this feature.\r\n\r\nagain, we can have a generic pipeline manually triggered from witch you specify as argument the cluster name, but the issue with that is that you cant guarantee the cluster.yaml in the repo will match the running cluster config. The running cluster config may be outdated if the pipeline did not run for that given cluster after a commit was pushed to master.\r\nwith this approach everything that is in the repo is applied on the cluster and you can consider the repo the source of truth.\r\nYou can have a 'testing' branch of this repo to apply it against a testing subset of clusters to test the config before applying it to the production clusters. ", "Hi, this work in jira was divided into 2 tkts, terraform elements and kops elements\r\nhttps://dsdmoj.atlassian.net/browse/CPT-472\r\nhttps://dsdmoj.atlassian.net/browse/CPT-483\r\n\r\nregarding the terraform part specifically:\r\n\r\n1)Use terraform to provision the VPC and other infrastructure needed.\r\n2)Turn this into an automated job to kick off the terraform build\r\n3)Make it so that any variables required by the kops job in CPT-483 can be passed to it.\r\n\r\nthat is what create_cluster.sh is doing.\r\nIf this is not what we want, please update the described tkts with the correct specification, and ill work on modifying those.\r\n\r\nYour description above is just a simplified version of what this pull request is already doing.\r\nIf we already have and automated way of creating a cluster, all the involved components, terraform workspace, terraform components (vpc and networking), and kops elements automatically , why turn that into manual steps that require us to handle them?\r\n", "ok", "yes good catch i missed that.", "yes, agree", "This was the way we did it for sandbox and nonprod clusters that already exist. Bastions are created by kops.\r\nWhen you say to create those in terraform, im assuming using kops to generate the terraform template for the bastions and then executing that template?", "sounds good", "The tickets are correct as far as I can see, and they don't describe handling Terraform as part of cluster creation:\r\n\r\n- Use terraform to provision the VPC and other infrastructure needed.\r\n- Turn this into an automated job to kick off the terraform build\r\n- Make it so that any variables required by the kops job in   CPT-483 READY FOR REVIEW  can be passed to it.\r\n\r\nTerraform handles management of all AWS resources that _aren't_ the cluster, so there's a separation between what Terraform and Kops do - therefore it makes sense to handle them as separate phases with separate processes and scripts managing them.", "this is a tricky one, and decided to hardcode it to get this working for the sprint.\r\nthe problem is that you have to run the terraform outputs for the terraform/global-resources to populate that value, and the terraform variables files is encrypted, making it not work form inside the code-build environment. \r\nWe need to think a way of exporting the key so its possible to de encrypt the repo from within the pipeline. Totally out of scope for this sprint.", "by create_cluster_config.py?", "or we can have a testing branch of this repo with the smaller instance size, and link that branch to a create-cluster-test-pipeline job that will run that against test cluster for test purposes before merging to master (prod)", "Yep, up until now we've had Kops handle creating everything, including the bastions, but the broad thrust of what we're doing here is separating out what Terraform should own and what Kops should own - so as with the VPC, the bastions aren't actually part of the cluster, so they should belong to Terraform. So I'd remove bastions from Kops entirely and do it purely in Terraform, possibly using [a module from the Terraform registry](https://registry.terraform.io/modules/kurron/bastion/aws/0.9.0), although I don't know what the quality of those modules are like.", "The hosted zone referenced here isn't the one managed by the global terraform resources, but the one that's [created in per-cluster resources](https://github.com/ministryofjustice/kubernetes-investigations/blob/master/terraform/cloud-platform/main.tf#L30) - so the DNS zone in question is (I think) `CLUSTERNAME.k8s.integration.dsd.io` in our current clusters.", "Yep - although, as per the discussion on how we should manage per-cluster config, maybe this actually should be a static value in an individual cluster's YAML file, so I'd leave this for now", "If that is the case, we can remove that from the create_cluster.sh\r\nThis PR also includes changes to the terraform templates to create the VPC and underlying networking parts, from terraform workspaces. So if you create a new terraform workspace and apply the templates it will create the vpc and other parts for the new cluster.\r\nThis will be an extra manual step if we remove it from create_cluster.sh\r\n", "ok ill take a look", "ok", "this was fixed", "this was fixed", "i changed this only for new keys\r\nin cases where the key exists , using that method will override other values inside the key making it inviable\r\nthe .update method must be used in those cases", "if we put instance type and numbers as arguments for the cluster creation script, its not going to live in code, nor in git.\r\nIf we put it in the pipeline, then we will need one pipeline per cluster creating duplication.\r\nI will suggest leaving this for now as it is.\r\nthe cluster yaml specification fill will have the size and number of instances for each cluster.\r\n", "as we determined to have a per cluster yaml file, this will be static for now.", "Yep, agreed - we can pull it out later, or pull the `InstanceGroup` specs into separate YML files later if it proves to be a problem.", "this was fixed", "this was fixed in https://github.com/ministryofjustice/kubernetes-investigations/pull/22/commits/e81efc201cd5f71f549fffb864a4505d7445b7ab", "What's the context in which `00-cluster_pipeline.sh` is intended to be executed? I don't think we ever want to execute a single command and create both Terraform and Kops resources all in one go, as they're distinctly different things, and will quite likely have significantly different lifecycles - thoughts @kalbir ?", "Kerin, 00-cluster_pipeline.sh is just a way of executing the different stepts automatically in a pipeline for 1 cluster.\r\nyou can manually execute 01. 02. 03. 04 and accomplish the same\r\n\r\n99-multiple_clusters.py is the first script executed by the pipeline, this script determines what clusters need to be created, and then triggers 00-cluster_pipeline.sh for each cluster, witch internally executes the steps for each cluster, \r\n01-terraform_resources.sh\r\n02-rsa_key.sh\r\n03-cluster_config.py\r\n04-kops_elements.sh\r\n", "OK - but that means that the Terraform phase and cluster phase are still bound together, and any change will trigger both `terraform apply` and `kops create`. We don't want that, as they have separate lifecycles - we're likely to have frequent changes to Terraform resources that don't impact the cluster at all, so they shouldn't trigger anything with Kops.\r\n\r\nSimilarly, the Kops `03-cluster_config.py` script is still interacting with Terraform directly, which binds the two together. Kops does not need to know anything about Terraform, so it would be cleaner to pass information obtained from Terraform into this script as command line arguments, as per [previous feedback](03-cluster_config.py) - this would make the script more flexible, as it wouldn't depend on any extra tooling or particular execution context."]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/10", "comments": [" --yes"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/9", "comments": ["mixing `-` and `_` in a variable name is a bit weird - can you change it to `non_prod` or `nonprod`?", "no probs - now changed."]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/8", "comments": ["What does this actually do? At the moment all PRs result in a failed Travis build because there's no Rakefile. Should there be a Rakefile? What would be in it?"]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/7", "comments": ["."]}, {"url": "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/3", "comments": ["Do we care if this specific cert goes away? Is this the cert that's created in c949106? If so, can this get the ARN automatically somehow (assuming that's not super overkill\u2026)?", "Yes we care - without the SSL cert we can't do SSL.\r\n\r\nYes it's the cert created in this PR.\r\n\r\nNo we can't create it automatically - neither Kubernetes nor nginx-ingress have any mechanism for ACM provisioning or attachment other than passing the full ARN of a pre-existing ELB."]}]}, {"url": "https://github.com/ministryofjustice/cloud-platform-terraform-elasticache-cluster.git", "pull_requests": [{"url": "https://github.com/ministryofjustice/cloud-platform-terraform-elasticache-cluster/pull/4", "comments": ["Here it says the defaul is 2, however, the actual value is 3.\r\nDo we even need to setup more than one node by default, given this will be typically used as a cache?", "I think we should instead set this automatically to something based on the provided tags.", "What is this ID (is it `cp-<random>`)? Does the user need to know this?", "I think this is used not anywhere?", "We shouldn't set the region in the module - this prevents it from being used in any other region.", "Can you please `fmt` this block?\r\n", "This should point to `?ref=2.0` (which will be the version that we'll cut after this is merged).\r\n\r\nAlso, this block needs to be formatted.", "For `cluster_name` and `cluster_state_bucket` we should avoid providing the actual values here as they will be provided automatically by the pipeline. We don't want these to be supplied by the user.\r\n\r\nHowever, I'm not entirely sure how to best present this here. Perhaps we can keep the comment from [here](https://github.com/ministryofjustice/cloud-platform-terraform-elasticache-cluster/blob/master/example/main.tf#L8-L14) but pass something like `cluster_name = ${var.cluster_name}` (and define the variables above) to demonstrate how it'll be used inside cloud-platform-environments? What do you think?\r\n\r\n(and the same could apply to the main README I suppose, for consistency)", "Is now", "Default back to 2 and slice on AZs implemented."]}, {"url": "https://github.com/ministryofjustice/cloud-platform-terraform-elasticache-cluster/pull/1", "comments": ["Can we bump this up please to maybe 8 bytes? Feels too short :)", "These are the public subnets for the VPC, can you change them to the private ones please?", "4 bytes of hex is 8 characters long. Still want more?", "Yes please! The `id` can be up to 20 characters so it fits - more randomess, less collisions.", "Is there a reason why we don't export the entire dict here?\r\nFor multi-node clusters we're losing information this way (nodes 2...n) and I think constructing an endpoint presumes that client libraries consume this in a certain way. Should we not leave this up to the user to consume as the see fit?", "As mentioned before, the subnets here are wrong - we should be using the private subnets of the cluster. Can you please adjust here and across examples & docs?", "dict won't work as a k8s secret, it expects a string; also the client library gets the address of the other nodes once connected via API", "Yes it won't, however, the act of consuming the outputs of the module (whether it means serialising into an endpoint using `join()`, exporting the whole dict with `jsonencode()`, exporting multiple attributes in the `Secret` or otherwise) can be done as part of the `kubernetes_secret` resource (shown in the example). It should be left to the user to decide how to consume the outputs of the module."]}]}, {"url": "https://github.com/dotancohen81/Rancher.git", "pull_requests": []}, {"url": "https://github.com/openregister/deployment.git", "pull_requests": [{"url": "https://github.com/openregister/deployment/pull/575", "comments": ["how is the token for the Slack webhook managed? For example, what would I need to do to update the token?", "And is the token only used for this integration?"]}, {"url": "https://github.com/openregister/deployment/pull/574", "comments": ["this isn't the case currently. I don't think we should say this in the README until it reflects the current reality. ", "should be _to appear_", "Once this PR is merged it will be true (see linked PR)", "it is not only the ansible task as you also need to re-deploy the application. Better to link to: https://github.com/openregister/deployment/blob/master/docs/extra-steps-beta.md#4-run-ansible-task steps 4 and 5.", "I would put at least `pass` in backticks so as not to confuse the language meaning and the application name. Also should be ORJ in capitals or write out the whole repo name, to reduce potential confusion.", "should we specify Python 3.7?", "Pipenv locks the version to 3.7 already (one of the reasons for using Pipenv)."]}, {"url": "https://github.com/openregister/deployment/pull/547", "comments": ["Can we add -u and -o pipefail to this? http://blog.kablamo.org/2015/11/08/bash-tricks-eux/", "Does this override any env variable you might have in your environment? If so, should we respect the environment?", "fixed in 2ccaa815b41e24935c7f35d60f8f9f9db7c18c77"]}, {"url": "https://github.com/openregister/deployment/pull/545", "comments": ["this does not work between phases as the `phase` field varies in the field definition.", "I struggled to understand this title because the readme is so long and I missed that it was under another top level header. It wasn't clear that it was a step in a process rather than some standalone piece of information. If things need to be done in a certain order then I think we should number these headings.", "Can you link to an example pull request instead of describing it in text?", "I don't think this is a good title for a top level thing. It assumes I already know all about the S3 config and when I might need to update it, but as someone new to registers I have no idea about that, even though I'm assuming it's something I'd need to do to accomplish something else. So I would be unlikely to actually read this section", "Again I got confused about the structure of the document while reading this as I thought it was a task rather than a step in a task", "unfortunately there is no PR that has done this correctly yet since the process changed. I can add this after we have done the process successfully once!", "OK I have changed this to a numbered list now."]}, {"url": "https://github.com/openregister/deployment/pull/535", "comments": ["This is a new option, I set it to false for now, to prevent any accidental breaking of the route 53 records."]}, {"url": "https://github.com/openregister/deployment/pull/534", "comments": ["I think runtime should be `6.10` to match what we currently have deployed.", "if we declare this variable further up, we can re-use it in `hittype`", "Can we add these with examples to the README for consistency?", "can we trim this to the maximum permitted characters?", "I trimmed this in the lambda where it's passed to GA, so we still log out the full  thing."]}, {"url": "https://github.com/openregister/deployment/pull/533", "comments": ["We should use an environment variable for the target bucket name.", "this line can be deleted as this lambda is not in the repo anymore.", "can we terraform this role, or use a terraformed existing role rather than `data`? I know we use this in some places but we should only use it as a workaround where a terraform defined role is not possible.", "I think there's no reason not to, but the existing lambdas are all using the \"lambda\" role. It would be good to chat about how best to do this and maybe pair on it later this week?", "I don't think `region` is required as this is the default value.", "I guess we could terraform this bucket, as I guess currently this is a manual step in this process to reproduce this? Not a blocker though.", "The reason I didn't do this was because the source bucket isn't terraformed and we decided not to terraform that. Since the source bucket would also have to be created manually if we set everything up from scratch, I drew the line between s3 and lambda so only everything in lambda is terraformed.\r\n\r\nI'd also prefer for both buckets to be managed the same way as the settings should be consistent across both them.", "Omitting this gives me the error:\r\n\r\n```\r\n* module root: module log-anonymiser: required variable \"region\" not set\r\nmake: *** [plan] Error 1\r\n```"]}, {"url": "https://github.com/openregister/deployment/pull/529", "comments": ["If you want, this script could also perform the re-index after updating e.g.\r\n```\r\ncf run-task registers \"bundle exec rake registers_frontend:populate_db:force_full_register_download[$register]\" -m 1G --name force_full_reindex\r\n```\r\nwe would need to make sure you were logged in and in the correct space though.\r\n", "I think I'll leave this bit out for now, because it depends on our local environments being set up in a particular way, and I'd rather run this part one-by-one anyway.\r\n\r\nThis time round I messed up the frontend by running this, so I think it makes sense to test populating the registers locally before doing it in production.", "Did you mean `register-name` rather than `friendly-name`?", "I am a bit confused by this last comment, what are the *binary strings*? Did you mean UTF-8?", "can we make this `GITHUB_OAUTH_TOKEN` to be more specific?", "can we specify `python3`? As the script did not work for me using `python`.", "can we specify `python3`?", "can we specify `python3` here? I think the script would be better called `update_name_and_description.py` as title is not how we refer to it in RSF, so better to keep things consistent.", "oops, yes I did", "I guess I meant bytestrings here. Python has two string types: unicode and bytes.", "Yep", "Yep. The prerequisites mentions python3 but I'll update this to be consistent with the other examples"]}, {"url": "https://github.com/openregister/deployment/pull/528", "comments": ["I think here we should change the target of this step, as it no longer produces the zip.", "this whole line isn't needed", "I think this build step is still needed to copy a subset of the files to another folder?"]}, {"url": "https://github.com/openregister/deployment/pull/525", "comments": ["What's the reason for using node 6.10 intead of 8.10?", "There is none, it was just because I used existing boilerplate. Have bumped version now!", "Would it be better to use a link to either `master` or a specific version instead of `develop`?", "this should be aws/lambda/node.", "this documentation makes it seem like you have to mess around with paths, but if you pip install it into a virtualenv it just works. So we could just add it to our requirements.txt in scripts and say to use that instead of linking to this guide.", "I think you could also write this without another promise by using await on the inner promise.\r\n\r\nSomething like this\r\n\r\n```javascript\r\nif (isBeta) {\r\n   try {\r\n     const data = await cloudfront.listDistributions({MaxItems: '1000'}).promise()\r\n     // set getDistributionId from data\r\n   } catch err {\r\n   }\r\n} else {\r\n  getDistributionId = distributionId;\r\n}\r\n```\r\n\r\nnot 100% sure about this though, as I'm new to this syntax"]}, {"url": "https://github.com/openregister/deployment/pull/520", "comments": ["where does this database live? Is it something we need to delete?", "We should make a follow-up task to delete these credentials from `registers-pass`", "The database lives inside influxcloud so it should just be a case of cancelling our description", "will do!"]}, {"url": "https://github.com/openregister/deployment/pull/519", "comments": ["It might be better to add this to the `/scripts/readme.md`? This section is kind of duplicated from there and think I might delete it in favour of linking to the specific read me.", "This works as long as we don't come across any other items with the same description in it. This is rare but sometimes we do have occasions where a register and an individual field will have the same description. This means that we risk picking up a `field:x` item here and accidentally combining it with a `register:x`entry.\r\n\r\nCould you update the logic to scan for the correct item based on knowledge of its hash? So scan for the entry with key `register:x`, get the item-hash, then scan the items for the item with the corresponding hash. The item always occurs before the entry, which means either scanning the RSF file twice, or storing items and their item-hashes as you scan them. Not quite ideal for a little script but better than the risk of creating some dud RSF?", "Although using this approach you would have to make sure you pick up the latest entry with key `register:x` as it's possible for there to be multiple versions of it.", "Ok, I'll have a go at this. It's probably safer to just parse all the item JSONs and look up the description key that way.", "I had a go at implementing this yesterday afternoon. It's more complicated than the previous version but it's stricter. Is this what you had in mind? (see new commit)", "can we just revert this file if it is whitespace only.", "There is nothing specific to beta in the script. We can change this to:\r\n>  this *example* assumes."]}, {"url": "https://github.com/openregister/deployment/pull/517", "comments": ["Am I being silly, I don't see where this file and the `custom-field-descriptions-meta.rsf` file are used?", "I forgot to remove them :man_facepalming: "]}, {"url": "https://github.com/openregister/deployment/pull/516", "comments": ["The use of underscored methods should be avoided as much as possible. A common way to check the same would be:\r\n\r\n```python\r\nif k in other:\r\n  dct[k] ...\r\n```", "On second thought, perhaps the two expressions that generate `custom_fields_by_name` could be extracted as a function so the logic is isolated (and can be tested as well), something on the lines of:\r\n\r\n```python\r\ndef custom_fields(phase, register_name, register_data_root, field_names):\r\n    fields = {}\r\n    for name in field_names:\r\n        field = read_custom_field_from_local(phase, register_name, name, register_data_root)\r\n        if field is not None:\r\n            fields[name] = field\r\n\r\n    return fields\r\n\r\ndef generate_rsf(args):\r\n  ...\r\n  custom_fields_by_name = custom_fields(args.phase, args.register_name,  args.register_data_root, field_names)\r\n```"]}, {"url": "https://github.com/openregister/deployment/pull/513", "comments": ["I would rather call it `register-name` as this is what it is called in the RSF, rather than `title`."]}, {"url": "https://github.com/openregister/deployment/pull/508", "comments": ["If I'm not mistaken, you can remove the parenthesis wrapping `user` and avoid the third group capture by using `[]`:\r\n\r\n```\r\nFile.write(ARGV[0], rsf.gsub!(/\\tuser\\t([\\w-]+)/m, \"\\tsystem\\tfield:\" + '\\1'))\r\n```"]}, {"url": "https://github.com/openregister/deployment/pull/503", "comments": ["this file is kinda strange. Does it still work if we make this an empty file?", "Yes it does - it's empty now \ud83d\udc4d "]}, {"url": "https://github.com/openregister/deployment/pull/500", "comments": ["Do we need to document a dependency also here on Python 3?"]}, {"url": "https://github.com/openregister/deployment/pull/498", "comments": ["Am not _sure_ this actually does anything? As per:\r\n> When the callback is called, the Lambda function exits only after the Node.js event loop is empty (the Node.js event loop is not the same as the event that was passed as a parameter). \r\n\r\nhttps://docs.aws.amazon.com/lambda/latest/dg/nodejs-prog-model-handler.html", "I can confirm that we definitely need to call the callback. It's necessary at the beginning of the function here before we do any returns to ensure it happens. If you don't have the callback, you get a 502 response, as shown below:\r\n\r\n![screen shot 2018-03-14 at 11 19 35](https://user-images.githubusercontent.com/5422487/37399571-e8ca3974-2779-11e8-8ceb-6b6006785964.png)\r\n\r\nThis makes sense, because we're intercepting the request as a _Viewer request_, meaning that it hasn't been passed to CloudFront yet. If we don't return the request, CloudFront will receive `null` and this is where the error occurs. It's probably also helpful to reference the following Lambda@Edge diagram here:\r\n\r\n![](https://docs.aws.amazon.com/lambda/latest/dg/images/cloudfront-events-that-trigger-lambda-functions.png)"]}, {"url": "https://github.com/openregister/deployment/pull/487", "comments": ["Should we include the `[metadata|user|all]` option for this script too?", "I'm wondering whether it's worth calling this `system` instead of metadata, just to be consistent with the entry type?", "Sure.", "We could do. I didn't because the script at the moment is intended for reloading registers, which means that you'll always need the system entries first. That being said, the `load-register-tsv.sh` script also deletes all register data before loading.\r\n\r\nMy intention with this script is to make it simpler to generate the metadata for a register separately from the actual data. It may be that we need some more control when invoking these scripts to determine, say, whether or not to go ahead and delete data from a register before they become more useful.", "Yes it looks like `load-register-tsv.sh` and `reload-metadata-yaml.sh` both do the same thing but for different registers. They both ask (yes/no) whether you would like to delete data from the register first, so we do already have control over whether they delete the data. Or did you mean something else?\r\n\r\nI think it would be good to make both scripts allow a user to specify `[metadata|user|all]` and maybe rename `reload-metadata-yaml.sh` to `load-metadata-yaml.sh` so that it's more obvious that they do similar things.\r\n\r\nAlso, the changes to `load-register-tsv.sh' now make the `update-register-tsv.sh` script redundant so can we remove it?"]}, {"url": "https://github.com/openregister/deployment/pull/481", "comments": ["might be easier to do this with the AWS CLI instead? https://docs.aws.amazon.com/cli/latest/reference/s3/index.html we can then wrap these in shell scripts like `download_config.sh` or something?", "You also need to mention that the key of this section needs to be changed from `fire-authority` to `meat-cuts`", "This bit isn't quite true. It will fail if the that route exists anywhere else in the whole of PaaS. i.e. it will fail if https://meat-cuts.cloudapps.digital has been claimed by any other user of PaaS. So you won't actually be able to see it from `cf routes` as this only shows routes for the current space/organisation.\r\n\r\nWe are hoping that this is unlikely to happen, but if it does speak to a developer and they can help by giving it a different domain via AWS."]}, {"url": "https://github.com/openregister/deployment/pull/462", "comments": ["Should we mention that this needs to be the latest certificate? (There may be two of them if the delete in the previous step failed).", "I *think* you may be confusing the IAM ID (which will change) with the ACM ARN which should not change (you are just changing the certificate associated with it). I have added a note to check the upload date for IAM though.", "Ah ok, yes I was confusing it. Thanks!"]}, {"url": "https://github.com/openregister/deployment/pull/437", "comments": ["Note, I believe this is just the VPC endpoint to access the buckets not the buckets themselves. See https://aws.amazon.com/blogs/aws/new-vpc-endpoint-for-amazon-s3/"]}, {"url": "https://github.com/openregister/deployment/pull/431", "comments": ["You can't remove these modules because some of these registers exist in other environments (beta) and these modules are still required when applying to those environments.\r\n\r\nThe only one you can remove is `school-type_register` module because this no longer exists in any environment (it was renamed to school-type-eng)."]}, {"url": "https://github.com/openregister/deployment/pull/417", "comments": ["We should still keep this configuration option.", "@karlbaker02 I thought we only had this enabled because the register was large? Is there another reason?", "I thought there was some legal issue around address data? I may be mistaken, in which case we could remove it.", "@karlbaker02 that's possibly true, however, the register only contains 833 records and you could pull all that in one request from the `/records` endpoint within the `page-size` limit anyway.", "This was only there because the data was large and a download made the app fall over. This won't happen for the small address register in discovery."]}, {"url": "https://github.com/openregister/deployment/pull/412", "comments": ["This change should only be applied when not running on PaaS. There's a magical `paas` bool you can use to make the generated configs different.", "Ah yes. I had forgotten that we were still using config from S3 for PaaS! Will update."]}, {"url": "https://github.com/openregister/deployment/pull/402", "comments": ["Are these fixes testable, are they worth testing?", "Good point. We do have a test class for `rsfcreator.py`. Can we add some tests @karlbaker02 ?", "Yes, I'll do this, thanks.", "Test has now been added."]}, {"url": "https://github.com/openregister/deployment/pull/393", "comments": ["is it worth making the port number configurable too? (these do vary with stack id)", "Ahhh, I didn't realise this. I clearly made a bunch of assumptions about this being the `TCP-SSL` port. I'll extract it to some configuration."]}, {"url": "https://github.com/openregister/deployment/pull/383", "comments": ["One tiny thing - should be ./performance_platform.py ?", "yes it should be. \ud83d\udc4d "]}, {"url": "https://github.com/openregister/deployment/pull/355", "comments": ["I cant see anything about this type attribute of classic in the documentation. Whats it for?", "hmmm, I _think_ it's related to the format that logback uses but I'll double check and see what it's actually doing.", "I don't entirely understand why it's needed but without it it fails to log requests /shrug", "@endamccormack https://github.com/dropwizard/dropwizard/blob/master/docs/source/manual/configuration.rst#classic-request-log", "Awesome, thanks"]}, {"url": "https://github.com/openregister/deployment/pull/350", "comments": ["I take it all these school related things are related to moving everything into `school-eng`?", "They have remove those as fields completely from school-eng and also removing the registers. See https://github.com/openregister/registry-data/pull/80.\r\n\r\nAlso, I have not removed the school-* registers from `registers.tf` yet as it is likely that they might end up in discovery at some point.", "\ud83d\udc4d "]}, {"url": "https://github.com/openregister/deployment/pull/329", "comments": ["should be openregister.app.artifacts", "Good spot \ud83d\udd0d "]}, {"url": "https://github.com/openregister/deployment/pull/326", "comments": ["This attribute seems to have an `off` syntax, can we do off instead of 0 to make it more clear?\r\n\r\nhttps://gpdb.docs.pivotal.io/4370/guc_config-log_hostname.html\r\nhttps://www.drupal.org/docs/7/guidelines-for-sql/logging-slow-sql-queries-server-side-in-postgresql", "Possibly. It's represented in the AWS console as `0` and `1` but I'll see if it deals with other values."]}, {"url": "https://github.com/openregister/deployment/pull/310", "comments": ["Will this know to regenerate the target if the password changes but there template doesn't?", "nope"]}, {"url": "https://github.com/openregister/deployment/pull/306", "comments": ["`services/influxcloud/admin` looks like a copypaste error?", "I think this is right\u2014it's getting the `tail -n1` from the file (which happens to the be the cluster address). The other usage of that credential gets `head -n1`.", "gosh i think you're right"]}, {"url": "https://github.com/openregister/deployment/pull/294", "comments": ["not [sha256](https://www.terraform.io/docs/configuration/interpolation.html#sha256_string_)?", "We chatted about this IRL:\r\n\r\n > The entity tag is a hash of the object. The ETag reflects changes only to the contents of an object, not its metadata. The ETag may or may not be an MD5 digest of the object data. Whether or not it is depends on how the object was created and how it is encrypted as described below:\r\n> -    Objects created by the PUT Object, POST Object, or Copy operation, or through the AWS Management Console, and are encrypted by SSE-S3 or plaintext, have ETags that are an MD5 digest of their object data.\r\n> -    Objects created by the PUT Object, POST Object, or Copy operation, or through the AWS Management Console, and are encrypted by SSE-C or SSE-KMS, have ETags that are not an MD5 digest of their object data.\r\n> -    If an object is created by either the Multipart Upload or Part Copy operation, the ETag is not an MD5 digest, regardless of the method of encryption.\r\n\r\nhttps://docs.aws.amazon.com/AmazonS3/latest/API/RESTCommonResponseHeaders.html"]}, {"url": "https://github.com/openregister/deployment/pull/280", "comments": ["Looks like it doesn't work with HTTPS:\r\n\r\n```\r\n$ curl https://registers.cloudapps.digital/registers/local-authority-eng -vo/dev/null\r\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n                                 Dload  Upload   Total   Spent    Left  Speed\r\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0*   Trying 54.171.81.236...\r\n* Connected to registers.cloudapps.digital (54.171.81.236) port 443 (#0)\r\n* TLS 1.2 connection using TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256\r\n* Server certificate: *.cloudapps.digital\r\n* Server certificate: DigiCert SHA2 Secure Server CA\r\n* Server certificate: DigiCert Global Root CA\r\n> GET /registers/local-authority-eng HTTP/1.1\r\n> Host: registers.cloudapps.digital\r\n> User-Agent: curl/7.43.0\r\n> Accept: */*\r\n>\r\n< HTTP/1.1 404 Not Found\r\n< Content-Type: text/plain; charset=utf-8\r\n< X-Cf-Routererror: unknown_route\r\n< X-Content-Type-Options: nosniff\r\n< X-Vcap-Request-Id: 431083e0-817f-4cb5-4883-07c55fec6567\r\n< Date: Tue, 14 Feb 2017 14:37:10 GMT\r\n< Content-Length: 79\r\n< Strict-Transport-Security: max-age=31536000; includeSubDomains; preload\r\n<\r\n{ [79 bytes data]\r\n100    79  100    79    0     0     95      0 --:--:-- --:--:-- --:--:--    95\r\n* Connection #0 to host registers.cloudapps.digital left intact\r\n```", "![screen shot 2017-02-14 at 14 40 06](https://cloud.githubusercontent.com/assets/3071606/22933412/7e8bbfa6-f2c3-11e6-8aeb-72babfa4c6f2.png)\r\n\r\n", "okay looks good now.\r\n\r\n/shrug"]}, {"url": "https://github.com/openregister/deployment/pull/279", "comments": ["How would you feel about using this?: https://www.terraform.io/docs/providers/aws/d/ami.html", "Looks like `chrisduraj` could be removed from `users.yaml`?", "Are we planning on doing the `unattended-upgrades` stuff in a different PR?", "done in @2dbf9be", "done in @2011103", "that looks interesting, maybe a separate pr though?", "\ud83d\udc4d "]}, {"url": "https://github.com/openregister/deployment/pull/269", "comments": ["Are we okay with naming not being consistent between the register and the history page?", "I think this should be `school-eng` rather `school-england`?", "Good spot.", "Fixed", "nice m8, nice"]}, {"url": "https://github.com/openregister/deployment/pull/268", "comments": ["while we're here, do we want to change the email address to something we own? This might make it easier for TLS cert providers to verify certs, for example", "we chatted about this IRL and decided it's probably okay as it is for the time being."]}, {"url": "https://github.com/openregister/deployment/pull/257", "comments": ["Is it possible to add `set -e`?", "If the `credentials` repo is getting cloned into `..` then surely the `PASSWORD_STORE_DIR` should be `\"../credentials\"`?\r\n\r\nEither way I think the convention in the team is to just clone at `~/.registers-pass`", "Does it make sense to assign `$1` and `$2` to variables with nice names?", "Is this `sed` happening because `serializer` is generating bad RSF?", "Do we need to worry about ever having a register of \"cacti\"? \ud83d\ude1c ", "We also might want to do a `pull` too?", "was this meant to be the `git fetch && git merge`? I'm not sure why you'd do a `pull` after a `fetch`?", "can do", "Ok, I'll set REGISTER and PHASE vars.", "At some point the script could be extended to halt if user has uncommitted changes.\r\n\r\nFor now I think I'll change this to: `git pull --rebase`", "Ok, I'll change ../credentials to ~/.registers-pass then.", "Plan is to change to a convention of using the single register name for these tsv files. Once done we can remove these plural checks.", "That's right the serializer was generating bad RSF. I've been told this has been fixed, so I'll remove the sed."]}, {"url": "https://github.com/openregister/deployment/pull/250", "comments": ["\ud83d\udc4d nice"]}, {"url": "https://github.com/openregister/deployment/pull/249", "comments": ["can we remove the `enable_availability_checks` and `registers` variables from variables.tf here, too?"]}, {"url": "https://github.com/openregister/deployment/pull/247", "comments": ["wait, why are you doing this? `address` only needs to be separate in `test`, right?", "why did you remove the `description`s?", "ah I see you explained in bc8313b9aaf57ae3bf97f9c0dcbd4fd71488d775", "what's this?", "this will need an update to the README (probably after #246 is merged) to document an extra step for creating a register", "you're right--this needs to go.", "Yup, I was just about to add a comment on your PR about this \ud83d\ude09 ", "Actually this is still needed so we don't cause any downtime when we deploy these changes. This can be removed later as part of cleanup.\r\n\r\nThis PR creates a temporary hosted zone which contains the records deployed in the new way. I'll swap over the `NS` records on `openregister.org` manually to this new Hosted Zone before doing some cleanup, applying these DNS changes to the Hosted Zone that's created by the `core` Terraform module, and swapping the `NS` records back."]}, {"url": "https://github.com/openregister/deployment/pull/237", "comments": ["even though this is just delaying the inevitable do we want to just make this the largest value for `page-size`?"]}, {"url": "https://github.com/openregister/deployment/pull/228", "comments": ["This still gets referenced here: https://github.com/openregister/deployment#terraform-config-for-a-register"]}, {"url": "https://github.com/openregister/deployment/pull/200", "comments": ["Typo? `desciption` should be `description`?"]}, {"url": "https://github.com/openregister/deployment/pull/198", "comments": ["we should talk about `Vary` headers at some point", "I don't completely understand what happens if `enable_cdn` is true, but `cloudfront_certificate_arn` is unset"]}, {"url": "https://github.com/openregister/deployment/pull/195", "comments": ["why does this function take two parameters? It looks to me like it only ever gets called with zero or one arguments.", "ditto", "looks like these tests do it right \ud83d\ude04 ", "`function(error) { callback(error); }` is bascially the same as `callback`", "incidentally, this refactoring is known as [eta conversion](https://en.wiktionary.org/wiki/eta_conversion)", "You can use that parameter ([docs](https://docs.aws.amazon.com/lambda/latest/dg/nodejs-prog-model-handler.html#nodejs-prog-model-handler-callback)), but we don't so it's probably sensible to remove it.", "\ud83d\udc4d "]}, {"url": "https://github.com/openregister/deployment/pull/179", "comments": ["Is there a reason for having the extra dash? Is it because you rebuilt the world whilst always having a load balancer running?"]}, {"url": "https://github.com/openregister/deployment/pull/178", "comments": ["did you consider putting this in the `build/` directory too?", "could just hardcode this?", "I tried running this but I don't have `npm` installed. Can we somehow document or check for a particular (minimum or exact) npm version?", "typo", "I installed it with Homebrew which means we're likely to run into the awkward dependency problems we have. It might be worth considering using Docker for these dependencies ([library/node](https://hub.docker.com/_/node/), for example). For the time being I'll do something similar to what we do for pinning Terraform versions.", "Sounds legit. \ud83d\udc4d ", "@philandstuff the `build/` directory contains a deployable build of the Lambda function (in this case a `.zip` file containing the Lambda handler and its dependencies). The dependent modules installed by `npm` are installed next to the implementation under `lambda/<name>`. The magical `sed` transformation required to add the Sumo Logic secrets also gets output here.\r\n\r\nI think I'm aiming for a situation where the `build/` directory contains nothing but the `.zip` files for Lambda functions and the intermediary build files exist elsewhere; in this case the \"elsewhere\" is next to the implementation which maybe feels a bit clumsy. \r\n\r\nI'll probably leave it for the time being because it doesn't seem that bad at the moment. Does this seem reasonable?"]}, {"url": "https://github.com/openregister/deployment/pull/167", "comments": ["What happens if the `registers` variable is a list? I believe this may have been broken in the previous commit as well.\n\nThe deployment README suggests that a list of register names can be passed. We should either fix this or change the variable name to `register` and update the README.\n", "good point, will fix\n", "@michaelabenyohai updated\n", "hmm, it turns out I didn't need this after all. Might leave it in though, seems useful? \ud83e\udd14 \n", "\ud83d\udc4d \n"]}, {"url": "https://github.com/openregister/deployment/pull/163", "comments": ["do we still need this task?\n", "why specify our own template? Isn't the default good enough?\n"]}, {"url": "https://github.com/openregister/deployment/pull/151", "comments": ["info about approval :)\n", "Done!\n"]}, {"url": "https://github.com/openregister/deployment/pull/139", "comments": ["oh cool, I didn't know about this. nice to reuse it\n"]}, {"url": "https://github.com/openregister/deployment/pull/129", "comments": ["@philandstuff please can we talk about whether these defaults are sensible for new openregister app.\n", "yeah, we should make all subnets a `/24` at least to avoid issues of running out of IPs like we did with the public cidr blocks before.\n"]}, {"url": "https://github.com/openregister/deployment/pull/108", "comments": ["hmm, do we need to talk about fixing this? Previously we used `indexer` as it had two nice properties:\n- it had access to both RDS instances\n- it was guaranteed to exist in each environment\n\nI'm happy to merge this PR as is to get it in master, but a brief discussion about how we iron out this wrinkle might be good.\n", "we should delete mint and indexer from this template\n", "ditto^H^H^H^H^H wait we should leave this til all mints and presentations are destroyed\n"]}, {"url": "https://github.com/openregister/deployment/pull/107", "comments": ["This needs to be changed to fit the new (openregister) style. Me or @michaelabenyohai can help you with this.\n"]}, {"url": "https://github.com/openregister/deployment/pull/106", "comments": ["this should just be `config.yaml`\n", "this needs more thought\n", "it should only add permission to an existing user:\nhttp://docs.ansible.com/ansible/postgresql_user_module.html#synopsis\n\nthe order of creating users is WRITE, READ so the second call (privilege `SELECT`) shouldn't do anything as WRITE has `ALL`\n", "this isn't a complete, valid config file for openregister-java. In particular, it's missing the `register:` field.\n"]}, {"url": "https://github.com/openregister/deployment/pull/102", "comments": ["typo\n"]}, {"url": "https://github.com/openregister/deployment/pull/101", "comments": ["worth commenting why this substitution is made?\n"]}, {"url": "https://github.com/openregister/deployment/pull/91", "comments": ["do we need to set this variable somewhere?\n", "`instance_count` for every environment is specified in `<environment>.tfvars` file, in this case `alpha.tfvars`.\n"]}, {"url": "https://github.com/openregister/deployment/pull/72", "comments": ["does this file need to be documented in the README? perhaps section around \"Preparing new environment\"?\n"]}, {"url": "https://github.com/openregister/deployment/pull/69", "comments": ["Probably also want the AvH fallback IPs - \"85.133.67.244/32\".\n"]}, {"url": "https://github.com/openregister/deployment/pull/63", "comments": ["Probably needs @michaelabroschomb's key added.\n"]}, {"url": "https://github.com/openregister/deployment/pull/62", "comments": ["Commented out?\n"]}, {"url": "https://github.com/openregister/deployment/pull/55", "comments": ["this is my old key.\n", "missing me and slawek?\n", "looking further: what's the relationship between this file and etcd.yml.template, and why do they both have `users` fields?\n", "old key again\n", "@philandstuff: etcd.yml is generated from etcd.yml.template via the generate_etcd_cluster_token.sh script.\n"]}, {"url": "https://github.com/openregister/deployment/pull/48", "comments": ["can we remove `-example` from the instance name to make it consistent with other resources?\n", "Have removed it and renamed to match other resource identifiers.\n"]}, {"url": "https://github.com/openregister/deployment/pull/45", "comments": ["should probably be `/bin/bash` -- I suspect you'll have used some bash-specific features\n", "why two separate variables?\n", "will this download the whole bucket? we should probably just copy what we need up rather than leaving unencrypted passwords on local machine\n", "see also `aws s3 cp --recursive`\n", "s3 sync doesn't download the whole bucket. it copies new and updated files from source to destination.\n"]}, {"url": "https://github.com/openregister/deployment/pull/43", "comments": ["don't need this\n", "not sure I like using `pushd` and `popd` in different scopes -- also have you considered using `cd` inside a subshell? eg:\n\n```\n(cd $dir\n   foo\n   bar\n   baz\n)\n# back in original dir here\n```\n", "shouldn't this be `pushd $PASSWORD_STORE_DIR`?\n", "is it worth explicitly creating a branch from `master` here, rather than whatever branch you happened to be on previously?\n", "duplicated from top of file?\n", "this won't work because this bash file isn't in the password store dir, it's in the `deployment` dir...\n"]}, {"url": "https://github.com/openregister/deployment/pull/37", "comments": ["if condition must check equality for 3 parameters now.\n", "good point\n"]}, {"url": "https://github.com/openregister/deployment/pull/28", "comments": ["or even `base64 < \"${USER_DATA_FILE}\"` :golf: :smile: \n"]}, {"url": "https://github.com/openregister/deployment/pull/26", "comments": ["fyi we can remove the PGPASSWD stuff when #25 is merged\n"]}, {"url": "https://github.com/openregister/deployment/pull/25", "comments": ["does this also need presentation db sg?\n", "typo\n"]}, {"url": "https://github.com/openregister/deployment/pull/24", "comments": ["can we fetch ARN by the role name instead of hardcoding it?\n", "it is good to have a separate script to create instance profile, we can call the script here to create profile.\n", "discussed IRL. the ARN is entirely based on the role name so this isn't a big deal.\n", "yup, will do\n"]}, {"url": "https://github.com/openregister/deployment/pull/18", "comments": [":+1: \n"]}, {"url": "https://github.com/openregister/deployment/pull/8", "comments": ["why is this commented out?\n", "the actual filename uses kebab-case, not snake_case\n", "we should probably review if this is too lax before finishing the story\n", "do we need the non-`eu-west-1` values here?\n", "in future it might be nice to have a default value here\n", "did you check that it works without these lines?\n", "CodeDeploy does it.\n", "Not sure - since our instances, s3 buckets, etc are in this region, I assumed that it was required.\n", "yes, they're in `eu-west-1`.  They're not in `us-east-1` or `us-west-2`, so I'm not sure why these lines are required.\n", "I think the install script for codedeployagent is kept not in the eu zone\nand it needs to be downloaded ... not sure - need to check.\n\nOn 5 August 2015 at 10:18, Philip Potter notifications@github.com wrote:\n\n> In codedeploy_role_document.json\n> https://github.com/openregister/deployment/pull/8#discussion_r36283019:\n> \n> > @@ -0,0 +1,17 @@\n> > +{\n> > -  \"Version\": \"2012-10-17\",\n> > -  \"Statement\": [{\n> > -    \"Sid\": \"\",\n> > -    \"Effect\": \"Allow\",\n> > -    \"Principal\": {\n> > -      \"Service\": [\n> > -        \"codedeploy.us-east-1.amazonaws.com\",\n> > -        \"codedeploy.eu-west-1.amazonaws.com\",\n> > -        \"codedeploy.us-west-2.amazonaws.com\",\n> \n> yes, they're in eu-west-1. They're not in us-east-1 or us-west-2, so I'm\n> not sure why these lines are required.\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/openregister/deployment/pull/8/files#r36283019.\n\n## \n\nThanks,\n\n/Saqib\n", "can use --query option to retrieve the required value from response \n", "Correct - updated to do so.\n\nOn 5 August 2015 at 17:18, Om Sharma notifications@github.com wrote:\n\n> In create-instance-profile.sh\n> https://github.com/openregister/deployment/pull/8#discussion_r36321236:\n> \n> > @@ -0,0 +1,23 @@\n> > +#!/bin/bash\n> > +\n> > +NAME=${1}\n> > +\n> > +# ReCreate a policy for codedeploy\n> > +PDP=\"file://$(pwd)/codedeploy_policy_document.json\"\n> > +RDP=\"file://$(pwd)/codedeploy_role_document.json\"\n> > +\n> > +POLICY=$(aws iam create-policy --policy-name ${NAME}_policy --policy-document ${PDP})\n> > +POLICY_ARN=$(echo $POLICY | sed -e 's/^._\\\"Arn\\\"/\\\"Arn\\\"/g' -e 's/\\\"Arn\\\": \\\"([^\\\"]_)\\\".*$/\\1/g')\n> \n> can use --query option to retrieve the required value from response\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/openregister/deployment/pull/8/files#r36321236.\n\n## \n\nThanks,\n\n/Saqib\n"]}]}, {"url": "https://github.com/cisagov/cyhy_amis.git", "pull_requests": [{"url": "https://github.com/cisagov/cyhy_amis/pull/749", "comments": ["While we are in here, we may as well alphabetize by variable name.", "Please see commit 2da8dff."]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/699", "comments": ["Alphabetize args:\r\n```suggestion\r\n    \"--ssh-common-args='-o StrictHostKeyChecking=no'\",\r\n    \"--user=${var.remote_ssh_user}\",\r\n```", "I simply copied the CyHy bastion's block and made necessary changes so if you are amenable I would like to do this in a separate PR that alphabetizes the values feeding all of the Ansible provisioner modules (both the SSH arguments and the environment variables where applicable).", "Sure, that's fine by me. \ud83d\udc4d "]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/689", "comments": ["If you know what modules you are using from `ansible.posix` you might think about adding a `version` key here [\u00e0 la cisagov/ansible-role-vnc-server](https://github.com/cisagov/ansible-role-vnc-server/blob/207d8d52588bbc59f2dabfb1e021bb00344ec80d/meta/requirements.yml#L12-L17).", "If you know what modules you are using from `ansible.posix` and `community.general` then you might think about adding a `version` key here [\u00e0 la cisagov/ansible-role-vnc-server](https://github.com/cisagov/ansible-role-vnc-server/blob/207d8d52588bbc59f2dabfb1e021bb00344ec80d/meta/requirements.yml#L12-L17)", "When I looked into this (I had the same thought) the module used was included in the 1.0 release with the options we are using. As a result I decided not to worry about adding a `version` key.", "When I looked into this (I had the same thought) the module from `ansible.posix` used was included in the 1.0 release with the options we are using. As a result I decided not to worry about adding a `version` key. It appears that the module used from `community.general` with the options we are using has been present since before it was broken out of being included with Ansible."]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/669", "comments": ["Feel free to re-word as you see fit, but I think it's important to indicate where in the `commander.conf` these values are being used, since there are multiple sections in that file (`DEFAULT`, `production`, `purge`, etc.)\r\n```suggestion\r\n# The maximum number of jobs to assign to each nessus host (vulnscanner)\r\n# in the \"production\" section of the commander configuration file\r\njobs_per_nessus_host: 16\r\n\r\n# The maximum number of jobs to assign to each nmap host (portscanner)\r\n# in the \"production\" section of the commander configuration file\r\njobs_per_nmap_host: 8\r\n```", "I confirmed that you have already added our current Production values for these settings into our Production Terraform variables file, so thank you!  \ud83d\udc4d \ud83d\udc4d ", "Please see [2efa82e](https://github.com/cisagov/cyhy_amis/pull/669/commits/2efa82e74084583452692010324ac50822ec2c42).", "Lovely!"]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/666", "comments": ["As long as we are expanding from short-form to long-form option names:\r\n```suggestion\r\n        job: cd /var/cyhy/orchestrator && docker compose down && docker compose up --detach 2>&1 | /usr/bin/logger --tag orchestrator\r\n```"]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/663", "comments": ["Generally, we just delete this comment, though I'm fine if you'd rather handle that change wholesale for all of the ansible roles in here.\r\n```suggestion\r\n```\r\n\r\nSee [here](https://github.com/search?q=org%3Acisagov+defaults%2Fmain&type=code) for examples.", "If it's no issue for you I'd rather just update all of the roles wholesale as I'm sure there are similar comments in more than just the `defaults/main.yml` files.", "That's fine by me."]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/660", "comments": ["```suggestion\r\n- name: chrony_aws\r\n  src: https://github.com/cisagov/ansible-role-chrony-aws\r\n- name: clamav\r\n  src: https://github.com/cisagov/ansible-role-clamav\r\n```\r\n\r\nYou missed this while sorting alphabetically. ", "Ah that was missed in https://github.com/cisagov/cyhy_amis/pull/410 it looks like. The only change I was paying attention to was flipping `name` and `src` so those were alphabetically in order for each item x)"]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/659", "comments": ["Deja vu...\r\n```suggestion\r\n      # v4. It is necessary to use with the backported resources in v3.75 to\r\n```", "```suggestion\r\n      # v4. It is necessary to use with the backported resources in v3.75 to\r\n```", "```suggestion\r\n      # v4. It is necessary to use with the backported resources in v3.75 to\r\n```", "```suggestion\r\n      # v4. It is necessary to use with the backported resources in v3.75 to\r\n```", "GAH. Just to note that I copied this between repos to consistently be inconsistent x.x"]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/658", "comments": ["```suggestion\r\n| bod\\_lambda\\_function\\_bucket | The name of the S3 bucket where the Lambda function zip files reside.  Terraform cannot access buckets that are not in the provider's region, so the region name will be appended to the bucket name to obtain the actual bucket where the zips are stored.  So if we are working in region `us-west-1` and this variable has the value `buckethead`, then the zips will be looked for in the bucket `buckethead-us-west-1`. | `string` | n/a | yes |\r\n```", "```suggestion\r\n  description = \"The name of the S3 bucket where the Lambda function zip files reside.  Terraform cannot access buckets that are not in the provider's region, so the region name will be appended to the bucket name to obtain the actual bucket where the zips are stored.  So if we are working in region `us-west-1` and this variable has the value `buckethead`, then the zips will be looked for in the bucket `buckethead-us-west-1`.\"\r\n```"]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/649", "comments": ["Alphabetize:\r\n```suggestion\r\n      \"ec2:DeleteNetworkInterface\",\r\n      \"ec2:DescribeNetworkInterfaces\",\r\n```", "I think we can safely consolidate this to:\r\n```suggestion\r\n    actions = [\r\n      \"s3:GetObject\",\r\n      \"s3:ListBucket\",\r\n    ]\r\n\r\n    resources = [\r\n      aws_s3_bucket.moe_bucket.arn,\r\n      \"${aws_s3_bucket.moe_bucket.arn}/*\",\r\n    ]\r\n```", "Similar consolidation:\r\n```suggestion\r\n      \"s3:DeleteObject\",\r\n      \"s3:ListBucket\",\r\n      \"s3:PutObject\",\r\n    ]\r\n\r\n    resources = [\r\n      aws_s3_bucket.moe_bucket.arn,\r\n      \"${aws_s3_bucket.moe_bucket.arn}/*\",\r\n    ]\r\n```", "I'm fine either way.", "I'm fine either way.  I can't decide which way I like better; both have their pluses and minuses.", "So this was based (I think) on the [AWS example IAM policy](https://docs.aws.amazon.com/AmazonS3/latest/userguide/example-policies-s3.html#iam-policy-ex0) and given some of the [more advanced examples](https://docs.aws.amazon.com/AmazonS3/latest/userguide/example-policies-s3.html#iam-policy-ex1) I'm wary of combining these permissions and having possibly unexpected interactions. Thoughts?", "I'm fine keeping it as is.  If it ain't broke....", "See https://github.com/cisagov/cyhy_amis/pull/649#discussion_r1164469340", "Just for documentation I did test both IAM policy changes and expected functionality worked."]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/648", "comments": ["Should this Ansible role be removed from `requirements.yml`?", "Is this Ansible role able to be removed because it is pulled in automatically where needed?", "I know you didn't write this, but might as well fix it since `cyhy-dashboard` isn't really a thing:\r\n```suggestion\r\n  name: Install and configure the CyHy dashboard\r\n```", "Typo:\r\n```suggestion\r\n# Retrieve the MaxMind GeoIP2 license from the AWS SSM Parameter Store\r\n```", "That role was relocated in https://github.com/cisagov/cyhy_amis/pull/648/commits/45a643848b8c4cd3adea69034e0745ea8e4a83c4 (after being removed in https://github.com/cisagov/cyhy_amis/pull/648/commits/1aa181330f33949b0c9b6ca1084950e2c49f2df9) to mirror [where it is installed in cisagov/skeleton-packer](https://github.com/cisagov/skeleton-packer/blob/develop/src/base.yml). Apologies for that taking place across two commits which made it unclear what was happening.", "Yes. It was removed in https://github.com/cisagov/cyhy_amis/pull/648/commits/cd19a034f28fa0ff965056594982774c4b481e61 because it is a dependency of [cisagov/ansible-role-ncats-webui](https://github.com/cisagov/ansible-role-ncats-webui/blob/develop/meta/main.yml). I assume based on its absence as an explicit role that it is also an appropriate dependency anywhere else Docker is desired."]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/646", "comments": ["Keep the capitalization train rolling... \ud83d\ude82 \r\n```suggestion\r\n  # Trigger the appropriate Lambda function whenever an object with the configured\r\n```", "Should we alphabetize these?", "Should we alphabetize these?", "Should we alphabetize these?", "Should we alphabetize these?", "Should we alphabetize these?", "Should we alphabetize these?", "If you are amenable I would like to punt that off into a separate PR to reformat _all_ of the Terraform as one cohesive piece of work.", "Sure", "See [here](https://github.com/cisagov/cyhy_amis/pull/646#discussion_r1161825858).", "See [here](https://github.com/cisagov/cyhy_amis/pull/646#discussion_r1161825858).", "See [here](https://github.com/cisagov/cyhy_amis/pull/646#discussion_r1161825858).", "See [here](https://github.com/cisagov/cyhy_amis/pull/646#discussion_r1161825858).", "See [here](https://github.com/cisagov/cyhy_amis/pull/646#discussion_r1161825858)."]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/640", "comments": ["If we want to maintain alphabetical order.  If not, I understand. \ud83d\ude04 \r\n```suggestion\r\n        key: ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIOreUDnms12MPI0gh7K+YGaESYgC2TY1zA+kSK/g+n5+ cyhy\r\n        user: cyhy\r\n```", "Ah, nope I missed that while migrating the configuration. Glad you caught it!"]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/638", "comments": ["Should we sort these named arguments alphabetically here and elsewhere below?", "We can. I always err on the side of conservative when it comes to changes in a Lineage PR so I just plopped it at the end.", "I'm fine with it as is if you don't want to test out that change.  Just let us know here what you decide to do.", "@mcdonnnj Any update here?", "@dav3r I'd like to do the sorting in a separate PR because I'd rather be comprehensive about it and that's outside the scope of this PR (in my opinion). I did test that the timeout value works ok when redeploying an instance.", "Works for me, thanks!"]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/613", "comments": ["Why is this `collections` block only in this particular `meta/main.yml` file?", "I only added `collections` blocks to the metadata files of the two roles that use non-builtin functionality. This role (`cyhy_dashboard`) uses `community.general.make` and the `mongo` roles has it because it uses `community.mongodb.mongodb_user`. I'm happy to add empty `collections: []` entries to all of the other roles for consistency.", "I'm good with adding empty collections entries for consistency.  @jsf9k, you good with that?", "Maybe also include a standard explanatory comment for those (like me) who were not familiar with the reasoning there.", "> I'm good with adding empty collections entries for consistency. @jsf9k, you good with that?\r\n\r\nYes, I am good with this.  We should also add it to [`cisagov/skeleton-ansible-role`](https://github.com/cisagov/skeleton-ansible-role).", "Why are `company` and `description` being explicitly moved out of alphabetical order?", "That is the order in [cisagov/skeleton-ansible-role](https://github.com/cisagov/skeleton-ansible-role/blob/95681aa71c17c7cf69d4658810547dec13d60ccb/meta/main.yml#L3-L5) and part of this PR is making these roles align more with our independent Ansible roles.", "I think the order should be fixed in `cisagov/skeleton-ansible-role` then, and can be left alone here.", "I have removed that group of changes as part of my rebase.", "So coming back here I actually found official documentation that had me remove these entries. Per the [documentation](https://docs.ansible.com/ansible/latest/collections_guide/collections_using_playbooks.html#using-collections-in-roles) that keyword is only used for namespace searching and is not involved in dependency resolution. Per https://github.com/ansible/ansible/issues/76030#issuecomment-942520399 there is no way for a role to depend on a collection as part of role metadata. The only way around this would be converting these Ansible roles into a collection and defining any collection dependencies there.", "Even better- thanks for looking into that. \ud83d\udc4d "]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/594", "comments": ["We should probably sort these targets alphabetically.", "I wasn't sure if order mattered as far as Terraform was concerned and the targets in other deploy scripts are not fully sorted either so I held back (but had the same thought).", "Terraform does not care about the order of the targets since it figures out its own order of operations for the resources it needs to deal with.", "Please see [c69ce41](https://github.com/cisagov/cyhy_amis/pull/594/commits/c69ce41f616fbef9c1b9d6884782dcd0a52ca213).", "Great, thanks!"]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/588", "comments": ["Might as well get rid of this old NCATS reference while we are here (I didn't search for any others in this repo; feel free to check for them if you want).\r\n\r\n```suggestion\r\n# CISA Cyber Hygiene AMIs \ud83d\udcc0 #\r\n```", "Please see [97f9e82](https://github.com/cisagov/cyhy_amis/pull/588/commits/97f9e828968fd526d67423b97ce674a12ef4b151)."]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/542", "comments": ["Alphabetize?\r\n```suggestion\r\n  file:\r\n    group: cyhy\r\n    mode: 0750\r\n    owner: cyhy\r\n    path: /etc/cyhy\r\n    state: directory\r\n\r\n- name: Create the configuration file for Nessus API access\r\n  template:\r\n    dest: /etc/cyhy/nessus_api.yml\r\n    group: cyhy\r\n    mode: 0640\r\n    owner: cyhy\r\n    src: nessus_api.yml.j2\r\n```", "I intentionally did not alphabetize to match the existing Ansible role structures and I was planning to update #478 once this PR is merged which would have those changes.", "OK, I suspected you had some motive here, but I wasn't sure what it was.  Thanks for the explanation. \ud83d\udc4d ", "Just to circle back I have rebased #478 and the concerns raised here should be resolved in https://github.com/cisagov/cyhy_amis/pull/478/commits/984084dc5dc8056eda10b189ccf25ffd42b54141."]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/461", "comments": ["I think this phrases things more accurately but let me know if you disagree.\r\n\r\n```suggestion\r\n# need to be globally readable.  The Compose specification does allow\r\n# one to specify the uid, gid, and mode of the secrets files, but that\r\n```", "This is phrased awkwardly to me now so I thought this might be a bit clearer.\r\n\r\n```suggestion\r\n# The compose command will automatically use docker-compose.yml and\r\n```", "Continuation since GitHub won't let me include the unmodified line in a complete suggestion.\r\n\r\n```suggestion\r\n# compose's behavior to the particular machine.\r\n```"]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/460", "comments": ["FYI, this is the default version as of cisagov/ansible-role-nessus#16.", "@mcdonnnj alluded to this in this PR's \"Motivation and context\" section above:\r\n> Since we need to update the version and instead of relying on an obfuscated software version installed as a default for the Ansible role we're using it makes sense to explicitly set the version we want used in nessus AMIs.", "This also allows the Ansible role to use whatever version it wants as a default while allowing the CyHy images to remain on a version tested against our orchestration.", "I wasn't suggesting changing it; I was just pointing it out in case anyone cared.  _Conversation resolved!_"]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/451", "comments": ["Typo:\r\n```suggestion\r\n        # Install pip2 for all instances that will run Python 2\r\n```"]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/436", "comments": ["Might as well remove these comments here, since they are not present in the other `meta/main.yml` files.", "Do we want to replace `/var/cyhy` with a local variable since it's now repeated a bunch of times in our Terraform?  I'm fine either way- just throwing it out there.", "Unless we change the Ansible roles creating some of these directories I'd rather leave it hard-coded to make it clear that it's not expected to change.", "Please see commit 8849ee1.", "I agree with @mcdonnnj, and I like it being made explicit in the `*_cloud_init.tf` file what directories are being `chown`ed.  With the local variable I'd have to go to another file to look up the value when reading the Terraform code.", "Those are good reasons in my book. \ud83d\udc4d ", "Would you re-arrange these `part`s so they are ordered how we expect them to run on the instance?", "Same ask regarding `part` ordering.", "Same ask regarding `part` ordering.", "Same ask regarding `part` ordering.", "I can certainly reorder the script `part`s in that order.  I believe the order in which the various `text/cloud-config` bits run is dependent on the contents and has nothing to do with the `part`s.  One such `part` could contain two pieces of content that are run at different stages, but for the most part they will all run _before_ the user scripts.\r\n\r\nShall I just put all the `text/cloud-config` pieces at the top of the file (ordered by their `filename` attribute) and all the `text/x-shellscript` parts below that (ordered according to how they are expected to run on the instance)?", "Yes you're right about `text/cloud-config` ordering and I'm totally fine with your solution as that's what I was thinking myself.", "Please see commit ddfa965.", "Please see commit ddfa965.", "Please see commit ddfa965.", "Please see commit ddfa965.", "This used to run before the `cyhy_docker_chown_orchestrator_output_directory.sh` script because of the default sorting from cloud-init (Python `sorted()` function). Are we ok to change this ordering?", "Same question about changed ordering.", "Same question about changed ordering.", "Same question about ordering.", "I think we are.  We could probably get away with only `chown`ing the parent directory, but it doesn't hurt to do the child directory (and mount point) first.\r\n\r\nThe disk is already set up when the script runs, and the script waits until the mount point is available before starting.", "I think we are.  We could probably get away with only `chown`ing the parent directory, but it doesn't hurt to do the child directory (and mount point) first.\r\n\r\nThe disk is already set up when the script runs, and the script waits until the mount point is available before starting.", "I think we are.  We could probably get away with only `chown`ing the parent directory, but it doesn't hurt to do the child directory (and mount point) first.\r\n\r\nThe disk is already set up when the script runs, and the script waits until the mount point is available before starting.", "I think we are.  We could probably get away with only `chown`ing the parent directory, but it doesn't hurt to do the child directory (and mount point) first.\r\n\r\nThe disk is already set up when the script runs, and the script waits until the mount point is available before starting."]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/425", "comments": ["As long as we're making this a local variable, we should utilize it here too:\r\nhttps://github.com/cisagov/cyhy_amis/blob/2d2a70bc3bc51cacce4e0babd17cec3bb5363d6f/terraform/cyhy_nessus_ec2.tf#L106-L109", "Please see [80d489a](https://github.com/cisagov/cyhy_amis/pull/425/commits/80d489a197e72d874000db8860f4581c65845767).", "I'm going to speak for @dav3r here (since he's out today) and say that commit 80d489a fully addresses his comment.", "Thanks @jsf9k for covering for me here.  You were indeed correct - this commit looks great to me."]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/423", "comments": ["This is not correct- https://github.com/cisagov/cyhy_amis/pull/423/commits/92dc671a86b3431a33cd290b641740cb938ce274 should be reverted, since `local.db_instances` is a map, not a list.  As it stands now, Terraform throws this error when attempting to apply:\r\n```\r\n\u2502 Error: Incorrect attribute value type\r\n\u2502 \r\n\u2502   on kevsync_failure_alarms.tf line 58, in resource \"aws_cloudwatch_metric_alarm\" \"kevsync_failure\":\r\n\u2502   58:       dimensions = {\r\n\u2502   59:         InstanceId = each.value\r\n\u2502   60:       }\r\n\u2502     \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\r\n\u2502     \u2502 each.value is object with 1 attribute \"hostname\"\r\n\u2502 \r\n\u2502 Inappropriate value for attribute \"dimensions\": element \"InstanceId\": string required.\r\n```", "Same as above.", "I rebased, removing the commit.", "I rebased, removing the commit."]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/422", "comments": ["I'm fine either way here, but since there's only one:\r\n```suggestion\r\n  # Ensure the EBS volume is attached before running Ansible\r\n```", "Same as above:\r\n```suggestion\r\n  # Ensure the EBS volume is attached before running Ansible\r\n```", "Same as above:\r\n```suggestion\r\n  # Ensure the EBS volume is attached before running Ansible\r\n```", "I kind of like the boilerplate comments for this, but I see where you're coming from with your feedback. Thoughts on the following as something boilerplate-y but less quantity specific?\r\n\r\n```suggestion\r\n  # Ensure any EBS volumes are attached before running Ansible\r\n```", "Sure, that's a nice compromise.  \ud83d\udc4d", "Please see [7a41648](https://github.com/cisagov/cyhy_amis/pull/422/commits/7a41648c06164c5973e68c7b7277f1974937a48e) and let me know if that works.", "Does [7a41648](https://github.com/cisagov/cyhy_amis/pull/422/commits/7a41648c06164c5973e68c7b7277f1974937a48e) also satisfy this?", "Does [7a41648](https://github.com/cisagov/cyhy_amis/pull/422/commits/7a41648c06164c5973e68c7b7277f1974937a48e) also satisfy this?", "Yes, sorry- I forgot to resolve these other conversations."]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/412", "comments": ["Why do we need the maxmind key here?", "Dependency chain. [cisagov/ansible-role-cyhy-archive](https://github.com/cisagov/ansible-role-cyhy-archive) depends on [cisagov/ansible-role-cyhy-core](https://github.com/cisagov/ansible-role-cyhy-core) which depends on [cisagov/ansible-role-geoip2](https://github.com/cisagov/ansible-role-geoip2). ", "Thanks for the reminder! \ud83d\udc4d "]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/410", "comments": ["We can get rid of these hard-coded lambda counts:\r\n```suggestion\r\n    resources = [ for lambda in aws_lambda_function.lambdas : lambda.arn ]\r\n```", "Capitalization - there are probably a bunch of other similar cases if you feel like fixing them:\r\n```suggestion\r\n# The roles we're creating for the Lambda functions\r\n```", "Capitalization - there are probably a bunch of other similar cases if you feel like fixing them:\r\n\r\n```suggestion\r\n# IAM policy document that that allows some CloudWatch permissions\r\n```", "@dav3r I have that taken care of as part of some other work ([improvement/refactor_bod_lambda_configuration](https://github.com/cisagov/cyhy_amis/tree/improvement/refactor_bod_lambda_configuration)). Do you mind if I leave that out of this PR? ", "Please see [021f2d9](https://github.com/cisagov/cyhy_amis/pull/410/commits/021f2d999cfd1d358eeec475db917ee0507cd8e2).", "Please see [021f2d9](https://github.com/cisagov/cyhy_amis/pull/410/commits/021f2d999cfd1d358eeec475db917ee0507cd8e2).", "\ud83d\udc4d No problem at all."]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/394", "comments": ["Typo:\r\n```suggestion\r\n  #    script is run, similar to what is done for the cyhy-nvdsync script here:\r\n```", "This will send failure emails to those two addresses in addition to `cisa-cool-group+cyhy@trio.dhs.gov`, correct? ", "Note that we list `aws_sns_topic.cloudwatch_alarm.arn` in the `alarm_actions`, `insufficient_data_actions`, and `ok_actions` attributes of `aws_cloudwatch_metric_alarm.kevsync_failure`.  Thus `cisa-cool-group+cyhy@trio.dhs.gov` will get emails for all state transitions for this alarm.", "I think this should be converted to a variable so it's straightforward to modify for testing deployments.", "Same comment about converting this to a variable.", "Since these must be unique within the account.\r\n\r\n```suggestion\r\n  alarm_name                = format(\"kevsync_failure_%s_%s\", each.value.hostname, local.production_workspace ? \"production\" : terraform.workspace)\r\n```", "Since these must be unique within the account.\r\n\r\n```suggestion\r\n  alarm_name                = format(\"nvdsync_failure_%s_%s\", each.value.hostname, local.production_workspace ? \"production\" : terraform.workspace)\r\n```", "In the COOL I just pull the email associated with the account from the AWS Organization via the master account.  Is there a way to do something similar here?  This is precisely the email we want to send alerts to, but I don't know how to access such a thing outside of an Organization.", "It's the email we want to send alerts to for production workspaces, but I don't think we want to clutter that email with testing deployment updates in non-production workspaces.", "Right, I get that, but that still doesn't answer my question:  _In the COOL I just pull the email associated with the account from the AWS Organization via the master account. Is there a way to do something similar here?_\r\n\r\nFor production workspaces I'd like to pull that email address from AWS vice making folks type it in again into their `tfvars` file.", "Please see commit 188da8d.", "I guess my suggestion was basically variable with a default to override? I was thinking of it along the lines of the AMI prefix variable I added. I'm not aware offhand of a way to do it the way you describe in this account since it's unfortunately not structured like COOL accounts.", "Please see commit 62c5cee."]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/361", "comments": ["Keep the capitalization train rollin':\r\n```suggestion\r\n  description = \"The name of the bucket where the assessment data import Lambda function can be found.  This bucket should be created with the cisagov/assessment-data-import-terraform project.  Note that in production Terraform workspaces, the string '-production' will be appended to the bucket name.  In non-production workspaces, '-<workspace_name>' will be appended to the bucket name.\"\r\n```", "Keep the capitalization train rollin':\r\n```suggestion\r\n  description = \"The name of the bucket where the findings data import Lambda function can be found.  This bucket should be created with the cisagov/findings-data-import-terraform project.  Note that in production Terraform workspaces, the string '-production' will be appended to the bucket name.  In non-production workspaces, '-<workspace_name>' will be appended to the bucket name.\"\r\n```", "Please see [b1bf5f0](https://github.com/cisagov/cyhy_amis/pull/361/commits/b1bf5f0a3dd5f7ff6e973ec2c15582f4a3cd2b56).", "Please see [b1bf5f0](https://github.com/cisagov/cyhy_amis/pull/361/commits/b1bf5f0a3dd5f7ff6e973ec2c15582f4a3cd2b56)."]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/355", "comments": ["Why do we do this instead of referencing `var.tags` explicitly?", "That's what I saw in [other projects](https://github.com/search?q=org%3Acisagov+aws_default_tags&type=code) and I pulled it from the skeleton [here](https://github.com/cisagov/skeleton-tf-module/blob/f1c81f4e0ec92f988c76def81d26786f5688d086/main.tf#L37-L38) and [here](https://github.com/cisagov/skeleton-tf-module/blob/f1c81f4e0ec92f988c76def81d26786f5688d086/main.tf#L55-L60).", "This could be a misinterpretation on my part because those projects often have multiple providers, but I figured I would follow precedent.", "In [a2de9a8](https://github.com/cisagov/cyhy_amis/pull/355/commits/a2de9a86237e768dbb7ab25d9de764e8281d850b) I removed the `provider` to keep in line with the examples I linked."]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/353", "comments": ["This should take care of the pre-commit issues:\r\n```suggestion\r\n    \"64.39.108.104/29\",\r\n    \"64.39.108.112/28\",\r\n    \"64.39.99.0/24\",\r\n```", "Keeping these ordered as they used to be (since the order does not impact functionality).\r\n\r\n```suggestion\r\n    \"64.39.99.0/24\",\r\n    \"64.39.108.103/32\",\r\n    \"64.39.108.104/29\",\r\n    \"64.39.108.112/28\",\r\n```", "I don't Know if it is a bug, but I am changing the title and notes on the commit, but it doesn't seem to hold when I confirm", "> I don't Know if it is a bug, but I am changing the title and notes on the commit, but it doesn't seem to hold when I confirm\r\n\r\nThe commit message looks good to me for https://github.com/cisagov/cyhy_amis/pull/353/commits/e75124c034c2aa78d5d4d30f0ab3a87bab548b36.  Or are you talking about a different commit?"]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/336", "comments": ["This can probably also be given a default value of 1.", "Good call! Please see 46576b5 for that default being added."]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/334", "comments": ["Typo:\r\n```suggestion\r\n\"\"\"Gather and publish the list of IPs of EC2 instances tagged for publication.\"\"\"\r\n```"]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/328", "comments": ["Great- we are going to have to update this title in less than 9 years! \ud83d\ude1b "]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/320", "comments": ["It would be nice to add a comment mentioning that this file is auto generated by the Terraform module for future brave souls.", "Is this actually a Terraform limitation? I'm not sure if it's a problem with the module, the Terraform version, or the AWS  provider version.", "```suggestion\r\n  description            = \"Adds HSTS security headers to the response\"\r\n```", "See commit ef022c0.", "You're right, it's actually [a limitation of the AWS provider](https://github.com/hashicorp/terraform-provider-aws/blob/2f23a59662cc53a1c9403517dc1312d2846b5434/aws/resource_aws_lambda_function.go#L26-L48).\r\n\r\nSee commit 71c048b.", "See commit 62d17a0.", "Thanks for taking the time to look into where the limitation was to be found. I believe an AWS provider v3 upgrade is likely a lot less potential work than upgrading Terraform versions.", "I can't remember- is there any reason why we never upgraded to version 3.x of the AWS provider in this repo?  We took care of the rest of our repos with https://github.com/cisagov/cool-system/issues/93.", "I'm not sure.  I'm OK upgrading just the `terraform_egress_pub` directory, but I wasn't sure if @mcdonnnj wanted to keep all of this repo at the same AWS provider version.", "See commits 8868b16 and 48be7ab.", "Excellent!"]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/316", "comments": ["Is there any output if the instance ID is not found?  It would be nice if there was some sort of user feedback for when this situation arises.", "There was not, but I have added it in 06d6ac1. Nice catch!", "Thanks - looks good!"]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/302", "comments": ["Do we still need the `*.dyn.tf` line for the code generated in the `terraform/dyn_*` directories?  I'm not sure, so I'm asking.", "Ah, that's a good question. We probably do and I just got overzealous with `.gitignore` cleaning.", "I have restored that pattern in 22c028b"]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/292", "comments": ["```suggestion\r\n        raise Warning(f\"Policy import failed; response={response.text}\")\r\n```", "```suggestion\r\n        raise Warning(f\"File upload failed; response={response.text}\")\r\n```", "```suggestion\r\n        raise Warning(f\"Policy list failed; response={response.text}\")\r\n```", "```suggestion\r\n            f\"Session destruction failed; response={response.text}\"\r\n```"]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/289", "comments": ["\"previously removed\" :arrow_right: \"previously-removed\"", "I think a comment is needed here stating \r\n* What the arguments to this function are (`start` and `stop`)\r\n* Whether the `start` to `stop` range is exclusive (`[start, stop)`) or inclusive (`[start, stop]`)", "I added some comments and addressed your concern in both a comment about the function, and as a note in the usage output in 85aeda2. Thanks for pointing out that it was ambiguous \ud83d\udc27", "I *think* that since `previously` is an adverb I'm safe. Thank you for bringing up the suggestion though!", "Ah, you are correct.  I have learned something.", "What you wrote is perfect.  Thanks for clearing that up."]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/287", "comments": ["If we are changing this, we can remove the `HACK ALERT` comment above and also update the name of this task to simply: `Install pymongo 3.6`", "Even better - Can we just install the latest pymongo via `pip` and change the name to `Install pymongo`?", "@mcdonnnj - Did you test installing the latest version of pymongo to see if it works?  That would be ideal, as @jsf9k suggested.", "@dav3r Thanks for pointing that out, fixed in a2b2af0. @jsf9k Unfortunately since there is already a version of `pymongo` installed when this step runs, it appears that if we do not specify an explicit version it will not change. I tested to verify, and without a version it fails in the same way that prompted this change.", "Got it- thanks for verifying that and explaining it!"]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/286", "comments": ["It's probably worth considering moving the upgrade and python steps to separate playbooks as is done [in cisagov/skeleton-docker](https://github.com/cisagov/skeleton-packer/blob/develop/src/packer.json#L65-L79).  The advantage is that Ansible \"resets\" and re-determines what version of python to use at the beginning of each provisioning step.  This way all the foo you really care about is installed under Ansible via python 3.\r\n\r\nIt probably doesn't matter much for the bastion, but it will matter a great deal for other AMIs that use the `pip` Ansible module.", "The python playbook removes python2 from the AMI.  Are the reporter, nmap, nessus, mongo, docker, and dashboard AMIs all ready for such a big step?", "The `python.yml` playbook has `remove_python2` separated into a standalone task (I didn't just blindly copy it). That task only applies to the `bastion` host at the moment.", "Instance types will be added as they become Python 3 only, and eventually it will just be one task when they are all on Python 3 only.", "Ah, I missed that.  Thanks for pointing it out.", "As long as we are updating our Packer JSON files, we might as well update our team tag to the slightly more modern `VM Fusion - Development` that we use elsewhere (e.g. [kali-packer](https://github.com/cisagov/kali-packer/blob/develop/src/packer.json#L54)).\r\n\r\nThis change should be made to all of our Packer files in this repo.", "Good catch! I did a find/replace on the repo in 3f8e4c6."]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/281", "comments": ["There's a typo in the last word here.", "\"confirms\" --> \"confirmed\"", "`confirms` should be `confirmed`.", "Is there a reason you decided against `202X-XX`? You left that in the `Procedure` section, so I think it should be consistent one way or the other.", "If we're moving to single issues instead of comments in a pinned issue, then this should be updated to reflect that change.", "Perhaps something like tracker instead of list would make more sense for how we're using that pinned issue?", "```suggestion\r\n## Procedure ##\r\n```", "Looking at this again, I think it would better to break these up by environments. So:\r\n```suggestion\r\n## Status ##\r\n\r\n- [ ] BOD\r\n  - [ ] Bastion\r\n  - [ ] Docker\r\n- [ ] CyHy\r\n  - [ ] Bastion\r\n  - [ ] Dashboard\r\n  - [ ] Database\r\n  - [ ] Reporter\r\n  - [ ] Scanners\r\n    - [ ] Portscanners (nmap)\r\n    - [ ] Vulnscanners (Nessus)\r\n```\r\n\r\nThis gives better visibility to the fact that there are really two environments in this repository's Terraform configuration.", "Thanks! Resolved in https://github.com/cisagov/cyhy_amis/pull/281/commits/d1ee4675a058de4e09a936e409100d64d3446279", "Thanks! Resolved in https://github.com/cisagov/cyhy_amis/pull/281/commits/d1ee4675a058de4e09a936e409100d64d3446279", "Thanks! Resolved in https://github.com/cisagov/cyhy_amis/pull/281/commits/d1ee4675a058de4e09a936e409100d64d3446279", "I'm considering pre-loading it for 2021 - what would you think?", "Thanks! Resolved in https://github.com/cisagov/cyhy_amis/pull/281/commits/d1ee4675a058de4e09a936e409100d64d3446279", "Thanks! Resolved in https://github.com/cisagov/cyhy_amis/pull/281/commits/d1ee4675a058de4e09a936e409100d64d3446279", "I'm really ok with any of `202X`, `2020`, or `2021`, I just wanted to make sure we were consistent."]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/280", "comments": ["I understand why removing this is easier on our end, but I still believe we should include these repositories. I'm not sure how the JSON is used on the other end, but if it's a replace instead of a merge those archived repositories will no longer be listed on code.gov. GSA still has archived repositories there, and we're still including `cisagov` archived repositories. I don't think we should be eliminating other archived repositories.", "@h-m-f-t suggested removing `usdhs`.  I'm happy to let him cast the deciding vote.  He may have more knowledge about the provenance of `usdhs` than we do.  What say you @h-m-f-t?\r\n\r\nIt's definitely a replace when the JSON is published to the web.", "I think @mcdonnnj's comment is fair and it doesn't hurt to leave it in, so let's do that. \r\n\r\n(Yo @ab / @brodygov, we'd welcome if you have a different take on @usdhs.)", "I did a force push to remove the commit where I removed `usdhs`."]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/275", "comments": ["Should we explicitly set the `mode` as well for completeness?", "It couldn't hurt- done in https://github.com/cisagov/cyhy_amis/pull/275/commits/47f9887f656a4cb1da9078c40dbfd3fe452dd071.  Thanks for the suggestion."]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/268", "comments": ["I'm late to the review game here, but `deploy_new_database_ami` -> `deploy_new_dashboard_ami`", "Ack, I should've done a find/replace. The mistakes we make trying to get something working in a hurry."]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/267", "comments": ["I don't think these are considered \"test Qualys scans\" anymore.  At this point, they can be referred to as \"Qualys web application scans\".", "Since it is now duplicated, perhaps this tuple of strings should be broken out into it's own variable, something like `qualys_was_ips`?", "You might as well add a `daver` workspace while you are adding the others.", "See commit 54a3835.", "See commit 54a3835.", "See commit 3bc437c.", "Ah, I wondered about that as well. Since it was duplicated before I assumed that was intentional."]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/259", "comments": ["Thanks for finally changing this! \ud83d\udc4d I've had it changed locally forever."]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/257", "comments": ["in to --> into", "Thanks- see https://github.com/cisagov/cyhy_amis/pull/257/commits/6032cc87d1a934398e3964823253f067e81c30cc."]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/255", "comments": ["Am I missing something?  Shouldn't this be:\r\n```\"ses_send_email_role={var.ses_role_arn}\"```\r\n", "Same question here as above.", "Fixed with a dramatic force push to remove the role name from the history.  See commit fdefaf7.", "Fixed with a dramatic force push to remove the role name from the history.  See commit fdefaf7.", "\ud83d\udc4d ", "\ud83d\udc4d ", "This is some :fire: :hankey: right here!"]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/253", "comments": ["I didn't realize they were supporting 3.8 now.  Sweet!"]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/249", "comments": ["Excellent job tracking down these redundant resources!"]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/246", "comments": ["I don't think `region` is ever used.  It can be removed.", "Ha, good catch, thanks! See https://github.com/cisagov/cyhy_amis/pull/246/commits/5a213187f09a1eff98626c295d135fb4ece6b201 for the change.  I was overzealous in my copy/pasting of a similar deploy script.", "![image](https://user-images.githubusercontent.com/5521725/70267915-6ca75080-176d-11ea-88d1-cd7c747e8f69.png)\r\n"]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/234", "comments": ["Is this comment correct?", "Verify this comment.", "Aha, good catch, thanks!  Fixed in https://github.com/cisagov/cyhy_amis/pull/234/commits/16cf850fd7434d9b2ec402a33b23b43ceab859f5.", "Thanks for the sharp \ud83d\udc40 @felddy!  Fixed in https://github.com/cisagov/cyhy_amis/pull/234/commits/16cf850fd7434d9b2ec402a33b23b43ceab859f5."]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/220", "comments": ["I believe (though someone should double-check this) `cyhy-feeds` only needs read-access to the CyHy database.  If that is the case, we should use the `/cyhy/mongo/users/reporter/*` credentials, rather than the `commander` credentials (fetched [here](https://github.com/cisagov/cyhy_amis/blob/develop/ansible/roles/cyhy_feeds/vars/main.yml#L17-L22)), which have write-access.", ":eagle: :eye:, @dav3r!", "Pulled credentials and references are updated now, please let me know if I missed something."]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/216", "comments": ["This does NOT work correctly on OSX:\r\n`sed $'s,\\x1b\\\\[[0-9;]*[[:alpha:]]],,g'`, however this does:\r\n`sed $'s,\\x1b\\\\[[0-9;]*[[:alpha:]],,g'`\r\n\r\nNot sure where that extra `]` came from, but it wasn't there when you gave me samples to test.", "Good eye.  I fat fingered that.  Fixed in 803e622."]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/209", "comments": ["This should be `production_workspace|bool` to avoid an Ansible 2.8 warning.", "Good catch, thanks @jsf9k - fixed in 2678ef5"]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/207", "comments": ["What is the CLI command for this?", "It's `aws ec2 terminate-instances --instance-ids <id1> <id2> ...`  \r\n\r\nHere's a handy snippet to get all of the instance IDs in a particular terraform workspace (assuming all of the instances are properly tagged with the workspace name):\r\n`aws ec2 describe-instances --filters \"Name=tag:Workspace,Values=<WORKSPACE_NAME>\" --output text --query \"Reservations[*].Instances[*].InstanceId\"`\r\n\r\nSo one way to do it would be:\r\n`aws ec2 describe-instances --filters \"Name=tag:Workspace,Values=<WORKSPACE_NAME>\" --output text --query \"Reservations[*].Instances[*].InstanceId\" | xargs aws ec2 terminate-instances --instance-ids\r\n`\r\n\r\nOur goal should be to not have to do this step at all.  Hopefully, after we move to terraform 0.12, we will be able to clean up our code so that `terraform apply` will be able to cleanly terminate our instances, then spin up their replacements (or in certain cases, we may be able create the new instances before destroying the old ones; eventually, we will want that model across the board).", "Roger.  Terraform 0.12 will fix all our woes!  ;) "]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/201", "comments": ["I'd vote for a slightly more descriptive name here, like `github_oauth_token`", "Same here, I'd prefer to see this called `gpg_trust` to improve readability", "Changed in 5a7097c.", "Renamed in f83ed1f."]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/193", "comments": ["Did we have a case where this `chown` step was taking more than 3 minutes to complete?", "Yes, it was sporadically timing out when I applied to my `jsf9k` workspace.  Not often, but occasionally."]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/190", "comments": ["@felddy, I wasn't sure if you'd prefer this CNAME record to be here or [here](https://github.com/cisagov/cyhy_amis/blob/develop/terraform_egress_pub/cloudfront.tf).", "Either place makes sense.  I'd leave it where it is for now.  Thanks for asking.  \r\n"]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/178", "comments": ["Why port -1?", "To close the loop on this, when the protocol is ICMP, -1 for `from_port` and `to_port` means \"allow all types of ICMP\".  I cannot find any official documentation on this, but a web search turns up various posts that mention it, like this:  https://blog.jwr.io/terraform/icmp/ping/security/groups/2018/02/02/terraform-icmp-rules.html ", "I know this is probably auto-generated but do we want it to be set to `CC0`?", "[That's exactly what I did in the Ansible roles that I broke out into their own repos](https://github.com/dhs-ncats/ansible-role-htop/blob/develop/meta/main.yml#L6).  We should probably do it everywhere (and get rid of the autogenerated cruft that we don't need).\r\n\r\nI need to get back to breaking more roles out into their own repos.  Once I get my backlog of PRs from the shutdown shepherded through I'll make some time for that.", "I can change it here since it relates to this PR, but it should also be done for all of the ansible roles that we have in cyhy_amis (or as @jsf9k said, just do it when they get split out into their own repos).", "License added in [this commit](https://github.com/dhs-ncats/cyhy_amis/pull/178/commits/84c397f4e2b09e6f05edb203633d3d012fed4755)"]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/161", "comments": ["I don't think this is a good way to handle this problem.  Why include the `production` section from the commander?\r\n\r\nBetter might be to create the `cyhy.conf` file that feeds needs if one does not already exist.  If one does exist then add the desired lines as you are doing.  You will want to add a  `when: cyhy_conf_result.stat.exists == True` to this block since there's no need for it to run if we're creating the `cyhy.conf` file from whole cloth.  Then there should be a parallel structure in the `cyhy_commander` Ansible code.\r\n\r\nThat way the correct file will get created regardless and feeds need not know anything about what commander wants in its `cyhy.conf` file.", "OK, I think I have a better solution in ee1697b.  Note that the feeds and commander Ansible roles now have a parallel structure.  It should not matter which one is run first, nor should it matter if they are run multiple times.\r\n\r\n@dav3r and @KyleEvers, please let me know what you think.  If you're happy with my change then I think this pull request is ready to be merged.  (I would approve it, but I can't approve a pull request that I created myself.)", "It seems I misunderstood what was going on.  feeds needs the commander/production `cyhy.conf` section.  This is corrected in commit 0dffd4a.", "Not sure if this matters, but shouldn't this be lower-case 'p' `[production]` to match the contents of the `block` below?", "Yes.  I'm not sure how that happened.  Fixing now."]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/156", "comments": ["Nice to see that this got simpler now that both Production and non-Production instance types are NVMe. \ud83d\udc4d "]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/155", "comments": ["Why did you get rid of the space before the `|` here?", "Here too.", "I fixed them. Atom was rendering it weird because the line was so long and I ended up deleting the space by mistake. ", "Ah."]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/154", "comments": ["Do we need to remove `SMTP (587)` from this comment?", "You are correct, sir!  I will remove it now.", "Removed in 7ff20c3."]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/153", "comments": ["\\<sarcasm\\>So happy to see this ugliness lives on...\\<\\/sarcasm\\>  \ud83e\udd22 ", "Nice! \ud83c\udfd7 "]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/150", "comments": ["Please remove these unnecessary spaces or just revert this file- it should not have changed at all."]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/149", "comments": ["These three comment lines can be removed or updated to more accurately reflect what is happening here", "Nitpick: This should read: \"Start ncat**s**-webd'\"", "These 3 comment lines can be removed.", "We already have a `pip` role at `packer/ansible/roles/pip`.  This section should be removed and `pip` should be added to the list of dependencies in `packer/ansible/roles/cyhy_dashboard/meta/main.yml`", "Is there a reason why `/var/cyhy` and `/var/cyhy/web` need different modes?", "This isn't a good way to start a service.  If the instance reboots the service won't be restarted.  You should really create a systemd unit instead.\r\n\r\nLook at the packer and terraform ansibles for the commander for an example.", "This is nit-picky, but \"Run\" is incorrect here.  It should be \"Build\".", "Again, this is a terrible way to start a service.  If the instance reboots the service won't be restarted.  You should really create a systemd unit instead.", "Bad formatting here.  The lines that follow are not sufficiently indented.", "I don't see where the token from `github_oauth` is used here.", "The directory name is incorrect in this comment.", "No need for a conditional if the result is the same either way."]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/146", "comments": ["This line and the `volume_size` line below it could obviously be simplified if the values don't depend on whether or not we're in a production workspace.  What is the intent?  Are you going to see if this works out and follow up?", "Is 8GB what we had before?  Seems small.", "Again, is 2GB the value we used before?", "Duplicate \"The\".", "Yes, I left it like that in case we end up switching to different instance types in the future.  Plus, it's consistent with the code over in the vulnscan instance.  If it looks like we are never going to have different instance types between Production and non-Prod, then I'm all for making the change to simplify this line.", "You're right- we used to have 20 GB here before (see [here](https://github.com/dhs-ncats/cyhy_amis/commit/b0b6b4175d080ced414494fe8691f03405b41207#diff-0ec35a026f754ebbbc04103a8e4c9031)).  I will change this back to 20 shortly.", "2GB is what [we used to have for this;](https://github.com/dhs-ncats/cyhy_amis/commit/b0b6b4175d080ced414494fe8691f03405b41207#diff-0ec35a026f754ebbbc04103a8e4c9031) the runner doesn't require that much space if we only have 12 concurrent jobs running on each portscan instance.", "Resolved in [this commit](https://github.com/dhs-ncats/cyhy_amis/pull/146/commits/42a97111fa99339a441e52b207a0c0e465c6778a)", "Resolved in [this commit](https://github.com/dhs-ncats/cyhy_amis/pull/146/commits/bd4335618c1a62fc7456a4f1b836620b10bb933f)"]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/138", "comments": ["Might be worth adding a couple of comments about why we need python 3.7 and xenial in here, even though you explained it well in your PR comments.", "Good call."]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/135", "comments": ["```suggestion\r\nwill update the roles that are being pulled from external sources.  This\r\n```"]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/130", "comments": ["@jsf9k Should we include github_oauth as a role dependency here?\r\nhttps://docs.ansible.com/ansible/2.5/user_guide/playbooks_reuse_roles.html#role-dependencies\r\n", "Thanks for pointing that out @dav3r!  I will go ahead and add `github_oauth` as a dependency where appropriate, and I will create another PR where I take full advantage of dependencies to simplify our Ansible code."]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/128", "comments": ["It looks like this block has been duplicated; also, this block has an incorrect name.", "Remove this line left over from a merge", "Remove these two lines left over from a merge", "Remove this line left over from a merge", "I would consider renaming this public key (both in the bucket and at the destination) to reflect the function of the key, rather than the name of the person who generated it, i.e. something like `nsd_cyhy_daily_extract_public.key`", "Remove these two lines left over from a merge", "Remove this line left over from a merge", "See earlier comment about renaming key", "Remove these two lines left over from a merge", "Remove this line left over from a merge", "You don't need both of these lines.", "You don't need both of these new blocks.", "You committed quite a bit of merge conflict in this file.", "This should probably have permissions `0444` to prevent accidental overwrites.", "Again, you only need one of these blocks.", "Correct this line.", "Correct this line.", "Use your own name :smiley: ", "Use your own name :smiley: ", "Prefer `package` to `apt` when you're not using any apt-specific options.  This makes the file more likely to work with non-Debian systems.", "More merge conflict.", "`debian` shouldn't be here.  The packer code was updated not to require it.  I think you were working from an old version.  Please update.", "Yet more merge conflict.", "Remove this line left over from a merge", "This should probably be `ebs_optimized = \"${local.production_workspace}\"` (and uncommented).", "Remove this line left over from a merge", "We no longer assign fixed IPs like this.  See the most recent code and update accordingly.", "Merge this rule into the previous one.  That should be slightly more efficient.", "What is up with the `trustdb.gpg` coming from your local .gnupg directory?  How are the rest of us supposed to run this ansible role? ", "Remove this line left over from a merge", "Remove these two lines left over from a merge", "This file should not have been deleted!  We need it. :skull_and_crossbones: Here be :dragon:!", "See other examples of creating a policy.  We create the policies separately instead of inline.", "See other examples of creating a policy.  We create the policies separately instead of inline.", "I'm not against putting this user in a path, but we (the devs) need to come to a consensus as to how we want to organize them.  I don't think `system` is a very specific or useful classification.", "See previous comment about paths.", "I like the very specific permissions.  Nice job!", "These permissions are identical to those of the read user.  This needs to be fixed (maybe `GetObject` should be `PutObject`) or one of these users should be removed as it is unnecessary.", "Throughout this file you have `become: no`, but these lines are not needed since `become` defaults to `no`.", "Just a reminder that this step will have to be deconflicted (possibly removed) once we move cyhy-feeds on to the Production mongo instance.", "Remove duplicated block", "Update description text", "Fix unresolved merge here", "More merge cleanup needed here", "This line can be removed since we no longer use static private IPs.", "I was just using the default example from terraform documentation. I have no problem changing it to something to be more uniform: https://www.terraform.io/docs/providers/aws/r/iam_user.html", "I wouldn't specify a path unless we have a scheme for organizing users.  (The path is optional and defaults to `/`.)", "The \"become: no\" is needed because it is a local_action that will want to run as sudo requiring a password", "This was not the local, but on the AWS instance. Switching to cyhy user. ", "\ud83d\udc4d ", "My bad on that- sorry!", "Uncommenting and pushing commit.", "```suggestion\r\n- name: import nsd daily public key\r\n```", "```suggestion\r\n# Run nightly at 0815 (UTC) as cyhy\r\n```\r\nSo that @jsf9k doesn't freak out \ud83d\ude04 ", "This duplication is still present", "Just checking to make sure you're aware that the machines are on UTC time.  So this will run at 0415 EST or 0315 EDT.  This is probably the intent.", "This should be \"moe_user_read\".", "It doesn't matter what time it runs as long as it is daily.", "Made this an issue to not lose track: https://github.com/dhs-ncats/cyhy_amis/issues/129#issue-372051958"]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/123", "comments": ["@jsf9k I don't think you meant to leave this test AMI in here.  Also, don't forget to put the ami_regions back in.", "@jsf9k Ditto here.", "Great idea to add this script! \ud83d\udc4d ", "Doh!"]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/119", "comments": ["I think this should instead say, \"Allow ingress from public subnet (bastion) via the...\".  Nothing unsolicited can come in via the NAT gateway.\r\n\r\nAlso, the Nessus UI port has nothing to do with the port scanners and can be dropped here.", "I don't think we need to allow ingress from anywhere via the Nessus UI port.  At this point the only way to access the Nessus UI is via ssh port forwarding.", "Similarly to the comment at the beginning of `cyhy_portscanner_acl_rules.tf`, his comment should read, \"Allow ingress from the public subnet (bastion) via...\".\r\n\r\nThis is the one place where the reference to the Nessus UI port should remain, since we will want to be able to access that port via ssh port forwarding.", "Clever!  I like it.", "@jsf9k good catch!", "Agreed!", "\ud83d\udc4d "]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/118", "comments": ["Good catch... ?\r\nHow about that \") ,2)\" ", "We'll have to revisit this for IPv6.  ", "What happened to our multiple database support?", "Now fixed.", "Agreed, but that was true before too.", "It's back."]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/111", "comments": ["Good catch!"]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/103", "comments": ["This could be dangerous if this host had a public IP.  I'm not sure we want to bother with passing in the instance's private IP and binding only to `localhost` and the private IP, but we should probably at least add a comment describing that this is safe in our environment.\r\n\r\nWe don't want to come along later and blindly reuse this in an environment where we lack the proper network controls."]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/100", "comments": ["Should this be the private IP?  I copied what was done in the CyHy VPC, but this doesn't seem correct.", "@felddy, care to comment about this?", "I'm trying to find where @jsf9k  copied this from.  The private bastion entries I wrote don't reference the `public_ip`:\r\nhttps://github.com/dhs-ncats/cyhy_amis/blob/bb304156750f0028b453ff6bef94bca92b9da700/terraform/cyhy_private_dns.tf#L35\r\n\r\nAlso, the entries in route53 look correct in production.  \r\n", "You are correct sir. I don't know where I got that from."]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/96", "comments": ["Name can be a list, like this:\r\n```\r\nname:\r\n  - curl\r\n  - unzip\r\n```\r\n\r\nSo you could combine both installs into a single Ansible command.\r\n\r\nIf you do make this change, can you also change \"it is\" to \"they are\" in the comment?", "Good catches, thanks @jsf9k!"]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/86", "comments": ["What about using `logging` instead of `print` statements?", "I like imports to be sorted in three groups in this order:\r\n* Python built-ins\r\n* External dependencies\r\n* Local dependencies\r\n\r\nThen, within each group, I like the imports to be sorted alphabetically.  This makes it easy to find imports as the list grows in length.\r\n\r\nWhat do you think about doing that here?", "Remove `correctlyself` and replace with `correctly`. :smiley: "]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/68", "comments": ["We need to add another S3 secret for the default report-key.  Let me know if you need any clarification on this.", "We have to discuss if/where we are going to store the reports each week after they are generated and sent out."]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/67", "comments": ["I personally like imports to be in alphabetical order, so I can quickly find the one I'm looking for or determine that one is missing.", "If only OCD were the extent of my problems, @KyleEvers!", "So you think line 71 is always going to be line 71, huh?  That's adorable.", "No good deed goes unpunished!", "I don't think this line is valid.  Shouldn't it be:\r\n`headers = {'X-Cookie': 'token={!s}'.format(self.token)}`"]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/66", "comments": ["I might add a comment in here about why we are doing this.  Describe the stateful behavior of security groups, and how it can get bogged down with connection state monitoring.  Maybe even put in the handy URL to the article.  (This will inevitably make that article go 404) \r\n\r\nI think these comments will be helpful for future \"us\", and external developers that use CyHy in the future.  ", "Good call- I will put something in there now and we can add to it after we (hopefully) get some further insights from AWS Support.", "Maybe it's time to think about a pre-processor for the provisioners.  Getting too \ud83d\udca6WET\ud83d\udca6.  Need to \ud83c\udf78DRY\ud83c\udf35 out.  ", "Very good comment.  I am now smarter for having read it.  \ud83c\udf93"]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/50", "comments": ["It is unclear to me how we want to store license keys and distribute them.  Or perhaps we just want to let this continue to be a manual step, which would require the updating of plugins to be manual as well.  We could add a script to the AMI that handles both, given the license key as input.", "I can't do this until a license key is registered.  See above.", "It's attention to detail like this that keeps us on the CRITICAL PATH!  ", "# :boom: CRITICAL PATH :volcano: #", "Since license keys are one and done, they're not too sensitive.  I'd think a sidecar yml file would be fine.  I used to associate them to the hosts in the old ansible inventory file.  We could define a variable in terraform, not set a default, and it will prompt the user to input it.  ", "Not a bad idea.  We could define said variable in the `production.tfvars` file, so the user isn't prompted in that case.", "This change has been made."]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/46", "comments": ["The regexp doesn't need to be this verbose.  Unless you're worried about not getting the quiet.\r\n", "Good point- I can trim it down, but I did want the --quiet in there.  I'll get rid of the --config part.", "I mean, it could even be shorter.  \r\n^ExecStart=  \r\nThere is only one ExecStart line I'm guessing, and you want it. "]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/44", "comments": ["You could use the Ansible module [`get_url`](https://docs.ansible.com/ansible/latest/modules/get_url_module.html) here and for the two similar lines below.  I think that's a little cleaner than `shell`.", "See comment above.", "See comment above."]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/19", "comments": ["@jsf9k What do you think about using some sort of naming convention for our workspaces, e.g. \"jsf9k_test\" vs. \"jsf9k_prod\" and have our logic look for those substrings?", "@dav3r, that makes sense.  How about if the workspace name contains \"production\" then use the \"real deal\" instance types?\r\n\r\n(I don't like prod because four letters seems too little...what if we hire Auguste Prodin?)", "@jsf9k, workspace name contains \"production\" works for me.", "Implemented in #24."]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/15", "comments": ["This isn't working.  :angry:   I need to fix this before we merge.", "There are a couple other changes that I made to the mongo config file (located at /etc/mongod.conf, not /lib/systemd/system/mongod.service), so let's coordinate on those too."]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/12", "comments": ["I asked @dav3r if this change was intentional, and he said it was.  When he booted up in Jessie the root volume had two partitions, which broke the old logic.  He amended the logic to work in both cases."]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/6", "comments": ["Comment should be \"The docker AMI\".  Probably needs to be updated in the main terraform dir too.", "1024"]}, {"url": "https://github.com/cisagov/cyhy_amis/pull/5", "comments": ["Did you mean to put \"mongo\" in here or is that a copy/paste error?", "Good catch, @dav3r! :trophy: "]}]}, {"url": "https://github.com/KryptionX/aws-instance-test.git", "pull_requests": []}, {"url": "https://github.com/virmis/tfactions.git", "pull_requests": []}, {"url": "https://github.com/mnovelo82/terragoat.git", "pull_requests": []}, {"url": "https://github.com/fairbanksio/tf-iac-cluster.git", "pull_requests": [{"url": "https://github.com/fairbanksio/tf-iac-cluster/pull/56", "comments": ["Space", "api -> API?", "Should we rename these now?", "If you use `[ ]` here, it creates a checkbox. :) ", "It's in todo's I suppose"]}]}, {"url": "https://github.com/olliefr/aws-terraform-cloud1.git", "pull_requests": []}, {"url": "https://github.com/InvictrixRom/website-infrastructure.git", "pull_requests": []}, {"url": "https://github.com/DanTulovsky/wetsnow-tf0.git", "pull_requests": []}, {"url": "https://github.com/tjpotenza/kubernetes-modules.git", "pull_requests": []}, {"url": "https://github.com/Wood1216L/New_Project2.git", "pull_requests": []}, {"url": "https://github.com/Harmelodic/automation-infrastructure.git", "pull_requests": []}, {"url": "https://github.com/JamesWoolfenden/terraform-aws-vpc-peering.git", "pull_requests": []}, {"url": "https://github.com/garylb2/terraform-example-patterns.git", "pull_requests": []}, {"url": "https://github.com/ChicagoWorldcon/infrastructure.git", "pull_requests": []}, {"url": "https://github.com/gstimac/terralab.git", "pull_requests": []}, {"url": "https://github.com/naciriii/terraform-ec2-gitlab-runner.git", "pull_requests": []}, {"url": "https://github.com/JamesWoolfenden/terraform-aws-codepipeline.git", "pull_requests": []}, {"url": "https://github.com/krishna98967/git-terraform-testing.git", "pull_requests": []}, {"url": "https://github.com/kscastro/localstack-with-terraform.git", "pull_requests": []}, {"url": "https://github.com/bridgecrew-demo/terragoat.git", "pull_requests": []}, {"url": "https://github.com/Andrew-Klaas/aws-simple.git", "pull_requests": []}, {"url": "https://github.com/Arkoprabho/TerraformTutorial.git", "pull_requests": []}, {"url": "https://github.com/gordonmurray/terraform_aws_rds_secrets_manager.git", "pull_requests": []}, {"url": "https://github.com/uk-gov-mirror/ministryofjustice.digital-studio-infra.git", "pull_requests": []}, {"url": "https://github.com/aristanetworks/CloudEOS.git", "pull_requests": []}, {"url": "https://github.com/Kalmalyzer/UE-Jenkins-BuildSystem.git", "pull_requests": []}, {"url": "https://github.com/davidjsanders/tf-learning.git", "pull_requests": []}, {"url": "https://github.com/JamesWoolfenden/terraform-aws-waf-regional.git", "pull_requests": []}, {"url": "https://github.com/joatmon08/expense-report.git", "pull_requests": []}, {"url": "https://github.com/forgotpw/forgotpw-infrastructure.git", "pull_requests": []}, {"url": "https://github.com/I0D8ivT2/hashicat-aws.git", "pull_requests": []}, {"url": "https://github.com/dshmelev/aws_kube_tc.git", "pull_requests": []}, {"url": "https://github.com/lalanza808/tf-modules.git", "pull_requests": []}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory.git", "pull_requests": [{"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/885", "comments": ["not marking as breaking since this is Internal module and modules using this module are already 4+", "Should this be a map(string) because you can specify the key name on `google_tags_tag_key`?", "Why are you setting up tags as part of the setup?", "Ah this was because I wanted use random ID in tags to prevent conflicts. I originally had it within example but got unknown values in for_each error, so moved to setup.", "I chose a list because we weren't passing in key information. I have addressed the main comment about why not include `google_tags_tag_key` too below.", "This should be safe with bpt v0.12+, however do you still want to init all at the start?", "Would `null` work/be better?\r\n\r\n```suggestion\r\n  default     = null\r\n```", "I removed the single init for now"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/843", "comments": ["Are we keeping this so as not to break incase of null/random provider major updates?", "Since this is a module versions let's keep the <6.0?", "Yup, good catch, probably a bad find criteria.", "I only pulled the google, google-beta, let me expand to the rest in examples.", "IMO we could just remove versions.tf from examples", "Yeah - I will try that.", "Two examples use a provider that is not required by any modules, so need to keep those, but we can remove the rest."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/788", "comments": ["Instead of adding this new variable and trigger key/value pair we could do something like \r\n`export TF_VAR_policy_id=$(gcloud access-context-manager policies list --organization=\"${TF_VAR_org_id:?}\" --format=\"value(name)\")` as part of the args to the `prepare` step where this is need. That would eliminate the need for the new output and variable as well.", "If we use the gcloud command to evaluate the policy id during the prepare step, we could probably get rid of this.", "We already have following lines in cloudbuild but for some reason it does not work. \r\n```\r\n- id: converge vpc-sc-project-local\r\n  waitFor:\r\n      - create-all\r\n  name: 'gcr.io/cloud-foundation-cicd/$_DOCKER_IMAGE_DEVELOPER_TOOLS:$_DOCKER_TAG_VERSION_DEVELOPER_TOOLS'\r\n  args: ['/bin/bash', '-c', 'source /usr/local/bin/task_helper_functions.sh && export TF_VAR_policy_id=$(gcloud access-context-manager policies list --organization=\"${TF_VAR_org_id:?}\" --format=\"value(name)\") && kitchen_do converge vpc-sc-project-local']\r\n```", "Got it. Ok let's leave the issue open so we can investigate what's happening. I'll merge this for now."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/766", "comments": ["@daniel-cit can we keep the same resource name so we can release this in a minor release?\r\nWe can add a comment to clean up for next breaking change.", "```suggestion\r\n  description = \"The duration to sleep in seconds before adding the project to a shared VPC after the project is added to the VPC Service Control Perimeter. VPC-SC is eventually consistent.\"\r\n```", "resource rename change reverted", "Description updated"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/738", "comments": ["```suggestion\r\n```", "```suggestion\r\n```", "```suggestion\r\n```", "```suggestion\r\n```", "```suggestion\r\n```", "Lets move `var.calendar_period == \"CUSTOM\"` to a boolean local and we can reuse it here and below.", "Might be simpler to express this as `DD-MM-YYYY`", "Lets plumb some of these inputs to the main module\r\nhttps://github.com/terraform-google-modules/terraform-google-project-factory/blob/9410ca40050668535068968a1a18a3ecfda915d7/main.tf#L90", "nit: lets prefix these vars used in root module with `budget_`, so `budget_calendar_period` etc", "Lets split only if `custom_period`", "We should not give default date since we will expect user to change this. We can give a default null.", "Same as above", "Let's call out that `custom_period_start_date` and `custom_period_end_date` must be set if `CUSTOM`"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/735", "comments": ["WDYT about just having `random_project_id_length` as an optional. If `random_project_id_length` is set it uses the new method?", "Do we need to ignore changes during normal usecase or is this for the import workflow? Would be good to add a comment.", "Since this is no longer breaking, let's move this to faq or troubleshooting docs?", "This was for import, but as that is no longer a relevant workflow I will remove it.", "With the new single variable method, I don't think it's required at all, so I'll drop it completely.", "SG - @bharathkkb PTAL as this was a rather major change.", "@apeabody LGTM"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/733", "comments": ["We should keep line btw blocks for readability.", "We usually do description followed by value. Lets revert these.", "Any reason why we are bumping versions?", "We should not need to bump this. currency_code seems to not need 4.11?", "We should not change providers here and throughout", "@drandell - Is there a reason to bump the minimum version for core_project sub-module?  If not, let's please leave as-is as the sub-module could be used independently of the main module or sub-modules that require 4.5.\r\n\r\nFYI: `~> 4.11` is functionally the same as `>= 4.11.0, < 5.0.0`"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/725", "comments": ["`project-num@cloudservices.gserviceaccount.com` is the API service agent which exists at project creation and not tied to `deploymentmanager.googleapis.com`. We grant this the necessary roles in core project factory. \r\nhttps://github.com/terraform-google-modules/terraform-google-project-factory/blob/d309270a6c6ace6e2b5bc792073bfee9a07c365d/modules/core_project_factory/main.tf#L41-L44\r\nhttps://github.com/terraform-google-modules/terraform-google-project-factory/blob/d309270a6c6ace6e2b5bc792073bfee9a07c365d/modules/core_project_factory/main.tf#L179-L191\r\nAre you using a different module for project creation?", "Hi @bharathkkb,\r\n\r\nthanks for the fast reply and sorry for the confusion. \r\n\r\nI thought it's tied to `deploymentmanager.googleapis.com` because of this article:\r\nhttps://cloud.google.com/deployment-manager/docs/access-control#access_control_for\r\n\r\n```\r\nAccess control for Deployment Manager\r\n\r\nTo create other Google Cloud resources, Deployment Manager uses the credentials of the Google APIs Service Agent to authenticate to other APIs. The Google APIs Service Agent is designed specifically to run internal Google processes on your behalf. This service account is identifiable using the email:\r\n\r\n[PROJECT_NUMBER]@cloudservices.gserviceaccount.com\r\n```\r\n\r\nWe are creating the service projects in an environment other than the network host project containing the shared VPC.\r\n\r\nThe network host project exists before the service projects are deployed in our deployment chain & the `shared_vpc_access`-module is used in the same environment where the service projects are deployed.\r\n\r\nFor creating network host projects and service projects we use the project-factory module in the following manner:\r\n\r\n```\r\n  source                  = \"terraform-google-modules/project-factory/google\"\r\n  version                 = \"~> 11.3\"\r\n```\r\n\r\nTo be honest, our DEV-teams are enabled to manage the `shared_vpc_iam`-roles by their own & it could be that they have overwritten the `networkUser`-role in their subnets.\r\n\r\nTomorrow I'll try to create a clean environment to check if the missing IAM-role assignments are in place to check if we had a unlucky conflict.\r\n\r\nThanks again!\r\n\r\nCheers!", "Hi @bharathkkb,\r\n\r\nOne addtition:\r\n\r\nWe use the `shared_vpc_access`-module instead of providing the network host project info to the `project-factory`-module because in the past we had issues with it.\r\n\r\nWe used the following attributes to bind the created service projects to the existing network host projects:\r\n\r\n```\r\n svpc_host_project_id\r\n shared_vpc_subnets\r\n grant_services_security_admin_role\r\n```\r\n\r\nIn some cases Terraform stated replacements of `google_project`-resources from the `project-factory` when something has changed in our network host projects.\r\n\r\nTo be honest, it's long time ago when we made the switch from the three attributes from the `project-factory` to the `shared_vpc_access`-module and I cannot find the related Terraform-plan-output to prove it and to figure out what in detail triggered the replacements.\r\n\r\nNevertheless is it possible in general to include the API service agent into the `shared_vpc_access`-module?\r\n\r\nIf yes, let me know which API should be provided.\r\n\r\nAnother option could be that I add a new module-attribute to assign the permissions to the API service agent, if there is no related API to the API service agent.\r\n\r\nIf you have another suggestion, just let me know.\r\n\r\nIf nothing helps, please, just decline my PR and we'll assign the permissions without the `shared_vpc_module`.\r\n\r\nCheers!", "@bestefreund sorry for the late reply.\r\n> In some cases Terraform stated replacements of google_project-resources from the project-factory when something has changed in our network host projects.\r\n\r\nThis seems like a bug, if you encounter this again feel free to open an issue.\r\n\r\n>  Is it possible in general to include the API service agent into the shared_vpc_access-module\r\n\r\nThis seems reasonable although we may need to do some investigation if it can co exist without a flag for https://github.com/terraform-google-modules/terraform-google-project-factory/tree/master/modules/svpc_service_project. If you can open an issue, we can discuss adding it there.\r\n"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/724", "comments": ["@nikhilmakhijani - I don't believe even a deleted `project_id` can be reused, please see: https://cloud.google.com/resource-manager/docs/creating-managing-projects#before_you_begin\r\n\r\n\"Cannot be in use or previously used; this includes deleted projects.\"", "```suggestion\r\nThis variables adds a suffix of 4 random characters to the `project_id` provided. It is important to note that once you delete a project you can't use the same `project_id`. `random_project_id` comes in handy in such situations (specially during testing) since it allows you to create and shut down projects without conflicts.\r\n```", "```suggestion\r\n## Requirement for `random_project_id`\r\n```"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/700", "comments": ["I think this is unnecessary since we have upgrade guides and release notes now. We can remove this and the one below it.", "Sure - Would you like a new upgrading_to_project_factory_v12.0.md?  Or do you think the existing v12 release notes are sufficient?", "@apeabody I think we can skip v12 since release is out anyway but could you append to the v13 release notes that some submodules like `modules/project_services` now require 4.5 since we are unifying them. Some submodules like `project_services` tend to get used standalone", "Hi @bharathkkb for simplicity I've limited this to allowing TPG 4.0 on the remaining tests and updating everything to the TF 0.13+ format.  That way will not impact the minimum version individually of any of the submodules."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/697", "comments": ["I am inclined to rename this from `grant_services_network_role` to `grant_network_role` since this is no longer limited to service agents.", "Lets add a test to make sure we wont have regressions in the future\r\nhttps://github.com/terraform-google-modules/terraform-google-project-factory/blob/master/test/integration/dynamic_shared_vpc/controls/svpc.rb", "```suggestion\r\n### `grant_services_network_role` renamed to `grant_network_role`\r\n```", "Lets add also confirm via a test that binding is added for a different service projevt where the flag is true(i.e by default). Maybe https://github.com/terraform-google-modules/terraform-google-project-factory/blob/616ede9456cc8f86ef7995192af3473d17ee7946/examples/shared_vpc/main.tf#L112", "this test scenario is cover for the [service-project](https://github.com/terraform-google-modules/terraform-google-project-factory/blob/63c7b40d5244d6472d6a22f8767c736987ef7e48/test/integration/dynamic_shared_vpc/controls/svpc.rb#L73-L80)", "```suggestion\r\n      it \"service project with explicit subnets includes project default service account in the roles/compute.networkUser IAM binding\" do\r\n```"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/683", "comments": ["Lets check if gcloud is available. If not, I am leaning towards using https://pkg.go.dev/golang.org/x/oauth2/google#DefaultClient to make the request. We can add a helper to the test framework if there is verbose logic. Based on the API doc, something like below is what I was thinking\r\n\r\n```go\r\nhttpClient, err := google.DefaultClient(oauth2.NoContext,\r\n\t\t\"https://www.googleapis.com/auth/cloud-platform\")\r\n\tif err != nil {\r\n\t\tt.Fatalf(\"\",err)\r\n\t}\r\nresp, err := httpClient.Get(runEndPointUrl)\r\n\tif err != nil {\r\n\t\tt.Fatalf(\"\",err)\r\n\t}\r\n\t// use utils.ParseJSONResult on resp.Body \r\n```\r\n", "nit: newer versions of the framework has a Runf method which is a bit cleaner\r\n```suggestion\r\n\t\tapis := gcloud.Runf(t, \"services list --project %s\", projectID)\r\n```", "nit: since we already have assert. https://pkg.go.dev/github.com/stretchr/testify/assert#NoError\r\n```suggestion\r\n\t\tassert.NoError(err)\r\n```", "here and throughout", "This seemed a bit confusing - reworded slightly based on fixture\r\n```suggestion\r\n\t\tassert.False(result.Get(\"overrides.0.dimensions\").Exists(), \"has empty dimensions\")\r\n```", "close body to prevent leaks\r\n```suggestion\r\n                defer resp.Body.Close()\r\n\t\tbody, err := io.ReadAll(resp.Body)\r\n```"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/640", "comments": ["terraform fmt seemed to add this\r\n\r\n```\r\n$ terraform version\r\nTerraform v1.0.11\r\non linux_amd64\r\n```", "I tried to follow the pattern in the rest of this module, this shouldn't do anything if the setting isn't set, otherwise it just passes through whatever the user defines. This seems like a safe way to implement this module, to avoid interfering with any existing installs", "Thanks, sounds good to me!", "Since this is a map of strings, can you change it to `map(string)`?", "Clarify that if unset this value isn't updated at all.", "thanks, added the following text (bolded for emphasis here):\r\n\r\n>Default Network Service Tier for resources created in this project. **If unset, the value will not be modified.** See https://cloud.google.com/network-tiers/docs/using-network-service-tiers and https://cloud.google.com/network-tiers.", "makes sense, done!"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/628", "comments": ["This logic can be simplified:\r\n\r\n```suggestion\r\n  activate_compute_identity = contains(var.activate_api_identities, \"compute.googleapis.com\")\r\n```", "Oh cool didn't know that worked for keys in maps. Thanks!", "Oh actually it might not. Nevermind.", "We could use a splat expression if that is better. Could change the two lines like this:\r\n```\r\n  activate_compute_identity = contains(var.activate_api_identities[*].api, \"compute.googleapis.com\")\r\n  services                  = var.enable_apis ? toset(concat(var.activate_apis, var.activate_api_identities[*].api)) : toset([])\r\n```", "I ended up merging your original approach since it worked fine."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/627", "comments": ["Can we test this by modifying this example to add a label\r\nhttps://github.com/terraform-google-modules/terraform-google-project-factory/blob/e444e2ae47632bfc7f1c060be6db1ab15e1cfb9d/examples/budget_project/main.tf#L40", "Sure. I will probably do that as a separate commit (rather than squashing all together)", "Addressed in 21b5c81", "Lets hardcode this in examples\r\n```suggestion\r\n  labels                 =  {\r\n    \"cost-center\" : \"dept-x\"\r\n  }\r\n```", "Lets bump these to `~> 4.5` here and throughout since that will be the min supported provider version", "Just to be explicit: if we expose this feature at the top level it imposes a 4.5+ requirement. you're willing to do that?", ">  if we expose this feature at the top level it imposes a 4.5+ requirement\r\n\r\nThe budget submodule [already](https://github.com/tpdownes/terraform-google-project-factory/blob/9ef4da545aaa6240664553eb900b84f0d79ac8de/modules/budget/versions.tf#L23) has 4.5+ requirement which would then add that as a version constraint to the [top level](https://github.com/terraform-google-modules/terraform-google-project-factory/blob/40ba6da63e7b6d548ceee8235361ed96bf8517e5/main.tf#L88-L99). For instance, in the [minimal fixture](https://github.com/terraform-google-modules/terraform-google-project-factory/tree/master/test/fixtures/minimal), this would be evaluated to \r\n```\r\nFinding hashicorp/google versions matching \">= 3.50.*, < 5.0.*, >= 3.50.*, < 5.0.*, >= 4.5.*, < 5.0.*, >= 3.43.*, < 5.0.*, >= 3.50.*, < 5.0.*, >= 3.43.*, < 5.0.*, >= 3.43.*, < 5.0.*\"\r\n...\r\nInstalling hashicorp/google v4.6.0...\r\n ```", "I see your point. I had been deliberately avoiding imposing 4.5+ on the top-level module but didn't realize (or look hard enough) that it imposes that requirement. Since it does, yeah, I agree entirely that we should just expose the variable through the top-level.", "Done on `HEAD`", "On `HEAD`, I believe that I've updated every submodule, test, and example to use `~> 4.5` if they touch the budget features. The remaining modules allow 3.x (above some minimum) and 4.x at the same time.", "Can we open an issue to track revert of this in the future?", "Lets pin to latest major for other modules \r\n```suggestion\r\n  version = \"~> 4.1\"\r\n```", "Any blockers pinning to \"~> 4.5\"?\r\n```suggestion\r\n      version = \"~> 4.5\"\r\n```", "No blockers, but it is not an accurate claim about the requirements.", "OK", "You want me to do this before PR is merged?", "Done", "The other similar examples are `fabric_project`, `project-hierarchy`, and `project_services`.", "@tpdownes we try to pin to a single major version when it comes to examples as they are not meant to be used as modules and do not require broad compat like a module.", "I've pinned all `google{-beta}` provider versions in the examples to `~> 4.5`.", "I think it makes the most sense to open this issue immediately after PR is closed to ensure I point to the right commit hash to revert. I've left this specific change as its own commit."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/618", "comments": ["nit: since we are gating `networkUser` role and service agent related roles which do not manage FW rules\r\n```suggestion\r\n  description = \"Whether or not to grant service agents the network roles on the host project\"\r\n```"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/617", "comments": ["Lets add this to .gitignore", "This submodule should be composed in the main module similar to [budget](https://github.com/terraform-google-modules/terraform-google-project-factory/blob/87d2df092daa2ea5efd36a98fbbd946ce5722bf7/main.tf#L84)", "I think we can default these to the values specified here as they will be most common", "WDYT about the config being notification_category_subscriptions=>contacts and language being common for all the contacts?\r\n```tf\r\nessential_contacts_config = {\r\n  \"ALL\" = [ \"user1@foo.com\",\"group1@foo.com\"],\r\n  \"SECURITY, TECHNICAL\" = [ \"security@foo.com\"],\r\n  \"TECHNICAL\" = [ \"app@foo.com\"]\r\n}\r\nlanguage_tag = \"en-US\"\r\n\r\n", "nit: Update readme", "the google_essential_contacts_contact resource is natively set up to accept an array of subscription categories per contact email - which allowed for easy nesting of the configs. The downside to this is that they could not set up multi-language notifications. Perhaps that is an edge case", "I'd prefer to avoid using comma-delimited lists when we can use native lists instead.\r\n\r\nThere's probably some room for more brevity in this config though. What if we dispensed with the lists entirely and instead just specified the categories for each user.\r\n\r\n```\r\nessential_contacts = {\r\n  \"user1@foo.com\" = [\"ALL\"],\r\n  \"security@foo.com\" = [\"SECURITY\", \"TECHNICAL\"],\r\n  \"app@foo.com\" = [\"TECHNICAL\"]\r\n}\r\nlanguage_tag = \"en-US\"\r\n```\r\n  ", "The above approach sgtm @gtsorbo ", "Test will also need to be added here to run in CI\r\nhttps://github.com/terraform-google-modules/terraform-google-project-factory/blob/87d2df092daa2ea5efd36a98fbbd946ce5722bf7/build/int.cloudbuild.yaml#L128-L147", "CI test image will also need to be bumped\r\nhttps://github.com/terraform-google-modules/terraform-google-project-factory/blob/87d2df092daa2ea5efd36a98fbbd946ce5722bf7/build/int.cloudbuild.yaml#L153", "```suggestion\r\n  description = \"Language code to be used for essential contacts notifications\"\r\n```", "Can we use the new framework instead? We are trying not to add new tests using the old framework", "Lets use newer approach syntax for versioning\r\nhttps://github.com/terraform-google-modules/terraform-google-network/blob/master/examples/simple_project/versions.tf", "Old readme?", " @gtsorbo I think this change was not applied or got lost in the rebase?", "nit: extra lines", "```suggestion\r\n * Copyright 2022 Google LLC\r\n```", "```suggestion\r\n      version = \">= 3.43, <5.0\"\r\n```", "```suggestion\r\n      version = \">= 3.43, <5.0\"\r\n```", "```suggestion\r\n    module_name = \"blueprints/terraform/terraform-google-project-factory:essential_contacts/v11.1.1\"\r\n```", "```suggestion\r\n    module_name = \"blueprints/terraform/terraform-google-project-factory:essential_contacts/v11.1.1\"\r\n```", "```suggestion\r\n  version = \"~> 4.0\"\r\n```", "We can remove this from here", "We can remove this", "We are trying to use 4.0+ in examples/tests", "Looks like it just a readme update thats needed", "I think outputting https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/essential_contacts_contact#name is more useful", "Now you can use the CLI to simplify this\r\nhttps://github.com/terraform-google-modules/terraform-google-event-function/pull/87\r\n```suggestion\r\n  args: ['/bin/bash', '-c', 'cft test run TestEssentialContacsExample --stage init --verbose']\r\n```", "nit: since we are making this the standard\r\n```suggestion\r\n- id: init-essential-contacts-example\r\n```", "We are trying to move away from fixtures in general. Could we instead move this into the example and invoke via `\"project-factory` rather than the submodule?", "We can remove this now", "we can remove this", "Lets use latest release. You can update via `go get -u github.com/GoogleCloudPlatform/cloud-foundation-toolkit/infra/blueprint-test`\r\nhttps://pkg.go.dev/github.com/GoogleCloudPlatform/cloud-foundation-toolkit/infra/blueprint-test?tab=versions", "nit: rather than using gjson syntax we prefer expressing test logic in golang. Some pseudocode below as an example \r\n```suggestion\r\n\t\tessentialContacts := gcloud.Run(t, fmt.Sprintf(\"essential-contacts list --project %s\", projectID)).Array()\r\n\t\tfor _, contact := range essentialContacts{\r\n\t\tassert.Equal(\"en-US\", contact.Get(\"languageTag\").String(), \"has correct language tag\")\r\n\t\temail := contact.Get(\"email\").String()\r\n\t\tswitch email {\r\n\t\t  case \"app@foo.com\":\r\n\t\t     assert. ElementsMatch([]string{\"TECHNICAL\"},utils.GetResultStrSlice(contact.Get(\"notificationCategorySubscriptions\").Array()))\r\n\t\t}\r\n\t\t}\r\n\t\t\r\n```", "```suggestion\r\n  description = \"The GCP project with essential contacts\"\r\n```", "nit: fix descriptions"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/614", "comments": ["Any reason not to use `setintersection` since both are known values at plan time? ", "index looks unused\r\n```suggestion\r\n    for api in local.active_apis : [for subnet in var.shared_vpc_subnets : \"${api},${subnet}\"]\r\n```", "Not sure if this works but if we made the output into a list of maps, we could avoid the nested split - something like \r\n\r\n```tf\r\nfor i, api in local.active_apis : [for i, subnet in var.shared_vpc_subnets : {api: api, subnet: subnet}]\r\n```\r\n\r\n```tf\r\nelement(\r\n    split(\"/\", local.subnetwork_api[count.index].subnet),\r\n    index(\r\n      split(\"/\", local.subnetwork_api[count.index].subnet),\r\n      \"subnetworks\",\r\n    ) + 1,\r\n  )\r\n  ```\r\n"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/613", "comments": ["```suggestion\r\n[Default SAs](https://cloud.google.com/iam/docs/service-accounts#default) can be removed by setting `default_service_account` input variable to `delete`, but there can be certain scenarios where the default SAs are required. Hence some considerations to be aware of:\r\n```"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/608", "comments": ["From the issue it seems like we only need this if `var.vpc_service_control_attach_enabled`?\r\nMight be good to make this a conditional creation via `var.vpc_service_control_attach_enabled ? 1 : 0`", "@bharathkkb yes sure good point, ill push the change"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/601", "comments": ["Doesn't depends_on = [google_project. project] work?", "I'm not sure which depends_on you're asking:\r\n1. if you're asking about depends_on here in output then no, changing \r\n```hcl\r\n  depends_on  = [google_project_service.project_services]\r\n```\r\nto \r\n```hcl\r\n  depends_on  = [google_project.project]\r\n```\r\ndoes not work. Terraform ignores this explicit dependency when it has the output value available immediately. This is especially the case when output value comes from input attribute. \r\n\r\n2. If you're asking whether explicit depends on module.project works e.g. in a datasource that is using this output, then yes, it's working. But please see my comment in main thread. \r\n```hcl\r\ndata \"google_storage_project_service_account\" \"gcs_account\" {\r\n  project = module.project.project_id\r\n  depends_on = [module.project]\r\n}\r\n```", "I see, I assumed depends_on may block on `google_project.project` since some of the attribs are computed.\r\n"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/574", "comments": ["This isn't the right source. What are you trying to show with this example?", "I'm trying to add some Terraform tabs to this page: https://cloud.google.com/vpc/docs/provisioning-shared-vpc#setting_up", "Got it. This isn't the right example for that, as this actually *creates* the host project. Is that what you want to do?\r\n\r\nIf you just want to activate Shared VPC on an existing project, a new example would be needed.", "Got it. Thanks for the guidance. I'm closing this PR and starting over with a new example."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/569", "comments": ["@lawliet89 could we keep >=0.12.6 as in all other modules?\r\n\r\nhttps://github.com/terraform-google-modules/terraform-google-project-factory/pull/505/files", "We've switched to requiring 0.13."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/559", "comments": ["We shouldn't touch the old upgrading docs as we won't be backporting this change.", "ah in that way, sure, will roll it back :)"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/550", "comments": ["What I think you're going to need to do is:\r\n\r\nKeep the `for_each` the same (iterating over the project_id).\r\n\r\nInside the resource itself, look up the number from the data source.", "I was able to repro using the integration tests. Not all tests are working (I don't think the errors are related to my changes) but the billing test seems ok now.\r\n\r\nSwitching from `for_each` to `count` seems to solve the issue.", "Thanks, looks like that worked."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/545", "comments": ["This description isn't accurate. Please make it clearer that Terraform will force-delete objects in the bucket (*not* fail) if this setting is active.", "@morgante I've just pushed a different description. Hopefully it's clearer this time. If you still want changes let me know what description you'd like."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/531", "comments": ["This should also still test for `var.create_project_sa`.", "To preserve backwards-compatibility, let's continue accepting `sa_role` on the \"outer\" modules but add a note to the description that it is deprecated."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/518", "comments": ["nit: not from this PR but for readability\r\n```suggestion\r\nRemove any references to `skip_gcloud_download` and `use_tf_google_credentials_env_var` if applicable.\r\n```"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/513", "comments": ["We shouldn't use add the `provider_meta` for internal modules so let's drop this section.", "sg; in that case should `shared_vpc` be an internal module or should we add a readme for it?", "We should add a README for it.", "done"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/500", "comments": ["I saw that you made this plural - `project numbers from data sources`. Aren't we just using a single data source to look up a single project ?", "I assume this is defensive naming for a future case where we might have to look up the host project number. Seems reasonable.", "Right, before it was a bit specific (lookup_service_project_number). But given @morgante comment above about continuing to support data sources, I imagine we may need to reuse this pattern in other places if this issue comes up, so using a generic/reusable var name will be more consistent for future uses.", "gotcha, thanks for clarifying."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/491", "comments": ["I don't think we need to make this configurable.", "it must be... if we DELETE the service account, the resource won't be able to revert after 30 days. So, the user must change to NONE.\r\nI proposed to keep track of when it was deleted and just try to undelete if less than 30 days, but Riley preferred to make configurable and change the value if error happens.", "It's fine for the behavior to be customizable on the provider, with the caveat that if set to \"REVERT\" I think the failure should not be an error (just a warning). /cc @rileykarson", "I disagree, I think. Terraform failing to do what you told it to (eg undeleting the deleted SAs) should result in an error. We could consider an additional option like \"REVERT_AND_IGNORE_FAILURE\" though.", "I think we can add another ENUM on_failure IGNORE or FAIL, but it would be an enhancement. I can work on it, but we should implement as-is for now.", "Normally, I agree. But I'm not sure an error which users can't resolve in any way is particularly helpful.\r\n\r\nI'd be fine if we wanted to split it to an additional `REVERT_AND_IGNORE_FAILURE` option instead though.\r\n\r\n@thiagonache Can you work on that? For this PR we can stick to `REVERT` and remove the configurability.", "> Normally, I agree. But I'm not sure an error which users can't resolve in any way is particularly helpful.\r\n> \r\n> I'd be fine if we wanted to split it to an additional `REVERT_AND_IGNORE_FAILURE` option instead though.\r\n> \r\n> @thiagonache Can you work on that? For this PR we can stick to `REVERT` and remove the configurability.\r\n\r\nI can for sure, but by making it configurable the user can take an action to change to NONE, no?\r\nAlso, any strong preference using REVERT_AND_IGNORE_FAILURE vs another ENUM on_failure with values IGNORE or FAIL? I prefer the second one, REVERT_AND_IGNORE_FAILURE looks odd but maybe it's just me being annoying.", "REVERT_AND_IGNORE_FAILURE imo- \"NONE\" and \"IGNORE\" doesn't make much sense to configure.", "I explicitly don't want this configurable. It's not configurable today and we don't shouldn't change the surface area of the module as part of this change.\r\n\r\nI'd prefer `REVERT_AND_IGNORE_FAILURE` as only this specific failure would be ignored (we would *not* ignore failures on original deletion, for example).", "If it is not going to be configurable, why do we want to have a variable?", "We don't. I want you to remove the variable.", "in the provider too? I mean in the provider", "we don't need to have a restore_policy variable there.", "There are two different things which need to happen:\r\n\r\n1. On the provider, update the `restore_policy` param to accept a `REVERT_AND_IGNORE_FAILURE` option.\r\n2. On this module, remove the variable for restore policy and hardcode to `REVERT_AND_IGNORE_FAILURE`.", "you mean it should accept REVERT and REVERT_AND_IGNORE_FAILURE on the provider? and hard code the content REVERT_AND_IGNORE_FAILTURE instead of using var on this module. that second part I understood", "yeah... it's clear now.", "Is it still unclear? Please remove the variable.", "I thought we are going to merge like that and just remove the variable when the provider handles the error... to me, it does not make sense to remove if it may cause an unrecoverable issue... but it's your call :)", "We can set to `DELETE` for now then and change to `REVERT_AND_IGNORE_FAILURE` once it's available in the module. I want to avoid introducing a variable we will remove soon after (as that will be yet another backwards-incompatible change).", "you mean REVERT, right?\r\nthe problem I see is if we delete the service account now and we have no variable the new version **must** be released in less than 30 days.", "I'm assuming you can work on a provider fix fairly quickly? We could also hold back this release until that's in.", "which I think is feasible unless something really bad happens.", "I'll be able to work on it next week and should take no more than one day. So, yeah, it's not a biggy to merge like that... we will have the new version before 30 days for sure", "Sounds good!", "We should not force users to change this. There's no reason we can't handle it easily in the module for them: https://www.terraform.io/docs/configuration/functions/upper.html", "We also need to note that users will need to remove any references to `skip_gcloud_download` and `use\\_tf\\_google\\_credentials\\_env\\_var`.", "Leave this unchanged to test the `upper()` functionality.", "i know the upper function... since it's a breaking change I just thought a cleaner way would be better. i was wrong again :)", "good catch.", "https://github.com/hashicorp/terraform-provider-google/pull/7768 I still need to work on tests but we can start to discuss it", "```suggestion\r\nRemove any references to `skip_gcloud_download and use_tf_google_credentials_env_var` if applicable.\r\n```"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/483", "comments": ["We could probably make this slightly more generic as future services might also need it.\r\n\r\n```suggestion\r\nvariable \"grant_services_security_admin_role\" {\r\n```", "Done."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/478", "comments": ["We shouldn't delete the tests.", "```suggestion\r\n    You can add one last check by setting the `--shared-vpc` parameter.\r\n```", "right... I should understand it first. Sorry."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/475", "comments": ["@umairidris I actually just noticed shouldn't this be \r\n```suggestion\r\n  description = <<EOF\r\n```", "D'oh! Good catch. It still isn't passing the docs generation though :("]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/468", "comments": ["Is `service` not required?", "We should also put this on the `gsuite` and `shared_vpc` submodules.", "We're trying to have examples use hard-coded values where possible, let's put a representative example in here.", "```suggestion\r\n| consumer\\_quotas | The quotas configuration you want to override for the project. | <pre>list(object({<br>    service = string,<br>    metric  = string,<br>    limit   = string,<br>    value   = string,<br>  }))</pre> | `[]` | no |\r\n```", "This should probably be indexed by service+metric. Ordered indexing is brittle."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/464", "comments": ["We shouldn't need this on the host project.", "Actually if it's the host project we should *not* set `shared_vpc` variable.", "Please leave the name unchanged on outer modules for backwards-compatibility.", "Please leave the name unchanged on outer modules for backwards-compatibility.", "```suggestion\r\n  description = \"If this project is a shared VPC host project. If true, you must set *not* shared_vpc variable. Default is false.\"\r\n```", "@morgante actually, no... shared_vpc is the name of the host vpc, this is a boolean.", "@morgante you suggested renaming this variable. You meant we should have two different names in different places for the same variable? I'm confused now.", "again, you asked to rename this variable. should I do it only in the root module? it's going to be confusing.", "we must set... remember that shared_vpc == host project name.. that why we opened the issue to rename this variable", "again, shared vpc is the host project name... it's better to repeat here than add an if in the code"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/459", "comments": ["We should probably be depending on `module.project_services` to make sure that compute api is enabled first?", "I am not sure about the purpose of this module?  IIUC we just need to make the addition in core and plumb it to the root module.", "We can probably condense this into the [existing SVPC example](https://github.com/terraform-google-modules/terraform-google-project-factory/tree/master/examples/shared_vpc). I am thinking removing [this flag ](https://github.com/terraform-google-modules/terraform-google-project-factory/blob/9bc317e763f767d5666f6876fdae91b3e9a6b200/examples/shared_vpc/main.tf#L65) and ideally this addition should take care of activating the host project. WDYT?", "You're right!", "So, my idea is to give two examples, but it does not mean I need two modules :) \r\nGoing to fix.", "My initial idea is to have both examples just to avoid introducing a breaking change. Like, the ppl using the current example won't need to bother. Please, lmk your thoughts. ", "@thiagonache It would not be a breaking change as it is not at the module level. We do not expect end users to directly use the example other than perhaps copy pasting.", "Got it."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/451", "comments": ["Can we provide a clearer README explaining the pattern?", "Should this be a name closer to the project purpose?", "This doesn't really need to be a module? I'd just put it directly in the example.", "Please include newline at end of file.", "We're moving away from using explicit credentials paths, let's remove this."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/450", "comments": ["@umairidris can we modify these hardcoded identities to use this now?\r\nhttps://github.com/terraform-google-modules/terraform-google-project-factory/blob/099cdcce28642b045337b4ca0a0c54a9949d9285/modules/shared_vpc_access/main.tf#L23", "The challenge with using this resource is you will need to manually grant any roles that were previously automatically granted on activation (e.g. for healthcare SA the healthcare.serviceAgent role is automatically granted).\r\n\r\nSo if using this resource it should be fine but you will also need to ensure you grant any permissions that you were previously assuming were automatically granted, else it will not have the right permissions to do its job.", "I think we might want to consider adding functionality for setting IAM roles on SAs to Project Factory, with sensible defaults which match the old defaults.", "Could you elaborate?\r\n\r\nCurrently the input from user looks something like this:\r\n\r\n```\r\nactivate_api_identities = [{\r\n    api = \"healthcare.googleapis.com\"\r\n    roles = [\r\n      \"roles/healthcare.serviceAgent\",\r\n      \"roles/bigquery.jobUser\",\r\n    ]\r\n  }]\r\n```\r\n\r\nDo you want us to add additional helpers to set e.g. `roles/healthcare.serviceAgent` when API is `healthcare.googleapis.com` by default? If so, should we manually maintain a mapping of API to default role? I am afraid that might be inconsistent if we miss certain APIs, though https://cloud.google.com/iam/docs/understanding-roles#service-management-roles might help. I'll start an internal thread with the team on potential automation. ", "Got it, I think we can merge as-is and evolve based on the thread."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/446", "comments": ["Would we not need additional checks in `shared_vpc_access` to catch the  case if `var.shared_vpc == \"\"`, which is the default value? I am also concerned if those checks (if implemented with `coun`t) would bring a scenario where TF may complain about being unable to determine number of resources until run time. ", "I believe what is happening here is in our svpc example https://github.com/terraform-google-modules/terraform-google-project-factory/blob/v8.1.0/examples/shared_vpc/main.tf  we test dynamic host + service project creation. However when you added `var.host_project_id != \"\"`, `var.host_project_id` is determined dynamically and hence TF complains ` \"for_each\" value depends on resource attributes that cannot be determined until apply`.\r\n\r\nI believe one solution could be modifying the `shared_vpc_access` to take in a boolean `shared_vpc_enabled` variable. Then in the `shared_vpc` module change the `shared_vpc_access` module instantiation to \r\n```tf\r\nmodule \"shared_vpc_access\" {\r\n  ...\r\n  shared_vpc_enabled = true\r\n}\r\n```\r\n\r\nIn the root module change the `shared_vpc_access` module instantiation to \r\n```tf\r\nmodule \"shared_vpc_access\" {\r\n  ...\r\n  shared_vpc_enabled = var.host_project_id != \"\" ? true : false\r\n}\r\n```\r\n This will enable users who want to dynamically provision both host and service projects to use a combination of the root module (for host project) and  `shared_vpc` module (for service projects) as shown [here](https://github.com/terraform-google-modules/terraform-google-project-factory/blob/master/examples/shared_vpc/main.tf) \r\n\r\n/cc @morgante would this preserve historical behavior for both the root and `shared_vpc` modules?", "Hi @bharathkkb I think that approach makes sense."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/438", "comments": ["`compact` was giving me the `count cannot determine number of resources error`. Weirdly enough this approach does not. I think it has to do something with this https://github.com/hashicorp/terraform/issues/25152\r\n", "I think looping on the actual accounts is actually dangerous. I think something like this would be better:\r\n\r\n```\r\nlocals {\r\n  apis = {\r\n    \"container.googleapis.com\": format(\"service-%s@container-engine-robot.iam.gserviceaccount.com\", data.google_project.service_project.number\r\n }\r\n  active_apis = setintersection(keys(local.apis), var.active_apis\r\n  subnetwork_api = setproduct(local.active_apis, var.shared_vpc_subnets)\r\n}\r\n```", "I ended up having to do `tolist(setproduct(local.active_apis, var.shared_vpc_subnets))` as it was otherwise a set and throwing error `This value does not have any indices`.  In this case I dont think element ordering matters as it becomes a list of elements of type [api,subnet]. ", "Can we change this to `for_each = local.subnetwork_api`?", "We shouldn't need these individual _enabled locals.", "We should drop the explicit per-API resources?\r\n\r\n", "yeah I tried this yesteday, but ran into the `cannot determine number of resources error`. I will give it another whirl with new structure.", "So I think the problem with for_each is that at plan time we only know the length and not the values. Similar to this issue here https://github.com/hashicorp/terraform/issues/22735#issuecomment-580491563\r\nLet me know if you have other suggestions.\r\n\r\nI tried something like\r\n```hcl\r\nlocals{\r\nsubnetwork_api = [for pair in setproduct(var.active_apis, var.shared_vpc_subnets): {\r\n    api = pair[0]\r\n    subnet = pair[1]\r\n    }\r\n  ] : []\r\n}\r\n resource \"google_compute_subnetwork_iam_member\" \"gke_dataproc_shared_vpc_subnets\" {\r\n...\r\nfor_each    = {for pair in local.subnetwork_api: \"${pair.api}.${pair.subnet}\" => pair}\r\n}\r\n```", "But we should know the values of the APIs though, no? Do you know which resource is unknown?\r\n\r\nIf it doesn't work we can stick to count though.", "Yeah I think its the subnets_self_links since they are created dynamically\r\nhttps://github.com/terraform-google-modules/terraform-google-project-factory/blob/9eb64e2217bef8477ae07e1a834c4bfb3f64273f/examples/shared_vpc/main.tf#L118", "We used to create this in `8.x` \r\nhttps://github.com/terraform-google-modules/terraform-google-project-factory/blob/af1db49139c30199cd80b39eb6369d704f3ef151/modules/core_project_factory/main.tf#L469\r\nand this is needed for GKE svpc? ", "This check will be needed for the `hostServiceAgentUser` binding but if that can be removed, we can get rid of this as well.", "Got it, we can keep it then.", "Hmm ok I guess we can stick to count then.", "Right but why do we need a conditional for dataproc? We should *only* use `gke_shared_vpc_enabled` for the hostServiceAgentUser part.", "Oops didnt see dataproc_enabled was still there, will clean up :) ", "```suggestion\r\nresource \"google_compute_subnetwork_iam_member\" \"service_shared_vpc_subnet_users\" {\r\n```", "```suggestion\r\nresource \"google_project_iam_member\" \"service_shared_vpc_user\" {\r\n```"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/434", "comments": ["nit:\r\n```suggestion\r\n  skip_gcloud_download = true\r\n```", "I am wondering if this would cause issues with dependency ordering. My concern is that  `local.active_api_s_accounts` can be computed locally and does not seem to dependent on any resources. Another thought is, we could output the project id and have a `depends_on` to enforce this.", "I do agree with you. Unfortunatelly `depends_on` block can not have variables in it. For example i can't do \r\n```hcl\r\noutput \"something\" {\r\n  value = local.active_api_s_accounts\r\n  depends_on = [var.project_id]\r\n}\r\n```\r\nThe submodule doesn't need any outputs. I can just remove `outputs.tf`.", "fixed", "That's not what a depends_on is meant to do - the point is to establish a connection with a resource.\r\n\r\nPlease add an output like this:\r\n```\r\noutput \"project_id\" {\r\n  value = var.project_id\r\n  depends_on = [google_compute_subnetwork_iam_member.gke_shared_vpc_subnets, google_project_iam_member. gke_host_agent, google_project_iam_member. dataproc_shared_vpc_network_user]\r\n}\r\n```", "added", "I believe we should also modify the output for this module to\r\n```hcl\r\noutput \"project_id\" {\r\n  description = \"If provided, the project uses the given project ID. Mutually exclusive with random_project_id being true.\"\r\n  value       = module.shared_vpc_access.project_id\r\n}\r\n```\r\nthis way when this module is used, the project-id is returned only after `module.shared_vpc_access` is completed.", "```suggestion\r\nThis module grants IAM permissions on host project and subnets to appropriate API service accounts based on activated\r\n```", "+1", "done", "@marko7460 Shouldn't this be `google_compute_subnetwork_iam_member` to avoid granting access to all subnets in the host?", "We'd need to support both paths, so adding another option like https://github.com/terraform-google-modules/terraform-google-project-factory/pull/434/files#diff-25530a290a058747ad4e0e2f230fc886R39", "The feature was coded based on https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/network#creating_a_cluster_that_uses_a_vpc_network_in_another_project. I did try giving permissions only on the subnet level and I was able to create a cluster only by specifying permissions on the subnet level. I can only confirm that those permissions are enough to create a cluster but i can't confirm if running and operating the cluster will not be an issue.", "@morgante What do you think about a future enhancement that breaks this one module into one module per API service, for the following reasons:\r\n\r\nConsider two teams, red and blue, each wanting GKE and Dataproc.  There are 4 subnets, {red,blue}-{dataproc,gke}.  The purpose of the subnets are to prevent someone spinning up a cluster from impacting running clusters by exhausting IP space.\r\n\r\nTo support this use case a per-service module would take as input a list of subnets.  For each subnet it would manage a `google_compute_subnetwork_iam_member` resource with the service agent as a member and network user as a role.\r\n\r\nThoughts?"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/428", "comments": ["we had some build failures due to this so for this fixture we should use the existing policy passed in like \r\nhttps://github.com/terraform-google-modules/terraform-example-foundation/blob/68c36bb90014c032ff8cfd2b6c7195dae8748a05/build/int.cloudbuild.yaml#L76\r\nwe can sync offline if needed", "nit: remove commented out code if not needed", "I havent used this resource too much but we may need a random prefix for this incase its not cleaned up, could you confirm?", "Wouldnt we need to expose `vpc_service_control_attach_enabled` as well and pass it in to core?", "This is likely redundant with org_id? Let's remove if we don't need it.", "Remove this as it's not a sensible default.", "This doesn't need to be a variable. The whole point of this fixture is to test VPCSC so we should hardcode to true.", "Is this needed? We don't use it in the test.", "Don't make this configurable, just leave sa_email off entirely.", "No need to add these redundant tests.", "We should add a test which validates presence in the perimeter.", "Use for_each instead of count.", "Added", "done"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/377", "comments": ["```suggestion\r\n  type        = bool\r\n```", "```suggestion\r\n}\r\n```\r\n", "```suggestion\r\n  use_tf_google_credentials_env_var = var.use_tf_google_credentials_env_var\r\n```", "```suggestion\r\n  use_tf_google_credentials_env_var = var.use_tf_google_credentials_env_var\r\n```", "```suggestion\r\n  type        = bool\r\n```"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/368", "comments": ["Not a blocker, but It should be possible to do this directly in inspec:\r\n\r\nhttps://www.inspec.io/docs/reference/resources/google_project_iam_bindings/", "Similar to above https://www.inspec.io/docs/reference/resources/google_compute_subnetwork_iam_policy/", "Same as above https://www.inspec.io/docs/reference/resources/google_compute_subnetwork_iam_policy/"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/354", "comments": ["I added a note in the readme about no longer supporting google provider 2.x and to use the previous version of this module if you need 2.x\r\n\r\nBut what's on master hasn't been pushed to terraform yet. We should push a release of what's in master before merging this so there is a 2.x version to use ", "A bit strange, the provider docs say this only support a 0 or 1 projects array currently \r\nhttps://www.terraform.io/docs/providers/google/r/billing_budget.html#projects\r\n\r\nHowever, passing in more than one works just fine. The test I created does just that. When setting more than one it also shows up in the billing budget UI on the console just fine too. So seems like the provider docs are just a bit out of date. ", "Just go ahead and put this in the project itself.", "I'd actually like to keep this *out* of the core project factory. Instead add a separate module invocation.", "Should this be a number?", "Please add default behavior if unset to description.", "Let's move this invocation into the respective top-level modules.", "Master was released as `6.2.1`. Updated readme to reflect", "Provider resource is a `string`. \r\nhttps://www.terraform.io/docs/providers/google/r/billing_budget.html#units\r\n\r\nMaybe because it can be something other than USD", "Weird, could we be more restrictive and mandate a number (which can be safely coerced to a string)?", "Moved `budget` to be called from the root module directly", "Done", "Made it a `number` with a `tostring` call in the module ", "Moved it out and called budget submodule directly from root and other modules ", "Done"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/348", "comments": ["If we're centralizing this in the devtools image, we should have the task defined there.", "Requirements should be installed in the image, not at runtime.", "Was this upstreamed?"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/340", "comments": ["This description needs to be corrected. The suffix generator uses 2 bytes, which translates to 4 characters. Please update all instances of this description.\r\n\r\n```suggestion\r\n  description = \"Adds a suffix of 4 random characters to the `project_id`.\"\r\n```", "I have applied the requested changes."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/326", "comments": ["Booleans no longer require quotation marks.\r\n\r\n```suggestion\r\n  random_project_id = true\r\n```", "The `auth_domain` variable should be removed since it is not used.", "Let's drop `location_id` since we're using the default value.", "Done", "I havent used ```auth_domain``` in the tests since I did not know what example domain to use but it is still a valid input to the resource. ", "Done", "Sorry, I just mean from the example. We aren't using it any more so it should be removed.", "Oh. On a second look, it has already been removed. Ignore me. :sweat_smile: "]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/315", "comments": ["We should talk about this, but I'm against using a global version which can inexplicably break. "]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/310", "comments": ["```suggestion\r\n### Fixed\r\n```"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/304", "comments": ["I suggest using map of arguments and \"[foo for var.var]\" to later map it to a string. Please also keep in mind that this is EXTREMELY unsafe", "This might require root access", "It depends on installation way. Basically - it does not.", "reworked", "You should always have a newline in between resources.", "This is way more complicated than it needs to be. Please separate into different lines and don't use `join` excessively.", "Fixed", "@morgante I've reworked it. Looks pretty simple in one-line. If It still needs to be separated into different lines, let me know, please."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/299", "comments": ["oops, typo.  Should be 'module'\r\n\r\nThese modules require a bash shell with python installed, but it probably otherwise does run in windows.  I tried it a few weeks back and basic functionality worked using the bash shell that gets installed with git by default.  However, I didn't exercise all of the functionality (gsuite integration) and/or run the integration tests, and I no longer have that windows machine to test with, so I can't confirm that all of the modules work correctly in windows when the dependencies are available.  \r\n\r\nTerraform is kind of a pain in windows, regardless of the use of this module.  There are a lot of assumptions that get made about unix tools being available. You might find running it in a linux container works better for a wide variety of terraform modules, though mounting the host filesystem inside a container in docker for windows brings its own set of headaches, in my experience."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/295", "comments": ["This condition will never trigger based on the earlier exit [here](https://github.com/terraform-google-modules/terraform-google-project-factory/pull/295/files#diff-f3fdb2558703bcb409cbf6fdc6d5b5ecR114-R117).", "The first check occurs only if the \"folder\" parameter is passed, and exit if the project folder does not exist on gcp.\r\nIf the \"folder\" parameter is not passed, the earlier check is always skipped, and this check is necessary in order not to apply the permissions related to the folder."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/290", "comments": ["I'm not sure how folks will feel about this, but I could not figure out a way to extract a parameter from the params destined for the python script without relying on external dependencies (sed, grep) unless it runs in bash, which allows arrays.", "Technically, this conditional isn't actually required.  Because the linter wants all variables to be quoted, and sending an empty string as one of the params to exec does cause the empty param to be received by pip, it turns out that I can't make it work correctly and pass lint without this extra conditional.\r\n\r\nTechnically, the following syntax is more correct, since quoted params are parsed into the PIP_FLAGS as a single value, and then each parsed value is added to exec as a separate value via the array syntax:\r\n\r\n`exec \"pip3\" \"install\" ${PIP_FLAGS[*]} \"-r\" \"path/to/requirements.txt\"`\r\n\r\nBut the linter wants to force quotes around the PIP_FLAGS reference.  If I put it in quotes, then pip objects to an empty arg being received if the array is empty.  So I added a conditional to prevent it from being sent at all unless it actually has a value in it, otherwise it is included, within a quoted string.\r\n", "We could also simply disable the linter check on this line if you think that'd improve the readability. Really, this seems a bit overcomplicated for simply injecting an extra flag\u2014I'm surprised we need an `extract_pip_flags` flag at all.\r\n\r\nOne possible alternative/simpler implementation would be to only expose a \"install_preconditions_as_user\" variable which adds the required flag.", "Sure, but the difficulty is in how to actually pass that information to the preconditions.sh script.  If it goes in the args, then you have to get it back out before they are passed to the python script.  Otherwise, you need either a positional param we can shift off the front, or 2 versions of the script.  I'm happy to implement it either way, if someone wants to express a preference.  \r\n\r\nI agree that this is a complex way to solve the problem, but it does keep duplicated code to a minimum and results in minimum impact to the user of the module while delivering the flexibility to pass arbitrary params to pip, rather than only allowing them to select between 2 options.  It is easy to imagine a requirement for a fair number of available options, especially for enterprise users, who can be stuck behind firewalls and internal artifact repositories, etc.\r\n\r\nThese are just the params that stand out as likely candidates for at least some users of the module.\r\n\r\n```\r\n  --user                      Install to the Python user install directory for your platform. Typically ~/.local/, or %APPDATA%\\Python on Windows. (See the Python documentation for site.USER_BASE for full details.)\r\n  --proxy <proxy>             Specify a proxy in the form [user:passwd@]proxy.server:port.\r\n  --trusted-host <hostname>   Mark this host as trusted, even though it does not have valid or any HTTPS.\r\n  --cert <path>               Path to alternate CA bundle.\r\n  --client-cert <path>        Path to SSL client certificate, a single file containing the private key and the certificate in PEM format.\r\n```\r\n\r\nI did realize the PR as it stands right now, has a bug in it which will actually break if you set pip3_extra_flags to be '--user', anyway, since it will recognize that as a flag intended for the python script instead of pulling it into the pip flags.  I know how to fix it, but I'll wait until I hear a solution preference.\r\n", "What if we simple separated this into two different `local-exec` scripts? One could handle installing the pip dependencies, while the second actually executes the Python script."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/288", "comments": ["```suggestion\r\n  description = \"The email of the G Suite group created with group_name\"\r\n```", "I didn't quite use your suggestion, as the GSuite spelling wasn't consistent with the prior output, and your description was maybe confusing about the difference between group_email and group_name, so I went with \"The group_name of the GSuite group\"", "We should still fix it to be \"G Suite\" as that is the official name.\r\n\r\nIf this output is \"my-team\" (*not* my-team@my-corp.com) then the proposed description makes sense.", "Yes, that's correct.  group_email is the full address, group_name is just the username portion of the address, but I wanted to avoid the word username.  I just pushed an update with the spelling correction, too."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/284", "comments": ["FYI I don't think the state download is needed for Terraform 0.12. Can probably skip straight to running the script.", "We still need this to pass through the project_id from the `google_project_service` resource (to preserve the dependency graph), not directly from var.project_id.", "This was a tricky one. I had to change it because the old `.*.` operator doesn't work anymore, and the new splat operator (`[*].`) doesn't work on `for_each` blocks.\r\n\r\nI managed to find a new `for` construct that works:\r\n```suggestion\r\n  value = element(\r\n    [for v in google_project_service.project_services : v.project],\r\n    0,\r\n  )\r\n```", "Good point. I'll make working from default state the default, and add a way for the user to point to a different state file if they want to be a bit safer about it."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/278", "comments": ["Need to add link to diff and increment to v3.4.0.", "Link to diff?", "```suggestion\r\n### [3.3.1] - 2019-10-08\r\n```"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/267", "comments": ["```suggestion\r\n  - Please note that if you are deploying an App Engine Flex application, you should not delete the default compute service account\r\n```"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/264", "comments": ["This should be expanded to include:\r\n\r\n- `TF_VAR_gsuite_admin_email`\r\n- `TF_VAR_gsuite_domain`", "This should be expanded to include:\r\n\r\n- `TF_VAR_gsuite_admin_email`\r\n- `TF_VAR_gsuite_domain`", "Can we quote `$(CURDIR)` here? i.e. `-v \"$(CURDIR)\":/workspace`. This is necessary to run the tests on my machine.", "Can we quote `$(CURDIR)` here? i.e. `-v \"$(CURDIR)\":/workspace`. This is necessary to run the tests on my machine.", "Can we quote `$(CURDIR)` here? i.e. `-v \"$(CURDIR)\":/workspace`. This is necessary to run the tests on my machine.", "Can we quote `$(CURDIR)` here? i.e. `-v \"$(CURDIR)\":/workspace`. This is necessary to run the tests on my machine.", "Can we quote `$(CURDIR)` here? i.e. `-v \"$(CURDIR)\":/workspace`. This is necessary to run the tests on my machine.", "Can we quote `$(CURDIR)` here? i.e. `-v \"$(CURDIR)\":/workspace`. This is necessary to run the tests on my machine.", "This should be expanded to include:\r\n\r\n- `TF_VAR_gsuite_admin_email`\r\n- `TF_VAR_gsuite_domain`", "Variables added to export", "Variables added to export", "Updated", "Updated", "Updated", "Updated", "Updated", "Updated", "Variables added to export", "@Jberlinsky can you open an issue for this against the module template?", "Yep! https://github.com/terraform-google-modules/terraform-google-module-template/issues/33", "where?", "@kopachevsky Below \ud83d\udc47", "This file should not be deleted.", "This file should not be deleted.", "Reverted", "Reverted"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/257", "comments": ["this `find_files` call doesn't match [module template](https://github.com/terraform-google-modules/terraform-google-module-template/blob/master/terraform-google-%7B%7Bcookiecutter.module_name%7D%7D/test/make.sh#L78) or [project factory](https://github.com/terraform-google-modules/terraform-google-project-factory/blob/master/test/make.sh#L89)", "This version of the function matches [module template](https://github.com/terraform-google-modules/terraform-google-module-template/blob/master/terraform-google-%7B%7Bcookiecutter.module_name%7D%7D/test/make.sh#L127-L142) but doesn't match [project factory](https://github.com/terraform-google-modules/terraform-google-project-factory/blob/master/test/make.sh#L144-L162). Which is the latest, @nick4fake? \r\n", "Remove quotes ```create_group       = true```", "Set variables type according to the module ```core_project_factory``` variables", "Thank you, fixed", "Fixed", "Add description to \"project_name\", \"project_id\" and \"project_number\" outputs", "Thank you, will do"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/246", "comments": ["Instead of a separate service block, we should inject this into the `activate_apis`. (In particular, this would break in the case of authoritatively setting the project services.)", "Renaming the resource is likely to lead to some issues with existing projects (causing state migrations). I'd prefer if we kept these as two separate null_resources.", "Make sure to run the format/linting commands.", "Should we note this option conflicts with specifying a `credentials_path` to project factory?", "Yep agreed - I will update this", "No problem, this formatting change was the result of running `terraform fmt` FYI, running make -s has a bunch of errors locally for me for files I haven't touched, perhaps I am using a different version of shellcheck. Mine is 0.4.7, here is a sample of the errors:\r\n\r\n```\r\nIn ./helpers/setup-sa.sh line 171:\r\n\\ \\ - serviceAccount:${SA_ID}\\\\\r\n^-- SC1117: Backslash is literal in \"\\ \". Prefer explicit escaping: \"\\\\ \".\r\n  ^-- SC1117: Backslash is literal in \"\\ \". Prefer explicit escaping: \"\\\\ \".\r\n\r\n\r\nIn ./helpers/setup-sa.sh line 172:\r\n\\ \\ role: roles/billing.user\" policy-tmp-$$.yml && rm policy-tmp-$$.yml.bak\r\n^-- SC1117: Backslash is literal in \"\\ \". Prefer explicit escaping: \"\\\\ \".\r\n  ^-- SC1117: Backslash is literal in \"\\ \". Prefer explicit escaping: \"\\\\ \".\r\n```", "This has been fixed in the latest commit and is injected in the locals block.", "Cool make sense, this has been fixed in the latest commit."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/244", "comments": ["does it make sense to create boolean variable for `var.shared_vpc_subnets_count != null` ?", "same for length(compact(var.shared_vpc_subnets)) , we can define value of this expression it as a local variale and just use it?", "Yes it makes sense, I'll try to test it", "Better use the boolean variable from your previous comment if it will work", "We should not add defaults if they are not valid for users.\r\n\r\n```suggestion\r\n```", "This logic should not be changed. The definition of `local.gke_shared_vpc_enabled` must be updated to use `var.shared_vpc_enabled`.", "Same issue about `local.gke_shared_vpc_enabled`.", "This should not have a default. We want to ensure that both public modules explicitly pass this argument.", "This variable should not be defined here.", "Done", "Removed", "Fixed", "Fixed", "you don't need ternary operator here", "\"If shared VPC should be used\"", "formatting", "Not related to your change, please revert", "Not related to your change, please revert", "Not related to your change, please revert", "Not related to your change, please revert", "Not related to your change, please revert", "Not related to your change, please revert", "Better description", "Please remove all changes except shared_vpc configs", "Done", "Fixed", "ok", "Reverted", "Reverted", "reverted", "reverted", "Done", "Done", "Reverted", "ok", "Fixed"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/241", "comments": ["This patch moves terraform_docs.sh from the image to the repository to re-enable local doc generation.  See https://github.com/GoogleCloudPlatform/cloud-foundation-toolkit/pull/216/files#r301803363 for the related change in the Docker image.\r\n\r\n> This is removed because terraform_docs is being added into the helpers folder of each module until such time as each module is updated to use the lint image to perform lint checks.", "With 0.12 terraform validate requires terraform init, so this behavior moves into a helper script.", "We added this warning while debugging mysterious lint failures which were fairly silent.  Seemed good to keep.  The warning may be disabled, e.g. when using grep to match trailing whitespace.", "Note here, using an unreleased version to get tests to pass until the dependency is released.", "Net new troubleshooting information", "This and similar are a result of the new terraform docs behavior in 0.12 and the result of `make generate_docs`", "Was using an old version of terraform-docs, updated to current v0.6.0 with terraform 0.12.3 and the docs patch became one line.", "Fix for:\r\n\r\n```diff\r\n-:featureSettings => {:splitHealthChecks=>true},\r\n+:featureSettings => {:splitHealthChecks=>true, :useContainerOptimizedOs=>true},\r\n```", "Added `.kitchen` directories to those excluded", "FYI, linting is considerably slower now due to `terraform init`, but no slower than integration.   Total time for all 3 pipeline jobs is unchanged.", "Is this a required change? Linting should be *much* faster than integration and have minimal requirements.", "Yes.  In 0.12 `terraform validate` does not work without `terraform init` having run.", "I see, thanks. We might eventually want to have a separate pure linting step (and put validation into a \"unit test\" of sorts).", "Good idea", "As per https://github.com/googlecloudplatform/cloud-foundation-toolkit/pull/216, this should be `2.2.0`.", "Kitchen-Terraform runs `terraform validate` as part of the workflow, so we could drop this entirely in favour of running it during integration tests.", "Fixed"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/240", "comments": ["Thoughts on spelling this out, e.g. \"Project default service account setting. Can be one of `delete`, `depriviledge`, or `keep`.\"", "Thoughts on spelling this out, e.g. \"Project default service account setting. Can be one of `delete`, `depriviledge`, or `keep`.\"", "```suggestion\r\n  description = \"Project default service account setting: can be one of `delete, `depriviledge`, or `keep`.\"\r\n```", "```suggestion\r\n  description = \"Project default service account setting: can be one of `delete, `depriviledge`, or `keep`.\"\r\n```"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/237", "comments": ["Given the addition to TROUBLESHOOTING.md, do we want to change this version-pin to `> 0.1.12`?", "Can we pin this to a specific version? 0.12.x compatibility was introduced in https://github.com/terraform-google-modules/terraform-google-network/commit/7ba1b231e0662f4eaf264e5ad4a7e7ba977a40cd", "Can we pin this to a specific version? 0.12.x compatibility was introduced in https://github.com/terraform-google-modules/terraform-google-network/commit/7ba1b231e0662f4eaf264e5ad4a7e7ba977a40cd"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/231", "comments": ["We should only use default values if they are valid for users.\r\n\r\n```suggestion\r\n```", "This invalid default value should also be removed.\r\n\r\n```suggestion\r\n```"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/230", "comments": ["We should indicate that the billing account is optional.\r\n\r\n```suggestion\r\n./helpers/setup-sa.sh <ORGANIZATION_ID> <SEED_PROJECT_NAME> [BILLING_ACCOUNT]\r\n```", "```suggestion\r\nIn order to execute this script, you must have an account with the following list of\r\n```", "```suggestion\r\npermissions:\r\n```", "Can you please undo this formatting? The Inputs and Outputs tables should remain as generated by `terraform-docs`.", "Are we missing `resourcemanager.projects.list` and `billing.accounts.list`?", "Are we missing `cloudresourcemanager.googleapis.com`?", "Sure, with next commit", "@aaron-lane, just fixed this one in [e41724f](https://github.com/terraform-google-modules/terraform-google-project-factory/pull/230/commits/e41724ff27932ad84dc65faf8e6c4d3307beff5e)", "Yes! Fixed that in [5e878a1](https://github.com/terraform-google-modules/terraform-google-project-factory/pull/230/commits/5e878a134a8d42dc5405439541013515fa372562)\r\nThank you!", "Yes!\r\nFixed that in [5e878a1](https://github.com/terraform-google-modules/terraform-google-project-factory/pull/230/commits/5e878a134a8d42dc5405439541013515fa372562)\r\nThank you for great review, @aaron-lane! Good eye!\r\n"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/220", "comments": ["The iterator value should not be represented as a constant.\r\n\r\n```suggestion\r\n        for required_api in self.REQUIRED_APIS:\r\n```", "```suggestion\r\n                name=parent + \"/services/\" + required_api\r\n```", "```suggestion\r\n                enabled.append(required_api)\r\n```"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/213", "comments": ["This expression can be simplified:\r\n\r\n```suggestion\r\n  count = \"${var.apis_authority ? 0 : length(var.activate_apis)}\"\r\n```", "This expression can be simplified:\r\n\r\n```suggestion\r\n  count = \"${var.apis_authority ? 1 : 0}\"\r\n```", "This description should be clarified:\r\n\r\n```suggestion\r\n  description = \"Toggles authoritative management of project services.\"\r\n```", "This description should be clarified:\r\n\r\n```suggestion\r\n  description = \"Toggles authoritative management of project services.\"\r\n```", "Thank you for your review. Done.", "Thank you for your review. I will keep this in mind."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/212", "comments": ["I believe ordering is important here, because you can reach a bad state if the seed project doesn't have required APIs but we try to validate the billing account.\r\n\r\nCould you make sure BillingAccount validators get appended after the SeedProject?\r\n\r\nOtherwise LGTM."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/210", "comments": ["what about folder_id maybe it's ok to have folder_id but not nessesary org_id?", "We need to check org_id. There is validate function(which checks permissions) in precondition script and it fails if org_id is None. \r\n\".terraform/modules/c158d4e24da0dc3f5e10ff9e6d98ef82/scripts/preconditions/preconditions.py\", line 125, in validate\r\n    resource = \"organizations/\" + self.org_id\r\nTypeError: can only concatenate str (not \"NoneType\") to str"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/207", "comments": ["Why are you changing this default? Blank isn't a valid default."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/201", "comments": ["Spelling.", "Let's standardize on the same name for shared variables with the standard module:\r\n- billing_account\r\n- activate_apis", "I'm not too keen on the `activate_apis` name, as it masks the actual resource name. But can see the benefits of standardizing, lemme fix that."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/200", "comments": ["why do we need group_name here?", "change to group_email\r\n ", "do not create new control. just put new describe inside project-factory-minimal", "should not create new **control** use existing _project-factory-minimal_", "```suggestion\r\n    it \"should be empty when group_name is empty\" do\r\n```", "We should only have one assertion per example to simplify debugging when failures occur. Please move this to a separate `it` example.", "Thank you for your review, done.", "Thank you for your review. Done.", "```suggestion\r\n    it \"group_name should be empty\" do\r\n```"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/194", "comments": ["```suggestion\r\nresource \"null_resource\" \"check_if_shared_vpc_subnets_contains_items_with_invalid_name\" {\r\n```", "Test cases must not be generated through metaprogramming; this practice can lead to false positives if the logic driving the generation happens to change.", "I agree, but how would you minimize code duplication in this case? basically we need to do same code against 2 different networks ", "Reducing code duplication in test cases is less of a priority than creating clear test cases. Duplicating logic in this scenario is totally acceptable."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/189", "comments": ["Why are we dropping these? Command explanations are useful.", "Please don't drop the symlinks.", "Missing ` -not -path \"./test/fixtures/shared/*`", "The comments were removed from the template. We will need to address this issue there.", "As discussed, we should drop this requirement."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/188", "comments": ["I guess we need to regenerate documentation in this case?", "no double quotes around", "very unclear description", "This description comes directly from the terraform documentation related to this \r\nargument,\r\nhttps://www.terraform.io/docs/providers/google/r/google_project_service.html#disable_dependent_services\r\n\r\nWhat exactly is not clear for you?\r\nThanks."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/186", "comments": ["Please add a default for this in a follow-up PR."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/180", "comments": ["This local is redundant.", "`local.project_id` is undefined.", "It's the existing convention for examples."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/178", "comments": ["Let's retain this test and assert that the base permissions are empty. This could change again in the future."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/166", "comments": ["```suggestion\r\n  description = \"Path to a service account credentials file with rights to run the Project Factory.\"\r\n```", "@thefirstofthe300 suggested supplying a random value through a variable to avoid the count error and hardcoding a static value. This could be done in `test/ci_integration#setup_environment`:\r\n\r\n```sh\r\nexport TF_VAR_secondary_group_name=\"$(cat /dev/urandom | tr -dc 'a-z' | fold -w 10 | head -n 1)\"\r\n```", "Attributes should be required to ensure that Terraform outputs match in naming.\r\n\r\n```suggestion\r\n    required: true\r\n```", "A default value is not needed as the value should always be provided by Terraform.\r\n\r\n```suggestion\r\n```", "Yeah, that works out well. I used this pattern but adjusted it to ensure it would work for macOS too", "Booleans must be quoted to ensure compatibility with Terraform v0.12.\r\n\r\n```suggestion\r\n  random_project_id = \"false\"\r\n```"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/164", "comments": ["Cleanup/nonblocker: this `only_if` expression stems from when I wrote a single integration test suite that ran with different parameters to test different modes. Since this test requires a shared VPC I think we can drop this check.\r\n\r\nIt may be better to follow up on this in a later PR, so if we want a quick turnaround resolve this issue and ping me; I'll file a ticket to follow up on this.", "Cleanup: I think this conditional can be dropped since `group_email` is required. As per the earlier comment we can defer this work in order to get this PR turned around.", "```suggestion\r\nservice project will have access to **all** shared VPC subnetworks.\r\n```", "Added to the original commit"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/155", "comments": ["```suggestion\r\n[1.1.2]: https://github.com/terraform-google-modules/terraform-google-project-factory/compare/v1.1.1...v1.1.2\r\n```", "Fixed."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/154", "comments": ["Why can't this continue to reference `project_number`?", "Why drop `local.project_number`?", "I think we should continue to have `project_id` reference the actual project created.\r\n\r\nWe can move the conditional check into the project ID itself.", "We should keep `local.project_id` unless there's a reason we can't, similarly for all cases of this replacement.", "This local doesn't necessarily refer to the value that will be used to set the project's ID. I'll rename these variables to make the naming a bit more sane.", "The local here is a level of indirection that is unnecessary, IMHO.", "The net effect of this change is a no-op. It removes a level of indirection since `local.project_number` is referring to `google_project.main.number`. I see no purpose for continuing to use `local.project_number`. It makes things a bit more difficult to read so I would much prefer to remove it.", "I am of the opinion that the project_id local should be removed or repurposed to make the project_id generation more clear. It also adds a layer of redirection that seems unnecessary so my comments on dropping the `project_number` local applies as well.", "It's easier to manage this in one place instead of having to update it on every resource.", "@thefirstofthe300 Please do not introduce completely unrelated changes into a different PR. Is this somehow related to the other functionality in this PR and I missed it?"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/153", "comments": ["Since we're using the value of `data.null_data_source.default_service_account.outputs[\"email\"]`, is this explicit dependency on the data source necessary?", "Good point. Removed."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/149", "comments": ["```suggestion\r\n[Unreleased]: https://github.com/terraform-google-modules/terraform-google-project-factory/compare/v1.1.1...HEAD\r\n```"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/147", "comments": ["Should this be `local.group_name`? `var.name` is the name of the project itself, right?", "Done."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/144", "comments": ["```suggestion\r\nAfter importing the resource, run `terraform plan` and `terraform apply`.\r\n```", "Fixed", "We should include the source reference, which I believe looks like the following.\r\n\r\n```suggestion\r\nmodule \"app-engine\" {\r\n  source = \"terraform-google-modules/project-factory/google//modules/app_engine\"\r\n  version = \"~> 2.0\"\r\n\r\n```", "References to the count `0` are no longer necessary.", "These variables are obsolete.", "Done.", "Done.", "Done.", "```suggestion\r\n```", "```suggestion\r\n## Upgrading\r\n```", "```suggestion\r\nThe current version is 2.X. The following guides are available to assist with upgrades:\r\n```", "```suggestion\r\nVersion 1.X of Project Factory used the `app_engine` map variable to configure App Engine:\r\n```", "This statement and the leading statement are redundant.\r\n\r\n```suggestion\r\n```", "```suggestion\r\n```", "```suggestion\r\n### App Engine Argument Changes\r\n```", "```suggestion\r\nVersion 2.X of Project Factory uses a new module named `app_engine`:\r\n```", "```suggestion\r\nmodule \"project-factory\" {\r\n  # ...\r\n}\r\n\r\n```", "```suggestion\r\n  # ...\r\n```", "Our style guide recommends using \"main\" when there isn't a more descriptive name for singleton resources.\r\n\r\n```suggestion\r\nresource \"google_app_engine_application\" \"main\" {\r\n```", "To conform with the suggested change to `modules/app_engine/main.tf`:\r\n\r\n```suggestion\r\nterraform import module.app-engine.google_app_engine_application.main $YOUR_PROJECT_ID\r\n```", "```suggestion\r\n  value       = \"${google_app_engine_application.main.name}\"\r\n```", "```suggestion\r\n  value       = \"${google_app_engine_application.main.url_dispatch_rule}\"\r\n```", "```suggestion\r\n  value       = \"${google_app_engine_application.main.code_bucket}\"\r\n```", "```suggestion\r\n  value       = \"${google_app_engine_application.main.default_hostname}\"\r\n```", "```suggestion\r\n  value       = \"${google_app_engine_application.main.default_bucket}\"\r\n```", "```suggestion\r\n  value       = \"${google_app_engine_application.main.gcr_domain}\"\r\n```", "Done.", "Done", "Done.", "Done.", "Done.", "Done.", "Done.", "Done.", "Done.", "Done.", "Done.", "Done.", "Done.", "Done.", "Done.", "Done.", "Done.", "Done.", "If I follow correctly, we're expecting the value of `feature_settings` to be a list because `google_app_engine_application.feature_settings` is a block which can technically be declared as a list of maps. In that case, we should convert this to a map and abstract away the need to insert it in a list. Additionally, we should document the expected structure of this variable.\r\n\r\n```suggestion\r\n\r\n```", "The wording here was pulled straight from the Terraform provider documentation and the source docs are terribly worded. The expectation here is that `feature_settings` is a list of map(s). Right now, that list can only consist of a single map with the single key `split_health_checks` so I assume the list of maps is there to allow for future expansion of feature settings maps.\r\n\r\nI think the best way to move forward is to do one of two things: either pass the feature settings list into the `google_app_engine_application` resource without any manipulation at all OR we should turn each feature setting into an input. I don't want to start doing list/map manipulation in the resource declaration because doing it correctly will require looping through the list and Terraform doesn't support this case well at all.\r\n\r\nI am leaning more towards abstracting out each feature setting into its own input for ease of use by the end user. Thoughts?", "Considering this matches the provider docs, I lean towards merging this as is.", "With respect to documenting the structure, I think it would be acceptable to simply link to the underlying resource documentation.\r\n\r\nLet me clarify the other point. The underlying resource argument is described as a block, which would be written like:\r\n\r\n```hcl\r\nresource \"google_app_engine_application\" \"main\" {\r\n  feature_settings {\r\n    split_health_checks = \"true\"\r\n  }\r\n}\r\n```\r\n\r\nOur variable is expected to be a list of maps, which works when passing block arguments via interpolation, but seems unintuitive for the end user. My proposal is that we convert this to a map so that it can be specified equivalent to the preceding example when invoking the module but converted as necessary within the module:\r\n\r\n```hcl\r\nresource \"google_app_engine_application \"main\" {\r\n  feature_settings = [\"${var.feature_settings}\"]\r\n}\r\n```", "The problem here is that the provider documentation is wrong. The type that Terraform is looking for in the feature_setting field is a list, not a map. The structure here makes little sense to me since it doesn't seem to mirror the API correctly, but it is what it is and I doubt it gets changed in the provider until v3.0.0 of the provider since mirroring the API correctly requires a breaking change.\r\n\r\nhttps://github.com/terraform-providers/terraform-provider-google/blob/master/google/resource_app_engine_application.go#L71\r\nhttps://www.terraform.io/docs/extend/schemas/schema-types.html#aggregate-types", "@thefirstofthe300 pointed out that the actual type is in fact a list, not a block: https://github.com/terraform-providers/terraform-provider-google/blob/master/google/resource_app_engine_application.go#L71."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/142", "comments": ["```suggestion\r\n  describe command(\"./test/scripts/gsuite/gsuite_groups.py --sa-json-credentials='#{credentials_path}' --group-email #{group_email} --impersonate-user #{gsuite_admin_account}\") do\r\n```", "Fixed."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/141", "comments": ["I don't think this logic will work for cases where `create_group = false`. I think we might be better off with an explicit `depends_on` to solve this issue.", "Good catch. I just tested that scenario and you are correct about there being a problem when `create_group = false`.\r\n\r\nUnfortunately, Terraform doesn't support depending on a module yet so that's not an option to fix the race. The `gsuite_group` resource needs to be referenced at some point in the graph to create the implicit dependency.\r\n\r\nThat being said, I came up with a bit of a hack to get the group definition into the graph or to use the provided email if `create_group` is set to false. It appears to be working as expected.\r\n\r\nPTAL."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/133", "comments": ["We shouldn't have a default here. Instead put that default into the project factory.", "No defaults please.", "We probably don't need to link to Project Factory here.", "Let's be consistent.\r\n\r\n```suggestion\r\n[`roles/serviceusage.serviceUsageAdmin`](https://cloud.google.com/iam/docs/understanding-roles#service-usage-roles) or [`roles/owner`](https://cloud.google.com/iam/docs/understanding-roles#primitive_role_definitions) \r\n```", "People should not directly invoke the module. Instead include an example of using it inside a Terraform config.", "This needs to be pulled from `google_project_service` so the dependency graph works out.\r\n\r\n```suggestion\r\n  value       = \"${google_project_service. project_services.project}\"\r\n```", "I think examples should be inside the submodule.", "Let's move this line to line 38.", "```suggestion\r\n# Project API Activation\r\n```", "Let's add a paragraph comparing to [`google_project_services`](https://www.terraform.io/docs/providers/google/r/google_project_services.html) and how this module is *non-authoritative*.", "```suggestion\r\nresource, which is  _non-authoritative_, as opposed to the [`google_project_services`](https://www.terraform.io/docs/providers/google/r/google_project_services.html)\r\n```", "```suggestion\r\nSee [examples/project_services](./examples/project_services) for an example.\r\n```"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/131", "comments": ["Please include links/numbers to PRs for all line items.", "@morgante just added PR links/numbers. This doesn't seem to be part of the spec. Do you think it would make sense to add a note after the \"...The format is based on...\" line at the top?"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/129", "comments": ["```suggestion\r\n        self.assertTrue(\r\n```", "```suggestion\r\n            set(TERRAFORM_DROPPED_DATA_SOURCES).isdisjoint(computed_moves))\r\n```", "```suggestion\r\n        self.assertTrue(\r\n```", "```suggestion\r\n            set(TERRAFORM_UNMIGRATED_MOVES).isdisjoint(computed_moves))\r\n```"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/128", "comments": ["Should we make all reference check instead of repeating all checks in both spots?"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/125", "comments": ["```suggestion\r\n## 1.0.1\r\n## [Unreleased]\r\n```"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/114", "comments": ["Commenting for posterity - we're getting CI failures, can this be a relative path in the same manner as `module.project-factory`?\r\n\r\nCI error:\r\n```\r\nError downloading modules: Error loading modules: error downloading 'file:///tmp/build/f541ec31/terraform-google-project-factory/${path.module}/modules/gsuite_group': source path error: stat /tmp/build/f541ec31/terraform-google-project-factory/${path.module}/modules/gsuite_group: no such file or directory\r\n```"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/104", "comments": ["A corresponding link needs to be added to the end of the file."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/103", "comments": ["Small detail - this might be safer if we suggest `terraform.tfstate.*`, since that pattern won't inadvertently blow away `terraform.tfstate`. Your call on if we should make this change.", "If you're using remote state, you don't want `terraform.tfstate` laying around anyways.", "The user should be using remote state, but also, \"If you are using remote state,\" clearly spells out the case to run it. LGTM"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/98", "comments": ["I thought this was a bug - is the intent of this behavior to grant full access to the shared VPC subnets if no subnets are specifically provided? The existing code and documentation doesn't make this behavior clear.", "#97 explains the expectations.", "Let's make sure the tests correctly cover this. Looks like we're going to need an additional suite.", "Agreed, we should add some tests for this."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/91", "comments": ["Why are we replacing the vpc module with manually creating the subnets ourselves?", "We shouldn't be automatically creating subnets.\r\n```suggestion\r\n  auto_create_subnetworks = \"false\"\r\n```", "We're doing this because the network module manages the VPC host sharing, so when the tests are torn down we disable the shared VPC project as a host. We can add a parameter making that resource optional, but for the sake of expediency I just added a couple of resources to provide the behavior we need.", "If you just leave off the shared_vpc argument from the network module, it won't affect the shared VPC status at all. https://github.com/terraform-google-modules/terraform-google-network/blob/master/main.tf#L30", "Switched back to the network module in c7b6ef7.", "Outputs should include descriptions.", "Outputs should include descriptions.", "This would make a great description. :smile: ", "Variables should include descriptions.", "This should also exclude any `.terraform` directories.", "Maybe include a note that the shared vpc status is managed out-of-band.", "Addressed at https://github.com/terraform-google-modules/terraform-google-project-factory/pull/91/files#diff-963d4c8c343b85de0fee346ecdad2ff9R63", "```suggestion\r\n  # The provided project must already be a Shared VPC host\r\n  shared_vpc_host = \"false\"\r\n```", "@adrienthebo Considering the description is right here in a comment, I think it makes sense to move it into an actual description."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/87", "comments": ["Per our style guide, the file name and the title should match. I think the file name can be more verbose.", "Is the G Suite provider necessary when the integration is disabled?", "Can this be dropped assuming we just wait for the 1.0 release to merge this?", "This should reference the v1.0 tag.", "This should reference the v1.0 tag.", "This should reference the v0.2.1 tag or the v0.2.2 tag.", "This should reference the v0.2.1 tag or the v0.2.2 tag.", "This should reference the v1.0 tag.", "This should reference the v1.0 tag.", "Yes, that note was specifically for this pull request review and not the final document.", "Yes, the gsuite provider produces errors otherwise. If you'd like to verify this you can check against the example code in this document.", "Renamed to `docs/upgrading_to_project_factory_v1.0.md`", "Comment dropped."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/79", "comments": ["Nitpick - let's add a period to this sentence.", "Good catch, thanks!  Added `.`", "\ud83d\udc4d ", "The Google Markdown style guide suggests this header should be named \"Glossary\".", "```suggestion\r\nA service account in the **Seed Project** used to create\r\n```", "```suggestion\r\nWhen the Project Factory is used with a misconfigured Seed Project, it will partially\r\n```", "```suggestion\r\ngenerate Target Projects.\r\n```", "```suggestion\r\ngenerate a new Target Project, fail, and enter a state where it can no longer\r\n```", "```suggestion\r\nThe Project Factory has generated a new Target Project but could not enable the\r\n```", "```suggestion\r\n    the Target Project.\r\n```", "```suggestion\r\n1.  The `compute.googleapis.com` API is not enabled on the Target Project because\r\n```", "```suggestion\r\n1.  `terraform plan` tries to query the default GCE service account.\r\n```", "```suggestion\r\n1.  The query fails because the `compute.googleapis.com` API is not enabled on\r\n```", "```suggestion\r\n    it does not have an associated billing account.\r\n```", "```suggestion\r\n1.  The Target Project does not have an associated billing account for one of the\r\n```", "```suggestion\r\n    following causes:\r\n```", "```suggestion\r\n    *   The Seed Project does not have the `cloudbilling.googleapis.com` API\r\n```", "```suggestion\r\n        enabled, so Terraform cannot enable billing on the Target Project.\r\n```", "```suggestion\r\n    *   The Seed Service Account does not have the `roles/billing.user` role on the\r\n```", "```suggestion\r\n        associated billing account, and cannot link the Target Project with the\r\n```", "```suggestion\r\n        billing account.\r\n```", "```suggestion\r\n`compute.googleapis.com` API is disabled on the Target Project, but the absence\r\n```", "```suggestion\r\nenabled on the Seed Project and Target Project.\r\n```", "```suggestion\r\n1.  Enable billing on the Seed Project:\r\n```", "```suggestion\r\n    1.  Enable the `cloudbilling.googleapis.com` API on the Seed Project:\r\n```", "```suggestion\r\n    1.  Associate a billing account with the Seed Project:\r\n```", "```suggestion\r\n```sh\r\n```", "```suggestion\r\n        ```sh\r\n```", "```suggestion\r\n1.  Enable `compute.googleapis.com` on the Target Project:\r\n```", "```suggestion\r\n    ```sh\r\n```", "```suggestion\r\n    # Requires `roles/serviceusage.admin` on $TARGET_PROJECT\r\n```", "```suggestion\r\n    gcloud services enable compute.googleapis.com --project $TARGET_PROJECT\r\n```", "```suggestion\r\n    the Seed Service Account to your list of authentication credentials by issuing\r\n```", "```suggestion\r\n    the following command and importing the Seed Service Account key:\r\n```", "```suggestion\r\n    ```sh\r\n```", "```suggestion\r\nIf domain wide delegation is not granted to the Seed Service\r\n```", "```suggestion\r\nAccount, it will fail to obtain the access token needed to interact with the\r\n```", "```suggestion\r\non the Seed Service Account with the following scopes:\r\n```", "```suggestion\r\nThe Project Factory requires the following services to be enabled on the Seed\r\n```", "```suggestion\r\nProject. If these APIs are not enabled, the Project Factory may fail to generate\r\n```", "```suggestion\r\n  App Engine instance on the Target Project)\r\n```", "```suggestion\r\nThe Seed Project does not have the `cloudresourcemanager.googleapis.com` API\r\n```", "```suggestion\r\n* **Option 2:** create a new Seed Service Account and enable the required APIs:\r\n```", "```suggestion\r\n  ```sh\r\n```", "```suggestion\r\n  # requires `roles/resourcemanager.organizationAdmin` on the organization and\r\n```", "```suggestion\r\n  # `roles/serviceusage.serviceUsageAdmin` on $SEED_PROJECT\r\n```", "```suggestion\r\n  ./helpers/setup-sa.sh [organization id] \"$SEED_PROJECT\"\r\n```", "```suggestion\r\nThe Seed Project does not have the `cloudbilling.googleapis.com` API enabled.\r\n```", "```suggestion\r\nThis error will occur *once* when applying a Terraform plan when the Seed\r\n```", "```suggestion\r\nProject does not have the Cloud Billing API enabled. On subsequent Terraform\r\n```", "```suggestion\r\nnot enabled on the Target Project. Watch out for this!\r\n```", "```suggestion\r\nThe Seed Project does not have the `iam.googleapis.com` API enabled. This\r\n```", "```suggestion\r\n* **Option 2:** create a new Seed Service Account and enable the required APIs:\r\n```", "```suggestion\r\n  ```sh\r\n```", "```suggestion\r\n  # requires `roles/resourcemanager.organizationAdmin` on the organization and\r\n```", "```suggestion\r\n  # `roles/serviceusage.serviceUsageAdmin` on $SEED_PROJECT\r\n```", "```suggestion\r\n  ./helpers/setup-sa.sh [organization id] \"$SEED_PROJECT\"\r\n```", "```suggestion\r\nThe App Engine API is not enabled on the Seed Project, which prevents creation\r\n```", "```suggestion\r\nof an App Engine instance on the Target Project.\r\n```", "```suggestion\r\n* **Option 2:** create a new Seed Service Account and enable the required APIs:\r\n```", "```suggestion\r\n  ```sh\r\n```", "```suggestion\r\n  # requires `roles/resourcemanager.organizationAdmin` on the organization and\r\n```", "```suggestion\r\n  # `roles/serviceusage.serviceUsageAdmin` on $SEED_PROJECT\r\n```", "```suggestion\r\n  ./helpers/setup-sa.sh [organization id] \"$SEED_PROJECT\"\r\n```", "```suggestion\r\n* **Option 2:** create a new Seed Service Account and enable the required APIs:\r\n```", "```suggestion\r\n  ```sh\r\n```", "```suggestion\r\n  # requires `roles/resourcemanager.organizationAdmin` on the organization and\r\n```", "```suggestion\r\n  # `roles/serviceusage.serviceUsageAdmin` on $SEED_PROJECT\r\n```", "```suggestion\r\n  ./helpers/setup-sa.sh [organization id] \"$SEED_PROJECT\"\r\n```", "```suggestion\r\nThe Seed Service Account must have the following roles in order to fully create a\r\n```", "```suggestion\r\n### Seed Service Account missing roles\r\n```", "```suggestion\r\nProject Factory.\r\n```", "```suggestion\r\nThe Seed Service Account does not have\r\n```", "```suggestion\r\norganizationViewer role grants the Seed Service Account the ability to look up the\r\n```", "```suggestion\r\nUse `helpers/setup-sa.sh` to create a new Seed Service Account with the necessary\r\n```", "```suggestion\r\nThe Seed Service Account does not have `roles/resourcemanager.projectCreator`\r\n```", "```suggestion\r\non the active organization. The projectCreator role allows the Seed Service Account\r\n```", "```suggestion\r\nUse `helpers/setup-sa.sh` to create a new Seed Service Account with the necessary\r\n```", "```suggestion\r\nThese roles are required for associating the Target Project with the host VPC\r\n```", "```suggestion\r\nUse `helpers/setup-sa.sh` to create a new Seed Service Account with the necessary\r\n```", "```suggestion\r\nThe Seed Service Account does not have the `roles/billing.user` role on the billing\r\n```", "```suggestion\r\nSeed Service Account has the `roles/billing.user` role on the billing account.\r\n```", "```suggestion\r\n  echo \"than the Seed Project organization.\"\r\n```", "```suggestion\r\n # Seed Project\r\n```", "```suggestion\r\n   echo \"The Seed Project does not exist. Exiting.\"\r\n```", "```suggestion\r\n # Seed Service Account creation\r\n```", "```suggestion\r\n echo \"Creating Seed Service Account...\"\r\n```", "```suggestion\r\n # Grant roles/resourcemanager.organizationViewer to the Seed Service Account on the organization\r\n```", "```suggestion\r\n # Grant roles/resourcemanager.projectIamAdmin to the Seed Service Account on the Seed Project\r\n```", "Amended", "Amended", "Amended", "Amended", "Good call, changed to Glossary", "```suggestion\r\n* [Seed Project missing APIs](#seed-project-missing-apis) - The Seed Project is\r\n```", "```suggestion\r\n* [Seed Service Account missing roles](#seed-service-account-missing-roles) - The Seed Service\r\n```", "```suggestion\r\n  Account has insufficient permissions.\r\n```", "```suggestion\r\n  action to propagate to our systems and retry., accessNotConfigured\r\n```", "The ``` needs to be moved to the next line.", "```suggestion\r\nThe Directory Admin API is not enabled on the Seed Project, which prevents\r\n```", "Tiny nitpick: the trailing period in the URL breaks the anchor. Can we get that fixed up really quickly?", "@adrienthebo Good catch thanks.  Fixed in 32c25c2...2a6e1c2 "]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/73", "comments": ["The `core_project_factory` module doesn't have a `group_email` output.", "In this context `${project_name}` won't be interpolated, right? I might be mis-remembering but this seems like an expression that might be expanded by HIL.", "As far as I am aware, Terraform does not perform interpolation on variable descriptions.", "Since we've replaced this script with https://github.com/terraform-google-modules/terraform-google-project-factory/pull/35 can we delete this file?", "Why is this being moved down here?\r\n\r\nLet's not reorganize the README in an unrelated PR.", "Why is group_name not being given access?", "We should highlight this more prominently, probably at the top of the README.", "`group_name` and `group_role` should still be accepted.\r\n\r\nThe difference the GSuite-less version of the module will not support *creating* new groups, but it should still grant them access to the project.", "Did we drop the args_missing check?", "We should not drop this check.", "Still need this.", "Still need this.", "Still need to give compute.networkUser to the group.", "Can't drop this.", "Still need this", "This is core functionality.", "This is core functionality.", "This is core.", "The `group_name` docs should be in core.", "Move this into core.", "Move to core.", "Move to core.", "Move to core.", "We should maintain this as a pass-through output (just reflecting back the input, if any).", "Can still pass in a group, it just must already exist.", "Okay, I will make the necessary corrections.", "@aaron-lane Something strange is going on with this diff. Ex. it's showing this entire file as being added when 1.0-rc1 already contains it: https://github.com/terraform-google-modules/terraform-google-project-factory/blob/1.0-rc1/docs/upgrading_to_project_factory_v1.0.md\r\n\r\nCould you look into this?", "Why isn't this just the `local.gsuite_group_id`?", "We should update this description since the main project factory doesn't create the group for you.\r\n\r\n```suggestion\r\n   description = \"The email of the G Suite group fo the project, if provided\"\r\n```"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/67", "comments": ["When I ran the tests, this only included the \"extra service account\".", "Nit. Is it possible to split this onto multiple lines for readability?", "Nit, separate lines for readability.", "This format is good, easier to read. Please use everywhere."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/64", "comments": ["I think you can just use the self_link here", "Our standard is to use the strings \"true\" and \"false\" for boolean variables.", "Changed in amended commit 4483ccd", "Now that a string is being used, you need to check for the string explicitly. See how we handle random ID.", "When we check the `random_project_id` variable we don't do an explicit string comparison, as given by the following snippet from `main.tf:\r\n\r\n```hcl\r\nlocals {\r\n  temp_project_id        = \"${var.random_project_id ? format(\"%s-%s\",var.name,random_id.random_project_id_suffix.hex) : var.name}\"\r\n  # [...]\r\n}\r\n```\r\n\r\nI've also tested the behavior in the terraform console:\r\n```\r\n> \"${\"true\" ? 1 : 0}\"\r\n1\r\n> \"${\"false\" ? 1 : 0}\"\r\n0\r\n> \"${\"shrug\" ? 1 : 0}\"\r\n__builtin_StringToBool: strconv.ParseBool: parsing \"shrug\": invalid syntax in:\r\n\r\n${\"${\"shrug\" ? 1 : 0}\"}\r\n```\r\n\r\nThat behaves as expected, only allowing true or false and rejecting other strings.\r\n\r\nIf we do an explicit string comparison, we lose the validation of the input as a boolean:\r\n\r\n```\r\n> \"${\"true\" == \"true\" ? 1 : 0 }\"\r\n1\r\n> \"${\"false\" == \"true\" ? 1 : 0 }\"\r\n0\r\n> \"${\"shrug\" == \"true\" ? 1 : 0 }\"\r\n0\r\n```\r\n\r\nHave I missed something with how we should handle booleans?", "The issue is we're relying on Terraform's implicit coercion from \"true\" to 1 which is not guaranteed.\r\n\r\nhttps://www.terraform.io/docs/configuration/variables.html#booleans", "Mirroring @morgante's comment here. Once that's resolved have a \ud83d\udc4d from me.", "@adrienthebo Where did we land on this? Would like to merge soon.", "Per the earlier discussion, this comparison is valid but we should use `\"true\"` over `true` as the variable input. I've updated the use of the bare `true` in the tests and updated this PR."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/58", "comments": ["Why are we adding quotes around the string variables ?", "I believe running this might require the roles/organization.viewer role. This role should not be required for a module that creates projects.", "Is it possible to have some error codes that don't quite correspond to 'not being authorized' here ?", "This allows the receiving script to receive positional arguments that are empty, which in turn allows us to tell the difference between scripts that received no arguments, and scripts that were called with an empty `credentials_path` variable. Is this design too clever?", "I just rechecked this, and when a given user doesn't have `roles/resourcemanager.organizationViewer`, running `gcloud organizations list` returns an empty list but exits with a return code of 0. Do you think this authorization probe relies on brittle behavior?", "Certainly! My thinking is that we should indicate 1) that `gcloud` isn't authorized, 2) indicate the authorization options (user account, service account, VM instance with a service account), and 3) link to https://cloud.google.com/sdk/docs/authorizing to provide more information. Would that be sufficient?", "This implementation has been replaced, resolving this comment.", "This implementation has been replaced, resolving this comment.", "Has this test fixture been tested when the group is being created? A service account credentials JSON file is required when creating a group due to the limitations with default application credentials. I suspect that this fixture will fall over if `create_group` is set to `true`.", "It took me a second to recall this - the `full` test fixture [still requires a credentials_path](https://github.com/terraform-google-modules/terraform-google-project-factory/blob/6cfc2cc8593cf23f0d552252ba01ad8fc4a1c878/test/fixtures/full/extra_variables.tf#L17). We're dropping the `credentials_path` lookup here because this was just configuring a file for running `gcloud`. Because `gcloud` can be configured with the `CLOUDSDK_AUTH_CREDENTIAL_FILE_OVERRIDE` environment variable and inspec-gcp can be configured with the `GOOGLE_APPLICATION_CREDENTIALS` environment variable, we can push the entire matter of credentials out of testing and into the environment.\r\n\r\nSo good catch on this, but since this is only dealing with tests, this code should work correctly in the `full` test fixture with `create_group = true`.\r\n", "Variables must have descriptions.\r\n\r\n```suggestion\r\nvariable \"credentials_path\" {\r\n  description = \"Path to a Service Account credentials file with permissions documented in the readme\"\r\n}\r\n```"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/56", "comments": ["This makes `var.name` optional by supplying a fallback value, but doesn't make the `name` variable itself optional. Is this intentional? Can we change `name` to be optional and add validation similar to https://github.com/terraform-google-modules/terraform-google-project-factory/blame/master/main.tf#L55 to make sure that one of `random_project_id` or `name` is supplied?", "Out of curiosity, why was this switched from `random_id` to `random_integer`? Both should work equally well, but I'd like to see if there's a particular reason for this change.", "+1, also see my comment on this", "I wanted to create the project ID to be as close to a google generated one. They seem to be using a 6 digit integer. But yes both work equally well.", "var.name is now optional and uses the pet-name without the random int on the end.\r\nnull_resource validation has also been added."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/54", "comments": ["Should this be renamed to `SharedVpcProjectPermissions` to match the intended usage?", "`folder_id` is not used to verify folder permissions.", "Sure, would you like me to make that change or would you prefer to do it?", "We should run `terraform fmt` to fix up this formatting.", "For consistency's sake we should quote true.", "Since we renamed the preconditions script I think we should rename this to be consistent.", "It's been months since I've touched this pull request so my memory is foggy, but I recall running into issues where testing for the `resourcemanager.projects.create` permission required walking the parent folders and testing for the permission. I'm happy to revisit this, or remove the check entirely - what's your thinking?\r\n\r\nEdit - I believe the issue was actually on `resourcemanager.folders.get`, and there was some strange behavior that either rendered this check irrelevant or wasn't possible. Again, happy to revisit this, or we can excise this code.", "I added the validation back in to the logic and it appears to work. I tested it against an invalid folder ID and a valid folder ID with and without the `resourcemanager.folders.get` permission. "]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/53", "comments": ["The extension of this file is incorrect, it should be `.yml` but is `.json`.", "Small fixup: since we used a 2 space indent in the previous code, could we switch this block to use 2 spaces as well?"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/48", "comments": ["Let's put this at docs/TROUBLESHOOTING.md.", "Should we put Common Issues at the top of the list?", "Let's include a link to the README section which provides the exhaustive list, in case this gets out of sync.\r\n\r\nhttps://github.com/terraform-google-modules/terraform-google-project-factory/tree/adrienthebo/troubleshooting-guide#apis\r\n\r\nAlso let's add links from the README back to this FAQ for each of the APIs (I liked that you included an explanation of why the API is needed.", "I believe we use it to destroy the default network? I'd prefer to not remove it from the list but we can remove the Troubleshooting section.", "Also prevents it from granting access to groups, etc.", "We should also include an explanation of why each role is required, and link to this explanation from the README section.", "We should include a high-level link back to the [README](https://github.com/terraform-google-modules/terraform-google-project-factory/tree/adrienthebo/troubleshooting-guide#permissions).", "I was surprised to find that the README doesn't state `compute.googleapis.com` as an API - I always assumed it was there. Will delete this section from the troubleshooting guide."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/36", "comments": ["@aaron-lane one of the things I'd like reviewed or discussed is this regular expression. Since I'm trying to parse a context free grammar with a regular expression this is quite brittle, and I think we'd be better served by using a Python HCL parser to handle this - but that'll mean pulling in an outside dependency which is also problematic. What's your take on this approach?", "I think using a package like [pyhcl](https://github.com/virtuald/pyhcl) is preferable to a complex regular expression. pyhcl in particular only depends on [ply](https://github.com/dabeaz/ply/tree/master) which appears to have no dependencies of its own. Does that satisfy the concern about external dependencies?", "Yeah, anything is better than this regular expression. We can throw a `requirements.txt` in either `.` or `./helpers` to handle the dependency definition, do you have a preference?", "I think we should add a second directory under `./helpers` to isolate this particular script and its requirements from other scripts.", "Was the test file accidentally removed?", "Do we need to track the transitive dependencies of pyhcl?"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/35", "comments": ["Can `TERRAFORM_STATE_LIST` be converted to a list of strings to avoid splitting it by new lines later?", "Same question for `TERRAFORM_MIGRATED_RESOURCES` as `TERRAFORM_STATE_LIST`.", "Since `TERRAFORM_STATE_LIST` is only used here, can the elements which fail this check just be removed?", "`from_path` should have tests to prove its correctness, or `self.resources` should be hardcoded with the expected values so it does not depend on the correctness of `from_path`.", "Ditto regarding `from_path`.", "I think that I intended to check that we didn't touch any other resources but it appears that I didn't write tests for that. Think it's worth the effort to write those tests or should we just rip out the extra resources and the `.startswith` filter?", "Added test coverage for `from_path` and some light input validation (though if `terraform state list` outputs bad values, something has gone horribly wrong)", "Addressed in https://github.com/terraform-google-modules/terraform-google-project-factory/pull/35/commits/319f3012ba0406a1cf9e56b7c5b6545e28ece28a", "Addressed in https://github.com/terraform-google-modules/terraform-google-project-factory/pull/35/commits/50b5f827873b9cc33e283709b3b397c2e8143f0f", "`google_organization.org`  was extracted to the `google_organization` submodule as the logic around it was duplicated in `gsuite_enabled` and `core_project_factory`.", "`data_final_group_email` was refactored out of existence.", "`data_group_email_format` was refactored out of existence.", "`google_compute_subnetwork_iam_member.group_role_to_vpc_subnets` remains in `gsuite_enabled` so this rule must be restricted.", "`google_project_iam_member.gsuite_group_role` and `google_project_iam_member.controlling_group_vpc_membership` remain in `gsuite_enabled` so this rule must be restricted.\r\n\r\nIn case we test this script against test state, `google_project_iam_member.additive_sa_role` and `google_project_iam_member.additive_shared_vpc_role` remain in `full` fixture.", "In case we test this script on test state, `google_service_account.extra_service_account` remains in `full` fixture.", "`google_service_account_iam_member.service_account_grant_to_group` remains in `gsuite_enabled` so this rule must be restricted.\r\n\r\nIn case we test this script on test state, `google_service_account_iam_member.additive_service_account_grant_to_group` remains in `full` fixture.", "`google_storage_bucket_iam_member.group_storage_admin_on_project_bucket` remains in `gsuite_enabled` so this rule must be restricted.", "I've dropped this from the refactored resource list, and since it's a data source it won't cause issues.", "I've dropped this from the refactored resource list, and since it's a data source it won't cause issues.", "The refactoring of the shared VPC `roles/compute.networkUser` role means that we can't perform a simple migration through `terraform state mv`. I'm getting this diff:\r\n\r\n```\r\nAn execution plan has been generated and is shown below.\r\nResource actions are indicated with the following symbols:\r\n  + create\r\n-/+ destroy and then create replacement\r\n\r\nTerraform will perform the following actions:\r\n\r\n  + module.project-factory.google_project_iam_member.controlling_group_vpc_membership\r\n      id:      <computed>\r\n      etag:    <computed>\r\n      member:  \"group:pf-gsuite-migrate-group@phoogle.net\"\r\n      project: \"thebo-host-c15e\"\r\n      role:    \"roles/compute.networkUser\"\r\n\r\n-/+ module.project-factory.module.project-factory.google_project_iam_member.controlling_group_vpc_membership[1] (new resource required)\r\n      id:      \"thebo-host-c15e/roles/compute.networkUser/group:pf-gsuite-migrate-group@phoogle.net\" => <computed> (forces new resource)\r\n      etag:    \"BwV872YZKPU=\" => <computed>\r\n      member:  \"group:pf-gsuite-migrate-group@phoogle.net\" => \"serviceAccount:303471683246@cloudservices.gserviceaccount.com\" (forces new resource)\r\n      project: \"thebo-host-c15e\" => \"thebo-host-c15e\"\r\n      role:    \"roles/compute.networkUser\" => \"roles/compute.networkUser\"\r\n\r\n-/+ module.project-factory.module.project-factory.google_project_iam_member.controlling_group_vpc_membership[2] (new resource required)\r\n      id:      \"thebo-host-c15e/roles/compute.networkUser/serviceAccount:303471683246@cloudservices.gserviceaccount.com\" => <computed> (forces new resource)\r\n      etag:    \"BwV872YZKPU=\" => <computed>\r\n      member:  \"serviceAccount:303471683246@cloudservices.gserviceaccount.com\" => \"serviceAccount:project-service-account@pf-gsuite-migrate-group-23dc.iam.gserviceaccount.com\" (forces new resource)\r\n      project: \"thebo-host-c15e\" => \"thebo-host-c15e\"\r\n      role:    \"roles/compute.networkUser\" => \"roles/compute.networkUser\"\r\n```\r\n\r\nI think we're stuck with re-creating these resources or doing some serious state surgery, which increases the risk of something going wrong.", "These resources should only be moved when found within a project-factory Terraform module, so this won't be touched.", "Is there a risk in recreating those resources?"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/34", "comments": ["Bump to 4.0.3", "Remove `inspec-attributes.yml`", "Drop `provider.google.credentials` in favor of https://www.terraform.io/docs/providers/google/provider_reference.html#credentials", "Refactor this file into `test/fixtures/full` and `test/fixtures/minimal`", "Replace `config.sh` in favor of `terraform.tfvars`", "Provide trivial way of setting this value, eg:\r\n\r\n```\r\norg_id=$(gcloud organizations list --format='get(name)')\r\n```", "Provide trivial way of setting this value, eg:\r\n\r\n```\r\nbilling_account=$(gcloud alpha billing accounts list)", "Provide trivial way of setting this value, eg:\r\n\r\n```\r\ndomain=$(gcloud organizations list --format='get(displayName)')", "Drop this in favor of https://www.terraform.io/docs/providers/google/provider_reference.html#credentials", "Drop `credentials_path` variable.", "Drop `name` variable, store as a local within the test module, and shorten value.", "We should treat the `usage_bucket_prefix` as an internal name.", "If we create this bucket as a fixture resource created within the test module, we can drop this variable.", "Can we derive this value?", "Delete `random_project_id` variable.", "Drop `group_role` variable in favor of local internal name.", "Drop `sa_role` variable in favor of local internal name.", "Drop `region` variable in favor of `local.region = \"us-east4\"", "Prefer InSpec 2.3 global attributes.", "Never depend on environment variables for InSpec attributes - it makes the input sources weird.", "Use `JSON.parse` instead of `JSON.load`", "Replace local attributes with InSpec 2.3 global attributes.", "Use JSON.parse instead of JSON.load\r\n\r\n", "Break up InSpec controls into separate implementations instead of over-reusing.", "Use `JSON.parse(_, symbolize_names: true)`", "Use `JSON.parse` instead of `JSON.load`", "Use separate test cases instead of pending.", "Use `JSON.parse` instead of `JSON.load`", "Collapse these assertions into a single test.", "I'd prefer we be explicit here and leave as is, especially when considering CI environments.", "I'd prefer we be explicit here and leave as is, especially when considering CI environments.", "I think this is necessary to be passed into the project factory, at least until your other change lands.", "I'm fine with keeping it as a variable, in cases where we might need to override, but it should have a sensible default and we shouldn't encourage overriding.", "Yes, that's a good idea (assuming it can be created in the same project).", "I'm fine with keeping this as a variable, but it should have a default.", "I believe some prior art discovered deriving it is error-prone. Fine with keeping as-is.", "I'm fine with keeping this variable, so long as it has a sensible default and we don't override it.", "I'm fine with keeping this variable, so long as it has a sensible default and we don't override it.", "I'm fine with keeping this variable, so long as it has a sensible default and we don't override it.", "Agreed that this should be explicit. My thinking is that we should provide examples for how to look up these values to make it easier to run tests. When a new contributor clones down the module and is determining how to run the tests we should guide them through setting up variables by providing example commands - but we shouldn't run them by default.", "@adrienthebo I still think requiring users to fill out both files is a bit redundant. Could we use a symlink?", "Looks like this variable is required: https://github.com/terraform-google-modules/terraform-google-project-factory/pull/34/files#diff-cbbd4b12a5763e27f79ee004d7fed184R29\r\n\r\nVariables which *must* be filled in should not be commented out.", "This won't work for absolute credentials paths.", "Moved to https://github.com/terraform-google-modules/terraform-google-project-factory/issues/59", "Moved to #60 "]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/32", "comments": ["Did we change something? I believe this should include appengine as well.\r\n\r\nhttps://github.com/terraform-google-modules/terraform-google-project-factory/blob/ddda28e82e375b575320e18aa3c2f4e184df1cef/test/integration/gcloud/integration.bats#L22"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/31", "comments": ["Please run `terraform fmt`.", "`create_group` is not part of the core project factory.", "Why are these variables disjunct from `modules/gsuite_enabled/variables.tf`? Having two variables files might be a bit confusing.", "The quotation and interpolation of `\"${gsuite_group.group.name}\"` looks to be redundant; since we're already in an interpolation expression we should be able to replace that with `gsuite_group.group.name`.", "The deletion of these variables changes the outward facing APIs. Are these variables no longer available or does one have to use `modules/gsuite_enabled` in order to access these variables?", "My understanding is that the `data_final_group_email` and `data_group_email_format` null data sources were defined so that the `gsuite_override.tf` configuration could replace these data sources. Now that we've refactored the configurations into two modules, are these data sources still needed? Can we replace them with local variables?", "Great point, I totally missed this. But yes moving over to local can be done and it would be one less thing to have to move in the state file."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/30", "comments": ["I don't think this will sort semver correctly.\r\n\r\n```\r\ncat test.txt | sort -r\r\n3.9.4\r\n1.9.3\r\n0.9.11\r\n0.3.0\r\n0.11.2\r\n0.1.0\r\n```", "This script shouldn't handle the actual pushing.", "`-a` seems dangerous for this use case.", "In this case wouldn't 3.9.4 be the desired version?", "\ud83d\udc4d I will remove that ", "If we aren't handling the push do we need to handle the commit?", "This assumes the script will be executed from the `scripts/` directory, which is not a good assumption IMO.", "Shouldn't this be version?", "Fixed myself: https://github.com/terraform-google-modules/terraform-google-project-factory/commit/5687696520fa25aebcded2f7002cb7d9b0dcde36"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/14", "comments": ["This will default to no group with the refactor.", "Can't depend on a module, should depend on an output of the module.", "We should move the G Suite variables into their own file.", "Why are we skipping these tests? Guessing that's a mis-commit.", "true, should I make it default to ${project_name}-editors? or change the description to have it default to no group? My issue here being that if the default group doesn't exist, the apply will error out. ", "Instead of re-calculating these outside the module, why not add them as outputs to the core module?", "Please remove commented code.", "definitely should have done this earlier!"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/7", "comments": ["Nit. \"example\"", "Let's add a link somewhere in here to the [docs](https://cloud.google.com/kubernetes-engine/docs/how-to/cluster-shared-vpc).", "Do we need gsuite_admin_user for this example? I'd prefer to not require gsuite unless necessary.", "Nit. Whitespace. Please run `terraform fmt` on your PR.", "`sample-GKE-shared-project` => `sample-gke-shared-project`", "Let's consolidate `var.shared_vpc != \"\" && contains(var.activate_apis, \"container.googleapis.com\")` in a single local boolean test at the top.", "This should also test that Shared VPC is actually being used. (Reuse the same boolean I mentioned in above comment.)", "nope! we don't need it, I just had in there as an error pops up if the gsuite_override.tf file isn't deleted. ", "ah yes, makes a ton of sense", "`local.gke_s_account_fmt` looks wrong?", "yup, planning to add tests by hopefully the end of the week. \r\n\r\nand yup, that's super wrong. ", "had to add the conditional for the gke service account fmt on line 39 of main.tf as conditionals for lists in the iam bindings doesn't work in .11 (https://github.com/hashicorp/terraform/issues/12453)"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/4", "comments": ["Does this actually work? var.app_engine is a map, not a list.", "@ryanckoch We should not delete the app engine service account\u2014deleting it will [break](https://cloud.google.com/appengine/docs/flexible/python/access-control#service_account_for_app_engine) App Engine.", "It gets the length of keys in app_engine which is a list", "But then I'm confused about how line 86 works? https://github.com/terraform-google-modules/terraform-google-project-factory/pull/4/files/a51eb1f65e51143af5b7dff92d9ce2fa268cfb38#diff-7a370d8342e7203b805911c92454f0f4R86\r\n\r\nWhere do we actually pass in the keys from the map?", "local.app_engine_config is a map of lists with keys `enabled` and `disabled`. Line 86 is referencing that list by key depending if local.app_engine_enabled is true or false. If local.app_engine_enabled is true, it sets `app_engine` to the `enabled` list which is the users config, otherwise it uses the `disabled` list which is empty. It is a dirty hack, but the only way I could see to pass a completely empty list to `app_engine` and still be able to accept the `app_engine` variable as a map in our module. Otherwise, it would set `app_engine = [{}]` which isnt an empty list and tells the provider to setill enable app_engine.", "@ryanckoch This is hard to parse and somewhat confusing. \r\n\r\nWouldn't `app_engine = \"${local.app_engine_enabled ? var.app_engine : list()}\"` work just as well?", "It wont allow for a list in a conditional. That would definitely be much cleaner, but that is the reason for the hack app_engine_config map.", "How about `\"${local.app_engine_enabled ? local.app_engine_config[\"enabled\"] : local.app_engine_config[\"disabled\"]}\"`", "Also worth noting, that although the examples in the documentation show app_engine as accepting a map, it accepts a list with a max length of 1.\r\nhttps://github.com/terraform-providers/terraform-provider-google/blob/master/google/resource_google_project.go#L95\r\n\r\nHave created an issue on the provider: https://github.com/terraform-providers/terraform-provider-google/issues/1821", "Same:\r\n```\r\nError: module.project-factory.google_project.project: 1 error(s) occurred:\r\n\r\n* module.project-factory.google_project.project: At column 3, line 1: conditional operator cannot be used with list values in:\r\n\r\n${local.app_engine_enabled ? local.app_engine_config[\"enabled\"] : local.app_engine_config[\"disabled\"]}\r\n```"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-project-factory/pull/3", "comments": ["@ryanckoch Why is this dependency removed? The default compute service account won't appear until the compute API is activated.", "Because of an issue where it causes the dependent trigger to run on every apply:\r\nhttps://github.com/hashicorp/terraform/issues/11806"]}]}, {"url": "https://github.com/gfl/terraform-sandbox.git", "pull_requests": []}, {"url": "https://github.com/AErmie/TFCloud-IaC-Using-Terraform.git", "pull_requests": []}, {"url": "https://github.com/sworisbreathing/splunk-refactor-poc.git", "pull_requests": []}, {"url": "https://github.com/reechar-goog/key-reechar-tf-bootstrap.git", "pull_requests": []}, {"url": "https://github.com/hands-on-cloud/aws-codepipeline-terraform-cicd-pipeline.git", "pull_requests": []}, {"url": "https://github.com/pvandervelde/infrastructure.azure.core.network.hub.git", "pull_requests": []}, {"url": "https://github.com/yardbirdsax/elasticsearch-the-hard-way.git", "pull_requests": []}, {"url": "https://github.com/geraldwuhoo/homelab-iac.git", "pull_requests": []}, {"url": "https://github.com/firehawkvfx/firehawk-main.git", "pull_requests": []}, {"url": "https://github.com/jkstenzel95/jks.gameservers.git", "pull_requests": []}, {"url": "https://github.com/Eximchain/terraform-aws-quorum-cluster.git", "pull_requests": [{"url": "https://github.com/Eximchain/terraform-aws-quorum-cluster/pull/56", "comments": ["This is for the private key that BackupLambda will use to SSH the machines right? The one we set up as a FoxPass service account?\r\n\r\nIf that is the case lets name it something else please. Something maybe like `backup_lambda_ssh_private_key_path`. I generally assume `private_key_path` corresponds to the same key as `public_key_path` and it seems like that's not actually the case here.\r\n\r\nIf it does correspond to the same key we initially launch the network with, then why do we need it now?", "nit: Let's use `backup_lambda` rather than `BackupLambda` for these. I understand you were shooting for consistency with the name of the application but I'd rather not introduce camel case into the Terraform configs.", "nit: maybe `quorum_vpc_main_route_table_id` or `region_main_route_table_id` instead here? The route table doesn't really apply to the whole cluster as this would seem to imply.", "nit: unnecessary comment", "nit: add version strings to these providers. I'm pretty sure it tells you exactly what strings to add when you run `terraform init`", "nit: Double check that you need the null provider here and can't just inherit it. I know I've used it but it may or may not be in this module.", "This will break TFE because the file won't exist. You need to add the option to provide the key directly in the variables file. If you keep the option to load it from a file there will need to be a `count` variable that ensures this data source is not created if the key is passed directly. I've dealt with this before so you should be able to look to my handling of SSH keys for examples.", "Can this name be more descriptive than `object`?", "nit: Applies across this whole page but again, please no camel case in resource names. Using it in the variables like you do with `name_prefix` is fine.", "Is this rule necessary? I'm pretty sure they already have egress open everywhere on all ports.", "nit: leave an empty line after `count` variables", "nit: this applies to the whole page at least. Align your `=` horizontally among variable declarations that are on adjacent lines. ", "Per my earlier email I think we should be downloading already-zipped releases from GitHub", "Please use a more descriptive name for this", "Outputs should not be mixed with the rest of the configuration. Also, this looks like maybe it was left around when it shouldn't be?", "What are you getting out of saving the file? We can't expect it to stick around on TFE", "More descriptive name please", "Again outputs shouldn't be mixed with other config. Also this name is far too general for an output name in this module anyway. We need to specify its purpose.", "This seems like a scary security group. What is it used for?", "I prefer to use `aws_security_group_rule` resources rather than specifying rules inline", "If this is just for the lambda we don't need a big network. Maybe we should split this CIDR into a few subnets and just assign this to the first one?", "More descriptive name please. I don't actually know what this instance does.", "more descriptive name please", "Put a few examples in the description please", "Maybe get rid of this? If you think it's helpful, format it like the others.", "nit: These outputs are the same", "> This is for the private key that BackupLambda will use to SSH the machines right? The one we set up as a FoxPass service account?\r\n\r\nYes, it is.\r\n\r\n> If it does correspond to the same key we initially launch the network with, then why do we need it now?\r\n\r\nI'm confused. Your question seems to imply it's not needed. How would the BackupLambda connect to the nodes then?", "fixed", "fixed", "fixed", "fixed", "The entire Terraform configuration was developed modularly, in isolation from each other. This was used during development to ensure that instances can be reached and connected via SSH, to test VPC, and to test the BackupLambda subnet.", "gw1 -> gateway 1", "If it's the backup service account key then it's not the same key we initially launch the network with and I understand why we need it. Given this I just think the name should be changed.", "Renamed to quorum_vpc_main_route_table_id", "These are now using backup_lambda...", "Version strings added", "This has been renamed to quorum_vpc_main_route_table_id", "Version added", "Removed", "Fixed", "Now retrieving zip from GitHub", "Renamed", "I think this can be simplified to `value = \"${element(coalescelist(aws_vpc.quorum_cluster.*.main_route_table_id, list(\"\")), 0)}\"`\r\n\r\ncoalescelist seems a little cleaner to me for avoiding the empty list issue (though admittedly I only discovered it somewhat recently) and you don't need the conditional since you'd just be grabbing an empty string out of the list if the VPC doesn't exist.", "style nit: empty line after `count` variables", "style nit: put `depends_on` at the end of the resource with an empty line above", "Why is the count related only to the maker nodes in the region? Would we not want the backup to run in a region with only validators or observers?\r\n\r\nI suspect we want these resources if there are any nodes of any type, but if they're going to be only attached to one type of node I'd also suggest it should be validators. Let me know what the intent is here.", "nit: **Path to** SSH private key to be used for authentication **by the BackupLambda function**", "nit: SSH private key to be used for authentication **by the BackupLambda function**", "style nit: put `description` before `default`", "If you have a URL parameter shouldn't you be using it here?", "I'm searching through the PR and I can't find where this `backup_lambda_binary` variable is used. Please either point out where it is used, modify some hard-coded things to use this variable instead, or remove this variable completely.", "I'm searching through the PR and I can't find where this `backup_lambda_binary_url` variable is used. Please either point out where it is used, modify some hard-coded things to use this variable instead, or remove this variable completely.", "I'm searching through the PR and I can't find where this `backup_lambda_binary_path` variable is used. Please either point out where it is used, modify some hard-coded things to use this variable instead, or remove this variable completely.", "Thanks for adding this link. I was going to ask you to do that but you beat me to it.", "As discussed, backup 1 (randomly) of validators if it exist. If not, then 1 (randomly) of maker, and if not, then 1 (randomly) of observers.", "FWIW it doesn't actually need to be random, just arbitrary. May as well do it randomly if that's easy though.", "Examples done", "Fixed", "Fixed", "Used in definition of aws_lambda_function. Fixed.", "Used in fetching the BackupLambda from Github release. Fixed.", "**bump** this comment", "style nit: Add empty line before `tags`", "style nit: Add empty line before `route`", "**bump** this comment", "nit: Put the description you wrote elsewhere here as well", "I don't see this being specified anywhere. Is this variable used?", "It seems like you changed defaults to help with testing in this file. Please don't change default values unnecessarily.", "This looks like something you added for testing. Remove it please.", "So if you use this repository after a fresh checkout, where do things end up being downloaded?\r\n\r\nThere's 3 things per region here, are they all used?  This is a nit, but it might be preferable to put the things that are downloaded into a particular directory to avoid cluttering the workspace.", "`backup_interval` currently has no default. What happens if you run it with default values? (e.g. empty string for `backup_interval`)\r\n\r\nI think ideally this backup stuff would be optional and not setting `backup_interval` would disable all of it. I won't insist on that if you think it's more work to handle than it's worth, but it should definitely do something reasonable if I use default values.", "**bump** this comment\r\n\r\nI know there's Go code too but if you made this change you'll need to change the `count` variables, right?", "Arbitrarily in computing terms means random, unless you're talking about me choosing a fixed value, in that case, it's called fixed.\r\n\r\nAnd please provide a style guide so I can fix everything all at once.", "Your instructions were to fix existing changes first, then fix the count. Unless your instructions are suggestions, in which case, I would then ignore it.\r\n\r\nSo, which is it? Instructions or suggestions?", "In order to investigate cloudwatch metrics and alarms, and due to the way Terraform Enterprise works, I have to change defaults. If you have a better way, please provide instructions.", "Remove which? Please be specific.", "This refers to the line I made the comment on: `workingterraformvars.txt`", "Why can't you just set the variables in `terraform.tfvars` (Terraform) or the Variables tab (Terraform Enterprise)?\r\n\r\nYou're free to change the defaults for testing purposes but these variables will need to be changed back before I pull this in", "I'd recommend doing something like what I did with the .gitignore [here](https://github.com/Eximchain/terraform-aws-quorum-cluster/blob/master/terraform/modules/quorum-vault/certs/.gitignore).\r\n\r\nPutting that file in a directory allows you to check in the directory but keep it empty. It basically says \"Ignore everything except .gitignore itself\".", "Don't you still have to set these resources to be created if there are any nodes, rather than just any maker nodes?\r\n\r\nI recall us deciding to do backups on validators, makers, and observers in that order of preference, so we need these resources if there are any nodes, right?", "Should this be going into `terraform/temp`?", "style nit: add empty line above `tags`", "Please answer this question, I do want to understand the purpose of this resource.", "style nit: add empty line above `tags`", "style nit: add empty lines above `tags`", "Style nit: remove extra spaces after `vpc` as so: `vpc = true`", "style nit: add empty line above `tags`", "style nit: prefer `${element(aws_eip.gateway_ip.*.id, 0)}` over `${aws_eip.gateway_ip.0.id}`", "style nit: prefer `${element(aws_subnet.quorum_maker.*.id, 0)}` over `${aws_subnet.quorum_maker.0.id}`", "style nit: add empty line above `tags`", "style nit: add empty line above `route`", "style nit: prefer `${element(aws_nat_gateway.backup_lambda.*.id, 0)}` over `${aws_nat_gateway.backup_lambda.0.id}`", "Why introduce `aws_instances` here? What do you get out of it that you can't get out of individual `aws_instance` data sources?  I don't mind the idea of replacing multiple `aws_instance` data sources with a single `aws_instance`, but I strongly prefer not to include both.\r\n\r\nThis comment applies to other node types as well", "Can we do better than just relying on the `Name` tag here? Using tags like `NetworkId` and `Role` is probably less fragile.\r\n\r\nThis comment applies to other node types as well", "style nit: Please address this and put `description` above `default`", "Style nit: put `description` above `default`", "Style nit: put `description` above `default`", "Style nit: put `description` above `default`", "Style nit: put `description` above `default`", "Style nit: put `description` above `default`", "Style nit: put `description` above `default`", "This encrypts the SSH private key for the BackupLambda function to SSH to the nodes", "This is used for debugging", "Yes.", "aws_instances is introduced because your final list of output (maker_node, observer_node, validator_node) is empty after first runs.", "Wow this is a cool feature!\r\n\r\nstyle nit: move this above the `backup_lambda_ssh_private_key` data source, just under the providers", "style nit: use kebab case consistently here\r\n\r\nchange to `iam-role-for-backup-lambda-${var.network_id}-${var.aws_region}`", "Here you use the directory `${path.module}/tmp/` but in your .gitignore, you ignore the directory `terraform/temp`.  I'm guessing these are supposed to agree with each other. If so pick either `temp` or `tmp` and use it consistently. If they are supposed to be unrelated perhaps change the name of one so they don't seem like the same thing modulo a typo.", "same `tmp` vs `temp` issue as above", "style nit: put `locals` up at the top of the file just under any providers", "nit: I believe this tag should be `Name` rather than `name`\r\n\r\nI'm not sure if it's case sensitive for console display purposes ", "style nit: use kebab case consistently\r\n\r\nChange to `BackupLambdaSSH-${var.network_id}-${var.aws_region}-allow-all-outgoing`", "I don't think this is an appropriate tag, given that it's a subnet and not a node.\r\n\r\nIf you think it's helpful perhaps rename it?", "Same as above comment, I think this `NodeType` tag should have a different name on subnets.", "Bump this comment. Using the `Name` tag seems fragile. If you think it's better to use that than to use a combination of other tags please explain why.", "Is `BackupLambda` hosted by the `Eximchain` organization yet?\r\n\r\nIf not, we should put that in our organization and point this at `https://github.com/Eximchain/BackupLambda/releases/download/0.1/BackupLambda.zip` by default instead", "Same as comment on other variables file, ideally this would point to an eximchain repository.", "Can't locate where this is, but please explain fragile how?\r\nUnless someone else, either you or me is changing code at the last minute, I'm not going to change this now.\r\n", "${element....} is harder to read then .0.id, so not going to change this.", "Fixed.", "Fixed", "Fixed", "Fixed", "${element...} is harder to read than .0.id so not going to change this.", "${element...} is harder to read than .0.id", "There are access issues with Eximchain/BackupLambda for some unknown reason.\r\nIf you have time, please investigate, or delete the entire BackupLambda, so I can recreate it and see if that resolves the issue.", "I checked and it says you are Admin. What can't you do and what errors do you get when you try to do it? If you can't interact with it via CLI, are you sure you have an SSH key uploaded to GitHub in your SSH agent?\r\n\r\nFollow up with me on this via email if you need more help.", "Bump this comment.\r\n\r\nIt seems like `${path.module}/tmp/` used here doesn't agree with `terraform/temp` listed in `.gitignore`\r\n\r\nShould you replace with local `temp_lambda_zip_path`?\r\n\r\nThis comment applies for the whole resource", "nit: I believe the `name` tag should be capitalized as `Name` to work with the AWS console", "nit: default to `false` to make our lives easier when testing", "nit: default to false", "nit: default to false", "Fixed.", "Fixed", "Fixed", "Fixed"]}, {"url": "https://github.com/Eximchain/terraform-aws-quorum-cluster/pull/52", "comments": ["Super nit but could you throw this in a function?  I think it's complex and specific enough to put it in a function.\r\n\r\nI'd pass the `AWS_REGION` in as an argument and read `USING_EIP` from file within the function. Should be plenty of examples of both.", "I've never seen `load` used in bash. What does it do and are you sure you didn't mean `local`?", "Might as well make this `local readonly`", "You got me, must've misread earlier in the file -- I'm just trying to patternmatch you"]}, {"url": "https://github.com/Eximchain/terraform-aws-quorum-cluster/pull/37", "comments": ["nit: Throw the date template string into a global variable at the top", "Make these variables local please. If you do need access to it outside the function, create the variable in the main code path and pass it to the function as an argument.", "After making these changes, do I do a new PR, or what? No idea how to proceed.", "See main thread comment below."]}, {"url": "https://github.com/Eximchain/terraform-aws-quorum-cluster/pull/34", "comments": ["nit: The style of the variable name `BACKUP_BUCKET` isn't really appropriate anymore. I would prefer we changed it to lowercase `backup_bucket` and read the value from file here, in an else block (instead of reading from file earlier and overwriting it if the arg is set.\r\n\r\nI'd also prefer it was taken out of the `try:` block"]}, {"url": "https://github.com/Eximchain/terraform-aws-quorum-cluster/pull/33", "comments": ["What happens if we don't give it exactly the expected arguments? Can we make it explode nicely?\r\n\r\nI suppose I prefer using an actual library like argparse but since it's only ever called by a script I'm okay with leaving it if you think it's more trouble than it's worth", "May I ask what the logic is behind capitalizing some of these but not others?", "These methods are complicated enough I'd kind of like a docstring, or at least a very descriptive comment.", "Maybe use single quotes to delineate the strings to save a bunch of escaping? It'd be easier to read if it works out.", "Looks like you changed the name of the role but didn't change this to match. Preferably they'd be the same.\r\n\r\nYou could also interpolate it (which may be what I should have done in the first place) like `name = ${element(aws_iam_role.bootnode.*.name, count.index)}`", "Do these need to be set up here?", "Toss this into a function please", "EDIT: Just tested this behavior, the unpack throws an error if there are either too few or too many arguments.\r\n\r\nI'm thinking that since the script is only called via script and can only be called in one way with all the right args, argparse is overkill.  Happy to build that code in there if you think it's important, but this tuple unpacking gets my specific job done.", "This is fine as long as we make it fail loudly when we get too many args", "Unfortunately, HCL [requires all strings to be double-quoted](https://www.terraform.io/docs/configuration/syntax.html#terraform-syntax).  Agreed that it makes this chunk of code illegible as all hell.\r\n\r\nEDIT: Clarifying -- Python would handle those double-quotes just fine since it's a multi-line string, all that escaping is for bash's benefit.", "Not strictly up there, but I do want `NETWORK_ID`, `AWS_ACCOUNT_ID`, and `SETUP_FILE` to be global -- the values will be the same throughout the whole script execution and I'd rather not have them clutter up the function args.\r\n\r\nMaybe I ought to move the top-level declaration down to right before the `if __name__ == '__main__'` statement?\r\n\r\nEDIT: Moved those declarations down (and eliminated one unnecessary one) in the most recent draft.", "Some are globals, the others aren't -- no more logic than that.  With that in mind, the `XXX_COUNTS` variables a little further down probably don't need to be capitalized as they aren't globals.\r\n\r\nEDIT: Changed everything but my three key globals (`SETUP_FILE`, `NETWORK_ID`, `AWS_ACCOUNT_ID`) to use snake_case.", "Can you try switching to single quotes so you can get rid of all the escaping?", "nit: Put an empty line between `count` and `name`"]}, {"url": "https://github.com/Eximchain/terraform-aws-quorum-cluster/pull/29", "comments": ["Do we only need to do this once?", "Rename this to `bootnode_ip`, this is technically inaccurate", "Yup!  This only needs to happen when the node turns on, then the EIP is associated until it's explicitly reclaimed or reassociated with a new node.  When a replacement node spins up and re-runs the command, it will then get this IP.", "Remove or clean up these messages", "Maybe make this an `elif` statement that checks for 0 so if and when they break this behavior we can fail loudly in the else block?", "nit: throw a `-` at the end of this `name_prefix`", "nit: Align the `=`\r\n\r\nSo keep the longest variable name as-is and pad the others with spaces until the `=` align vertically.\r\n\r\nYou don't need to re-run the test since it's a purely cosmetic change", "Whoops, should have been more specific about the convention. What I meant was to line up the user data vars. \r\n\r\nThe convention is to line up `=` for any variables listed on consecutive lines. If you skip a line, the `=` don't need to align with the ones in the previous block.\r\n\r\nSo for example, `vault_dns` and `vault_port` should be aligned with each other, but don't need to align with `eip_id` above it or `consul_cluster_tag_key` below it"]}, {"url": "https://github.com/Eximchain/terraform-aws-quorum-cluster/pull/26", "comments": ["You can test this if you want. A private IP will start with 10 if I'm not mistaken.", "Probably so we don't accidentally destroy them? Not super important right now", "No it does not assume that, but it currently uses a single user-data for all bootnodes, and any difference between them comes from the terraform provider.\r\n\r\nI think you will need to turn this into multiple user-data.", "We can just throw that whole mechanism out.\r\n\r\nSince everything is run by user-data now, we just have it write the data first and we know the data is there. This was to fix a race condition between the user-data and the provisioner."]}, {"url": "https://github.com/Eximchain/terraform-aws-quorum-cluster/pull/19", "comments": ["Leave the whitespace lines around this please", "Can we not create this file? Pretty sure we don't use it now with your change and it's a security hole", "New commit addresses this & one below!", "Ooooh one more nit: Remove this newly unused variable"]}, {"url": "https://github.com/Eximchain/terraform-aws-quorum-cluster/pull/18", "comments": ["While you're doing this, explicitly mention that we expect naming conflicts running two networks with the same network id in the same AWS account", "We expect that path is correct for OS X in particular. Just mention that so there's less confusion.", "Didn't see this comment, gonna cut one more commit to fix it", "Most recent commit addresses both this & the other one -- should be good to go!"]}]}, {"url": "https://github.com/bretmullinix/terraform-for-beginners.git", "pull_requests": []}, {"url": "https://github.com/DKhan1998/cne-sfia2-project.git", "pull_requests": []}, {"url": "https://github.com/hmcts/ccpayfr-shared-infrastructure.git", "pull_requests": [{"url": "https://github.com/hmcts/ccpayfr-shared-infrastructure/pull/80", "comments": ["Do you want Premium SKU in all envs? For cost saving, I would only have Premium in Prod/AAT"]}, {"url": "https://github.com/hmcts/ccpayfr-shared-infrastructure/pull/78", "comments": ["```suggestion\r\n  name: \"ccpayfr-shared-infrastructure\"\r\n```", "```suggestion\r\n    - url: https://hmcts-reform.slack.com/app_redirect?channel=cc-payments-tech\r\n      title: \"#cc-payments-tech on Slack\"\r\n```", "```suggestion\r\n  owner: dcd_group_fees_pay_v2\r\n```"]}, {"url": "https://github.com/hmcts/ccpayfr-shared-infrastructure/pull/63", "comments": ["don't you want to swap to your team group? not this group, people shouldn't be in this group any more, (the replacement group is 'DTS CFT Developers')", "Hi @timja - Can we swap to this group **dcd_group_fees&pay_v2**? And also do we need to do any additional changes apart from this?", "yes you can change to that, that would be my recommendation, no other changes", "Thanks @timja. I have updated the group. Can you please approve ?"]}, {"url": "https://github.com/hmcts/ccpayfr-shared-infrastructure/pull/60", "comments": ["Use join function to remove string interpolations, where applicable.", "If app service plan is not used, this module can be removed. If this is removed, any reference to this module must be removed too.", "This change is related to creating a shared MI. This can be removed, unless you are trying to create a shared MI along with this change.", "Same comment as above.", "Add AzureRm version\r\n\r\nversion = \"=2.20.0\"", "Can be changed as follows. Replace the variable name test with a suitable name. Check for syntax errors if any.\r\n\r\nlocals {\r\n  test = {\r\n    \"Deployment Environment\" = var.env\r\n    \"Team Name\"    = var.team_name\r\n    \"Team Contact\" = var.team_contact\r\n    \"Destroy Me\"   = var.destroy_me\r\n  }\r\n\r\n  tags = merge(var.common_tags, local.test)\r\n}", "Done the interpolation changes", "suggested changes have been done", "For the ASP plan we would like to keep that as it is, as we are not sure about usage and impact as part of these changes.", "Added version as per review comments", "Done the changes as per review comments, also updated version to the latest 29.0", "Removed create_managed_identity    = true as per review comments", "Removed create_managed_identity    = true as per review comments"]}, {"url": "https://github.com/hmcts/ccpayfr-shared-infrastructure/pull/13", "comments": ["can you remove branch ref as it's merged right?", "remove forwardTo  here"]}, {"url": "https://github.com/hmcts/ccpayfr-shared-infrastructure/pull/6", "comments": ["We need to specify the pricing plan, as by default Azure assigns the most expensive", "We need to process the following outputs from the service bus and stored them in vault so they can be accessed by payments-api:\r\n\r\n \"outputs\": {\r\n    \"primarySendAndListenConnectionString\": {\r\n      \"type\": \"string\",\r\n      \"value\": \"[listkeys(variables('sendAndListenAuthRuleResourceId'), variables('sbVersion')).primaryConnectionString]\"\r\n    },\r\n    \"secondarySendAndListenConnectionString\": {\r\n      \"type\": \"string\",\r\n      \"value\": \"[listkeys(variables('sendAndListenAuthRuleResourceId'), variables('sbVersion')).secondaryConnectionString]\"\r\n    },\r\n    \"primarySendAndListenSharedAccessKey\": {\r\n      \"type\": \"string\",\r\n      \"value\": \"[listkeys(variables('sendAndListenAuthRuleResourceId'), variables('sbVersion')).primaryKey]\"\r\n    },\r\n    \"secondarySendAndListenSharedAccessKey\": {\r\n      \"type\": \"string\",\r\n      \"value\": \"[listkeys(variables('sendAndListenAuthRuleResourceId'), variables('sbVersion')).secondaryKey]\"\r\n    }\r\n}", "We need to provision the Function App Server Too for which there is no module yet", "We need forward to and forward to deadletter parameters added here and on the actual module", "it's set as \"Standard\" in our terraform module. ", "true.. no module yet. But that's a separate piece of work different from this PR.", "Lets talk about this with Jalal and all", "May be reading from terraform state file like this https://github.com/hmcts/bulk-scan-processor/blob/master/infrastructure/state.tf#L34 \r\nhttps://github.com/hmcts/bulk-scan-processor/blob/master/infrastructure/main.tf#L118", "deadletter q will be resolved later"]}]}, {"url": "https://github.com/gc-ss/demo-aws-env.git", "pull_requests": []}, {"url": "https://github.com/navdhayagnik76/terragoat.git", "pull_requests": []}, {"url": "https://github.com/kborovik/gcp-gke-vault.git", "pull_requests": []}, {"url": "https://github.com/dwp/dataworks-aws-bgdc-connectivity.git", "pull_requests": [{"url": "https://github.com/dwp/dataworks-aws-bgdc-connectivity/pull/5", "comments": ["you could simplify these by iterating over a list of maps. There's an example here https://github.com/dwp/dataworks-aws-ingestion-ecs-cluster/blob/master/security_groups.tf#L2"]}, {"url": "https://github.com/dwp/dataworks-aws-bgdc-connectivity/pull/4", "comments": ["This looks very odd. Why do you only want the route table attached to a single subnet? That means 2 of your AZs aren't going to route properly at all.\r\n\r\nOh, I see, it's a data source not a resource...where is the `bgdc_private` route table managed? Perhaps an output might be better here so you can reference it directly rather than having to hop through a data source?", "Why does BGDC need to route to PDM? The PDM cluster is ephemeral.", "We have a policy/approach of not using Network ACLs anywhere. Why does BGDC think it needs them/why aren't SGs enough?", "It's because Hive Metastore RDS sits in PDM subnets", "This will be refactored (i.e. NACL's set to allow all) when we convert VPC creation Cloudformation into TF. Until then just injecting a required NACL rule", "It's created by a Cloudformation script at the moment. This will be converted into Terraform soonish and all those data sources will go away."]}, {"url": "https://github.com/dwp/dataworks-aws-bgdc-connectivity/pull/2", "comments": ["```suggestion\r\n  auto_accept = true\r\n\r\n```"]}, {"url": "https://github.com/dwp/dataworks-aws-bgdc-connectivity/pull/1", "comments": ["This should be kept and commented out too if you are commenting out the job code", "Should it also have a Name tag?"]}]}, {"url": "https://github.com/Accurate0/infrastructure.git", "pull_requests": []}, {"url": "https://github.com/t-dever/public-reusable-aviatrix-terraform-modules.git", "pull_requests": []}, {"url": "https://github.com/nikkaushal/terraform-shipping.git", "pull_requests": []}, {"url": "https://github.com/darthfork/tf-infra.git", "pull_requests": []}, {"url": "https://github.com/JamesWoolfenden/terraform-azurerm-sql.git", "pull_requests": []}, {"url": "https://github.com/Midas-Protocol/webtwo-infra.git", "pull_requests": []}, {"url": "https://github.com/krishna98967/gittesting.git", "pull_requests": []}, {"url": "https://github.com/qagit0510/iac-repo.git", "pull_requests": []}, {"url": "https://github.com/apnmt/azure-cluster.git", "pull_requests": []}, {"url": "https://github.com/sweeneyb/iot-core-tf-for-esp32.git", "pull_requests": []}, {"url": "https://github.com/Carlovo/full-stack-app-aws.git", "pull_requests": []}, {"url": "https://github.com/akentosh/ec2-testing.git", "pull_requests": []}, {"url": "https://github.com/ImminentDomain/immdom-terraform.git", "pull_requests": []}, {"url": "https://github.com/hur/ctfd-gcp.git", "pull_requests": []}, {"url": "https://github.com/samq-ghdemo/terragoat.git", "pull_requests": []}, {"url": "https://github.com/GBergeret/tf-vpc-module.git", "pull_requests": [{"url": "https://github.com/gbergeret/tf-vpc-module/pull/11", "comments": ["- [x] Call VPC in non saving mode in test.f\r\n- [x] Test VPC non saving mode with instance in"]}]}, {"url": "https://github.com/h0n9/devops-playground.git", "pull_requests": []}, {"url": "https://github.com/trustypangolin/bedrock-foundation-template.git", "pull_requests": []}, {"url": "https://github.com/rust-lang/simpleinfra.git", "pull_requests": [{"url": "https://github.com/rust-lang/simpleinfra/pull/406", "comments": ["Originally, these two static constants were defined in Terragrunt. But they don't change depending on the environment and hardcoding them removes a potential panic if they'd accidentally got deleted.", "`.ok()` is used here to prevent issues with the logs causing a request to fail.", "is there a reason for including `host` if it's essentially derived from `url`?", "I did a really quick experiment with the `Remapper` processor on Datadog, but that doesn't seem to like using a nested attribute (`http.url_details.host`) as the source. So I'd say we just leave it in for now for simplicity."]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/389", "comments": ["Is there a \"$unused[*]\" or something needed here?\r\n\r\n(Maybe we should write this script in Rust, like the ssh auth scripts... If this runs as root this seems easy to get wrong and cause us, at least theoretical, trouble).", "> Is there a \"$unused[*]\" or something needed here?\r\n\r\nNo, since `$unused_cache_directories` is a multiline string and not a Bash array. \ud83d\ude05 But that question and specific implementation detail is probably not a bad reason to rewrite this in Rust. Would also make it much easier to write tests for the functionality. I'll give this a try and see how it would look...", "I've took a stab at this, but ultimately I think it's too much work to justify for me right now. I'd rather get the script deployed to resolve the current issue, and then create a GitHub issue so that someone else can rewrite the script as a Rust binary.", "You may also want to sweep `build-rust-analyzer` too, which is a secondary build dir recommended for r-a workflows: https://rustc-dev-guide.rust-lang.org/building/suggested.html#configuring-rust-analyzer-for-rustc", "I'll make a note of this in #390, which tracks rewriting the script in Rust. I fear adding more conditions to the `find` command will get unmanageable quickly. \ud83d\ude48"]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/377", "comments": ["```suggestion\r\n      values   = [data.aws_arn.src_bucket.account]\r\n```"]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/374", "comments": ["This seems like an excellent starting point, but I expect us to require expansion as needs arise - view only access is basically metadata only, not enough to do regular actions (e.g., re-drive messages on the eventual queue).", "Agreed. I wasn't able to find prior art for this, and I don't think we actually discussed how exactly we want to deal with this. The separate accounts make it quite easy to grant pretty broad permissions, simplifying management. But I also feel like we need to make sure we have some oversight to prevent accidents or abuse. Let's discuss this further in #t-infra."]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/365", "comments": ["Why is this syntax used? We're not enabling any optional features and afaik this does not disable default features. So why not just use `once_cell = \"1.18.0\"`?", "I'd prefer moving this into a constant, but also seem to vaguely remember that `once_cell` doesn't support that (yet)?", "Unwrapping here seems dangerous. I'm not sure how much debugging information we'll get if we just fail hard. Instead, I think it is better to change the return type of the function to `Result<(), Error>` and handle the error gracefully. And if we log an error with `error!`, we'll get to see that in the service logs.", "I honestly have no idea what happened here... \ud83d\ude02\r\n\r\nI'll fix it :)", "I don't think const is possible since the regex can't currently be constructed at buildtime", "hmm, can you think of a scenario where the unwrap would panic? the outer if let ensures that the regex matches and both of the captures are non-optional so I think unwrap is safe here for this regex \ud83e\udd14", "now that I think about it, I think I followed https://docs.rs/regex/latest/regex/#usage and used `cargo add` for the first time. is that the default for `cargo add`!? \ud83e\udd14 ", "No, at least not on my machine. \ud83d\ude05", "Yeah that's what I thought. Then let's leave it like this for now. \ud83d\udc4d ", "That's a good argument. I don't think this can panic in its current form, but I'm also somewhat paranoid about changes in the future and other people assuming, based on this example, that it's okay to `unwrap` in this binary."]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/355", "comments": ["Nit: I'd create a data source for the provider:\r\n\r\n```terraform\r\ndata \"aws_iam_openid_connect_provider\" \"gha\" {\r\n  url = \"https://token.actions.githubusercontent.com\"\r\n}\r\n```\r\n\r\n...and get the ARN from there. That way we don't hardcode the account id.", "This is an improvement over the current situation, but it'd be nice to scope these by the commit hash (`${aws_s3_bucket.artifacts.arn}/rustc-builds-try-alt/${sha}/*`). As far as I'm aware it might not be possible to do that in IAM directly (the commit hash is in the GitHub Actions OIDC claim, but it might not be possible to access it from IAM), but at that point I'd prefer having a lambda function validating the JWT and issuing a properly scoped policy.\r\n\r\nAlso, the `*`-less variant shouldn't be needed.", "For more context on why this would be helpful: right now a job can override artifacts from other jobs, so in theory a try build (triggered by a trusted reviewer) could override the artifacts of a previously merged commit / try build, while if we scope things by commit hash a build would only be able to write in their scratch space.", "Yeah, I looked into this a bit and it seems like the only way to do this is custom code, we can expose the SHA into the sub claim with a custom claim but I don't think we can parse it out from there.\r\n\r\nThe Lambda function sounds plausible, we do somehow similar for sync-team kickoff... it would mean custom code in this relatively sensitive area though. I guess the risk would mostly be that we just don't get it's benefits though - should be easy to avoid further escalation.", "My inclination I think is to not block on the further scope reduction at this time, I'm happy to work on it but I want to get new bors treating unblocked quickly.", "> Yeah, I looked into this a bit and it seems like the only way to do this is custom code, we can expose the SHA into the sub claim with a custom claim but I don't think we can parse it out from there.\r\n\r\nYeah, I remember a while back reading somewhere that it was possible to pass arbitrary custom claims into IAM policies if they had specific keys in the JWT token, but I can't seem to find that piece of docs anymore. It'd need work on the GitHub side to change those claims anyway, so it wouldn't be something we could rely on in a timely manner.\r\n\r\n> The Lambda function sounds plausible, we do somehow similar for sync-team kickoff... it would mean custom code in this relatively sensitive area though. I guess the risk would mostly be that we just don't get it's benefits though - should be easy to avoid further escalation.\r\n\r\nIndeed. A way to limit the damage would be to have the function call be authenticated with OIDC too, so the most damage would be a job overriding another job's artifacts (i.e. the status quo) compared to third parties obtaining tokens, but still, it'd be sensitive code.\r\n\r\n> My inclination I think is to not block on the further scope reduction at this time, I'm happy to work on it but I want to get new bors treating unblocked quickly.\r\n\r\nI think it's fine to land this now to unblock the new bors (it uploads to a different directory than current bors anyway, so no risk of overriding), but it'd be nice to have it in place in the future.", "> Yeah, I remember a while back reading somewhere that it was possible to pass arbitrary custom claims into IAM policies if they had specific keys in the JWT token, but I can't seem to find that piece of docs anymore. It'd need work on the GitHub side to change those claims anyway, so it wouldn't be something we could rely on in a timely manner.\r\n\r\nYeah, I'm not quite sure if the GitHub side has exactly the claim we'd need. https://token.actions.githubusercontent.com/.well-known/openid-configuration has a listing but I don't know if the head_ref for example is useful or just the branch name.\r\n\r\nhttps://docs.github.com/en/enterprise-cloud@latest/actions/deployment/security-hardening-your-deployments/about-security-hardening-with-openid-connect#understanding-the-oidc-token lists a `\"sha\": \"example-sha\"` but it's not documented and not clear whether example-sha would be a full commit hash or what.\r\n\r\n", "I think `workflow_sha` would be the claim we'd be interested in, as it'd be the hash of the commit containing the workflow we're executing.\r\n\r\nAlso, I found the AWS feature I was thinking of: [Session Tags](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_session-tags.html#id_session-tags_adding-assume-role-idp). If the proper tag was passed in the JWT, then we could have `${iam:ResourceTag/workflow_sha}` in the IAM policy I think. But that's not applicable for us because GHA doesn't put the claims under the `https://aws.amazon.com/tags` key.\r\n\r\nEdit: the `sha` in the docs might be legacy, before they split `workflow_sha` and `job_workflow_sha` due to the introduction of reusable workflows.", "Actually @Mark-Simulacrum found this out looking at that issue https://awsteele.com/blog/2023/10/25/aws-role-session-tags-for-github-actions.html.", "Interesting! I did see some references to Cognito, we should try to figure out how complicated/pricey it'll be."]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/336", "comments": ["Why does Wiz need to create KMS keys?", "This seems like it allows Wiz to effectively bypass any KMS policies we might establish? We don't today, but if we e.g. managed signing keys as a kms resource I think this would allow wiz to sign things?", "Can we allowlist instead or in addition to denylist, with an alarm/audit to make sure all buckets are listed?", "I dug into this some, it appears to be able to scan KMS keys and use the DescribeKey policy mainly; it utilizes `CreateKey` and `CreateGrant` to allow itself to call KMS and perform `DescribeKey` for iterating vulnerabilities in keys (weak keys, expiration, usage across the infrastructure, etc).\r\n\r\nSince we don't use KMS right now, lets just drop these permissions. We can revisit explicit allowances if we ever are worried about vulnerabilities in that aspect (Hint: I don't think we ever will be)", "Since we don't use KMS right now, lets just drop these permissions. We can revisit explicit allowances if we ever are worried about vulnerabilities in that aspect (Hint: I don't think we ever will be)", "I'd argue with an allow list we would be losing benefit we get from Wiz s3 monitoring, which is getting insight into new buckets and making sure they were established correctly. I am more concerned about a bucket being stood up and used with unintentionally incorrect settings/permissions out-of-band than settings being changed on an existing bucket we know about (although that is also a concern). \r\n\r\nAre you suggesting we have a out-of-band job, maybe a validation lint here in `simpleinfra`, that confirms that the allowlist matches all buckets currently in existence mod explicit denials?", "Yes, I was under the impression that Wiz already is doing that validation - basically, I am 100% onboard with every bucket having an explicit decision, but I want that decision, at least while we still have buckets with sensitive contents. If we e.g. switch to using KMS encryption for terraform state and any other secrets in s3 rather than just s3 key encryption, then we wouldn't need this (can just not grant KMS key access so the objects aren't interesting).", "If I'm not missing anything, the only actions that Wiz is allowed to take on S3 are:\r\n\r\n- `s3:GetBucketNotification`\r\n- `s3:GetMultiRegionAccessPointPolicy`\r\n- `s3:ListMultiRegionAccessPoints`\r\n\r\nThose seem fine to have enabled for all buckets, even sensitive ones we create accidentally. Personally, I don't think it's worth the added complexity to maintain an allow list manually and create a script/GitHub Action that periodically checks the list against our AWS accounts.", "Now I'm confused, because those don't seem like enough to even get a list of buckets or check any of the policies I'd expect Wiz to want to check? Are we sure these permissions are a complete list?\r\n\r\nBut yes, I agree that if we're not granting object access then it's not important to filter buckets. I'm surprised that we're not required to grant *some* kind of access though (e.g., at least to generate inventories or similar, to check ACLs etc.)", "I totally missed that the AWS-managed [SecurityAudit](https://docs.aws.amazon.com/aws-managed-policy/latest/reference/SecurityAudit.html) group also includes a bunch of permissions for S3.\r\n\r\n```\r\n\"s3:GetAccelerateConfiguration\",\r\n\"s3:GetAccessPoint\",\r\n\"s3:GetAccessPointPolicy\",\r\n\"s3:GetAccessPointPolicyStatus\",\r\n\"s3:GetAccountPublicAccessBlock\",\r\n\"s3:GetAnalyticsConfiguration\",\r\n\"s3:GetBucket*\",\r\n\"s3:GetEncryptionConfiguration\",\r\n\"s3:GetInventoryConfiguration\",\r\n\"s3:GetLifecycleConfiguration\",\r\n\"s3:GetMetricsConfiguration\",\r\n\"s3:GetObjectAcl\",\r\n\"s3:GetObjectVersionAcl\",\r\n\"s3:GetReplicationConfiguration\",\r\n\"s3:ListAccessPoints\",\r\n\"s3:ListAllMyBuckets\",\r\n```", "Okay, in that case it looks like Wiz isn't even requesting GetObject permissions -- maybe the right thing to do is for us to explicitly deny that permission (globally, across all buckets) and otherwise not need a deny list on these buckets?", "The Wiz-provided module had another resource that would request `GetObject` _if_ data scanning was enabled. But I removed that resource when copying over the policies, since we're not planning on enabled the feature anyways.\r\n\r\nYou mean changing the last block to something like this:\r\n\r\n```json\r\n{\r\n  \"Action\": [\r\n    \"s3:GetObject\"\r\n  ],\r\n  \"Effect\": \"Deny\",\r\n  \"Resource\": [\r\n    \"*\"\r\n  ],\r\n  \"Sid\": \"WizAccessS3\"\r\n}\r\n```", "Yes, exactly. I think that covers our bases and avoids needing bucket name matches (which could diverge accidentally).", "Done."]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/335", "comments": ["I think we can remove `usermod.yml` and simply add the call to `set_shell.yml` at the end of the list:\r\n\r\n```yaml\r\n- name: Set shell\r\n  include_tasks: set_shell.yml\r\n  with_items: \"{{ vars_user_config }}\"\r\n```", "Small nit: I would rename this to `Check user {{ item.username }} exists`.", "This we can probably remove for the final version.", "I tested this on `staging` and think that this needs to be:\r\n\r\n```suggestion\r\n  ignore_errors: yes\r\n```\r\n\r\nOtherwise the playbook will continue with the `Set the user shell` task and create the missing user.", "yes, you're absolutely right\r\n"]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/317", "comments": ["If this becomes an issue, because people without access to SSM want to deploy staging services, we can just move this into the group vars for the dev-desktops. I want to deploy the agent on staging _somewhere_, but it doesn't have to be on all machines necessarily."]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/313", "comments": ["Based on last ~30 days I think this would mean 339 million * $0.60/million requests - so roughly an extra ~$200/month. I think if we can switch to cloudfront functions we get 6x cheaper pricing ($0.10/million requests) and presumably roughly the same functionality for the redirects desired here?", "Great suggestion! I refactored the code to use a CloudFront function instead."]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/289", "comments": ["We may want to move this back to 50/50 or something, since otherwise we're not testing that CF is working on dev-static.", "I'm afraid that realistically the traffic volume against `dev-static` isn't high enough to have a lot of confidence whether both are working anyways. We'll have to test changes against both CDNs manually whenever we make them. But I'll drop this to 50/50 and to the same for `static.staging.crates.io`.", "Yeah, that's true. I think some amount of passive testing is likely though (e.g., when we announce a pre-release). That will help with changes upstream that aren't caused by us - things like the artifact size limitations we ran into previously - while being low-cost on our end."]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/282", "comments": ["The other parameters are all hard-coded to a single `/prod` version. For Fastly, I created two tokens and scoped them to the respective service so that each environment can only interact with its own service."]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/281", "comments": ["Unsure what the intention of this is but does this elevate the usage of a feature is is legacy / deprecated?   We don't even document this in the [manifest documentation](https://doc.rust-lang.org/cargo/reference/manifest.html) and many of us have gone a long time without even knowing it exists (preparing the PR to merge `cargo add` into `cargo` was when I learned of it after all of my other `cargo add` work)."]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/274", "comments": ["noncurrent_days = 30 is our expiration timeframe which we may want to shrink (256 MB * 24/day * 30 days is ~180 GB, feels a little excessive). But that's still quite cheap so I'm fine either way.", "Note that the index is actually 44 MB. I forgot to look what the other storage was used for in the EFS (and I don't really want to spin up everything to access the EFS again), but I have a good guess on what that might be.\r\n\r\nRLA uses the [`atomicwrites`](https://docs.rs/atomicwrites/latest/atomicwrites/) crate to write the file to disk, and that crate works by creating the file first in `.atomicwritesRANDOM/`, and then atomically moving it. I noticed while working on my PR that if the server is shut down when writing to the temporary directory, that directory will be orphaned.", "So in short it might actuually be ~30 GB, which IMO is negligible.", "Ah, sounds good. Then yeah, let's not worry about this for now."]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/264", "comments": ["Why is this under `/prod/crates-io`?", "Doesn't matter that much, but it'd be nice to use `jsonencode()` here rather than plaintext JSON.", "We have more blocks like this in Terraform. Let me prepare a separate PR to switch them to `jsonencode`.", "If I remember correctly, the first version had the fastly-exporter in the crates-io module before I realized it would be better to have it as a separate module/service."]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/262", "comments": ["Hard coding these and the domain seem fine, but we may want to consider passing them as variables. ", "I'm surprised by wanting an entire cloudfront distribution. Is the reason for this getting the http to https redirect?", "Why are we using JavaScript for this one and Python for the other lambda?", "I would like access to this as well if possible.", "If we're going to implemnent AWS sync (which I'd love to), having admin access to this account would mean escalating privileges to infra-admin levels. It's best to keep perms restricted here.", "I remember spending hours to try and get the Python version to work without success, and switching to js fixed the problem.", "The cloudfront distribution is needed to have the custom domain, which is less phishable than the random lambda URL.", "I don't think a CF distribution is a problem, seems pretty lightweight from most perspectives. I think this is fine for now.", "I think we should grant read-only access (which is safe?) but that can happen separately.", "We would then need to restrict accessing the parameters from the read-only account, and make sure logs are sanitized.", "Sure. We should probably do that anyway for all humans (i.e., parameters shouldn't be readable by infra-admins either, IMO)."]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/243", "comments": ["Seeing the current filesystem usage (~100 GB) I would prefer something at least double this size. \r\n\r\n( of course the current usage also includes the database & some web cache)", "It would be nice if we didn't need so much storage. I believe a large part of that storage is only needed during a single crate's build and afterwards can be deleted, no? Would it be possible to add some clean up to the builder process so that the filesystem usage doesn't grow so large?", "Hm.. we _are_ cleaning up after the build. \r\n\r\nPlus the cleanup tasks for docker images, which are in cron right now. \r\n( btw, cc @Nemo157 @jyn514 , these cronjobs would need to be configured in our ansible images too, right? )\r\n\r\nOnly looking at the above I could totally imagine to just try with the current definition above, let the builder build, and watch how much space is used. ( assuming the big docker image is configured?)\r\n\r\nBut, we're also planning on adding some build artifact caching: https://github.com/rust-lang/docs.rs/issues/1757 \r\n( of course we could increase storage only then, when that feature is finished)", "Yep, we just have a daily cronjob (systemd-timer) running `docker container prune --force && docker image prune --force` (and cargo-sweep which shouldn't be necessary if we rebuild the image for a new version?).", "Where is the cronjob currently configured? I can add this to the Ansible configuration (though I wouldn't block merging this).", "It's in\r\n\r\n```\r\n/etc/systemd/system/prune-disk-space.service\r\n/etc/systemd/system/prune-disk-space.timer\r\n```", "I'm confused what the autoscaling does when you've pinned it to always be at one instance?", "It assures that there's one healthy instance. So if one instance stops or gets terminated a new one boots. "]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/241", "comments": ["I *think* GetObject isn't necessary and it only needs ListBucket.", "we shouldn't need CreateBucket I don't think?", "I believe that it the bucket doesn't exist (albeit an unlikely possibility), the worker can create the bucket. ", "We only ever create a bucket in tests, not in prod: https://github.com/rust-lang/docs.rs/blob/d97bbf54b25362e1d1010f7fb6e29c5324cfb0a6/src/storage/s3.rs#L58", "yep, I'm quite certain we don't need `GetObject`", "we're actually only using the `DeleteObjects` action, my guess would be that's a separate permission? ", "As far as I can tell, there is only `DeleteObject` which is used whether deleting a single object or many objects.", "Would [this](https://github.com/rust-lang/docs.rs/blob/d97bbf54b25362e1d1010f7fb6e29c5324cfb0a6/src/storage/s3.rs#L74-L79) not fail without that permission or perhaps this is not being used by the builder?", "I don't think we should grant the builder create bucket in any case, it's too easy to get that wrong - and the bucket is then not controlled by terraform, which also seems bad.\r\n\r\nGranting delete bucket is also hopefully not necessary, since it'll be hard to avoid deleting production bucket if things aren't configured right or whatever.", "Unfortunately [deleting is currently necessary](https://github.com/rust-lang/simpleinfra/issues/238#issuecomment-1427980920).", "Removed this and it still seems to work.", "Removed CreateBucket", "I was specifically referring to delete bucket, not object, but yeah, looks good."]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/234", "comments": ["this process will also include: \r\n- the repository-stats-updater (pulls stars, issues etc from github & gitlab) \r\n- the cdn invalidation queue handler \r\n\r\n", "I've been experimenting a little bit with the flowchart. Would be nice to have the request cycle as a straight line at the center and the other nodes on the top or at the bottom, but I haven't figured out if that's even possible with Mermaid.\r\n\r\n```mermaid\r\nflowchart LR\r\n    subgraph Legend\r\n        direction TB\r\n        dns([DNS Record])\r\n        infra[Service]\r\n    end\r\n\r\n    crates([crates.io]) -. DNS ..-> CloudFront\r\n    alb([ecs.docs-rs-prod.rust-lang.net]) -. DNS .-> ECSLB\r\n\r\n    User -- Request--> CloudFront\r\n    CloudFront --> ECSLB[Application Load Balancer]    \r\n    ECSLB --> service[ECS Service]\r\n    \r\n    subgraph ecs [ECS Cluster]\r\n        service --> Container\r\n        service -.-> task[Task Definition]\r\n    end\r\n```", "Wow! Your Mermaid foo is *much* better than mine..."]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/231", "comments": ["hmm, why does this need root access? I guess docker effectively gives you root permissions already though.", "How did you determine this number? I'm not sure 50 GB is enough; how often is this builder going to be torn down and recreated? Cargo has several caches that grow without bound, we ended up bumping this all the way to 200 GB in prod because we kept running out of space on the 100 GB disk.", "Is there an upgrade path for changing this if we ever fix https://github.com/rust-lang/docs.rs/issues/244 ?", "This shouldn't be necessary?", "What does `chdir=` do? In shell syntax it just sets an env variable, it doesn't actually change the directory.", "FYI: this is a small bug fix. The version gets printed to stdout and not stderr. Without this change, the block was always being run.", "Maybe allow restarting too? How are we going to manage the service in prod if we run into issues?", "Don't have time right now but I want to compare this to what we're running in prod.", "This is wrong, it needs to be using the full image, not linux-micro.\r\n\r\nFor staging it's ok, but it need to be changed before we put things into prod.", "This was completely unscientific. I took what the playground is using (which was my basis for these tasks) and added some zeros until I didn't run out of memory. I think we'll need to think more about this...", "Seems to work with the micro one. Do you know what the difference between the two is?", "Sounds good. We can also land this now and iterate on it as we go forward too.", "The micro one doesn't support all the crates on docs.rs, only crates that have no C dependencies.", "Yes, I think we would just create a new image with a different executable path. This does make me think that we should probably control which commit of docs.rs we're checking out ", "Things like upgrading the apt-get cache are locked to root. I bet we could make this better at some point...", "yes please, deploys should be explicit, not on every merge to master", "ok, here's the existing config:\r\n```\r\n[Unit]\r\nDescription=Cratesfyi daemon\r\nAfter=network.target postgresql.service\r\n\r\n[Service]\r\nUser=cratesfyi\r\nGroup=cratesfyi\r\nEnvironmentFile=/home/cratesfyi/.docs-rs-env\r\nExecStart=/home/ubuntu/docs.rs/target/release/cratesfyi daemon\r\nWorkingDirectory=/home/ubuntu/docs.rs\r\nLimitNOFILE=20000\r\nRestart=on-failure\r\n\r\n[Install]\r\nWantedBy=multi-user.target\r\n```\r\nThe file limit I *think* should be ok to omit because we now upload files as .zips instead of .html, but I'd prefer to keep it around until we have everything else working. `Restart=on-failure` looks important. Environment file is ok to omit since it's configured directly in the .service file, but ideally we'd have some way to configure `DOCSRS_TOOLCHAIN` in prod in case we need to lock it to a specific version.\r\n\r\nHere's the env file:\r\n```\r\nDOCSRS_PREFIX=/opt/docs-rs-prefix\r\nDOCSRS_DATABASE_URL=postgresql://cratesfyi@%2Fvar%2Frun%2Fpostgresql\r\nDOCSRS_GITHUB_ACCESSTOKEN=redacted\r\nDOCSRS_RUSTWIDE_WORKSPACE=/home/cratesfyi/workspace\r\nDOCSRS_TOOLCHAIN=nightly\r\nDOCSRS_BUILD_CPU_LIMIT=3\r\nDOCSRS_STORAGE_BACKEND=s3\r\nDOCSRS_LOG=docs_rs=debug,docs_rs::web::strangler=info,rustwide=info\r\nRUST_BACKTRACE=1\r\nSENTRY_DSN=https://redacted@redacted.ingest.sentry.io/redacted\r\nCACHE_CONTROL_MAX_AGE=600\r\nCACHE_CONTROL_STALE_WHILE_REVALIDATE=86400\r\nCLOUDFRONT_DISTRIBUTION_ID_WEB=redacted\r\nCLOUDFRONT_DISTRIBUTION_ID_STATIC=redacted\r\nDOCSRS_CDN_BACKEND=cloudfront\r\n```\r\nAll the CACHE_CONTROL vars are important to keep - cc @syphar @jsha to confirm. DOCSRS_CDN_BACKEND and the CLOUDFRONT vars are important to keep. SENTRY_DSN and the GITHUB_ACCESSTOKEN are important. We need some way of configuring secrets, I'm not sure how you're doing that today.\r\n\r\nI think it's ok to drop `DOCSRS_BUILD_CPU_LIMIT`, that's set so we can run the web server in parallel but this is just the builder without a web server.", "Is there a way to make this append-only, so it can't delete or read existing files?", "I think the correct argument for the pure builder is `start-build-server`. \n\n", "See also https://github.com/rust-lang/docs.rs/pull/1785", "`CACHE_CONTROL_MAX_AGE=600` can be deleted; we don't use that config field anymore.\r\n\r\n`CACHE_CONTROL_STALE_WHILE_REVALIDATE=86400` should stay; we still use that.", "Would the build-server only get the config that it needs for the builds? \n\nOr should the config be the same across the server / container types? \n\nWhile it feels cleaner to only have the needed config here, \ndue to the shared the codebase it could lead to bugs when we do changes. ", "ah good point, I forgot that CACHE_CONTROL is only used by the web server - ok, those variables are probably unnecessary then. the CLOUDFRONT variables are still necessary since we invalidate the cache after a build, though.", "> ah good point, I forgot that CACHE_CONTROL is only used by the web server - ok, those variables are probably unnecessary then. the CLOUDFRONT variables are still necessary since we invalidate the cache after a build, though.\n\nThat's the kind of questions that made me think if we should have the same config / environment in all server types. At least until we reflect this in our implementation so a developer wouldn't assume locally / in testing that the config is available. ", "The environment variables exposed to the worker vs the web frontend are configured separately in this repo. The web frontend is given its env variables through the terraform config [here](https://github.com/rust-lang/simpleinfra/blob/cb2b9920774a63bd54b3676f2b669ea1e777a91e/terragrunt/modules/docs-rs/web-server.tf#L20-L28) while the worker gets its environment variables through the systemd unit file created through Ansible [here](https://github.com/rust-lang/simpleinfra/pull/231/files#diff-1f5d5ca0e1ea04bafd26697d106e95e5d1d27f2cc4b26e0d7d0138862b46648a). \r\n\r\nIt would be pretty difficult to unify these two. I personally think it's best we start treating these two parts of the system separately as they will only become more and more separate over time. ", "Yes, we can set the Action above to only non-delete write operations.", "Just to be clear, this has nothing to do with *when* deploys happen. A push to master does not cause a deploy. Deploys are currently very much explicit (in fact, too explicit right now as there is a lot of manual work currently needed to deploy a new version). My comment is instead about controlling *what* gets deployed. As it stands, whenever deploys are kicked off, whatever happens to be on master will be deployed. Instead we should make sure which revision gets deployed is controllable. ", "I pushed a change that takes a specific sha from parameter store. We'll want to think more deeply on what exactly deployment looks like, but I think this is good enough for a first step.", "I tried moving to only allowing the following actions:\r\n\r\nPutObject, PutObjectTagging, PutObjectAcl, CreateBucket\r\n\r\nThis failed in a strange way. All artifacts were created and successfully uploaded to the s3. The logs only showed one error which simply stated that the library in question could not be documented (even though it clearly was successfully being done so). There were no other errors in the logs as far as I could see to indicate some additional error. Any idea what might be happening here?", "I've updated the unit config with the suggestions here except for the CLOUDFRONT variables. I need to understand invalidations a bit better before I can make that change. I personally would prefer we not block merging this PR before we tackle that issue. The point of the staging environment is that we don't need to be perfect before deploying it.", "\ud83d\udc4d "]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/221", "comments": ["I guess renaming is not an easy operation? This name is pretty opaque..", "This is only true of the root account I believe. Should we add account.json files for the other accounts?", "It's not as easy as changing the name in Terraform and running `apply`. We would have to change it as the admin user through the AWS console, and I'm not sure what the impact of that would be. It's something that we can look into, but it has a pretty low priority on my backlog right now.", "We've added that file to all accounts in https://github.com/rust-lang/simpleinfra/pull/168."]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/219", "comments": ["The changes in the rest of the files are fine, but I'd like to keep the shorter ID here. There is no chance of a collision happening (the `gpg` command is run inside an ephemeral `GPGHOME` with just that key in it), and the shorter ID doesn't hide the command we're trying to run.", "I've reverted the change in the readme :+1: "]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/217", "comments": ["@albertlarsan68 \r\n```suggestion\r\n      - lldb\r\n```\r\n`llvm` is already installed. Is this what you meant?", "Yes, thanks!"]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/212", "comments": ["Is this something that we want to add as a plain text variable or put into a secret?", "Do we want to log all requests or just `static.crates.io`? AFAIK requests to the app should be logged already.", "The application itself already has request logs in Papertrail, those are probably fine for that purpose. I think just logging static.crates.io will be enough for now.\r\n\r\n(crates.io itself serves comparatively little bandwidth, though most static.crates.io requests are redirects from crates.io I believe).", "(But it might make this more complicated to limit the logging -- logging all requests seems also fine to me).", "I *think* we should probably treat it as a secret; any requests coming out of the Fastly AWS account in possession of this ID can assume the role in our account. No one other than Fastly should be issuing such requests of course but no need to expose it IMO.", "Yeah I feel better if we keep this private as well \ud83d\udc4d ", "I've removed logging from the other two CloudFront distributions and left it untouched for `static.*`.", "`date` and `time` are serialized using the `serde-human-readable` feature in the `time` crate. Not sure yet if I really like that. It avoids the need for custom serialization, but it's also a bit implicit.", "Do we want to rename the field to `content-length`? The reason I ask is that `HEAD` requests are still logged with the size of the content, even though no body is returned. For example:\r\n\r\n```json\r\n{\"bytes\":55252,\"date\":\"2023-02-08\",\"ip\":\"127.0.0.1\",\"method\":\"HEAD\",\"status\":200,\"time\":\"15:33:05.395478208\",\"url\":\"https://fastly-static.staging.crates.io/crates/rand/rand-0.3.14.crate\",\"version\":\"1\"}\r\n```", "Seems OK for now, but human readable sounds iffy to me. For logs I would expect us to want something less human and more machine readable...\r\n\r\nIt's not clear to me what this actually ends up being but I think something with ~no ambiguity is better.", "Yes, I think we want to log the content length of the returned response rather than the HTTP header specifically.", "I would expect us to be able to get this from the bucket somehow, but seems fine to hardcode for now.", "I think S3 prefers that we use bucket-in-DNS for requests though, rather than this endpoint -- e.g., fastly-requests.s3.us-west-1.amazonaws.com.", "The default format is the internal integer representation of the time or date, which is impossible to interpret. I've updated the code to write dates using [RFC 3339](https://datatracker.ietf.org/doc/html/rfc3339), which should solve for both human- and machine-readability.\r\n\r\n```json\r\n{\r\n  \"date_time\":\"2023-02-28T11:17:19.002782375Z\"\r\n}\r\n```", "Sounds great, thanks.", "I've been looking into this, but the `Response` struct is kinda limited. The body is streamed through the edge worker, so inspecting the size is non-trivial.\r\n\r\nWe could add a special case for `HEAD` requests like below, but we can do that when parsing the logs as well.\r\n\r\n```rust\r\nif request.get_method() == Method::HEAD {\r\n    log_line.bytes(Some(0))\r\n}\r\n```"]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/207", "comments": ["Do we want to set this dynamically or through a variable??", "Same question as above."]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/200", "comments": ["Bionic seems off here - we're using focal below. Probably worth moving to 22.04 as well, but let's at least name the resource right (maybe just \"Ubuntu\")."]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/198", "comments": ["Why are we not using `staging` here to keep naming consistent with the account?", "I think that we should have a `/staging` namespace now that we're spinning up staging environments. Should we create a GitHub issues for this?", "Are we sharing the S3 bucket between staging and production? This feels like something that should come from either a variable or a resource.", "Same question here as above regarding the naming of the environment: `dev` vs. `staging.`", "Should we change this to `us-east-2` based on our [decision re. AWS regions](https://forge.rust-lang.org/infra/docs/aws-regions.html)?", "This might sound more passive-aggressive than it was intended. \ud83d\ude05 I suspect there might be a historic reason why `dev` is used here. But if there isn't, I would strongly advise us to keep the naming consistent between environment variables and AWS accounts.", "That's a good point. `staging` is a much longer word, but perhaps that's fine?", "This should certainly not be in a prod namespace. However, I think we're not going to have multiple environments in the same account so perhaps we should just drop this completely?", "I believe these will be in separate accounts, but we should not be hard coding the bucket name.", "Oh that's a good point! :+1:", "Bucket names are globally unique. So it doesn't matter in what account this is, it would still refer to the one `rust-docs-rs` bucket. Not the first time we're running into this. \ud83d\ude1e "]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/191", "comments": ["I'm not sure this is the right variable. It might be more straight-forward to make the variable more directly about what it's used for. ", "My reasoning was that should only be set to `true` in the legacy account. \ud83d\ude05", "I get it - makes the code harder to understand IMO, but it's also not a big deal.", "I'm happy to improve this still. Just wanted to get this merged first to unblock more pull requests. \ud83d\ude05 Although I have to admit that I'm not sure how this can be made significantly better. More documentation maybe?"]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/185", "comments": ["Needs to be globally unique. Perhaps post fix with the account id.", "Just create the bucket. \r\n\r\nQuestion: does this need to be configurable?", "Ask in Zulip whether we need different states for the web and the builder (considering they share resources like s3 and RDS).", "Make name globally unique", "Change this name to \"static-storage\"", "It was agreed in Zulip that this does not need to happen. We should keep them in the same state for simplicity sake."]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/182", "comments": ["admittedly this is kinda janky; I'm ok with installing it just for my user if you don't think other people on the machine will use it.", "This article mentions in the [Support for Arm processors](https://learn.microsoft.com/en-us/powershell/scripting/install/install-ubuntu?view=powershell-7.3#support-for-arm-processors) section that ARM is only supported using the [binary archive](https://learn.microsoft.com/en-us/powershell/scripting/install/install-other-linux?view=powershell-7.3#binary-archives) installation method. If that's true, we should probably do that since the `eu-1` and `us-1` desktops are running on ARM.\r\n\r\nIf you want, we can do this in a separate PR to get the rest merged sooner.", "Installing it for your user might be the easiest option for now. If we do want to install it for everyone, then I'd like to break up the `shell` block into individual steps and maybe add a check first to see if there even is a new version.", "\ud83d\udc4d makes sense, I don't think a lot of other people are using it, happy to remove it"]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/173", "comments": ["Hm, I feel like I'd rather see these run by Ansible (automatically on apply), rather than needing to login ourselves to update a particular machine.\r\n\r\nHappy to see this merged in the meantime though.", "How do we update the default quota for new users, created after this script runs? Is that done with the Ansible value for the filesystem quota? Can we document that at the top of this file?", "Oh I didn't even consider running this through Ansible. The benefit would be that we can then fully rely on a single variable to set the quota for both existing and new users. Let me give that a try...", "Thanks for catching this, @Mark-Simulacrum! Running this through Ansible is actually much simpler and offers much better maintainability. \ud83d\ude4f ", "I don't think I quite understand how we've resolved this yet FWIW ", "You got me thinking. Previously, we used the `team_login` binary to set the quota on new accounts. But that felt kinda dirty, so I went ahead and refactored that to instead use the `QUOTAUSER` setting in Linux. The quotas should not be fully managed by Ansible."]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/172", "comments": ["I think it makes sense to move this into its own state as a general pattern that we use for all accounts. Even if there's only one service in the account, having the VPC and the ECS cluster as a state seems like a reasonable and future-proof convention to me.", "To avoid too many files, I'd move the outputs (and the inputs) into `_terraform.tf`.", "For now, let's have only a public subnet and a private subnet with no untrusted subnets to save money on NAT gateways.", "The [Standard Module Structure](https://developer.hashicorp.com/terraform/language/modules/develop/structure) for Terraform modules explicitly names `main.tf`, `variables.tf`, and `outputs.tf`. For stuff in `modules/shared`, I think it's helpful to follow that convention.", "Done"]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/171", "comments": ["Can we show an example run of this command?", "I've added one at the end of the comment."]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/169", "comments": ["I think we might not want to say that the \"provision\" but rather than the provide the configuration for provisioning. Then we should mention that _state_ use these modules as to do the provisioning. ", "Perhaps we should clarify why an AWS account houses two instances of Azure based modules - i.e., that the shared terraform state lives in the AWS account.", "I thought the plan was to get rid of the shared directory. Master does not have a shared directory and I changed #172 to not use one.", "The reason there is no `modules/shared` directory on `master` is that I thought we were going to use dependencies in Terragrunt when I migrated `crates-io`. But my understanding from our conversation was that we want to use `modules/` for anything that can be a state in Terragrunt, and `modules/shared` for internal dependencies/resources in Terraform.", "Added a sentence below."]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/165", "comments": ["Can you make a comment on this since what this does isn't obvious on first glance?", "The first domain is the primary domain. We should document that. ", "Documenting `lifecycle` configuration is probably a good idea since the reason for it is generally not super obvious. ", "Is `cert_validation` the best name for this?", "Would be awesome to get descriptions for these variables. Even the ones that are somewhat obvious like \"index_domain_name\" would still benefit from documentation IMO.", "Would be good to have a very short comment on the architecture here that requires the fallback bucket.", "Nit: comment that this is 1 year", "Do we need the prefix as a variable? Can we just turn the domain name into the prefix like we do with the `aws_cloudfront_response_headers_policy`?", "Would be nice to comment on the invalidation architecture.", "This is now referencing a commit in the same branch. I think we should update this to the merge commit once the PR has been merged into `master`.", "There is no distinction between primary domains and subject alternate names in practice, it's just that the AWS API requires to specify a primary domain. I don't think it's worth documenting this implementation detail in the variable description (a comment on the resource could be helpful though).", "This gets a list of the top-level domains for the domains included in the certificate (like `crates.io` and `rust-lang.org` for `static.crates.io` and `static.rust-lang.org`). That's needed to get the correct DNS zones.", "One year :sweat_smile: Yeah we need the comment :P", "I understand what it does - I meant to make a comment in the file as to what it does \ud83d\ude0a", "Not sure if IAM supports dots.", "I think so. The DNS record is not the record of the service, but the record used for validating the ownership of the domain when issuing the certificate. For example:\r\n\r\n```\r\n_2b22bc60aa422e56d75b13e0214d82c5.staging.crates.io => _2d2b066a0344d52e0467384209b47a07.mzlfeqexyx.acm-validations.aws.\r\n```", "The lifecycle is used when changing the certificate (which requires deleting it and creating a new one). Since the certificate is in use (by Cloudfront or a load balancer, depending on where the module is used), we can't delete it before a new one is created, we have to create a new one, switch the resources to use the new one, and then delete the old one. That's what the lifecycle does.", "That's mostly used as a backup and as a fallback when the main AWS region is down, so that we can failover to it. See https://ops-guide.crates.io/on-call/common/dl-endpoint.html", "I don't mean using the domain itself but rather using the domain as the input that gets transformed into something using `_`."]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/164", "comments": ["Am I understanding the syntax correctly in that this is measuring that the 10-minute rolling average idle time over a 30-minute period is always under 15%? \r\n\r\nIf so, I think the description could use a bit of adjustment. The description makes it sound like CPU usage *never* dips below 85% in the 30-minute window, but I believe it can temporarily. ", "I updated the descrition"]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/158", "comments": ["While this query would've indeed catched the problem that happened recently, it might hide high CPU usage in some cases. The query is currently considering only the `user` mode, but a sizeable chunk of CPU usage could be due to `system` (in the kernel) or due to `iowait` (IO latency), and you'd warn to be alerted for both.\r\n\r\nI'd suggest to instead check if there is less than 10% of idle CPU.\r\n\r\n```suggestion\r\n              expr: avg(rate(node_cpu_seconds_total{job=\"node\",instance=\"docsrs.infra.rust-lang.org:9100\",mode=\"idle\"}[1m])) < 0.1\r\n```"]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/157", "comments": ["What does auth for this look like locally? I sort of think maybe it makes sense to split into separate directories - it can be annoying to need credentials for something you're not changing.\r\n\r\nI wonder if we could pivot off of AWS credentials to fetch temporary azure credentials automatically.", "That's a good point. Happy to split the module into `dev-desktops-aws` and `dev-desktops-azure`.\r\n\r\nWe haven't created a `team-members-azure` module yet to manage user accounts on Azure. With the limited knowledge that I have about Azure, it seems that we'd need to set up Azure AD and provision accounts there. That seemed a bit much just for spawning two virtual machines, so I've used the root account and the Azure CLI to authenticate.", "Nit: I think some of these modules could use some comments with a short explainer about what they're doing."]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/155", "comments": ["We are using an `origin_group` on CloudFront with two S3 buckets and a failover strategy based on HTTP `5xx` responses. Achieving the same setup is slightly involved on Fastly:\r\n\r\n- The `fastly_service_vcl` supports [failovers](https://developer.fastly.com/learning/concepts/failover/) through _automatic load-balancing_ or a _fallback director_. The latter is [not supported yet](https://github.com/fastly/terraform-provider-fastly/issues/436) in Terraform, and the first requires us to set up health checks against S3.\r\n- We can probably write some custom VCL to replicate the functionality.\r\n- The `fastly_service_compute` allows us to deploy a [Compute@Edge](https://github.com/fastly/compute-starter-kit-rust-static-content/blob/main/src/main.rs) function, which can mirror CloudFront's behavior. Requires building a local WASM module.\r\n\r\nThe benefit of `compute` over `vcl` seems to be that we have full control over the request cycle in a Rust runtime. The downside is that we are now relying on our own potentially buggy code instead of a provided Terraform module. If we do custom stuff, I'd still rather write some Rust than VCL.", "We are once again getting bitten by the fact that we cannot run this against `staging` only. Using the variable + `count` hack doesn't work, since we have nested dynamic resources:\r\n\r\n> The \"for_each\" map includes keys derived from resource attributes that cannot be determined until apply, and so Terraform cannot determine the full set of keys that will identify the instances of this resource.\r\n\r\nOpen to suggestions on how to resolve this. \ud83e\udd37\u200d\u2642\ufe0f ", "I feel like I commented somewhere but can't find it -- one alternative is to \"just\" have Fastly hit cloudfront as its origin, right? We can add a CNAME to cloudfront (e.g., cloudfront.static.crates.io) which Fastly hits for its origin.", "I think long-term the answer here is probably two different terraform state files (and variable-based config), one for staging and one for production, and we pick one based on a tfvars file or similar.\r\n\r\nWe hit this in ~every area we have a dev vs. prod distinction and we need to invest in fixing it more generally without hacks like for_each maps or similar.", "For the new AWS organization with SSO, @pietroalbini suggested using [terragrunt](https://terragrunt.gruntwork.io/).\r\n\r\nThe workaround for now can be to run\r\n\r\n```shell\r\nterraform plan -target=module.staging\r\n```\r\n\r\nAt least as long as the changes are in a separate branch.", "I don't feel good about that approach, to be honest, since we're not gaining much in terms of simplicity. But we are adding an additional hop between client and S3, and we'll lose the ability to fail-over between CDNs should any of them go down.\r\n\r\nLet's try to solve the problem first with an edge function. We have to implement one anyways for the release distribution, and it should be fairly simple code-wise. If we don't like that approach, we can always fallback to CloudFront as the origin.", "Our hit rate is >99.9% IIRC, we serve on the order of hundreds of requests per month from s3 - so I'm not too worried about the extra hop.\r\n\r\nWe do lose the ability to fallback if CloudFront goes down, I agree. Not sure we really need to be 100% up in that case though.", "Another problem would be dealing with invalidations. If both CDNs are independent we can issue invalidations to both, while if Fastly points to CloudFront we would first need to invalidate CloudFront, wait for the invalidation to be finished, and then invalidate Fastly. That sounds like a mess to implement.", "The setup for [logging](https://developer.fastly.com/learning/compute/rust/#logging) is not complete yet, and we are not [streaming logs](https://docs.fastly.com/en/guides/about-fastlys-realtime-log-streaming-features). So this warning will not show up anywhere.", "I'd split crates.io into terragrunt ASAP and target this PR on there.", "If possible I'd prefer not to have a Rust binary handling this. It makes deploying changes to the CDN configuration more complex, and has a higher chance of bugs.\r\n\r\n> and the first requires us to set up health checks against S3.\r\n\r\nWhile it wouldn't be exactly the same behavior as CloudFront, setting up a health check would be trivial: we can create an empty[^1] `health` file into the S3 bucket and have Fastly use that as the health check. It would still cover the reason why the fallback is there (S3 is down in that region), even though it's not exactly the same mechanism as CloudFront.\r\n\r\n[^1]: Well, in the content of the health file I'd put something like \"needed by the Fastly CDN for the health check\" so that future us will know why that file exists.", "Yes, that's absolutely the goal!", "Even with a health check, we will not be able to set up a primary/fallback configuration with Fastly. Fastly can only load balance between two buckets, and retry the other if the first request fails. Which is not a big issue in my opinion, but something to note. (See the remark about the _fallback director_ [not being supported](https://github.com/fastly/terraform-provider-fastly/issues/436) in Terraform.)\r\n\r\nPersonally, I don't have an issue using a compute function here. I think that we will need a binary for the Rust releases, since that does a lot of rewriting that cannot be expressed easily in VCL (as far as I can tell). So sooner or later, we have to learn how to manage it anyways.\r\n\r\nBut I'm fine leaving that discussion for later, and configuring `static.crates.io` with VCL for now.", "I'm surprised by this - isn't terraform supposed to be able to handle dependencies like this?", "Yes and no.\r\n\r\nThe problem here is that the newly created resources are used as keys in a `for_each` statement:\r\n\r\n```text\r\nError: Invalid for_each argument\r\n\r\n  on fastly-index.tf line 74, in resource \"aws_route53_record\" \"index_tls_validation\":\r\n  74:   for_each = {\r\n  75:     for challenge in fastly_tls_subscription.index.managed_dns_challenges :\r\n  76:     trimprefix(challenge.record_name, \"_acme-challenge.\") => challenge\r\n  77:   }\r\n    \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\r\n    \u2502 fastly_tls_subscription.index.managed_dns_challenges is a set of object, known only after apply\r\n\r\nThe \"for_each\" map includes keys derived from resource attributes that\r\ncannot be determined until apply, and so Terraform cannot determine the\r\nfull set of keys that will identify the instances of this resource.\r\n\r\nWhen working with unknown values in for_each, it's better to define the map\r\nkeys statically in your configuration and place apply-time results only in\r\nthe map values.\r\n\r\nAlternatively, you could use the -target planning option to first apply\r\nonly the resources that the for_each value depends on, and then apply a\r\nsecond time to fully converge.\r\n```\r\n\r\nThe same problem exists when rewriting this block to use `count`:\r\n\r\n```text\r\nError: Invalid count argument\r\n\r\n  on fastly-index.tf line 72, in resource \"aws_route53_record\" \"index_tls_validation\":\r\n  72:   count = length(fastly_tls_subscription.index.managed_dns_challenges)\r\n\r\nThe \"count\" value depends on resource attributes that cannot be determined\r\nuntil apply, so Terraform cannot predict how many instances will be\r\ncreated. To work around this, use the -target argument to first apply only\r\nthe resources that the count depends on.\r\n```\r\n\r\nThe only potential workaround I've found is splitting the configuration into two modules, but those would still need to be applied after each other. We can do that with dependencies in Terragrunt, but that would mean we need a state for the `fastly_tls_subscription` and a state for the validation.\r\n\r\n```text\r\ncrates-io-staging\r\n\u251c\u2500\u2500 crates-io\r\n\u251c\u2500\u2500 fastly-tls-subscription\r\n\u2514\u2500\u2500 fastly-tls-validation\r\n```\r\n\r\nOne could then apply all changes by running `terragrunt run-all apply` from the `crates-io-staging` directory, which will resolve the dependencies and apply the changes in the right order.\r\n\r\nThinking more about this, I kinda like this approach. It makes the dependency explicit in the tooling, and not in the documentation. What do you think?", "I've put together a quick proof-of-concept here: https://github.com/jdno/rust-simpleinfra/commit/28bb026d0844ae45920c2738d7b0ac3db6738821 Haven't tried actually running it, though.", "Without too much experience here, I can't have a strong opinion, but the suggestion feels better than commenting out code.", "Is this lockfile actually used? The dependencies should be included in the one at the root of the repo due to the workspace.", "I'm worried that you have to remember to run `fastly compute build` to get the right configuration, and if you don't changes will be silently not applied. Can we use the [`external` data source](https://registry.terraform.io/providers/hashicorp/external/latest/docs/data-sources/data_source) to invoke the compilation as part of planning?", "I'm a bit confused by this, how's [AWS validation working then?](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/acm_certificate_validation) It also generates the DNS records dynamically.", "It wasn't until I added the external data source. But since Terragrunt copies the Rust crate into a temporary build environment, we cannot provide a stable path to include the crate in the workspace.", "Done. I had to add a shell scripts that runs `fastly compute build` and returns a valid JSON object, though.", "Here is the relevant part of a new `aws_acm_certificate` in a Terraform plan:\r\n\r\n```\r\nresource \"aws_acm_certificate\" \"cert\" {\r\n  domain_validation_options = [\r\n    {\r\n      domain_name           = \"test.jdno.dev\"\r\n      resource_record_name  = (known after apply)\r\n      resource_record_type  = (known after apply)\r\n      resource_record_value = (known after apply)\r\n    },\r\n  ]\r\n```\r\n\r\nAnd here is the `fastly_tls_subscription`:\r\n\r\n```\r\nresource \"fastly_tls_subscription\" \"subscription\" {\r\n   managed_dns_challenges  = (known after apply)\r\n```\r\n\r\nThe reason why AWS works is that the number of `domain_validation_options` with their respective `domain_name`, i.e. the key for the `for_each` statement, is known when planning.\r\n\r\nWe can create a feature request to get this added to [terraform-provider-fastly](https://github.com/fastly/terraform-provider-fastly), but in the meantime we are stuck with either running the _initial_ apply twice or using dependencies.\r\n\r\nOpinions, @pietroalbini and @rylev?", "I've created a feature request for the Fastly provider: https://github.com/fastly/terraform-provider-fastly/issues/627", "Ooh ok, your explaination on the issue (unfortunately) makes a lot of sense. Ugh. I'd go with the two applies for now. Also, can you flag the issue with our Fastly contact to see if it can be prioritized on their end?", "I forwarded both issues to our contact and will post an update in the team meeting when I know more about the priorities."]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/154", "comments": ["```suggestion\r\n  source = \"../../../modules/aws-organization\"\r\n```", "The double slash is actually intentional. From the terragrunt docs:\r\n\r\n> Terragrunt will download all the code in the repo (i.e. the part before the double-slash `//`) so that relative paths work correctly between modules in that repo.\r\n", "Oh. We should have a comment, then.", "This is actually a feature of Terraform:\r\n\r\n> A special double-slash syntax is interpreted by Terraform to indicate that the remaining path after that point is a sub-directory within the package.\r\n\r\nhttps://developer.hashicorp.com/terraform/language/modules/sources#modules-in-package-sub-directories", "@Mark-Simulacrum the `//` will be in every Terragrunt configuration file, would you expect a comment in each file?", "I guess I know about it now so maybe not so important. I think having a link in each file isn't terrible though."]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/150", "comments": ["```suggestion\r\n              expr: sum(increase(playground_request_duration_seconds_count[5m])) == 0\r\n```", "I'll have to figure out the meaningful difference here I suppose."]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/148", "comments": ["Can we use the environment variable instead, and remove the tfvars from gitignore? https://registry.terraform.io/providers/fastly/fastly/latest/docs#environment-variables"]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/147", "comments": ["The `a1.metal` instances are not available in the `us-west-1` region."]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/140", "comments": ["Let's add a quick check to see if Node is already installed and use the `apt` module to install the package:\r\n\r\n```suggestion\r\n- name: Check if Node is installed\r\n  command: node --version\r\n  register: node_version\r\n  changed_when: false\r\n  failed_when: node_version.rc != 0 and node_version.rc != 2\r\n\r\n- name: Set up NodeSource repository\r\n  shell: |\r\n    curl -fsSL https://deb.nodesource.com/setup_18.x | bash -\r\n  when: node_version.rc == 2\r\n\r\n- name: Install Node\r\n  apt:\r\n    name: nodejs\r\n    state: present\r\n    update_cache: yes\r\n```"]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/136", "comments": ["Would it make sense to link to the [issue](https://github.com/rust-lang/crates.io/issues/5332) in a comment so that it's very obvious *why* we're doing this?", "Great idea! I've added a comment linking to the issue. :+1:"]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/133", "comments": ["Can we have an `instance_arch` of \"amd64\" / \"arm64\" in the `instances` key (like `instance_type`)?"]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/132", "comments": ["looks like this only installs rustup now? why not keep it named `setup_rustup.sh`?", "can we put this in some `shared.sh` file to avoid repeating it?", "this seems very heavy. is it ok to take 30+ minutes here? we can trick rustup into creating a toolchain without actually building the compiler with `touch` on a few relevant files.\r\n\r\nif you really do want to build the repo and not just link the toolchain, let's be more specific about waht we want:\r\n`x.py build --stage 1 library/std src/tools/rustdoc`", "this is dead code, `x.py build` doesn't build stage 2 by default", "this seems somewhat confusing, usually I want different config files in different worktrees. but if no one has complained so far it's probably fine", "I am looking at https://github.com/rust-lang/simpleinfra/pull/110 as something that we can put into this script as well.", "Personally, I prefer repetition here since it makes the flags very explicitly. We can replace it with something like `source ./enable-strict-mode.sh`. But I'm afraid that no-one will know what that actually does, leading to confusion and frustration when debugging or extending a script.", "I don't know enough about developing Rust to have an opinion on this. The previous version of the script failed since it couldn't find `stage1` or `stage2`, so I put the build command in there. With the `if` statement that follows the build command, we shouldn't get errors anymore even if Rust hasn't been built yet. So I'm fine removing the build command here.", "The script gets called from at least one of the worktree scripts as well, so I'm assuming it's in there for cases where people have built `stage2` manually.", "@jyn514 Since we removed `./x.py build` from `link_rust.sh`, should we put it in here? Without it, calling `link_rust.sh` is kinda useless.", "If we remove the build command, then this script won't do anything at all. My preference is the first thing I said, avoid x.py altogether and `touch` the relevant files so we can link a rustup toolchain without waiting for rustc to compiler.", "My assumption is that these scripts are not designed with onboarding in mind, but instead to help folks when they're already working on the dev desktop. While the script doesn't to anything on a fresh installation, it is probably useful when you've manually compiled stages 1 or 2 in your own fork?", "The PR description says\r\n> For users who want to set up their own Rust toolchain, the setup_rust script clones their fork of the rust-lang/rust repository, compiles it, and links the build artifacts. This is optional, however, and not required if users want to use the dev desktop to work with different repositories.\r\n\r\nI think for that use case, where we're cloning the repo for the first time, we absolutely should link the toolchain to avoid manual work.\r\n\r\nI feel like there's some communication gap here; this feels very in-line with your original goal for the PR, just with a slightly different approach. Is there a reason you've changed your mind? I think the `touch` code will take about half an hour to write and test, and less than a second to execute in the script.", "```suggestion\r\n    if [ \"$bootstrap_version\" -gt 2 ]; then\r\n```"]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/126", "comments": ["Can we also calculate the kernel flavor from `uname -r`? it should be the last item when splitting by `-`."]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/124", "comments": ["Can we change both variables to `vars_linux_kernel_flavor` that can be \"aws\" or \"virtual\"? `linux-tools-virtual` exists as well, so it should be just possible to suffix the package names with the kernel flavor."]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/120", "comments": ["Can we make this configurable from the playbook?", "We sure can! I went through two iterations, first setting the quota as an environment variable and then passing it as an argument to the CLI. I like the second option much more, since it makes the dependency explicit. The downside is that I needed/wanted to pull in `clap` to parse the arguments."]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/119", "comments": ["I am not sure if rebooting as part of the role can cause issues with existing workflows. A reboot is definitely required after changing `kernel.yama.ptrace_scope`, but maybe there is a better way to ensure that it happens.\r\n\r\n(This will also come up with the quotas, since they require a restart as well to enable the feature.)", "Can we do the reboot with a handler? That way if multiple steps require a reboot we only do it once.", "There is also a [reboot module](https://docs.ansible.com/ansible/2.7/modules/reboot_module.html).", "Oh my. The module is so nice. Role has been updated to use a handler and the module. :+1:"]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/117", "comments": ["Code looks good! In general, the assume role policy can be a bit finicky to write, and I'm wondering if it's worth creating a module like:\r\n\r\n```terraform\r\nmodule \"ci_sync_team_role\" {\r\n  source = \"../shared/modules/gha-oidc-role\"\r\n  name = \"ci--rust-lang-sync-team\"\r\n  repo = \"rust-lang/sync-team\"\r\n  branch = \"master\"\r\n  policy = jsonencode({ ... })\r\n}\r\n```", "Yeah, I thought about it. I'm not sold on a module making this much better (my main annoyance with modules is having to reapply all over the place after editing them) and it seems like we're currently copy pasting anyway.", "Hmm yeah that part is annoying, even though for this I don't really expect the module to change. The only change I can see is adding other options other than `branch`, and those shouldn't affect existing impls of the module. I think with how low risk of this module changing is, I'd prefer to switch to one so that we don't risk messing up the assume policy.", "Yeah, seems ok. I'll make that update when I get a chance and migrate existing module and the PRs here over."]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/110", "comments": ["This should use the endpoint for the permission, the `cloud-compute` team is temporary:\r\n\r\nhttps://team-api.infra.rust-lang.org/v1/permissions/dev_desktop.json", "Hmm, rather than querying the file we should have a new team-api.infra.rust-lang.org endpoint to get the information we need.", "I might be missing something, but why are we checking `dev_desktop.json` first? We already know that the `username` is the GitHub name, based on the conventions that are used to create the user accounts. And the user cannot run the script without being in that file. Instead of fetching `dev_desktop.json` and checking there first, can't we simply look for the user in `people.json`?\r\n\r\n```python\r\nif username not in people_map:\r\n    print(\"could not find a matching user in the people map!\")\r\n    continue\r\n```\r\n\r\n"]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/94", "comments": ["From https://linux.die.net/man/3/getlogin_r (emphasis mine)\r\n\r\n> Unfortunately, it is often rather easy to fool getlogin(). Sometimes it does not work at all, because some program messed up the utmp file. Often, it gives only the first 8 characters of the login name. The user currently logged in on the controlling terminal of our program need not be the user who started it. **Avoid getlogin() for security-related purposes.**", "This is what `getuid` is for, right? To know the original user before the program changed it's EUID?", "Rebased on top of master, and added the last commit to address this. I am *pretty sure* that's safe, but I'd like another set of eyes on it."]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/93", "comments": ["```suggestion\r\nvars_playground_s3_bucket: bucket-name\r\n```"]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/84", "comments": ["I don't actually recognize this existing key. The first line is my old laptop \u2014 is this some internal infra key?", "No, shouldn't be. I would suggest removing it if we don't know what it is.", "Removed!"]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/83", "comments": ["Hmm, this makes me worried it will trigger when no one publishes a crate to crates.io for an hour. I don't know how likely that is, but it doesn't seem impossible given that this is running 24/7. Could we also check that there's at least one crate enqueued during this time?", "hm... `docsrs_queued_crates_count` is a `IntGauge`, not an `IntCounter`. \r\n\r\nI'll check how I can combine these two", "we also could just add a new metric (something like `docsrs_enqueued_builds` as `IntCounter`)", "@jyn514 I think I found a way, if I'm not mistaken. "]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/82", "comments": ["Maybe set this to 12 hours instead to match the ratio from before? but I don't feel strongly", "sure, changed. "]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/79", "comments": ["I'm a bit worried that the first run of this will end up being too long and then subsequent runs (based on the cron timer) start trying to run scripts in the same directory in parallel and that seems bad...", "Or did I misunderstand and the init script is run by the user (and not us)?", "This is not run by a cron job or anything. This is just a set of scripts provided to all users to quickly be able to set up a dev environment. Automating this can be addressed in the future, but I think for now it's ok for them to do this manually.\r\n\r\nWe may want to enable the motd again and put some instructions in there, or just slap a README into the home directories.", "This looks like it's taking care of user creation, but I'm not seeing the user deletion code. I imagine we'd need to enumerate the set of users on this machine? It's probably *ok* if we just delete their ssh keys for now, we can worry about actually deleting their home directory separately -- but it may not be any easier to decouple those two actions.", "Yea, I'll add the code to delete the ssh keys before adding them. I'll need to take care to never touch the infra accounts, otherwise you may get locked out of your accounts if by accident https://team-api.infra.rust-lang.org/v1/teams/all.json ever returns an empty list.", "I think we'll want to be careful: if this is run every 5 minutes, then we don't want constant disconnects or connection failures as the keys get deleted and re-added. So we probably need to make sure we don't touch keys that are expected to get re-added in the next run (note: important that this is about *keys* not users, as users can edit their configured keys in github, to remove a leaked key, for example).\r\n\r\nIt's not a big worry if we delete infra accounts -- we can always reprovision the instance if needed. I'd prefer to avoid any hardcoding here for particular users.", "> (note: important that this is about _keys_ not users, as users can edit their configured keys in github, to remove a leaked key, for example).\r\n\r\nwell... that itself is not an issue. We overwrite update users' entire key file in one operation. The main issue I see is users that are removed from the teams that should now lose their ssh access.\r\n\r\nI'll collect the list of users and compare it with the key files in the key directory and remove any that weren't on the list. That should not cause intermittent missing keys.", "> well... that itself is not an issue. We overwrite update users' entire key file in one operation. The main issue I see is users that are removed from the teams that should now lose their ssh access.\r\n\r\nWe do? I don't think `std::fs::write(format!(\"/etc/ssh/authorized_keys/{}\", person.github), keys)?;` is guaranteed to be  single write call or otherwise atomic, so this doesn't seem true.", "true, but it should be very hard to hit the milliseconds during which your keyfile is invalid. I don't see how we can avoid that as sshd_config expects the file in a very specific location and I don't think we can specify a pattern.", "OK. We can see if there's pain in the future -- my worry would also be that if this is interrupted, a partial file maybe a security problem.\r\n\r\nMaybe the way to go is the rename dance, but that seems likely insufficient without more investment so probably not worth it.", "> I'll collect the list of users and compare it with the key files in the key directory and remove any that weren't on the list. That should not cause intermittent missing keys.\r\n\r\nI implemented this", "Can we pre-install rustup for each user by just copying these files or so into /etc/skel, perhaps?\r\n\r\nI think it's something we have to do right away, otherwise the files don't get copied after the user is first created.", "```\r\n[WARNING]: Consider using the get_url or uri module rather than running 'curl'.  If you need to use command because get_url or uri is insufficient you can add 'warn: false' to this command task or set\r\n'command_warnings=False' in ansible.cfg to get rid of this message.\r\n\r\nfatal: [dev-desktop.infra.rust-lang.org]: FAILED! => {\"changed\": true, \"cmd\": \"curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\", \"delta\": \"0:00:00.359799\", \"end\": \"2021-12-15 18:30:07.489197\", \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2021-12-15 18:30:07.129398\", \"stderr\": \"info: downloading installer\\nrustup: Unable to run interactively. Run with -y to accept defaults, --help for additional options\", \"stderr_lines\": [\"info: downloading installer\", \"rustup: Unable to run interactively. Run with -y to accept defaults, --help for additional options\"], \"stdout\": \"\", \"stdout_lines\": []}\r\n```\r\n\r\nSo probably a little more needs to be done to make this work. ", "I patched the command, it works locally, but not sure about ansible.", "Sorry, going on vacation now, I won't be able to do that. We can always run scripts for all users later if we want to do sth like that.", "Let's avoid curling-to-bash. A simple hash verification would makes sense here:\r\n\r\n```\r\nset -eu\r\n\r\nRUSTUP_VERSION=1.24.3\r\nRUSTUP_SHA=\"a3cb081f88a6789d104518b30d4aa410009cd08c3822a1226991d6cf0442a0f8\"\r\n\r\ncurl --proto '=https' --tlsv1.2 -sSf -O \\\r\n  https://raw.githubusercontent.com/rust-lang/rustup/${RUSTUP_VERSION}/rustup-init.sh\r\n\r\necho \"${OUR_RUSTUP_SHA}  rustup-init.sh\" | sha256sum --check --\r\n\r\nsh rustup-init.sh \\\r\n   --default-toolchain nightly -y \\\r\n   --component rust-src\r\n```", "I'm happy to submit a follow-up PR for this.", "```suggestion\r\n  shell: |\r\n    set -eu\r\n    RUSTUP_VERSION=1.24.3\r\n    RUSTUP_SHA=\"a3cb081f88a6789d104518b30d4aa410009cd08c3822a1226991d6cf0442a0f8\"\r\n    curl --proto '=https' --tlsv1.2 -sSf -O \\\r\n      https://raw.githubusercontent.com/rust-lang/rustup/${RUSTUP_VERSION}/rustup-init.sh\r\n    echo \"${RUSTUP_SHA}  rustup-init.sh\" | sha256sum --check --\r\n    sh rustup-init.sh --default-toolchain nightly -y --component rust-src\r\n```", "Makes sense, thanks!", "I don't think we should just disable this step, as that would prevent removing sudo users (that are only managed in ansible) and practically result in us forgetting to remove those perms.\r\n\r\nA better approach here would be to add (only on the dev-desktop machines) [an extra group of users allowed to ssh](https://github.com/rust-lang/simpleinfra/blob/master/ansible/roles/common/templates/ssh/sshd_config#L37) called something like `dev-desktop-allow-ssh`. That way it won't interfere with the ansible group management.", "Can we have a prefix like `gh-{username}` to prevent users from colliding with system users?", "I'm not too keen on the `skel` approach for providing pre-made scripts, as making any update/fix to them is going to be a pain for existing users on a machine. I'd directly add them to `/usr/local/bin`, that way they're centrally managed and we can add/update them without any issue.", "Nit: 20.04 is focal, not bionic :slightly_smiling_face: Removing the codename altogether would probably be better.", "This is going to result in a lot of requests every 5 minutes, do we know what the rate limit on the endpoint is?", "I'd add a new `dev-desktop = true` permission rather than just allowing the `all` team. Mostly because that'd allow to manually set `dev-desktop = false` on any user or team if problems arise.", "An example of colliding user here would be `aidanhs`, but I could also imagine some avenues for privilege escalation.", "Playground, bastion and shared use the same thing. I don't think I am able to do any changes here beyond execute an exact replacement that you tell me about.", "nope, but it's been doing that for weeks now", "once https://github.com/rust-lang/team/pull/720 lands this PR will work again, as right now it just fails since the field does not exist", "Ok, sounds reasonable. Can you add a user agent like `rust-lang/simpleinfra (infra@rust-lang.org)` so that GitHub can reasonably contact us if this starts to become problematic for them?", "No, this was mostly for Mark (who authored the code). I can probably also make those changes eventually. It's not a bit deal at all.", "Not a blocker for the initial prototyping, but you mentioning the sync is currently failing due to the team repo changes not being applied reminded me that we don't have proper monitoring in place for cronjobs failing, but we do have monitoring in place for systemd units failing.\r\n\r\nCould the cronjob be switched to a systemd timer/service combo? You can see an example in this repo, with the corresponding [.service](https://github.com/rust-lang/simpleinfra/blob/master/ansible/roles/docker/templates/update-images/docker-images-update.service) and [.timer](https://github.com/rust-lang/simpleinfra/blob/master/ansible/roles/docker/templates/update-images/docker-images-update.timer).", "Note that you also moved the `config.toml` to `/usr/local/bin`, even though it's not a script :sweat_smile:\r\n\r\nI'm not sure exactly what to do for that, either omit it or still add it as part of the skeleton.", "```suggestion\r\nBy accessing and making use of this Cloud Compute Program resource, you are agreeing that you have both read and will abide by its official Access Agreement. The Access Agreement can be found at https://foundation.rust-lang.org/policies/cloud-compute-program/.\r\n```", "facepalm emoji", "```suggestion\r\ndebug = true\r\n```\r\n\r\nso we don't get.....\r\n\r\n```\r\nfailed to parse TOML configuration 'config.toml': invalid type: string \"true\", expected a boolean for key `rust.debug`\r\n```\r\n\r\n", "in the current instance build, `rustup` doesn't look to be working, even though it appears to be installed here.", "This is not currently showing on the current instance build based on this config.", "Can we make the default shell `bash` instead of `sh`?", "rustup needs to be installed per user. There is an open issue to support multi-user environments: https://github.com/rust-lang/rustup/issues/313", "My default shell after login is bash:\r\n\r\n```\r\noli-obk@dev-desktop:~/rust$ echo \"$SHELL\"\r\n/bin/bash\r\n```\r\n", "Ah interesting, only the admin users have this, everyone else has `sh` \ud83d\ude15 looking into it", "Without any post-configuration on your part? We were seeing `sh` the first time we logged in.", "Ha - ok.", "One problem: all existing users now are stuck with `sh` \ud83d\ude06 I'll patch them manually, but in the future all deploys will use bash", "Done, you may need to delete the `.vscode-server` folder on the server as it remembers the shell at setup time out of some reason\r\n", "We'll definitely recreate the base machine (not just Ansible deploy) before the next stage, so that's a temporary condition.", "@oli-obk this is still pending btw :slightly_smiling_face: ", "Thanks for this @oli-obk ! \r\n\r\nJust wanted to clarify something -- will the user (i.e. those that are logging into the cloud compute machine to do Rust development) be setting up the App? Or will an admin of the cloud compute machine set up the App and then admin installs and grants access to the users?\r\n\r\nIn other words, does a user or admin follow these steps? I feel like it is an admin, but wasn't 100% sure. ", "Yea, this is an admin. I mean, we could make it an app per user, but that's annoying to set up and not really more secure unless you wipe your key after your session and copy it again when you reconnect.\r\n\r\nThe only step the user has to follow with this is to install the app, for which we'll provide them with a URL, not sure when yet, possibly at login when they haven't set up the app yet", "help! We've reached the point where someone needs to create the app and secrets, store the secrets somewhere secret and set it up so ansible can find them and upload them. I can't do any of these steps and it's probably faster for one of you to set it up than to explain it to me (and me learning it has no benefit, because it's unlikely I'll be handling infra-secrets in the future).", "oh this is the wrong user. we need to get the user from the logged in username, otherwise users can steal other user's repos. will fix this tomorrow", "Can we only add this on the dev-desktop machines rather than all machines? Maybe adding an `extra-ssh-allow-groups` variable.", "The workflows permission also needs to be granted, otherwise it's not possible to push GitHub Actions workflow files.", "We usually have all our docs in the [Documentation section of the forge](https://forge.rust-lang.org/infra/docs/index.html), could this be moved to a PR there? I'd create separate pages for team members and for the infra team (like for AWS access).", "This documentation is purely for the infra team, there's nothing there a user of the dev desktops needs to read", "I don't know how to do that.\r\n\r\nAppending sshd_config with files in sshd_config.d has been very weird with overwriting previous flags. I'll try it out, but if that doesn't work, we should imo just allow this group or rename it to something generic like `allow-ssh-noninfra`", "Definitely! We're trying to keep the documentation on the infrastructure on the forge though, so that it's all in a central place rather than being scattered around :slightly_smiling_face: ", "I would add this to the [default variables for the Ansible role](https://github.com/rust-lang/simpleinfra/blob/master/ansible/roles/common/defaults/main.yml):\r\n\r\n```yaml\r\nallow_ssh_extra_groups: \"\"\r\n```\r\n\r\nThen the current line in the `sshd_config` can be replaced with:\r\n\r\n```\r\nAllowGroups allow-ssh {{ allow_ssh_extra_groups }}\r\n```\r\n\r\nAnd finally in the playbook, in the common role we add:\r\n\r\n```yaml\r\n- role: common\r\n  # ...\r\n  allow_ssh_extra_groups: dev-desktop-allow-ssh\r\n```\r\n\r\nI agree it's not worth it messing with `sshd_config.d`.", "Oh sorry, I'm all for that. I was just confused by what you wanted me to split when you wrote\r\n\r\n> I'd create separate pages for team members and for the infra team\r\n\r\n", "Oooh, these templates are great. Thanks for the explanation"]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/78", "comments": ["These values need to be properly encrypted before merging.", "In general for production we store tokens in AWS SSM Parameter Store, see the other group vars for how they're loaded.", "In production we shouldn't use IAM Users with hardcoded access keys, we should use a IAM Role attached to the EC2 instance. Roles don't need to be configured with Ansible (or in the server itself) at all, we just need to configure AWS with Terraform for it.", "Is there a reason why you're not using the Docker engine from the Ubuntu repositories?", "We should only provide AWS access keys for the local environment, if the access key is not provided (like in production) we should just omit these two lines with an `if` block.", "Why are we binding to `0.0.0.0`? We're proxying this through nginx, so binding to localhost should suffice.", "What's the purpose of the mountpoint? Could you add that as a comment somewhere?", "It tends to lag behind the current stable version from the Docker repositories. Since so much heavy lifting is done by Docker as part of the playground, having the most up-to-date release has made the most sense over the years. This also allows me to use newer features (not sure if there are any _right now_ that are in one and not the other).", "I believe it's a holdover from before we only supported HTTPS.", "Ok.\r\n\r\nI don't know how to do that.", "I'm guessing that I don't have permissions to muck about with AWS SSM Parameter Store, so it seems like someone with appropriate access will need to put the values in. Should I copy-paste some existing code (e.g. `vars_aws_credentials` from crater.yml) and just make up key names?", "Yes, that'd be great! We can then fill the params in before running the first prod deploy. If you want to deploy on your own we'll also need to grant you access to (a subset of) Parameter Store, I'll take care of that in the next couple of days."]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/47", "comments": ["The trailing comma is not valid JSON.", "\r\n\r\nThe trailing comma is not valid JSON.\r\n"]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/38", "comments": ["Let's use `-` instead of `_`, to be consistent with the rest of the params in parameter store.", "This is not Secrets Manager, it's SSM parameter store.", "Let's call it `crates-io-ops-bot` to be consistent with the rest of the task definitions (it should have the same name as the ECR repository).", "Let's call this `crates-io-ops-bot` to be consistent with the rest of the tasks."]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/34", "comments": ["I'd prefer not to have a default repository name.", "```suggestion\r\n        if selected_image_index is not None:\r\n```", "A solution here could be to list the services inside the cluster with:\r\n\r\n```\r\naws ecs list-services --cluster {ECS_CLUSTER}\r\n```\r\n\r\nIf a service with the same name as the repository exists we redeploy that service, otherwise we rollback but *not* redeploy.", "Great, just to clarify the `repository name` should be a required argument.", "Sounds good, and it ok to have the `ECS_CLUSTER` as a constant or you want to receive as argument?\r\nThx!", "Yep, we only have one cluster at the moment.", "Yes.", "In our repository, only the `latest` image is tagged, while all the past ones are untagged. It would be nice if the prompt looked something like this (the list is sorted from the most recently pushed image to the oldest):\r\n\r\n```\r\nPlease choose an image to rollback:\r\n2) 2020-04-13 12:02:39 (latest)\r\n3) 2020-04-11 00:25:25\r\n4) 2020-04-06 12:02:30 (other-tag)\r\n5) 2020-04-01 13:15:24\r\n```\r\n\r\nYou can use the `aws ecr describe-images` command instead of `aws ecr list-images` to fetch the additional information. Also, since not all the images are tagged you'll need to use digests to identify images.", "```suggestion\r\n    print(\"Please choose an image to rollback:\")\r\n```\r\n\r\nSmall typo :)", "It'd be nice here to show success message even for other cases:\r\n\r\n* Successfully rolled back the image, but no service with the same name to redeploy found\r\n* Successfully rolled back the image, but redeploying the service with the same name failed", "thanks! :)", "Hi @pietroalbini, thanks for the feedback. I just pushed all the changes.\r\nThx!", "```suggestion\r\n    return list(sorted(out[\"imageDetails\"], key=lambda image: image[\"imagePushedAt\"], reverse=True))\r\n```"]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/26", "comments": ["What is stopping you from migrating to a higher node version? This version will show a deprecation warning, and [GitHub will soon drop support](https://github.blog/changelog/2022-09-22-github-actions-all-actions-will-begin-running-on-node16-instead-of-node12/).", "It's probably better to pin this to a specific version so that future modifications won't break your existing users:\r\n\r\n```suggestion\r\n- uses: rust-lang/simpleinfra/github-actions/run-github-release@v1\r\n```\r\n\r\nOf course, there will be a need to create a new release in this repository, but it's better to be safe than sorry!"]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/14", "comments": ["You need to put it outside the range, otherwise it will get repeated if there are multiple alerts in the same message."]}, {"url": "https://github.com/rust-lang/simpleinfra/pull/6", "comments": ["I'm personally not very familiar with ansible, so this file seems entirely magical to me both in existence, what the keys are, and what they're configured to. Could files perhaps have a link to a URL describing them and/or relevant documentation?", "I personally find bash scripts to be pretty awful for long-term usage, especially when they're managed by multiple folks (everyone seems to always have their own style). This is pretty small though, so would something like Python perhaps work for the script?", "Speaking as an outsider at least, this comment doesn't really make much sense to me. It looks like we're configuring to use an interpreter that isn't installed in various places? Not that I really know what's going on with this file anyway...", "Uh, woops, the comment is wrong, it should be \"Ubuntu doesn't ship with python2 preinstalled anymore\". Ansible by default uses Python 2, but it can be configured to run with Python 3."]}]}, {"url": "https://github.com/skyscrapers/terraform-vpc.git", "pull_requests": []}, {"url": "https://github.com/billy-reilly/terraform-frontend.git", "pull_requests": []}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam.git", "pull_requests": [{"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/469", "comments": ["We can just add this permission into https://github.com/terraform-aws-modules/terraform-aws-iam/blob/f65532fc786b79b1ef24b0993e8f2ff6b25b22cf/modules/iam-role-for-service-accounts-eks/policies.tf#L157-L168\r\n\r\nwe can skip the variables and dynamic statement, etc.", "Done"]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/459", "comments": ["I think here typo EFS > S3", "Thanks for catching that. Just fixed it!", "lets change all of the `s3_csi` references to `mountpoint_s3_csi`", "Per https://github.com/awslabs/mountpoint-s3-csi-driver/blob/3fd288dc112b9777e244b633ea12cd3f14ca581b/docs/install.md?plain=1#L74\r\n\r\n```suggestion\r\n      namespace_service_accounts = [\"kube-system:s3-csi-driver-sa\"]\r\n```", "to be more cross partition friendly\r\n\r\n```suggestion\r\n    resources = coalescelist(var.s3_csi_bucket_arns, [\"arn:${local.partition}:s3:::*\"])\r\n```", "this could surprise users, lets leave it to them to provide the proper arn with path prefix - we can use a separate variable for this to distinguish between the buckets for the `list` permissions and the paths for the `get`/`put`/`delete` permissions\r\n\r\n```suggestion\r\n    resources = var.mountpoint_s3_csi_path_arns\r\n```", "with the change above, this becomes\r\n```suggestion\r\n  default     = []\r\n```\r\n\r\ndon't forget to add the new `mountpoint_s3_csi_path_arns` variable as well and ensure the descriptions detail the differences", "changed :)", "udpated :)", "updated but I matched the pattern for coalescelist(var.s3_csi_path_arns, [\"arn:${local.partition}:s3:::*/*\"]) from the bucket arns. Let me know if that's an issue", "This would give quite permissive access by default, so instead we will rely on users to provide the paths\r\n```suggestion\r\n    resources = var.mountpoint_s3_csi_path_arns\r\n```", "```suggestion\r\n# Mountpoint S3 CSI Driver Policy\r\n```", "```suggestion\r\n  name_prefix = \"${var.policy_name_prefix}Mountpoint_S3_CSI-\"\r\n```", "```suggestion\r\n  description = \"Mountpoint S3 CSI driver policy to allow management of S3\"\r\n```", "```suggestion\r\n  description = \"Determines whether to attach the Mountpoint S3 CSI IAM policy to the role\"\r\n```", "```suggestion\r\n  description = \"S3 bucket ARNs to allow Mountpoint S3 CSI to list buckets\"\r\n```", "```suggestion\r\n  description = \"S3 path ARNs to allow Mountpoint S3 CSI driver to manage items at the provided path(s). This is required if `attach_mountpoint_s3_csi_policy = true`\"\r\n```"]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/452", "comments": ["please revert this change", "this is intentional - please revert this change"]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/446", "comments": ["since this is already covered in the `CloudWatchAgentServerPolicy` managed policy - we can actually just use the two managed policies as is without a custom policy"]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/440", "comments": ["When `create_group` is set to `false,` then it expects that the IAM group with the name specified in `name` has already been created. Also, this module adds provided properties (such as `group_users`, `custom_group_policy_arns`, ...) to it.", "@antonbabenko with due respect, but I don't see the same behaviour being followed in the other modules, `iam-user` for example.", "If we had called this module `iam-group,` then the scope of resources should be - `all` or `nothing` (like in `iam-user`), but since it is `iam-group-with-policies`, it expects IAM group in one way or another.", "I found this behaviour pretty confusing @antonbabenko, but fair enough, thank you for the explanation \ud83d\ude4f ", "I agree it is confusing."]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/436", "comments": ["```suggestion\r\n  for_each = { for k, v in var.cluster_service_accounts : k => v if var.create_role }\r\n```\r\n\r\nIIRC, this approach is better when `var.cluster_service_accounts` contains dynamically created values (eg. resources). Is it still the case @bryantbiggs ?", "its the preferred approach so that you don't hit the error where the left side is of type `A` and doesn't match the right side of type `B`", "```suggestion\r\n    for_each = { for k, v in var.cluster_service_accounts : k => v if var.create_role }\r\n```", "@bryantbiggs Thanks for confirming this :)"]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/435", "comments": ["Comparing the [official AWS documentation page](https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_examples_aws_my-sec-creds-self-manage.html) with this statement block, should not we also have one more in `not_action`?\r\n\r\n> To also allow a user to change their password from their own user page without signing in using MFA, add the iam:UpdateLoginProfile action to the DenyAllExceptListedIfNoMFA statement.", "The doc has a bit blurry description.\r\nThe `iam:UpdateLoginProfile` action as exception needed to change the password **without** MFA if MFA enforcement is present, for example on initial login to reset the password.\r\nBut at the same time it gives the ability to bypass MFA when using AWS CLI or API to update the password via login profile call, e.g. `aws iam update-login-profile`. So in case of compromised access keys, the password could be changed without MFA code which is only required to login through Web Console."]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/434", "comments": ["```suggestion\r\n```", "```suggestion\r\n```", "```suggestion\r\n```", "```suggestion\r\n```"]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/411", "comments": ["What cases?"]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/407", "comments": ["I'm more inclined to revert back to the original since https://github.com/aws-actions/configure-aws-credentials#recent-updates"]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/403", "comments": ["Instead of putting these values in the examples, we would rather have them as defaults, so users should just upgrade the version of the module and use it right away.\r\n\r\n/cc @bryantbiggs WDYT?", "ya we can try that. I've checked internally as well and there isn't a clear path to resolution so lets try and see what happens", "lets just call this \r\n```suggestion\r\nvariable \"additional_thumbprints\" {\r\n```"]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/402", "comments": ["```suggestion\r\n    resources = var.load_balancer_controller_targetgroup_arns\r\n```"]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/396", "comments": ["Please update this version, also."]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/393", "comments": ["The only change I think that would be worthwhile here would be to change this to match the other modules by converting it to a variable with this value as the default. Then users have the ability to override and extend as they see fit", "It's changed like you said. In this modules this variable is right now a list of STS actions. Please review PR.", "apologies - it looks like we have/had multiple different methods in use across the modules here. reverted back to the concatting you had originally proposed"]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/389", "comments": ["this won't solve the issue - to solve the issue we just need to change the default value of `role_name_prefix` to `\"\"`", "Setting the `role_name_prefix` to `\"\"` does not solve the issue. It will create another issue because you will have `role_name` set to a value and `role_name_prefix` set to `\"\"`, and providing both of them to `aws_iam_role` generates a conflict error:\r\n`\"name_prefix\": conflicts with name`", "I think `aws_iam_role` can be created without either `name` or `name_prefix` which means both `role_name` and `role_name_prefix` can be kept  with default values `null`. In this case, \"else\" part will be executed and `\"${var.role_name_prefix}*\"` produces same error `Cannot include a null value in a string template.`\r\nWhat do you think about changing exactly the problematic place? I mean, something like\r\n```\r\nrole_name_condition = var.role_name != null ? var.role_name : \"${var.role_name_prefix == null ? \"\" : var.role_name_prefix}*\"\r\n```\r\nThis way if role is created without name or prefix, `role_name_condition` is `*` but never `null`", "But we want to allow only this role to assume itself. \r\n```\r\ncondition {\r\n        test     = \"ArnLike\"\r\n        variable = \"aws:PrincipalArn\"\r\n        values   = [\"arn:${local.partition}:iam::${local.account_id}:role${var.role_path}${local.role_name_condition}\"]\r\n}\r\n```\r\nWith `role_name_condition` set to `*`, the policy is too permissive.\r\nThe suggested solution solves the issue. Why is it problematic? ", "Hm, you're right about too permissive. By problematic I meant the place that causes the error", "Yeah, I see. But what is wrong with the proposed solution?", "If module is initiated without specifying `role_name` and `role_name_prefix` they are `null` by default. So `var.role_name != null` is false and \"else\" statement, which is `\"${var.role_name_prefix}*\"` being executed. This produces error \"Cannot include a null value in a string template.\"  even if `allow_self_assume_role` is false.", "In general, this solution is the same is it was in 5.19.0, so should be ok. \r\nWas I set as review on purpose or it's automatic?", "Yes, this solution is the same as it was in previous versions. And it is the same as how it is handled in other modules, such as: [iam-assumable-role-with-oidc/main.tf](https://github.com/terraform-aws-modules/terraform-aws-iam/blob/master/modules/iam-assumable-role-with-oidc/main.tf#L10)"]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/387", "comments": ["This output should be computed, something like `aws_iam_user_policy_attachment.this.*.arn` but not `var....`. Please update.", "This will fail if `var.create_user` is `false`.", "```suggestion\r\noutput \"policy_arns\" {\r\n```\r\n\r\nThe word `custom` is obsolete in this context. Please change the input variable name as well.", "```suggestion\r\n# IAM user with IAM policy attached\r\n```"]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/378", "comments": ["In the comment, does it make sense to point to a tag/release instead of a moving `main` branch?\r\n\r\nThe rest LGTM.", "good point - corrected in https://github.com/terraform-aws-modules/terraform-aws-iam/pull/378/commits/5ca15c6b85f6802b384d6ab9687d136c11ac7a5c", "It will never be `null`, because there is always at least `*`, so `try()` is obsolete.", "I think you are thinking of the `karpenter_controller_cluster_id`/`karpenter_controller_cluster_name` which defaults to `\"*\"` - `role_name` and `role_name_prefix` both default to `null` which will cause `coalesce()` to fail if neither are provided a value (in the case of `create = false`)", "oh, or perhaps you are referring to the asterisk on the prefix variant - this too fails when `role_name_prefix` is `null`, stating that a `null` value cannot be supplied to a templated value", "Right, then it is well-written. :)", "I think this needed conversation needed more thoughts. this condition now makes line 33 always fail if `role_name_prefix` is not provided"]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/373", "comments": ["this will cause issues as stated here https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_role\r\n\r\n![image](https://user-images.githubusercontent.com/10913471/232491917-082a5c6c-890a-4e7b-96ba-d017e4720fb6.png)\r\n"]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/370", "comments": ["```suggestion\r\n  pgp_key                 = try(data.http.pgp_key[0].response_body, var.pgp_key)\r\n```", "Please add an empty line after `count`."]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/360", "comments": ["I believe we can simply use:\r\n```suggestion\r\n  assume_role_policy = coalesce(var.assume_role_policy, data.aws_iam_policy_document.assume_role_with_oidc[0].json)\r\n```", "this can be removed", "```suggestion\r\nvariable \"assume_role_policy\" {\r\n```\r\n\r\nDescription `Custom policy that grants an entity permission to assume the role. A policy will be created if a custom policy is not provided`\r\n\r\nDefault value should be `null`", "the other changes can be carried throughout the other modules", "Hello @bryantbiggs, changes done as per your peer review.\r\nThanks a lot for your precious feedback.\r\nLet me know if there are still adaptations to be done.", "this is a breaking change so we won't be making that here. a lot of these changes and nuanced differences will be resolved at the next breaking change (ref  https://github.com/clowdhaus/terraform-aws-iam)", "So, I reverted back my changes to remove the breaking chages.\r\nThanks."]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/357", "comments": ["we can remove `\"autoscaling:UpdateAutoScalingGroup\"` since its not listed in the cluster-autoscaler policy on the project, but the rest of the changes need to be reverted. The statement below has a condition which many of these permissions will fail on", "First thanks you for the quick response. Based on the related [documentation](https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/cloudprovider/aws/README.md#full-cluster-autoscaler-features-policy-recommended) it is possible to use it with condition and tags like here: _\"In this example, only the second block of actions should be updated to restrict the resources/add conditionals:\"_ And also the EC2 instances has the tag from autoscaling group. For \"eks:DescribeNodegroup\" in the 2nd [example](https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/cloudprovider/aws/README.md#minimal-iam-permissions-policy) is it similar with ARN but not same. Below the example the API use case with \"eks:DescribeNodegroup\" is described but I could not test so far.", "@bryantbiggs I can adjust the PR, but I wanted to ask if the additional information has it described a little better and impact  first feedback?", "I'm sorry but I am not following. from what I can see from the upstream project, we should only be removing `autoscaling:UpdateAutoScalingGroup` and not modifying anything else in this PR", "@bryantbiggs the PR is update as discussed.", "```suggestion\r\n        \"autoscaling:TerminateInstanceInAutoScalingGroup\",\r\n```", "Now it's fixed. \ud83d\udc4d"]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/345", "comments": ["we can remove this - its redundant "]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/343", "comments": ["https://github.com/terraform-aws-modules/terraform-aws-iam/pull/341/files#r1128702566", "fixed. Should have checked for other PRs before making this, sorry."]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/341", "comments": ["Should probably substitute `aws` with `${local.partition}` here."]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/335", "comments": ["we should add a variable `path` that defaults to `\"/\"` and then update like:\r\n```suggestion\r\n[\"arn:${local.partition}:iam::${local.aws_account_id}:user/${var.path}$${aws:username}\"]\r\n```", "Adding a path here will not work as users with different paths (or even with no path) can be added to the same IAM group.", "ah right, you are correct. It would have to be something like `$${aws:userpath}` that AWS would know how to populate dynamically"]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/321", "comments": ["Please write it in one line like \"Whether to create a custom role trust policy\".", "The condition should be reverted to be the same as before. Now, `create_custom_role_trust_policy` is `false`, by default. Please verify.", "Done 1b682e14ba2e2adc719d80c43df929a190771b37", "~I don't really understand your point here, `create_custom_role_trust_policy = false` and `custom_role_trust_policy == \"\"` are equivalent. right?~ I understand now the issue, sorry\r\nAlso, I found an issue happening when  `create_custom_role_trust_policy` was false and `custom_role_trust_policy` was not empty. I introduced a fix here: 1d9c0e43283ee6e22f637e18ec7fb4236e99b31c", "Done 84a47eacda09cb35960310bfe6c634f1b770ddc2"]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/317", "comments": ["```suggestion\r\n    actions = compact(distinct(concat([\"sts:AssumeRoleWithSAML\"], var.trusted_role_actions)))\r\n```"]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/315", "comments": ["Since this is optional, it should be `null` which the API or the provider will set the actual default value\r\n\r\n```suggestion\r\n  default     = null\r\n```", "```suggestion\r\n| <a name=\"input_iam_access_key_status\"></a> [iam\\_access\\_key\\_status](#input\\_iam\\_access\\_key\\_status) | Access key status to apply. | `string` | `null` | no |\r\n```"]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/313", "comments": ["I think we should make this a variable where the default is the current behavior, but users can override with a wildcard for multiple MFA devices", "I will take another look to confirm (create a new IAM user and try to add a virtual MFA device with current `IAMSelfManagement` policy).\r\nBut it seems to me that since this new feature was released, the very first MFA device resource ARN take the name defined by user during his creation : `arn:aws:iam::<aws_account_id>:mfa/<virtual_mfa_device_name>`", "> \r\n\r\nSorry for not getting back to you sooner, but after a new test, I can confirm the issue. \r\n\r\nI have tested the following scenarios from a brand-new IAM user deployed with the module : \r\n- Add virtual MFA device : :-1:  \r\n- Remove existing virtual MFA device : :-1: \r\n\r\nAfter modifying the `IAMSelfManagement` policy with `arn:aws:iam::<aws_account_id>:mfa/*` : \r\n- Add virtual MFA device : :+1:  \r\n- Remove existing virtual MFA device when logged in without MFA : not working, that's normal  :+1: \r\n- Remove virtual MFA device : :+1: \r\n\r\nThe day after the PR, I noticed that the[ AWS documentation](https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_examples_aws_my-sec-creds-self-manage-mfa-only.html) was updated : see `AllowManageOwnVirtualMFADevice` statement.\r\nBut this is not updated [everywhere](https://github.com/awsdocs/iam-user-guide/blob/main/doc_source/reference_policies_examples_iam_mfa-selfmanage.md) yet.\r\n", "awesome, thank you for investigating! \r\n\r\n1. I see, you are absolutely correct on the wildcard\r\n2. However, we need to really update our policy. Could you update to match what they have provided in that doc which is more scoped now when we introduce wildcards. Note: I didn't fully check/compare so please do that - but we should look to split out to multiple statements based on the resource being specified\r\n\r\n```json\r\n{\r\n    \"Version\": \"2012-10-17\",\r\n    \"Statement\": [\r\n        {\r\n            \"Sid\": \"AllowViewAccountInfo\",\r\n            \"Effect\": \"Allow\",\r\n            \"Action\": \"iam:ListVirtualMFADevices\",\r\n            \"Resource\": \"*\"\r\n        },\r\n        {\r\n            \"Sid\": \"AllowManageOwnVirtualMFADevice\",\r\n            \"Effect\": \"Allow\",\r\n            \"Action\": [\r\n                \"iam:CreateVirtualMFADevice\"\r\n            ],\r\n            \"Resource\": \"arn:aws:iam::*:mfa/*\"\r\n        },\r\n        {\r\n            \"Sid\": \"AllowManageOwnUserMFA\",\r\n            \"Effect\": \"Allow\",\r\n            \"Action\": [\r\n                \"iam:DeactivateMFADevice\",\r\n                \"iam:EnableMFADevice\",\r\n                \"iam:GetUser\",\r\n                \"iam:ListMFADevices\",\r\n                \"iam:ResyncMFADevice\"\r\n            ],\r\n            \"Resource\": \"arn:aws:iam::*:user/${aws:username}\"\r\n        },\r\n        {\r\n            \"Sid\": \"DenyAllExceptListedIfNoMFA\",\r\n            \"Effect\": \"Deny\",\r\n            \"NotAction\": [\r\n                \"iam:CreateVirtualMFADevice\",\r\n                \"iam:EnableMFADevice\",\r\n                \"iam:GetUser\",\r\n                \"iam:ListMFADevices\",\r\n                \"iam:ListVirtualMFADevices\",\r\n                \"iam:ResyncMFADevice\",\r\n                \"sts:GetSessionToken\"\r\n            ],\r\n            \"Resource\": \"*\",\r\n            \"Condition\": {\r\n                \"BoolIfExists\": {\"aws:MultiFactorAuthPresent\": \"false\"}\r\n            }\r\n        }\r\n    ]\r\n}\r\n```", "To have a more scoped policy with no impacts, I made few changes : \r\n- Rollback previous changes (`AllowSelfManagement` & `AllowDeactivateMFADevice` statements)\r\n- Add 2 more explicit statements :\r\n  - `AllowManageOwnVirtualMFADevice` => to allow action `iam:CreateVirtualMFADevice` with the correct resource name\r\n  - `AllowDeleteVirtualMFADevice` => to allow the action with the correct resource name", "Hello, \r\n\r\nI made few changes here, according to [this AWS documentation ](https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_examples_aws_my-sec-creds-self-manage.html). \r\n\r\nThe AWS policy allows IAM users **that are authenticated using multi-factor authentication (MFA)** to manage their own credentials on the _My security credentials page_. It also **requires** the user to set up and authenticate using MFA before performing **any** other operations in AWS ! \r\n\r\nIn real terms, that enforce MFA utilization. Because the IAM user **cannot do anything** before his MFA is configured, and he is authenticated with. \r\n\r\nThis is a great security improvement but this is a big change too. Is it what we want ?  \r\n\r\n\r\n\r\n\r\n", "@bryantbiggs Are you OK with that ? \r\n\r\nIf you're not, I can try to add a new variable to allow the user to choose between the [standard policy](https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_examples_aws_my-sec-creds-self-manage-no-mfa.html) (which do not force MFA utilization) or the [more secure](https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_examples_aws_my-sec-creds-self-manage.html) (which force MFA).", "yes, I think this looks great and a good improvement; thank you"]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/310", "comments": ["```suggestion\r\n      values = [for subject in var.subjects : \"repo:${trimprefix(subject, \"repo:\")}\"]\r\n```\r\n\r\nA bit shorter and nicer with native functions - https://developer.hashicorp.com/terraform/language/functions/trimprefix"]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/308", "comments": ["I think this ok for the main github.com, but it will have to be parametrized when using with GitHub Enterprise, as described [here](https://sjramblings.io/github-actions-aws-authentication-with-oidc-for-github-enterprise/) (search for `mygithub.com/_services/token`).\r\n\r\nLet's make this as a variable with this value as the default.", "good callout, however - I don't know if that post is correct. For example, it does not appear to reference the AWS STS service (secure token service) anywhere so I'm a little confused. I've reached out internally to see if I can get in contact with someone at GitHub for some guidance. I'll update once I know a bit more", "\ud83d\udc4d Maybe the post I found was not the most accurate one.", "eh, I don't know if I know enough to weigh in on whether its correct or not \ud83d\ude05 - since its security related, I figured its better to error on the side of caution and see if I can find someone who would be able to weigh in on the matter", "Currently, you've made it as a variable (with the correct default value), so it should be good enough for merge.", "well, that post doesn't have some things like this https://github.com/terraform-aws-modules/terraform-aws-iam/pull/308/files#diff-490344238465f9b048f0ff98d48bfe068162248472dba85614109d31edf6f269R33-R37\r\n\r\nwhich made me realize they don't have any reference to the secure token service which I believe is a hard requirement for these two entities to create a trust relationship (between GitHub and AWS)", "Right. Hopefully, someone with GHE experience can verify and confirm it.", "learned something new - at the top of the GitHub docs, theres a drop down on the right header to switch the docs between different flavors of GitHub:\r\n- Standard docs for SaaS GitHub: https://docs.github.com/en/actions/deployment/security-hardening-your-deployments/configuring-openid-connect-in-amazon-web-services\r\n- Enterprise docs: https://docs.github.com/en/enterprise-server@3.7/actions/deployment/security-hardening-your-deployments/configuring-openid-connect-in-amazon-web-services\r\n\r\nPer those docs, it looks like the sub and aud URLs are the only thing changing, and potential the aud value whether you are using the official github action or not so I have updated the PR to suit those conditions"]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/304", "comments": ["lets make this dynamic if an SQS queue arn is provided", "lets add a variable for this `karpenter_sqs_queue_arn` since we are not guaranteed that the queue name will always be the cluster name ", "@bryantbiggs what do you mean with dynamic?\r\ni've already created a var for `karpenter_sqs_queue_arn` and a local"]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/301", "comments": ["I think this is better suited to be a variable if we need to change it - see https://github.com/terraform-aws-modules/terraform-aws-iam/blob/3ec0f0fd5d360019231f14fc7431418b52deda0c/modules/iam-role-for-service-accounts-eks/variables.tf#L76", "Fixed", "This example doesn't match the changes being made", "Should be fixed now", "```suggestion\r\n  default     = \"StringLike\"\r\n```", "```suggestion\r\n| <a name=\"input_assume_role_condition_test\"></a> [assume\\_role\\_condition\\_test](#input\\_assume\\_role\\_condition\\_test) | Name of the [IAM condition operator](https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_elements_condition_operators.html) to evaluate when assuming the role | `string` | `\"StringLike\"` | no |\r\n```"]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/299", "comments": ["```suggestion\r\n- Does not support multiple regions, consider using [iam-role-for-service-accounts-eks](https://github.com/terraform-aws-modules/terraform-aws-iam/blob/master/modules/iam-role-for-service-accounts-eks/) if role needs to support clusters in multiple regions\r\n```", "Can we update/combine this with the 2nd bullet since I think they are related. It supports multiple clusters, but the caveat is that it does not support multiple regions due to the use of the `aws_eks_cluster` data source\r\n\r\n```suggestion\r\n- Does not support multiple regions, consider using [iam-role-for-service-accounts-eks](https://github.com/terraform-aws-modules/terraform-aws-iam/blob/master/modules/iam-role-for-service-accounts-eks/) if role needs to support clusters in multiple regions\r\n```\r\n\r\ncc @max-rocket-internet ", "Hey \ud83d\udc4b\r\n\r\n@sepulworld \r\n\r\n>  inform user that this sub module will not work for multiple regions\r\n\r\nThere is a note already in the [README](https://github.com/terraform-aws-modules/terraform-aws-iam/blob/master/modules/iam-eks-role/README.md) that says \"The EKS cluster needs to exist first, in the current AWS account and region\". I think that's pretty clear, no?\r\n\r\n> consider using iam-role-for-service-accounts-eks\r\n\r\nI don't think this is great advice since the `iam-role-for-service-accounts-eks` module is stated for \"commonly used controllers/custom resources\" (quite specific) whereas `iam-role-eks` has no specific use case like this, it's simply to create a general IRSA role that could be used for anything. The existing readme already details differences compared to [iam-assumable-role-with-oidc](https://github.com/terraform-aws-modules/terraform-aws-iam/blob/master/modules/iam-assumable-role-with-oidc/), perhaps we recommend using this for multi-region?"]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/290", "comments": ["ALL examples should be executable right away, as described in the README - `terraform init -upgrade && terraform apply -auto-approve && terraform destroy -auto-approve`.\r\n\r\nCurrently, some of the examples are failing with `EntityAlreadyExists` errors. Please fix.", "Revert this change.", "Also this one.", "Could you please elaborate on why it's better to use data instead of local?", "Usually, do not touch it if it works is a very important rule. Such microchanges pollute the PR and make it hard to review. This PR is doing more than fixing an original issue.\r\n\r\nIntroducing `locals` makes perfect sense when there is some logic in it (e.g. `local.aws_account_id`).", "Got it, thank you for the explanation.", "@antonbabenko  This one can't be reverted because the module will stop working due to missing `account_id` local. If you check locals above you can see that `aws_account_id` is declared, however, `account_id` is not. When I looked at [this](https://github.com/terraform-aws-modules/terraform-aws-iam/pull/283/files#diff-ab579ba376417161fb0950cae991b5ffb34ee5c20c780f0cc154ad5fbf263880L28) change which introduced the problem it seemed obvious to just revert it to state it was before.", "@antonbabenko Fixed most of the examples that were failing with error above. NOTE: `iam-eks-role` can't be applied for some time now so I consider it out of the scope to fix it in this PR.", "Reverted"]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/283", "comments": ["please see the failed CI checks - these should all be a local\r\n```suggestion\r\n        values   = [\"arn:${local.partition}:iam::${local.account_id}:role${var.role_path}${local.role_name_condition}\"]\r\n```"]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/281", "comments": ["when testing the example, this failed due to the account ID (I assume) so I removed"]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/278", "comments": ["```suggestion\r\n    try([data.aws_iam_policy_document.assume_role_with_oidc[0].json, [])\r\n```", "```suggestion\r\n    try([data.aws_iam_policy_document.assume_self[0].json], [])\r\n```", "note - be careful because role path is not clear here and unless users know to pre-pend the role path into `var.role_name`, they may face issues when using roles with role paths", "Maybe we should include `var.role_path` also into this line?", "instead of a new document data source and then merging documents, we can use a dynamic statement block instead like\r\n\r\n```hcl\r\n  dynamic \"statement\" {\r\n    for_each = var.explicit_permission_to_assume_self ? [1] : []\r\n    \r\n    content {\r\n      ...\r\n    }\r\n  }\r\n```", "For Govcloud and CN support:\r\n\r\n```suggestion\r\n      identifiers = [\"arn:${data.aws_partition.current.partition}:iam::${data.aws_caller_identity.current.account_id}:role${var.role_path}${var.role_name}\"]\r\n```"]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/273", "comments": ["this is already available here https://github.com/terraform-aws-modules/terraform-aws-iam/blob/d6164989a94e1e9711e40e6fb0c374c2d3945149/modules/iam-role-for-service-accounts-eks/policies.tf#L586", "this is already provided here https://github.com/terraform-aws-modules/terraform-aws-iam/blob/d6164989a94e1e9711e40e6fb0c374c2d3945149/modules/iam-role-for-service-accounts-eks/policies.tf#L570", "this is is already provided here https://github.com/terraform-aws-modules/terraform-aws-iam/blob/d6164989a94e1e9711e40e6fb0c374c2d3945149/modules/iam-role-for-service-accounts-eks/policies.tf#L581", "we need to provide support for deleting launch templates that karpenter creates", "this makes some strong assumptions that go against feedback from users and is also a breaking change", "That's not required from my experience.", "@bryantbiggs The Karpenter controller IAM role is using the policies defined [here](https://github.com/terraform-aws-modules/terraform-aws-iam/blob/9210e6c6dc2bbd00065bc6f9212d04a0f49adec2/modules/iam-role-for-service-accounts-eks/policies.tf#L517). When using that policy karpenter has lots of unauthorized errors and can not even spin up nodes. However,  we use the policy defined in the [AWS EKS Blueprints](https://github.com/aws-ia/terraform-aws-eks-blueprints/blob/015834f05273cab73310cec68386aebf7d64627b/modules/kubernetes-addons/karpenter/data.tf) karpenter works well.\r\n\r\nThe current IRSA module for karpenter does not work out of the box for us because of the missing permissions. I can show you some evidence that the current module `5.3.1` does not have the right permissions in place.", "What feedback did you get about it ? This change seems to work well for us", "The link you provided to the policy makes reference to [karpenter v0.6.1](https://github.com/terraform-aws-modules/terraform-aws-iam/blob/d6164989a94e1e9711e40e6fb0c374c2d3945149/modules/iam-role-for-service-accounts-eks/policies.tf#L516). Karpenter is currently on v0.16.1. You may need to validate the IAM policy against the current karpenter version", "Newer versions of karpenter have a new label that can make this delete policy depend on it, instead of the name like it did in the past.\nHard coding it back to just name is bad. ", "it is required", "can you provide your configuration so I can try to reproduce on my end?"]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/271", "comments": ["I think this fix is ok as a temporary solution while the upstream provider is not fixed properly...\r\n\r\nPlease add a comment to the [upstream provider issue](https://github.com/hashicorp/terraform-provider-aws/issues/23567) around this line so that we know why this was added in the module in the future.", "@antonbabenko Done!"]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/250", "comments": ["Demonstrates computed resource usage which is what was raised in #193"]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/242", "comments": ["eh?"]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/231", "comments": ["```suggestion\r\n      \"arn:${local.partition}:iam::*:role/aws-service-role/appmesh.${local.dns_suffix}/AWSServiceRoleForAppMesh\"\r\n```", "```suggestion\r\n      values   = [\"appmesh.${local.dns_suffix}\"]\r\n```", "This is a resource when it should be actions "]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/229", "comments": ["we should leave this as is - its up to users to provide the correct ARNs", "same as above, leave as is", "same for all of these - we don't modify the variables users provide us, they should provide the correct ARNs", "this is just a comment showing where the policy came from so leave as is"]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/206", "comments": ["thank you \ud83d\ude4f\ud83c\udffd ", "I think we only need `\"iam:CreateServiceLinkedRole\"` here, and can remove `\"iam:AttachRolePolicy\"` and `\"iam:PutRolePolicy\"`\r\n\r\nRef: \r\n```json\r\n{\r\n  \"Action\":\"iam:CreateServiceLinkedRole\",\r\n  \"Effect\":\"Allow\",\r\n  \"Resource\":\"*\",\r\n  \"Condition\":{\r\n    \"StringLike\":{\r\n      \"iam:AWSServiceName\":[\r\n        \"fsx.amazonaws.com\"\r\n      ]\r\n    }\r\n  }\r\n},\r\n```", "The actions should be changed to:\r\n\r\n```\r\n\"s3:ListBucket\",\r\n\"fsx:CreateFileSystem\",\r\n\"fsx:DeleteFileSystem\",\r\n\"fsx:DescribeFileSystems\",\r\n\"fsx:TagResource\"\r\n```\r\n\r\nRef: \r\n\r\n```json\r\n{\r\n  \"Effect\": \"Allow\",\r\n  \"Action\": [\r\n    \"s3:ListBucket\",\r\n    \"fsx:CreateFileSystem\",\r\n    \"fsx:DeleteFileSystem\",\r\n    \"fsx:DescribeFileSystems\",\r\n    \"fsx:TagResource\"\r\n  ],\r\n  \"Resource\": [\"*\"]\r\n}\r\n```", "Lets remove these extra blank lines please", "Lets remove these extra blank lines please - just need one blank line between doc comment and previous resource block", "```suggestion\r\n# FSx for Lustre CSI Driver Policy\r\n```", "```suggestion\r\n      \"arn:${local.partition}:iam::*:role/aws-service-role/s3.data-source.lustre.fsx.${local.dns_suffix}/*\",\r\n```", "```suggestion\r\n      values   = [\"fsx.${local.dns_suffix}\"]\r\n```", "```suggestion\r\n  description = \"Determines whether to attach the FSx for Lustre CSI Driver IAM policy to the role\"\r\n```", "this is not resolved - please double check the policies provided by AWS", "I guess I overlooked this before? I don't remember it - but this is not in the policy so we can remove this whole statement block"]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/199", "comments": ["For the `Modify*`/`Register*`/`Deregeister*` actions, should we not break these permissions out to avoid the wildcard, similar to the [full controller policy](https://github.com/terraform-aws-modules/terraform-aws-iam/blob/691bb9203b4fb970c26a6b1e09379e259cb0e3bd/modules/iam-role-for-service-accounts-eks/policies.tf#L686-L712). Something like\r\n\r\n```hcl\r\n  statement {\r\n    actions = [\r\n      \"ec2:DescribeSecurityGroups\",\r\n      \"ec2:DescribeInstances\",\r\n      \"ec2:DescribeVpcs\",\r\n      \"elasticloadbalancing:DescribeTargetGroups\",\r\n      \"elasticloadbalancing:DescribeTargetHealth\",\r\n    ]\r\n\r\n    resources = [\"*\"]\r\n  }\r\n\r\n  statement {\r\n    actions = [\r\n      \"elasticloadbalancing:ModifyTargetGroup\",\r\n      \"elasticloadbalancing:ModifyTargetGroupAttributes\",\r\n    ]\r\n    resources = [\"*\"]\r\n\r\n    condition {\r\n      test     = \"Null\"\r\n      variable = \"aws:ResourceTag/elbv2.k8s.aws/cluster\"\r\n      values   = [\"false\"]\r\n    }\r\n  }\r\n\r\n  statement {\r\n    actions = [\r\n      \"elasticloadbalancing:RegisterTargets\",\r\n      \"elasticloadbalancing:DeregisterTargets\",\r\n    ]\r\n    resources = [\"arn:${local.partition}:elasticloadbalancing:*:*:targetgroup/*/*\"]\r\n  }\r\n```\r\n\r\nWith that we could even go one step further and allow users to restrict which target groups with\r\n\r\n```hcl\r\n  statement {\r\n    actions = [\r\n      \"ec2:DescribeSecurityGroups\",\r\n      \"ec2:DescribeInstances\",\r\n      \"ec2:DescribeVpcs\",\r\n      \"elasticloadbalancing:DescribeTargetGroups\",\r\n      \"elasticloadbalancing:DescribeTargetHealth\",\r\n    ]\r\n\r\n    resources = [\"*\"]\r\n  }\r\n\r\n  statement {\r\n    actions = [\r\n      \"elasticloadbalancing:ModifyTargetGroup\",\r\n      \"elasticloadbalancing:ModifyTargetGroupAttributes\",\r\n    ]\r\n    resources = [\"*\"]\r\n\r\n    condition {\r\n      test     = \"Null\"\r\n      variable = \"aws:ResourceTag/elbv2.k8s.aws/cluster\"\r\n      values   = [\"false\"]\r\n    }\r\n  }\r\n\r\n  statement {\r\n    actions = [\r\n      \"elasticloadbalancing:RegisterTargets\",\r\n      \"elasticloadbalancing:DeregisterTargets\",\r\n    ]\r\n    resources = [for name in var.load_balancer_controller_targetgroup_names :\r\n      \"arn:${local.partition}:elasticloadbalancing:*:*:targetgroup/${name}/*\"\r\n    ]\r\n  }\r\n```\r\n\r\nWhere the variable `load_balancer_controller_targetgroup_names` defaults to `*`. What do you think?", "The use case for TargetGroupBinding only mode, vs. full ALB, is that you want to create (or already have pre-existing) TargetGroups outside of the kubernetes environment.  This change would require the TargetGroup in question to have the elbv2.k8s.aws/cluster tag.  While on one hand this solution ensures that at least the owner/creator of the TargetGroup intended for it to be updated from a load-balancer-controller, the downside is there may be valid reasons for that tag to not exist.\r\n\r\nThe second thought - your proposed change is a better version than what is documented as part of the load-balancer-controller intro guide.   A person trying for the first time to use this module would quickly realize it didn't work, until they reverse engineer looking at this policy, then see that they need to go back and tag their TargetGroups with this k8s tag.  I suggest that if you implement it this way, the ideal would be that the TargetBingingOnly documentation should include this more restricted version of the role vs. their more permissive one.  The load-balancer-controller documentation could then describe the requirement to tag the TargetGroup.\r\n\r\nHowever, the Register/Deregister change I think is brilliant.  We could make an option as well for var.load_balancer_controller_targetgroup_arns if we wanted to, and then you could pass name or arn...?\r\n", "```suggestion\r\n  role_name                                                       = \"load_balancer_controller_targetgroup_binding_only\"\r\n```", "what a name \ud83d\ude05 ", "For now we'll proceed with what is defined by the upstream documentation. We can revisit later for any additional policy scoping", "```suggestion\r\n  description = \"Determines whether to attach the Load Balancer Controller policy for the TargetGroupBinding only\"\r\n```"]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/189", "comments": ["Is it better to use [`aws_service` data source](https://github.com/hashicorp/terraform-provider-aws/pull/16640/files) instead of generating values manually? It is not in the documentation for some reason, yet. I am trying to think about a use case for it and whether we should be using it in some time?", "Cool! _assuming it works_ \ud83d\ude35\u200d\ud83d\udcab ", "(oof, looks like I had an error here). I tried that new data source but I don't think in this scenario it will help. using the `dns_name` attribute it gives back a region specific endpoint but for IAM permissions I think we want global like https://github.com/kubernetes-sigs/aws-load-balancer-controller/blob/694a0b14184e388806f9f34be0dd9075aa8fb0a7/docs/install/iam_policy.json#L12\r\n\r\nat least for this instance I don't think its warranted yet, I'm sure there are other areas that it could be useful", "I see. We would need to use `dns_prefix` (`\"amazonaws.com\"`) but there is only `reverse_dns_prefix` (`\"com.amazonaws\"`) among attributes.", "https://github.com/hashicorp/terraform-provider-aws/pull/16640#issuecomment-1043389369"]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/185", "comments": ["```suggestion\r\n  default     = []\r\n```\r\n\r\nIt should be up to the user to decide what should be denied. Actually, `s3:GetObject` is pure read-only action :)", "It is pure read indeed\r\nThis default is more of a guardrail since s3:GetObject gives to all resources will unintentionally give access to sensitive data. If everyone would use CMK's for the sensitive data according to security best practices then s3:GetObject would be not a problem because you would also need km:Decrypt for the key to get the object.\r\n\r\nAnyhow, I see your point but got many people to point out that giving s3:GetObject is dangerous. So user's preference here is to disable it or replace it with more stuff.\r\n\r\nPerhaps I should add this explanation to the description. What do you think?\r\n", "I believe that these modules should contain as few `magic values` as possible. Let's make it `default = []` and I will merge it right away."]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/184", "comments": ["Is this the official way of dealing with attribute outputs from resources that may or may not exist now? I like it, it's cleaner, but it works in all cases, like when on `destroy` also?", "Over all I like the idea of including the policies as it makes the module much more useful.\r\n\r\nBut it's quite a deviation from historical practice in the hashicorp module where they are generally kept VERY sparse and simple.", "This would be too broad for most people I think as it would allow termination of ANY EC2 instance in an ASG.\r\n\r\nPersonally I would copy the policy from [here](https://github.com/terraform-aws-modules/terraform-aws-eks/pull/716/files#diff-49c22f96d12f8b3391c9493b1ebcf2d0b8f9d6948fec4f0f3475338b0b1a7c6bR26-R66) as it includes the proper `condition` to limit the policy to this cluster. But then you would need to pass in the `cluster_id`...", "I think you can just do this, no?\r\n\r\n```suggestion\r\n    resources = var.external_dns_hosted_zone_arns\r\n```", "Could also be done in a later PR by someone who wants it", "You don't need to write this policy, it's already done by Amazon \ud83d\ude03\r\n\r\n```suggestion\r\n  policy_arn = \"arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy\" \r\n```", "Totally up to you but I would strictly stick to policies for tools that are solely from AWS otherwise you will get PRs from people for every random service they want to use \ud83d\ude05", "Please don't remove all this! This is the whole reason why I wrote this module! To get a nice clean simple implementation, for example like this:\r\n\r\n```\r\nmodule \"iam_eks_role\" {\r\n  source      = \"terraform-aws-modules/iam/aws//modules/iam-eks-role\"\r\n  role_name   = \"my-app\"\r\n\r\n  cluster_service_accounts = {\r\n    \"cluster1\" = [\"default:my-app\"]\r\n  }\r\n}\r\n```\r\n\r\nIn this case the user only needs to know the name of the cluster. That's it. By removing `data.aws_eks_cluster.main` you are then putting it on the user to get/find their OIDC provider ARN and URL. At which point the user needs to either have the EKS cluster in the same TF configuration (like you have in the examples now with `provider=module.eks.oidc_provider`) OR they have to use a data resource. If you rewrite it like this then it's basically the same as the [iam-assumable-role-with-oidc](https://github.com/terraform-aws-modules/terraform-aws-iam/tree/master/modules/iam-assumable-role-with-oidc) module \ud83d\ude05\r\n\r\nFurthermore, I already added `var.provider_url_sa_pairs` in case people really want to deal with the OIDC provider details or mix both.", "No it hasn't and shouldn't be related or reliant on this other module IMO\r\n\r\n```suggestion\r\nThis module has been design in conjunction with the [`terraform-aws-eks`](https://github.com/terraform-aws-modules/terraform-aws-eks) module and easily integrates with it:\r\n```", "That policy is only valid for IPv4 clusters; if you want to use IPv6 then you have to create your own https://github.com/bryantbiggs/terraform-aws-eks/blob/9c9ac81e3a3a91d52b5341d005de80a05a2fa0e8/node_groups.tf#L11 - just wrapping them both here allows for simpler conditionals as well as coverage for both IPv4 and IPv6 in one role", "OK now I see that Karpenter is an AWS project. Never heard of it. So I guess ignore this comment!", "but it has and it should be - this module handles the IAM roles/policies while the EKS module handles the cluster resources. there are next steps to remove current pieces from the EKS module like https://github.com/bryantbiggs/terraform-aws-eks/blob/master/node_groups.tf#L9-L47\r\n\r\nplus we have other teams that are looking for this integration as well to simplify their user experience - Karpenter being one of them with others interested as well", "likewise, we have made changes to make these more interoperable https://github.com/terraform-aws-modules/terraform-aws-eks/pull/1870", "OK cool, sounds good", "unfortunately, this is the crux of the issue with this sub-module however. \r\n1. its not clear to users that the cluster name should be the key of the maps\r\n2. it restricts users to creating a role in one region while roles are global - they will will have to figure out when to use `cluster_service_accounts` and when to use `provider_url_sa_pairs` when its not quite clear what the difference is on the surface\r\n3. most importantly is the lifecycle issue. you cannot specify this role and a cluster and create at the same time. the cluster has to exist first", "But there is nothing currently in this module that is related to the EKS module? They weren't \"designed in conjunction with\" at all, they were written and are separate. You could create your EKS cluster with `eksctl` and still use this module? Maybe my beef is just with the wording..", "Maybe I'm missing some context here, is there a github issue talking about issues with the `iam-eks-role` module?\r\n\r\n1. How is it not clear? Do you have some example github issues where users can't work it out? There were examples where it [was](https://github.com/terraform-aws-modules/terraform-aws-iam/commit/61cf5428fedd898de7f8287af2031a449d644723#diff-b335630551682c19a781afebcf4d07bf978fb1f8ac04c6bf87428ed5106870f5R255-R260) clear but it seems @antonbabenko has changed it with `random_pet `\ud83e\udd14  But in the main readme there is an example where the key is `cluster1`, that's pretty clear, no?\r\n2. But even with your change, it's not any different in this regard. If the difference between `cluster_service_accounts/provider_url_sa_pairs` is not clear from the docs then let's fix the docs. Or just remove `provider_url_sa_pairs` as this can be done in the module `iam-assumable-role-with-oidc` anyway.\r\n3. Why does that matter? An IAM role could be created in a separate TF configuration by a separate team to an EKS cluster. You can't create an RDS instance with `terraform-aws-rds` without a EC2 subnet existing but a subnet ID is just passed as a string, for example \ud83d\ude42", "ya, its the \"new kid on the block\"", "good call out - fits with the other policies and corrected in https://github.com/terraform-aws-modules/terraform-aws-iam/pull/184/commits/41d38278638f6ea2df00492b69deedfd5c0a304d", "thats a great point, skipped over that section in the docs. this too fits inline with the other policies where the docs are more open with `\"*\"` but here we are defaulting to open-ish while giving folks access to be more restrictive. added in https://github.com/terraform-aws-modules/terraform-aws-iam/pull/184/commits/41d38278638f6ea2df00492b69deedfd5c0a304d", "official - I don't know. however, I definitely use and abuse `try()` since it works so well in various use cases; outputs just happens to be one of those (and it shortens up the syntax a bit)", "imho its not perfectly clear that the key of the map has to match the exact cluster name for functional reasons and isnt just meant to be an abbreviation to differentiate in the context of the map", "To give some context, this change came about from \r\n- https://github.com/terraform-aws-modules/terraform-aws-eks/issues/1825\r\n- https://github.com/terraform-aws-modules/terraform-aws-eks/issues/1841\r\n\r\nAnd I agree with the sentiments of those issues - these seem like common patterns many folks are repeating over and over and over (creating an IRSA role, specifying a policy, etc. - for common addons like VPC CNI, cluster autoscaler, etc.)\r\n\r\nAt first I thought something like this was being requested https://github.com/terraform-aws-modules/terraform-aws-eks/pull/1827 but after clarifying, its really just the IRSA role w/ policy for common addons. Something where folks can just simply create an IRSA role and flip a flag to provide canned permissions for the use case of that role. \r\n\r\nSo with that I came here because of the `iam-assumable-role-with-oidc` module, but then saw and remembered you added something for EKS and thought it would make the most sense to add on to this role to allow users to opt in to various canned permissions for common addons. However, in testing that I came across the lifecycle issues and  through testing cycles just reduced it down to the version you see now. \r\n\r\nThats the context bit.\r\n\r\nRegarding a path forward, I do believe we have to fix the lifecycle issue. Unfortunately this is how a lot of people work, especially when testing/trying out modules, plus we are seeing a lot more use cases where users are creating and destroying resources quite frequently in a CI pipeline type setup. So the targetted apply of `terraform apply -target module.vpc -target module.eks` is not going to fly. It also won't fly when we start propagating the use of this module to other modules and documentation. Its just one of the core tenants people rely on with Terraform - that Terraform will manage the lifecycle dependencies and not them.\r\n\r\nOutside of that, personally I don't see the benefit in having the data source embedded with the restrictions it provides over having users provide the details. They can use the data source on their end if they like. And this is the area where I say that the module has been designed with in conjunction with the EKS module. I have aligned the inputs of this module with the outputs of that module so its very clear what is expected. That said, it doesn't lock people into using the EKS module; it just shows the relationship since I suspect this will most likely be the most used case. ", "All the context being given here is from the behemoth EKS module, used solely by EKS admins. Where the `iam-eks-role` module was written for regular users who have workloads on EKS who just want a simple IRSA role created.", "Update main README.md in the root of the module to include this new module&example into the lists there also. ", "If it is not critical for the example, can we disable NAT and VPC flow logs in the example to be able to spin up things faster&cheaper?", "@max-rocket-internet `try()` works better than using ternary operators for `destroy`. `try()` works in the same way as `element(concat(...))` but shorter.", "Please add one `module` for a case where `create_role = false` because sometimes there can be some weird things we can't check in the happy path.\r\n\r\nI don't remember the name of the module where this was a problem a few weeks/months ago.", "ah, we actually do need the NAT gateway (or replace it with 3 private VPC endpoints which takes just as long to provision as a NAT gateway)", "done! (and it was Atlantis w/ EFS \ud83d\ude05 )", "Done - also ordered them to match the sub-module/example directory", "> @bryantbiggs the implementation of the policy submodules looks really great so far \ud83d\udc4d\ud83c\udffc Happy to see these modules coming\r\n> \r\n> How do you feel about also adding aws-load-balancer-controller policy ? It's quite common also and by now preferable over the in-tree one\r\n> \r\n> Btw I will also give the policies a 3rd pair of eyes if you don't mind.\r\n\r\n@philicious we'll add some more in a next PR, this one is getting big enough - hang tight", "> done! (and it was Atlantis w/ EFS \ud83d\ude05 )\r\n\r\nso it was so much recently :)"]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/183", "comments": ["@antonbabenko I don't really see the point of adding a whole declaration of the `terraform-aws-eks` module in here? Now it's not really clear that you can use this module completely separately. And now the use of `(random_pet.this.id)` as the cluster name is even more confusing IMO \ud83d\ude42", "\"All examples should ALWAYS be executable right away as-is using `terraform apply`\" - this is the standard rule we have in all modules.\r\n\r\n`cluster1` was not a known cluster name.", "I think I should have written it differently to be more understandable - `(module.eks.cluster_id)` instead of `(random_pet.this.id)`."]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/179", "comments": ["Use relative path to submodule", "And remove version", "Use valid policy here", "Could you also update the code in `example` to have `provider_url_sa_pairs`? ", "Please move all these data sources at the top of `main.tf` like we have in all other modules.", "Add newline after meta-arguments like `count` and `for_each`.", "Add newline here, too.", "And here :)", "```suggestion\r\n  role       = aws_iam_role.this[0].name\r\n```\r\n\r\nAnd update `for_each` to do anything only if `var.create_role` is true.", "Use a newline to separate meta-arguments from the rest. Put a newline after `version`.", "Done!", "Done", "Done", "Done"]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/177", "comments": ["Will it work well if `trusted_role_arns` or `trusted_role_services` is not specified?", "Maybe split this into two separate statement blocks?"]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/176", "comments": ["Something like this is more in spirit of Terraform 0.13+:\r\n```suggestion\r\n  assume_role_policy = coalesce(var.custom_role_trust_policy, try(data.aws_iam_policy_document.assume_role_with_mfa[0].json, data.aws_iam_policy_document.assume_role[0].json))\r\n```", "Also, add `count = var.role_requires_mfa ? 1 : 0` (and opposite) in both data sources.", "Thanks for the quick review, will try to fix it all today", "Done both and fixed doc failed check"]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/174", "comments": ["Add another example of module call with `create_policy = false` and update variables defaults accordingly.", "`distinct(concat(...))` to be safer :)", "Please set `>= 0.12.6` as on all other modules. We will bump to `>= 0.13.1` in all modules in another PR.", "If I remember correctly, 2.23 does not work with Terraform 0.15.\r\n\r\nPlease downgrade the minimum version of Terraform (see comment above).", "```suggestion\r\n# iam-read-only-policy\r\n```", "No resources or data sources should be created if `create_policy = false` is set. Add `count` to everything.", "There is no need to use 0.15 features here.\r\n\r\nAlso, it is rather a bad idea to expose the whole resource with all the properties (same as in programming in most cases). Please change to export attributes individually.", "```suggestion\r\nvariable \"additional_policy_json\" {\r\n```\r\n\r\nThis is how such variable is called in other modules (e.g. Lambda, Step Functions).", "Let's move these from locals to separate variable defaults to allow customizations (if necessary).", "```suggestion\r\n  description = \"Allows List/Get/Describe/View actions for services used when browsing AWS console (e.g. resource-groups, tag, health services)\"\r\n```\r\n\r\nSimilar to the descriptions of other vars.", "Same version requirements here as in the example.", "```suggestion\r\n# IAM read-only policy example\r\n```", "added distinct to the module itself to sanitize input", "thus here it will be unnecessary ", "done", "done", "intention of create_policy is to skip creation of iam policy and only generate json doc thus you need this data in both cases and that is why there is no count", "could argue with that in this particular case but alright will do as you suggested", "done", "done", "if I misunderstood your comment please give me an example of what you mean", "Normally, in other terraform-aws-modules, nothing is being created if `create_* = false` is defined. This way is compatible with situations when users want to control the creation of `all` or `nothing` (e.g. still handy with terragrunt).\r\n\r\nI see what you mean in this example. Let's leave it as you have done already. I think it makes sense here.", "```suggestion\r\n    aws = \">= 2.23\"\r\n```", "```suggestion\r\nConfiguration in this directory creates read-only IAM policy and attaches it to AWS SSO.\r\n```"]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/170", "comments": ["```suggestion\r\n    for_each = var.role_allows_session_tag ? [true] : []\r\n\r\n```", "I don't know if there can be a `condition` block for this action? Please verify AWS docs."]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/165", "comments": ["```suggestion\r\n  value       = element(concat(aws_iam_group.this.*.arn, [\"\"]), 0)\r\n```"]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/163", "comments": ["There are `default` values already specified for all variables in the module, so you can remove everything starting from line 61 ([like here](https://github.com/terraform-aws-modules/terraform-aws-vpc/blob/master/examples/complete-vpc/main.tf#L171-L175)).", "Ok, I've removed \"path\" and \"description\".\r\n\r\nThank you for your time!", "Please remove everything and leave just `source` and `create_policy = false` with empty line in between.", "Done."]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/158", "comments": ["```suggestion\r\nvariable \"oidc_fully_qualified_audiences\" {\r\n```", "```suggestion\r\n          values   = var.oidc_fully_qualified_audiences\r\n```", "```suggestion\r\n        for_each = length(var.oidc_fully_qualified_audiences) > 0 ? local.urls : []\r\n```"]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/155", "comments": ["`pgp_key` is input into a module and I don't think it makes a lot of sense to mark it sensitive here. It makes sense to mark `sensitive = true` only resource attributes (see line 46 in this file).", "hmmm I agree with you, although I am getting `Error: Output refers to sensitive values.` when I am trying to use it. (Terraform 0.14.10 / Terragrunt v0.28.19)", "Nevermind, it seems to be not related to this module itself, but the fact I am creating a new module and using this one as one of the sources...."]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/138", "comments": ["Please update the code to have the same variable name as before but with `type = any` to be able to support (string and list(string) values simultaneously).", "Sure thing @antonbabenko.  I have reverted back to the original variable name."]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/122", "comments": ["It would be great if this list can be autogenerated from the actual code. We already have some conversions, eg code is in the root and in `modules/*`.\r\n\r\nI can't imagine anyone updating these workflow files manually correctly.", "I think we can just include `examples/*` into `pre-commit`, because `terraform validate` is already part of `pre-commit`."]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/110", "comments": ["I don't think you need to replace partition and account id in a loop like this. The values in `provider_ids` and/or `provider_id` will be already correct.", "You're right. I assumed it was needed because of the other implementation. I've removed it."]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/96", "comments": ["`number_of_role_policy_arns`", "`number_of_custom_role_policy_arns`"]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/93", "comments": ["looks good - might be worth considering a refactor to `for_each` with an array of maps. just food for thought", "ill go over he module and see where this refactor is needed. i wanted to make changes more incremental"]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/81", "comments": ["Make sure to use `${data.aws_partition.current.partition}` instead of `aws` as a partition name.", "Ah good catch. Fixed.", "Update `description` for this variable in `variables.tf`.", "`concat` of `list` and `string` types may not work, so wrap string with `[]`", "`List of URLs of the OIDC Providers`"]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/70", "comments": ["Please add another output instead of replacing it.", "Alright, thanks for quick review!", "Done. Updated README as well."]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/50", "comments": ["1. `var.cluster_oidc_url` - where this is defined?\r\n\r\n2. Use Terraform 0.12 short syntax by removing `\"${...}\"` wrapper.", "1) No idea, must have been from copying this from our own module. PR is so old I can't remember. Fixed.\r\n2) Fixed."]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/23", "comments": ["Also, simpler, and there is no need in using `local`:\r\n```\r\ncount = \"${var.create_admin_role ? length(var.poweruser_role_additional_policies_arn) : 0}\"\r\n```", "There is no need in `type = \"string\"`. Once this module is converted to support Terraform 0.12 we may review this and add types, if necessary."]}, {"url": "https://github.com/terraform-aws-modules/terraform-aws-iam/pull/19", "comments": ["Could you please add this file also? We need to make sure that examples are always working with just `terraform apply`.", "Fixed, tested."]}]}, {"url": "https://github.com/srijitha-HPC/HPC_lab.git", "pull_requests": []}, {"url": "https://github.com/chaspy/terraform-alibaba-isucon8.git", "pull_requests": []}, {"url": "https://github.com/Cinegy/terraform-cinegy-modules.git", "pull_requests": []}, {"url": "https://github.com/SUSE/caps-automation.git", "pull_requests": [{"url": "https://github.com/SUSE/caps-automation/pull/87", "comments": ["Why do you have to use internal images?", "Because `redis-operator` is installed from the Devel repository which is not published outside.", "Why can't we use the public one? We didn't publish it yet?", "Its just that we want to catch issues as early as possible and Devel is the earlier we can go. If we choose to use the published images we risk finding issues only after releasing.", "OK, good point"]}, {"url": "https://github.com/SUSE/caps-automation/pull/84", "comments": ["So why don't you install ingress into `nginx-ingress` namespace? (sorry I did not check other parts of the code..)\r\n\r\nWhat about `kubectl get svc --all-namespaces -l app=nginx-ingress -l component=controller -o jsonpath=\"{.items[].status.loadBalancer.ingress[].ip}\"` ?\r\n\r\n", "Hm, I would rather go with `--no-headers` so you don't have to create a header that you'll be ignoring with grep, just for clarity, the result is the same of course...", "How is this change related to deleting namespaces?", "> So why don't you install ingress into `nginx-ingress` namespace? (sorry I did not check other parts of the code..)\r\n\r\nTo install additional services on the cluster I am using the same logic as in the aks/eks workflwos where it uses the upstream nginx-ingress. However for CaaSP we use th suse nginx-ingress in that case I need a different name to differentiate it, that's why I install it on the nginx-ingress-suse namespace.\r\n\r\n> What about `kubectl get svc --all-namespaces -l app=nginx-ingress -l component=controller -o jsonpath=\"{.items[].status.loadBalancer.ingress[].ip}\"` ?\r\n\r\nWell, I believe there are several ways to achieve the same result, is there any advantage on the one you mentioned?\r\n", "I was not aware of the `--no-headers` I will make that change, thanks!", "ops, this is something I was testing. Its just to set the kubeconfig on the node running the job. I can create another commit for it.", "Not really, I just like to achieve the result with `kubectl` alone, without the need to grep/awk the results"]}, {"url": "https://github.com/SUSE/caps-automation/pull/81", "comments": ["this is no longer needed?", "this is needed until the tests supports running with a password different than the default `Harbor12345`.", "I see"]}, {"url": "https://github.com/SUSE/caps-automation/pull/78", "comments": ["azure? Some string replacement is still needed...", "I assume the config is not called `azurek8s`", "yes, I pushed to the wrong origin", "fixed"]}, {"url": "https://github.com/SUSE/caps-automation/pull/73", "comments": ["So ... this is what came naturaly, but didn't this location have problems with Redis Cache creation?", "Why are you not using the 'offical' deployment command?\r\nhttps://kubernetes.github.io/ingress-nginx/deploy/#azure", "Any chance you can also add `schema_migrations` table to `registry` database?", "Its not really a problem of the location.\r\nCreating an azure cache deployment does take a considerable amount of time and according to [this feedback post](https://feedback.azure.com/forums/169382-cache/suggestions/7049852-work-on-creation-time-of-redis-cache) the mains reason is:\r\n`\"Azure Cache currently runs on Windows VM's and the creation time is largely determined by how fast the underlying VM's become available on-demand.\"`", "The azure documentation does the ingress deployment using helm, see: https://docs.microsoft.com/en-us/azure/aks/ingress-basic", "So, besides the database we also need to create this table? According to the Harbor documentation:\r\n`Harbor will create tables automatically when starting up.`", "Most of the tables, but not this one I assume. Or why else is it created in the initial set of SQL commands (that are executed by init container for the internal database case)? \r\n\r\nhttps://github.com/goharbor/harbor/blob/master/make/photon/db/initial-registry.sql#L4\r\n", "I believe that unless this is documented we should not add this or we might end up with CI environments different than what customers do."]}, {"url": "https://github.com/SUSE/caps-automation/pull/57", "comments": ["For master, we're switching to `harbor` prefix...", "Ugh, right, thanks for reminding me :+1: "]}, {"url": "https://github.com/SUSE/caps-automation/pull/54", "comments": ["```suggestion\r\n          cat << EOF | tee ${NAMESPACE}.yaml\r\n          suse:\r\n            AcceptBetaEULA: \"yes\"\r\n          expose:\r\n```", "```suggestion\r\n        run: |\r\n          chart=\"./harbor\"\r\n          rm -rf ${chart}\r\n          helm chart pull ${{ matrix.install_src }}/charts/registry/harbor:latest\r\n          helm chart export ${{ matrix.install_src }}/charts/registry/harbor:latest\r\n          # replace images repository according to source\r\n```", "```suggestion\r\n        run: |\r\n          chart=\"./harbor\"\r\n          rm -rf ${chart}\r\n          helm chart pull ${{ matrix.upgrade_src }}/charts/registry/harbor:latest\r\n          helm chart export ${{ matrix.upgrade_src }}/charts/registry/harbor:latest\r\n          # replace images repository according to source\r\n```", "```suggestion\r\n              echo \"::set-env name=NAMESPACE::spr21-sched-${{ matrix.source }}\"\r\n```", "This is required to remove the chart pulled by the previous run", "same here"]}, {"url": "https://github.com/SUSE/caps-automation/pull/47", "comments": ["I think the error message without the newlines looks much better even comparing to using `fail`", "I don't think this line is necessary.", "removed", "ok, removed newlines again"]}, {"url": "https://github.com/SUSE/caps-automation/pull/44", "comments": ["I think the name of the image is `harbor-notary-server`", "and here should be `harbor-notary-signer`?", "good point"]}, {"url": "https://github.com/SUSE/caps-automation/pull/43", "comments": ["Just a note: the use of `latest` is ok for now, but soon we'll have `latest` associated with 2.1, so we'll need to change this to something like `1.4.2`", "Nevermind, I realized you submitted this to master, which will always track the latest minor release (currently 2.0). When we release 2.1, we'll just backport the workflows to the 2.0 branch and use a different tag there."]}, {"url": "https://github.com/SUSE/caps-automation/pull/41", "comments": ["There's a typo: `rregistry` ", "fixed, thank you!"]}, {"url": "https://github.com/SUSE/caps-automation/pull/29", "comments": ["You should keep the `rev1` bit.", "Same here: keep the `rev1` bit.", "done", "done"]}, {"url": "https://github.com/SUSE/caps-automation/pull/17", "comments": ["BTW, if you try to push this upstream, you'll have to rename `whitelist` and `blacklist` to something like `allowlist` and `denylist` or `includelist` and `excludelist`", "We should probably do the same we did with other images and refer the harbor version instead.", "good point, I have changed it to `include` and `exclude`which are the same parameters used by robotframework.", "done."]}, {"url": "https://github.com/SUSE/caps-automation/pull/5", "comments": ["There's an extra space here."]}, {"url": "https://github.com/SUSE/caps-automation/pull/1", "comments": ["I would use `sp2` as a tag here, to align with the base images used by other components", "Hm, isn't the latest tag ensuring that it indeed is SP2 image and not SLE15GA?", "registry.suse.com/suse/sle15:latest is actually SP1. I do not know if there's an image with SP2..."]}]}, {"url": "https://github.com/pivotal-cf/terraforming-aws-ops-manager.git", "pull_requests": []}, {"url": "https://github.com/akshay3030/dockerized-jenkins-master.git", "pull_requests": []}, {"url": "https://github.com/intetunder-temp/terraform-gcp-trial.git", "pull_requests": []}, {"url": "https://github.com/JamesWoolfenden/terraform-aws-codeartifact.git", "pull_requests": []}, {"url": "https://github.com/00inboxtest/cloud-foundation-fabric.git", "pull_requests": []}, {"url": "https://github.com/laurijssen/tform_azure.git", "pull_requests": []}, {"url": "https://github.com/vtog/aws-container-lab.git", "pull_requests": []}, {"url": "https://github.com/dotmesh-io/dotscience-tf.git", "pull_requests": [{"url": "https://github.com/dotmesh-io/dotscience-tf/pull/67", "comments": ["This line gets longer and longer - I feel splitting it into single `--foo VALUE \\` entries per line is needed!"]}, {"url": "https://github.com/dotmesh-io/dotscience-tf/pull/13", "comments": ["How does this get uploaded? and is it versioned?", "currently here https://github.com/dotmesh-io/dotscience-images/pull/71/files but once it's merged, I will add another step to generate tagged binaries", "so the plan is to have three binaries uploaded:\r\n1. unstable on each commit to master\r\n2. 1.5.0 - tagged ones (so you can pin to a specific version if you want to)\r\n3. stable - latest tagged one (generated on each tag) ", "Sounds good. Majority of our changes to the ami is actually the startup script. Decoupling that and pushing that to S3, google storage means the images will only change when we need to update the version of local-stack/env. file changes. Maybe even that can be extracted out!", "so maybe we can move startup.go to a separate repo? ", "Yeah, why not? We would need to update both the tf environments to use it."]}]}, {"url": "https://github.com/AwakeningSV/live-infrastructure.git", "pull_requests": []}, {"url": "https://github.com/hryze/kakeibo-app-terraform.git", "pull_requests": []}, {"url": "https://github.com/cloud-native-toolkit/terraform-ibm-container-platform.git", "pull_requests": []}, {"url": "https://github.com/testorganizationyay/tf-inf-code.git", "pull_requests": []}, {"url": "https://github.com/my-gcp-org/terraform-google-iam.git", "pull_requests": []}, {"url": "https://github.com/hallatech/terraform.git", "pull_requests": []}, {"url": "https://github.com/alphagov/govuk-terraform-provisioning.git", "pull_requests": [{"url": "https://github.com/alphagov/govuk-terraform-provisioning/pull/138", "comments": ["What's the reason behind this change?"]}, {"url": "https://github.com/alphagov/govuk-terraform-provisioning/pull/137", "comments": ["My bad - I think this should be `${var.lambda_artefact_name}`"]}, {"url": "https://github.com/alphagov/govuk-terraform-provisioning/pull/136", "comments": ["var.lambda_artefact_name \ud83d\udc4d ", "This bucket has already been created elsewhere, so suspect this will conflict. We may have to just hardcode the `id` when we reference it?"]}, {"url": "https://github.com/alphagov/govuk-terraform-provisioning/pull/126", "comments": ["Seems like an incorrect description"]}, {"url": "https://github.com/alphagov/govuk-terraform-provisioning/pull/125", "comments": ["Make sure we don't merge this in!"]}, {"url": "https://github.com/alphagov/govuk-terraform-provisioning/pull/117", "comments": ["This was changed to include files other than .tf so that we can pull pingdom IPs (#115)", "Is there a reason you're not using a [policy doc](terraform.io/docs/providers/aws/d/iam_policy_document.html) for this? ", "Are the `username_base` and `team` variables ever going to be set to anything but these defaults? Why is username_base separate from `bucket_name`?"]}, {"url": "https://github.com/alphagov/govuk-terraform-provisioning/pull/108", "comments": ["I think this should be done using a [policy document](https://www.terraform.io/docs/providers/aws/d/iam_policy_document.html) rather than a single long string. Otherwise this looks good.", "There is already a policy defined with a template and another one with a string, I'm trying to be consistent with what already have in place", "Fair enough, I'm happy then", "Thanks @SamLR , we can have a chat about this later during planning and review if we want docs for everything"]}, {"url": "https://github.com/alphagov/govuk-terraform-provisioning/pull/99", "comments": ["I think this can replace the line above entirely ", "Having both is a requirement of the aws cli tool"]}, {"url": "https://github.com/alphagov/govuk-terraform-provisioning/pull/97", "comments": ["Technically yes but for clarity, I think it should read something like `Please set the \"TF_VAR_account_id\" environment variable to the name of the aws account i.e. \"govuk-infrastructure-integration\".`  Nice one addressing the enigmatic warning message though.\r\n\r\n"]}, {"url": "https://github.com/alphagov/govuk-terraform-provisioning/pull/94", "comments": ["is this meant to be commented out?", "I had meant to remove that, sorry!"]}, {"url": "https://github.com/alphagov/govuk-terraform-provisioning/pull/86", "comments": ["Is it worth having this in a variable if it's always true?", "It'd be good to standardise on just one of `bucket_name` or `bucketname`."]}, {"url": "https://github.com/alphagov/govuk-terraform-provisioning/pull/85", "comments": ["Having an `owner` tag would be nice so we know which team to talk to about this in the future.", "Done."]}, {"url": "https://github.com/alphagov/govuk-terraform-provisioning/pull/65", "comments": ["typo\n", "and actually, the module here (and above) should be the name of the module rather than the bucket\n", "@surminus What would you suggest for the module names? As they cannot be called the same thing.\n", "Actually, maybe I was having a moment. Does it even matter? If it doesn't then please just ignore me! \n", "No worries.  Could you review and deploy please??\n"]}, {"url": "https://github.com/alphagov/govuk-terraform-provisioning/pull/55", "comments": ["specifically say \"read-only\" rather than RO\n"]}, {"url": "https://github.com/alphagov/govuk-terraform-provisioning/pull/47", "comments": ["`dir` here is `resources` or `resources/<env>` so this is working with an expected structure where the `templates` and `files` are inside `resources` rather than in `<project>`. Is that correct as it doesn't match up with @surminus's comment on https://github.com/alphagov/govuk-terraform-provisioning/pull/46?\n", "This works for a directory structure as per @surminus's #46 comment if we also pass the project directory into the loop at line line 163\n", "Sorry, seem to have left this go stale. I believe this approach is correct and the one I stated [here](https://github.com/alphagov/govuk-terraform-provisioning/pull/46#issuecomment-213479977) is incorrect as we might want to have different files or templates with a different environment, which this loop takes account of. \n"]}, {"url": "https://github.com/alphagov/govuk-terraform-provisioning/pull/46", "comments": ["This isn't required because [it is supplied as part of common variables](https://github.com/alphagov/govuk-terraform-provisioning/blob/master/configs/common_variables.tf)\n", "Could give this a proper ID I think?\n", "Fixed in ca7c3c1. Seems that using a `uuid` is the way to go although I haven't used an `ID` at all in the other policies. I'm not sure if there's any benefit to using them. As it happens this policy confuses `terraform apply` into thinking it has changed every time it is run which I hoped the change you suggested might fix but didn't unfortunately. I think it's line 27 not being specific enough but haven't been able to work out a more 'fully qualified' version that works.\n", "FYI: `source_code_hash` expects a hash of the ZIP file, so you'll keep getting unnecessary diffs in `plan` with the current approach as the hash will never match with what the API returns.\n", "`0.6.15` was released just a few hours ago \ud83d\ude09 \nhttps://www.terraform.io/downloads.html\n", "Thanks for your comment. I was using the zip file path originally but in an effort to try and avoid having zipped files in the repo I've moved its creation into a `null_resource`. As a result the `base64sha256` function raises a `no such file` error if I use the zip file. Is there a better way that I can trigger this resource to be updated when the .py source changes?\n", "> Is there a better way that I can trigger this resource to be updated when the .py source changes?\n\nBefore Terraform gets to `plan/apply` stage, it (by default) performs `refresh` (effectively `Read` from CRUD for each resource in all `*.tf` files) so it can figure out what may have changed and how does it affect `plan/apply`. After refresh is done for all resources, it performs `plan/apply`.\n\n> As a result the base64sha256 function raises a no such file error if I use the zip file.\n\nThe `base64sha256()` function is executed at the time of `refresh` since it has static value (static path to zip file) hence Terraform won't mark it as \"computed\". All provisioners are always executed at the time of `apply`, not during `refresh`. That's why you're hitting this.\n\nTo mark it as \"computed\" you would probably need to have a 1st class support for \"zipping\" in terraform which would be returning the shasum that you would reference in `aws_lambda_function. source_code_hash`. There are some (good) reasons why Terraform doesn't support this (yet):\nhttps://github.com/hashicorp/terraform/pull/3858\n\nThe only way to get around this would be possibly executing terraform twice (+ removing any unnecessary `triggers` & `depends_on`):\n\n```\nterraform apply -target=null_resource.build_rename_email_files_with_request_id\nterraform plan/apply\n```\n\nthat way terraform won't perform any validation/checks on any resources except the targeted one.\nObviously the `null_resource`'s provisioner would be executed twice (in the second run too), but Terraform would at least get a chance to prepare the right `plan` and `apply` it correctly.\n\nAlso keep in mind that any `local-exec` provisioner makes your Terraform files platform-specific - i.e. the requirement suddenly isn't just terraform binary, but also platform-specific `zip` utility having the same interface (e.g. supporting `-j` flag). This is also why I think that building ZIP files via CI is a better solution.\n", "This isn't required because it's set by default.\n", "If I'm reading [this correctly](https://github.com/hashicorp/terraform/pull/5370) it suggests this isn't a required setting, and it would make life much easier to pull the latest by default. Makes life more difficult if we wish to deploy a specific version, though.\n", "Unfortunately that's not how this optional field works.\nThe only reason it's optional is because some people prefer to use `s3_key` for something like `rename_email_files_with_request_id-version0.2.3.zip` - i.e. leverage the object key for versioning.\n\nSomething still has to trigger the update (and generate the diff) and Lambda API won't talk to S3 directly and ask for new versions neither will Terraform (out of the box).\n\nYou would either need to [`taint`](https://www.terraform.io/docs/commands/taint.html) the `aws_lambda_function` which would recreate it from scratch and (yes) pull down the latest version from S3 or use `s3_object_version` and keep bumping the version per each release.\n\nOr wait for the nearest Terraform release which will contain [data sources](https://github.com/hashicorp/terraform/issues/4169) + someone who will implement S3 object data source - I actually started working on it...\nhttps://github.com/hashicorp/terraform/compare/master...TimeIncOSS:f-aws-s3-object-data-source\n", "Ah OK, I see. Thanks for clarifying! The original plan was to grab the `VersionId` using another tool and set it as an environment variable and I was just looking to cut a corner. \n", "Does this need to go in the `Gemfile`?\n", "Instead of iterating over all of the `bucket.object_versions` (which might grow quite quickly) I think calling `bucket.object(lambda_filename).version_id` will return the latest version. It might also be worth guarding against the case where that value is `\"null\"` (which I think is what happens when versioning isn't enabled).\n", "Nitpick: this could use a bit of identation.\n", "Perfect!\n", "The dependency is pulled in by `awspec` so I don't _think_ it also needs to be included in the Gemfile.\n", "Yep sorry, you're right!\n"]}, {"url": "https://github.com/alphagov/govuk-terraform-provisioning/pull/36", "comments": ["Since we have multiple VPCs and are not creating a new one here, will this return the default VPC?\n", "The VPC is created in https://github.com/alphagov/govuk-terraform-provisioning/pull/36/files#diff-bceb2970582adbc31fcc9e7dbb79d1a6R2 so it should use a distinct one.\n", "I see it now. I was expecting the file to be called vpc.tf instead of networking.tf\n"]}, {"url": "https://github.com/alphagov/govuk-terraform-provisioning/pull/35", "comments": ["Can we avoid hard-cording these values?\n", "Can these `Sid` be made more descriptive? For example, I think many of these actions are not read-only. It'd be good if the Sid could help us to distinguish between the groups of actions there are here.\n"]}, {"url": "https://github.com/alphagov/govuk-terraform-provisioning/pull/29", "comments": ["Should we keep the `govuk` prefix for consistency, since bucket names must be globally unique?\n", "We probably should, yes :+1:\n"]}, {"url": "https://github.com/alphagov/govuk-terraform-provisioning/pull/15", "comments": ["@deanwilson Is there any way to lock this down further so that this user can't terminate Production VMs?\n", "The ami creation requires the ability to stop and start instances so that permission can't be removed.\n\nAre you worried about it stopping instances in each environment or only production?\n", "I know we can't remove the permission but I was wondering if can restrict that permission to some kind of logical zone in AWS that would mean it wouldn't have permissions to do any damage to running VMs that are serving user traffic in Production. I don't know enough about AWS so know if such a thing exists - maybe a VPC?\n", "I think you can lock this down to a particular VPC, if Packer has it's own.\n"]}, {"url": "https://github.com/alphagov/govuk-terraform-provisioning/pull/13", "comments": ["Should we rename the module if it's so terrible? :-) Maybe `S3BucketTwoUsers`?\n", "I'm happy to rename it, but we'll only be renaming it once to avoid bikesheding. If this is the name the team wants I can make the change.\n", "How about `ReadUserWriteUserBucket`? or... `RuWuBucket` :neutral_face: \n\nAlternatively we don't worry about it and just make sure people read the description\n", "I think it'd be good to at least mention 'S3' or 'bucket'.\n", "We commonly use `FIXME` rather than `todo` for this kind of note - it'd be good to be consistent so that it's easy to search.\n"]}, {"url": "https://github.com/alphagov/govuk-terraform-provisioning/pull/12", "comments": ["Do we want to change the bucket name based on the project? My understanding was that we'd change the name of the statefile from `terraform.tfstate` to (for example) `terraform-#{project_name}.tfstate` and still just have one bucket per environment.\n", "I'm not majorly sold on either way. Having different buckets per project means we can let certain people run certain projects without going through us. Once we move to jenkins this might be a null point. We can do either.\n", "I don't feel too strongly about it, but given that bucket names are globally unique creating lots of them to only contain one file feels like the incorrect thing to do? Happy to be told otherwise though!\n\nThough actually that might be a valid point, I think setting up new buckets programmatically to contain statefiles is difficult right now.\n"]}, {"url": "https://github.com/alphagov/govuk-terraform-provisioning/pull/9", "comments": ["Should we use [govuk-lint](https://github.com/alphagov/govuk-lint) instead? It includes Rubocop.\n", "We'll stick with base rubocop to avoid the SASS linters and their deps. If we add another language then it's probably worth migrating over.\n"]}, {"url": "https://github.com/alphagov/govuk-terraform-provisioning/pull/5", "comments": ["I wonder if we should sanitise the environment, i.e. check that it matches an expected value.\n", "Definitely\n", "Do we need to create one of these files for each of the new environments?\n", "Is this something you plan to add as part of this PR?\n", "Might also need one for 'test'?\n", "Just spotted the `test` file :+1:\n", "Sorry @mattbostock, yes, though an idea on how to actually do in the Makefile would be appreciated. Not sure if you can do it with `ifeq` or `ifneq`, or just break it out into `bash` or something? \n", "We can tackle this separate to this PR I think.\n", "Why do we need to remove the directory?\n", "I understood that it might have statefiles in there, that could a problem with the first run? It's what happens in the Makefile, so I was copying the behaviour to ensure that when we manually do stuff nothing unexpected happens.\n", "Removal of `.terraform/terraform.tfstate` and `.terraform.tfstate` is a :hammer: to crack a nut with regards to state caches and Terraform's behaviour when remote state is configured.\n\nBe aware that the Pay wrapper around Terraform is hardly the most finely engineered approach, we're just familiar with its shortcomings :)\n\nWe've been bitten by the following situations:\n\nWhen first enabling remote state following a Terraform run:\n- `terraform.tfstate` (the default local state file name) exists following a Terraform run when no remote state is configured\n- Remote state is enabled (either manually, or due to a Makefile task being executed)\n- Terraform creates/fetches the remote state file and _merges_ with the state in `terraform.tfstate`, the result is stored in `.terraform/terraform.tfstate` and pushed to the remote state location.\n- You run Terraform and wonder why you've just destroyed the wrong environment\n\nThis is defended against by https://github.com/alphagov/pay-infra/commit/fc1b0c2a14ce47316a1a3f5240b62f1e2ea2bc24\n\nThe other situation is where remote state is configured and we change the environment we wish to act upon (we have separate state files for each environment, stored in the same S3 bucket, with a key name equal to the environment name):\n- Following the last Terraform run, Terraform caches the currently configured remote state file in `.terraform/terraform.tfstate`\n- If you reconfigure the remote state (again, either manually or via a Makefile task), then Terraform creates/fetches the newly configured remote state file, _merges_ with what's in `.terraform/terraform.tfstate`\n- You, once again, enjoy watching the wrong thing be destroyed.\n\nThat's defended against by https://github.com/alphagov/pay-infra/commit/feb2eba538b3f22bf0950d741d4b912fcf4cf6ed\n\nThese two checks seem to Work For Us\u2122, but I'm sceptical that any of this is really the \"right\" approach. Hopefully the above gives a little more context for what's going on.\n", "Oh, and if you proceed down the route of using modules, they are pulled into `.terraform/` so blowing away the entire directory may be excessive and cause modules to have to be re-fetched. \n"]}, {"url": "https://github.com/alphagov/govuk-terraform-provisioning/pull/3", "comments": ["You can make some \"loops\" here to drop some duplicated code:\nhttps://github.com/alphagov/pay-infra/blob/master/provisioning/aws/logging.tf#L149-L156\nhttps://github.com/alphagov/pay-infra/blob/master/provisioning/globals.tf#L137-L140\n"]}, {"url": "https://github.com/alphagov/govuk-terraform-provisioning/pull/1", "comments": ["Could we pass these in as environment variables, e.g. https://www.terraform.io/docs/configuration/variables.html? It would avoid storing credentials to disk.\n", "You can reduce this to \n\n```\nprovider \"aws\" {\n  region = \"eu-west-1\"\n}\n```\n\nand lose all other references to `var.aws_*_key`s and it'll Just Work.\n", "We definitely can, but we should have a conversation about this. I find it significantly more complicated to set up environment variables each time I want to work on a project rather than store a file on disk, and as we mandate full disk encryption I wonder how large the risk of storing them in a file is.\n", "The risk is accidentally committing the file (I know it's `.gitignore`d, but still)\n", "Not suggesting you do the same as us, but FYI this was our thinking on managing users and group assignment:\n\n> I'm thinking that we'll just manage groups and policies, but not users or their assignment to groups. I don't want anyone to assume that it is the canonical list of users and that removing someone from the config means that they definitely do not have an account - because we won't be running Terraform automatically and it has no way to \"purge\" all unmanaged accounts.\n", "You may be surprised to find that `terraform plan` updates the state file. This is expected, just a little unusual on first encounter - it's not a completely side-effect free \"dry-run\".\n\nhttps://www.terraform.io/docs/commands/plan.html and https://github.com/hashicorp/terraform/issues/3631 for explanation.\n", "Makes sense. We were manually retrieving credentials via the UI anyway (there may be a better way to do this).\n", "I've removed the users in 75017d4 having discussed it with @alexmuller.\n", "Thanks @bazbremner, I've updated the title.\n", "I'd like to manage the users via terraform so we have them both in code and version control. We can initially add a comment in the file saying to delete the users in AWS on removal from the codebase and then later add our own equivalent to puppet resource purging.\n\nWhile the resource not being an absolute source of truth is an issue i think having the users created manually is also the wrong path.\n", "We tested because we weren't sure: adding a user with Terraform and then removing the resource does delete the account, but there's still the case where users can be added using the interface (they won't be deleted).\n", "@tijmenb has pointed out that it would be useful if the bucket was publicly listable. Is there a reason to not do that?\n", "That's a good point and as it's public data we should do it to make usage easier.\n", "We have permission to make it public readable.\n"]}]}, {"url": "https://github.com/StatCan/terraform-statcan-aaw-platform.git", "pull_requests": []}, {"url": "https://github.com/dvsa/motr-terraform.git", "pull_requests": [{"url": "https://github.com/dvsa/motr-terraform/pull/78", "comments": ["drop '_log_metric_filter', it's your resource type, there's no need to repeat that in the name", "same here", "Done.", "Done."]}, {"url": "https://github.com/dvsa/motr-terraform/pull/70", "comments": ["Name should be motr-sms-receiver-env-key or similar.", "Done.", "do you really need this?", "it think it's time to create a separate .tf file for the new apig and rename the existing one", "terraform fmt", "do you really need that proxy path? can't you achieve everything with the root resource so that you will pass a simple URL without the URI part?", "what are GET/POST methods for? you need both?", "don't you want to parametrize throttling settings so that you can easily adjust them when needed?", "what's this api key for? don't you secure this service differently?", "depends on the key you probably don't need", "terraform fmt", "rename the file to apigateway_sms_receiver.tf", "revert all those comment changes in this file as you created a separate one ", "move this resource to the new apigateway file for now, it's not a provider, we will move it later to a dedicated file for data sources", "recEIver typo!", "recEIver typo!", "recEIver typo!", "recEIver typo!", "recEIver typo!", "recEIver typo!", "Yes :) going to change this now to be root resource only", "can we reuse somehow the public_dns_domain for this? see cloudfront.tf", "SMSReceiver for the resource name is more than enough", "SMSReceiver for the resource name is more than enough", "SMSReceiver for the resource name is more than enough", "final decision to not have these settings parametrized?", "Will change :)", "terraform fmt", "I think for now we can leave them un parametrized.  Potential future enhancement if we find we need to regularly change it", "I'd change it to sms_receiver_alias_record to keep it consistent with other variables", "ok", "Sure will change now :)"]}, {"url": "https://github.com/dvsa/motr-terraform/pull/68", "comments": ["Shouldn't the be parameter be \"dvlaVehicleId\"? \"number\" is the path param for getVehicleByMotTestNumber endpoint."]}, {"url": "https://github.com/dvsa/motr-terraform/pull/61", "comments": ["Split a line after the } and before ##'s and give it a name such as the pinger above", "The role needs changed", "And name", "what are these defaults doing here? it's a module and it shouldn't have any defaults, please refer to other variables for other lambdas and see how it looks there", "description - see other similar variables", "description - see other similar variables"]}, {"url": "https://github.com/dvsa/motr-terraform/pull/58", "comments": ["We shouldn't require both endpoints anymore", "Also, the WebHandler should not need to know about the MOT Test Number endpoint, you might have missed this"]}, {"url": "https://github.com/dvsa/motr-terraform/pull/57", "comments": ["it has to go"]}, {"url": "https://github.com/dvsa/motr-terraform/pull/56", "comments": ["cancelled write and read capacity :)"]}, {"url": "https://github.com/dvsa/motr-terraform/pull/44", "comments": ["we already have a universal policy for that", "we already have data \"template_file\" \"lambda_assumerole_policy\"", "don't we need resource \"aws_cloudwatch_log_group\" for that?"]}, {"url": "https://github.com/dvsa/motr-terraform/pull/42", "comments": ["Should these variables match the naming of MOT_TEST_REMINDER? :)", "The ones that are seen by the lambda will match the naming :) These are just mapped to the MOTR repo, and match the timeout naming of the notifier - but for consistency I am happy to update.", "why do we have different variables names on both sides: Lambda Env vars vs Terraform vars?", "I've updated it now anyway :)"]}, {"url": "https://github.com/dvsa/motr-terraform/pull/30", "comments": ["indentation", "... is good?"]}, {"url": "https://github.com/dvsa/motr-terraform/pull/22", "comments": ["why not ${var.post_purge_delay_loader} to be consistent with other env vars, ex. ${var.inflight_batches_loader} ?"]}, {"url": "https://github.com/dvsa/motr-terraform/pull/21", "comments": ["it would be also good to change terraform variable to reflect lambda env variable, so var.mot_test_reminder_info_endpoint could be var.mot_test_reminder_info_api_uri", "Should now be updated :)"]}, {"url": "https://github.com/dvsa/motr-terraform/pull/13", "comments": ["commas in front? git ninja style"]}, {"url": "https://github.com/dvsa/motr-terraform/pull/10", "comments": ["kms:Decrypt should be the only permission we need here", "Root does not have it anyway ?", "no defaults in the module, only on the component side", "no capital letters in the name attrib, just to be consistent across all our code", "no need for _ and - in the description - just to be consistent across our code and your code :P", "indent 2 spaces not 4 :)"]}, {"url": "https://github.com/dvsa/motr-terraform/pull/9", "comments": ["please, be more descriptive like cf-apig-channel-key", "waf", "cant var.with_cloudfront be just true or false without ternary op ?", "it can but it is more visible what value will be assigned and not what value is hidden behind the with_cloudfront variable"]}, {"url": "https://github.com/dvsa/motr-terraform/pull/5", "comments": ["should be var.variable_name\r\nPlease ask Przemek but maybe we should have some more consistency in how we name those variables.\r\nSo for example if we have GOV_NOTIFY_API_TOKEN we should also have  GOV_NOTIFY_SUBSCRIPTON_TEMPLATE_ID or let's just drop the GOV_ prefix.\r\nI would then also give the same name to the terraform variables but still keeping them in small letters.\r\nThis should be then reflected on the webops/motr side."]}]}, {"url": "https://github.com/duckalini/my_first_terraform.git", "pull_requests": [{"url": "https://github.com/duckalini/my_first_terraform/pull/2", "comments": ["Prob link to documentation on IAM here.", "Do we want the resource name properties to match?", "Thoughts for future: do we want to explain why it's good to separate out dev & admin users and what the distinction is? Is explaining RBAC outside our mandate?", "I think I like using full names - lets prioritise clarity over brevity ", "Same as before - clarity over brevity?", "I think that's good content for a talk on this... struggling to decide how much detail is useful for a codebase... ", "probably, yes"]}, {"url": "https://github.com/duckalini/my_first_terraform/pull/1", "comments": ["Not sure about the brew advice - I recall the version being super out of date? May need to suggest specifying the latest version when using brew", "This should probably be where tf.state is first mentioned", "missing a word `if you don't any modules or resources`", "Let's be more specific about what we mean than IC - maybe \"everyone who uses terraform for the same project\"?", "Maybe we should split out a pre-reqs section?", "\"your\" not \"you\""]}]}, {"url": "https://github.com/JamesWoolfenden/terraform-aws-glue-crawler.git", "pull_requests": []}, {"url": "https://github.com/lirshindalman/terragoat1.git", "pull_requests": []}, {"url": "https://github.com/GBergeret/micro-service-as-code.git", "pull_requests": []}, {"url": "https://github.com/femnad/geheim.git", "pull_requests": []}, {"url": "https://github.com/andreas-prinz/gcp-terraform-google-lb.git", "pull_requests": []}, {"url": "https://github.com/upalepu/iac.git", "pull_requests": []}, {"url": "https://github.com/vishalbhogate/terraform-aws-billing-role-default.git", "pull_requests": []}, {"url": "https://github.com/aaaaasam/azure.git", "pull_requests": []}, {"url": "https://github.com/rails-on-services/terraform-data-metabase.git", "pull_requests": []}, {"url": "https://github.com/pbaskar85/pbaskar85.git", "pull_requests": []}, {"url": "https://github.com/Hapag-Lloyd/terraform-aws-bastion-host-ssm.git", "pull_requests": [{"url": "https://github.com/Hapag-Lloyd/terraform-aws-bastion-host-ssm/pull/148", "comments": ["## Lambda functions should have X-Ray tracing enabled\n\nFunction does not have tracing enabled.\n\n[Show more details](https://github.com/Hapag-Lloyd/terraform-aws-bastion-host-ssm/security/code-scanning/8)", "## IAM policy should avoid use of wildcards and instead apply the principle of least privilege\n\nIAM policy document uses sensitive action 'ec2:StopInstances' on wildcarded resource '*'\n\n[Show more details](https://github.com/Hapag-Lloyd/terraform-aws-bastion-host-ssm/security/code-scanning/9)", "## IAM policy should avoid use of wildcards and instead apply the principle of least privilege\n\nIAM policy document uses sensitive action 'ec2:StopInstances' on wildcarded resource '*'\n\n[Show more details](https://github.com/Hapag-Lloyd/terraform-aws-bastion-host-ssm/security/code-scanning/10)", "fixed", "fixed", "fixed", "## IAM policy should avoid use of wildcards and instead apply the principle of least privilege\n\nIAM policy document uses sensitive action 'ec2:StopInstances' on wildcarded resource '*'\n\n[Show more details](https://github.com/Hapag-Lloyd/terraform-aws-bastion-host-ssm/security/code-scanning/11)", "## IAM policy should avoid use of wildcards and instead apply the principle of least privilege\n\nIAM policy document uses sensitive action 'ec2:StopInstances' on wildcarded resource '*'\n\n[Show more details](https://github.com/Hapag-Lloyd/terraform-aws-bastion-host-ssm/security/code-scanning/12)", "## IAM policy should avoid use of wildcards and instead apply the principle of least privilege\n\nIAM policy document uses sensitive action 'ec2:StopInstances' on wildcarded resource '*'\n\n[Show more details](https://github.com/Hapag-Lloyd/terraform-aws-bastion-host-ssm/security/code-scanning/15)", "## IAM policy should avoid use of wildcards and instead apply the principle of least privilege\n\nIAM policy document uses sensitive action 'ec2:StopInstances' on wildcarded resource '*'\n\n[Show more details](https://github.com/Hapag-Lloyd/terraform-aws-bastion-host-ssm/security/code-scanning/16)", "## IAM policy should avoid use of wildcards and instead apply the principle of least privilege\n\nIAM policy document uses sensitive action 'ec2:StopInstances' on wildcarded resource '*'\n\n[Show more details](https://github.com/Hapag-Lloyd/terraform-aws-bastion-host-ssm/security/code-scanning/17)", "## CloudWatch log groups should be encrypted using CMK\n\nLog group is not encrypted.\n\n[Show more details](https://github.com/Hapag-Lloyd/terraform-aws-bastion-host-ssm/security/code-scanning/13)", "## CloudWatch log groups should be encrypted using CMK\n\nLog group is not encrypted.\n\n[Show more details](https://github.com/Hapag-Lloyd/terraform-aws-bastion-host-ssm/security/code-scanning/14)"]}]}, {"url": "https://github.com/cts-terraform-modules/terraform-google-log-export.git", "pull_requests": []}, {"url": "https://github.com/fitzroyacademy/infrastructure.git", "pull_requests": []}, {"url": "https://github.com/companieshouse/ewf-terraform.git", "pull_requests": [{"url": "https://github.com/companieshouse/ewf-terraform/pull/120", "comments": ["I know it's currently 1 line without any var, so not a proper template, but the idea here is that keeping the same pattern with bep already at this stage might keep life easier for any future requirement. ", "same as https://github.com/companieshouse/ewf-terraform/pull/120/files#r766731140"]}, {"url": "https://github.com/companieshouse/ewf-terraform/pull/109", "comments": ["Can remove count altogether here as it was only to stop Live deployment.", "Updated in ef95156. Test plans against Dev and Staging look good.\r\n\r\nI had tested this and saw state inconsistencies without the `count` declaration but I must have made a mistake previously."]}, {"url": "https://github.com/companieshouse/ewf-terraform/pull/106", "comments": ["This `${var.aws_account}-${var.aws_region}` could be replaced with `${var.aws_profile}` as it contains the same details."]}, {"url": "https://github.com/companieshouse/ewf-terraform/pull/70", "comments": ["Could we replace this custom statement with your new work and list put the bucket names into the relevant list?"]}, {"url": "https://github.com/companieshouse/ewf-terraform/pull/53", "comments": ["keep this one, as its the updated naming.", "needs removed."]}, {"url": "https://github.com/companieshouse/ewf-terraform/pull/10", "comments": ["C+P error on your descriptions", "Updated."]}, {"url": "https://github.com/companieshouse/ewf-terraform/pull/6", "comments": ["Missing 433 for https and probably shouldnt have icmp in there.", "this should be 0.0.0.0/0 to allow inbound users from internet, it may be best to make this a variable however so that we can configure non production environments admin_cidrs if thats what is required.", "We do not need to create an SSL certificate for this, we already have one stored in ACM that we can use.\r\nTerraform provides the following data source to lookup that certificate:\r\nhttps://registry.terraform.io/providers/hashicorp/aws/latest/docs/data-sources/acm_certificate\r\n\r\nJira story CM-77 contains all information about the certificate that was uploaded.", "This needs to be a new data lookup, the one here uses the data subnets, we want to use the public subnets for the ALB.", "update to use data resource output", "index may be 0 not one as there is a single target group and index will usually start at 0", "We dont know exactly what path this should be so may need to update it when the EWF AMI is created.", "Need to confirm what the backend server is going to listen on when EWF AMI is created.", "please use the application variable instead of ewf", "same as above, ewf should be referenced by application variable in name fields", "Web Servers will have their own security group so you will need to create one for the ASG EC2 instances.\r\nThen reference that security group here.", "name reference update to variable. Look at other code to see use of format function for name fields to make things consistent.", "Needs to be a new data reference for web subnets, this is for data.\r\nThe web servers should use web subnets and ALB will use public.", "Use application variable for ewf and remove the whitespace (replace with hypen if you wish).\r\nPlease look at RDS code for the use of tags and merging of local tag value as these are consistent across resources.\r\n\r\nMaybe use the optional `tags_as_map` key for this module to create something like this:\r\n```\r\ntags_as_map = merge(\r\n    local.default_tags,\r\n    map(\r\n      \"Name\", \"${var.application}-web-instance\",\r\n      \"ServiceTeam\", \"${upper(var.application)}-DBA-Support\"\r\n    )\r\n  )\r\n  ```", "Example code looks good, we'll have to update the name and owner before the PR is merged.", "I dont see a `key_name` value anywhere in the ASG, we need to create a key_pair for the EC2 instances that are launched so they can be accessed if required. Check out the NetApp code to see how we're creating the key and referencing it. (Will require a Vault entry for the key).\r\n\r\nWe can probably make use of the `termination_policies` and set to: `OldestLaunchConfiguration` so it can do rolling updates but needs some quick reading to be sure its the right setting.", "Environment = var.environment?", "Agree, should probably be a var with a default. Later once we have generic AMI's this can then be used to actaully configure at startup as well so we only need to set in one place.", "+1, should be a var with a default", "Should be var provided from env profiles?", "Scaling/health check settings should be var provided from env profiles?", "The ASG security group cannot use the same variable as the ALB. The internal ASH EC2 instances will only accept traffic from internal subnet ranges, in this case the ALB.\r\nMaybe change this to be security group Ids instead of cidr_blocks and then reference the ALB security group.", "We will need to confirm if we need an EBS block at all and what size the EBS and root device should be.", "possible rename to ewf_rc2 as the path may contain more than just the keys.", "match the data naming above, so ewf_ec2_data instead of asg_keypair_input_data", "possibly rename this to public_cidr_block as it will only be used on the ALB.", "out of date comment", "Source dest check disable not needed, this is specific to the routing on the proxy so it can NAT traffic", "health check on var.backend_port as well?", "AMI configured for this to be in user data user's home dir?", "good shout, I dont think the cloudwatch role was applied to the rhel6 or ewf AMIs so we'll have to add it.", "Removed.", "removed", "port = 80 replaced to port = var.backend_port", "Cloudwatch role is included in RHEL 6 Base AMI, but cw helper isn't being applied but will be added into the base AMI when the collections and base repos are in place, so not an issue for this PR."]}, {"url": "https://github.com/companieshouse/ewf-terraform/pull/1", "comments": ["If it is data from the same account, should it be pulled from Vault, or using a data source?\r\n```\r\ndata \"aws_vpc\" \"selected\" {\r\n  tags = {\r\n    Name = \"vpc-${var.aws_account}\"\r\n  }\r\n} \r\n```\r\n\r\nFrom Vault is the obvious choice when it's cross-account, but if within the same account then need to make a decision if data source is a better option.\r\n- Gives access to all attributes and no external reliance on these to be added to Vault if require more\r\n- Doesn't rely on Vault being available... (This point is irrelevant though as other items also required from Vault)\r\n- Standard Terraform practice would be to use a data source\r\n\r\nA con of data source would it be requiring that the tag or whatever it is filtered on, doesn't change", "The environment tag is a difficult one.. I don't really know what environment you would tag it as. I don't think it would be`heritage-development` as that's the account. The environment would generally run within the account. \r\nE.g. Have a `platform` (the real one that's used) and a `sandbox` (used for testing upgrades etc) environment within the same account. Maybe ask one of the DBA's what environment is currently called / should be called\r\n ", "These should be pulled from a data source \r\n```\r\ndata \"aws_subnet_ids\" \"data\" {\r\n  vpc_id = data.aws_vpc.selected.id\r\n  filter {\r\n  name   = \"tag:Name\"\r\n  values = [\"sub-data-*\"]\r\n  }\r\n}\r\n```\r\n`subnet_ids = data.aws_subnet_ids.data.ids`", "Get info from DBA's about what these values should be as they will have a rough idea.\r\nIf start with only 10gb then would have to wait for storage to expand when adding data, should try and start with about the correct amount and then leave the space for autoscaling the storage if required", "14 days for Live has been decided by DBAs", "7 days for Staging has been decided by DBAs", "So this is the default Oracle port of `1521` - however originally when I was asked by the DBA's they said to use port `1522`. Need to ask if there if a need for it to use a different port", "There is an issue with cross-region creation here, something we've hit in other areas. May be a moot point as not any plan to launch it outside of eu-west-2, but worth thinking about.\r\nIf tried to launch in a different region after it has already been created in eu-west-2 then the creation would fail as globally the IAM role would already exist. \r\n\r\nWays to get around this is add a region var into the role name (duplication though), or decouple the creation of the role into a separate group ( ensure this group is run first). \r\nIn this case this same `rds-enhanced-monitoring` role would be used by all RDS's in the account as all it's doing is allowing `monitoring.rds.amazonaws.com`, so should it be created at an account level? ", "Typo: Should be `kms-data`", "Similar to the security group comment, will need to match whatever the DBA's say. I don't see a reason not to use 1521 though", "Is there a `-` missing here?", "Need to confirm with DBA's the instance class required for each account", "yep makes sense as the name is consistent.", "yep again makes sense as the name is constant.", "Steve and Jon have agreed the storage for the account and I've updated to match those.", "Makes sense, this should be moved to Infra group code and shared with all RDS instances in that account.", "Can be updated if they require it but as its Oracle we'll leave as 1521 for the first iteration. ", "No I left the record as ewfdb as the fqdn is now: `ewfdb.heritage.development.aws.internal`.\r\nI didnt think the hypen was necessary as that would be a more VM name than DNS, what do current DBs or services use in this sense?", "instance class agreed with Steve and I've changed to suit each account.", "This is an odd one, what CH call accounts I would typically call environments and with our account names that contains an environment \"level\".\r\nIn this case it could just be development over heritage-development because thats the actual environment and heritage-development is the account only. May need a call to align these.", "Yup I would agree a call to make a decision on this would be good as it will be the same in basically everything created. The tag is only used for organising / costing anyway so isn't a huge deal but good to be consistent ", "I've modified to shorten then environment value to be a specific environment not the account name."]}]}, {"url": "https://github.com/sassoftware/viya4-iac-gcp.git", "pull_requests": [{"url": "https://github.com/sassoftware/viya4-iac-gcp/pull/206", "comments": ["As of `terraform-google-modules/kubernetes-engine/google//modules/private-cluster` v30.0.0, `autoscaling_profile` needs to now be defined in this map.", "is this a breaking change or are the items that changed transparent to the end user?", "Is this a potential breaking change as well?", "@thpang Looking over this again, I believe that this would be considered breaking in that the changes are not backwards compatible only forwards compatible. Once you create a cluster with 30.0.0, or upgrade existing infrastructure with this newer code, an older version of `terraform-google-modules/kubernetes-engine/google//modules/private-cluster` cannot be used to modify the cluster. This is due to a change in permissions of the \"default cluster service account\" that gets created along with the cluster, a new role has been created. https://github.com/terraform-google-modules/terraform-google-kubernetes-engine/blob/master/docs/upgrading_to_v30.0.md\r\n\r\nIn our end the change will be transparent to the user, if they initially created their infra with 5.8.0 and then used a newer release with this PR included running `terraform apply` will work and automatically modify the \"default cluster service account\" with the new permissions.\r\n\r\n**I'm going to mark this change and breaking and make a note to include something in the release notes about this.**\r\n\r\n---\r\nThe `autoscaling_profile` change should be transparent, the default in <30.0.0 was `balanced`, this new version just exposes and makes parameter required if the user opts for `cluster_autoscaling`", "The v19.0.0 release is unique in that it is breaking for MySQL module, but postgres is fine. The update here does not cause any issues, see\r\nhttps://github.com/terraform-google-modules/terraform-google-sql-db/blob/v19.0.0/CHANGELOG.md#1900-2024-02-08\r\n"]}, {"url": "https://github.com/sassoftware/viya4-iac-gcp/pull/205", "comments": ["Nice!"]}, {"url": "https://github.com/sassoftware/viya4-iac-gcp/pull/203", "comments": ["These are all patch level versions. Just checking to be sure that's what's required here. Seems like the team has been moving toward minor updates like \"~> 2.25\" unless these values are still truly constrained by google. This comment would apply to **ALL** versions being adjusted here.", "I purposely made it so that the patch version could be >= to the last number. I havn't seen it in the kubernetes provider in particular, but in Google case some providers/modules introduce breaking changes even during minor version bumps which can be problematic.\r\n\r\nSee terraform-provider-google:5.4.0 changelog as a quick example https://github.com/hashicorp//blob/main/CHANGELOG.md#540-oct-30-2023\r\n\r\nI just found it to be safest in this project's case to only allow variations in the patch.", "Ok, I'll approve but believe that David has some other thoughts on this one. Might be a good time to have a team meeting about versioning ;)"]}, {"url": "https://github.com/sassoftware/viya4-iac-gcp/pull/197", "comments": ["Guessing this is based on the new foo/bar-branch naming convention?", "That's correct, changing it to `branches: [ '**' ]` allows for the workflow to be automatically run again `foo/bar-branch` naming convention as well those without forward slashes , `foo-bar-branch`"]}, {"url": "https://github.com/sassoftware/viya4-iac-gcp/pull/185", "comments": ["Guessing there is an equivalent Artifact Registry on AWS/Azure we'll be adding in as well?", "Azure and AWS still has ACR & ECR, and as far as I am aware they are not deprecating those cloud services. It's just GCP that's pushing people towards the \"new-ish\" Artifact Registry service before GCR is retired in 2024."]}, {"url": "https://github.com/sassoftware/viya4-iac-gcp/pull/183", "comments": ["Why were these removed?", "These variables in local.tf were never used so TFLint threw a warning. The effective set of these variables are actually located in `viya4-iac-gcp/modules/kubeconfig/locals.tf` these are unused duplicates.\r\n\r\n---\r\n\r\nHad to look through the git history, here's some historical context: \r\n`service_account_name`,`cluster_role_binding_name`,`service_account_secret_name` were added in PR that introduced the Terraform Enterprise changes here:\r\nhttps://github.com/sassoftware/viya4-iac-gcp/pull/144/files#diff-9a576c4980b4f226b7ef1042670d564777bbb0ed8ae2d1df33afbd03e2991fcdR38\r\n\r\nHowever in that PR these variables were added to both `viya4-iac-gcp/modules/kubeconfig/locals.tf` and `viya4-iac-gcp/locals.tf`. Only the set in `viya4-iac-gcp/modules/kubeconfig/locals.tf` are actually consumed when templating out the kubeconfig.\r\n\r\n\r\n"]}, {"url": "https://github.com/sassoftware/viya4-iac-gcp/pull/181", "comments": ["Pulling my review approval.  The SAS doc link for CDS was just changed.  \r\nI found this new link for SAS Common Data Store Requirements in 2023.06 \r\nhttps://go.documentation.sas.com/doc/en/itopscdc/default/itopssr/p05lfgkwib3zxbn1t6nyihexp12n.htm#n03wzanutmc6gon1val5fykas9aa ", "I believe the name here must have an underscore for the server instance, but that must be converted to slash when using the value as the server name. Was this taken into account and tested?", "@sayeun, Susan recommended using the replacement links I committed which should work permanently.", "@thpang, please refer to my [comment ](https://github.com/sassoftware/viya4-iac-aws/pull/211#discussion_r1232582145) in the related PR for AWS.\r\nJay shared that there is a current issue being able to create 2 or more external PG instances in GCP https://rndjira.sas.com/browse/IAC-1022 but it does not seem related to dashes being part of the postgres server instance name.", "Unable to resolve, @sayeun can you try to resolve this convo?"]}, {"url": "https://github.com/sassoftware/viya4-iac-gcp/pull/178", "comments": ["We call this monitoring; however, this was already part of the code base in `create_gke_monitoring_service` what/how will we distinguish these items and keep the confusion down with our customers? I know AWS has a prometheus offering and Azure has their version in preview, Is prometheus a variant of monitoring? and/or a solution being offered as its the industry go to?", "false shouldn't be quoted as it's a Boolean value.", "Summary of : https://cloud.google.com/stackdriver/docs/solutions/gke\r\n\r\nThe main difference is that `gke_monitoring_service` (Cloud Monitoring service add-on) is used to to monitor both the the system and workload components of the cluster. However I just found out that as of 1.24 workload monitoring is deprecated and Google recommends that the Google Cloud Managed Service for Prometheus is used monitor and alert on your workloads. Quote on bottom.\r\n\r\nEven through the monitoring is split up between the GKE add on and Prometheus all the data will still flow into the GCP monitoring service here https://console.cloud.google.com/monitoring. Setting the `enable_managed_prometheus` flag just installs the Prometheus data collector service within the cluster which ends still ends up sending the data to the GCP monitoring service, but it also enables better integration with Grafana or promql based workflows. The user also doesn't need to worry about scaling a Prometheus instance if they have multiple clusters or vms since the Prometheus data collector sends it all to cloud managed service. \r\n\r\nAnother behavior that I saw is that with `enable_managed_prometheus` and `gke_monitoring_service` both enabled the user needs to explicitly specify which components the `gke_monitoring_service` (the add-on) will monitor, this requires one additional variable `gke_monitoring_enabled_components` that I am in process of adding.\r\n\r\nI saw this in the GKE details page\r\n\r\n>Cloud Monitoring is a Google Kubernetes Engine (GKE) addon that collects metrics emitted by your applications and by GKE infrastructure. Learn more \r\n\r\n>System monitoring includes over 40 platform metrics such as CPU, memory, and storage for essential system components. Cloud Monitoring does not charge for the ingestion of system metrics. Learn more \r\n\r\n>Workload monitoring is deprecated. Workload monitoring is removed in GKE 1.24 and later. Workload monitoring is replaced by Google Cloud Managed Service for Prometheus, which is Google's recommended way to monitor Kubernetes applications by using Cloud Monitoring. Learn more ", "fixed in latest push"]}, {"url": "https://github.com/sassoftware/viya4-iac-gcp/pull/173", "comments": ["For these does it ignore them and then terraform can delete the postgres server or are they literally abandoned and left in your subscription for clean up later, but terraform still deletes the postgres server?", "Should hashicorp/external version be updated to 2.3.1 per your table?", "Should the version on line 288 be 4.2.1?\r\n```terraform\r\nmodule \"sql_proxy_sa\" {\r\n  source        = \"terraform-google-modules/service-accounts/google\"\r\n  version       = \"4.1.1\"\r\n```", "Should version on line 26 be \"3.0.0\" ?\r\n```terraform\r\nmodule \"cloud_nat\" {\r\n  count         = length(var.nat_address_name) == 0 ? 1 : 0\r\n  source        = \"terraform-google-modules/cloud-nat/google\"\r\n  version       = \"2.2.1\"\r\n```", "Looks like that change didn't get pushed. 4.2.1 only updates deps without any behavior changes, let me do a smoke test and push this version up. I'll let you know when it's in.", "Looks like that change didn't get pushed as well. Nothing in 3.0.0 will require any additional changes on our end since they just increase the minimum required provider version. Once again I'll make the change, test and push it up.", "It looks like hashicorp/null is 3.2.1 in my table, you may have gotten it mixed up with hashicorp/external which is below that.", "@thpang  I had to do a little digging to see the exact behavior\r\nhttps://github.com/hashicorp/terraform-provider-google/pull/13107\r\n\r\nBut essentially during the terraform destroy process, for both the user and database it will skip over deletion so we no longer get blocked by the \"failed to deleteuser\" error due to the \"SharedServices\" db that get's created during the Viya deployment process relying on the \"pgadmin\" user. \r\n\r\nEven though the user and db deletion is skiped, the Postgres Instance is getting destroyed anyways so those resources are getting wiped. Nothing is left over in the GCP project for the user to clean up.", "Changes made and retested, see scenario 5 in the table above.", "Changes made and retested, see scenario 5 in the table above.", "It's just the value of \"2.2.2\" on line 34 that I was asking about, probably should have removed the previous lines to avoid any confusion, sorry.\r\n\r\nHere's the reference to hashicorp/external \"2.3.1\" from your table that I was asking about.\r\n\r\nhashicorp/external\r\nVersions:\r\nInitial Version: 2.2.2\r\nFinal Version: 2.3.1\r\nNotes:\r\nNo notable breaking changes or deprecations observed that would affect us", "Oh I see what you are pointing out now.\r\nLet me fix that and get it through another quick test round. hashicorp/external is just used to generate the build info configmap so I can test this out quickly just by creating infrastructure without a viya deployment.", "Ended up including a deployment in my retest since I saw another module that wasn't fully updated. Must have been an issue when I was rebasing between branches. See the new scenario 6.\r\n\r\n@dhoucgitter Thanks again for catching this, this is ready for review again."]}, {"url": "https://github.com/sassoftware/viya4-iac-gcp/pull/172", "comments": ["Just be aware some customers may have earlier versions of terraform and this could break their automation. ", "Yes it will be \"breaking\" for anyone who does not have Terraform 1.4.5 installed and is not using the Docker image.\r\nSince this PR is marked as \"breaking\" I'll be sure to include release notes advising users to update their terraform versions before consuming this release."]}, {"url": "https://github.com/sassoftware/viya4-iac-gcp/pull/161", "comments": ["Just checking, but this works now for all 3 providers correct? That is having the k8s version listed as only the MAJOR.minor version leaving off the patch level.", "Why would this value of the `kubernetes_version` not be set to `1.24` as it was above?", "That how it is in AWS and when I tested it in Azure it also worked.\r\n@riragh will be switching to the aliased version during Azure's update to support 1.25", "In this specific section we are showing the user that you can list out versions using `gcloud container get-server-config ...` and choose an exact one. We describe aliased versions (like 1.24), in the section right below this.\r\n\r\nI could maybe change the sentence above on L63 to clear it up?\r\n\r\n\"To set the exact version for your cluster you would take one of these values and set the `kubernetes_version` variable in your tfvars files like this:\"\r\n\r\n", "Updated the doc with the suggestion from my previous comment. \r\n@thpang ready for re-review,  let me know if clears up that section, I'm still willing to make changes.", "Yes, please update your comment to reflect the exact version."]}, {"url": "https://github.com/sassoftware/viya4-iac-gcp/pull/150", "comments": ["Just to explain this better:\r\n\r\nIf a user defines an external PG server in their their .tfvars without specifying any `database_flags` then the `base_database_flags` will be used. This will set the `max_prepared_transactions` & `max_connections` values for the server to 1024, as recommended by the SAS documentation. See line: https://github.com/sassoftware/viya4-iac-gcp/pull/150/files#diff-9a576c4980b4f226b7ef1042670d564777bbb0ed8ae2d1df33afbd03e2991fcdR91\r\n\r\n\r\nIf the user does specify values for `database_flags` then their values will be merged on top of the `base_database_flags`, example:\r\n\r\nUser sets `database_flags = [{ name = \"max_prepared_transactions\", value = \"2222\" }, { name = \"other_custom_flag\", value = true }]`\r\nThe final flags applied on the PG server will be: `[{ name = \"max_connections\", value = \"1024\" }, { name = \"max_prepared_transactions\", value = \"2222\" }, { name = \"other_custom_flag\", value = true }]`\r\n\r\n\r\nThis logic here on line 224 does that, breaking this line down:\r\n```terraform\r\nbase_database_flags = [{ name = \"max_prepared_transactions\", value = \"1024\" }, { name = \"max_connections\", value = \"1024\" }] # from locals.tf\r\ndatabase_flags [{ name = \"max_prepared_transactions\", value = \"2222\" }, { name = \"other_custom_flag\", value = true }] # user values from .tfvars\r\n\r\nconcat(local.base_database_flags.*.name,each.value.database_flags.*.name)\r\n# Concat list of all name values from both base_database_flags & database_flags\r\n# Call this A\r\n [\r\n  \"max_prepared_transactions\",\r\n  \"max_connections\",\r\n  \"max_prepared_transactions\",\r\n  \"other_custom_flag\",\r\n]\r\n\r\nconcat(local.base_database_flags,each.value.database_flags)\r\n# Concat list of all maps from both base_database_flags & database_flags\r\n# Call this B\r\n[\r\n  {\r\n    \"name\" = \"max_prepared_transactions\"\r\n    \"value\" = \"1024\"\r\n  },\r\n  {\r\n    \"name\" = \"max_connections\"\r\n    \"value\" = \"1024\"\r\n  },\r\n  {\r\n    \"name\" = \"max_prepared_transactions\"\r\n    \"value\" = \"2222\"\r\n  },\r\n  {\r\n    \"name\" = \"other_custom_flag\"\r\n    \"value\" = true\r\n  },\r\n]\r\n\r\n\r\n(zipmap(A,B)\r\n# constructs a map from a list of keys and a corresponding list of values\r\n# The key reason why this is used Each pair of elements with the same index from the two lists will be used as the key and value of an element in the resulting map. If the same value appears multiple times in keyslist then the value with the highest index is used in the resulting map.\r\n# This removes the max_prepared_transactions from index 0 which was overridden by a user value\r\n# Call this C\r\n{\r\n  \"max_connections\" = {\r\n    \"name\" = \"max_connections\"\r\n    \"value\" = \"1024\"\r\n  }\r\n  \"max_prepared_transactions\" = {\r\n    \"name\" = \"max_prepared_transactions\"\r\n    \"value\" = \"2222\"\r\n  }\r\n  \"other_custom_flag\" = {\r\n    \"name\" = \"other_custom_flag\"\r\n    \"value\" = true\r\n  }\r\n}\r\n\r\nvalues(C)\r\n# values takes a map and returns a list containing the values of the elements in that map.\r\n# This transforms it into the format that `database_flags` parameter from postgressql module needs\r\n[\r\n  {\r\n    \"name\" = \"max_connections\"\r\n    \"value\" = \"1024\"\r\n  },\r\n  {\r\n    \"name\" = \"max_prepared_transactions\"\r\n    \"value\" = \"2222\"\r\n  },\r\n  {\r\n    \"name\" = \"other_custom_flag\"\r\n    \"value\" = true\r\n  },\r\n]\r\n```", "Jay, that additional breakdown is useful, it does a good job of explaining how \"If the same value appears multiple times in keyslist then the value with the highest index is used in the resulting map.\""]}, {"url": "https://github.com/sassoftware/viya4-iac-gcp/pull/144", "comments": ["Minor change, need to update the \"default\" column for this variable in the CONFIG-VARS.md", "This can be removed.", "Could parenthesis be added to this expression to help indicate the associations for the\r\ncondition ? true_val : false_val\r\nrelationships.", "What can be removed? TF Enterprise requires that the default_public_access_cidrs value be 0.0.0.0/0 given we don't know the IP of the worker agent that will actually being performing the updates inside the cluster. Please clarify", "The comment block mentions the \"SAS Cary Network\" and an internal URL.\r\n\r\nYou could probably leave the \"Use the IP reported in https://ifconfig.me/ and append \"/32\", e.g. 1.2.3.4/32\" portion though", "I can remove that\r\ndone", "How would the parens help in clarification? Would you need extra formatting? ", "done", "No extra formatting, only add parens to indicate the grouping similar to this two-level conditional which is simpler than yours:\r\n test = \"condition ? value : (elif-condition ? elif-value : else-value)\"\r\n", "If the parens are added we'll need to start testing again given the logic change to verify. Looking to avoid this if possible just for the sake of semantics. ", "Talked with @dhoucgitter on this one and for now the code will stay as is. In the future we'll be looking to help format, if possible, in a way to keep `tf fmt` happy along with the complex logic blocks making more sense to everyone. Thanks again.", "Reviewed the logic with Thomas, he tried adding parens for grouping. terraform fmt ends up formatting things that make it harder to understand the associations when that is done. Maybe there are more layers to this conditional than fmt is able to deal with. I'm OK with leaving this as for now."]}, {"url": "https://github.com/sassoftware/viya4-iac-gcp/pull/143", "comments": ["I would say it would list the supported versions not version required. ", "Reworded it to say  \"Refer to the Viya 4 Deployment Guide to see a list of supported PostgreSQL versions\""]}, {"url": "https://github.com/sassoftware/viya4-iac-gcp/pull/142", "comments": ["See https://github.com/terraform-google-modules/terraform-google-sql-db/blob/v12.0.0/CHANGELOG.md#features-3", "Details on this change. Seems correct, but there is both `zone` and `location` need to know the difference.", "`gpu_resources` was added for gpu support?", "Up to `4.38.0` at this point. ;)", "in 4.4.0 the zone field is deprecated and they recommend that location is used instead so I made the swap. \r\nSee https://github.com/hashicorp/terraform-provider-google/blob/main/CHANGELOG.md#440-december-13-2021\r\n\r\n\r\n", "Doesn't look like the changes in 4.38.0 will require any changes on our end. I'll bump the version and provision some infrastructure to test this out.\r\n\r\nSee https://github.com/hashicorp/terraform-provider-google/blob/main/CHANGELOG.md#4380-september-26-2022", "In v16.0 for terraform-google-kubernetes-engine `cluster_autoscaling` now requires a `gpu_resources` to be included. The upgrade guide states leave that variable as a blank list if you wish to preserve the behavior of the previous versions. I did not want to introduce any behavior changes as part of this PR that is just meant updating the modules.\r\n\r\nSee https://github.com/terraform-google-modules/terraform-google-kubernetes-engine/blob/master/docs/upgrading_to_v16.0.md which describes the change", "Updated to 4.38.0, no issues with infrastructure creation."]}, {"url": "https://github.com/sassoftware/viya4-iac-gcp/pull/137", "comments": ["No breaking changes here? Just asking as it's a major jump from 14 -> 15.", "Same here no breaking changes? Going from version 1 -> version 2", "None that I found affects us, from my change notes above I reviewed the 15.0.2 changelog and there was no big changes in modules we use.\r\nhttps://github.com/terraform-google-modules/terraform-google-kubernetes-engine/blob/v15.0.2/CHANGELOG.md\r\n", "There was one small change with this update from my notes above:\r\n\r\n> Updated hashicorp/kubernetes to 2.13.0\r\nRemoved load_config_file from the provider parameters, that feature was deprecated in hashicorp/kubernetes v2 and we were setting that value to false anyways so that behavior was not being used.\r\n\r\nFrom a infrastructure creation standpoint did not run into any issues. Testing a Viya deployment on the cluster is still in progress.", "Do you still need depends_on here after adding back the `data \"kubernetes_secret\" \"sa_secret\"`", "Also, I would suggest to add this block `data \"kubernetes_secret\" \"sa_secret\"` back up to L20 as it was originally.", "that should be the data element not the resource element: `data.kubernetes_server.sa_secret`", "I would restore this block to its old location.", "Did you check the [breaking changes](https://github.com/hashicorp/terraform-provider-kubernetes/releases/tag/v2.0.0) section in the release notes for 2.0.0?", "Here the list of [breaking changes](https://github.com/terraform-google-modules/terraform-google-kubernetes-engine/releases/tag/v15.0.0). You have to look at the initial major version update for breaking changes. Please verify", "@thpang See my my previous comment. It has that same link, already made sure that any breaking changes from 15.0.0-15.0.2 didn't require us to make any changes", "@thpang I did check for any breaking changes in the 2.0.0, see my previous comment. The `load_config_file` was removed in our code since it was deprecated in this new version.", "Updated.", "Latest change moved it back", "Moved it back and changed the depends_on"]}, {"url": "https://github.com/sassoftware/viya4-iac-gcp/pull/134", "comments": ["Change version from : \"1.23.6-gke.1700\" -> \"1.22.9-gke.1500\"", "Updated"]}, {"url": "https://github.com/sassoftware/viya4-iac-gcp/pull/121", "comments": ["This code is infrastructure so why are we trying to tell them this is an external postgres? This is a SAS related term and relevant to SAS Viya. The original comment tells the user this code is creating a postgres server if the flag `create_postgres=true` I do not believe this should be changed. Please clarify the reason for the update.", "Please clarify what changed here.", "Is this to add clarity? Again asking as these changes seem a bit trivial.", "Is this to add clarity? Again asking as these changes seem a bit trivial.", "Is this to add clarity? Again asking as these changes seem a bit trivial.", "The `create_postgres` flag was removed in this commit on 2021-08-18 https://github.com/sassoftware/viya4-iac-gcp/commit/0c167146a22ba5f4a1981fc48a3838625a9d8438#diff-ad6a080aef90f6d0485712cd918e926b8a3a69ae3c97dceeb853a4800f9b590fL235\r\n\r\nMaybe a better way to word the note section would be:\r\n\r\nOnly used with the `postgres_servers` variable block?", "Removed a newline between the words and & \"Storage\r\nThat extra newline was causing the note to be split into multiple cells, You can see that here in the main branch: https://github.com/sassoftware/viya4-iac-gcp/blob/main/docs/CONFIG-VARS.md#google-container-registry-gcr", "Minor change, just updated the link from ../CONFIG-VARS.md#postgres to ../CONFIG-VARS.md#postgres-servers\r\n\r\nCorrecting the link to \"postgres-servers\" will make the page auto scroll to the section when CONFIG-VARS.md gets opened.", "Minor change, just updated the link from ../CONFIG-VARS.md#postgres to ../CONFIG-VARS.md#postgres-servers\r\n\r\nCorrecting the link to \"postgres-servers\" will make the page auto scroll to the section when CONFIG-VARS.md gets opened.", "Minor change, just updated the link from ../CONFIG-VARS.md#postgres to ../CONFIG-VARS.md#postgres-servers\r\n\r\nCorrecting the link to \"postgres-servers\" will make the page auto scroll to the section when CONFIG-VARS.md gets opened.", "if you're going to change this here, are you also updating the docs for AWS/Azure? Is this to add clarity? Again, stating we're using the Provider based SQL engine implies the postgres instance is external hence the need for the `database_subnet_cidr` ", "I checked out the AWS & Azure documentation and they had references to create_postgres=true removed as part of the commit for \"Data Server Updates\" on 8/18, it's just GCP that still has this stray reference in the notes section that needs to be updated."]}, {"url": "https://github.com/sassoftware/viya4-iac-gcp/pull/120", "comments": ["These are CASE sensitive. I believe the correct entry would be: COS_CONTAINERD. Remember to look at the Terraform docs for these updates. Check [here](https://github.com/terraform-google-modules/terraform-google-kubernetes-engine/blob/e6b928288cdd79035d32ea84fd8ce6ca40979246/docs/upgrading_to_v19.0.md#-default-node-image-changed-to-cos_containerd).", "Didn't realize it was, pulled the lower case format from the Google documentation from my description and it ended up using the correct image. I'll switch this to all caps so it's more in line with the terraform-google-kubernetes-engine module usage documentation.", "Case changed, testing by deploying a v1.21.6-gke.1500 and the container runtime was still containerd"]}, {"url": "https://github.com/sassoftware/viya4-iac-gcp/pull/115", "comments": ["Just verifying that if I set `create_jump_vm = false` and have `storage_type != \"standard\"` the file(...) directive here in the conditional does not get triggered if the `ssh_public_key` physically does not exist on the file system or the user actually sets the value to `null`", "yes, due to lazy evaluation"]}, {"url": "https://github.com/sassoftware/viya4-iac-gcp/pull/114", "comments": ["Was thinking here you'd use a [directive](https://www.terraform.io/docs/language/expressions/strings.html#directives) but if you did you'd have to pass in the storage_type flag to check. This looks fine.", "Does this always return a value now? Checking as we used to pass in null to deactivate the user_data on the jump vm. Not sure what happens when you pass in an empty array [\"\"]. If you can verify.", "The user_data template is gated by the same count as the vm. \r\nIn the current code, we  never have a case where we do not pass in user_data.\r\nThat check looked like cruft from an earlier version of the code, maybe. ", "The flag that's keeping the data element from being created is also the same flag that keeps the VM from being created. So it'll always have a value if the vm is needed."]}, {"url": "https://github.com/sassoftware/viya4-iac-gcp/pull/110", "comments": ["So the variable flag `create_container_registry` has been changed to `enable_registry_access` which is a bit different than we do with Azure. Is the container registry there by default in GCP and we just need to actually enable access to that CR? Asking as we've now moved away from the standard naming of the variable.", "Short answer: yet, the container registry is there by default in gcp, at https://gcr.io/<project-name>\r\nDetails:\r\nhttps://cloud.google.com/container-registry/docs/overview"]}, {"url": "https://github.com/sassoftware/viya4-iac-gcp/pull/108", "comments": ["Since the resource variable is `initial_node_count` let's change `local.minimum_node_count` -> `loca.initial_node_count`", "Lets change `minimum_node_count` to `initial_node_count` to match resource variable."]}, {"url": "https://github.com/sassoftware/viya4-iac-gcp/pull/106", "comments": ["I think this line need to be removed as database_flags is also defined and that is the new variable name", "agreed. Removing now. Good catch.", "Set to true in variables.tf. ", "Fixed.", "The CPS example has any additional level. The default example appears to be missing one. ", "This has been fixed."]}, {"url": "https://github.com/sassoftware/viya4-iac-gcp/pull/105", "comments": ["From comment above : Only used when `storage_type=\"ha\" Is there a check here? Should this not be:\r\n```\r\nreserved_ip_range = var.storage_type == \"ha\" ? var.file_store_subnet_cidr : null\r\n```", "From comment: Only used when `create_postgres=true` so this line and 57 should have a guard on them.\r\n```\r\naddress = var.create_postgres ? split(\"/\",var.database_subnet_cidr)[0] : null\r\n```", "Another guard\r\n```\r\nprefix_lenght = var.create_postgres ? split(\"/\",var.database_subnet_cidr)[1] : null\r\n```", "the guard is already in the resource\r\n  count  = var.storage_type == \"ha\" ? 1 : 0 \r\n", "the guard is already in the resource:  \r\ncount = var.create_postgres ? 1 : 0", "the guard is already in the resource: \r\n count = var.create_postgres ? 1 : 0"]}, {"url": "https://github.com/sassoftware/viya4-iac-gcp/pull/101", "comments": ["extra quote \"us-east1-b\"**\"**. Note all samples have this extra quote. "]}, {"url": "https://github.com/sassoftware/viya4-iac-gcp/pull/100", "comments": ["I would say given we have 3 providers and would need a flag for `private_cluster` support, this flag should be more generic. This is specific to GCP. I believe on the AWS side I'll be using `private_cluster` as the flag to tell the system to disable any `public` facing networking, etc.", "I would change the output here as well to be `private_cluster`"]}, {"url": "https://github.com/sassoftware/viya4-iac-gcp/pull/96", "comments": ["If `BASIC_HDD` is the default why would this not be `1024` as the doc above states.", "It was a judgement call. Trying to set a default that works in the largest number of cases.\r\n\r\nWith a default for 2560, both BASIC_HDD and BASIC_SSD will work by default.\r\nWith a default of 1024 BASIC_SDD will fail unless you also increase filestore_size.\r\n\r\nNote that CONFIG_VARS.md states that you can reduce the filesize for basic_sdd. \r\nIn practice, it's not a big cost factor (~$20 per TB per month), and just as well to have plenty storage.", "Can we not put a check in there to guard against that if it's HDD > 1024 if it's SDD > 2560?", "We can put a check in. It's not really necessary, though. The Filestore will kick you out with a reasonable error message, too.\r\nI was just aiming for a smoother user experience (i.e. avoid cascading dependencies between parms)", "How about in locals:\r\n\r\n```\r\nfilestore_size_in_gb = var.filestore_tier == \"BASIC_HDD\" ? (var.filestore_size_in_gb < 1024 ? 1024 : var.filestore_size_in_gb) : (var.filestore_size_in_gb < 2560 ? 2560 : var.filestore_size_in_gb)\r\n```\r\n\r\nAnd then set the default value to `null` this way if the user chooses a value its checked and set according to the `filestore_tier` selection.", "ok. but... I'm not sure about silently overwriting user-set input values.\r\nHow about we set the defaults if the user has not set any value, and otherwise try to apply the value set by the user?\r\nSimplified code:\r\n\r\n```\r\nvariable filestore_size_in_gb {\r\n  default = null\r\n}\r\nlocals (\r\n   filestore_size_in_gb = (\r\n      var.filestore_size_in_gb == null\r\n        ? (var.filestore_tier == \"BASIC_HDD\" ? 1024 : 2560 )\r\n        : var.filestore_size_in_gb  \r\n   ) \r\n)\r\n\r\n```       \r\n       ", "The reasoning for the logic I provided above is that it will not let the user set illegal values. So yes it does overwrite what they may have, but only to protect the system from throwing an error. The code you have will simply allow them to set a value without any error checking. Which does cause an error which can be prevented.", "I see your reasoning. But I think it runs up against a hard principle of never overriding user-inputs.\r\nSay a user specifies 500g - ignoring all documentation (it does happen!) - and the \"terraform apply\" will succeed. \r\nThe value set by user does  now not match the infrastructure, the project did not create the infrastructure that the user explicitly requested.\r\nLater the user notices the 1T value in the actual Filestore and will be confused at best, and raise a bug at worst.\r\n \r\nBetter to stop processing and let users know when they set invalid values.", "I kinda agree, but if you tell someone that the minimum value is x and anything less is not accepted. To have them enter x and throw and error seems contrary. I believe the user is simply trying to create a usable system. My thought is that if they ignore the docs, they get what we give them. Everyone should read the docs, especially on a project like this one. But I'll let it go for now. If you can implement your simplified code."]}, {"url": "https://github.com/sassoftware/viya4-iac-gcp/pull/86", "comments": ["Not sure if you've done a recent pull but the lowercase value is required. This was added with the prefix checks needed for kubernetes items being added that include the prefix which can only be lowercase. This needs to be added back in.", "oh, that's not the right change\r\n", "sorry about that. Got thrown because my local was still based on pre-squash .\r\n"]}, {"url": "https://github.com/sassoftware/viya4-iac-gcp/pull/69", "comments": ["For consistency, recommend replacing \u201cvar.location\u201d with \u201clocation\u201d. That is the name used under the Required Variables section of this document and in the terraform.tfvars example files.", "Updated and added link"]}, {"url": "https://github.com/sassoftware/viya4-iac-gcp/pull/66", "comments": ["Is there a way to keep these pseudo blocks aligned? Would like to see this formatting kept.", "Is there a way to keep these pseudo blocks aligned? Would like to see this formatting kept. For all of these items.", "Is there a way to keep these pseudo blocks aligned? Would like to see this formatting kept.", "Same as above with the pseudo block alignment."]}, {"url": "https://github.com/sassoftware/viya4-iac-gcp/pull/11", "comments": ["This variable is different for GCP vs AWS/Azure. Again consistency needs to be in play here. I would suggest changing this back as a PR I have for AWS and Azure's current code base has this as: default_nodepool_node_count", "These look good. I have also added these into the AWS code base. Azure does not appear to have these, but does have cluster tags. Again not part of this PR but something wee need to focus on.", "I would keep this as it was originally, if needed we can clean these up in the future, or you can update the other providers to match this syntax. No preference just looking for consistency. ", "Same comment as before keep the original value.", "Keep original", "Keep original", "This does match the initial default nodepool variable, so just need to find a common ground here for the node pools and other providers.", "sorry, this is not part of this change. I will remove this PR until the node-pool PR is pushed"]}, {"url": "https://github.com/sassoftware/viya4-iac-gcp/pull/10", "comments": ["typo on max_nodes. It should be each.value.max_node_count", "current gke 1.18 version is 1.18.9-gke.1501", "Given the information from the [tf page](https://www.terraform.io/docs/providers/google/r/container_node_pool.html#initial_node_count) on this item \r\n\r\ninitial_node_count - (Optional) The initial number of nodes for the pool. In regional or multi-zonal clusters, this is the number of nodes per zone. Changing this will force recreation of the resource. WARNING: Resizing your node pool manually may change this value in your existing cluster, which will trigger destruction and recreation on the next Terraform run (to rectify the discrepancy). **If you don't need this value, don't set it. If you do need it, you can use a lifecycle block to ignore subsequent changes to this field.**\r\n\r\nHave we made sure this might not interfere with subsequent updates?", "Ok, so retracting my initial comment here. We have 3 different default values in our provider code base:\r\n\r\n```\r\nAzure - {}\r\nAWS   - { project_name = \"viya\" }\r\nGCP   - { project_name = \"viya401\" }\r\n```\r\nSo can we get a vote here from @manoatsas @enderm and @NormJohnIV on this one.\r\n\r\nI vote for simply:\r\n```\r\n{ project_name = \"viya4\" }\r\n```", "+1", "I think the question here is how we handle out-of-band updates. My understanding is that Terraform fundamentally does not honor them. If you change something manuall, and then re-apply your terraform manifest, you manual change will get wiped out.\r\nBut maybe I'm missing the point\r\nMaybe with \"manual\" they mean \"if an autoscaling event changes the number of nodes\".\r\nI've found the GCP terraform provider to less coherent than aws or azure. That are a few cases where they have a field, but then tell you not to use it, but without clear in-depth explanation...", "I went ahead and added the lifecycle workaround. It won't harm anything.", "+1 for { project_name = \"viya4\" }. It's good to have a sample value in there. And it's just a default, can easily be changed by the user.\r\n", "as to this PR: for now, I blanked out the labels. I can include this label change into a later PR. ", "So this value will have to be aligned to our old variable names:\r\n\r\n* machine_type -> vm_type", "So this value will have to be aligned to our old variable names:\r\n\r\n* min_node_count -> min_nodes\r\n* max_node_count -> max_nodes"]}, {"url": "https://github.com/sassoftware/viya4-iac-gcp/pull/9", "comments": ["Looks like this needs a value of 3. Did you actually stand up a cluster with this code? Wondering if tf would have caught this empty value when applying this.", "This code was put in place for Azure to indicate auto-scaling. Does this also apply to GCP? Just checking as the AWS code always seems to auto-scale so this logic seems out of place."]}, {"url": "https://github.com/sassoftware/viya4-iac-gcp/pull/1", "comments": ["So currently in AWS we have: cluster_endpoint, we did have public_endpoint here which is more generic. Unless we know we are going to expose other endpoints public/private. I would prefer the value: cluster_endpoint for all providers and keep any provider information out of the output variables all together. This will help keep things consistent. ", "I would prefer if we had the bool values all have some default true or false. Unless the 'null' is being used to help with logic in the auto creation. If that's the case a comment here would be helpful.", "will do. I had chaned it to be consistent with aks, which currently uses aks_host", "yes, null is used for the logic. I'll add comments.\r\n", "A little concerned about this one. Terraform has a bad habit of not liking elements when re-running. But given this is already a sub-element of another array not sure what's going to happen when/if this resource is not created. If you can verify. "]}]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake.git", "pull_requests": [{"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/253", "comments": ["```suggestion\r\n## [7.1.1] - 2024-04-03\r\n```", "```suggestion\r\n- Renamed variable from `common_producer_iamroles` to `apiary_common_producer_iamroles` to make the name consistent.\r\n```"]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/251", "comments": ["Are all of these permissions needed?\r\nThe definition only mentions read and write permissions to buckets. ", "Let me adjust the permissions to match a subset of the permissions in producer_iamroles.", "Changes looks good to me, but since this is a new feature we going to support, so I suggest to bump the version to `7.1.0`", "Updated version to 7.1.0 in CHANGELOG", "pls add tagging permissions in case:\r\n`PutObjectTagging`\r\n`GetObjectTagging`", "Added the tagging permissions."]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/247", "comments": ["needs to be updated in variables.md", "discussed offline. Needs to be tested to check if the code works when api_key and app_key are not set in secrets manager.", "done", "tested it with the key not present in SecretsManager. The rest of the terraform code works fine"]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/245", "comments": ["Why do we have 2 releases on the same PR?", "Should the policy be set on all resources? Or should instead be configurable and that way you can choose to do it on all resources or a subset?", "Is there a difference between the R/O and R/W metrics? If it isn't, can we put it in a separate file and reference it in both places?", "The indentation seems to be off.", "The same here.", "If this is for HMS, shouldn't we use HMS as a prefix in the variable name? This name is too generic.", "The same goes for all the other RDS variables.", "Maybe a better name would be `datadog_agent_sidecar_enabled`?"]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/241", "comments": ["```suggestion\r\n- Upgrade AWS provider to `4.x`.\r\n```"]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/240", "comments": ["please mention which version of TF provider we are making this work with. \r\n\r\nAlso, needs a major version update - 7.0.0", "done"]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/238", "comments": ["```suggestion\r\n  description = \"Enable HMS lock house keeper. When enabled, this creates a new HMS instance for housekeeping.\"\r\n```", "```suggestion\r\nvariable \"enable_hms_housekeeper\" {\r\n```\r\n\r\nis that better ?", "README update - https://github.com/ExpediaGroup/apiary-data-lake/blob/master/VARIABLES.md", "do we need all these additional envs variable also on this housekeeping deployment ?\r\n\r\nMay be we should remove all unnecessary environment vars from this.", "I was not sure should we keep this or not, but it should not impact anything.", "do we need ranger and atlas ?", "probably not, let me remove it, does ldap also needed ? might not need too ?", "```suggestion\r\n- Added variable `enable_hms_housekeeper ` to support hive metastore lock house keeper.\r\n```", "what about this ? will it also try to create the Databases ?", "it wont, just grants access, we have same in hms-readonly.", "Tested without `HIVE_DB_NAMES` and `LDAP` setting, worked fine, removed all of those unnecessary configures."]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/236", "comments": ["limt=limit", "limt=limit"]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/232", "comments": ["is this namespace ok for egap? \r\n```\r\n\\\"namespace\\\": \\\"hms_readonly\\\"\r\n```", "yes that is kept intentionally so that I can have 1 dashboard across the platforms\r\n\r\nthis namespace will just be appended in front of each metric name just for identification."]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/229", "comments": ["I was thinking to have a variable(s) containing all metric names. If you have individual variables for each metric, then you have the same problem. You add a new one and you need to remember to modify both RO and RW.  ", "```suggestion\r\n  description = \"HMS metrics to be sent to Datadog.\"\r\n```", "```suggestion\r\n## [6.18.0] - 2023-05-19\r\n```", "Updated it. Thanks for the review.", "default should be false", "add variables in https://github.com/ExpediaGroup/apiary-data-lake/blob/master/VARIABLES.md", "changed it to false.", "added it. thanks", "what about this var - `datadog_metrics_hms_readwrite_readonly` ?", "added it too. ", "```suggestion\r\n## [6.18.0] - 2023-05-25\r\n```"]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/228", "comments": ["Assuming the metrics in both R/W and R/O are the same, wouldn't it be better to put the metric names in the variables file and use them in both tf files?", "Yes, that makes sense, I will put it in a variable. Thanks for the review.", "I have moved them to the variables file. Please have a look."]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/227", "comments": ["```suggestion\r\n            \"Sid\": \"Apiary consumer IAM role permissions based on a condition\",\r\n```", "```suggestion\r\n  description = \"IAM policy condition applied to apiary_conditional_consumer_iamroles for s3 object access.\"\r\n```", "```suggestion\r\n  description = \"AWS IAM roles allowed conditional read access based on apiary_consumer_condition to managed Apiary S3 buckets. Setting apiary_consumer_condition is mandatory for this to take effect.\"\r\n```", "Only added line 21", "I am unsure if adding this condition inside the text block is possible. The rest of the blocks add `if/else/for` at the beginning and at the end only.", "```suggestion\r\n  description = \"AWS IAM roles allowed conditional read access based on apiary_customer_condition to managed Apiary S3 buckets.\"\r\n```"]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/221", "comments": ["Shouldn't this be a minor bump?", "so this should be `6.15.0` ?", "I would say so, yes. It's not a patch, you're just adding new functionality that is backwards compatible. ", "```suggestion\r\n  description = \"Additional environment variables for Hive metastore.\"\r\n```", "```suggestion\r\n## [6.15.0] - 2022-11-11\r\n```", "I think this part is not indented properly", "2 spaces less"]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/217", "comments": ["Should we increase this percentage? Is 60% a quantity we should worry about?", "Maybe adding `hms_ro_k8s_min_replica_count` instead of `hms_ro_k8s_replica_count`", "```suggestion\r\n## [6.13.0] - 2022-07-07\r\n```", "this is also used when autoscaling is not enabled, so named keeping that in mind.", "this is what we typically use so that metastore won't run with 80+ percentage, once we hit 80-90% metastore operation will slow down.\r\n\r\nwhat percentage do you recommend? ", "I do not know which is the avg percentage of the hm-ro, just wondering if setting a low percentage could mean that we are hitting this threshold much easier - so we are mostly at maximum capacity.\r\n\r\nBut if you think this is ok, let's just keep an eye in the deployment."]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/215", "comments": ["```suggestion\r\n## [6.12.3] - 2022-06-01\r\n```"]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/214", "comments": ["I set this explicitly to `false` on the RO HMS instance because I wasn't sure at what point a `create table` will fail on the RO HMS.  If it happens after stats gathering, then the default of `hive.stats.autogather=true` would just cause us to waste time and block threads.\r\n\r\nI'm happy to be talked out of it, though."]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/212", "comments": ["```suggestion\r\napiary_consumer_prefix_iamroles = {\r\n```"]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/210", "comments": ["```suggestion\r\n| rds\\_family | RDS Family | `string` | aurora5.6 | no | \r\n```\r\nThis way it will match what you put in `variables.tf`."]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/208", "comments": ["```suggestion\r\n  description = \"AWS IAM governance roles allowed read and tagging access to managed Apiary S3 buckets.\"\r\n```", "Need to add this new variable to `VARIABLES.md` also.", "I hate to be nitpicky, but we try to keep these in alphabetical order.  Can you move this line to just after line 14?", "Done", "```suggestion\r\n## [6.11.2] - 2021-11-12\r\n```"]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/205", "comments": ["this may pollute hive metastore logs as thrift doesn't like health check tcp connections. prom export agent runs on port 8080, alternative we can use that ...\r\n", "I am not sure I follow. I don't see anything unusual in the HMS logs specific for TCP connections. \r\n\r\nhttps://kubernetes-dashboard.egdl-eks-us-east-1.egdp-dev.aws.away.black/#/log/metastore/hms-readwrite-57684b6b-qpc4h/pod?namespace=metastore&container=hms-readwrite\r\n", "We can reduce the frequency to every 2-3 mins and see how that goes. We have 3 replicas, so we don't have to restart pods instantly.", "please add this to `VARIABLES.md` also.", "A couple of questions:\r\n\r\n1. Does this probe do anything more than a `telnet <host> 9083` does?  Does it just verify that the prober can connect to the port?\r\n2. When we have seen our HMS's lock up/go down, was connecting to port 9083 failing, or still working?\r\n\r\nI just want to understand if this will really catch the situation we are hoping to catch.", "It just opens a socket on port 9083: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#define-a-tcp-liveness-probe\r\n\r\nIt is hard to reproduce the issue in dev but when the issue was happening in prod couple of weeks back, I could not connect to it from the Hive CLI as that was timing out.\r\n", "In Dev, I killed the HMS service after logging in the pod and that did fail the liveness check and restarted it. Writing a custom health check probe which performs an actual query is ideal. Perhaps we can try this out and see if it helps improve the situation over the weekend, otherwise we can remove it on Monday.", "Done."]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/203", "comments": ["Based on how you set the `local.rw_ingress_cidr`, this variable is not required, and the default is `var.ingress_cidr`.\r\n```suggestion\r\n| rw_ingress_cidr | Read-Write metastore ingress CIDR list. | list | `var.ingress_cidr` | no |\r\n```", "```suggestion\r\n  description = \"Read-Write metastore ingress CIDR list. If not set, defaults to `var.ingress_cidr`.\"\r\n```"]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/198", "comments": ["I'm pretty sure if we set `hms_instance_type` to `ecs`, all references to `[0]` will fail with this error: https://github.com/hashicorp/terraform/issues/22480\r\n\r\nCan we just change them to `[count.index]`?", "If we are using `kiam`, will this annotation having a value of `\"\"` cause any issues?", "Do we always want to create the service accounts when using `k8s`, or only when we are not using `kiam`?", "Can we rename `k8s_namespace` to `metastore_namespace` or something more descriptive?", "should add to VARIABLES.md", "should add to VARIABLES.md", "Does this variable function as the toggle between using IRSA vs kiam?  I am assuming it does, but maybe a description in README.md or VARIABLES.md somewhere describing the two ways to do IAM in k8s would be good.", "creating service accounts when using kiam will not cause any issues, so creating always to keep terraform setup simpler, but we will also probably deprecate kiam as IRSA is working in clusters with Kiam", "tested this scenario, IAM using kiam is working as expected when eks.amazonaws.com/role-arn = \"\", but is not working if configure role as IRSA is overriding kiam", "added to Notes in README", "not sure if that is still happening with current version or setup, if so we probably need to fix it here\r\nhttps://github.com/ExpediaGroup/apiary-data-lake/blob/117749c6d50f8df83306d4f44c36ad305d558c20/k8s-readonly.tf#L70\r\nI will test `ecs` deployment mode in new island."]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/197", "comments": ["if `customer_condition` is empty, will `customer_principal` definitely be defined?", "no\r\nI switched to use nested if , all these policies wont be create if customer_principal is empty \r\nhttps://github.com/ExpediaGroup/apiary-data-lake/blob/bc750d59fbd45e8a69ebbf765d2effe51beb2139/templates/apiary-bucket-policy.json#L5\r\n", "Oh sorry, PR didn't show me that line.  I should have checked."]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/195", "comments": ["default value should be `true` for backward compatibility, we can override this in internal deployment.\r\n", "So, in case that I set this to true I think it will disallow the setting, which means that it won't be validated\r\nTrue -> No validation\r\nFalse -> Validation\r\n\r\nIs that what you want?", "I think it is opposite\r\ntrue -> hive will validate schema changes\r\nfalse -> hive won't validate schema changes", "Yes, I just checked and it's true, I just changed it :) "]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/193", "comments": ["I have it as 'OBJECT_TYPE' in my code, but I'll change it to 'type'", "variable is generic, we can use OBJECT_TYPE internally, above is just a example to show usage", "Oh this is in the README, didn't notice..."]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/190", "comments": ["How weird, thanks for the comment explaining this.", "Obviously needs an update."]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/189", "comments": ["The date will need updating.", "```suggestion\r\n- Added `DenyUnsecureCommunication` policy for `s3-other.tf` buckets.\r\n```", "Updated\r\n"]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/188", "comments": ["```suggestion\r\n  description = \"Time in seconds after which message will be deleted from the queue.\"\r\n```", "```suggestion\r\n| s3\\_logs\\_sqs\\_message\\_retention\\_seconds | Time in seconds after which message will be deleted from the queue. | `number` | `345600` | no |\r\n```"]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/187", "comments": ["```suggestion\r\n  description = \"Enable metastore NLB, Route53 entries VPC access and VPC endpoint services, for cross-account access.\"\r\n```", "Does the else of this ternary need to be `[]` instead of null or will setting null here result in k8s ignoring this entirely?", "Same question here:\r\n> Does the else of this ternary need to be [] instead of null or will setting null here result in k8s ignoring this entirely?", "Does this mean that if we don't have any endpoint services being created (because we don't have any customer_accounts defined), that we won't create the internal route53 records for HMS for the `.lcl` domain?  Why would we want to delete those?  We use those records all the time within the account itself.", "null essentiall will mean we are setting `load_balancer_source_ranges` , else I think k8s complains saying that `load_balancer_source_ranges ` invalid for ClusterIP type.", "Can you make the same documentation change to VARIABLES.md?", "this creates additional k8s loadbalancer, nlb, security group rules, route53 entires, we don't always use these and just configure services to use waggle-dance, same is case for analytics usecase currently, this is still enabled by default.\r\n\r\n", "Just so I understand, with this change, if `enable_vpc_endpoint_services` is `false`, then the HMS service type in K8S is `ClusterIP`, which means that the HMS will only be accessible from within the K8S cluster, correct?", "done", "correct, it will only create k8s internal service, which can be used with waggle-dance."]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/186", "comments": ["Is IAM ok with comma in the last item in a list?  I can never remember.\r\n```suggestion\r\n                \"arn:aws:s3:::${bucket_name}/*\"\r\n```"]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/181", "comments": ["```suggestion\r\n- Fix colliding Grafana dashboard names for multiple Apiary instances.\r\n```", "One small thing:\r\n```suggestion\r\n    panels         = \"[${join(\",\", data.template_file.grafana_graphs.*.rendered)}]\"\r\n    instance_alias = local.instance_alias\r\n```"]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/179", "comments": ["If someone wants to disable customer-account access for a particular schema, would it work to set `customer_accounts = \"\"`?  It appears as if it would, which would also be a nice feature.", "yes that should work!"]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/177", "comments": ["Can we also do this for our internal buckets like inventory, logs, etc?  Especially for inventory bucket, this would allow us to federate the inventory tables if we ever decide we want to.\r\n\r\nAlthough looking at the docs closer, it would rely on Amazon inventory process writing files with `bucket-owner-full-control` ACL for the object to get correct AWS owner.  Maybe we can set it in the hopes that AWS either does use that ACL, or will in the future.", "done for inventory bucket, other bucket should be written from same accounts"]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/171", "comments": ["This says S3 bucket will be deleted but docs above say S3 data won't be deleted so I'm a bit confused as to what it is. Also, why is this a list of maps and not of strings containing db names? What are the map keys and values?", "Good catch, thanks.  Originally I was going to delete the s3 buckets also, but after talking to Raj, decided it was better to never do automated deletion of actual data.  S3 data can be cleaned up manually if necessary.\r\n\r\nThe entry is a list of maps (instead of a list of strings) for two reasons:\r\n\r\n1.  So that entries from `apiary_managed_schemas` can be easily copy/pasted to this entry when schemas to delete are indentified.\r\n2. More importantly, it is a map to reserve the ability to add extra properties to each entry to control future delete-time functionality.", "Ack on the maps, I see you have documented that now too which makes it clearer as to why this type."]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/170", "comments": ["If we are going to allow this for `customer_principals`, seems like we should allow it further down for `producer_iamroles` too.", "This seems like a `6.4.3` to me.", "I'm ok with that. I couldn't decide since the specific tool we are doing this for isn't planned to be a producer, but I will add that. ", "Sounds good.", "I added that now, please review again @barnharts4.", "can we also add `s3:GetObjectAcl` ?", "Not sure about the workflow for releasing, but I went ahead and changed the date to today and put 6.4.3 in the version number here. Hope that's right."]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/166", "comments": ["Move `mysql-master-credentials` to secrets manager for mounting use in ECS.", "This piece gets a bit nebulous to me, i.e. if we aren't using an external database what should these secrets be?", "Can we rename `secret_seed_slug` to something more indicative of what it is?  `rds_master_password` or something?", "I would suggest increasing the complexity - maybe 12 or 16, and include special, upper, lower, etc.", "Channeling my inner @massdosage  - line break here, please. \ud83d\ude04 ", "If this is only created if `var.external_database_host == \"\"`, then is seems like lower down, the logic of launching the init container needs to change if `var.external_database_host == \"\"`.\r\n\r\nI agree, this all becomes a bit nebulous.  We need someone with more context on how external database host works to give feedback.", "So this actually isn't the secret, so maybe the name isn't clear enough \ud83d\ude05 . \r\nIt's just for appending to the name of the secret to deal w/ secrets_manager not being immediately deleted on `terraform destroy` runs. \r\ni.e. `db_master_credentials` becomes `db_master_credentials_<random_slug>` so we can delete and immediately recreate required resources w/o collision.  \r\n\r\nREF: https://docs.aws.amazon.com/secretsmanager/latest/userguide/manage_delete-restore-secret.html", "Ah, that makes sense.  So then the name is still confusing.  Maybe `secret_name_suffix` or something.  And a comment in the code that explains what it is for exactly as you did in the above comment.", "@rpoluri @massdosage could either of you provide more context on how this should be handled properly? (additionally run through a review of this PR when you have a few minutes \ud83d\ude05 )", "Sorry for the long delay in reply, this dropped off the edge of my TODO list. I'm afraid I don't know the answer, hopefully @rpoluri can comment?", "with external_database_host, assumption is we won't be managing DB and credentials, so we shouldn't be running the init container also.", "we should use `local.instance_alias` instead of `apiary_` to identify which instance this particular secret belongs to ", "can we make init container optional, to not run when using external_database_host", "same here, can we make this optional when using external_database_host?", "external is used when apiary terraform module in not managing database, so we shouldn't need this when using external database.", "probably can make this optional here by not including init container when using external database", "@barnharts4 @rpoluri \r\nThese changes should probably go first before this is merged so we can set the defaults here to something thats not TBD: https://github.com/ExpediaGroup/apiary-metastore-docker/pull/78"]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/164", "comments": ["Add a [closing line break](https://stackoverflow.com/questions/5813311/no-newline-at-end-of-file) to EOF please."]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/161", "comments": ["```suggestion\r\n  description = \"Apiary ${each.key} KMS key\"\r\n```", "Will this work for cross-account roles?  I imagine soon after this rolls out, someone will have a use-case to access the bucket cross-account.", "Now that the user of this module can specify the encryption type in the schema array, should we have some terraform code that validates it is one of the only two valid values - `AES256` or `aws:kms`?", "Or at the very least, make that clear in the documentation.", "in theory yes, but we may not have usecases to allow cross account access to KMS encrypted buckets as we will have little control on who is access the data one cross accounts access is allowed.", "good point, do you think adding as comment to example usage in README is sufficient?", "I think if it is in both the README, and in that line in VARIABLES.md that I pointed out, that should be sufficient.  If a user doesn't read at least one of those, they are going to have lots of other issues too. :)", "```suggestion\r\n| encryption | S3 objects encryption type, supported values are AES256,aws:kms. | string | null | no |\r\n```"]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/160", "comments": ["- `They will be updated on a scheduled basis signal the Hive metastore` - ???  Not sure what you mean by `signal`.\r\n- Actually, your other PR is `apiary-metastore-docker` version `1.15.0`.", "I really think that we should just use `ranger_policy_manager_url` as the criteria.   E.g.:\r\n```\r\n          env {\r\n            name  = \"ENABLE_RANGER_LOGS\"\r\n            value = var.ranger_policy_manager_url != \"\" ? \"1\" : \"\"\r\n          }\r\n```\r\netc.", "see my previous comment.  I don't think we need this variable.", "yes, agree, changing. ", "I'll try this and will update PR when I can make it work correctly", "This relies on us deciding on the name in the [other PR](https://github.com/ExpediaGroup/apiary-metastore-docker/pull/77) first...", "Add a [closing line break](https://stackoverflow.com/questions/5813311/no-newline-at-end-of-file) to EOF please.", "```suggestion\r\n- Create`system` database and buckets. This is pre-work for Ranger access logs Hive tables and other system data. Requires `apiary-metastore-docker` version `1.15.0` or above.\r\n```", "this line is unnecessary - count defaults to 1 if count is not specified.", "this line is unnecessary", "can you replace `_` with `-` for bucket name, s3 doesn't support `_` in bucket name", "```suggestion\r\n- Create `apiary_system` database and buckets. This is pre-work for Ranger access logs Hive tables and other system data. Requires `apiary-metastore-docker` version `1.15.0` or above.\r\n```", "bucket names can't have underscores, and the default value of `var.system_schema_name` is `apiary_system`.  You need to use TF `replace` function to turn `_` to `-`.   Look at line 20 of this file for an example.", "`count = 1` is still unnecessary", "unnecessary", "```suggestion\r\n- Create `apiary_system` database and buckets. This is pre-work for Ranger access logs Hive tables and other system data. Requires `apiary-metastore-docker` version `1.15.0` or above.\r\n```\r\nThis is the 3rd time I have made this suggestion.  Please commit it so we don't have embarrassing typos in our open-source documentation.", "Probably should put today's date here now, since this should be able to be released today."]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/159", "comments": ["```suggestion\r\n- Optional `customer_principal` and `producer_iamroles` in Apiary managed bucket policies.\r\n```"]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/158", "comments": ["Can you move it down a line so it's alphabetized?  Petty, I know. :)", "Do you find the new whitespace makes it easier to read the `merge()` args?  To me it's messier.", "What is the intent of this change?  For thse IAM roles, not allowing *any* actions (such as `List*`), seems overly punitive.  If people can't even see if their file was/wasn't created in the bucket correctly by listing the contents, it will just create more support incidents I would think.", "List still seems to works as that is a bucket operation instead of object, in this PR we are applying deny to bucket/*, which is only restricting access to objects.", "this is from terraform fmt command, my VI editor is setup to run `terraform fmt` on save :-)", "Wow, hashicorp needs to update `terraform fmt` to not mangle function args that badly. \ud83d\ude03 ", "Ah, ok.  I missed that.  Sounds good."]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/157", "comments": ["Just to make sure I understand - so this is based on how much ram has been assigned to the HMS, not what's available on the machine right? So if we assigned 4GB of RAM to the HMS we'd get ~2000 threads as the maximum? How did you decide on this link between the two values?", "This is actually based on how much ram as been assigned to the instance (be it EKS or ECS).  However, we give 90% of that ram to HMS (https://github.com/ExpediaGroup/apiary-metastore-docker/blob/master/files/startup.sh#L165-L168).\r\n\r\nAfter investigating on-prem HMS where we have 100K max threads configured, and after looking at this Apache Hive Jira (https://issues.apache.org/jira/browse/HIVE-8666), we decide it would be safe to dedicate up to 50% of the instance's ram to threads and connections when it is busy.  When it is not busy, the thread pool will shrink to the minimum size, which we are configuring at 1/4 of the max, or 12.5% of available ram.", "any reason this is removed?", "Doh!  copy/paste error.  Fixed."]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/151", "comments": ["you can have a `### Removed` section and put this line over there. Based on https://keepachangelog.com/en/1.0.0/.", "```suggestion\r\n * Copyright (C) 2018-2020 Expedia, Inc.\r\n```\r\n(yes, the comma is apparently important according to our legal team)", "```suggestion\r\n * Copyright (C) 2018-2020 Expedia, Inc.\r\n```", "```suggestion\r\n * Copyright (C) 2018-2020 Expedia, Inc.\r\n```", "```suggestion\r\n * Copyright (C) 2018-2020 Expedia, Inc.\r\n```", "```suggestion\r\n * Copyright (C) 2018-2020 Expedia, Inc.\r\n```", "```suggestion\r\n * Copyright (C) 2018-2020 Expedia, Inc.\r\n```", "```suggestion\r\n * Copyright (C) 2018-2020 Expedia, Inc.\r\n```", "```suggestion\r\n * Copyright (C) 2018-2020 Expedia, Inc.\r\n```", "```suggestion\r\n * Copyright (C) 2018-2020 Expedia, Inc.\r\n```\r\netc. for the rest below, seeing as we're updating the year we might as well fix the comma too.", "Done", "Done everywhere"]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/150", "comments": ["can we use `enable_data_events` instead of `enable_data_event_queue` as queue is only created once per datalake  instead of per schems.", "since we are creating a breaking change, can you we update these variables to use actual `bool` values `true/false`", "can we use `enable_data_events` and bool values `true/false`", "probably can update `enable_data_events` to use `bool` data type", "when we added this, discussed possibility of removing the variable and block public access by default, so we should be able remove `s3_block_public_access` variable and above condition as we are creating breaking change.", "do we still need these 3 variables? I see you are using schemas_info for some loops", "nice!!, simpler way to manage bucket names.\r\n\r\nmay be we can rename `replaced_name` as `resource_name/resource_suffix` ...etc as that is what we are using for.", "Currently, all the breaking changes I have created so far can be mitigated by running the migrate script, and the user doesn't have to do anything to their app code except update TF 0.12 version.\r\n\r\nChanging all the 0/1 variables to boolean would create real breaking changes that the migration script can't handle for the user.  Is that OK?  If so, I can make those changes.", "No, we can't use boolean.  Remember from our per-schema `tags` investigation that every key/value in the `apiary_managed_schemas` map *MUST* be a string, otherwise it doesn't work unless every possible key/value is specifically set by the caller.  Best we could do is to use \"true\" and \"false\" strings and then call `tobool` on them to cast.  Not sure that's any better, though, and may be also confusing.", "Same question as above - migration script can't handle this for user.  Is this OK?", "Same question as above - migration script can't handle this for user.  Is this OK?", "Yes, all three are being used in other places still that need to use either `join` on strings, or need to use `count` in their indexing.  I suppose in all places where they are used I could replace the reference to a `local` variable with the actual list comprehension code, but does that seem better to you?", "We already have `var.enable_data_events` for creating data notifications to SNS topics.  Are you suggesting we use the same named variable in the schema info map to trigger that schema to use SQS instead of SNS?  If that is what you are saying, won't that be confusing?", "Yes, I think `enable_data_events` still makesense, `enable_data_event_queue` implies we are going to create a queue per schema.\r\nor else,what do you think of `enable_data_events_sqs`", "ok makesense.", "generally, it is better to introduce breaking changes when updating major version. may we be can merge this change but not release, then create another PR with all breaking changes for variables.", "same as above, can address in another PR", "can also add in another PR", "Found a way to get rid of all 3 of those derived lists that didn't look clumsy so will remove them.", "Changed to `enable_data_event_queue`.", "@rpoluri - why is the `ecs_widgets` template created once per Apiary schema?   Seems like it should only be created once?", "done", "What is the number in the bucket?", "Good migration docs!", "Add a [closing line break](https://stackoverflow.com/questions/5813311/no-newline-at-end-of-file) to EOF please.", "is that * ok here ? ", "I was just following the IAM policy for the SNS topic: https://github.com/ExpediaGroup/apiary-data-lake/blob/master/sns.tf#L39\r\n\r\nHowever, you are right, I should probably tighten it up as per this doc: https://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html#grant-destinations-permissions-to-s3.  Will do.", "done", "Done", "I changed the example to a more generic one.", "Haha, I meant to change `enable_data_event_queue` to `enable_data_events_sqs` based on your PR comment, but through the magic of copy/paste errors, I changed it to exactly what it already was. :slightly_smiling_face: \r\n\r\nFixed now.", "yes, should be created only once."]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/147", "comments": ["```suggestion\r\n- Configuration to delete incomplete multi-part S3 uploads.\r\n```", "```suggestion\r\n| s3_lifecycle_abort_incomplete_multipart_upload_days | Number of days after which incomplete multipart uploads will be deleted. | string  | `7` | no |\r\n```", "```suggestion\r\n| tags | Additional tags added to the S3 data bucket. The map of tags must be encoded as a string using `jsonencode` (see sample above). If the `var.apiary_tags` collection and the tags passed to `apiary_managed_schemas` both contain the same tag name, the tag value passed to `apiary_managed_schemas` will be used. | string | null | no |\r\n```"]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/146", "comments": ["can you move this up a line, and clean up the indentation to line up all the maps being merged?", "You need to add a line here to document the new `tags` entry.", "Also add a valid `tags` line to the example invocation in the `apiary_managed_schemas` section.", "```suggestion\r\n| tags | Additional tags added to the S3 data bucket. If the `var.apiary_tags` collection and the tags passed to `apiary_managed_schemas` both contain the same tag name, the tag value passed to `apiary_managed_schemas` will be used. | map | null | no |\r\n```", "```suggestion\r\nNote: User must specify zero instances of tags in `apiary_managed_schemas`, or must add it for all the instances, with `tags={}` for instances where additional tags do not exist.\r\n```"]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/145", "comments": ["```suggestion\r\nvariable \"s3_bucket_expiry_days\" {\r\n```\r\nIs it possible to rename this so it's more descriptive?", "```suggestion\r\n  description = \"Number of days after which Apiary S3 buckets expire\"\r\n```\r\nDoes the bucket expire? Or do the objects within the bucket expire?", "Agree.  Should be something like `Number of days after which objects in the Apiary S3 buckets expire`", "I would suggest `s3_object_expiration_days`", "That's even better, yes.", "This is new functionality, not a bug fix, so should be `5.2.0`.", "If my understanding is correct, we want to configure this for certain buckets only (things like analyst sandbox, scratch areas, etc).  But from this line where it is added as a module variable, and then in `s3.tf` where it is used as the default value if `s3_object_expiration_days` is *not* configured in the `apiary_managed_schemas` list of maps, it seems like the user of this module could end up configuring a value for this variable that could wipe out all their bucket objects inadvertently after the timer expires.\r\n\r\nI am understanding this correctly?  If so, I strongly suggest we do NOT have an overall default value that is applied if the setting is not set on a per-bucket basis.  Was an overall default one of the requirements for this feature?", "See my previous comments where I don't think we should have an overall default value for this.", "Also, the above line documents the overall default variable `s3_object_expiration_days`.  But we also need documentation about setting it per-bucket.  Could you update the documentation for `apiary_managed_schemas` to expand it to documenting *ALL* fields that are allowed in each map entry of `apiary_managed_schemas` (see documentation for `apiary_assume_roles` in this same file for an example).  Please add a section to `VARIABLES.md` that completely documents `apiary_managed_schemas`.  Yes, I know adding all the documentation is outside the scope of adding this one feature, but the longer we neglect it, the more it gets impossible to understand what `apiary_managed_schemas` does.", "```suggestion\r\n| schema_name | Name of the S3 bucket. Full name will be `apiary_instance-aws_account-aws_region-schema_name`. | string | - | yes |\r\n```", "```suggestion\r\n| s3_lifecycle_policy_transition_period | Number of days for transition to a different storage class using lifecycle policy. | string | \"30\" | No |\r\n```", "```suggestion\r\n| s3_storage_class | Destination S3 storage class for transition in the lifecycle policy. | string | \"INTELLIGENT_TIERING\" | No |\r\n```", "```suggestion\r\n| s3_object_expiration_days | Number of days after which objects in Apiary managed schema buckets expire. | number | null | No\r\n```", "And it is now `2020-03-20`", "```suggestion\r\n- Documentation in `VARIABLES.md` for the `apiary_managed_schemas` variable.\r\n```", "This exact same line (106) should be added to the description for `apiary_managed_schemas` on line 13, along with a section link to this section (please do it the same way as `apiary_assume_roles`).\r\n\r\nAlso, this section comes alphabetically after `apiary_assume_roles`, so it should be moved below.", "Since you removed the variable from `variables.tf`, you need to remove this line too.", "```suggestion\r\n| apiary_managed_schemas | List of maps - each map entry describes an Apiary schema, along with S3 storage properties for the schema. See section [`apiary_managed_schemas`](#apiary_managed_schemas) for more info. | list(map) | - | no |\r\n```", "```suggestion\r\n| s3_storage_class | Destination S3 storage class for transition in the lifecycle policy. For valid values for S3 Storage classes, reference: https://www.terraform.io/docs/providers/aws/r/s3_bucket.html#storage_class | string | \"INTELLIGENT_TIERING\" | No |\r\n```", "The date will need updating obviously, rest looks good.", "```suggestion\r\n## [5.2.0] - 2020-03-23\r\n```"]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/143", "comments": ["we probably shoud create another inline policy and just add s3-inventory read permissions to both readwrite and readonly metastore,  we shouldn't have need for users to write to inventory bucket.", "What about the situation when a new deployment of S3 inventory is turned on? :\r\n\r\n1. Deploy `apiary-data-lake` with S3 inventory enabled.\r\n2. Terraform enables inventory for the apiary buckets, but nothing will run for up to 24 hours, so the inventory bucket is empty.\r\n3. HMS docker image starts up and tries to create the tables.  When the Hive `create table` statement is run, hive will see that the table folder doesn't yet exist in S3 and will try to create the `<tableName>_$folder$` object in the inventory bucket. <-- *This will fail w/o write permissions in IAM for R/W HMS*\r\n\r\nIs there a way around this while still keeping users from writing?  ", "Hacky, but could we pre-create that folder here? Hopefully there's a better way but...", "can we use readonly instead of readwrite?", "Metastore docker image now won't try to create the table until the data is written the first time by AWS, so scheduled job doesn't need write privs to bucket.", "do we need to add these variables to readwrite container? considering that we moved repair script to another job", "@rpoluri - I'm not sure if this is the correct role.  It worked in `egdp-dev`, but maybe it should be different?", "same here, do we need these?", "`readonly` worked fine and recreated the test inventory after I dropped it.", "Fixed.", "Fixed."]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/142", "comments": ["```suggestion\r\n- Variable to configure `apiary_assume_roles` cross-region S3 access.\r\n```", "\" a role that is created in this account\"\r\nDo we create the roles we find here or do we require them to already exist? (i.e. something else has created them before setting this). I think it's the latter, in which case I'd suggest rewording this to \"a role that exists in this account\" or \"a role that has already been created in this account\"", "Can we rename this to `max_role_session_duration_seconds` to match what I've seen AWS call it?", "```suggestion\r\n| name | Short name of the IAM role to be created.  Full name will be `apiary-<name>-<region>`. | string | - | yes |\r\n```", "We actually *do* create the roles that are listed here.", "will do", "```suggestion\r\n## [4.5.0] - TBD\r\n```\r\n(since you're adding a feature here not fixing a bug IMHO - NABD either way though)", "Don't you also want to mention the other added variable for controlling the role session duration?", "That feature was already there from a previous change.  I just added the documentation while I was making my change.  Was added in `4.0.0` on Oct 8, 2019.", "Ah, now that you put it that way should we go with a 5.0.0 version number since it's a user-facing backwards incompatible change?", "Done."]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/137", "comments": ["`apiary_logs_bucket` vs `apiary_log_bucket` is really confusing, especially since enabling one disables the other.  Can we use a more descriptive name?  Maybe something like `apiary_managed_logs_bucket` (or similar), and add to the CHANGELOG that it is only enabled if the customer does not supply their own logs bucket with the variable `apiary_log_bucket`?"]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/135", "comments": ["```suggestion\r\n- Added Prometheus scrape annotations to Kubernetes deployments.\r\n```", "What port is this and is it different to what it was before? (if so don't we need to document this in the CHANGELOG?)", "@massdosage - was wondering the same thing, so I did some digging in.  The k8s service definition already defined the thrift port `9083` as the port.  Adding it to the k8s deployment seems to be informational only, in the same vein as the docker `EXPOSE` directive.  https://medium.com/faun/should-i-configure-the-ports-in-kubernetes-deployment-c6b3817e495", "Added this as prometheus service disovery looks this port, then replaces with exporter port when exporter is running on different port.", "oh, interesting...  Thank you for the explanation.", "Thanks for the info."]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/134", "comments": ["We are kind of abusing this to contain both the server info and also something which is more like `kafka_events_enabled`. On the other hand it means one less thing to configure. I can live with it, we just to need to be clear that the other kafka variables don't turn Kafka events on, this one does. So we need to document that here (which you've done) and also that it contains the list of bootstrap servers (which is missing currently). Or we need to introduce another variable to turn the Kafka events on. Thoughts from others?", "In the apiary extension this is just \"TOPIC\", I'm happy to change it to \"TOPIC_NAME\" (just fyi)", "The Kafka listener also requires a client id to be provided (`KAFKA_CLIENT_ID`)\r\n", "@massdosage - I agree in theory, but we are also using config vars like `SNS_ARN`, `RANGER_POLICY_MANAGER_URL`, etc, to do the same things for other metastore features.   So this is consistent with the current code.  I am ok with keeping it this way, and when we decide on a better (more explicit) way of turning on/off these features, do it consistently across the code.", "Well, we already have `enable_gluesync`, `enable_metadata_events` and others so I'd argue having an enabled flag for this is actually *more* consistent with what we already have in this file?", "main difference between gluesync/sns and kafka is , we are not providing any service info, so just enable is sufficient for those cases.\r\n\r\nfor kafka and ranger we need to providing server info, if we add enable variable, we need 2 variables, which is redundant to accomplish the same.", "OK, so what is `enable_metadata_events` used for? From reading the description here I thought it was to enable the SNS listener?", "https://github.com/ExpediaGroup/apiary-data-lake/blob/master/k8s-readwrite.tf#L83\r\nwhen we set enable_metadata_events, SNS_ARN(managed by terraform) environment variable is passed on to docker container", "OK, fine, let's go with this for now. At some point we might decide to refactor to have a different/more consistent way of enabling/disabling features etc.", "saw change is made in apiary-extensions, so will keep this name."]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/131", "comments": ["Not sure about the next release date", "That's OK, we usually leave it blank or set it to `TBD` until just before we're ready to release and know the date (or we do a small separate PR which updates the version and date in thie file).", "This is probably a `4.2.0` release since (if I understand it correctly) it's a backwards-compatible new feature and not a bug fix.", "will do"]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/130", "comments": ["It looks like you are trying to get a unique `graph_id` for each bucket.  However, eventually `random_integer` could return the same value in this sequence.  If you only have to have them be unique to each other, you could just use `count.index` as the `graph_id`.  If they have to be unique to other things in the system (more Grafana graphs?), then could the id be a UUID?  Terraform has the `uuid()` function.", "should this alias also be `IntelligentTieringFAStorage`?", "This should be `4.1.0` since this is new functionality, not a bug release.", "How/where is this config map used?  I am not seeing the linkage.", "Are these dashboards only supposed to be created when Apiary metastores are running in k8s?  \r\n\r\nIf not, how does it work for ECS?\r\n\r\nIf so, then you need to constrain this resource to only be used in a k8s deployment with:\r\n     `count = \"${var.hms_instance_type == \"k8s\" ? 1 : 0}\"`", "What if someone is using this open-source module in a deployment where they don't have Grafana?  Should we be generating all this if there is no Grafana?", "`dashboard-test.json` seems like a very test-oriented filename.  Should probably be something more generic for production code.", "\ud83d\udc4d ", "\ud83d\udc4d ", "Raj would be the best person to ask this. I've pieced this solution together using other examples provided, but could never actually find how the config map is being consumed. I would like to answer this question as well! ", "\ud83d\udc4d  If they're using a config map, I'd assume so :) ", "How would we check if Grafana is running? \r\n\r\nI asked Raj a similar question (If users of apiary-data-lake haven't configured Datawatch as a source for Grafana, none of this will work), his opinion was that apiary-data-lake assumes a few things are in place, such as kubernetes provider, grafana is set up and is configured to pick up the config maps. ", "\ud83d\ude05  Didn't catch that after finishing testing. ", "That's true! I originally had a different solution that would increment the integer by one for every new graph. However, this is cumbersome since we are creating multiple graphs per bucket so we would have to change our tf for loop with the amount of graphs we want to create every time we add a graph.\r\n\r\nuuid would not work for this field as it needs to be an int. However, I it seems grafana may make it's own ID if this field is left null. Testing this now. ", "If you leave graph_id NULL, you can delete this `random_integer` resource.", "@rpoluri - can you comment here?  Where does this config map get used and what piece of code uses it?", "That didn't work. If we don't add an ID, grafana will not display the dashboard at all. I tried a few solutions and kept getting errors. \r\n\r\nSo, I reverted to the original solution I had, basically we will start with integer 100 for bucket graph ids (because we would like to allow graphs that are not created once per bucket but are general for all buckets which will have ids starting with 1) and will increment it by one for every other graph id. \r\n\r\nHowever, the major issue with this solution is that if we wanted to add a third graph per bucket to our dashboard, we will need to change not only the template file, but also the terraform itself:\r\n\r\nin grafana-dashboard.tf: \r\n`    graph_id = range(100, length(local.apiary_data_buckets) * 2, 2)[count.index]` \r\n\r\nThe reason why we multiply the length of apiary data buckets by two and skip every other integer is because we have two graphs per bucket in this dashboard. The template has these two ids for the two graphs: \r\n\r\n`      \"id\": ${graph_id},`\r\n`      \"id\": ${graph_id+1},`\r\n \r\nIf we wanted to add a new graph to this dashboard, in the template it will have `\"id\": ${graph_id+2},` and in the tf we will have to change the for loop to be `graph_id = range(100, length(local.apiary_data_buckets) * 3, 3)[count.index]`\r\n\r\nI originally thought this solution was a bit harder to understand and updating in the future would not be as straight forward. However, I also understand the point that the random integer can repeat itself which will make the dashboard miss one or more graphs. \r\n\r\nSo, what do you think is better, random integer or increasing for loop? Do you have a better solution for this? ", "To add for future reference what we discovered: \r\n\r\nlinkage is here: https://github.com/helm/charts/blob/master/stable/grafana/values.yaml#L447 and https://github.com/zpor/apiary-data-lake/blob/egdl-308-add-dashboard/grafana-dashboard.tf#L29 - label matches sidecar-configured label, so sidecar auto-reads it", "You will need to change this date to whenever this PR is merged and the repo tagged.", "Maybe add to this: `If deployed in EKS, a Grafana dashboard will be created that shows S3 bucket sizes for each Apiary bucket.`", "I think the for loop is the best solution - I certainly don't have a better one.  However, this probably needs documenting in the README, and instead of hardcoding `100` and `2`, you could define `local` variables at the top of `grafana_dashboard.tf` like:\r\n```\r\nlocals {\r\n   graph_id_base  = \"100\"\r\n   num_s3_graphs_per_bucket = \"2\"\r\n}\r\n```\r\nso that it is easy to find and modify those two values.", "datalake has lot of resources, can we `grafana_graphs` for this name?  so that it is clear in terraform plan output. ", "same here, can we use `grafana_dashboard` as name?", "typicially we use `_` in terraform resource names and `-` for AWS resources like S3 bucket names...etc.\r\nso can you use `grafana_dashboard` instead?", "Assumption is that when we are deploying k8s, evironment is setup accordingly. we can add this to k8s requirements.", "can we use `apiary-data-lake-dashboard` instead?", "similarly `apiary-data-lake-dashboard.json`", "can we rename this as grafana-dashboard.tpl?", "similarly can we rename this as grafana-graph.tpl?", "can we use `data.aws_region.current.name` to configure this instead of hardcoding?", "same here, can we use `data.aws_region.current.name`?", "same here, can we use data.aws_region.current.name", "data.aws_region.current.name", "\ud83d\udc4d  - I did this in a previous version and must have overwritten it at some point.", "@rpoluri  where are the requirements? Where should I add the grafana requirements? ", "Isn't this actually `number_of_graphs_per_bucket`?  I thought that is what this is being used for.", "Yes it is! "]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/129", "comments": ["All of the changes in this file _except_ for the above line were just to re-alphabetize the variables."]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/127", "comments": ["What is the value of this variable?  The name makes it sound like a boolean or a `1 / 0` but then you use the value of the TF variable to set the Environment variable, so I am confused.", "Also, wouldn't you need this in k8s-readonly.tf also?", "wouldn't this also be needed in `apiary-hms-readonly.json`?", "Need to update `VARIABLES.md` and `CHANGELOG.md` also.", "I guess since this is for DDL updates, this doesn't make sense on the RO endpoints, so never mind.", "I thought to send events to atlas, we ll only use readwrite endpoint. Correct me if I am wrong", "Yes", "No, you are correct - sorry.", "Yes I guess I may be just keep it as a boolean, though I dont know if there would be cases where we dont want hive to sync with atlas. I can change the name or value according to what the purpose would be", "Ok, after looking at https://github.com/ExpediaGroup/apiary-metastore-docker/blob/feature/EGDL-152/files/startup.sh#L87, this makes sense.  I just didn't know what the value of `ATLAS_HIVE_SYNC` was supposed to be - like a class name or something.", "I would rename this to `enable_atlas_hive_sync`", "I would rename this to `enable_atlas_hive_sync`", "In the `description`, maybe put something like `if this is set to any non-empty value, Kafka Metastore listener for Atlas will be enabled.`", "also better to name enable_atlas_hive_bridge, so not to confuse with internal hive sink", "Since you also changed the name of the env var passed to the docker image, are you also going to update https://github.com/ExpediaGroup/apiary-metastore-docker/blob/feature/EGDL-152/files/startup.sh#L87?  If not, I don't think this will work.", "Yes i have updated it already, there are a lot of changes on docker-metastore side so will create a PR for it shortly", "One too many full stops ;)", "fixed"]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/126", "comments": ["are the `root_vol_...` variables still needed with no EC2 support?", "removed these variables, can you check and approve again?"]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/124", "comments": ["Can you add these to `VARIABLES.md`?", "to be consistent with naming conventions above and to group related configuration could we rename this to `s3_enable_inventory`? And then move it above with the other s3 related variables.", "`s3_block_public_access`?", ":+1: "]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/122", "comments": ["We probably should tag the role with the `tags` array here.", "Do we want to keep this example here?", "moved to README", "Since you made this a different variable than `producer_iamroles`, is your intention that people can configure cross-account writes that either do `bucket-access-full-control` *or* do the `assume role`?  It doesn't seem like there's much of a use case for not assuming the role, except for backwards compat.\r\n\r\nIt almost seems to me like this new list should be part of the `producer_iamroles` variable, and if we need to differentiate between role assumption or not, have a boolean in the map that says whether or not to assume the role.", "If we leave this as two different apiary vars - `producer_iamroles` and `apiary_assume_roles`, somewhere there needs to be some documentation on what the difference is between the two, and the ramifications for one vs. the other.\r\n\r\nAlso, how do either of these two variables interact with `apiary_external_buckets`?  It looks like from the code that `apiary_external_buckets` have policy of basically allowing Apiary to do anything to those buckets, as long as it is all within the same account.  But are there any cross-account write permissions granted?  Should there be?\r\n\r\nSorry about all the questions, but it is getting hard to keep all this straight and configure this stuff.  I know that I get several questions from other groups any time they try to deploy Apiary.", "Planning to deprecate producer_iamroles as it is not working as expected, didn't want to add complexity by changing current variable behaviour", "external_buckets are usually managed by other teams, we are not trying to manage any aspect of external buckets other than allowing metastore IAM roles to read & write .", "ok"]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/121", "comments": ["Why do we need to hardcode `Name` tag here when we have the variable `apiary_tags` which can contain `Name` as one of the tags passed by the caller of this module ?", "As this module is in open-source, shouldn't we leave the choice of tags including the `Name` tag to the user ?", "`var.apiary_tags` are applied to multiple resources created by this module, and `Name` tag is unique to a resource, so we cannot pass a generic `Name` tag using the variable. \r\n\r\nThis is not hardcoding, just like any other variable, we are using `local.instance_alias` to apply appropriate tag.", "Alright. Perhaps `hardcode` was not the right word for it but thanks for the explanation !"]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/120", "comments": ["can you add this to 4.0.0? as that is not yet released", "done", "vpc -> VPC.\r\n\r\nPlease add a closing full stop."]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/116", "comments": ["Was someone having issues with only 2 instances of the ECS containers?", "we saw issues when waggle-dance and metastores end up in different physical AZs , this is to increase chance of both being in same physical AZ"]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/115", "comments": ["Do you mean \r\n\r\n> Support for configuring read-only HMS with Ranger audit-only mode\r\n\r\n ?", "Haha, yes!  That's what I get for doing this on Friday evening. :)", "Are all these new variables optional?", "Yes.  All these vars were previously passed into the read-write HMS ECS template (as either blank/not-set when Ranger is not configured, or with appropriate values for Ranger).  This code is just also now passing them into the read-only ECS template so that read-only HMS can use Ranger for auditing (if Ranger is configured)."]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/114", "comments": ["Is `m5.large` really the default keypair name?", "In line #37 above, should `ecs` be removed from the name of the role since that will just cause confusion if `ecs` mode is off?", "also in the next role too.", "`ecs` shouldn't be part of the name.", "`ecs` shouldn't be part of the name.", "good catch, will update.", "yes, ideally we should change ecs-task-readwrite to hms-readwrite, this will cause some resources to be recreated when we update existing deployment, if others are ok with the change, will update accordingly.\r\n\r\n", "`Support for running metastore in EC2 nodes` --> `Support for running metastore running Hive Metastore on EC2 nodes.`", "`voluem ` --> `volume`", "maybe we get latest Amazon AMI using data source otherwise users can choose centos, debian, redhat and packages maynot work as expected?", "maybe just use the Amazon AMI on which Ansible scripts are tested.", "can you run `terraform fmt` ?", "`hive metastore` --> `Hive Metastore`", "we should remove this variable.", "we are already using datasource to get latest AMI, this is to override default image.", "most of environment use custom AMIs to ensure security agents are installed, so this will be needed. we just need to provide a requirement to use Amazon Linux based image.", "@pradeepbhadani @mroark1m any comment on this?", "Small typo on 'Hiv Metastore', should be 'Hive Metastore'.", "I don't have an issue with it. I wonder if it may fail to deploy cleanly on existing deployments. Because even once the task is updated, the old task will still exist using the old role until ECS gets finished with it's deployment cycle, and so if it has to do create/destroy to update the name, it may balk at doing the destroy. I think that might just mean we have to run it twice? Not sure...", "I agree with Raj's reasoning on this... probably we are going to need it.", "terraform was able to make change without issue after adding following lifecycle block to IAM role, otherwise everything seems to work fine.\r\n+  lifecycle {\r\n+    create_before_destroy = true\r\n+  }", "I will update roles accordingly.", "I suggest to keep the IAM roles separate as it is a short term limited fix.", "`2018` --> `2018 - 2019`", "this will expose the password in ansible playbook.yml?", "Can you install `nc` or `telnet` as well?", "`.` at the end", "`metastore` --> `Hive Metastore`", "`metastore` --> `Hive Metastore`", "`metastore` --> `Hive Metastore`", "Can you make this optional as this is only required when the mode is not `ecs`.", "can you make this optional too", "i thought of the same, but just adds duplicate code, we need to attach same iam policies to both roles, with current setup, we just need to allow both services(ecs&ec2) assume the policy.", "it adds duplication but if we are going to remove this workaround later than it could help.\r\nAlso, Please do not rename the existing task role name as this may break the access to our external buckets (we use explicit Deny and allow to this IAM role).", "can you provide details? what is the issue if we change the role name? we are controlling external buckets access from the role itself. "]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/109", "comments": ["I realize I\u2019m late to the game, but don\u2019t you need to add the `\u2014region` flag to the `aws secretsmanager` command that is getting the `MYSQL_USER` value too?", "ahh..nice catch.\r\nsomehow it worked as expected but will raise another PR to make it consistent.", "@barnharts4  - new PR https://github.com/ExpediaGroup/apiary-data-lake/pull/110"]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/107", "comments": ["this looks weird is this what @mroark1m was talking about that should be merged with 2.0.0? Are we actually going to have a 1.1.0 release?"]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/106", "comments": ["Please format this as the other files are formatted. You can run `terraform fmt` on your project to format all the files in the consistent manner.", "sure, thanks ", "why `apiary_apiary`?\r\nAlso, how does this achieve the same functionality of replacing `_` with `-`?", "can you please add `type`?", "`default_s3_storage_class` --> `s3_storage_class`", "`default_s3_lifecycle_policy_transition_period` --> `s3_lifecycle_policy_transition_period`", "can you please add `type`?", "Sure", "Okay, I added default as its the default value if user doesnt provide one. I will change it to s3_storage_class \ud83d\udc4d ", "\ud83d\udc4d ", "Sure", "How would they provide one other than this? There is no mechanism for it. Can they override it somehow at a per-bucket level?", "Will it be possible to specify additional lifecycle rules per bucket? If we want to specify retention rules at a table level within a schema bucket, can we do that?", "var.apiary_managed_schemas and local.apiary_managed_schemas were being used for different purpose. local.apiary_managed_schemas for S3 bucket creation.\r\n\r\nso you need 2 local variables, probably apiary_managed_schemas_original, apiary_managed_schemas_replaced \r\n\r\nand you can use following for apiary_managed_schemas_replaced  template.\r\nreplace(lookup(var.apiary_managed_schemas[count.index], \"schema_name\"),\"_\",\"-\") in the template", "Okay sure, I will make the above change", "Yes so s3_storage_class and no_of_days can be configured when users deploy apiary-datalake by specifying something in variables like this\r\nmanaged_schemas = [\r\n    {\r\n        schema_name = \"dm\"\r\n        s3_storage_class = \"INTELLIGENT_TIERING\"\r\n        s3_lifecycle_policy_transition_period = \"50\"\r\n    },\r\n    {\r\n        schema_name = \"test\"\r\n        s3_lifecycle_policy_transition_period = \"30\"\r\n    },\r\n    {\r\n        schema_name = \"ads\"\r\n    }\r\n]\r\n\r\nIf these variables are not provided, then we ll use the default values. ", "We can re-use the block of managed_schemas mentioned above to specify any additional parameters like retention rules and configure it in the bucket policy.", "Ah, I see. Thanks @spuranda123!", "Could you please add `.` at the end?", "and while we're being pedantic change s3 to S3 :)", "This should also go under the \"Added\" section below so there is only one.", "See https://keepachangelog.com/en/1.0.0/ if you haven't worked with this file type before.", "s3 storage -> S3 storage \r\nno of days -> number of days", "I see the type has changed here. What are the keys and values in the map? Also, is this a backwards incompatible change for end users? If so the version number should go to 2.0.0 and we should clearly mention this change in the CHANGELOG so users migrating know what they would need to do when they upgrade.", "No -> Number", "s3 -> S3\r\nIs there an AWS document we can link to that lists all the valid values for this string? If not, can we list the valid values here then?", "Sure, making those changes", "\ud83d\udc4d ", "Hey where is a good place to add the valid keys and values in the map? This change is backward incompatible ", "This should be local.apiary_managed_schema_names_original as we are checking to see if a hive database is in shared list.", "same here, should be local.apiary_managed_schema_names_original", "This should be local.apiary_managed_schema_names_replaced as we use `-` to create AWS resource instead of `_`", "should be local.apiary_managed_schema_names_replaced"]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/103", "comments": ["we may not need this change.", "same here, container wont need to read docker credentials?", "@rpoluri  - we may need later if we ever need to fetch some binaries from artifactory from docker container.\r\nif you think we may not need this in near future then i can remove this.", "we shouldn't be doing this, instead containers should be just replaced.", "@rpoluri  updated PR", "removed this. updated PR"]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/100", "comments": ["`tag` --> `Tag`"]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/99", "comments": ["Worth mentioning that this will work with `apiary-metastore-docker > v1.0.1`?", "apiary-metastore-docker version is yet to be created, we can update this when releasing new version."]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/87", "comments": ["how removing this code is related to `shared_schema` ?", "To match schema access configuration same as S3 buckets.\r\nSince access to read-only metastore access is primarily controlled at account level, in practice this makes it simpler, so that we don't have to know which AD groups are users coming in through read-only metastore part of.\r\n\r\n", "okay."]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/77", "comments": ["`EntireBucket` --> `entire-bucket` ?", "EntireBucket is the name used by AWS for default metrics configuration.\r\nusing anything else will create new configuration instead of updating existing one.\r\n"]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/74", "comments": ["this should be optional and we should be able to provide a password from the secret manager.", "reading individual elements from secretmanager makes it complicated as terraform natively doesn't support json.\r\n\r\nAlso master user is only need for aurora DB setup, from my opinion providing option master user is not a requirement/need.\r\n\r\nIf you feel like it is needed you can create PR for this later.\r\n", "`secretsmanager ` --> `secretsmanager-ro`", "`secretsmanager ` --> `secretsmanager-rw`", "this is already qualified by role name? this is to just identify what kind of policy is that, why do we need this?", "same here", "`.` at the end", "`.` at the end", "`.` at the end", "Add additional variables detail here", "okay. I thought it is going to name the policy.", "We decided to use the master_username as RW user some point. so thought of passing from the secret manager. \r\nWe should store this secret somewhere so that in case we need then we can retrieve the password.\r\n\r\nand yes, I agree terraform don't support json so it's a bit complicated.", "can you use RW username instead?\r\n\r\nyou can retrieve master username from state file, can also reset without impacting anything else if you don't use master username else where.", "done.", "I can use RW username but I was highlighting this as we discussed in past to use master user for RW operation."]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/73", "comments": ["The values don't need to change?", "values are just internal references, no that imporant, but will update anyway.", "Might as well do this one too?", "and here?\r\n\r\n(minor, just thought it might be good to be consistent)"]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/70", "comments": ["metastore  -> Metastore ", "metastore  -> Metastore ", "`Enable sending metastore metrics to CloudWatch.` --> `Enable sending Hive Metastore metrics to CloudWatch.`", "`metastore` --> `Hive Metastore`", "maybe we rename this variable as `enable_metastore_metrics` or `enable_hive_metastore_metrics` because `enable_metrics` is generic and lead to confusion in future if we add support of metrics for any other component.\r\n@rpoluri @massdosage @mroark1m  thoughts?", "Agreed. `enable_hive_metastore_metrics ` gets my vote."]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/64", "comments": ["aws -> AWS", "You start the other \"Description\"s with an uppercase letter so you should do the same here, similar for many below so the table is consistent.", "Similar, be consistent referring to Apiary (not \"apiary\")", "s3 -> S3 etc.", "aws iam -> AWS IAM, apiary -> Apiary, s3 -> S3 etc. (apply below too, I won't call them all out)", "What are the key and the value in the map?", "seperated -> separated", "I don't understand this one, do you mean if the size of the data (if so, which data?) in S3 exceeds this? What is it measured in (bytes?)", "The days to retain backups for, for the rds metastore. -> Number of days to retain metastore RDS backups for", "remove the closing \".\" (or add them to all, as long as it's consistent across all the Descriptions).", "rds -> RDS etc below too.", "hive cli -> Hive CLI", "Measured in what unit? Seconds?", "Link these through to the relevant sub-module in apiary-extensions - i.e. https://github.com/ExpediaInc/apiary-extensions/tree/master/apiary-gluesync-listener", "hive -> Hive, sns -> SNS", "As above, also provide a link to https://github.com/ExpediaInc/apiary-extensions/tree/master/apiary-metastore-listener  for more info", "apiary,but -> Apiary, but", "mysql -> MySQL", "docker -> Docker (same applies below)", "What are the valid values for this? The standard sfl4j levels?", "RO -> read only\r\n\r\nApplies below too", "RW -> read/write\r\n\r\nand below", "cane -> can ", "cane -> can", "cidr -> CIDR", "multi instance -> multi-instance", "LDAP, DN etc.", "LDAP, URL, Hadoop etc.", "Solr", "Vault", "Remove additional \"", "@rpoluri @pradeepbhadani The default value here previously was actually 10TB in bytes, but the documentation said 1TB. I'm not sure which is correct. I've made the change to the number of bytes to be 1TB but perhaps the change needs to be the other way around? I'm also not clear from reading this what S3 bucket size this is actually watching to trigger an alert, can someone please clarify.", "As far as I can tell this is unused.\r\n\r\n```\r\nsh-3.2$ grep -r -i apiary_s3_alarm_threshold *\r\nvariables.tf:variable \"apiary_s3_alarm_threshold\" {\r\nsh-3.2$\r\n``` \r\n", "yes It is currently unused.\r\nThis was originally added to configure storage utilization alerts on S3 buckets, removed corresponding cloudwatch alert when added support for external buckets.", "We should remove it then.", "Please refer **to**", "removed", "updated."]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/61", "comments": ["OK, so this is the varaiable referred to in the other PR, so now I see where it comes from, but why do we need it? What would a typical value for this be? The changes look reasonable I just want to make sure I understand what's going on here.", "@massdosage  this variable will allow passing the value of `-path` flag in `vault login` command.  This value can differ depends on vault setup in accounts."]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/55", "comments": ["Can we prefix this and the next one with MYSQL_ too? That way all MySql related environment variables are consistently named."]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/51", "comments": ["There are quite a few grammar and other small things I'd like to change but it would be a lot faster if I just edited the file directly rather than putting lots of comments. @rpoluri are you OK with me doing that?", "@massdosage , yes you can edit file directly. Thanks!"]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/49", "comments": ["We only put dates into the CHANGELOG right before we do a release, otherwise they get out of date (like has just happened here).", "removed date in changelog"]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/37", "comments": ["Shall we restrict resources based on Tag?", "@pradeepbhadani I don't see any way to restrict resource for PutMetricData. Other three actions are all readonly actions, not sure if it matters for those?\r\n\r\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazoncloudwatch.html#amazoncloudwatch-resources-for-iam-policies\r\n", "merging this PR, I also didn't find anyway to restrict this, we can open another issue if we need to tweak."]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/27", "comments": ["I think producer may need `PutObjectAcl` to transfer ownership ?"]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/13", "comments": ["worth adding `copy_tags_to_snapshot = true`. This will copy tags to snapshots and makes easy to identify.", "@pradeepbhadani I'll create a new PR for copy_tags_to_snapshot = true. "]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/12", "comments": ["It might be more compact to list all the buckets in one policy than to create a policy for every bucket. The limit on inline policies is 10240 chars in aggregate.\r\n\r\nBut I'm fine with using this as-is for now, and then we can refactor it later to do that.", "this is configured to use \"count\", so will add separate entry for each bucket.\r\nname  = \"external-s3-data-for-ec2-${count.index}\"\r\n", "What I understand is there will be a separate named inline policy for each bucket, with repetition of the content of the policy (apart from the bucket name itself). If we have 3 buckets we will have 3 inline policies, with names: external-s3-data-for-ec2-0, external-s3-data-for-ec2-1, and external-s3-data-for-ec2-2\r\n\r\nThe content of each of those policies is mostly the same, only the bucket name changes. The overall limit on all inline policies in a single role, in aggregate, is 10240 characters, so the repetition of the policy template part will count against those 10240 characters in each instance of the policy.\r\n\r\nI think it's fine for now and I would just merge this as-is, just pointing out that a more compact representation would be to have a single inline policy with all the buckets in it in a single statement. That will be less character repetition and the overall inline policy character count would be shorter.", "ok, I didn't know that limitation, yes we can refactor to make it optimal.", "We can refactor later to pass the bucket names via variable and put in the policy\r\n"]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/6", "comments": ["Having \"sg-\" in the name for security groups is an item in our naming standards. I don't feel very strongly about it though... CC @pradeepbhadani is this rule important to you?", "same note here on security group naming.", "terraform is failing when security group starts with \"sg-\", looks like that is AWS restriction.", "Hmmm that's interesting. I guess I see now that it's meant to be the 'Name' tag, not the 'Group Name', they are two different things. Confusing because on an EC2 instance, the 'name' and the Name tag always change together.\r\n\r\nSince we use a variable for the tags, this doesn't seem to apply anyway. I will approve this without change.", "What timezone are these in?", "these are in UTC, pushed a new commit to use variable for this.", "Can you run `terraform fmt` ?", "Can you add timezone description here?", "done.", "done."]}, {"url": "https://github.com/ExpediaGroup/apiary-data-lake/pull/4", "comments": ["This file is supposed to be an exact copy of https://www.apache.org/licenses/LICENSE-2.0.txt and shouldn't be changed in any way so please put this back.", "done"]}]}, {"url": "https://github.com/mjedrasz/ttd-terraform-v2.git", "pull_requests": []}, {"url": "https://github.com/nmaupu/auto-gcp.git", "pull_requests": []}, {"url": "https://github.com/jenkins-infra/aws.git", "pull_requests": [{"url": "https://github.com/jenkins-infra/aws/pull/507", "comments": ["```\r\n# module.cik8s.aws_eks_addon.this[\"coredns\"] will be updated in-place\r\n  ~ resource \"aws_eks_addon\" \"this\" {\r\n      ~ addon_version     = \"v1.9.3-eksbuild.9\" -> \"v1.9.3-eksbuild.11\"\r\n\r\n# ...\r\nPlan: 0 to add, 1 to change, 0 to destroy.\r\n```\r\n\r\n\r\nLooks like we forgot one to upgrade manually: Infra as code is really cool!"]}, {"url": "https://github.com/jenkins-infra/aws/pull/473", "comments": ["Note: to be deleted manually (tracked in https://github.com/jenkins-infra/helpdesk/issues/3662#issuecomment-1770472278)", "Note: to be deleted manually (tracked in https://github.com/jenkins-infra/helpdesk/issues/3662#issuecomment-1770472278)"]}, {"url": "https://github.com/jenkins-infra/aws/pull/395", "comments": ["Note: used for stashes. You can also configure S3 to automatically delete old blobs according to various policies.\r\n\r\n(Should this have been in `ci_jenkins_io_artifacts_objects`? Not obvious to me why there are two policy documents.)", "The 2 policies documents are for 2 \"layers\":\r\n\r\n- The first is for the IAM permissions (e.g. AWS API permissions) and needs to be restricted to the S3 bucket's ARN (as we don't want ci.jenkins.io to see other buckets if any)\r\n- The 2nd is a S3 policy level (e.g. inside the 2S api itself)\r\n\r\n\r\nBoth were required to not have an HTTP/403 error (first one was catcheable in the general configuration, the 2nd one when the real stash/unstash operation happenned). I guess it's because of https://aws.amazon.com/blogs/aws/heads-up-amazon-s3-security-changes-are-coming-in-april-of-2023/"]}, {"url": "https://github.com/jenkins-infra/aws/pull/362", "comments": ["do we only every run 1 pod per node at the same time?\r\n\r\nor is this volume per pod?", "You're right, there might be multiple pods running at the same time on the same node, I don't know how much though.", "As it's for volumes mounted as `emptyDir`, all of them would compete for the available space on each node, AFAIK there is nothing in that case ensuring they'll get a reserved space.", "As we run 3 pods per nodes, that means we need at least 69 Gb for the emptyDir in current state.\r\nIf you had the system space (+ docker images and other emptyDirs), that means ~ 90 Gb is needed.", "```suggestion\r\n            volume_size           = 90 # With 3 pods / machine, that can use ~25 Gb each at the same time (`emptyDir`)\r\n```"]}, {"url": "https://github.com/jenkins-infra/aws/pull/331", "comments": ["Maybe add a \"why\" here?"]}, {"url": "https://github.com/jenkins-infra/aws/pull/261", "comments": ["Where is this variable used exactly?\r\n\r\n(ref. https://github.com/jenkins-infra/aws/pull/261/files#diff-49b6dfd157f2e0513e99f20fea69f13b7ef66d1007b5555b44994848543b7edaR9 :) )", "I don't see it in the docs, just the mention they must be declared:\r\n\r\n<img width=\"1078\" alt=\"image\" src=\"https://user-images.githubusercontent.com/91831478/195845261-587b6b96-1922-4c78-b73e-d96f4e81b36e.png\">\r\n", "In the context of this documentation (screenshot), \"variables\" means \"child module's variables\": https://www.terraform.io/language/modules/syntax#calling-a-child-module .\r\n\r\nSo `vars.azs` is the input attribute `azs = <...>` that I linked earlier, which is set to the value from a data source.", "> that I linked earlier\r\n\r\nAh OK\r\nYour link returned nothing particular (no line selected nothing)", ">  Your link returned nothing particular (no line selected nothing)\r\n\r\nMy bad. Here is the link: https://github.com/jenkins-infra/aws/blob/main/vpc.tf#L9"]}, {"url": "https://github.com/jenkins-infra/aws/pull/259", "comments": ["\ud83d\udc4d "]}, {"url": "https://github.com/jenkins-infra/aws/pull/250", "comments": ["```suggestion\r\n      # This worker pool is expected to host the \"technical\" services (such as the autoscaler, the load balancer controller, etc.) and the public services like artifact-caching-proxy\r\n```"]}, {"url": "https://github.com/jenkins-infra/aws/pull/236", "comments": ["```suggestion\r\n    title: Bump `hashicorp-tools` docker image version to {{ source \"dockerHashicorpToolsImageVersion\" }}\r\n```"]}, {"url": "https://github.com/jenkins-infra/aws/pull/232", "comments": ["```suggestion\r\n## TODO: Proceed to renaming\r\n# module \"eks_iam_assumable_role_autoscaler_eks\" {\r\nmodule \"eks_iam_role_autoscaler\" {\r\n```\r\n\r\nRenaming will destroy the actual mapping and create a new one.\r\nWDYT about keeping this PR focused on eks-public (and defering the renaming when we'll rename the current cluster cik8s)"]}, {"url": "https://github.com/jenkins-infra/aws/pull/229", "comments": ["Should we try it with these \"v\"?"]}, {"url": "https://github.com/jenkins-infra/aws/pull/226", "comments": ["These are the additional lines of this PR in complement of the revert of #224 "]}, {"url": "https://github.com/jenkins-infra/aws/pull/218", "comments": ["```suggestion\r\n    # https://github.com/kubernetes-sigs/aws-load-balancer-controller/issues/2462\r\n    ingress_allow_access_from_control_plane = {\r\n```", "```suggestion\r\n  subnet_ids      = module.vpc.private_subnets\r\n```\r\nTesting on a new cluster locally before merging.", "cleaned in an incoming commit.", "The keepers should allow renewing the name each new cluster.", "```suggestion\r\n```", "```suggestion\r\n```", "```suggestion\r\n  # both the public and private subnets must be tagged with the cluster name(s) \r\n  # https://kubernetes-sigs.github.io/aws-load-balancer-controller/v2.4/deploy/subnet_discovery/#common-tag\r\n  tags = {\r\n```", "nitpick: We keep the block here to pin the version but we'll have to do https://github.com/jenkins-infra/aws/issues/221", "(but outside this PR)", "```suggestion\r\n```", "nitpick: not sure of the value of moving it to a local (as it's the only ocurence)", "Moved here as it's a value we'll probably want to change.\r\n\r\nSet to 2 as the vpc-cni didn't had enough resources with only one node to be installed.", "nitpick: https://github.com/jenkins-infra/aws/issues/222", "As I understood it, variables to be modified should be in locals.tf or variables.tf so you know what are the actionables.", "@hervelemeur not blocking here but I find confusing that the variable says \"service account\" while in this line, it is not a Kubernetes service account but an AWS IAM role (which has to be mapped to this service account).\r\n\r\nUsing the same value is useful though!", "@dduportal I had the same thought, any suggestion for a better name?", "```suggestion\r\n      max_size             = 2 # Allow manual scaling when running operations or upgrades\r\n```", "```suggestion\r\n```", "```suggestion\r\n  nlb_account_name             = \"aws-load-balancer-controller\"\r\n```", "`nlb_account_name` (discussed the 3 of us)"]}, {"url": "https://github.com/jenkins-infra/aws/pull/207", "comments": ["- Should be in the `providers.tf`\r\n- The file `.terraform.lock.hcl` need to be updated to pin the current version of this new provider (you can check the log of the Terraform plan in the CI check (`Finding hashicorp/kubernetes versions matching \">= 2.10.0\"`)"]}, {"url": "https://github.com/jenkins-infra/aws/pull/201", "comments": ["```suggestion\r\nname: Bump `aws-load-balancer-controller` version and IAM policy content\r\n```", "```suggestion\r\n    kind: githubrelease\r\n    name: \"Retrieve the latest version\"\r\n```", "Can you test it please? In this context, YAML consider the string as literal, so the backticks *might* be important", "Nice,  in that context, the double quotes makes sense \ud83d\udc4d "]}, {"url": "https://github.com/jenkins-infra/aws/pull/200", "comments": ["Could you remove this file from the PR?\r\n\r\nBecause its content mentions binaries that are darwin/amd64. Not a problem as terraform , in the CI, would override it, but it would ease the code review :)\r\n\r\nWorst case, next updatecli PR will override.", "Don't forget to track this with updatecli (like it's done for the other cluster). WDYT about an upcoming PR (to avoid failing checks)?", "Is it correct?\r\nThat's the point I'm not sure, reusing the existing public subnets or recreating new ones.", "that looks fine, you are correct: we want this cluster to have private IPs for its pods and Kube-services in these subnets.\r\n\r\nWhy multiple subnets? Because a given VPC spans across different availability zones.", "I've kept only this one and get rid of the jnlp one", "```suggestion\r\n# Reference the existing user for administrating the charts from github.com/jenkins-infra/kubernetes-management\r\n```\r\nThis repo I suppose?", "I'm not sure about [which machine](https://aws.amazon.com/ec2/instance-types/) we should use.\r\n\r\nI've first thought about the T4g serie but I don't see a difference in term of CPU credits compared to the others.\r\n> [Amazon EC2 T4g instances](https://aws.amazon.com/ec2/instance-types/t4/) are powered by Arm-based custom built AWS Graviton2 processors and deliver up to 40% better price performance over T3 instances for a broad set of burstable general purpose workloads.", "```suggestion\r\n      max_size             = 10 # Allow manual scaling when running operations or upgrades\r\n```\r\nWDYT?", "As discussed together, let's start with a `a1.xlarge` which is cheaper (`$0.102`), less memory but twice the network bandwitdh (useful for I/O), but the CPU is a older though.\r\n\r\n- https://aws.amazon.com/fr/ec2/instance-types/a1/\r\n- https://aws.amazon.com/ec2/instance-types/", "I would keep as it until we need more."]}, {"url": "https://github.com/jenkins-infra/aws/pull/188", "comments": ["```suggestion\r\n  version                       = \"5.3.2\"\r\n```"]}, {"url": "https://github.com/jenkins-infra/aws/pull/133", "comments": ["```suggestion\r\n@Library('pipeline-library@pull/342/head') _\r\n```"]}, {"url": "https://github.com/jenkins-infra/aws/pull/121", "comments": ["```suggestion\r\n      matchpattern: 'jenkinsciinfra/hashicorp-tools:(.*)'\r\n      replacepattern: 'jenkinsciinfra/hashicorp-tools:{{ source `dockerHashicorpToolsImageVersion` }}'\r\n```\r\nThere is no tedious replacement needed here, no need for block scalar."]}, {"url": "https://github.com/jenkins-infra/aws/pull/77", "comments": ["```suggestion\r\n      \"20.72.105.159/32\" # temp-privatek8s AKS cluster outside IP\r\n```"]}, {"url": "https://github.com/jenkins-infra/aws/pull/61", "comments": ["```suggestion\r\n    - name: jnlp\r\n```"]}, {"url": "https://github.com/jenkins-infra/aws/pull/59", "comments": ["```suggestion\r\n      if (env.BRANCH_IS_PRIMARY) {\r\n```", "Note to self for later: accept also an env var defined locally, like `SHARED_TOOLS_DIRECTORY`", "```suggestion\r\n* Run the command `make --directory=.shared-tools/terraform validate` again to ensure that your changes are OK\r\n```", "how would you use it? Except `make --directory=\"${SHARED_TOOLS_DIRECTORY}\" help` ?", "Nevermind, mistake from my part."]}, {"url": "https://github.com/jenkins-infra/aws/pull/57", "comments": ["Specified to use a specific pipeline library version I presume?", "absolutely, and then remove on the main branch afterward.\r\nIt allowed to test https://github.com/jenkins-infra/pipeline-library/pull/252/ before merging it.\r\n\r\nThe exit code 137 we had on infra.ci was due to the pod being OOM killed"]}, {"url": "https://github.com/jenkins-infra/aws/pull/4", "comments": ["Reverse logic so that we destroy unless `DISABLE_DESTROY` is non-empty\r\n```suggestion\r\n\tif os.Getenv(\"DISABLE_DESTROY\") == \"\" {\r\n```", "Consider renaming a variable for clarity\r\n```suggestion\r\n\ttf_output_cluster_id := terraform.Output(t, terraformOptions, \"cluster_id\")\r\n\tassert.NotEqual(t, \"\", tf_output_cluster_id)\r\n```", "```suggestion\r\n\t// Run \"terraform init\" and \"terraform plan\". Fail the test if there are any errors.\r\n```", "```suggestion\r\nif (env.BRANCH_NAME == 'main' && !currentBuild.getBuildCauses('hudson.triggers.TimerTrigger$TimerTriggerCause')) {\r\n```", "Wouldn't it be better to use `H H * * *`", "I've copy-and-pasted from a pipeline of mine, and I realize that we can even use the `@daily` notation to make it easier to read (because cron syntax is the not the most user friendly syntax of this world...). Thanks!", "```suggestion\r\n    cron(env.CHANGE_ID || env.TAG_NAME ? '' : '@daily')\r\n```"]}, {"url": "https://github.com/jenkins-infra/aws/pull/1", "comments": ["Newbie question here: what is the reason of using a PVC instead of a local volume?", "Newbie questions:\r\n- Is the `kubernetes` block can be defined on top-pipeline level to spawn the pod 1 time, and each stage might specify a different container of the pod to run inside?\r\n- If I provide a `Dockerfile` to provide a custom and reproducible build environment (with the exact tooling I need: `terraform`, `tfsec`, etc.), what would be the pattern to use it with k8s agents?"]}]}, {"url": "https://github.com/DataBiosphere/gitlab-in-google.git", "pull_requests": [{"url": "https://github.com/DataBiosphere/gitlab-in-google/pull/1", "comments": ["What's the meaning of the suffix?", "No meaning, just makes it unique since I want to reuse the name in other accounts and google bucket names need to be globally unique."]}]}, {"url": "https://github.com/eddiez0719/jenkins-ecs-terraform.git", "pull_requests": []}, {"url": "https://github.com/rbabyuk/terra.git", "pull_requests": []}, {"url": "https://github.com/vtirumani/terragoat-bc-test.git", "pull_requests": []}, {"url": "https://github.com/scaffoldly-demo/scaffoldly-bootstrap.git", "pull_requests": []}, {"url": "https://github.com/utilitywarehouse/system-terraform-modules.git", "pull_requests": []}, {"url": "https://github.com/ministryofjustice/hmpps-delius-core-terraform.git", "pull_requests": [{"url": "https://github.com/ministryofjustice/hmpps-delius-core-terraform/pull/611", "comments": ["Why do we need to shorten the idle timeout period?"]}, {"url": "https://github.com/ministryofjustice/hmpps-delius-core-terraform/pull/576", "comments": ["Should this be:\r\n```suggestion\r\n    SENTRY_DSN                     = \"/${var.environment_name}/${var.project_name}/probation-integration/community-api/sentry-dsn\"\r\n```"]}, {"url": "https://github.com/ministryofjustice/hmpps-delius-core-terraform/pull/423", "comments": ["```suggestion\r\n```\r\n\r\nAlready defined here: https://github.com/ministryofjustice/hmpps-delius-core-terraform/blob/master/security-groups/delius-db-in.tf#L191"]}, {"url": "https://github.com/ministryofjustice/hmpps-delius-core-terraform/pull/421", "comments": ["Worth uncommenting this now?", "agreed, have uncommented"]}, {"url": "https://github.com/ministryofjustice/hmpps-delius-core-terraform/pull/375", "comments": ["Can we get some of these vars from terraform, as this .js file is templated in [data.tf](https://github.com/ministryofjustice/hmpps-delius-core-terraform/pull/375/files#diff-1a4d37934355f9821b17b6af88e2d578R97-R105)?\r\n```suggestion\r\n    let logsPath = \"https://eu-west-2.console.aws.amazon.com/cloudwatch/home?region=eu-west-2#logsV2:log-groups/log-group/$252Faws$252Flambda$252F${lambda_name}\";\r\n```", "Can we get some of these vars from terraform, as this .js file is templated in [data.tf](https://github.com/ministryofjustice/hmpps-delius-core-terraform/pull/375/files#diff-1a4d37934355f9821b17b6af88e2d578R97-R105)?\r\n```suggestion\r\n    environment_name=\"${environment_name}\";\r\n```", "I've added the environment variable into Lambda as we know it at deploy time.", "added this line to get environment_name from Env Vars"]}, {"url": "https://github.com/ministryofjustice/hmpps-delius-core-terraform/pull/295", "comments": ["Perhaps this should be namespaces? \"delius_core_monitoring_ lambda_runtime\", as this might be needed elsewhere - unless we update all to use same?", "or we could have a map", "Looks good to me... afaik, each component has it's own lambda and variables so I'm not sure it matters greatly whether it's `lambda_runtime` or `delius_core_monitoring_lambda_runtime`.  Conversely, if delius-core ever creates another nodejs lambda for something else, then perhaps `delius_core_lambda_runtime` is a more apt name"]}, {"url": "https://github.com/ministryofjustice/hmpps-delius-core-terraform/pull/278", "comments": ["did you meant to leave this here?", "that's the value of a PR! Noo"]}, {"url": "https://github.com/ministryofjustice/hmpps-delius-core-terraform/pull/259", "comments": ["Do we have support for this yet in the LDAP server configuration?", "Yep, see https://github.com/ministryofjustice/hmpps-delius-core-ldap-bootstrap/pull/5"]}, {"url": "https://github.com/ministryofjustice/hmpps-delius-core-terraform/pull/201", "comments": ["ideally Python3.x "]}, {"url": "https://github.com/ministryofjustice/hmpps-delius-core-terraform/pull/195", "comments": ["do LBs need to have access to themselves? ", "do LBs need to have access to themselves? ", "this is to support inter-LB communication, we have the same SGs applied to the HAProxy LB and the ALB so this allows them to talk to each other", "ahh ok that makes sense now!"]}, {"url": "https://github.com/ministryofjustice/hmpps-delius-core-terraform/pull/177", "comments": ["I'd say these would be better as env vars as you probably don't want them scaling to the same degree in sandpit as prod", "env var again for me", "env vars", "env vars"]}, {"url": "https://github.com/ministryofjustice/hmpps-delius-core-terraform/pull/163", "comments": ["This is redundant, the users role takes care of this.", "Should this be removed? Do we want to leave the default users (ec2-user or centos) on?", "needs a parameter\r\ngroup_vars/${bastion_inventory}.yml", "Removed", "According to Brett, the users_deleted part of the users role breaks on the ECS AMI - so recommendation was to remove it from the users.yml file", "Added bastion_inventory var", "a that would make sense. A comment to explain this would be useful for those coming along later :)\r\n"]}, {"url": "https://github.com/ministryofjustice/hmpps-delius-core-terraform/pull/139", "comments": ["was account number needs to be a var"]}, {"url": "https://github.com/ministryofjustice/hmpps-delius-core-terraform/pull/126", "comments": ["\r\n\"${data.terraform_remote_state.s3-ldap-backups.s3_ldap_backups.name}\"", "updated"]}, {"url": "https://github.com/ministryofjustice/hmpps-delius-core-terraform/pull/120", "comments": ["Nice comment, very useful."]}, {"url": "https://github.com/ministryofjustice/hmpps-delius-core-terraform/pull/92", "comments": ["This needs to be enclosed in a \"locals\" block.\r\nhttps://www.terraform.io/docs/configuration/locals.html", "This isn't necessary when previous comment attended to."]}, {"url": "https://github.com/ministryofjustice/hmpps-delius-core-terraform/pull/85", "comments": ["should this not be a variable?", "not in this case. it's a value which can't be derived from env config but is required for the DB module. This file is where the property is set."]}, {"url": "https://github.com/ministryofjustice/hmpps-delius-core-terraform/pull/66", "comments": ["We have a load balancer module, consider refactoring this to consume it"]}, {"url": "https://github.com/ministryofjustice/hmpps-delius-core-terraform/pull/41", "comments": ["don't need jq\r\n"]}, {"url": "https://github.com/ministryofjustice/hmpps-delius-core-terraform/pull/39", "comments": ["is this ingress or egress?"]}, {"url": "https://github.com/ministryofjustice/hmpps-delius-core-terraform/pull/16", "comments": ["Won't work until we're merged into master\r\n\r\nPleas use `HMPPS Delius-Core OracleDB *` for now"]}, {"url": "https://github.com/ministryofjustice/hmpps-delius-core-terraform/pull/13", "comments": ["use master please, this ami is the same thing and may be a bit faulty", "done"]}, {"url": "https://github.com/ministryofjustice/hmpps-delius-core-terraform/pull/3", "comments": ["Is it?", "Delius?"]}]}, {"url": "https://github.com/wellcomecollection/goobi-infrastructure.git", "pull_requests": [{"url": "https://github.com/wellcomecollection/goobi-infrastructure/pull/454", "comments": ["unrelated to the AMI change, but a good thing to change"]}, {"url": "https://github.com/wellcomecollection/goobi-infrastructure/pull/397", "comments": ["I think we should start without provisioned mode and see how performance turns out. This adds extra cost and can easily be modified later."]}, {"url": "https://github.com/wellcomecollection/goobi-infrastructure/pull/389", "comments": ["We have modules to do autoscaling already: https://github.com/wellcomecollection/catalogue/blob/master/infrastructure/modules/worker/main.tf#L33\r\n\r\nIf those work for you i'd prefer we re-use them, but i'm also happy if you find the `umotif-public` one easier to work with.", "The `umotif-public` autoscaling module allows us to use custom metrics with the `metric_query`. As we wanted to use the number of visible messages in the job queue for scaling out and back in, I used the `umotif-public` module."]}, {"url": "https://github.com/wellcomecollection/goobi-infrastructure/pull/319", "comments": ["You might want to to turn this into a `var`.", "instance_type and key_name are variables now, defaulting to those values."]}, {"url": "https://github.com/wellcomecollection/goobi-infrastructure/pull/273", "comments": ["As I understand it these shellservers do different things.\r\n\r\nIt might be worth commenting what each is for here, as on the surface it appears that you could have one of these with task count set to 4 (though I think that is not possible as these services are actually heterogenous).", "You might be able to create a module and abstract a bunch of this boilerplate away, save copypasting 4 times.", "\ud83d\udc4f ", "It would be more pleasing if there could a single module and two instantiations (one for each environment). Though I think I remember someone saying that wasn't an option as the two envs were to be different\r\n\r\nIt would be nice if they were as similar as possible as expressed through a single module with perhaps options for scaling services as appropriate for an env.", "yes, each shellserver handles different jobtypes. We will get rid of the shellservers alltogether and repace them with auto-scaling worker nodes. This however should not be tested in production, so we needed the staging environment first.\r\n\r\nI added comments to the shellservers so it should be more clear why we need more of them", "As mentioned above, we will get rid of the shellservers some time in the future. After that, we will have the single module with two instantiations", "We might want to leave out the AWS backup stuff in the staging system completely. These resources might collide with the production ones actually.", "removed the backup from staging ", "rename it to workflow-stage oder -staging maybe?", "This one is already defined in the prod stack, could be added as data {} here", "renamed"]}, {"url": "https://github.com/wellcomecollection/goobi-infrastructure/pull/10", "comments": ["This either needs:\r\n\r\n* `git diff --exit-code` so it fails the build, or\r\n* auto-commit and push to the PR", "\ud83d\udc4d "]}, {"url": "https://github.com/wellcomecollection/goobi-infrastructure/pull/1", "comments": ["Minor: might be nice to define this as an `aws_iam_policy_document`, because who wants to write JSON?\r\n\r\nExample here, I\u2019m aware we\u2019re not super consistent about it in the platform repo. https://github.com/wellcometrust/terraform-modules/blob/d13903d0ec359e6e980f2cc7dbcc1260d6e47a79/autoscaling/app/ecs/iam.tf#L1-L10", "I agree. Going to leave this open for @mgeerdsen to have a look."]}]}, {"url": "https://github.com/Leonard-Ta/Sample-Security-service-Terraform.git", "pull_requests": []}, {"url": "https://github.com/git0510/tf-repo.git", "pull_requests": []}, {"url": "https://github.com/dwp/dataworks-aws-bgdc-interface.git", "pull_requests": [{"url": "https://github.com/dwp/dataworks-aws-bgdc-interface/pull/59", "comments": ["Since this is going to production [?] its worth removing these resources entirely rather than commenting them out else it can cause confusion", "Perhaps puts these into variables rather than hard coding?", "Perhaps puts these into variables rather than hard coding?", "This name has underscores where as other resources have names with dashes in. Can we keep this consistent so its easier for when people refer to remote states", "This name has dashes where as other resources have names with underscores in. Can we keep this consistent so its easier for when people refer to remote states", "Something with a more meaningful name that \"lb\". Again, in case people refer to remote states, this won't be clear.", "empty lines to remove.", "Its best practice to stick outputs into an outputs.tf, that way contributors know where to look for the outputs of this terraform code."]}, {"url": "https://github.com/dwp/dataworks-aws-bgdc-interface/pull/34", "comments": ["I was told that it might be best to keep all the SG rules for this with the provider of the service.\r\nSo inside internal compute. But regardless it should work anyway as the rules are correct", "We use this pattern of inserting SG rules remotely a lot as it follows the principle of layered, rather than circular dependencies between repos."]}, {"url": "https://github.com/dwp/dataworks-aws-bgdc-interface/pull/10", "comments": ["is that suppose to be a link at the end?", "another missing link?"]}]}, {"url": "https://github.com/cqa01/tf.git", "pull_requests": []}, {"url": "https://github.com/portefaix/portefaix.git", "pull_requests": [{"url": "https://github.com/portefaix/portefaix-kubernetes/pull/2714", "comments": ["tfsec check aws-ssm-secret-use-customer-key failed. \n\nDescription: Secret explicitly uses the default key.\n\nSeverity: LOW\n\nFor more information, see:\n\n- https://aquasecurity.github.io/tfsec/v1.27.1/checks/aws/ssm/secret-use-customer-key/\n- https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/secretsmanager_secret#kms_key_id\n"]}, {"url": "https://github.com/portefaix/portefaix-kubernetes/pull/1767", "comments": ["<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L4161-L4253\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L4161-L4253\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L4161-L4253\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4161-L4253\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4161-L4253\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4161-L4253\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L4161-L4253\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure securityContext is applied to pods and containers</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_43</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: <image>\n+   securityContext:\n```\n\n<h4>Description</h4>\n**securityContext** defines privilege and access control settings for your pod or container, and holds security configurations that will be applied to a container. Some fields are present in both **securityContext** and **PodSecurityContext**,  when both are set, **securityContext** takes precedence. \n\nWell-defined privilege and access control settings will enhance assurance that your pod is running with the properties it requires to function.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure securityContext is applied to pods and containers</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_43</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: <image>\n+   securityContext:\n```\n\n<h4>Description</h4>\n**securityContext** defines privilege and access control settings for your pod or container, and holds security configurations that will be applied to a container. Some fields are present in both **securityContext** and **PodSecurityContext**,  when both are set, **securityContext** takes precedence. \n\nWell-defined privilege and access control settings will enhance assurance that your pod is running with the properties it requires to function.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L4161-L4253\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L4161-L4253\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure securityContext is applied to pods and containers</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_43</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: <image>\n+   securityContext:\n```\n\n<h4>Description</h4>\n**securityContext** defines privilege and access control settings for your pod or container, and holds security configurations that will be applied to a container. Some fields are present in both **securityContext** and **PodSecurityContext**,  when both are set, **securityContext** takes precedence. \n\nWell-defined privilege and access control settings will enhance assurance that your pod is running with the properties it requires to function.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L4161-L4253\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L4161-L4253\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure securityContext is applied to pods and containers</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_43</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: <image>\n+   securityContext:\n```\n\n<h4>Description</h4>\n**securityContext** defines privilege and access control settings for your pod or container, and holds security configurations that will be applied to a container. Some fields are present in both **securityContext** and **PodSecurityContext**,  when both are set, **securityContext** takes precedence. \n\nWell-defined privilege and access control settings will enhance assurance that your pod is running with the properties it requires to function.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L4161-L4253\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L4161-L4253\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L4161-L4253\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L4161-L4253\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4161-L4253\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>"]}, {"url": "https://github.com/portefaix/portefaix-kubernetes/pull/1764", "comments": ["<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.1/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3997-L4081\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.1/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3914-L3996\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.1/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3914-L3996\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.1/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4082-L4169\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.1/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3914-L3996\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.1/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4170-L4265\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.1/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3997-L4081\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.1/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4082-L4169\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.1/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3997-L4081\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.1/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4170-L4265\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure securityContext is applied to pods and containers</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.1/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4082-L4169\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_43</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: <image>\n+   securityContext:\n```\n\n<h4>Description</h4>\n**securityContext** defines privilege and access control settings for your pod or container, and holds security configurations that will be applied to a container. Some fields are present in both **securityContext** and **PodSecurityContext**,  when both are set, **securityContext** takes precedence. \n\nWell-defined privilege and access control settings will enhance assurance that your pod is running with the properties it requires to function.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.1/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3914-L3996\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure securityContext is applied to pods and containers</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.1/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3914-L3996\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_43</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: <image>\n+   securityContext:\n```\n\n<h4>Description</h4>\n**securityContext** defines privilege and access control settings for your pod or container, and holds security configurations that will be applied to a container. Some fields are present in both **securityContext** and **PodSecurityContext**,  when both are set, **securityContext** takes precedence. \n\nWell-defined privilege and access control settings will enhance assurance that your pod is running with the properties it requires to function.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.1/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4082-L4169\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.1/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3997-L4081\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.1/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4082-L4169\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.1/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3914-L3996\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.1/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4170-L4265\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.1/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3997-L4081\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.1/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4170-L4265\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.1/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4170-L4265\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.1/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4082-L4169\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>"]}, {"url": "https://github.com/portefaix/portefaix-kubernetes/pull/1753", "comments": ["<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure securityContext is applied to pods and containers</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_43</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: <image>\n+   securityContext:\n```\n\n<h4>Description</h4>\n**securityContext** defines privilege and access control settings for your pod or container, and holds security configurations that will be applied to a container. Some fields are present in both **securityContext** and **PodSecurityContext**,  when both are set, **securityContext** takes precedence. \n\nWell-defined privilege and access control settings will enhance assurance that your pod is running with the properties it requires to function.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/medium.svg\" alt=\"MEDIUM\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Minimize wildcard use in Roles and ClusterRoles</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L3721-L3801\">ClusterRole.default.crd-controller-flux-system</a> |  ID: <code>BC_K8S_107</code>\n            <br></summary>\n<h4>Description</h4>\nTBD\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure securityContext is applied to pods and containers</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_43</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: <image>\n+   securityContext:\n```\n\n<h4>Description</h4>\n**securityContext** defines privilege and access control settings for your pod or container, and holds security configurations that will be applied to a container. Some fields are present in both **securityContext** and **PodSecurityContext**,  when both are set, **securityContext** takes precedence. \n\nWell-defined privilege and access control settings will enhance assurance that your pod is running with the properties it requires to function.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L4161-L4253\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/medium.svg\" alt=\"MEDIUM\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Minimize wildcard use in Roles and ClusterRoles</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L3721-L3801\">ClusterRole.default.crd-controller-flux-system</a> |  ID: <code>BC_K8S_107</code>\n            <br></summary>\n<h4>Description</h4>\nTBD\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L4161-L4253\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L4161-L4253\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure securityContext is applied to pods and containers</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_43</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: <image>\n+   securityContext:\n```\n\n<h4>Description</h4>\n**securityContext** defines privilege and access control settings for your pod or container, and holds security configurations that will be applied to a container. Some fields are present in both **securityContext** and **PodSecurityContext**,  when both are set, **securityContext** takes precedence. \n\nWell-defined privilege and access control settings will enhance assurance that your pod is running with the properties it requires to function.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L4161-L4253\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L4161-L4253\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L4161-L4253\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L4161-L4253\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/medium.svg\" alt=\"MEDIUM\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Minimize wildcard use in Roles and ClusterRoles</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3721-L3801\">ClusterRole.default.crd-controller-flux-system</a> |  ID: <code>BC_K8S_107</code>\n            <br></summary>\n<h4>Description</h4>\nTBD\n</details>"]}, {"url": "https://github.com/portefaix/portefaix-kubernetes/pull/1752", "comments": ["<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.1/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3997-L4081\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.1/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3997-L4081\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.1/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4170-L4265\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure securityContext is applied to pods and containers</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.1/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4082-L4169\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_43</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: <image>\n+   securityContext:\n```\n\n<h4>Description</h4>\n**securityContext** defines privilege and access control settings for your pod or container, and holds security configurations that will be applied to a container. Some fields are present in both **securityContext** and **PodSecurityContext**,  when both are set, **securityContext** takes precedence. \n\nWell-defined privilege and access control settings will enhance assurance that your pod is running with the properties it requires to function.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.1/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4170-L4265\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.1/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4170-L4265\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.1/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3997-L4081\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.1/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3914-L3996\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.1/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4082-L4169\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.1/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3914-L3996\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.1/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3997-L4081\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.1/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4082-L4169\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure securityContext is applied to pods and containers</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.1/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3914-L3996\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_43</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: <image>\n+   securityContext:\n```\n\n<h4>Description</h4>\n**securityContext** defines privilege and access control settings for your pod or container, and holds security configurations that will be applied to a container. Some fields are present in both **securityContext** and **PodSecurityContext**,  when both are set, **securityContext** takes precedence. \n\nWell-defined privilege and access control settings will enhance assurance that your pod is running with the properties it requires to function.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.1/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3914-L3996\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.1/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3997-L4081\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.1/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3914-L3996\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.1/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3914-L3996\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.1/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4082-L4169\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.1/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4082-L4169\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.1/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4082-L4169\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.1/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4170-L4265\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.1/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4170-L4265\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/medium.svg\" alt=\"MEDIUM\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Minimize wildcard use in Roles and ClusterRoles</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.1/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3721-L3801\">ClusterRole.default.crd-controller-flux-system</a> |  ID: <code>BC_K8S_107</code>\n            <br></summary>\n<h4>Description</h4>\nTBD\n</details>"]}, {"url": "https://github.com/portefaix/portefaix-kubernetes/pull/1751", "comments": ["<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-aws-v0.26.1/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-aws-v0.26.1/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure securityContext is applied to pods and containers</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-aws-v0.26.1/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_43</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: <image>\n+   securityContext:\n```\n\n<h4>Description</h4>\n**securityContext** defines privilege and access control settings for your pod or container, and holds security configurations that will be applied to a container. Some fields are present in both **securityContext** and **PodSecurityContext**,  when both are set, **securityContext** takes precedence. \n\nWell-defined privilege and access control settings will enhance assurance that your pod is running with the properties it requires to function.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure securityContext is applied to pods and containers</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-aws-v0.26.1/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_43</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: <image>\n+   securityContext:\n```\n\n<h4>Description</h4>\n**securityContext** defines privilege and access control settings for your pod or container, and holds security configurations that will be applied to a container. Some fields are present in both **securityContext** and **PodSecurityContext**,  when both are set, **securityContext** takes precedence. \n\nWell-defined privilege and access control settings will enhance assurance that your pod is running with the properties it requires to function.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-aws-v0.26.1/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L4161-L4252\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-aws-v0.26.1/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-aws-v0.26.1/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-aws-v0.26.1/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-aws-v0.26.1/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-aws-v0.26.1/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-aws-v0.26.1/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-aws-v0.26.1/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-aws-v0.26.1/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-aws-v0.26.1/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L4161-L4252\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/medium.svg\" alt=\"MEDIUM\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Minimize wildcard use in Roles and ClusterRoles</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-aws-v0.26.1/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L3721-L3801\">ClusterRole.default.crd-controller-flux-system</a> |  ID: <code>BC_K8S_107</code>\n            <br></summary>\n<h4>Description</h4>\nTBD\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-aws-v0.26.1/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L4161-L4252\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-aws-v0.26.1/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L4161-L4252\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-aws-v0.26.1/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-aws-v0.26.1/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L4161-L4252\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-aws-v0.26.1/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-aws-v0.26.1/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-aws-v0.26.1/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-aws-v0.26.1/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>"]}, {"url": "https://github.com/portefaix/portefaix-kubernetes/pull/1750", "comments": ["<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-azure-v0.26.1/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-azure-v0.26.1/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure securityContext is applied to pods and containers</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-azure-v0.26.1/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_43</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: <image>\n+   securityContext:\n```\n\n<h4>Description</h4>\n**securityContext** defines privilege and access control settings for your pod or container, and holds security configurations that will be applied to a container. Some fields are present in both **securityContext** and **PodSecurityContext**,  when both are set, **securityContext** takes precedence. \n\nWell-defined privilege and access control settings will enhance assurance that your pod is running with the properties it requires to function.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-azure-v0.26.1/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-azure-v0.26.1/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-azure-v0.26.1/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L4161-L4252\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-azure-v0.26.1/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L4161-L4252\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/medium.svg\" alt=\"MEDIUM\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Minimize wildcard use in Roles and ClusterRoles</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-azure-v0.26.1/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L3721-L3801\">ClusterRole.default.crd-controller-flux-system</a> |  ID: <code>BC_K8S_107</code>\n            <br></summary>\n<h4>Description</h4>\nTBD\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure securityContext is applied to pods and containers</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-azure-v0.26.1/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_43</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: <image>\n+   securityContext:\n```\n\n<h4>Description</h4>\n**securityContext** defines privilege and access control settings for your pod or container, and holds security configurations that will be applied to a container. Some fields are present in both **securityContext** and **PodSecurityContext**,  when both are set, **securityContext** takes precedence. \n\nWell-defined privilege and access control settings will enhance assurance that your pod is running with the properties it requires to function.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-azure-v0.26.1/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-azure-v0.26.1/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-azure-v0.26.1/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-azure-v0.26.1/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L4161-L4252\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-azure-v0.26.1/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-azure-v0.26.1/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-azure-v0.26.1/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-azure-v0.26.1/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-azure-v0.26.1/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-azure-v0.26.1/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-azure-v0.26.1/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L4161-L4252\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-azure-v0.26.1/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-azure-v0.26.1/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-azure-v0.26.1/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L4161-L4252\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>"]}, {"url": "https://github.com/portefaix/portefaix-kubernetes/pull/1749", "comments": ["<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-gcp-v0.26.1/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-gcp-v0.26.1/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-gcp-v0.26.1/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L4161-L4252\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-gcp-v0.26.1/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L4161-L4252\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-gcp-v0.26.1/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure securityContext is applied to pods and containers</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-gcp-v0.26.1/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_43</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: <image>\n+   securityContext:\n```\n\n<h4>Description</h4>\n**securityContext** defines privilege and access control settings for your pod or container, and holds security configurations that will be applied to a container. Some fields are present in both **securityContext** and **PodSecurityContext**,  when both are set, **securityContext** takes precedence. \n\nWell-defined privilege and access control settings will enhance assurance that your pod is running with the properties it requires to function.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-gcp-v0.26.1/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-gcp-v0.26.1/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-gcp-v0.26.1/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-gcp-v0.26.1/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-gcp-v0.26.1/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure securityContext is applied to pods and containers</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-gcp-v0.26.1/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_43</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: <image>\n+   securityContext:\n```\n\n<h4>Description</h4>\n**securityContext** defines privilege and access control settings for your pod or container, and holds security configurations that will be applied to a container. Some fields are present in both **securityContext** and **PodSecurityContext**,  when both are set, **securityContext** takes precedence. \n\nWell-defined privilege and access control settings will enhance assurance that your pod is running with the properties it requires to function.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-gcp-v0.26.1/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-gcp-v0.26.1/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/medium.svg\" alt=\"MEDIUM\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Minimize wildcard use in Roles and ClusterRoles</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-gcp-v0.26.1/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L3721-L3801\">ClusterRole.default.crd-controller-flux-system</a> |  ID: <code>BC_K8S_107</code>\n            <br></summary>\n<h4>Description</h4>\nTBD\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-gcp-v0.26.1/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-gcp-v0.26.1/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-gcp-v0.26.1/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L4161-L4252\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-gcp-v0.26.1/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L4161-L4252\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-gcp-v0.26.1/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-gcp-v0.26.1/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-gcp-v0.26.1/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-gcp-v0.26.1/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L4161-L4252\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>"]}, {"url": "https://github.com/portefaix/portefaix-kubernetes/pull/1733", "comments": ["<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.0/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4082-L4169\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.0/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4082-L4169\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.0/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4170-L4265\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.0/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3997-L4081\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.0/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3914-L3996\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.0/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4082-L4169\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.0/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4170-L4265\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.0/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3914-L3996\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.0/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3914-L3996\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.0/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3914-L3996\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.0/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4170-L4265\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.0/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3997-L4081\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.0/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4082-L4169\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.0/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4170-L4265\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.0/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3997-L4081\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.0/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3997-L4081\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.0/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3914-L3996\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.0/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3997-L4081\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.0/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4170-L4265\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure securityContext is applied to pods and containers</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.0/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3914-L3996\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_43</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: <image>\n+   securityContext:\n```\n\n<h4>Description</h4>\n**securityContext** defines privilege and access control settings for your pod or container, and holds security configurations that will be applied to a container. Some fields are present in both **securityContext** and **PodSecurityContext**,  when both are set, **securityContext** takes precedence. \n\nWell-defined privilege and access control settings will enhance assurance that your pod is running with the properties it requires to function.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.0/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4082-L4169\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure securityContext is applied to pods and containers</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.0/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4082-L4169\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_43</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: <image>\n+   securityContext:\n```\n\n<h4>Description</h4>\n**securityContext** defines privilege and access control settings for your pod or container, and holds security configurations that will be applied to a container. Some fields are present in both **securityContext** and **PodSecurityContext**,  when both are set, **securityContext** takes precedence. \n\nWell-defined privilege and access control settings will enhance assurance that your pod is running with the properties it requires to function.\n\n</details>"]}, {"url": "https://github.com/portefaix/portefaix-kubernetes/pull/1720", "comments": ["<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-azure-v0.26.0/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure securityContext is applied to pods and containers</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-azure-v0.26.0/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_43</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: <image>\n+   securityContext:\n```\n\n<h4>Description</h4>\n**securityContext** defines privilege and access control settings for your pod or container, and holds security configurations that will be applied to a container. Some fields are present in both **securityContext** and **PodSecurityContext**,  when both are set, **securityContext** takes precedence. \n\nWell-defined privilege and access control settings will enhance assurance that your pod is running with the properties it requires to function.\n\n<b>Dependent Resources</b>\n<br>\n<br><p>Calculating...</p>\n</details>\n<p>:tada: &nbsp; <b>Fixed</b> by commit 1b58fd6b5f9e2231becaa0c2a0e7d346131c23bf - Update Flux to v0.26.0 on Azure</p>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure securityContext is applied to pods and containers</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-azure-v0.26.0/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_43</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: <image>\n+   securityContext:\n```\n\n<h4>Description</h4>\n**securityContext** defines privilege and access control settings for your pod or container, and holds security configurations that will be applied to a container. Some fields are present in both **securityContext** and **PodSecurityContext**,  when both are set, **securityContext** takes precedence. \n\nWell-defined privilege and access control settings will enhance assurance that your pod is running with the properties it requires to function.\n\n<b>Dependent Resources</b>\n<br>\n<br><p>Calculating...</p>\n</details>\n<p>:tada: &nbsp; <b>Fixed</b> by commit 1b58fd6b5f9e2231becaa0c2a0e7d346131c23bf - Update Flux to v0.26.0 on Azure</p>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-azure-v0.26.0/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L4161-L4252\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n<b>Dependent Resources</b>\n<br>\n<br><p>Calculating...</p>\n</details>\n<p>:tada: &nbsp; <b>Fixed</b> by commit 1b58fd6b5f9e2231becaa0c2a0e7d346131c23bf - Update Flux to v0.26.0 on Azure</p>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-azure-v0.26.0/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-azure-v0.26.0/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n<b>Dependent Resources</b>\n<br>\n<br><p>Calculating...</p>\n</details>\n<p>:tada: &nbsp; <b>Fixed</b> by commit 1b58fd6b5f9e2231becaa0c2a0e7d346131c23bf - Update Flux to v0.26.0 on Azure</p>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-azure-v0.26.0/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-azure-v0.26.0/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n<b>Dependent Resources</b>\n<br>\n<br><p>Calculating...</p>\n</details>\n<p>:tada: &nbsp; <b>Fixed</b> by commit 1b58fd6b5f9e2231becaa0c2a0e7d346131c23bf - Update Flux to v0.26.0 on Azure</p>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-azure-v0.26.0/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L4161-L4252\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-azure-v0.26.0/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-azure-v0.26.0/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n<b>Dependent Resources</b>\n<br>\n<br><p>Calculating...</p>\n</details>\n<p>:tada: &nbsp; <b>Fixed</b> by commit 1b58fd6b5f9e2231becaa0c2a0e7d346131c23bf - Update Flux to v0.26.0 on Azure</p>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-azure-v0.26.0/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n<b>Dependent Resources</b>\n<br>\n<br><p>Calculating...</p>\n</details>\n<p>:tada: &nbsp; <b>Fixed</b> by commit 1b58fd6b5f9e2231becaa0c2a0e7d346131c23bf - Update Flux to v0.26.0 on Azure</p>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-azure-v0.26.0/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n<b>Dependent Resources</b>\n<br>\n<br><p>Calculating...</p>\n</details>\n<p>:tada: &nbsp; <b>Fixed</b> by commit 1b58fd6b5f9e2231becaa0c2a0e7d346131c23bf - Update Flux to v0.26.0 on Azure</p>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-azure-v0.26.0/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L4161-L4252\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n<b>Dependent Resources</b>\n<br>\n<br><p>Calculating...</p>\n</details>\n<p>:tada: &nbsp; <b>Fixed</b> by commit 1b58fd6b5f9e2231becaa0c2a0e7d346131c23bf - Update Flux to v0.26.0 on Azure</p>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-azure-v0.26.0/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-azure-v0.26.0/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-azure-v0.26.0/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-azure-v0.26.0/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L4161-L4252\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/medium.svg\" alt=\"MEDIUM\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Minimize wildcard use in Roles and ClusterRoles</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-azure-v0.26.0/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L3721-L3801\">ClusterRole.default.crd-controller-flux-system</a> |  ID: <code>BC_K8S_107</code>\n            <br></summary>\n<h4>Description</h4>\nTBD\n<b>Dependent Resources</b>\n<br>\n<br><p>Calculating...</p>\n</details>\n<p>:tada: &nbsp; <b>Fixed</b> by commit 1b58fd6b5f9e2231becaa0c2a0e7d346131c23bf - Update Flux to v0.26.0 on Azure</p>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-azure-v0.26.0/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n<b>Dependent Resources</b>\n<br>\n<br><p>Calculating...</p>\n</details>\n<p>:tada: &nbsp; <b>Fixed</b> by commit 1b58fd6b5f9e2231becaa0c2a0e7d346131c23bf - Update Flux to v0.26.0 on Azure</p>"]}, {"url": "https://github.com/portefaix/portefaix-kubernetes/pull/1719", "comments": ["<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/medium.svg\" alt=\"MEDIUM\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Minimize wildcard use in Roles and ClusterRoles</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.0/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3721-L3801\">ClusterRole.default.crd-controller-flux-system</a> |  ID: <code>BC_K8S_107</code>\n            <br></summary>\n<h4>Description</h4>\nTBD\n<b>Dependent Resources</b>\n<br>\n<br><p>Calculating...</p>\n</details>\n<p>:tada: &nbsp; <b>Fixed</b> by commit e2d1534537c152db194cd83c947d26f8cba19623 - Update Flux to v0.26.0 on k3s Homelab</p>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.0/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4082-L4169\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.0/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3997-L4081\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.0/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4170-L4265\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.0/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4082-L4169\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.0/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3997-L4081\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.0/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3997-L4081\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.0/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4170-L4265\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.0/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3914-L3996\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.0/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4170-L4265\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.0/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3997-L4081\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.0/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3997-L4081\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.0/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3914-L3996\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.0/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4082-L4169\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.0/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4082-L4169\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.0/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4170-L4265\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.0/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4082-L4169\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.0/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3914-L3996\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-kind-v0.26.0/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3914-L3996\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>"]}, {"url": "https://github.com/portefaix/portefaix-kubernetes/pull/1718", "comments": ["<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-aws-v0.26.0/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-aws-v0.26.0/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-aws-v0.26.0/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-aws-v0.26.0/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L4161-L4252\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-aws-v0.26.0/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-aws-v0.26.0/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-aws-v0.26.0/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-aws-v0.26.0/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-aws-v0.26.0/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-aws-v0.26.0/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-aws-v0.26.0/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-aws-v0.26.0/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L4161-L4252\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-aws-v0.26.0/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure securityContext is applied to pods and containers</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-aws-v0.26.0/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_43</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: <image>\n+   securityContext:\n```\n\n<h4>Description</h4>\n**securityContext** defines privilege and access control settings for your pod or container, and holds security configurations that will be applied to a container. Some fields are present in both **securityContext** and **PodSecurityContext**,  when both are set, **securityContext** takes precedence. \n\nWell-defined privilege and access control settings will enhance assurance that your pod is running with the properties it requires to function.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-aws-v0.26.0/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L4161-L4252\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-aws-v0.26.0/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-aws-v0.26.0/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L4161-L4252\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-aws-v0.26.0/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-aws-v0.26.0/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L4161-L4252\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure securityContext is applied to pods and containers</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-aws-v0.26.0/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_43</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: <image>\n+   securityContext:\n```\n\n<h4>Description</h4>\n**securityContext** defines privilege and access control settings for your pod or container, and holds security configurations that will be applied to a container. Some fields are present in both **securityContext** and **PodSecurityContext**,  when both are set, **securityContext** takes precedence. \n\nWell-defined privilege and access control settings will enhance assurance that your pod is running with the properties it requires to function.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-aws-v0.26.0/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-aws-v0.26.0/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/medium.svg\" alt=\"MEDIUM\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Minimize wildcard use in Roles and ClusterRoles</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-aws-v0.26.0/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L3721-L3801\">ClusterRole.default.crd-controller-flux-system</a> |  ID: <code>BC_K8S_107</code>\n            <br></summary>\n<h4>Description</h4>\nTBD\n<b>Dependent Resources</b>\n<br>\n<br><p>Calculating...</p>\n</details>\n<p>:tada: &nbsp; <b>Fixed</b> by commit 696d654a3a41e036e60bf8381e8223aefb1c4f43 - Update Flux to v0.26.0 on AWS</p>"]}, {"url": "https://github.com/portefaix/portefaix-kubernetes/pull/1717", "comments": ["<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure securityContext is applied to pods and containers</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-gcp-v0.26.0/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_43</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: <image>\n+   securityContext:\n```\n\n<h4>Description</h4>\n**securityContext** defines privilege and access control settings for your pod or container, and holds security configurations that will be applied to a container. Some fields are present in both **securityContext** and **PodSecurityContext**,  when both are set, **securityContext** takes precedence. \n\nWell-defined privilege and access control settings will enhance assurance that your pod is running with the properties it requires to function.\n\n<b>Dependent Resources</b>\n<br>\n<br><p>Calculating...</p>\n</details>\n<p>:tada: &nbsp; <b>Fixed</b> by commit 34ca30213ae8461c30001f1596f4c4193f50a9bc - Update Flux to v0.26.0 on GCP</p>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-gcp-v0.26.0/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n<b>Dependent Resources</b>\n<br>\n<br><p>Calculating...</p>\n</details>\n<p>:tada: &nbsp; <b>Fixed</b> by commit 34ca30213ae8461c30001f1596f4c4193f50a9bc - Update Flux to v0.26.0 on GCP</p>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-gcp-v0.26.0/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-gcp-v0.26.0/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n<b>Dependent Resources</b>\n<br>\n<br><p>Calculating...</p>\n</details>\n<p>:tada: &nbsp; <b>Fixed</b> by commit 34ca30213ae8461c30001f1596f4c4193f50a9bc - Update Flux to v0.26.0 on GCP</p>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-gcp-v0.26.0/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n<b>Dependent Resources</b>\n<br>\n<br><p>Calculating...</p>\n</details>\n<p>:tada: &nbsp; <b>Fixed</b> by commit 34ca30213ae8461c30001f1596f4c4193f50a9bc - Update Flux to v0.26.0 on GCP</p>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-gcp-v0.26.0/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L4161-L4252\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-gcp-v0.26.0/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L4161-L4252\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-gcp-v0.26.0/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure securityContext is applied to pods and containers</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-gcp-v0.26.0/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_43</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: <image>\n+   securityContext:\n```\n\n<h4>Description</h4>\n**securityContext** defines privilege and access control settings for your pod or container, and holds security configurations that will be applied to a container. Some fields are present in both **securityContext** and **PodSecurityContext**,  when both are set, **securityContext** takes precedence. \n\nWell-defined privilege and access control settings will enhance assurance that your pod is running with the properties it requires to function.\n\n<b>Dependent Resources</b>\n<br>\n<br><p>Calculating...</p>\n</details>\n<p>:tada: &nbsp; <b>Fixed</b> by commit 34ca30213ae8461c30001f1596f4c4193f50a9bc - Update Flux to v0.26.0 on GCP</p>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-gcp-v0.26.0/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-gcp-v0.26.0/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-gcp-v0.26.0/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-gcp-v0.26.0/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L4161-L4252\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-gcp-v0.26.0/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-gcp-v0.26.0/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L4161-L4252\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n<b>Dependent Resources</b>\n<br>\n<br><p>Calculating...</p>\n</details>\n<p>:tada: &nbsp; <b>Fixed</b> by commit 34ca30213ae8461c30001f1596f4c4193f50a9bc - Update Flux to v0.26.0 on GCP</p>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-gcp-v0.26.0/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-gcp-v0.26.0/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-gcp-v0.26.0/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-gcp-v0.26.0/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L4161-L4252\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-gcp-v0.26.0/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-gcp-v0.26.0/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-gcp-v0.26.0/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/medium.svg\" alt=\"MEDIUM\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Minimize wildcard use in Roles and ClusterRoles</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/flux/update-gcp-v0.26.0/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L3721-L3801\">ClusterRole.default.crd-controller-flux-system</a> |  ID: <code>BC_K8S_107</code>\n            <br></summary>\n<h4>Description</h4>\nTBD\n<b>Dependent Resources</b>\n<br>\n<br><p>Calculating...</p>\n</details>\n<p>:tada: &nbsp; <b>Fixed</b> by commit 34ca30213ae8461c30001f1596f4c4193f50a9bc - Update Flux to v0.26.0 on GCP</p>"]}, {"url": "https://github.com/portefaix/portefaix-kubernetes/pull/1716", "comments": ["<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L4161-L4253\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L4161-L4253\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L4161-L4253\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure image pull policy is set to Always</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4161-L4253\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_14</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n  containers:\n  - name: <container name>\n+   imagePullPolicy: Always\n\n```\n\n<h4>Description</h4>\nThe Image Pull Policy of a container is set using the **imagePullPolicy**. The **imagePullPolicy** and the tag of the image are triggered when the kubelet attempts to pull the specified image. When the **imagePullPolicy** is set to **Always**, you ensure the latest version of the image is deployed every time the pod is started. Avoid using the **:latest** tag when deploying containers in production, it is harder to track which version of the image is running and more difficult to roll back correctly.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L4161-L4253\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/medium.svg\" alt=\"MEDIUM\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Minimize wildcard use in Roles and ClusterRoles</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L3721-L3801\">ClusterRole.default.crd-controller-flux-system</a> |  ID: <code>BC_K8S_107</code>\n            <br></summary>\n<h4>Description</h4>\nTBD\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L4161-L4253\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure securityContext is applied to pods and containers</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_43</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: <image>\n+   securityContext:\n```\n\n<h4>Description</h4>\n**securityContext** defines privilege and access control settings for your pod or container, and holds security configurations that will be applied to a container. Some fields are present in both **securityContext** and **PodSecurityContext**,  when both are set, **securityContext** takes precedence. \n\nWell-defined privilege and access control settings will enhance assurance that your pod is running with the properties it requires to function.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/medium.svg\" alt=\"MEDIUM\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Minimize wildcard use in Roles and ClusterRoles</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L3721-L3801\">ClusterRole.default.crd-controller-flux-system</a> |  ID: <code>BC_K8S_107</code>\n            <br></summary>\n<h4>Description</h4>\nTBD\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L4161-L4253\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L4161-L4253\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure securityContext is applied to pods and containers</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_43</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: <image>\n+   securityContext:\n```\n\n<h4>Description</h4>\n**securityContext** defines privilege and access control settings for your pod or container, and holds security configurations that will be applied to a container. Some fields are present in both **securityContext** and **PodSecurityContext**,  when both are set, **securityContext** takes precedence. \n\nWell-defined privilege and access control settings will enhance assurance that your pod is running with the properties it requires to function.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L4161-L4253\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure images are selected using a digest</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_39</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2\n```\n\n<h4>Description</h4>\nIn some cases you may prefer to use a fixed version of an image, rather than update to newer versions. Docker enables you to pull an image by its digest, specifying exactly which version of an image to pull. \n\nPulling using a digest allows you to \u201cpin\u201d an image to that version, and guarantee that the image you\u2019re using is always the same. Digests also prevent race-conditions; if a new image is pushed while a deploy is in progress, different nodes may be pulling the images at different times, so some nodes have the new image, and some have the old one. Services automatically resolve tags to digests, so you don't need to manually specify a digest. \n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L4161-L4253\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure seccomp is set to Docker/Default or Runtime/Default</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/aws/staging/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_29</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\n  annotations:\n+  \tseccomp.security.alpha.kubernetes.io/pod: \"docker/default\" \n\tor\n+   seccomp.security.alpha.kubernetes.io/pod: \"runtime/default\"\n\n```\n\n<h4>Description</h4>\nSecure computing mode (seccomp) is a Linux kernel feature used to restrict actions available within the container. The seccomp() system call operates on the seccomp state of the calling process. The default seccomp profile provides a reliable setting for running containers with seccomp and disables non-essential system calls.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>PCI-DSS V3.2 2</li>\n<li>CIS KUBERNETES V1.5 1.6.4</li>\n<li>CIS GKE V1.1 4.6.2</li>\n<li>CIS EKS V1.1 4.6.1</li>\n<li>CIS KUBERNETES V1.6 5.7.2</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L3994-L4075\">Deployment.flux-system.kustomize-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure securityContext is applied to pods and containers</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L4076-L4160\">Deployment.flux-system.notification-controller</a> |  ID: <code>BC_K8S_43</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <Pod name>\nspec:\n  containers:\n  - name: <container name>\n    image: <image>\n+   securityContext:\n```\n\n<h4>Description</h4>\n**securityContext** defines privilege and access control settings for your pod or container, and holds security configurations that will be applied to a container. Some fields are present in both **securityContext** and **PodSecurityContext**,  when both are set, **securityContext** takes precedence. \n\nWell-defined privilege and access control settings will enhance assurance that your pod is running with the properties it requires to function.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L4161-L4253\">Deployment.flux-system.source-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure service account tokens are mounted where necessary</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_35</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n+  automountServiceAccountToken: false\n```\n\n<h4>Description</h4>\nOne way to authenticate the API is by using the Service Account token. **ServiceAccount** is an object managed by Kubernetes and used to provide an identity for processes that run in a pod. Every service account has a secret related to it, this secret contains a bearer token. This is a JSON Web Token (JWT), a method for representing claims securely between two parties.\n\nThis Service Account token is being used during the authentication stage and can become useful for  attackers if the service account is privileged and they have access to such a token. With this token an attacker can easily impersonate the service account and use REST APIs.\n\n<h4>Benchmarks</h4>\n<ul>\n<li>CIS GKE V1.1 4.1.6</li>\n<li>CIS EKS V1.1 4.1.6</li>\n<li>CIS KUBERNETES V1.6 5.1.6</li>\n</ul>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/medium.svg\" alt=\"MEDIUM\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Minimize wildcard use in Roles and ClusterRoles</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/k3s/homelab/flux-system/gotk-components.yaml#L3721-L3801\">ClusterRole.default.crd-controller-flux-system</a> |  ID: <code>BC_K8S_107</code>\n            <br></summary>\n<h4>Description</h4>\nTBD\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >CAP_SYS_ADMIN Linux capability is used</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/gcp/prod/flux-system/gotk-components.yaml#L3914-L3993\">Deployment.flux-system.helm-controller</a> |  ID: <code>BC_K8S_37</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: <name>\nspec:\n\tsecurityContext:\n+ \trunAsUser: <UID higher then 10000>\n```\n\n<h4>Description</h4>\nLinux namespaces provide isolation for running processes and limits access to system resources. To prevent privilege-escalation attacks from within a container, we recommend that you configure your container\u2019s applications to run as unprivileged users. The mapped user is assigned a range of UIDs which function within the namespace as normal UIDs from 0 to 65536, but have no privileges on the host machine itself. \n\nIf a process attempts to escalate privilege outside of the namespace, the process is running as an unprivileged high-number UID on the host, not mapped to a real user. This means the process has no privileges on the host system and cannot be attacked by this method.\n\nThis check will trigger below UID 10,000 as common linux distributions will assign UID 1000 to the first non-root, non system user and 1000 users should provide a reasonable buffer.\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/medium.svg\" alt=\"MEDIUM\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Minimize wildcard use in Roles and ClusterRoles</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/renovate/fluxcd-flux2-0.x/gitops/fluxcd/clusters/azure/dev/flux-system/gotk-components.yaml#L3721-L3801\">ClusterRole.default.crd-controller-flux-system</a> |  ID: <code>BC_K8S_107</code>\n            <br></summary>\n<h4>Description</h4>\nTBD\n</details>"]}, {"url": "https://github.com/portefaix/portefaix-kubernetes/pull/1699", "comments": ["<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/critical.svg\" alt=\"CRITICAL\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure WAF prevents message lookup in Log4j2</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/feat/aws-waf/terraform/aws/waf/modules/waf/waf.tf#L39-L165\">module.waf.aws_wafv2_web_acl.core</a> |  ID: <code>BC_AWS_NETWORKING_61</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```tf\nresource \"aws_wafv2_web_acl\" \"pass\" {\n  ...\n\n  rule {\n    name     = \"AWS-AWSManagedRulesKnownBadInputsRuleSet\"\n    priority = 1\n\n    override_action {\n      none {}\n    }\n\n    statement {\n      managed_rule_group_statement {\n        name        = \"AWSManagedRulesKnownBadInputsRuleSet\"\n        vendor_name = \"AWS\"\n      }\n    }\n\n    ...\n  }\n\n  ...\n}\n```\n\n<h4>Description</h4>\nUsing a vulnerable version of Apache Log4j library might enable attackers to exploit a Lookup mechanism that supports making requests using special syntax in a format string which can potentially lead to a risky code execution, data leakage and more.\nSet your Web Application Firewall (WAF) to prevent executing such mechanism using the rule definition below.\n\nLearn more around [CVE-2021-44228](https://nvd.nist.gov/vuln/detail/CVE-2021-44228)\n\n</details>\n<p>:tada: &nbsp; <b>Fixed</b> by commit 626288606f50ccc2e83ff814898101cd8cf9fd59 - Update: refactoring waf rules code</p>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure WAF2 has a Logging Configuration</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/feat/aws-waf/terraform/aws/waf/modules/waf/waf.tf#L39-L165\">aws_wafv2_web_acl.core</a> |  ID: <code>BC_AWS_LOGGING_33</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```tf\nresource \"aws_wafv2_web_acl\" \"example\" {\n  name        = \"rate-based-example\"\n  description = \"Example of a rate based statement.\"\n  scope       = \"REGIONAL\"\n\n  ...\n++    visibility_config {\n      cloudwatch_metrics_enabled = false\n      metric_name                = \"friendly-rule-metric-name\"\n      sampled_requests_enabled   = false\n    }\n  }\n\n```\n\n<h4>Description</h4>\nYou can enable comprehensive logging on a web access control list (web ACL) using an Amazon Kinesis Data Firehose stream destined to an Amazon S3 bucket in the same Region. To do so, you must use three AWS services:\nAWS WAF to create the logs\nKinesis Data Firehose to receive the logs\nAmazon S3 to store the logs\nNote: AWS WAF and Kinesis Data Firehose must be running in the same Region.\n\n\n</details>\n<p>:tada: &nbsp; <b>Fixed</b> by commit 626288606f50ccc2e83ff814898101cd8cf9fd59 - Update: refactoring waf rules code</p>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure WAF2 has a Logging Configuration</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/feat/aws-waf/terraform/aws/waf/modules/waf/waf.tf#L39-L244\">aws_wafv2_web_acl.this</a> |  ID: <code>BC_AWS_LOGGING_33</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```tf\nresource \"aws_wafv2_web_acl\" \"example\" {\n  name        = \"rate-based-example\"\n  description = \"Example of a rate based statement.\"\n  scope       = \"REGIONAL\"\n\n  ...\n++    visibility_config {\n      cloudwatch_metrics_enabled = false\n      metric_name                = \"friendly-rule-metric-name\"\n      sampled_requests_enabled   = false\n    }\n  }\n\n```\n\n<h4>Description</h4>\nYou can enable comprehensive logging on a web access control list (web ACL) using an Amazon Kinesis Data Firehose stream destined to an Amazon S3 bucket in the same Region. To do so, you must use three AWS services:\nAWS WAF to create the logs\nKinesis Data Firehose to receive the logs\nAmazon S3 to store the logs\nNote: AWS WAF and Kinesis Data Firehose must be running in the same Region.\n\n\n</details>\n<p>:tada: &nbsp; <b>Fixed</b> by commit 534e4fe810cba6a3f53e79caebf00183754357f6 - Update: aws rules</p>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/critical.svg\" alt=\"CRITICAL\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure WAF prevents message lookup in Log4j2</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/feat/aws-waf/terraform/aws/waf/modules/waf/waf.tf#L39-L174\">module.waf.aws_wafv2_web_acl.this</a> |  ID: <code>BC_AWS_NETWORKING_61</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```tf\nresource \"aws_wafv2_web_acl\" \"pass\" {\n  ...\n\n  rule {\n    name     = \"AWS-AWSManagedRulesKnownBadInputsRuleSet\"\n    priority = 1\n\n    override_action {\n      none {}\n    }\n\n    statement {\n      managed_rule_group_statement {\n        name        = \"AWSManagedRulesKnownBadInputsRuleSet\"\n        vendor_name = \"AWS\"\n      }\n    }\n\n    ...\n  }\n\n  ...\n}\n```\n\n<h4>Description</h4>\nUsing a vulnerable version of Apache Log4j library might enable attackers to exploit a Lookup mechanism that supports making requests using special syntax in a format string which can potentially lead to a risky code execution, data leakage and more.\nSet your Web Application Firewall (WAF) to prevent executing such mechanism using the rule definition below.\n\nLearn more around [CVE-2021-44228](https://nvd.nist.gov/vuln/detail/CVE-2021-44228)\n\n</details>\n<p>:tada: &nbsp; <b>Fixed</b> by commit df994e2e6e714126a6d399990f4a2144f1f1d09f - Update: aws rules</p>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/critical.svg\" alt=\"CRITICAL\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure WAF prevents message lookup in Log4j2</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/feat/aws-waf/terraform/aws/waf/modules/waf/waf.tf#L39-L244\">module.waf.aws_wafv2_web_acl.this</a> |  ID: <code>BC_AWS_NETWORKING_61</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```tf\nresource \"aws_wafv2_web_acl\" \"pass\" {\n  ...\n\n  rule {\n    name     = \"AWS-AWSManagedRulesKnownBadInputsRuleSet\"\n    priority = 1\n\n    override_action {\n      none {}\n    }\n\n    statement {\n      managed_rule_group_statement {\n        name        = \"AWSManagedRulesKnownBadInputsRuleSet\"\n        vendor_name = \"AWS\"\n      }\n    }\n\n    ...\n  }\n\n  ...\n}\n```\n\n<h4>Description</h4>\nUsing a vulnerable version of Apache Log4j library might enable attackers to exploit a Lookup mechanism that supports making requests using special syntax in a format string which can potentially lead to a risky code execution, data leakage and more.\nSet your Web Application Firewall (WAF) to prevent executing such mechanism using the rule definition below.\n\nLearn more around [CVE-2021-44228](https://nvd.nist.gov/vuln/detail/CVE-2021-44228)\n\n</details>\n<p>:tada: &nbsp; <b>Fixed</b> by commit 534e4fe810cba6a3f53e79caebf00183754357f6 - Update: aws rules</p>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure WAF2 has a Logging Configuration</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/feat/aws-waf/terraform/aws/waf/modules/waf/waf.tf#L39-L83\">aws_wafv2_web_acl.core</a> |  ID: <code>BC_AWS_LOGGING_33</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```tf\nresource \"aws_wafv2_web_acl\" \"example\" {\n  name        = \"rate-based-example\"\n  description = \"Example of a rate based statement.\"\n  scope       = \"REGIONAL\"\n\n  ...\n++    visibility_config {\n      cloudwatch_metrics_enabled = false\n      metric_name                = \"friendly-rule-metric-name\"\n      sampled_requests_enabled   = false\n    }\n  }\n\n```\n\n<h4>Description</h4>\nYou can enable comprehensive logging on a web access control list (web ACL) using an Amazon Kinesis Data Firehose stream destined to an Amazon S3 bucket in the same Region. To do so, you must use three AWS services:\nAWS WAF to create the logs\nKinesis Data Firehose to receive the logs\nAmazon S3 to store the logs\nNote: AWS WAF and Kinesis Data Firehose must be running in the same Region.\n\n\n</details>\n<p>:tada: &nbsp; <b>Fixed</b> by commit af5932f38d6931209cdbe287c11c25370bba9668 - Update: refactoring WAF rules</p>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/critical.svg\" alt=\"CRITICAL\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure WAF prevents message lookup in Log4j2</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/feat/aws-waf/terraform/aws/waf/modules/waf/waf.tf#L39-L83\">module.waf.aws_wafv2_web_acl.core</a> |  ID: <code>BC_AWS_NETWORKING_61</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```tf\nresource \"aws_wafv2_web_acl\" \"pass\" {\n  ...\n\n  rule {\n    name     = \"AWS-AWSManagedRulesKnownBadInputsRuleSet\"\n    priority = 1\n\n    override_action {\n      none {}\n    }\n\n    statement {\n      managed_rule_group_statement {\n        name        = \"AWSManagedRulesKnownBadInputsRuleSet\"\n        vendor_name = \"AWS\"\n      }\n    }\n\n    ...\n  }\n\n  ...\n}\n```\n\n<h4>Description</h4>\nUsing a vulnerable version of Apache Log4j library might enable attackers to exploit a Lookup mechanism that supports making requests using special syntax in a format string which can potentially lead to a risky code execution, data leakage and more.\nSet your Web Application Firewall (WAF) to prevent executing such mechanism using the rule definition below.\n\nLearn more around [CVE-2021-44228](https://nvd.nist.gov/vuln/detail/CVE-2021-44228)\n\n</details>\n<p>:tada: &nbsp; <b>Fixed</b> by commit af5932f38d6931209cdbe287c11c25370bba9668 - Update: refactoring WAF rules</p>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure WAF2 has a Logging Configuration</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/feat/aws-waf/terraform/aws/waf/modules/waf/waf.tf#L85-L180\">aws_wafv2_web_acl.custom</a> |  ID: <code>BC_AWS_LOGGING_33</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```tf\nresource \"aws_wafv2_web_acl\" \"example\" {\n  name        = \"rate-based-example\"\n  description = \"Example of a rate based statement.\"\n  scope       = \"REGIONAL\"\n\n  ...\n++    visibility_config {\n      cloudwatch_metrics_enabled = false\n      metric_name                = \"friendly-rule-metric-name\"\n      sampled_requests_enabled   = false\n    }\n  }\n\n```\n\n<h4>Description</h4>\nYou can enable comprehensive logging on a web access control list (web ACL) using an Amazon Kinesis Data Firehose stream destined to an Amazon S3 bucket in the same Region. To do so, you must use three AWS services:\nAWS WAF to create the logs\nKinesis Data Firehose to receive the logs\nAmazon S3 to store the logs\nNote: AWS WAF and Kinesis Data Firehose must be running in the same Region.\n\n\n</details>\n<p>:tada: &nbsp; <b>Fixed</b> by commit af5932f38d6931209cdbe287c11c25370bba9668 - Update: refactoring WAF rules</p>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/critical.svg\" alt=\"CRITICAL\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure WAF prevents message lookup in Log4j2</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/feat/aws-waf/terraform/aws/waf/modules/waf/waf.tf#L85-L180\">module.waf.aws_wafv2_web_acl.custom</a> |  ID: <code>BC_AWS_NETWORKING_61</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```tf\nresource \"aws_wafv2_web_acl\" \"pass\" {\n  ...\n\n  rule {\n    name     = \"AWS-AWSManagedRulesKnownBadInputsRuleSet\"\n    priority = 1\n\n    override_action {\n      none {}\n    }\n\n    statement {\n      managed_rule_group_statement {\n        name        = \"AWSManagedRulesKnownBadInputsRuleSet\"\n        vendor_name = \"AWS\"\n      }\n    }\n\n    ...\n  }\n\n  ...\n}\n```\n\n<h4>Description</h4>\nUsing a vulnerable version of Apache Log4j library might enable attackers to exploit a Lookup mechanism that supports making requests using special syntax in a format string which can potentially lead to a risky code execution, data leakage and more.\nSet your Web Application Firewall (WAF) to prevent executing such mechanism using the rule definition below.\n\nLearn more around [CVE-2021-44228](https://nvd.nist.gov/vuln/detail/CVE-2021-44228)\n\n</details>\n<p>:tada: &nbsp; <b>Fixed</b> by commit af5932f38d6931209cdbe287c11c25370bba9668 - Update: refactoring WAF rules</p>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure WAF2 has a Logging Configuration</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/feat/aws-waf/terraform/aws/waf/modules/waf/managed.tf#L15-L59\">aws_wafv2_web_acl.core</a> |  ID: <code>BC_AWS_LOGGING_33</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```tf\nresource \"aws_wafv2_web_acl\" \"example\" {\n  name        = \"rate-based-example\"\n  description = \"Example of a rate based statement.\"\n  scope       = \"REGIONAL\"\n\n  ...\n++    visibility_config {\n      cloudwatch_metrics_enabled = false\n      metric_name                = \"friendly-rule-metric-name\"\n      sampled_requests_enabled   = false\n    }\n  }\n\n```\n\n<h4>Description</h4>\nYou can enable comprehensive logging on a web access control list (web ACL) using an Amazon Kinesis Data Firehose stream destined to an Amazon S3 bucket in the same Region. To do so, you must use three AWS services:\nAWS WAF to create the logs\nKinesis Data Firehose to receive the logs\nAmazon S3 to store the logs\nNote: AWS WAF and Kinesis Data Firehose must be running in the same Region.\n\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/critical.svg\" alt=\"CRITICAL\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure WAF prevents message lookup in Log4j2</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/feat/aws-waf/terraform/aws/waf/modules/waf/managed.tf#L15-L59\">module.waf.aws_wafv2_web_acl.core</a> |  ID: <code>BC_AWS_NETWORKING_61</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```tf\nresource \"aws_wafv2_web_acl\" \"pass\" {\n  ...\n\n  rule {\n    name     = \"AWS-AWSManagedRulesKnownBadInputsRuleSet\"\n    priority = 1\n\n    override_action {\n      none {}\n    }\n\n    statement {\n      managed_rule_group_statement {\n        name        = \"AWSManagedRulesKnownBadInputsRuleSet\"\n        vendor_name = \"AWS\"\n      }\n    }\n\n    ...\n  }\n\n  ...\n}\n```\n\n<h4>Description</h4>\nUsing a vulnerable version of Apache Log4j library might enable attackers to exploit a Lookup mechanism that supports making requests using special syntax in a format string which can potentially lead to a risky code execution, data leakage and more.\nSet your Web Application Firewall (WAF) to prevent executing such mechanism using the rule definition below.\n\nLearn more around [CVE-2021-44228](https://nvd.nist.gov/vuln/detail/CVE-2021-44228)\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure WAF2 has a Logging Configuration</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/feat/aws-waf/terraform/aws/waf/modules/waf/custom.tf#L39-L133\">aws_wafv2_web_acl.custom</a> |  ID: <code>BC_AWS_LOGGING_33</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```tf\nresource \"aws_wafv2_web_acl\" \"example\" {\n  name        = \"rate-based-example\"\n  description = \"Example of a rate based statement.\"\n  scope       = \"REGIONAL\"\n\n  ...\n++    visibility_config {\n      cloudwatch_metrics_enabled = false\n      metric_name                = \"friendly-rule-metric-name\"\n      sampled_requests_enabled   = false\n    }\n  }\n\n```\n\n<h4>Description</h4>\nYou can enable comprehensive logging on a web access control list (web ACL) using an Amazon Kinesis Data Firehose stream destined to an Amazon S3 bucket in the same Region. To do so, you must use three AWS services:\nAWS WAF to create the logs\nKinesis Data Firehose to receive the logs\nAmazon S3 to store the logs\nNote: AWS WAF and Kinesis Data Firehose must be running in the same Region.\n\n\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/critical.svg\" alt=\"CRITICAL\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure WAF prevents message lookup in Log4j2</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/feat/aws-waf/terraform/aws/waf/modules/waf/custom.tf#L39-L133\">module.waf.aws_wafv2_web_acl.custom</a> |  ID: <code>BC_AWS_NETWORKING_61</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```tf\nresource \"aws_wafv2_web_acl\" \"pass\" {\n  ...\n\n  rule {\n    name     = \"AWS-AWSManagedRulesKnownBadInputsRuleSet\"\n    priority = 1\n\n    override_action {\n      none {}\n    }\n\n    statement {\n      managed_rule_group_statement {\n        name        = \"AWSManagedRulesKnownBadInputsRuleSet\"\n        vendor_name = \"AWS\"\n      }\n    }\n\n    ...\n  }\n\n  ...\n}\n```\n\n<h4>Description</h4>\nUsing a vulnerable version of Apache Log4j library might enable attackers to exploit a Lookup mechanism that supports making requests using special syntax in a format string which can potentially lead to a risky code execution, data leakage and more.\nSet your Web Application Firewall (WAF) to prevent executing such mechanism using the rule definition below.\n\nLearn more around [CVE-2021-44228](https://nvd.nist.gov/vuln/detail/CVE-2021-44228)\n\n</details>\n<p>:tada: &nbsp; <b>Fixed</b> by commit d54469bf1f66d2bb0788aa8dc2d5c791aaa9a99b - Fix: check array length</p>"]}, {"url": "https://github.com/portefaix/portefaix-kubernetes/pull/1684", "comments": ["<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure IAM policies does not allow write access without constraint</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/feat/aws-eventbridge-chatbot/terraform/aws/chatbot/modules/chatbot/iam.tf#L61-L71\">aws_iam_policy_document.lambda_invoke</a> |  ID: <code>BC_AWS_IAM_57</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```tf\n           data \"aws_iam_policy_document\" \"example\" {\n              statement {\n                sid = \"1\"\n                effect = \"Allow\"\n                actions = [\n                        \"s3:*\"\n                ]\n            \n                resources = [\n                  \"foo\",\n                ]\n              }\n            }\n```\n\n<h4>Description</h4>\nThis policy allows actions that permit modification of resource-based policies or can otherwise can expose AWS resources to the public via similar actions that can lead to resource exposure.\n\nFor example:\n1 - s3:PutBucketPolicy, s3:PutBucketAcl, and s3:PutObjectAcl grant permissions to modify the properties of S3 buckets or objects for new or existing objects in an S3 bucket, which could expose objects to rogue actors or to the internet.\n2 - ecr:SetRepositoryPolicy could allow an attacker to exfiltrate container images (which sometimes unintentionally contain secrets and non-public information), tamper with container images, or otherwise modify.\n3 - iam:UpdateAssumeRolePolicy could allow an attacker to create a backdoor by assuming a privileged role in the victim account from an external account.\nThe ability to modify AWS Resource Access Manager, which could allow a malicious actor to share a VPC hosting sensitive or internal services to rogue AWS accounts\nAttackers can easily exploit Resource Exposure permissions to expose resources to rogue users or the internet, as shown by endgame, an AWS pentesting tool that was also released by Salesforce.\n\nFor more info, visit cloudsplaning documentation\nhttps://cloudsplaining.readthedocs.io/en/latest/glossary/resource-exposure/\n\n</details>\n<p>:tada: &nbsp; <b>Fixed</b> by commit db11b46100982a5bf5524d891aa7936952d99d9e - Add: Renovate precommit</p>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure AWS resources that support tags have Tags</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/feat/aws-eventbridge-chatbot/terraform/aws/chatbot/modules/chatbot/iam.tf#L25-L28\">aws_iam_role.this</a> |  ID: <code>BC_AWS_GENERAL_26</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```tf\nresource \"aws_security_group\" \"sg\" {\n  name = \"my-sg\"\n  ...\n+ tags = {\n+   Environment = \"dev\"\n+   Owner = \"apps-team\"\n+ }\n}\n```\n\n<h4>Description</h4>\nMany different types of AWS resources support tags. Tags allow you to add metadata to a resource to help identify ownership, perform cost / billing analysis, and to enrich a resource with other valuable information, such as descriptions and environment names. While there are many ways that tags can be used, we recommend you follow a tagging practice.\n\nView AWS's recommended tagging best practices [here](https://d1.awsstatic.com/whitepapers/aws-tagging-best-practices.pdf).\n\n</details>\n<p>:tada: &nbsp; <b>Fixed</b> by commit a5734011ac5721ffdb284a678de15983cdb3ac96 - Add: Tags for ChatBot resources</p>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure AWS resources that support tags have Tags</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/portefaix/portefaix/blob/feat/aws-eventbridge-chatbot/terraform/aws/chatbot/modules/chatbot/iam.tf#L25-L28\">module.chatbot.aws_iam_role.this</a> |  ID: <code>BC_AWS_GENERAL_26</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```tf\nresource \"aws_security_group\" \"sg\" {\n  name = \"my-sg\"\n  ...\n+ tags = {\n+   Environment = \"dev\"\n+   Owner = \"apps-team\"\n+ }\n}\n```\n\n<h4>Description</h4>\nMany different types of AWS resources support tags. Tags allow you to add metadata to a resource to help identify ownership, perform cost / billing analysis, and to enrich a resource with other valuable information, such as descriptions and environment names. While there are many ways that tags can be used, we recommend you follow a tagging practice.\n\nView AWS's recommended tagging best practices [here](https://d1.awsstatic.com/whitepapers/aws-tagging-best-practices.pdf).\n\n</details>\n<p>:tada: &nbsp; <b>Fixed</b> by commit a5734011ac5721ffdb284a678de15983cdb3ac96 - Add: Tags for ChatBot resources</p>"]}, {"url": "https://github.com/portefaix/portefaix-kubernetes/pull/1483", "comments": ["```suggestion\n# Copyright 2021 Nicolas Lamirault <nicolas.lamirault@gmail.com>\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n#ENC[AES256_GCM,data:NuMIuCewi/OIm04NFbVDuWGYCKN6QhXCSEWjaJ6DkVqgpuYFoSn+xrfWjVnStCRTpQ8jreMWzFofu9q0APbaGcP+KQ==,iv:7FLstsShvpR+SWYqmWhyFM8+yvwN4rhiGemr7TosyEs=,tag:HeLAAAqp1GPYI/c14Xkw7w==,type:comment]\n```\n<!-- license-eye hidden identification -->", "```suggestion\n# Copyright 2021 Nicolas Lamirault <nicolas.lamirault@gmail.com>\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\ngrafana:\n```\n<!-- license-eye hidden identification -->", "```suggestion\n# Copyright 2021 Nicolas Lamirault <nicolas.lamirault@gmail.com>\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n---\n```\n<!-- license-eye hidden identification -->", "```suggestion\n# Copyright 2021 Nicolas Lamirault <nicolas.lamirault@gmail.com>\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\napiVersion: v1\n```\n<!-- license-eye hidden identification -->", "```suggestion\n# Copyright 2021 Nicolas Lamirault <nicolas.lamirault@gmail.com>\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\napiVersion: v1\n```\n<!-- license-eye hidden identification -->", "```suggestion\n# Copyright 2021 Nicolas Lamirault <nicolas.lamirault@gmail.com>\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\napiVersion: v1\n```\n<!-- license-eye hidden identification -->", "```suggestion\n# Copyright 2021 Nicolas Lamirault <nicolas.lamirault@gmail.com>\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\napiVersion: v1\n```\n<!-- license-eye hidden identification -->", "```suggestion\n{*\n Copyright 2021 Nicolas Lamirault <nicolas.lamirault@gmail.com>\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License.\n\n*}\n{{/*\n```\n<!-- license-eye hidden identification -->", "```suggestion\n# Copyright 2021 Nicolas Lamirault <nicolas.lamirault@gmail.com>\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# Default values for infra.\n```\n<!-- license-eye hidden identification -->", "```suggestion\n{*\n Copyright 2021 Nicolas Lamirault <nicolas.lamirault@gmail.com>\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License.\n\n*}\n{{/*\n```\n<!-- license-eye hidden identification -->", "```suggestion\n# Copyright 2021 Nicolas Lamirault <nicolas.lamirault@gmail.com>\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# Default values for apps.\n```\n<!-- license-eye hidden identification -->", "```suggestion\n{*\n Copyright 2021 Nicolas Lamirault <nicolas.lamirault@gmail.com>\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License.\n\n*}\n{{/*\n```\n<!-- license-eye hidden identification -->", "```suggestion\n# Copyright 2021 Nicolas Lamirault <nicolas.lamirault@gmail.com>\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# Default values for infra.\n```\n<!-- license-eye hidden identification -->", "```suggestion\n{*\n Copyright 2021 Nicolas Lamirault <nicolas.lamirault@gmail.com>\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License.\n\n*}\n{{/*\n```\n<!-- license-eye hidden identification -->", "```suggestion\n# Copyright 2021 Nicolas Lamirault <nicolas.lamirault@gmail.com>\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# Default values for apps.\n```\n<!-- license-eye hidden identification -->", "```suggestion\n{*\n Copyright 2021 Nicolas Lamirault <nicolas.lamirault@gmail.com>\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License.\n\n*}\n{{/*\n```\n<!-- license-eye hidden identification -->", "```suggestion\n# Copyright 2021 Nicolas Lamirault <nicolas.lamirault@gmail.com>\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# Default values for infra.\n```\n<!-- license-eye hidden identification -->", "```suggestion\n{*\n Copyright 2021 Nicolas Lamirault <nicolas.lamirault@gmail.com>\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License.\n\n*}\n{{/*\n```\n<!-- license-eye hidden identification -->", "```suggestion\n# Copyright 2021 Nicolas Lamirault <nicolas.lamirault@gmail.com>\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# Default values for apps.\n```\n<!-- license-eye hidden identification -->", "```suggestion\n{*\n Copyright 2021 Nicolas Lamirault <nicolas.lamirault@gmail.com>\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License.\n\n*}\n{{/*\n```\n<!-- license-eye hidden identification -->", "```suggestion\n# Copyright 2021 Nicolas Lamirault <nicolas.lamirault@gmail.com>\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# Default values for apps.\n```\n<!-- license-eye hidden identification -->"]}, {"url": "https://github.com/portefaix/portefaix-kubernetes/pull/1085", "comments": ["You can use a revision later this option is included, such as `uses: apache/skywalking-eyes@49d536241d6fe8f92400702b08710514dc298cd4`", "```suggestion\n# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n#\n# Copyright (C) 2021 Nicolas Lamirault <nicolas.lamirault@gmail.com>\n```\n<!-- license-eye hidden identification -->", "```suggestion\n# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n#\n# Copyright (C) 2021 Nicolas Lamirault <nicolas.lamirault@gmail.com>\n```\n<!-- license-eye hidden identification -->", "```suggestion\n; Licensed to the Apache Software Foundation (ASF) under one\n; or more contributor license agreements.  See the NOTICE file\n; distributed with this work for additional information\n; regarding copyright ownership.  The ASF licenses this file\n; to you under the Apache License, Version 2.0 (the\n; \"License\"); you may not use this file except in compliance\n; with the License.  You may obtain a copy of the License at\n;\n;   http://www.apache.org/licenses/LICENSE-2.0\n;\n; Unless required by applicable law or agreed to in writing,\n; software distributed under the License is distributed on an\n; \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n; KIND, either express or implied.  See the License for the\n; specific language governing permissions and limitations\n; under the License.\n;\n; Copyright 2021 Nicolas Lamirault.\n```\n<!-- license-eye hidden identification -->", "```suggestion\n; Licensed to the Apache Software Foundation (ASF) under one\n; or more contributor license agreements.  See the NOTICE file\n; distributed with this work for additional information\n; regarding copyright ownership.  The ASF licenses this file\n; to you under the Apache License, Version 2.0 (the\n; \"License\"); you may not use this file except in compliance\n; with the License.  You may obtain a copy of the License at\n;\n;   http://www.apache.org/licenses/LICENSE-2.0\n;\n; Unless required by applicable law or agreed to in writing,\n; software distributed under the License is distributed on an\n; \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n; KIND, either express or implied.  See the License for the\n; specific language governing permissions and limitations\n; under the License.\n;\n; Copyright 2021 Nicolas Lamirault.\n```\n<!-- license-eye hidden identification -->", "```suggestion\n# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n#\n# Copyright (C) 2021 Nicolas Lamirault <nicolas.lamirault@gmail.com>\n```\n<!-- license-eye hidden identification -->", "```suggestion\n# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n#\n#!/usr/bin/env bash\n```\n<!-- license-eye hidden identification -->", "```suggestion\n# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n#\n#!/bin/bash\n```\n<!-- license-eye hidden identification -->", "```suggestion\n# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n#\n#!/usr/bin/env bash\n```\n<!-- license-eye hidden identification -->", "```suggestion\n; Licensed to the Apache Software Foundation (ASF) under one\n; or more contributor license agreements.  See the NOTICE file\n; distributed with this work for additional information\n; regarding copyright ownership.  The ASF licenses this file\n; to you under the Apache License, Version 2.0 (the\n; \"License\"); you may not use this file except in compliance\n; with the License.  You may obtain a copy of the License at\n;\n;   http://www.apache.org/licenses/LICENSE-2.0\n;\n; Unless required by applicable law or agreed to in writing,\n; software distributed under the License is distributed on an\n; \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n; KIND, either express or implied.  See the License for the\n; specific language governing permissions and limitations\n; under the License.\n;\n; Copyright 2021 Nicolas Lamirault.\n```\n<!-- license-eye hidden identification -->", "```suggestion\n# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n#\n# Copyright (C) 2021 Nicolas Lamirault <nicolas.lamirault@gmail.com>\n```\n<!-- license-eye hidden identification -->", "```suggestion\n# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n#\n# Copyright 2021 Nicolas Lamirault.\n```\n<!-- license-eye hidden identification -->", "```suggestion\n# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n#\n# Copyright 2021 Nicolas Lamirault.\n```\n<!-- license-eye hidden identification -->", "Great it works.", "I just see also the `v0.2.0` release"]}]}, {"url": "https://github.com/karim7262/IaC-AWS.git", "pull_requests": []}, {"url": "https://github.com/seanturner026/maido-terraform.git", "pull_requests": []}, {"url": "https://github.com/djam4/terragoat.git", "pull_requests": []}, {"url": "https://github.com/Azure/sap-automation.git", "pull_requests": [{"url": "https://github.com/Azure/sap-automation/pull/395", "comments": ["```suggestion\r\n      -e @$SAP_PARAMS -e \"_workspace_directory=$PARAMETERS_FOLDER\" $EXTRA_PARAMS     \\\r\n      -e ansible_ssh_pass='${password_secret}'                                                                                   \\\r\n```"]}, {"url": "https://github.com/Azure/sap-automation/pull/358", "comments": ["```suggestion\r\n    mnt_options:                       \"rw,vers=4,minorversion=1,hard,timeo=600,rsize=262144,wsize=262144,intr,noatime,lock,_netdev,sec=sys\"\r\n```", "```suggestion\r\n    mnt_options:                       \"rw,vers=4,minorversion=1,hard,timeo=600,rsize=262144,wsize=262144,intr,noatime,lock,_netdev,sec=sys,nconnect=8\"\r\n```", "This is centrally handled in https://github.com/Azure/sap-automation/blob/05cd9ae11c456021c7734b161adc68268249dc45/deploy/ansible/roles-sap/3.3.1-bom-utility/tasks/bom-template.yaml#L26"]}, {"url": "https://github.com/Azure/sap-automation/pull/357", "comments": ["Please don't include vscode color settings"]}, {"url": "https://github.com/Azure/sap-automation/pull/294", "comments": ["```suggestion\r\n      ansible.builtin.pip:\r\n```", "```suggestion\r\n      ansible.builtin.pip:\r\n```", "```suggestion\r\n      ansible.builtin.pip:\r\n```"]}, {"url": "https://github.com/Azure/sap-automation/pull/290", "comments": ["This should be like this we set that using export TF_VAR_Agent_IP\r\n\r\n```suggestion\r\n  Agent_IP = try(var.Agent_IP, \"\")\r\n```"]}, {"url": "https://github.com/Azure/sap-automation/pull/263", "comments": ["For Azure Files NFS this has to be false\r\n\r\nhttps://docs.microsoft.com/en-us/azure/storage/files/storage-troubleshooting-files-nfs#cause-2-secure-transfer-required-is-enabled"]}, {"url": "https://github.com/Azure/sap-automation/pull/216", "comments": ["```suggestion\r\n    - name:     HANA_2_00_059_v0003ms\r\n```"]}, {"url": "https://github.com/Azure/sap-automation/pull/191", "comments": ["```suggestion\r\n      poll:                            0\r\n```", "Please bring this back\r\n\r\n    - name:                            \"DBLoad Install -Wait for asynchronous job to end\"\r\n      ansible.builtin.async_status:\r\n        jid:                           '{{ dbload_results.ansible_job_id }}'\r\n      register:                        job_result\r\n      until:                           job_result.finished\r\n      retries:                         120\r\n      delay:                           60\r\n      when:                            dbload_results.ansible_job_id is defined\r\n"]}, {"url": "https://github.com/Azure/sap-automation/pull/179", "comments": ["We need this to be here - Azure DevOps tasks will otherwise fail if they run for longer than 60 minutes", "But due to the poll and async in the previous task it stays there until it's either finished, or if 2 hours have passed.\r\nIn our case it's finished within those 2 hours and that results in the next task (the one I removed) failing, because the job cannot be found.\r\n\r\nAs far as I'm aware either the poll in the async task needs to be 0, or the wait needs to be removed", "Hi, I've based mine on this: https://docs.ansible.com/ansible/latest/user_guide/playbooks_async.html \r\n\r\nand have been using it without any issue\r\n<img width=\"589\" alt=\"image\" src=\"https://user-images.githubusercontent.com/25486924/174020395-e3071f77-74ed-41a5-af69-ec78a86923ae.png\">\r\n\r\nWithout it our Azure DevOps tasks fail - I assume that is because if there is no action on the main thread", "Hi Kimmo I just ran some tests locally with the following code: \r\n\r\n```yaml\r\n- name: Async sleep for 15 seconds\r\n  ansible.builtin.command: sleep 15\r\n  register: results\r\n  async: 60\r\n  poll: 10\r\n\r\n- name: check status (wait task)\r\n  ansible.builtin.async_status:\r\n    jid: \"{{ results.ansible_job_id }}\"\r\n  register: job_result\r\n  until: job_result.finished\r\n  retries: 90\r\n  delay: 10\r\n  when: results.ansible_job_id is defined\r\n ```\r\n With the poll in the first task i get the following output:\r\n ```\r\n TASK [Async sleep for 15 seconds] *************************************************************************************************************************************************************************************************\r\nASYNC POLL on localhost: jid=317019997408.17994 started=1 finished=0\r\nASYNC OK on localhost: jid=317019997408.17994\r\nchanged: [localhost]\r\n\r\nTASK [check status] ***************************************************************************************************************************************************************************************************************\r\nfatal: [localhost]: FAILED! => {\"ansible_job_id\": \"317019997408.17994\", \"attempts\": 1, \"changed\": false, \"finished\": 1, \"msg\": \"could not find job\", \"results_file\": \"/home/aa618475/.ansible_async/317019997408.17994\", \"started\": 1, \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"\", \"stdout_lines\": []}\r\n\r\nPLAY RECAP ************************************************************************************************************************************************************************************************************************\r\nlocalhost                  : ok=1    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   \r\n```\r\n\r\nThe async task is already finished when we get to the wait task, so there is no job to wait for anymore.\r\nThe other option is to set the poll to 0 to go straight to the wait task. That will result in the following output:\r\n\r\n```\r\nTASK [Async sleep for 15 seconds] *************************************************************************************************************************************************************************************************\r\nchanged: [localhost]\r\n\r\nTASK [check status] ***************************************************************************************************************************************************************************************************************\r\nFAILED - RETRYING: [localhost]: check status (90 retries left).\r\nFAILED - RETRYING: [localhost]: check status (89 retries left).\r\nchanged: [localhost]\r\n\r\nPLAY RECAP ************************************************************************************************************************************************************************************************************************\r\nlocalhost                  : ok=2    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0\r\n```\r\n ", "ok - let me run the same using our pipelines"]}, {"url": "https://github.com/Azure/sap-automation/pull/166", "comments": ["```suggestion\r\n      ansible.builtin.debug: \r\n```", "```suggestion\r\n      ansible.builtin.debug: \r\n```", "```suggestion\r\n      ansible.builtin.debug: \r\n```", "```suggestion\r\n      debug: \r\n```\r\n```suggestion\r\n      ansible.builtin.debug: \r\n```", "```suggestion\r\n    - name:                            \"1.10 Networking - Get the IP information from instance meta data service\"\r\n```", "```suggestion\r\n    - name:                            \"1.10 Networking - Pass the output of instance meta data to azure meta data function\"\r\n```", "```suggestion\r\n    - name:                            \"1.10 Networking - Filter out the values for IPAddresses in json format\"\r\n```", "```suggestion\r\n    - name:                            \"1.10 Networking - Convert ips to list\"\r\n```", "```suggestion\r\n    - name:                            \"1.10 Networking - Get the secondary IP\"\r\n```", "```suggestion\r\n    - name:                            \"1.10 Networking - Print ip info\"\r\n```"]}, {"url": "https://github.com/Azure/sap-automation/pull/79", "comments": ["```suggestion\r\n        tier:                          bom_processing\r\n```"]}, {"url": "https://github.com/Azure/sap-automation/pull/57", "comments": ["```suggestion\r\nname:    'HANA_2_00_055_v0006ms'\r\n```"]}, {"url": "https://github.com/Azure/sap-automation/pull/51", "comments": ["```suggestion\r\n      ansible.builtin.command:          ./hcmtsetup\r\n```", "```suggestion\r\n      ansible.builtin.command:              ./hcmt -v -p config/executionplan.json\r\n```", "```suggestion\r\n      ansible.builtin.find: \r\n```", "```suggestion\r\n      ansible.builtin.fetch:\r\n```", "```suggestion\r\n        flat: true\r\n```"]}, {"url": "https://github.com/Azure/sap-automation/pull/26", "comments": ["@KimForss when using IaaS NFS shares wouldn't this fail?"]}, {"url": "https://github.com/Azure/sap-automation/pull/25", "comments": ["```suggestion\r\n  ansible.builtin.debug:\r\n```", "```suggestion\r\n    msg:                           \"{{ sapbits_location_base_path }}/boms/{{ bom_base_name }}\"\r\n```", "> \r\n\r\nResolver in commit b50c03666a268e0527a05b30033c2ef206b31899", "> \r\n\r\nresolved in commit b50c03666a268e0527a05b30033c2ef206b31899"]}, {"url": "https://github.com/Azure/sap-automation/pull/5", "comments": ["```suggestion\r\n        playbookPathOnAgentMachine: 'sap-automation/deploy/ansible/playbook_04_00_01_db_ha'\r\n```", "pacemaker playbook is obsolete"]}, {"url": "https://github.com/Azure/sap-automation/pull/1", "comments": ["```suggestion\r\nThis pipeline performs the SAP System deployment\r\n```", "```suggestion\r\n          wget -q https://releases.hashicorp.com/terraform/1.0.8/terraform_1.0.8_linux_amd64.zip\r\n```", "```suggestion\r\n          unzip -qq terraform_1.0.8_linux_amd64.zip\r\n```", "```suggestion\r\n          sudo mv terraform /bin/ ; rm terraform_1.0.8_linux_amd64.zip\r\n```", "```suggestion\r\n# This pipeline performs the software download\r\n```", "```suggestion\r\n```", "```suggestion\r\n  default: DEV-NOEU-SAP01-X00\r\n```", "```suggestion\r\n  displayName: Base OS Configuration\r\n```", "```suggestion\r\n  displayName: SAP specific OS Configuration\r\n```", "```suggestion\r\n  displayName: Database Install \r\n```", "```suggestion\r\n- name: dbinstall\r\n```", "```suggestion\r\n- stage: DB_Install\r\n```", "```suggestion\r\n  - job: DB_Install\r\n```", "```suggestion\r\n      displayName: DB_Install\r\n```", "```suggestion\r\n        playbookPathOnAgentMachine: 'sap-automation/deploy/ansible/playbook_04_00_00_db_install.yaml'\r\n```", "```suggestion\r\n  - DB_Install\r\n```", "```suggestion\r\n  - DB_Install\r\n```", "```suggestion\r\n  - DB_Install\r\n```", "```suggestion\r\n  - DB_Install\r\n```", "```suggestion\r\n  - DB_Install\r\n```", "```suggestion\r\n  - DB_Install\r\n```", "```suggestion\r\n        playbookPathOnAgentMachine: 'sap-automation/deploy/ansible/playbook_04_00_01_db_ha.yaml'\r\n```"]}]}, {"url": "https://github.com/jjffggpp/jjffggpp.git", "pull_requests": []}, {"url": "https://github.com/cisagov/vulnerable-instances.git", "pull_requests": [{"url": "https://github.com/cisagov/vulnerable-instances/pull/2", "comments": ["I detest this style, but Terraform does appear to advocate it.", "Why the blank lines between bullets?", "Thanks- I was fighting with a linter message about blank lines between lists, but it turned out to be an issue with not indenting the subsequent lines of the list items.  Anyway, I got rid of those blank lines in 8673edc.", "I don't love it, but since `terraform_fmt` takes care of it automatically, I don't really care that much."]}]}, {"url": "https://github.com/greyhats13/avana-aws-infra.git", "pull_requests": []}, {"url": "https://github.com/lwilliams1990/deepfence-threatmapper-lab.git", "pull_requests": []}, {"url": "https://github.com/terraform-course/mastercourse.git", "pull_requests": []}, {"url": "https://github.com/adeelbarki/aws-with-terraform-and-ansible.git", "pull_requests": []}, {"url": "https://github.com/DFE-Digital/cf-monitoring.git", "pull_requests": [{"url": "https://github.com/DFE-Digital/cf-monitoring/pull/68", "comments": ["Could we add an output as well to print a message to the users, as in https://stackoverflow.com/questions/66675106/is-there-a-way-to-add-comments-for-teraform-to-display-at-the-end-of-terraform", "Output doesn't appear in logs unless defined in calling template"]}, {"url": "https://github.com/DFE-Digital/cf-monitoring/pull/65", "comments": ["Can we append APP_ALERT_RULES to ALERT_RULES just like we append POSTGRES_ALERT_RULES?", "There may be more than one if max_crash_count > 1", "Can we refer to max_elevated_req_failure_count instead of hardcoding 10%", "Could we set the default value in `try(settings.response_threshold, 1)` instead?", "The name of the app is unique in the whole paas so the space is not required here", "This is not an environment but a space, we can remove this label", "We don't really need the space as the app name is unique and contains the environment name", "I tried that first but it's failing since `groups` is duplicated in alert_rules and local.app_alert_rules.  So we have to use one of those 2 alert_rules objects.", "removed label.", "@saliceti  so what's the fix for this ?\r\n", "maybe 10% instead of 0.1?", "1 second", "This could be merged with the list above so we don't repeat it", "app alert yaml has  value 0.1 before i parameterized.  https://github.com/DFE-Digital/bat-infrastructure/blob/bde92d4444dd92f1d735b16e2171dc37b6fb89de/monitoring/config/alert.rules.tmpl#L70"]}, {"url": "https://github.com/DFE-Digital/cf-monitoring/pull/60", "comments": ["As discussed, let's not hardcode the labels", "Rename app to service_instance?", "This is not used", "Typo: postrgres", "The SpaceName should be the postgres service space, not the monitoring space. Could it be added to the alert template maybe?", "removed severity and environment", "Changed app to instance", "removed unused var definition", "Fixed typo (and the one above that I copied it from)", "Done. Had to change the alertable_postgres_services var to a map, so that a space could be set per instance"]}, {"url": "https://github.com/DFE-Digital/cf-monitoring/pull/54", "comments": ["`influxdb downsampling` rather than `influxdb downscaling`", "`Influxdb downsampling` rather than `Influxdb downscaling`", "Thanks!", "Thanks!"]}, {"url": "https://github.com/DFE-Digital/cf-monitoring/pull/51", "comments": ["Quotes are not required (same on line 20)"]}, {"url": "https://github.com/DFE-Digital/cf-monitoring/pull/36", "comments": ["Can we remove remote_write as it's read only?", "I am looking at that, on a previous attempt I had removed the write section and the config didn't work.  I dont know if it was something I had done wrong or whether it needed it. but I will relook at it after a coffee", "internal_apps is not required by the template", "Maybe `prometheus_readonly` would be a more explicit name?", "It may be simpler to use a boolean like `readonly = true`", "Thanks .. will remove", "true", "yup .. see that , will do", "Odd, I have removed the write section and it no longer reads :(", "Typo: scraper"]}, {"url": "https://github.com/DFE-Digital/cf-monitoring/pull/29", "comments": ["why not include it as part of the existing var.exporters? and have a default scarpe_internval for others?", "include as part of enabled modules?", "done", "done"]}, {"url": "https://github.com/DFE-Digital/cf-monitoring/pull/21", "comments": ["I think - ${app.name}-internal.apps.internal should be just ${app.name}.apps.internal  and it is the responsibility of the calling app to add the full name, i added -internal because of taste \r\n", "agree", "this can be removed?", "done. and i've moved the internal domain into a constant", "done"]}, {"url": "https://github.com/DFE-Digital/cf-monitoring/pull/17", "comments": ["should be `name` ?", "its identical to redis way, so in my case\r\n postgres_services                 = [\"${var.paas_space}/${var.paas_database_common_name}\"]\r\n\r\nIt equates too  **get-into-teaching/get-into-teaching-api-dev-pg-common-svc** \r\n\r\nso kept in line with REDIS way ", "can we just use `var.monitoring_space_id` for the space and\r\n`name = var.postgres_service_instance` and avoid the split?", "no, because we had that originally with redis but we needed two redis instances. and once upon a time we had two postgres instances, so I think it better to keep the same and allow expandability."]}, {"url": "https://github.com/DFE-Digital/cf-monitoring/pull/15", "comments": ["Shall we add this to the slack template file instead?\r\nI guess here: https://github.com/DFE-Digital/cf-monitoring/blob/master/alertmanager/config/slack.tmpl#L85", "done... and it worked too.."]}, {"url": "https://github.com/DFE-Digital/cf-monitoring/pull/14", "comments": ["can we just have one `exporters` array containing all exporters?\r\n```yml\r\nscrape_configs:\r\n%{ for exporter in exporters ~} \r\n- job_name: ${exporter.name}\r\n  scheme: ${exporter.scheme}\r\n  static_configs:\r\n    - targets: [${exporter.endpoint}]\r\n%{ endfor ~}\r\n```", "```suggestion\r\noutput exporter {\r\n  value = {\r\n   name       = cloudfoundry_route.redis_exporter.name\r\n   endpoint = cloudfoundry_app.redis-exporter.endpoint\r\n  }\r\n}\r\n```", "```suggestion\r\n```suggestion\r\noutput exporter {\r\n  value = {\r\n   name       = cloudfoundry_route.paas_prometheus_exporter.name\r\n   endpoint = cloudfoundry_app.paas_prometheus_exporter.endpoint\r\n  }\r\n}\r\n```\r\n```", "```suggestion\r\nvariable exporters { default = [] }\r\n```", "```suggestion\r\n  exporters                         = [module.redis_prometheus_exporters*.exporter, module.paas_prometheus_exporter[0].exporter]\r\n```\r\nsomething like this?", "Makes sense. I will look at it", "Excellant Idea", "is `pushgateway` for pushing custom metrics from app code?\r\nshould it be opt-in?", "accomplished", "why local_space and local_instance? should it be redis_space and redis_instance?", "do we need to set honor_labels per exporter? can't we leave it as false by default in prometheus?", "Can we take the opportunity to simplify? This should work:\r\n```\r\ninclude_alerting = var.alert_rules != \"\"\r\ninclude_scrapes = var.extra_scrape_config != \"\"\r\n```", "yes, I havent really finished this, so I was going to just default it for my testing, but I am worried about it having an external interface and allowing the world to push metrics in. so still needs a few changes.", "I really do need to learn how to type ..", "yes I will look at that", "will do", "Push gateway removed", "Can we change it to a `for_each`? This will be easier to identify the exporters.\r\nie `redis_prometheus_exporters[3].cloudfoundry_app.redis-exporter` will be `redis_prometheus_exporters[\"teaching-vacancies-production/teaching-vacancies-redis-queue-production\"].cloudfoundry_app.redis-exporter`", "Then you would have:\r\n`redis_service_instance = each.key`", "Please keep the name singular"]}, {"url": "https://github.com/DFE-Digital/cf-monitoring/pull/11", "comments": ["Can we pass a name instead? And add a data source to resolve the name to the id", "In my case where monitoring is  in a different space to the Redis Service, you would need to pass both the Name of the Redis Instance and the Name of the Space, then resolve both of them. ", "Shouldn't it be `var.redis_service_instance_id == null ?`\r\n", "Shouldn't it be\r\n`var.redis_service_instance_id == null ? null : module.redis_prometheus_exporter[0].endpoint`", "agreed", "Can we pass a list instead? We may have multiple redis instances to monitor (in teaching vacancies for example)"]}]}, {"url": "https://github.com/EOjeah/route53-ps.git", "pull_requests": []}, {"url": "https://github.com/UrbanOS-Examples/scos-alm-durable.git", "pull_requests": [{"url": "https://github.com/UrbanOS-Examples/scos-alm-durable/pull/21", "comments": ["Can we make the version a variable so we don't have to update it in so many places?"]}, {"url": "https://github.com/UrbanOS-Examples/scos-alm-durable/pull/16", "comments": ["does it make sense to name these \"test\" or something to indicate they are pre-configured for something and not general purpose?", "do we want these to be alphabetized?", "I'll give an approve, but I do think it would be nice to alphabetize this. ", "It would be, wouldn't it.", "Done"]}]}, {"url": "https://github.com/latacora/latacora-service-control-policies.git", "pull_requests": [{"url": "https://github.com/latacora/latacora-service-control-policies/pull/12", "comments": ["This is fine for now but it's wild that this is still how you do conditionals in modern Terraform"]}, {"url": "https://github.com/latacora/latacora-service-control-policies/pull/8", "comments": ["Should remove these now that we have replaced them. ", "I know I said organizations before, but not sure if that is actually the right call. \r\n\r\nMaybe a service like \"Global\" to make it understood it works on all services would be better. ", "Typo - \"...to learn more about this issue before **deployment**\""]}]}, {"url": "https://github.com/amatas/test-exekube.git", "pull_requests": []}, {"url": "https://github.com/terraform-google-modules/terraform-google-cloud-storage.git", "pull_requests": [{"url": "https://github.com/terraform-google-modules/terraform-google-cloud-storage/pull/309", "comments": ["So we can default to the provider default\r\n\r\n```suggestion\r\n  default = { }\r\n```", "Okay, made it optional for the type to work"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-cloud-storage/pull/308", "comments": ["Nice work - and appreciated.\r\n\r\nIdeally, runtime issues (during terraform apply) are caught during validation.\r\nThere are consequences for the client when a resource fails that may require mitigation to get back on track.  A partial deploy may need some rollback or recreation of resources and/or use up quota in the case of project recreation.\r\n\r\nif we already know that the bucket name through some naming convention will not pass through the GCP API - it helps to know this upfront.  A length and format check like what occurs here is greatly appreciated by the client - but even more by the CD pipeline (cloud build or ADO...)\r\n\r\nThis PR fixes an issue that is part of the family if issues that occur only at commit time - some of these like quota limits are hard to test for or simulate - but naming standards are one of the main requests by public sector clients", "As stated, there are too many areas where this can occur. ", "From a maintenance perspective these are hard keep upto date as the API evolves. Additionally rather than doing this at the module layer, this should be upstreamed to the provider which I believe already checks a subset https://github.com/hashicorp/terraform-provider-google/blob/main/google/tpgresource/utils.go#L539", "Thanks for the suggestion @bharathkkb. I opened the following issue and PR to address this:\r\n* https://github.com/hashicorp/terraform-provider-google/issues/17831\r\n* https://github.com/GoogleCloudPlatform/magic-modules/pull/10426"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-cloud-storage/pull/303", "comments": ["Since upstream APIs can change this would be hard to keep upto date in the module. The provider seems to have some prior art doing this, my suggestion would be to upstream this check there\r\nhttps://github.com/hashicorp/terraform-provider-google/blob/678449a1b0559d19b430ed760056734ea25c5e96/google/services/cloudfunctions/resource_cloudfunctions_function.go#L48"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-cloud-storage/pull/265", "comments": ["Unless autoclass is currently enabled by default, we should probably default this to `false` to maintain existing behavior (avoid breaking change).\r\n\r\n```suggestion\r\n  default     = false\r\n```", "```suggestion\r\n  description = \"Optional map of lowercase unprefixed bucket name => boolean, defaults to false.\"\r\n```"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-cloud-storage/pull/238", "comments": ["```suggestion\r\nNo outputs.\r\n```"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-cloud-storage/pull/231", "comments": ["Is this syntax supported in TF 0.13?  \r\n\r\nhttps://github.com/terraform-google-modules/terraform-google-cloud-storage/blob/master/modules/simple_bucket/versions.tf#L18", "Yeah, it is.\r\nI also tested doing a `terraform plan` on 0.13.0. Worked out fine (see picture)\r\n\r\n![Screenshot 2023-03-21 at 14 01 24](https://user-images.githubusercontent.com/10381866/226613739-f3cd8718-226a-4e61-8e82-c7a412675e96.png)\r\n", "Thanks!"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-cloud-storage/pull/202", "comments": ["Since `condition` is a `map(string)` and there fields need a [list input per provider](https://github.com/hashicorp/terraform-provider-google/blob/d2ea6580ef848edd94862d13ab7cddcb162df904/google/resource_storage_bucket.go#L213), we would need to follow an approach like `matches_storage_class` taking these in as a comma delimited string.", "Got it! In the `simple_bucket` module I saw that `matches_storage_class` is not joining with commas like the primary module. I updated the line there as well.\r\n\r\nhttps://github.com/terraform-google-modules/terraform-google-cloud-storage/blob/dc0f1ab886be433d48490903b569e700491643ee/modules/simple_bucket/main.tf#L74", "```suggestion\r\n        matches_storage_class      = contains(keys(lifecycle_rule.value.condition), \"matches_storage_class\") ? split(\",\", lifecycle_rule.value.condition[\"matches_storage_class\"]) : null\r\n```", "I believe this should now be just a string? Tests are failing with\r\n```\r\nTestAll/examples/simple_bucket 2022-12-12T17:57:50Z command.go:185: Error: Invalid function argument\r\nTestAll/examples/simple_bucket 2022-12-12T17:57:50Z command.go:185: \r\nTestAll/examples/simple_bucket 2022-12-12T17:57:50Z command.go:185:   on ../../modules/simple_bucket/main.tf line 75, in resource \"google_storage_bucket\" \"bucket\":\r\nTestAll/examples/simple_bucket 2022-12-12T17:57:50Z command.go:185:   75:         matches_prefix             = contains(keys(lifecycle_rule.value.condition), \"matches_prefix\") ? split(\",\", lifecycle_rule.value.condition[\"matches_prefix\"]) : null\r\nTestAll/examples/simple_bucket 2022-12-12T17:57:50Z command.go:185:     \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\r\nTestAll/examples/simple_bucket 2022-12-12T17:57:50Z command.go:185:     \u2502 lifecycle_rule.value.condition[\"matches_prefix\"] is tuple with 1 element\r\nTestAll/examples/simple_bucket 2022-12-12T17:57:50Z command.go:185: \r\nTestAll/examples/simple_bucket 2022-12-12T17:57:50Z command.go:185: Invalid value for \"str\" parameter: string required.\r\n```\r\n"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-cloud-storage/pull/185", "comments": ["I am not sure why this would happen with the proposed code change in the module? Did this happen for you locally?", "I just wanted to flag the current example didn't work for me, hence I changed it. If you're fine with the proposed example I'm happy to drop the comment.", "Hi @Tensho - The INT tests also include assertions for the example which need to match: https://github.com/terraform-google-modules/terraform-google-cloud-storage/blob/master/test/integration/multiple_buckets/multiple_buckets_test.go#L56", "Fair enough, I'll make adjustments.", "@apeabody The test passes now:\r\n```\r\n[root@bb37621fcfea workspace]# cft test run all\r\nok  \tgithub.com/terraform-google-modules/terraform-google-cloud-storage/test/integration\t65.892s\r\nok  \tgithub.com/terraform-google-modules/terraform-google-cloud-storage/test/integration/multiple_buckets\t92.755s\r\n```", "FYI: This will be a breaking change for existing users.  Probably can use something like `terraform state mv 'random_id.bucket_suffix.hex' 'random_id.bucket_suffix[0].hex'` to migrate the existing suffix to the new resource location.", "I specified it in the PR description \"Note\" section \u2013 it won't be a breaking change. Terraform implicitly modifies the state. Try to run the following experiment:\r\n\r\n1. Draft a simple configuration without `count` and apply it:\r\n\r\n    ```hcl\r\n    resource \"random_id\" \"x\" {\r\n      byte_length = 1\r\n    }\r\n    ```\r\n    ```shell\r\n    $ terraform apply -auto-approve\r\n    Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:\r\n      + create\r\n    \r\n    Terraform will perform the following actions:\r\n    \r\n      # random_id.x will be created\r\n      + resource \"random_id\" \"x\" {\r\n          + b64_std     = (known after apply)\r\n          + b64_url     = (known after apply)\r\n          + byte_length = 1\r\n          + dec         = (known after apply)\r\n          + hex         = (known after apply)\r\n          + id          = (known after apply)\r\n        }\r\n    \r\n    Plan: 1 to add, 0 to change, 0 to destroy.\r\n    random_id.x: Creating...\r\n    random_id.x: Creation complete after 0s [id=wA]\r\n    \r\n    Apply complete! Resources: 1 added, 0 changed, 0 destroyed.\r\n    ```\r\n\r\n1. Modify resource with `count` and apply it:\r\n\r\n    ```hcl\r\n    resource \"random_id\" \"x\" {\r\n     count = 1\r\n     byte_length = 1\r\n    }\r\n    ```\r\n    ```shell\r\n    $ terraform apply -auto-approve\r\n    random_id.x[0]: Refreshing state... [id=wA]\r\n    \r\n    Terraform will perform the following actions:\r\n    \r\n      # random_id.x has moved to random_id.x[0]\r\n        resource \"random_id\" \"x\" {\r\n            id          = \"wA\"\r\n            # (5 unchanged attributes hidden)\r\n        }\r\n    \r\n    Plan: 0 to add, 0 to change, 0 to destroy.\r\n    \r\n    Apply complete! Resources: 0 added, 0 changed, 0 destroyed.\r\n    ```\r\n\r\nPay attention resource has been moved, no replacement happened.", "Thanks for explanation @Tensho!\r\n\r\nI just confirmed this worked on TF 0.13 (https://github.com/terraform-google-modules/terraform-google-cloud-storage/blob/master/versions.tf#L18), although the messaging is not as clear:\r\n\r\n```\r\n./terraform apply\r\nrandom_id.x[0]: Refreshing state... [id=9w]\r\n\r\nApply complete! Resources: 0 added, 0 changed, 0 destroyed.\r\n```"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-cloud-storage/pull/181", "comments": ["Lets set project explicitly", "Can we use var.hmac_service_accounts directly instead of having a bool flag?", "Do you mean to add the next string?\r\n`project = var.project_id`", "Sorry, I'm not sure that I understand you clearly. Do you want to use it like this?\r\n`for_each = var.hmac_service_accounts`", "Yes, otherwise it will depend on provider default", "Right since it's {} by default.", "Done", "Without this condition, we can't drop all hmac access using only one variable \"set_hmac_access\". \r\nFor example, I have a few service accounts with hmac access, and I want to drop them all temporarily. Maybe in the future, I will want to back. And for more convenient usage I can set the variable to false to delete all hmac access without deleting all lists of service accounts from a code.\r\nI think with this condition it is better. "]}, {"url": "https://github.com/terraform-google-modules/terraform-google-cloud-storage/pull/173", "comments": ["Why is this being removed?"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-cloud-storage/pull/169", "comments": ["```suggestion\r\n  description = \"Override lifecycle_rules for a specific bucket. Map of lowercase unprefixed name => list of lifecycle rules to configure.\"\r\n```", "Can we add an assert that the other bucket also has the expected rule? ", "The current implementation doesn't **override** lifecycle rules, it appends them: [`for_each = setunion(var.lifecycle_rules, lookup(var.bucket_lifecycle_rules, each.value, toset([])))`](https://github.com/terraform-google-modules/terraform-google-cloud-storage/pull/169/files#diff-dc46acf24afd63ef8c556b77c126ccc6e578bc87e3aa09a931f33d9bf2532fbbR108):\r\n\r\nSo what do you think of \r\n```suggestion\r\n  description = \"Additionnal lifecycle_rules for specific buckets. Map of lowercase unprefixed name => list of lifecycle rules to configure.\"\r\n```", "No we cannot, because the other bucket (`\"two\"`) should not have it.\r\nI can try to add an assert that the other bucket doesn't have this rule, but it may be a little bit difficult: should I only assert that `metadata.lifecycle.rule[1]` does not exist, or should I check each element of `metadata.lifecycle.rule` to make sure that it doesn't match the new rule ?", "sgtm", "@AlexisBRENON sorry I should have clarified - I meant we should check that it only has the one expected SetStorageClass rule. I think asserting length of one for that slice is fine."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-cloud-storage/pull/132", "comments": ["This should actually be a list.\r\n\r\n```suggestion\r\n  type        = set(any)\r\n```", "I technically agree that this would make more sense here. I was just following the description which clarifies this being a \"map of maps\". The only downside might be a complete reconfiguration of all CORS definition in case one list element gets removed. @morgante WDYT?", "I think ideally we accept a set. I don't think reordering should matter much since they're all sub-blocks of the same resource.\r\n\r\nSince this was never working before, it's fine to change the types."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-cloud-storage/pull/128", "comments": ["we should use `any` and look up. This way users won't have to provide empty values for unused fields. [Example](https://github.com/terraform-google-modules/terraform-google-cloud-storage/blob/a0982c94f92df37d903af0a85e7ee5fe1e655d1e/variables.tf#L192)"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-cloud-storage/pull/127", "comments": ["While this works, it's better if we don't index over the `map` itself.\r\n\r\n```suggestion\r\n    for_each = lookup(var.retention_policy, each.value, {}) != [] ? [var.retention_policy[each.value]]\r\n\r\n```"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-cloud-storage/pull/124", "comments": ["```suggestion\r\n  version = \"~> 2.2\"\r\n```"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-cloud-storage/pull/117", "comments": ["We should use this same logic for the top-level module as well.", "I'd prefer to keep the top-level module logic the same, as I believe it aligns with the raw bucket resource inputs better. For example this is a valid value for the `logging` variable in the top-level module:\r\n```\r\n{\r\n  first = {\r\n    log_bucket = \"test-bucket\"\r\n  }\r\n  second = {\r\n    log_bucket = \"test-bucket\"\r\n    log_object_prefix = \"test-prefix\"\r\n  }\r\n}\r\n```\r\nand in this case, GCS itself handles making the prefix the same as the bucket name for `first`.\r\nThe only reason I implemented the ternary logic in the `simple_bucket` module is that I set the type of the input variable to be an object with two strings, and the `optional` constraint is currently experimental in terraform 0.14. This means that the following is NOT a valid value for logging in the `simple_bucket` module, and so to obtain the default GCS behaviour I implemented the bucket name/prefix logic manually:\r\n```\r\n{\r\n  log_bucket = \"test-bucket\"\r\n}\r\n```\r\n\r\nThere are two solutions that I'd choose over re-implementing the logic in the root module:\r\n1. Change the type of the `logging` variable in the `simple_bucket` module to `any` and document the input format better, similar to the nested objects in `lifecycle_rules` - this would allow passing in the `log_object_prefix` field to actually be optional\r\n2. Leave it as-is, and have a small difference in logic between the modules\r\n\r\nWhat are your thoughts @morgante (Also thanks for taking a look at this so quick!)", "In that case, I'd like to actually update the `simple_bucket` submodule to accept `log_bucket` and `log_object_prefix` as top-level variables. I don't think the layer of indirection in an object is helpful.", "makes sense, have made this change @morgante "]}, {"url": "https://github.com/terraform-google-modules/terraform-google-cloud-storage/pull/80", "comments": ["We definitely shouldn't need to set up a budget.", "I agree but it seems the project-factory module v7 requires it? https://registry.terraform.io/modules/terraform-google-modules/project-factory/google/7.0.0?tab=inputs", "It's optional. You might want to upgrade to the latest version (9.0.0): https://github.com/terraform-google-modules/terraform-google-project-factory", "let me try again with v6 which doesn't require it", "To be clear no version has ever required it.https://github.com/terraform-google-modules/terraform-google-project-factory/tree/v7.0.0#inputs", "Thanks, i was looking at the wrong thing"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-cloud-storage/pull/64", "comments": ["\r\n```suggestion\r\n  default     = [\"one\", \"two\"]\r\n```\r\nint test failing to to mismatch, between folders defined in https://github.com/terraform-google-modules/terraform-google-cloud-storage/blob/7c32ee228895d1bf42a54387776c3e1fb48eae7c/test/fixtures/multiple_buckets/main.tf#L33 and default here.\r\n", "Thanks for the catch, I was changing things around for testing."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-cloud-storage/pull/63", "comments": ["@pkatsovich Could you remove this? While I agree with it, this is a breaking change which I'd like to avoid.", "Thanks for the quick review, @morgante  . I've removed this change."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-cloud-storage/pull/57", "comments": ["Can we make this a relative path?", "So I think relative paths for PRs are still buggy: https://github.com/github/markup/issues/576\r\nI was able to do a workaround. PTAL\r\n", "Example with relative path staged here: https://github.com/bharathkkb/terraform-google-cloud-storage/pull/8", "Great, let's also make that the default (in the central script) so we don't have to specify it for each repo."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-cloud-storage/pull/52", "comments": ["We should hardcode this or provide a default.", "If we hard code it won't it have a conflict? Since buckets are globally unique", "Good point."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-cloud-storage/pull/49", "comments": ["nit: Are we switching to `any` to keep the end user configs more concise? \r\nvs main module types\r\nhttps://github.com/terraform-google-modules/terraform-google-cloud-storage/blob/a0782d700d7f2b5c726bf3a42d8c9dc723795a7a/variables.tf#L132", "Right, this is a temporary type and is due to the fact that terraform does not support optional keys in objects.\r\n\r\nIn the main module, I am guessing you always need to set `storage_class` on the action to empty or null, even if you only want to set `type`?\r\n\r\nOnce Terraform can support optional keys then we can describe the entire schema.\r\n\r\nNote: if the user tries to use any other type it will cause an error so this is relatively safe. The only major downside is it won't catch any extra fields set in the object.", "Note: also can't use map(string) without breaking the interface like how the main module forces matches_storage_class to be a string instead of list of strings like the underlying API. I believe any is better than map(string) because it lets you preserve the underlying API.", "yeah I agree. `any` lgtm, I was wondering if making a similar change to `any` type on the main module is also worthwhile, since it seems to be the best option as we wait for optional keys in obj.  ", "+1 to backporting this to the main module."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-cloud-storage/pull/48", "comments": ["Looking at the `google_storage_notification` resource docs I think `object_name_prefix` and `custom_attributes` seem useful to be user configurable.", "nit: I think you meant to remove this?", "nit: I think you meant to remove this?", "```suggestion\r\nvariable \"pubsub_notification_topics\" {\r\n```"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-cloud-storage/pull/43", "comments": ["There is already a type constraint defined above actually.", "whoops! let me take care of that. "]}, {"url": "https://github.com/terraform-google-modules/terraform-google-cloud-storage/pull/35", "comments": ["Instead of requiring users to set IAM roles themselves (and potentially misconfiguring IAM), could we use `bucket_admins`, `bucket_creators`, and `bucket_viewers` variables?", "For consistency, let's call this `project_id`.", "Just to be clear, you mean helper iam fields in addition to iam_members?\r\n\r\nIf we require a helper field for every role it can get quite large and somewhat inflexible I imagine (esp if using custom roles, etc like in https://github.com/terraform-google-modules/terraform-google-cloud-storage/issues/18).\r\n\r\nAlso other modules like healthcare, etc also just have a single iam_members field.", "Fair point, I was mostly thinking about consistency with the existing module. I guess it's a nice-to-have but not required.\r\n\r\nAgreed with should always support explicit `iam_members`.", "Great. I'll hold off on this for the initial version. I think it's worth it for users to understand the exact roles they are assigning as there are some subtle differences e.g. roles/storage.admin vs roles/storage.objectAdmin. We can definitely expand it in the future as you mentioned alongside explicit iam_members.", "Done.", "```suggestion\r\n- One GCS buckets\r\n```", "```suggestion\r\n- Zero or more IAM bindings for that bucket\r\n```", "There's no version of this module for TF 0.11. Could probably drop this whole section.", "Remove.", "```suggestion\r\n  description = \"The ID of the project to create the bucket in.\"\r\n```", "```suggestion\r\n  description = \"When deleting a bucket, this boolean option will delete all contained objects. If false, Terraform will fail to delete buckets which contain objects.\"\r\n```"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-cloud-storage/pull/34", "comments": ["I think we should have a more descriptive name.\r\n\r\n```suggestion\r\nvariable \"encryption_key_name\" {\r\n```", "```suggestion\r\n          # Omitting default is deprecated & can help show if there was a bug\r\n```", "Yeah I started with a longer name but I ended up with a short one. I'll get these sorted and pushed soon :)", "I've gone with `encryption_key_names` plural just because it's a list but I can amend the commit to `encryption_key_name` if you'd prefer", "Either sounds good!"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-cloud-storage/pull/32", "comments": ["It seems like there should be a separate iam_binding for a custom role"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-cloud-storage/pull/22", "comments": ["I suppose `toset([])` will cause an error (in case of `set_admin_roles` set to false) for tf versions before 0.12.9\r\nhttps://github.com/hashicorp/terraform/issues/22281\r\nShall we update the `versions.tf` and redame?", "Good point, yes `versions.tf` bump, and we also need a migration guide/tool which is a bit tricky.", "```suggestion\r\n  for_each = var.set_object_creator_roles ? local.names : toset([])\r\n```", "```suggestion\r\nvariable \"set_object_admin_roles\" {\r\n```", "```suggestion\r\n  for_each = var.set_object_admin_roles ? local.names : toset([])\r\n```", "```suggestion\r\nvariable \"set_object_creator_roles\" {\r\n```", "```suggestion\r\nvariable \"set_object_viewer_roles\" {\r\n```", "```suggestion\r\nvariable \"set_hmac_key_admin_roles\" {\r\n```", "```suggestion\r\n  description = \"Map of lowercase unprefixed name => comma-delimited IAM-style per-bucket storage admins.\"\r\n```", "```suggestion\r\n  description = \"Map of lowercase unprefixed name => comma-delimited IAM-style per-bucket HMAC key admins.\"\r\n```", "```suggestion\r\nvariable \"object_viewers_by_bucket\" {\r\n```", "```suggestion\r\nvariable \"object_creators_by_bucket\" {\r\n```", "```suggestion\r\nvariable \"object_viewers\" {\r\n```", "```suggestion\r\nvariable \"object_admins\" {\r\n```", "```suggestion\r\nvariable \"hmac_key_admins\" {\r\n```", "```suggestion\r\nvariable \"object_admins_by_bucket\" {\r\n```", "```suggestion\r\n    split(\",\", lookup(var.storage_admins_by_bucket, each.key, \"\"))\r\n```", "```suggestion\r\n    split(\",\", lookup(var.hmac_key_admins_by_bucket, each.key, \"\"))\r\n```", "```suggestion\r\n    split(\",\", lookup(var.object_creators_by_bucket, each.key, \"\"))\r\n```", "```suggestion\r\n    split(\",\", lookup(var.object_admins_by_bucket, each.key, \"\"))\r\n```", "```suggestion\r\n  for_each = var.set_hmac_key_admin_roles ? local.names : toset([])\r\n```", "```suggestion\r\nresource \"google_storage_bucket_iam_binding\" \"hmac_key_admins\" {\r\n```", "```suggestion\r\nvariable \"hmac_key_admins_by_bucket\" {\r\n```", "```suggestion\r\nvariable \"storage_admins_by_bucket\" {\r\n```", "```suggestion\r\n  description = \"Grant roles/storage.admin role to storage_admins and storage_admins_by_bucket.\"\r\n```", "```suggestion\r\n  description = \"Grant roles/storage.hmacKeyAdmin role to storage_admins and storage_admins_by_bucket.\"\r\n```", "```suggestion\r\n  description = \"Grant roles/storage.objectCreator role to creators and object_creators_by_bucket.\"\r\n```", "```suggestion\r\n  description = \"Grant roles/storage.objectAdmin role to admins and object_admins_by_bucket.\"\r\n```"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-cloud-storage/pull/19", "comments": ["Are you sure they shoudn't be ordered?", "You can't skip providing these values due to the way terraform checks types. These checks are redundant", "I suggest checking JSON instead of strings", "yes, no order", "fixed", "Looks like a misformatting? Shouldn't have a tab here.", "Please hard-code an example directly instead of making this a variable.", "Referring to \"blocks\" is confusing in this context.\r\n\r\nInstead we should say something like:\r\n```suggestion\r\n  description = \"List of lifecycle rules to configure. Format is the same as described in provider documentation https://www.terraform.io/docs/providers/google/r/storage_bucket.html#lifecycle_rule except condition.matches_storage_class should be a comma delimited string.\"\r\n```", "Since we're hardcoding this now, can we remove the variable?", "Remove variable.", "Remove, this is set in the example?", "@morgante  make sense to leave it in once place, you suggest to set it in example but not here, right?", "@kopachevsky To be clear, I don't want *any* variables for lifecycle_rules in either examples or fixtures, it can just be hardcoded in the example.", "did it in example ", "But you still have a variable in the example. Please remove the variables, as I've said a number of times.", "@kopachevsky Please regenerate docs.", "sorry, my mistake", "done"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-cloud-storage/pull/15", "comments": ["Instead of maintaining this separately, could we also copy over the standard [Contributing file](https://github.com/terraform-google-modules/terraform-google-module-template/blob/master/terraform-google-%7B%7Bcookiecutter.module_name%7D%7D/CONTRIBUTING.md)?", "Added"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-cloud-storage/pull/10", "comments": ["We should use the new 'devex' image, like KMS: https://github.com/terraform-google-modules/terraform-google-kms/blob/master/build/lint.cloudbuild.yaml", "done, thanks"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-cloud-storage/pull/9", "comments": ["Is this intentional? The dropping of location looks like a functionality change.", "This looks like an unrelated change?", "True, reasoning was that it's easy to inject that in prefix if needed. But let's revert, move to 0.12, then maybe pick this up again.", "You mean force destroy? Yep, forgot I had added it. :) I think it's really needed, it can of course go in a separate PR if you prefer.", "Agreed, let's do that in a separate PR if it's needed.", "Fine to keep it here, just please add a note to the CHANGELOG.", "Reverted and retested, thanks.", "Added note."]}, {"url": "https://github.com/terraform-google-modules/terraform-google-cloud-storage/pull/8", "comments": ["The outer string interpolation can be removed here.", "Done. This wasn't used before so i've also fixed that in this PR. Old behaviour meant that with a empty `prefix` your final bucket name would be `-{name}`.\r\n\r\nNew behaviour:\r\n```\r\n# prefix=\"\"\r\n+ name               = \"first\"\r\n\r\n# prefix=\"foo\"\r\n+ name               = \"foo-eu-first\"\r\n```"]}, {"url": "https://github.com/terraform-google-modules/terraform-google-cloud-storage/pull/6", "comments": ["No need to make this a variable in the example IMO. Let's just leave it off.", "To be clear -- leave out test coverage for this functionality?", "I see now that the way tests are set up in this repo is (slightly) suboptimal, so we can leave as-is."]}]}, {"url": "https://github.com/SamTowne/BasketballDrillBot.git", "pull_requests": []}, {"url": "https://github.com/Crown-Commercial-Service/ccs-scale-infra-services-fat.git", "pull_requests": [{"url": "https://github.com/Crown-Commercial-Service/ccs-scale-infra-services-fat/pull/183", "comments": ["This will need to be the ARN of the secure SSM param - not the value", "but on this [file](https://github.com/Crown-Commercial-Service/ccs-scale-infra-services-fat/blob/a8991d0057c123fb4706ed6cfa25e395070d5e2d/terraform/modules/configs/deploy-all/main.tf#L242), the name of the variable is `rollbar_access_token`"]}, {"url": "https://github.com/Crown-Commercial-Service/ccs-scale-infra-services-fat/pull/179", "comments": ["This variable will need adding to the this module's vars too (has to be passed down through the entire module hierarchy)", "as above", "as above"]}, {"url": "https://github.com/Crown-Commercial-Service/ccs-scale-infra-services-fat/pull/169", "comments": ["Why is this being changed to UAT? As per the bug raised(https://crowncommercialservice.atlassian.net/browse/SFAT-376) we don't want it to be UAT."]}, {"url": "https://github.com/Crown-Commercial-Service/ccs-scale-infra-services-fat/pull/158", "comments": ["Think it should be 'Your name's not on the list, you're not getting in', but happy with 'Access denied' \ud83d\ude04 ", "So this triggers a redeployment on policy change I guess?", "> Think it should be 'Your name's not on the list, you're not getting in', but happy with 'Access denied' \ud83d\ude04\r\n\r\n\ud83d\ude04 \"Computer says No....\"?", "Yep exactly - uncovered it during the first round of changes to make the APIs private (which also involved a policy). This seemed the most reliable way to initiate a deployment.  Otherwise you are forced to make a manual deployment, but then when you run the next `terraform apply` it sees drift in the deployment ID and overwrites it back to _not having_ a policy at all, or the previous version."]}, {"url": "https://github.com/Crown-Commercial-Service/ccs-scale-infra-services-fat/pull/132", "comments": ["Snapshot version crept into this PR for decision tree DB service - remove", "Ahh - sorry - will update (actually need to deploy a new one - so 2 birds with one PR)", "Updated now \ud83d\udc4d "]}, {"url": "https://github.com/Crown-Commercial-Service/ccs-scale-infra-services-fat/pull/22", "comments": ["Do you think it's worth passing this in via container secrets? Little point I guess unless you can restrict access to view the keys in the AWS Console too - which I can't recall atm.. \ud83e\udd14 ", "@tommyb82   I did think of that, but as you say if you have console access - then these keys are all visible via the API Gateway anyway so wasn't sure if that added any value. I can add it to the tech debt register to look at again? ", "Actually - I can give it a quick try on SBX5 to see if it still works - makes sense to do it still I think"]}, {"url": "https://github.com/Crown-Commercial-Service/ccs-scale-infra-services-fat/pull/6", "comments": ["`guided_match`", "I checked too - but the endpoint name, not the DB name d'oh! Sorry - updated now"]}]}, {"url": "https://github.com/nlitterat/env0-playground.git", "pull_requests": []}, {"url": "https://github.com/lostcities-cloud/devops.git", "pull_requests": []}, {"url": "https://github.com/ecsworkshop2018/expertalk-2018-ecs-workshop.git", "pull_requests": [{"url": "https://github.com/ecsworkshop2018/expertalk-2018-ecs-workshop/pull/3", "comments": ["```suggestion\r\nversioning {\r\n    enabled = true\r\n  }\r\n```", "Any reason this is mentioned. Isn't prevent_destroy false default?", "I don't think it is recommended practice to update the vpc main route table to allow traffic to the internet. Any Subnets created under the VPCs inherit the routes from the main routing table implicitly unless you associate a separate table to them. So it better to create a separate public table and explicitly assign it to public subnets. \r\nAt least this is the case if done from aws console.", "Intended for it to be true. Committed the fix"]}]}, {"url": "https://github.com/amezousan/serverless-blog-in-aws.git", "pull_requests": [{"url": "https://github.com/harrythecode/serverless-blog-in-aws/pull/1", "comments": ["**POST** method may be used later. It would be nice to add here in advance, even though you don't have any plan for that. Because it takes quite a time to deploy cloudfront.", "As of now, TLSv1 is vulnerable to man-in-the-middle attacks, which is not secure to users. I recommend you to specify here either: `TLSv1_2016`, `TLSv1.1_2016` or `TLSv1.2_2018`\r\n\r\nRef: https://www.terraform.io/docs/providers/aws/r/cloudfront_distribution.html#minimum_protocol_version", "I think you're missing an instruction here, because you don't mention how to modify the s3.tfbackend file.", "I want to see the pic, which makes it more clear.", "What do you want to show here?", "Instead of having simple words, you can mention a bit clear steps so that we can make sense.", "I'll add POST as well!", "I'll update it to use `TLSv1.1_2016`", "I'll add this.", "Sure!", "I'll have AWS architecture overview here (e.g., which component will be deployed in your Aws account. etc)", "Okay :) ", "FYI: During terraforming, I got the error below:\r\n```\r\nThe parameter AllowedMethods is invalid (must be: [HEAD, GET] or [HEAD, GET, OPTIONS] or [HEAD, DELETE, POST, GET, OPTIONS, PUT, PATCH]).\r\n```\r\n\r\nSo, I choose the full method option."]}]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta.git", "pull_requests": [{"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/476", "comments": ["Still keeping the emoji?"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/469", "comments": ["I guess `jq` default quoting for outputted strings makes the `$(...)` here work, which is interesting...", "yes i thought it was quite neat"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/466", "comments": ["```suggestion\r\n        runbook: \"https://re-team-manual.cloudapps.digital/prometheus-for-gds-paas-users.html#re-observe-prometheus-at-least-one-missing\"\r\n```", "God damn it. Also, of course, this section doesn't exist yet so that's another TODO"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/463", "comments": ["Does the denominator of the fraction also need an exclusion for the static errors app?  Otherwise the percent won't be quite right.", "No, Prometheus matches labels when doing arithmetic on metrics.  See https://prometheus.io/docs/prometheus/latest/querying/operators/#vector-matching", ":exploding_head: "]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/455", "comments": ["Should this (and elsewhere) be `labels.product`?", "`labels.app` will tell us whether this is the account manager or attribute service, whereas `labels.product` will just say `govuk-accounts` ([here's an example in Prometheus dashboard](https://prom-2.monitoring.gds-reliability.engineering/graph?g0.range_input=1h&g0.expr=sum%20without(exported_instance%2C%20status_range)%20(rate(requests%7Borg%3D%22govuk-accounts%22%2C%20space%3D%22production%22%2C%20status_range%3D%225xx%22%7D%5B5m%5D))%20%2F%20sum%20without(exported_instance%2C%20status_range)%20(rate(requests%7Borg%3D%22govuk-accounts%22%2C%20space%3D%22production%22%7D%5B5m%5D))&g0.tab=1))."]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/453", "comments": ["Does this need a double-dollar by any chance? (see other examples of its use in this file)", "@risicle @46bit I took this directly from the documentation at https://github.com/alphagov/paas-prometheus-endpoints/tree/main/src/redis#setup as such please may the documentation be updated?", "added in 9a081d2", "Ah I think _that_ example is probably right, the extra dollar here is because this is actually a `.yml.tpl` - a terraform-template of yaml, and the extra `$` is to escape the terraform templating.\r\n\r\nIsn't life fun?", "the double dollar is because of this codebase, not relevant to those other docs. sorry this is such a pain--custom config of the observe prometheus is something i added in a hurry and it's not a widely-used feature. ping me on slack if you want to pair"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/452", "comments": ["i made this domain up, i don't know what the correct thing is", "this is also made up", "Oh. How long were you going to wait for me to realize I'd mapped the wrong route path on the internal prometheus (I thought it used `/metrics` like anything else)", "I think we should only annotate the hostname that the metrics were federated _from_ here, because that's all we know for sure at this end. I think it would be better to annotate space/org/region/app name from the federated end, where it can be injected via the terraform template and is less likely to get out of sync.", "All domains are made up, man."]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/450", "comments": ["we'll either need to add this into `data.template_file.alertmanager_nlb_container_defn` next to `default.tmpl`, or (probably easier for now) whack it into `default.tmpl`.", "```suggestion\r\n  - html: '{{ template \"zendesk.notify.text\" . }}'\r\n```\r\nit's not html, as you say in the PR description :)", "```suggestion\r\n{{ define \"zendesk.notify.text\" }}\r\n```"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/447", "comments": ["On the naming of the key, is the key specific to P2 incidents, or is it not specific to the priority?", "It is specific to p2 incidents. We have one key for p1 incidents and one key for p2 incidents (although this PR only adds the p2 key as we don't yet require the p1 key in any of these alerts)", "Cool, good to know :+1: "]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/416", "comments": ["What does `_` mean?", "am I being blind or does this target group not exist?", "It's a convention in some languages (maybe not terraform?) to mean \"this is a variable I have to set but which I don't care about\".  I only want the values from the map, not the keys.", "it's in `alb.tf`", "...which is an untracked file. D'oh!", "I can confirm `alertmanager_per_az` does not exist.", "now added"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/409", "comments": ["I'm not entirely convinced this will match the `1 +` logic so I'd appreciate someone familiar with this to check this carefully.", "I'm not entirely convinced this will match the `1 +` logic so I'd appreciate someone familiar with this to check this carefully.", "I think this is fine as long as it works at all.  The `1 + length` logic is just an expression which should match the expected size of `aws_acm_certificate.alertmanager_cert.domain_validation_options` without having to dynamically depend on it, because such dynamic dependencies made terraform sad.", "see https://www.terraform.io/docs/configuration/expressions.html#values-not-yet-known\r\n\r\n> The count meta-argument for resources cannot be unknown, since it must be evaluated during the plan phase to determine how many instances are to be created.\r\n\r\n", ":+1: "]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/404", "comments": ["We'll need to set this path correctly once the new secret is in your `pass` store.", "Done in https://github.com/alphagov/re-secrets/commit/75c91ca4e0051f70d9625f3da71a9af2484d5a5c and this won't need changing.", "Rather than grabbing all aiven metrics and filtering with `metric_relabel_configs`, could we ask the federate endpoint to only provide the metrics we need?  For example:\r\n```suggestion\r\n      - \"disk_free{job='aiven'}\"\r\n      - \"disk_used_percent{job='aiven'}\"\r\n      - \"{__name__=~\"system_load.*\",job='aiven'}\"\r\n      - \"{__name__=~\"elasticsearch_clusterstats.*\",job='aiven'}\"\r\n```\r\n\r\nThis will make less work for prometheus since it doesn't have to filter out a bunch of metrics on every scrape.\r\n\r\nMy only concern is that under the hood, this will construct a giant query string for the `/federate` request, and it may end up with a query that's too large.  I think my answer to that would be multiple scrape_configs to scrape different sets of metrics.", "I think I'd rather pass the whole scrape_config into the module as one big string, with a default of the empty string.  We'd then template and construct the scrape_config in `terraform/projects/prom-ec2/paas-production`.\r\n\r\nWhy?\r\n\r\n - so that our staging observe prometheus doesn't try to scrape this stuff\r\n - to keep explicit references to DM out of the supposedly-generic prom-ec2 module", "This is a good idea. I'll restructure the PR to do it. \ud83d\udc4d ", "This is a good idea but I'd like to avoid changing it for now. This exporter is probably very temporary and in future we won't need to filter out metrics in this way.", "```suggestion\r\n  final_prometheus_config = merge(local.prometheus_config, {\"scrape_configs\" = local.final_scrape_configs})\r\n```", "```suggestion\r\n  final_prometheus_config_yaml = yamlencode(local.final_prometheus_config)\r\n```", "```suggestion\r\n```\r\n`data.template_file` is deprecated, we should migrate to the tf 0.12 `templatefile` function instead.  (Yes I know data.template_file is used elsewhere here, we haven't got around to fixing it)", "```suggestion\r\n  extra_scrape_configs = yamldecode(templatefile(\"${path.module}/extra-prometheus-scrape-configs.yml.tpl\", {\r\n    dm_elasticsearch_metrics_password = data.pass_password.dm_elasticsearch_metrics_password.password\r\n  }))\r\n```"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/403", "comments": ["you'll need to add the `data` resource for this above .... see ~ line 130 to copy what one of the others looks like. path will be `pagerduty/integration-keys/dcs-p2`", "done", "Currently this will NOT be caught as the matcher above it will catch all the things that match \"namespace = verify-doc-checking-prod\" and send them to slack.\r\n\r\nI think what you want is to add some sub routing _below/inside/within_ that matcher, that further filters on the prod namespace and the p2 severity label.\r\n\r\nLike:\r\n\r\n```suggestion\r\n      routes:\r\n      - match:\r\n          namespace: verify-doc-checking-prod\r\n          severity: p2\r\n        receiver: \"dcs-p2\"\r\n```\r\n\r\n"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/397", "comments": ["can we only change this in prod, not in staging too?", "I want to test the resize logic works on way through staging ... but can lower it in PR after", "just set the variable in terraform/projects/prom-ec2/paas-production/main.tf"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/388", "comments": ["```suggestion\r\nCOPY assume-role /usr/bin/assume-role\r\nRUN chmod +x /usr/bin/assume-role\r\n```", "I have no idea what this line does. I'm sure you've tested it and it works a treat! :)", "is that required? ... git stores attributes fine doesn't it?", "yeah name service voodoo ... it's like a poor man's `dig`"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/385", "comments": ["what's the purpose of the `+0`? cast to integer or something?", "Yes. It was used in the example I copied from and couldn't find a decent description in the awk documentation. As usual, though. stackoverflow helped:\r\nhttps://stackoverflow.com/questions/5808971/casting-to-int-in-awk"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/367", "comments": ["0.12.20 is out now. \ud83d\ude48", "don't care, wasn't when i started this \ud83d\ude04 "]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/365", "comments": ["I think (but im not sure) that you might need to add a dev-null receiver for the ones that don't match... like:\r\n\r\n```\r\n      - match_re:\r\n          namespace: verify-doc-checking-.*\r\n        receiver: dev-null\r\n        routes:\r\n        - receiver: dcs-slack\r\n          match: \r\n            type: pipeline-alert\r\n        - receiver: dcs-slack\r\n          match:\r\n            namespace: verify-doc-checking-prod\r\n```\r\n\r\nwhich I think will:\r\n\r\n* route to dcs-slack if type:pipeline-alert AND namespace:verify-doc-checking-*\r\n* route to dcs-slack if namespace:verify-doc-checking-prod AND namespace:verify-doc-checking-*\r\n* else route to dev-null \r\n\r\nMaybe it bubbles up to the next receiver up, but I'm not 100% sure\r\n "]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/363", "comments": ["match will need to be match_re I think to make use of regex", "\ud83d\udc4d ?"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/347", "comments": ["Can we lowercase this for consistency with the rest of the _thing_ names? (eidas, autom8, dcs)"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/345", "comments": ["```suggestion\r\n      and on(instance)\r\n```", "```suggestion\r\n      (time() - node_creation_time > 12 * 60 * 60)\r\n```", "The `on(instance)` is a modifier to `and` so I'd put it on the same line"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/344", "comments": ["Is this enough?"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/338", "comments": ["```suggestion\r\n        * * * * * root [ \"${ireland_targets_bucket}\" != \"\" ] && aws s3 sync s3://${ireland_targets_bucket}/active/ /etc/prometheus/ireland-targets --region=${region} --delete\r\n```\r\nkebab case for directories please (and for consistency with your prometheus config)"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/336", "comments": ["can we have some `relabel_configs` here to add `region: london` to everything?", "I'd like to rename this to `ireland_targets_bucket` at some point but not needed now", "Couldn't work out how to do this - realised you can add labels with relabel too. See next commit."]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/329", "comments": ["What is this last one?", "Extra hacks for the router to try and deal with the multiple domains thing I think - IIRC it has a normal `/metrics` endpoint but the address was getting confused due to sometimes having a -release and also having a custom route attached to it. The PR to discover the routes with a `/metrics` should solve this issue too"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/328", "comments": ["```suggestion\r\n    \"18.130.62.225\",\r\n```", "```suggestion\r\n    \"3.8.38.79\",\r\n```", "```suggestion\r\n    \"52.56.126.222\",\r\n```"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/327", "comments": ["```suggestion\r\n              bundle exec rake\r\n```"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/316", "comments": ["Insert comment about how we don't have `Observe` as a concept anymore \ud83d\ude04 ", "yeah i know but naming is hard and we already use this prefix for the config bucket, so consistency or something \ud83d\ude04 "]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/302", "comments": ["Can we delete this if it agreed with the root one?"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/300", "comments": ["I personally prefer http://www.catipsum.com/."]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/298", "comments": ["This looks like a duplicate of line 86?", "```suggestion\r\n\r\n```", "66% of the time... it works _everytime_", "fixed \ud83d\ude07 ", "\ud83d\ude00 "]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/283", "comments": ["I don't think this is the right key - it will need to be a different service for p2", "I'll look into how to make one and where to put it.", "this won't work for us. the logic is:\r\n\r\nAlert `HubSamlProxyNonEidasErrorRate` needs to go to Pagerduty P1 when `deployment: prod` but to Pagerduty P2 when `deployment: integration`.  Currently, `HubSamlProxyNonEidasErrorRate` is marked `severity: p1` which goes to Pagerduty in prod and Slack in all other environments.\r\n\r\nNow it's probably becoming clear that the `severity: p1` label is misnamed.\r\n\r\nAnyway the shortest possible change here is:\r\n```suggestion\r\n        severity: p1\r\n```\r\nwhich will Do The Right Thing, but it's confusing having a `severity: p1` going to a `verify-p2` receiver, and someone will probably \"fix\" it at some point, so i think there's a future piece of work to find better words to describe what `severity` is trying to do.", "it lives in re-secrets and we have terraform pass provider data sources to pull secrets out of there", "But whatever alert should go to PagerDuty as a P2 if it\u2019s in office hours and in the integration environment, as I understand it.\r\n\r\nCurrently integration issues show up in Slack a P1 which confuses people (myself included) when we don\u2019t get called about it.\r\n\r\nHow do we configure in-hours integration alerts as P2 alerts sending to PagerDuty and Slack, and P1 alerts for production, in this case?", "@issyl0 that's exactly what my proposed change does:\r\n\r\nIf it matches `severity:p1` and `deployment:prod`, it goes to pagerduty P1\r\nIf it matches `severity:p1` and `deployment:integration`, it goes to pagerduty P2 (which only calls in hours)\r\nIf it matches `severity:p1` but has another deployment, it goes to slack."]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/281", "comments": ["Hmm, do YAML anchors not work in `.tpl` files even though they're actually YAML, or does Terraform not work like Concourse, ie doesn't expand them in the plan?\r\n\r\n`terraform plan` output:\r\n\r\n```\r\nname: \\\"verify-p1\\\"\\n  pagerduty_configs:\\n    - service_key: \\\"[REDACTED]\\\"\\n  slack_configs: *verify-2ndline-slack-configs\\n\\n\"\r\n```", "YAML anchors aren't a templating syntax; they're interpreted by alertmanager when it reads the config file.", ">  or does Terraform not work like Concourse, ie doesn't expand them in the plan?\r\n\r\nso yes i would argue that concourse has the unusual behaviour here (even if it is helpful)", "Oh, interesting. \ud83d\udc4d"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/265", "comments": ["does this mean that the source_security_group variable in the prom-ec2 module isn't needed any more? can we have another PR to remove it if so?", "ditto for prometheus_sg_id?", "I can't find any references to source_security_group any longer in the code so it appears to be gone already", "This no longer exists in the code too"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/264", "comments": ["I don't understand why this line isn't also `9100`?\r\n\r\n`from_port` and `to_port` define a port range, so this rule opens all ports from 9090 to 9100 inclusive, from prometheus_ec2 to itself.", "```suggestion\r\n# - scraping itself and other prometheis on port 9090\r\n```", "ditto, I think this from_port should be `9093` too", "Explained understood and corrected thanks :-)", "Added.", "Explained understood and corrected thanks :-)"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/259", "comments": ["Could we change the commit message that introduces this to explain importantly why we are adding this please", "This doesn't match staging. We need to pull in the dead mans switch as a data variable from the password store and use it via `${data.pass_password.cronitor_staging_url.password}\"` or similar.", "Corrected, thanks"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/258", "comments": ["I think we may instead be able to remove the group_interval and instead add a `repeat_interval: 1m` to the dead mans switch receiver although I suggest testing this out manually", "So I think this is going to change the group interval for all receivers? We might just want to change it for the dead mans switch receiver (I think that's a valid thing to do)", "Ah this is good but even better, we should just set this as `var.dead_mans_switch_cronitor`. And then we pass in the variable in the project files (e.g. https://github.com/alphagov/prometheus-aws-configuration-beta/blob/3596f1e0b6d137d4cd98ea83b7361e102a6ff282/terraform/projects/app-ecs-services-production/main.tf) so there is no if statement and the project is the bit that defines the config", "We should treat these URLs as private (but not secret)"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/251", "comments": ["Optional: I think `alertmanager_allowed_cidrs` is more specific. Whilst `alerts` probably conveys the same information I see no reason to deviate from consistency.\r\n\r\nAlternatively we already have a variable/naming convention for these IPs (`allowed_cidrs`) which would be good to reuse/make consistent but happy to let this one slide.", "Helpful comment ", "Optional: If I understand this correctly, it might be good to change the names of these two rules to\r\n`prom_alb_allow_http` and `prom_alb_allow_https` so it's clear this is about allowing public traffic to the ALB but not the prometheus EC2 instance itself. The comment above this rule is also useful but could be more specific around what 'here' is (which I think is the ALB).", "We still need the monitoring_external_sg to be attached to the ALB?", "If I understand this correctly, our target group will send traffic to our alertmanager on port 80? But at the moment we likely want this to go to port 9093 which our ECS instances expose for alertmanager? I might have misunderstood something here though", "Optional: Wonder if we should always be explicit that these are `public_subnets` rather than just any `subnets`?", "So I see that you have introduced a different cert for prom and a different cert for alertmanager. Could you explain your rough reasoning please why this is beneficial as I don't have any context of why we want to do this? ", "Ah I see your commit message saying this can later be removed \ud83d\udc4d ", "That\u2019s a good question. My thinking is a bit vague but the following factors contributed to the decision:\r\n\r\n- principle of least authority: the alermanager ALB doesn\u2019t need a prom-1 cert, so it shouldn\u2019t have one. \r\n- a view towards extracting common functionality later: the alert manager ALB and the Prometheus ALB have very similar functionality. I\u2019ve been grouping the resources for each together in the app-ecs-albs module. The old certificate was awkward in that it was one of very few pieces of shared functionality which would make a future extracting of a common \u201cALB\u201d module more difficult. ", "Happy with this change ", "\ud83e\udd14 you know, I\u2019m not at all sure though I think you are probably right", "I deliberately chopped `public_` off these names because I think that if app-ecs-albs is offering it as an input, then app-ecs-albs shouldn\u2019t care what kind of subnet it is. ", "Thanks, good to go with this. Will add some of this context to the commit message", "I think I misread your commit message and got confused about which security group it was referring to. I think we do need to remove this now (or when we do the traffic swap over) though as it allows all public traffic to alertmanager. I can see no benefit of keeping it at the moment however so will remove it now. ", "No I got confused again, this is fine for the moment as this is the prometheus ALB whilst I was thinking of the alertmanager ALB. "]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/243", "comments": [" needs terraform fmt"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/241", "comments": ["Optional: Maybe we could be passing the region in as a var?", "Is this regex intentional here? `regex` by default should apply use `.*` But if we only want to get Prometheus nodes (rather than ECS which have no Job label?) then could we more explicit and explicitly ask for instances with  job equal to 'prometheus'?", "YAGNI :)", "The thinking was: match any instance which has a Job label at all (which will therefore exclude ECS).  However, Prometheus doesn't distinguish between an empty label and no label at all, so if you match on `.*` you'll match everything.\r\n\r\nI understand about matching `prometheus` explicitly, I guess I was thinking about future-proofing but, er, YAGNI :).  Happy to just match `prometheus`."]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/219", "comments": ["Small one but maybe something like `aws_profile_name` rather than `env` would be clearer of what you should be putting?", "I know we are overwriting the default later but is there a reason to not have this as true?", "is there a reason to have `variable`s in projects at all, rather than just `local`s?", "Lift and shift. \ud83d\ude09 ", "```suggestion\r\ncd projects/enclave/paas-staging/prometheus\r\n```"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/204", "comments": ["can we keep the types and descriptions please? (see #201)", "missing outputs?", "We want to name this `-modular`. We can just rename the statefile in S3?", "\ud83e\udd14 this variable is only needed for the remote state data source.  that got me thinking: is it maybe the project's job to wire up the remote state buckets?\r\n\r\nProbably not worth doing in this PR but might be worth a discussion.", "\ud83e\udd14 ", "I'd rather not do _any more_ stuff in this PR..."]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/200", "comments": ["this is in a block with `scheme: http` so i don't think it'll work.\r\nyou might need a separate block with `scheme: https`?"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/196", "comments": ["TODO: Split this \"Project\" tag into the project itself.", "we'll need to have `output` stanzas here for outputs to end up in the project statefile, so that they can be consumed by remote_state in other projects. \ud83c\udf5d ", "Which outputs? [All of these](https://github.com/alphagov/prometheus-aws-configuration-beta/pull/196/files#diff-2a21f8981318c66bb6891f0f6b2edc40R105)?", "did we mean to remove the type/description/default values?", "should this be `-modular` like the others, given we hardcode the filename (but allow the bucket name to vary)?"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/190", "comments": ["Why has this changed to be `ecs_optimized` when the rest of the PR is for EC2 Prometheis?", "see commit message for 6ec9817c2debe168ac6cb96753fcf4ba38534e0d", "Oh, I didn't look at the commits individually.", "Do we need to remove the ssh instructions here as I assume they are no longer relevant?", "i've left ssh in place for the minute while we evaluate session manager, but my hope is that this will go away in future"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/183", "comments": ["```suggestion\r\n  - \"if [ -n '${logstash_hosts}' ]; then /root/setup_filebeat.sh; fi\"\r\n```\r\nI think this would be more explicit that we are conditional on a non-empty string here", "can you update your editor settings to always add newline at end of file please", "urgh terraform", "this variable is called `logstash_hosts` but I'm not sure from reading the code how I would pass more than one host to it.  Can it be either documented (eg with a [variable description](https://www.terraform.io/docs/configuration/variables.html#description-1)) or renamed to `logstash_host` please?", "Damn, don't know why I never did that before... That's gonna save me time", "Indeed. Interesting conversation here about the direction Terraform want this to go https://github.com/hashicorp/terraform/issues/18195"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/174", "comments": ["These are Docker volumes, not EBS volumes, right?", "Not sure what you mean here", "Don't worry, I answered my own question. :-)", "Should the name have `paas-proxy` if this is now being treated a task iam role to be shared across all config grabbing? (If I understand this correctly that is).", "Maybe `GetConfigFiles` would be more accurate but aware that is getting in the realm of changing things rather than just moving them in this PR so optional comment", "Could you explain the removal of this for me please?", "Not needed, the role was only needed to attach a policy to access s3 and paas-proxy doesn't need this", "I'll update", "Will update"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/173", "comments": ["According to @kentsanggds, this is relevant to the Verify enclave, not our EC2 enclave. It would be good to specify that, and what extra permissions are needed. I have no idea.", "Correct.\r\n\r\nPermissions wise you need to have a aws-vault profile as such:\r\n\r\n```\r\n[profile verify-perf-a]\r\nmfa_serial = arn:aws:iam::<user_arn>:mfa/<email_address>\r\nrole_arn = arn:aws:iam::170611269615:role/prometheus_deployer\r\n```\r\n\r\nI believe as well that team members will also need to be added to have access for that role. I don't know if this is something we can do or something we need to ask people with Verify permissions to do for us.\r\n\r\nhttps://reliability-engineering.cloudapps.digital/iaas.html#access-aws-accounts"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/170", "comments": ["Indentation looks slightly off here.", "And here.", "Typo:\r\n\r\n\"promtheus\" => \"prometheus\"", "Thanks have corrected the indentation, and typo."]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/168", "comments": ["we don't need the _EC2 suffix now"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/163", "comments": ["```suggestion\r\n    prometheus_addresses      = \"${join(\"\\\",\\\"\", formatlist(\"%s:9090\", aws_route53_record.prom_ec2_a_record.*.fqdn))}\"\r\n```\r\nWe have a variable for the list of prom-ec2 records, we can use it rather than hardcoding. (It's used on the line below for the node exporters)", "```suggestion\r\n      - targets: [\"${prometheus_addresses}\"]\r\n```\r\nThis is needed along with the previous suggestion"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/152", "comments": ["this set of labels doesn't specifically match any receiver in [our alertmanager configuration](https://alerts-1.monitoring.gds-reliability.engineering/#/status).\r\n\r\nThe default receiver is observe's pagerduty, but it might be good to be more explicit, maybe?", "please can we not continue copypasting this not-terribly-useful description? :)", "We edited the alertmanager config to explicitly call pagerduty for this.", "I think we still want to use our existing 'prometheus' receiver. 'product' is not the best name but more refers to the team who should be alerted rather than the actual product. If we set it as `prometheus` then our team will be rung. There shouldn't be too much benefit from having an extra `grafana` receiver.", "Amended to use the prometheus receiver.", "I think the product should be `prometheus`", "This is now pushed up (we had changed it but it didnt get commited)"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/147", "comments": ["I don't think we want these files duplicated in both `terraform/projects/app-ecs-services...` and `terraform/modules/app-ecs-services`?", "Is there any official documentation on the prometheus website to link to about how these tests are created/defined etc?", "Ah I think I spotted one below. I think that should go at the top for context.", "They should be deleted from projects", "Whilst these are all nice examples of promql expression tests, are these things we actually get benefit of testing (although I realise they were likely of benefit to play around with to learn how it all works)", "Nice comment", "I'm not sure how closely these should be mimicking real data. For me to have good faith in this unit test I'd like it to be a bit closer to reality, something like \r\n\r\n```\r\n- series: 'up{job=\"alertmanager\", instance=\"instance1\"}'\r\n  values: '0+0x14' \r\n- series: 'up{job=\"alertmanager\", instance=\"instance2\"}'\r\n  values: '0+0x14' \r\n- series: 'up{job=\"alertmanager\", instance=\"instance3\"}'\r\n  values: '0+0x14'\r\n```\r\n\r\nand ideally we would also test the other cases \r\n\r\nwhere we just had 2 alertmanagers down:\r\n\r\n```\r\n- series: 'up{job=\"alertmanager\", instance=\"instance1\"}'\r\n  values: '0+0x14' \r\n- series: 'up{job=\"alertmanager\", instance=\"instance2\"}'\r\n  values: '0+0x14' \r\n- series: 'up{job=\"alertmanager\", instance=\"instance3\"}'\r\n  values: '1+0x14'\r\n```\r\n\r\nwhere we had 1 alertmanager down not firing\r\n\r\n```\r\n- series: 'up{job=\"alertmanager\", instance=\"instance1\"}'\r\n  values: '0+0x14' \r\n- series: 'up{job=\"alertmanager\", instance=\"instance2\"}'\r\n  values: '1+0x14' \r\n- series: 'up{job=\"alertmanager\", instance=\"instance3\"}'\r\n  values: '1+0x14'\r\n```\r\n\r\nThis would involve getting round the problem with one test per set of series which you mentioned in knowledge share. I was going to play around and try and get it working myself but I accidently upgraded prometheus to 2.6.0 and now don't want to go to the effort of trying to downgrade to get the tests to pass...", "The main benefit was to show how we can experiment with the `promql_expr_test`, would probably be more useful to show what can be done with particular types of queries like difference between `rate` and `increase`, how to use `without` and `ignoring` etc", "I did the bare minimum to get the alerts to fire, but they should probably be updated on an iterative basis to show how alerts will fire in real life."]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/141", "comments": ["it's a pedantic point, but this thing isn't a dns name because it has a port number.  I'm not sure what it should be. `address`, maybe? That fits prometheus's use of the `__address__` label.", "I encourage pedantic comments \ud83d\udc4d I agree. Will look to get this tidied up when we move the other two prometheis over to EC2"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/133", "comments": ["These job doesn't have exactly the same as our ECS file (here alertmanager has been made plural). This means that our alerts we've written for alertmanager will not fire - https://github.com/alphagov/prometheus-aws-configuration-beta/blob/master/terraform/projects/app-ecs-services/config/alerts/observe-alerts.yml", "So I believe this security group allows traffic from EC2 prometheus to the node exporter running on the EC2 instances. We could probably rename the security group rule from `allow_prometheus_private` to something that mentions `node_exporter` too.\r\n\r\nWe've changed the existing rule rather than adding a new one meaning that the previous rule is no longer needed. Could you explain why please as I wasn't able to figure it out myself. Thanks!", "Good catch this very important as we would have broken this in the worst way possible ", "We have modified the rule so that Prometheus can scrape node exporter on other instances. We have also change the name to make more clear as to the purpose of the rule."]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/129", "comments": ["Note that this alert won't fire if there is *any* instance of `prometheus_build_info{version=\"2.1.0+ds\"}`.\r\n\r\nI think in an ideal world we should only alert if `prometheus_sd_file_mtime_seconds` isn't defined on a prometheus instance that is `prometheus_build_info{version=~\"2.4.*\"}`.\r\n\r\nHowever, as this is a temp fix it's probably ok for now \ud83d\udc4d "]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/127", "comments": ["I am not sure how happy I am with having a none effective cron job on the system. Is there nothing we can do in order to commit the cron job is the targets do not exist.\r\n\r\nWe could maybe have a conditional based on whether this variable is set or not.", "Please explain this section a little it more. What is happening here and what is the intended outcome?"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/126", "comments": ["Am I right in thinking we could remove the hardcoding of 2 here and use the length of `var.prometheus_private_ips`?"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/124", "comments": ["There's a typo in the filename, should be `environment.sh`", "This comment appears to be duplicated on the same line?", "Can the title be different so that it can be distinguished from the PaaS tests, and can the PaaS `inspec.yml` file be updated with a more meaningful title.", "This comment appears to be duplicated on the same line?", "Unnecessary #", "Do you mean the extra hash or ?", "I have extended the titles however they provide not much benefit in the actual running tests. It helps with the clarity I suppose.", "done", "This echo could say why it is sleeping for 120 secs e.g. sleep 120 seconds whilst prometheus restarts", "Do we need to keep the instruction about setting up an aws-vault profile in the london region?"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/123", "comments": ["The description says 100, but it looks like the query specifies 1000", "\ud83d\udc4d thanks @brucebolt  - fixed in 13f6c5b", "Will this trigger PagerDuty for issues in staging?", "I think so.\r\n@idavidmcdonald - we did chat about this in the lab on Friday, but I can't remember - can we target only production?", "You can indeed only target production by using `sidekiq_enqueued_jobs{job=\"publish-data-production-queue-monitor\"}` although please do check this in the prometheus interface to double check this gives you what you want", "I think we should add something to this query to make it specific to DGU in any case: otherwise, if some other user adds sidekiq metrics from their own services, this alert might alert on that other metric.  Probably on the `org` or `space` label?\r\n\r\nGood work capturing that 1000 is a guess in the commit message \ud83d\udc4d this will make it easier for people to make an informed decision if they want to change it later.", "@idavidmcdonald  - thanks - that worked!\r\n\r\n@thomasleese I've updated the query now so it should only pull through prod c18577d\r\n\r\n@philandstuff - thanks for the hint - I've added in the org label to the query - also added a grafana screenshot to support my guess :)", "`{{ $labels.app }}` will not evaluate to anything as you do not have a label on your metric with the key `app`.\r\n\r\nYou have the following labels available:\r\n`sidekiq_enqueued_jobs{cf_app_instance=\"0\",instance=\"7c027d9f-5339-4d93-bb42-d39a9470f657:0\",job=\"publish-data-production-queue-monitor\",org=\"gds-data-discovery\",space=\"data-gov-uk\"}`\r\n\r\nYou could instead use the `job` label or you could just hardcode production (or whatever you'd like to put in it's place).\r\n\r\nIt's all looking good apart from that!"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/117", "comments": ["I recognize that this is an existing pattern, but do we really need to capture `private_ip` as a label? Isn't our `instance` label good enough?  Especially as it will be captured as the \"endpoint\" on the targets page.", "I think I got the CIDR blocks right here - policy is on high side, and 10.1.0.0/16 is high side? right? @ejrowley ", "Missing `metrics_path` here (I snowflaked it and forgot to push to the branch)", "Good spot, will fix", "this can go, it was just an example of capturing a meta label making it public", "10.1.0.0/22 is the high side"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/113", "comments": ["can this be more descriptive?  something like \"map from availability zones to subnet CIDRs\"?", "this is a confusing name for this variable - I would expect this to just be a list of availability zones.", "although not ideal, it matches the name of the variable elsewhere. Perhaps we should change it everywhere to `availablity_zone_map`", "@ejrowley and I chatted IRL - maybe `subnets_by_az` or `subnets_by_availability_zone` might be better?", "ok", "will change it to `subnets_by_az`"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/109", "comments": ["Optional: Will this be taken care of by the line above it?", "Optional: Would `**/.kitchen/**` be equivalent to line `terraform/modules/enclave/prometheus/.kitchen/` and `*/.kitchen/**` combined?", "Can we remove this if it is not needed please", "Think we can remove this verify_enclave variable too", "I don't think this tag is related? Can we remove it please or replace it please", "Are either of the variables in this file being used?", "Is there a way to make sure it doesn't have any other permissions apart from the two you've listed here?", "Is there a way to make sure those only lets in this ipv4 range and not a larger one?", "We might want to pin this exactly to 0.11.7 like we do for all the rest of the codebase", "Might be good to call this `verify-perf-a-test` to match the name of the project", "Also will we run into issues if more than one person tries to run the tests at the same time? (although this probably is something we could survive with for the moment)", "Do we want to check mode on this too?", "Just spotted that this file is misspelt as `operanting_systems.rb` as opposed to `operating_systems.rb`", "This is based on things that we had when rebasing. Some stuff had made it into the rebased content. ", "Removed this and a few of the ones beginning taken care of by the regex.", "Yep nice catch \ud83d\udc4d ", "Ok removed these", "I have replaced this and added the ability to access the Prometheus for dev environments only.", "The az_zone we do not need anymore but the endpoint IP's is a good one to have as a placeholder.", "No there is not as of this moment, however, I believe in future versions it will. They have the function in the security group section but not this one.", "Yep, this check should check that. You can use a feature call allow_in_only which checks to make sure no other ports are allowed in. We did not use those since most of these are on a shared security group.", "yep added :)", "Looks like we should remove this line actually as per https://stackoverflow.com/questions/4151495/should-gemfile-lock-be-included-in-gitignore", "Yep for the time being it is basic and this means that we can use this until we get a make file. The reason why I avoided that was that I did not want to run in to charecter limits. ", "https://stackoverflow.com/questions/4151495/should-gemfile-lock-be-included-in-gitignore", "Is this actually SSH access though? I see no port 22", "Maybe the `statement_count` variable could be useful? https://www.inspec.io/docs/reference/resources/aws_iam_policy/", "It is supposed to be internet access as by default the node can't talk to the outside world.", "I'm not sure if the second sentence here is adding much value so maybe could be either deleted or expanded on to be specific (although feel free to disagree). I think there is a missing word too before `difficult`.\r\n", "I had not come across this statement count. I have added it in now. We tried to get the most basic functionality then improve on them as time progressed.", "Optional: Add an example of this command"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/107", "comments": ["Not sure if we want to be passing the zendesk details into dev configuration ever to prevent us putting tickets in from our dev stacks?", "That's a good point. We also have `ticket_recipient_email ` in our environments, I'm not sure which one takes precedence, would the pass store one overwrite the environment or the opposite?", "Check the terraform docs about variables/tfvars as I think the environment variable overwrites but worth testing it out yourself to be confident.", "So I tried it and it seems like pass store takes precedence so I removed all references to that variable where it's not needed anymore."]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/104", "comments": ["So here we should actually use `exported_space=\"prod\"` rather than `space=\"prod\"`. We cover this very briefly in https://reliability-engineering.cloudapps.digital/manuals/alerting-with-prometheus-for-paas.html#writing-your-alerting-rule-promql-expression.\r\n\r\nThe reason for this is the label for `space` actually refers to the space that your `openregister-metric-exporter` app is running in whereas `exported_space` refers to the application the metric refers to. I assume you only want to alert on apps run in your prod space (rather than those for example that are running in staging or sandbox)?\r\n\r\nThere is a technical reason behind the scenes about why this is happening and I don't think it's perfect so it may be something we try and change in the future.\r\n\r\nUnrelated but for further interesting reading on alerting on disk space you may be interested in this article - https://www.robustperception.io/reduce-noise-from-disk-space-alerts. It may be overkill for the moment, especially as your disk usage appears to be very static but it's an interesting thing to know about.\r\n", "Same comment here as above regarding use of `space` rather than `exported_space`", "I'm happy that `avg_over_time` is indeed the moving average we were after based on https://github.com/prometheus/prometheus/issues/383\r\n\r\nOn another note, if you play around in the prometheus interface and up the range you are averaging over (currently 5m), the graph does indeed become much smoother as we expected. Changing the range to 30s (which is currently how often new metrics are being scraped) gives you the identical graph to it without using `avg_over_time`. It may be worth us playing with this value for your graphs. We could also expand the summary to make it clear this is based on a moving average being above 80% for 5 minutes rather than every single data point being above 80% for the last 5 minutes.\r\n\r\nNext step after that is also to look at removing the restriction to a single app but to include all your apps.\r\n\r\n"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/103", "comments": ["Do we want these to be so aggressive? Default is 1m, our PaaS prometheus is every 30 seconds.", "You may be interested in setting so that all files must be served side encrypted similar how we do for our current stack:\r\nhttps://github.com/alphagov/prometheus-aws-configuration-beta/blob/master/terraform/projects/app-ecs-services/main.tf#L143", "Am I right in thinking this just prints out the apt sources so we can see it in the cloud init script to help with debugging?", "Could explain to me why we restart prometheus here please if we do a reboot immediately after? I'm not so familiar with this stuff so more just looking to learn. My thoughts were either why aren't we just starting it rather than calling restart? Or does the reboot command not kill the prometheus process immediately after? ", "Do we want to remove/replace the `verify` specific part here of the bucket name?", "So no autoscaling group? Was this a decision for speed or is there a different reason?", "Could you explain why we `skip_destroy` please?", "Might be nice to variable out the IP address, not sure if it should live in the module", "I think this variable is not being used?", "Do we want to make this consistent with all the other terraform versions which are pinned at 0.11.7", "Could we add some sort of comment to describe what this AMI is or why it is chosen?", "Could you explain this one please", "Could you explain this one please", "Just wanted to double check we want the VPC endpoint policy to be so permissive?", "Not a big deal but tabel is misspelt ", "Might be worth calling this `ec2-private-api-interface` or similar", "Pop a comment to say what this is doing please", "Fix me", "Can change this in another iteration", "Speed and not enough value out of them for the cost", "Think we can get rid of this", "I think this was just to ensure that Prometheus starts successfully as we discussed with Ed. We will just stick to one reboot and start on a new state of the instance. This will do for the time being.", "currently going to run a quick test with this what the outcome is but it should be safe to remove. I believe it just creates the attachment in a different way. That most likely preserves the disk.", "We have reverted the scrape interval to 30 seconds", "we have removed skip destroy", "Fixed typo", "This is a policy around accessing S3, not about accessing individual buckets. Each bucket we control has its own policy. We could restrict access to buckets we control here, but they are created in the prometheus project - we would end up with cyclic dependencies if we tried to wanted to include them here ", "Just realised this is `govukobserve` which is a bit misleading", "Unused variable"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/102", "comments": ["Need to add this data into the template file for `alertmanager_config_file`", "Well spotted! Have fixed it now."]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/96", "comments": ["Optional: I know it's super unlikely but I wonder if our script should fail if it ever gets to this point?", "Optional: Maybe prefixing this so it's `private_dns_zone_id` would be a quick improvement for readability", "Optional: I'm guessing this is added because we will have records added by the API call from the instances which otherwise would stop terraform a terraform destroy? Might be worth adding as a super brief inline comment or in the commit message just so it's clear why this line of code is here", "Could we keep this how it was before so that `config.file` and `web.external-url` are still defined in the task definition (it feels nice to keep it in there rather than move it into Terraform which is less related and seems to have all the different commands spread over various parts of the code)? We could then have something like:\r\n\r\n```\r\n\"command\": [\r\n     \"--config.file=/etc/alertmanager/alertmanager.yml\",\r\n     \"--web.external-url=${alertmanager_url}\"\r\n     \"${peer_commands}\"\r\n]\r\n```", "We are defining `alertmanager_url` twice here. If you see my comment below I think we should stick with the first definition and remove this second one.", "Optional: If this is using `local.private_subdomain` which is defined a few lines below it might make sense to move `private_subdomain` up the order so it is defined before being used (at least in sense of reading the code).", "This is generally not a bad idea, I have not considered the concept myself. The idea behind putting the args in terraform is having a single point of reference. This simplifies maintenance a tiny little bit in that you have one point of reference.\r\n\r\nI will test this. i suppose my only question is how does 'alertmanager_url' get passed to the config file ?", "hmmm I believe that is a matter of preference. It is an iffy one. :/\r\n\r\nshould the script fail, I do not know at this stage. these are the last commands, i believe the purpose of this message is to have something in the log file. \r\n\r\nWhy would you want the script to fail as I am currently not sure ? "]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/94", "comments": ["Our convention appears to be using `-` instead of `_` for the task name.\r\n\r\nAlso please could we include an example to our description i.e. `Create console session, make create-console project=<project name>`", "I'm not that good at bash but do we need this if statement? If the console statement exits, regardless of the exit code we would exit the function anyway as it's the end of it?", "The idea behind this peace of code was to enable the ability t catch unforseeen cases. It is not majorly required but since the console is highly dynamic enviroment we can always forsee possible failure cases.\r\n\r\nI am happy to remove if you are happy to continue with that risk. This peace of code takes the exit code from the previously run command and checks it. The main purpose if to prevent the code from hanging.", "This now gives me the following error: `make: Nothing to be done for `create-console'.`\r\n\r\nThis is potentially because whilst you changed the `.PHONY`, the line below it might also need changing to use `-`.\r\n", "You changed the function name above but not this one to match", "yep that is true I missed other places where the function is defined.", "yep edited this"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/86", "comments": ["we can also remove the `cidr_admin_whitelist` variable because it's no longer used"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/81", "comments": ["is it worth trying to cache this stuff?", "@idavidmcdonald told me IRL that travis recommends only caching for built artefacts, not for downloaded binaries.  this rings a bell with me so I'm happy \ud83d\udc4d  (i can't be bothered finding the reference though)", "https://docs.travis-ci.com/user/caching/#things-not-to-cache"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/79", "comments": ["We can probably also remove the `SHARED_DEV_DNS_ZONE` defined at the top of the file."]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/73", "comments": ["I'm not that good at understanding all these security groups. Could you explain for me why we are able to remove this security group rule please :)\r\n", "the security group rule name no longer makes sense - it's not `any_http` it's only `office_http`", "This is a rule that made through from the way that we previously had prometheus configured. We had more components which required more rules. We now mainly utilise virtual hosts through the LB.", "Currently hoping that I caught all any-any for external facing interfaces. ", "There is a bunch of them so I believe it is worth reviewing and clean up as part of a card.", "can you explain clearly and specifically:\r\n\r\n - what the security group did\r\n - why it is not needed\r\n\r\nWhen you say \"we had more components which required more rules\" - which components? Which rules?  What was the specific change that made this rule no longer necessary?", "We use to run prometheus and alert manager in fornt of an ALB\r\nwith an Nginx server with each service. There where multiple targets\r\ngroups which exposed alertmanager to the external facing ALB. This\r\nmeant that we needed alot of security group rules in order to\r\npermit access to external facing ALB from the public. We also needed\r\ninternal security groups to ensure that communciation was occuring.\r\n\r\nWe have now added a signle nginx service that enables routing based\r\nhost header, including similar rules to ALB's. This means\r\nwe now no longer need to many rules.", "Looking over this rule with @DavidJeche, we can't understand what it was supposed to be doing. It allows http access directly from our office IPs to the internal load balancer.  Why did we ever want this?\r\n\r\nIf I try to visit the internal ALB (by copypasting it's default DNS record into a browser), it just times out, suggesting that even with this rule, access isn't permitted.  Did it ever work?  Since we always have accessed alertmanager via the nginx auth proxy (not directly), I'm not sure we've ever seen this rule in action.", "This rule used to allow nginx and prometheus to access the internal ALB (in order to access prometheus and alertmanager for proxying/scraping/alerting).  What is the equivalent now that we've got rid of `alertmanager_external_sg`?", "please can we not be so permissive with ingress rules?  We may need to permit port 80 (and possible 8080? 9090? 9093?) but that doesn't mean we should permit the world.", "After looking at this again, I realise that this PR isn't newly introducing this behaviour; this permissive rule is already present in master.  Therefore, it's no reason to block this change.\r\n\r\nWe should still have a think about how we use our security groups but for now this PR can be merged."]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/72", "comments": ["why don't we want to send emails from staging? can you explain?", "this needs to be removed", "I think the wording needs to be improved, as we probably only want to target a verified email and don't expect the quota to go above the daily limit of `100`, whereas in production it might. I've already opened up a case to enable production access, it might take a few days for AWS to resolve.", "Yes, will remove after testing on staging and production, or could otherwise trigger `NoFileSdTargets`"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/70", "comments": ["I wrote `type:ticket` for the arbitrarily-chosen tag in https://trello.com/c/Fpir7Ilk/509-enable-prometheus-alerts-to-be-delivered-by-email so can we be consistent with that?", "I took that from a blog post and only saw that we're using type later... fixed!", "oh well if there's prior art then we can go with `severity` and update the trello card", "From this blog post: https://www.robustperception.io/reduce-noise-from-disk-space-alerts", "oh cool. seems there's prior art for `severity: ticket` as well here: https://www.robustperception.io/alerting-on-crash-loops-with-prometheus\r\n\r\nand `severity: page` is used in prometheus's own examples: https://prometheus.io/docs/prometheus/latest/configuration/alerting_rules/\r\n\r\nso i'm happy to go with it."]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/60", "comments": ["why port 8181? why not a more standard port like 80 or 8080?  You don't open the port directly on the host (using `hostPort`) so I think 80 and 8080 are available to you.  Going with 8181 violates the principle of least surprise to me - it jumps out as being unusual, and it makes me wonder if there's something funny going on.", "why are we reusing the alertmanager role for the nginx task here?", "you said in the PR description that we want to return a 404, but there's nothing here that explicitly sets up that behaviour.  If this is something we care about, do we want to have an explicit 404 here?", "That is the wrong role, what is interesting is that everything is working regardless. This is because things are co-located and we are relying on the config grabber in the prometheus task. I am reluctant to add a config grabber task to the nginx because we don't need it but perhaps we should for consistency and in case the nginx gets scheduled on a box with out a config grabber.", "This was not to clash with the existing endpoint I think, it can be changed to 80 now that we have removed the old listeners and ALB", "The default behaviour in this case will be to return 404", "ew. i'm not massively keen on relying on the config grabber in the prometheus task", "Does this need to be 3, can it be 1 for dev stacks?\r\nAlso similar question for `config_updater desired_count`"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/59", "comments": ["Maybe we could look into ordering these variables in a nicer way (either by grouping similar together or alphabetical)", "Will need to run the `make docs` command to generate new docs as we have new variables please", "Any particular reasons for moving it rather than just deleting it? Would people ever need to use/see the old version again?", "Any particular reasoning for these values out of interest?", "could order them", "ok", "some people have settings in their stacks that they would like to keep, I will need to set up my own schedule for downscaling so want to copy those values across", "I haven't tried t2.micro but it might work? The numbers themselves I had to adjust as I downsized the instances to get the task to work"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/58", "comments": ["I might suggest moving this paragraph one up so it comes second as this is quite closely related to the first paragraph about spinning down behaviour.", "Just checking that you wanted to have the name contain the cron expression in it rather than just a simple `asg_dev_scaledown_schedule_0`, `asg_dev_scaledown_schedule_1` etc?\r\n\r\nIt looks a little bit strange in the AWS console but technically there's nothing wrong with it", "I don't know if we particularly need to output this but fine either way", "ok", "ok", "Thought it would be useful to see what the schedule would be in case devs have a setting in their `tfvars` but have forgotten about it, as it won't be that visible unless the schedule is changed."]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/55", "comments": ["Do we have to add a severity here? Happy to if we do just a slight worry about doing enacting this without a shared understanding of severity levels", "although I've just seen that we're using P2 in other places too ", "yeah i think it was just here as an example of what labels might look like.  But we have product too, so i think we can kill severity until we define it better \ud83d\udeae "]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/51", "comments": ["Think this should be `<=1`"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/49", "comments": ["This change should not be in this commit it's unrelated to the commit and there is another pull request which fixes the problem.", "can we not add `jq` it is another dependancy to manage, instead use the --output text and POSIX tools (awk/sed). Reason being `jq` has had CVEs in the past which have taken along time to get fixed, I would not be surprised if the version being installed here had open CVEs against it", "We understand but without this change the PR will not function as expected. The alternative PR didn't merge so we just took some of the logic. ", "We could not use jq and utilize the AWS cli, I got not issue with that. Everything has CVEs attached to it. Just make sure you stop people from getting to them :D \r\n\r\nWe need to have a discussion about vuln management at some point.", "I have made the change and removed this from the script", "I am not sure what you would like to do about this but it is up to you to fair.", "It's still being installed in line 4 though", "Is this working now?", "good spot, thanks, have removed", "yeah I've taken this line out about three times, kept coming up after rebasing, is gone for good now (hopefully)", "I've updated the PR which should resolve this issue - https://github.com/alphagov/prometheus-aws-configuration-beta/pull/47, so that just needs to be approved and merged in, then you can rebase off master.", "We are still using jq here"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/47", "comments": ["maybe we can have the best of both worlds by creating some local variables `${local.alerts_records_total}` and `${local.prom_records_total}` or similar, and using them to define both this count and the counts for `aws_route_53_record.prom_alias` and `aws_route_53_record.alerts_alias`?", "this comment is wrong now (I think it can just be deleted)", "very tiny minor thing, but I don't think the parentheses are needed:\r\n\r\n` count = \"${1 + local.alerts_records_count + local.prom_records_count}\"`", "this should be `local.alerts_records_count`, no?", "ok", "ok, will simplify", "should be!"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/43", "comments": ["Should we be using `rate` instead of `increase` here:\r\n> increase should only be used with counters. It is syntactic sugar for rate(v) multiplied by the number of seconds under the specified time range window, and should be used primarily for human readability. Use rate in recording rules so that increases are tracked consistently on a per-second basis.\r\n\r\nThis is an open question, I am not sure I agree with the documentation. I like the fact that with this current check we can have a real number `3` which makes it a bit more readable (this is me assuming that it translates to we have had 3 5xx errors in the last 5 minutes).", "I agree with the documentation - but I don't think it says we should change anything here.  Alerting rules and recording rules are different things: recording rules are like materialised views which should generate consistently-defined time series - so a rate time series should be rate-per-second, rather than a mix of series with rates per second, per minute, per 5 minutes, or whatever.\r\n\r\nAlerting rules should be human-readable - in this case, it's saying \"alert if the increase in errors is greater than 3 within a 5 minute window\" which is far more understandable than \"alert if the rate of errors per second is greater than 0.01 over a 5 minute window\".  Alerting rules don't output new time series into the tsdb, so they don't have to adhere to the same consistency contraints as recording rules."]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/39", "comments": ["Why does this one not have the `prod` suffix? ;)", "You're meant to be on holiday! Also because it's the default behaviour, prod's so important it doesn't need a suffix", "although obviously if this is confusing can change :)", "Could we maybe store this string as a variable at the top of the script, something like `DEFAULT_DEV_TARGETS_S3_BUCKET`", "I can't think of any particular issues with this but I'd be interested to know if you had a particular reason for making this change?", "Basically because all of the other variables have prod as standard, figured they should probably be the same", "is this just to make it easier to change later on?", "My thinking was more that it's essentially a configuration value and it's good to have our config and code that does things live separately if possible (whether that be in different files or just separated at the top of the script). It makes it easier to see what all your config are without having to look in random places in the script."]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/35", "comments": ["maybe we could at least compute the length of the input? eg\r\n\r\n```\r\ncount = \"${length([\"${aws_route53_record.prom_alias.*.fqdn}\", \"${aws_route53_record.alerts_alias.*.fqdn}\"])}\"\r\n```\r\n\r\nor create a new local with the value `[\"${aws_route53_record.prom_alias.*.fqdn}\", \"${aws_route53_record.alerts_alias.*.fqdn}\"]`?\r\n\r\nThis would avoid having a magic number.", "How did you choose this policy over any other?\r\n\r\nIs there a chance we could pin to at least TLS 1.2?", "do we need to duplicate these listener rules for the https listener?", "it feels risky to deploy the HTTPS stuff and remove HTTP access at the same deploy.  Can we do this in two separate steps please?\r\n\r\nWhen we deploy to production, we don't want up to half an hour of downtime while we wait for certs to be approved.", "minor thing, but I'd expect this to be adjacent to `public_zone_id` further down", "Quite right, will do", "This is the suggested policy to use by AWS for general use as per https://docs.aws.amazon.com/elasticloadbalancing/latest/application/create-https-listener.html#describe-ssl-policies\r\n\r\n```We recommend the ELBSecurityPolicy-2016-08 policy for general use. You can use the ELBSecurityPolicy-FS-2018-06 policy if you require Forward Secrecy (FS). You can use one of the ELBSecurityPolicy-TLS policies to meet compliance and security standards that require disabling certain TLS protocol versions, or to support legacy clients that require deprecated ciphers. ```\r\n\r\nWe can either use the current one as suggested for general use or we can look to use the one with only support for TLS 1.2 by using the `ELBSecurityPolicy-TLS-1-2-Ext-2018-06` policy. Dropping old TLS versions would probably be fine in reality given it's GDS users (although I don't know if as a service we have any hard restrictions on browser support).\r\n\r\nMurilo and I are currently leaning towards using `ELBSecurityPolicy-TLS-1-2-Ext-2018-06` I think.", "It looks like the `Ext` version is the same as the regular TLS1.2 except it supports SHA1 ciphers.  As a result I'd prefer the plain `ELBSecurityPolicy-TLS-1-2-2017-01`", "Ah yes, well spotted. Thanks. Will implement.", "I believe so as per https://stackoverflow.com/questions/47032187/terraform-aws-lb-listener-with-multiple-ports", "I don't think I made myself particularly clear. What I'm trying to say is: do we need to duplicate the `aws_lb_listener_rule` resources (which hasn't been done), *as well as* the `aws_lb_listener` resource (which has already been done above)", "My thinking is that: because the `aws_lb_listener_rule`s refer to the HTTP `aws_lb_listener`, I wondered if we needed similar rules for the HTTPS listener too.", "Ah I understand you now. Good question. I need to bit of reading to make sure I understand how they all work together so let me get back to you on this one..."]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/31", "comments": ["I was wondering if we could make this easier by doing something like\r\n\r\n```\r\nGOBIN=~/.terraform.d/plugins/darwin_amd64 go install github.com/camptocamp/terraform-provider-pass\r\n```\r\n\r\nbut i am unable to test this right now :(\r\n", "we should have `set -eu` at the top\r\n\r\n", "can this check for != 'true'", "ditto", "why has the `etag` gone? can we still ensure that terraform won't re-upload the config file each time?", "can this comment explain why we don't want to call `git pull`?", "\ud83d\udc4d \r\n", "it upsets me that terraform templates don't support conditionals \ud83d\ude22 ", "is it worth inlining this variable now?", "\ud83d\udc4d ", "\ud83d\udc4d ", "\ud83d\ude3f", "\ud83d\udc4d ", "We have done some investigation \ud83d\udd75\ufe0f \r\n\r\nAn Etag is generated automatically by AWS when calling `PutObject` (https://docs.aws.amazon.com/AmazonS3/latest/API/RESTCommonResponseHeaders.html) with encryption so we still get an Etag for our object. We've also checked the Etag of the encrypted object is identical to the Etag of the object uploaded without encryption.\r\n\r\nIf we add the etag back in as before then we get the following error message:\r\n`Error: aws_s3_bucket_object.nginx-htpasswd: \"etag\": conflicts with server_side_encryption (\"AES256\")`.\r\n\r\n`Etag` is not a compatible argument if we are defining `kms_key_id` as per the docs (https://www.terraform.io/docs/providers/aws/r/s3_bucket_object.html#etag) but we aren't using `kms` to encrypt and instead using AES256 as our encryption method so we are surprised to see this error message. Maybe is worth us opening an issue with Terraform unless you can think of some areas to further investigate.\r\n\r\nWe've manually testing running make apply twice and it appears that the files are not reuploaded again given that the \"last modified\" datetime does not update when you apply the second time.\r\n\r\nWe also aren't quite sure whether AWS or Terraform is responsible for not reuploading a file if it matches the Etag and haven't been able to find that out either.", "We've checked and if the file stays the same then terraform does not try and reupload it on top of the existing file.", "Terraform thinks this object is changing everytime we run make apply which it shouldn't so we should fix this.", "I got something working:\r\n\r\n```\r\ngo get github.com/camptocamp/terraform-provider-pass\r\nGOBIN=~/.terraform.d/plugins/darwin_amd64 go install github.com/camptocamp/terraform-provider-pass\r\n```\r\n\r\nand the provider can now be used \ud83d\ude04 ", "We fixed this by adding the bucket policy version.", "can this use a ``` block", "wait, we never actually added `set -ue`", "No we didn't. We did try it and it worked okay but it meant that we were no longer getting useful error messages. Instead it just hits the `set -eu` and quits. We thought that it was better to keep the informative messages that we'd written rather than be stuck with the standard ones but happy to be overruled if quitting with a message irrespective of error is better than holding on to our current messages.", "The other blocker which was more going to take up some time learning how to fix it was that we refer to `$2` in our code a lot in reference to a second parameter passed into the script, however we don't usually pass a second parameter and it's optional. However if `$2` is not defined then our script fails so we need to add this ability to have `set -eu`. It took more than about 5 minutes of investigation with no immediate answer and we thought it wasn't essential to this PR so we stopped. Happy to look into it a bit more though.", "\ud83d\udc4d this is a good explanation"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/27", "comments": ["given the DNS names are private, is there any harm in then being either: a) the same (ie `monitoring.private` everywhere) or b) very simply patterned (ie `${var.stack_name}.monitoring.private` everywhere)", "you mentioned IRL that it'd be good to have a better default action. I'm happy with this for now but we should think about alternatives", "we can DRY this up by specifying `resolver` at the higher level - it's a valid `http` directive, so doesn't have to be inside a `server` block", "ditto for the `auth_basic` directives", "why do we use `set` here rather than just proxying directly to `${alertmanager_1_dns_name}`?"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/25", "comments": ["Can this be moved to the infra-networking-route53 project please.", "Can this be moved to the infra-networking-route53 project please.", "This should be `prom-1.monitoring.gds-reliability.engineering` for production, and `prom-1.monitoring-staging` for staging, `prom-1.<stack name>.dev.gds-reliability.engineering` for dev stacks\r\n\r\nSee - `prometheus_subdomain` in https://github.com/alphagov/prometheus-aws-configuration-beta/blob/master/stacks/production.tfvars", "was this part of your working this stack? If so should it be in your personal gitignore rather than here if there's no chance of it coming up again?", "I am not sure. The only problem I have with that is that I wanted the domain name to  be close to the service. I understand that we have sub-zone created within main.tf of route53 folder. If we keep the DNS record setting separate from service file. It means that when deleting services a stale DNS record will remain unless we perform a destroy on the DNS records folder. \r\n\r\nI think there should be some static values within the DNS folder, this will be something like prom-1 & alert-1. We should use the ability to set a custom value closer to the service. There is also an issue that if you run apply-single on the service dir it will not update infra-route53 folder.\r\n\r\nI am happy to move this into that folder but I need you consider this point first.", "See comment above ", "Ok this needs to be changed will look in to making this change.", "probably shouldn't have your name in here", "extra whitespace", "whitespace - `terraform fmt` should remove this?", "changing this so you can rebuild in your dev environment is fine but this should be changed back for prod", "I ended up moving this, I think it is better for the time being until a use case comes up.", "I removed this in favour of prometheus_subdomain", "I don't know my idea just keeps adding it. Ermmmmm that is consideration. I may need to set this up though.", "changed, thanks for spotting that :D ", "removed", "changed back to true :D ", "Is this the best Name for the ALB? Surely `\"${var.stack_name}-alertmanager\"` would be better?", "why did you make this part of the alertmanager ALB? It's a bit weird as they don't have much to do with each other", "This description is inaccurate. Copypaste error?", "Ditto", "Ditto", "Ditto", "Ditto", "Ditto", "stray whitespace", "@kentsanggds I don't think `infra-networking-route53` should own all route53 records. That's not a good way of structuring our projects.", "I have moved this to the route53 folder. I will wait until we move it to networking, then I will add the records back into the services section.", "map(\"Name\", \"${var.stack_name}-internal-alb\")\r\n\r\nI have renamed it to this, since we have multiple services on the alb that exposed internally. When we go multi-AZ we will need to add the the count to the alb name or AZ association.", "This was inline with digram so basically they can share an ALB as long we as we correctly define the forwarding rules  They share one internal ALB in the AZ. They are currently only routed based on port number. PaaS proxy is on port 8080 & Alertmanager is on 80.", "Yep... I hate typing when I can copy & reword :( \r\n\r\nI wanted to make it work, will clean these up to ensure the description matches the output \ud83d\udc4d ", "This will need to change", "What is this doing?", "I think we might want to get rid of `infra-networking-route53` here"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/24", "comments": ["This comment I think is slightly wrong. Maybe you could help @kentsanggds. \r\n\r\nAt the moment if you are applying the `infra-networking-route53` project for the first time you will\r\n- apply\r\n- import_shared_dev_route53\r\n- apply again\r\n\r\nwhy do we want to apply twice as opposed to just doing:\r\n- import_shared_dev_route53\r\n- apply again\r\n", "Sorry, @kentsanggds could you just explain to me what this logic is doing but more so why it is doing it please?", "The `initialised` value is automatically set when running `make apply`, so will only be valid if a developer decides not to use the `Makefile` or `setup.sh` helper files. I would probably encourage developers to use one of those as otherwise additional steps could be missed so not sure if this comment is necessary.\r\n\r\nIf you want to describe the process it might be better to state that after the initialised value is set, it's possible to run the `terraform import` and `make apply` to use the `shared_dev` route53 zone to build the route53 hosted zones for a dev stack, as it's necessary to have an existing `tfstate` file in order to import a resource.", "A state file needs to be present otherwise it won't do the import, hence create the state file, then import and apply", "Thanks for the clarity", "Ah, I had a slightly different mental model in my head so this is helpful. I'll update the comment to more accurately describe the process.", "Do you mean `168`, when destroying we need to ignore `infra-networking-route53` errors otherwise it will always interrupt the destroy all as we can't ignore the `shared_dev` resource, see here for more detail - https://github.com/alphagov/prometheus-aws-configuration-beta/pull/24/commits/a6b7435107b37934aca2e02a803cf45207ae2b05", "`s/to/for/` as above", "why was this removed from the README but not from the Makefile?", "if I run `terraform destroy` manually, am I likely to delete the route 53 zone because I forget to unimport the shared zone?  Is there a way we can avoid this hazard?", "it's confusing to use `1` to mean \"true\" in bash.. normally `0` is true and any nonzero value is false.", "if you flip the `0` and `1` senses (see comment above in definition of `does_stack_config_exist`), then I think you can use it directly in the `if` block:\r\n\r\n```sh\r\nif does_stack_config_exist; then\r\n```", "I don't think this will do anything? [scripts are run inside a subshell, so changing directory in the subshell doesn't affect the caller](https://stackoverflow.com/a/255415)", "this is an excellent comment", "I think this record should be in the app-ecs-albs module; we shouldn't have a circular dependency between `infra-networking` and `app-ecs-albs` because, when creating a new environment, which one do you create first?\r\n\r\nSpecifically, I imagine that infra-networking creates the zone (with the zone id as an output), and app-ecs-elbs creates the record within the zone.", "We decided to remove it as the apply, will also run the plan and in the initial creating of a new stack there will be errors from the plan as resources are not available. So for a fresh stack we will need to apply each project so that the plans pass.\r\n\r\nIt is left in so that developers can see the impact of any changes without applying them in an existing stack.", "It doesn't destroy the shared `dev.gds-reliability.engineering` zone as terraform recognises that there are other resources in the zone. \r\n\r\nThe un-import should happen automatically for dev stacks, and should allow the resource specific for a user to be removed without affecting other dev stacks.", "Thats true, will switch them around", "Tested and works a treat \ud83d\udc4d ", "ok will remove", "ok, that could work, will then mean that we won't need a separate route53 terraform project"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/19", "comments": ["can this be simple present tense \"create\" and \"grant\" rather than \"creating\" and \"granting\"", "I don't understand this change. You've created a `prometheus` user and group, but how does that relate to the prometheus docker container? We never specify a user or group for it to run as.", "Also, don't you need the execute bit on the directory, in order to `cd` into it? shouldn't this be `770` not `760`?", "The prometheus user needs to have a specific UID & GID. This is why when creating the user we specify these values. \r\n\r\nI do however think that on line 42 /ecs/prometheus is an issue :(, it should /ecs/prometheus_data or just recursive chmod on the whole dir.\r\n\r\nThe prometheus use should be fine, since they are the only user in that group. We could even do 700 to be fair.", "Where do the UID/GID come from? Can you link to some docs/Dockerfile source or something to show why this works?", "I was wondering about where the UID/GID come from too. I was of the understanding that it runs as `nobody` and therefore is `99/99` as per https://github.com/prometheus/prometheus/issues/3441 but it supposedly looks like this is referenced as `65534` in the original PR comments too https://github.com/prometheus/prometheus/pull/2859.", "@idavidmcdonald This is a value that is static within the docker container. We use this value in order to set a predictable UID/GID. \r\n\r\nWe have the option to possibly set it manually within the container however this will add unnecessary complexity. I believe this is the best method thus far.", "Could we reorder this into the two following steps as at the moment it feels like the mounting is somewhat put into the middle of a section it doesn't belong in (unless I'm missing something):\r\n\r\nStep 1: Create directory and mount to volume\r\n```\r\nmkdir -p /ecs/prometheus_data\r\nmount /dev/$DEVICE /ecs/prometheus_data\r\n```\r\n\r\nStep 2: Permissions\r\n``` groupadd... etc```", "Typo on `Create` and needs a space after the `#` I think. You could also be more explicit so it is `Create prometheus user and group` rather than `Create prometheus`.", "Glancing at the docs (https://linux.die.net/man/8/useradd), you might be able to do the groupadd and useradd in one line using `useradd --usergroup`. Maybe worth a quick look (and a double check that is correct) but not fussed if you don't use it (you might also feel it impacts the readability)", "Is the `--groups` option doing nothing here? We are already specifying that it should join gid `65534` which is the prometheus group?\r\n\r\nWe could also match the order of the above statement so that `--system` comes first just for prettiness \ud83d\udc84 ", "Would be good to be explicit that the prometheus container runs as nobody which has UID `65534` by default (with a link to prove that if easy to find)", "I'm also a tiny bit confused by the useradd. Does this user not already exist (`nobody` running as `65534`)? Are we trying to recreate that user here when we may not need to (and we could just attach it to the prometheus group?). Maybe I'm just not understanding the docs though", "Yes we can do this. I should have to no impact on the outcome, it is just a preference/style/readability thing", "You can not set GID this way. This is why we had to do this in this way.", "Yep, to be fair I just added that in there for readability. We can take this out since the groupadd shows this.", "I don't know what you mean by link in this context. If you mean that this is the correct method I would say: \r\n\r\n'docker run prom/prometheus'\r\n\r\nin a new terminal: \r\n\r\ndocker exec -it <<hash of container>> /bin/sh\r\n/prometheus $ whoami\r\nnobody\r\n/prometheus $ id\r\nuid=65534(nobody) gid=65534(nogroup)\r\n\r\nThrough this you can verify the permissions. If this is not what you mean by link please clarify.", "The name of the user can be anything, the UID is a bit different. nobody user will exists on our system but this user will not have the same UID as the one that exists in the container. \r\n\r\nI would get an error if I tried to create a user on the node & that user already existed. In this step what I do is I create the prometheus & I give it a custom UID 65534. \r\n\r\nWhen the volume(filesystem folder) is mounted in to the container it pretty much keeps host filesystem defaults. This means that in the container in order to be able to perform operations on the volume you need to have a matching UID as the user that prometheus runs as.", "It might be a little clearer if the comment on this line was something like:\r\n`Mount volume to be used by prometheus container`\r\n\r\nAnd the comment on the second section was like:\r\n` Create prometheus group and allow it to read and write to our volume for storing prometheus data. Note, 65534 is chosen as the UID to be added to the prometheus group as this is the UID that prometheus in the docker container runs as.`\r\n\r\nMy point regarding a link specifying the UID was that someone looking at this code probably won't know where the number 65534 has come from. They could find out by going into the docker container as you demonstrated but if they could just read it in some external docs for prometheus that would be quicker/easier. However I don't think the prometheus docs document this fact (the best I could find was github issues of people complaining about the choice of UID and referenced it there).\r\n", "`prometheus:prometheus` refers to user with name `prometheus` and group with name `prometheus` if I understand this correctly. Do we have a user with name `prometheus`? We set up the group but I don't know if we have the user?", "True, unfortunately we don't have any form of documentation around this. This is just one of those things. \r\n\r\nWe will have to assume that the comments & the code will be enough for them. Let us also hope that they stumble upon these comments. ", "Ok I took the user out for some strange reason, however I have put the user back in and all should be well :)\r\n", "I don't think we need this line 46 anymore as 43 and 44 are fairly descriptive and feel like they are already saying this. Do you agree?", "I think we can remove this line 34 as the rest of our comments further down are quite precise and closer to the code they relate to.", "Yep, I agree"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/18", "comments": ["our existing images are amazon linux - can we stick to that? (we went with it to have the baked-in optimized drivers for networking and i/o)", "I don't think we need separate files for variables and outputs. @surminus explained why better than I could: https://surminus.github.io/post/terraform-structures-and-layouts/ (see section \"variables and outputs\")", "i don't see where this module gets used. it also looks far too small to be something worth extracting into a module", "i suspect our `terraform fmt` travis check is complaining about the alignment of all the `=` here", "this is probably fine for now, but i wonder if it's worth assigning an EIP?", "Is this `OUTPUTS` being used anywhere? I can't work out why we are storing it in a subprocess", "Does the `set -e` now take care of this?", "Ditto comment on the `OUTPUTS` and `TODO` as above", "Might be good to add a very short comment that says lines 185-194 is all to find out the private IP address of the instance we want to SSH into", "Is this variable being used?", "Not particularly important but the rest of our code doesn't add a `_` between `jump` and `box`", "Do we need the variable in this file given it's not used directly in it?", "Should we have something jumpbox specific in the general instance module?", "See https://www.terraform.io/docs/configuration/variables.html#booleans as I believe it is suggested to use `\"false\"`", "Instance type could be put in a variable with t2.small as the default as it seems a bit specific to the jumpbox (I don't mind if you don't address this comment too much by the way)", "Do we want to have `jumpbox` in here as I believe it is supposed to be generic? Potentially instead of taking `stack_name` as a variable to the module we could take `key_name` and let the caller be responsible for naming it?", "Is this expected to always be a version? Would appending `_version` on the end help communicate this if so? Or maybe `ami_release_version`?", "It feels like this ami module is specific to ECS optimised instances so maybe the module should be called `ecs-ami` rather than just `ami`?", "I wonder if a more appropriate name for this module would be `jumpbox_instance`?", "https://www.terraform.io/docs/configuration/variables.html#booleans", "Wondering if all instructions to get this working should be in the README as it feels like someone might not know to look here?", "Is there a particular advantage to having the ssh_key as it's own file? It feels like it's closely enough tied to the jumpbox (as in we have no other need for one) that it could go into that file in the same way the security groups do", "This move to a version number rather than an AMI version, does it mean that the README instructions on finding the latest AMI ID is no longer so useful? (I don't know the answer)", "not being used, could take it out, as was planning on using it to check for errors.", "Not sure, I'll take out the comment as probably covers it", "no can take out", "ok, will make consistent", "Can probably take out", "I think it's only used by the jumpbox project, so maybe could move the code into jumpbox?", "I'm not sure it's necessary to add additional comments, the code is fairly readable as it's split up into fairly atomic parts", "can do, but there are a few places where this is not done in the codebase", "Think this module should be part of jumpbox project", "This is also only used by the jumpbox so could move to that project", "Think so, though  I'm not sure if there needs to be any change as it's specific to the amazon release", "Don't think this is used", "I'll have a chat with Ed to see what he thinks", "ok", "Don't think these instructions are used, there are instructions in the main `README` that explains how to use the jumpbox", "README should probably be updated? Will check with Ed", "Could be in the jumpbox project", "I think this comment is no longer needed?", "I think this one is also not needed?", "Cool, happy to go with that then", "Would be good to get your other PR merged and this rebased out of here as it conflicts", "Are we allowing any IP address access to the jumpbox as opposed to just the GDS IPs here which would have been the default if we had not provided a value for `allowed_cidrs`? If so, is there a reason for that? I can't remember how cidr blocks work exactly so I might have misunderstood", "It appears these docs have been written manually meaning running `make docs` will overwrite them. Instead they can be included at the top in a docblock of the project file and they will be produced using `make docs`.", "Any chance we could put the make list stuff in as a separate PR just for ease of keeping this PR small? I haven't had a chance to look at that new code/test it", "\ud83d\udc4d ", "\ud83d\udc4d ", "\ud83d\udc4d ", "I'll check with @ejrowley on this", "Sure, will create a new PR for this", "ok"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/15", "comments": ["can we not mix camel and snake case please? all hyphens would be better", "can you set your editor to always put a newline at end of file?"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/14", "comments": ["Is this going to work on zsh only?", "Not sure, why not try it"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/10", "comments": ["do we want to cache this somehow, so we don't have to redownload terraform on every CI run? https://docs.travis-ci.com/user/caching/", "So I think Terraform is distributed as a binary package (https://www.terraform.io/intro/getting-started/install.html). The Travis docs say it is not particularly useful to cache a compiled binary (https://docs.travis-ci.com/user/caching/#Things-not-to-cache).\r\n\r\nIf my understanding is correct (I'm not that familiar with binary packages), it means this wouldn't be particularly needed. If you could just double check my logic that would be great thanks."]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/8", "comments": ["does this allow the instance to attach *any* volume?  is it worth trying to be a bit more restrictive?", "do we need `sudo` in user data? I thought it ran as root anyway?", "is `chmod 777` really necessary? \ud83d\ude28 \r\n\r\n(answer: no it's not. let's see if we can tighten this up)", "\ud83d\udc4d ", "I've opened #9 to deal with this - we can leave it for now but it'll get changed again", "can we document that this is default directory that our docker image expects? i was confused for a while because i couldn't see how this got wired up", "I think we could probably be more specific: https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_AttachVolume.html", "Actually it's done in here: https://github.com/alphagov/prometheus-aws-configuration-beta/pull/8/files?utf8=%E2%9C%93&diff=unified&w=1#diff-b9fa37e9b366d987de5582400d4a8326R8", "that line doesn't restrict permissions though.  The instance could still, if compromised somehow, attach arbitrary volumes.  I just wondered if we could specify `resources` to only allow attaching the prometheus volume.", "we didn't, have changed", "I tried running at 755, it wouldn't go through. Ed recommended that we wait until we can have access to the box to change groups around and work out what we can get away with. I've left it as is for now", "\ud83d\udc4d ", "Do we need all of these new permissions?", "Could we document in the readme that people should be setting the account idea in their tfvars file so we can spin this up please? Actually, passing it in to the command line is probably better given it removes the risk that people commit them in the staging and production tfvars.\r\n\r\nI kind of dislike the fact that we manually need to know the account ID to run any of the terraform. Might be worth double checking if there is any way we could get around this though...", "Maybe the terraform-pass integration so we could get it from reng-pass could be an option...", "did some spiking and it looks like we can use `data \"aws_caller_identity\"`: https://www.terraform.io/docs/providers/aws/d/caller_identity.html", "oops"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/4", "comments": ["Hardcoded stack name here to fix", "It feels like it would be nice to make this a bit more explicit (maybe a comment above it or in a different section?) to say that this is uploading the config found in the repo so prometheus can retrieve it", "Could we name `pulled-config` something more explicit, so it's clear why it differs from `config-from-s3`?", "Could we expand this description to include the added/changed functionality please", "Interested in why this alerts config is a directory as opposed to the prometheus config which is a file?", "I can add a comment, but for me it feels like it would duplicate documentation about what `aws_s3_bucket_object` is", "I'll just name it `config-from-s3`", "gut feel more than anything else.  We know we're going to manage other files within /etc/prometheus elsewhere (for the paas service discovery stuff) but I kind of feel we own all things in /etc/prometheus/alerts within terraform.  I could be wrong though.", "`ecs-monitoring` rather than `gdsprom` may be more consistent but not a big deal", "Good point, don't worry about this", "I worry that this might not be sufficiently globally unique and we might find bucket names have been claimed already", ".oO(maybe we should use `bucket_prefix` instead of bucket)"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/3", "comments": ["These tags could be more consistent with the rest of our tags in the other projects please (e.g. adding `Stackname`, using additional vars as well)", "Do we need the stream prefixes? They seem kind of redundant as it is a duplicated in the log stream name", "Ditto to above", "can you be more specific? I can't find any other examples of us setting Environment in this repo", "I tried without and it turns out that specifying a stream prefix has nontrivial extra behaviour which we want. see 148fc06 for details.", "https://github.com/alphagov/prometheus-aws-configuration-beta/blob/master/stacks/staging.tfvars Is where we set the environment as an additional tag and then we set all the tags on resources like https://github.com/alphagov/prometheus-aws-configuration-beta/blob/master/terraform/projects/infra-security-groups/main.tf#L85", "Thanks for investigating \ud83d\udc4d "]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/2", "comments": ["can this be `kebab-case` not mixed `snake_and_kebab-case`?", "ditto", "ditto (even if the old code was mixed)"]}, {"url": "https://github.com/alphagov/prometheus-aws-configuration-beta/pull/1", "comments": ["@deanwilson we copied this across from your spike repo, when is this supposed to be used?", "This would be used when moving to an updated ECS AMI, it stops you having to click through the AWS website docs for an hour.\r\n\r\nhttps://github.com/deanwilson/ecs-monitoring/blob/master/terraform/projects/app-ecs-nodes/main.tf#L23\r\n\r\nYou can do some lookup magic to make EC2 pick the newest AMI but I intensely dislike that as you don't know what your base AMI is.", "@deanwilson does this comment still stand?", "Probably not anymore.", "Is this the right number of subnets?", "Do we still want the stack name", "Same as above", "We should explain why we're using this path", "What should this be?", "To start with you probably only need one but it should be in multiple AZs, I'd say 3, by the end of the beta.", "If you want to run two versions of the environment at once, for example a load testing and an upgrade test, how would you determine which is which if you remove the stackname? Not saying to keep it, but ensure you have some way to tell.", "The instance type will come out of the capacity planning trello story. If you're going to point this at DGU then you'll want at least as big as you currently have.", "Thanks, have added a small sentence to clarify when to use this.", "Thanks, will go 1 AZ for the moment then.", "Cool, will bump up \ud83d\udc4d ", "Could someone please clarify why we need to do this? We appear to be doing tags in a different way for `monitoring_external_alb.tags` so trying to understand if there is intentional difference in behaviour?", "Sounds good, we will keep", "this is going to be too small probably. see the [task size](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_definition_parameters.html) section of the docs", "I got a bit worried when reading this.  If I uncheck these options, when will my keychain ever lock again?\r\n\r\n(I don't know a lot about OS X Keychain)", "after a bit of digging I think this advice is wrong.\r\n\r\nThere's two different things going on:\r\n - access for aws-vault app to the keychain\r\n - whether the keychain is locked or unlocked\r\n\r\nBy default, you have to type the password each time you want the app to access the keychain, whether the keychain itself is locked or not.  To prevent this, you click \"always allow\" instead of \"allow\" in the pop up dialog.\r\n\r\nAlso by default, the keychain locks after your computer sleeps, or after 5 minutes of inactivity.  After that, any use of the keychain requires the password again.\r\n\r\nI think we should recommend users click \"always allow\" to allow aws-vault to access the keychain without prompting every time, but do not change the \"lock after X minutes\" or \"lock when sleeping\" settings.", "do we need to document how to actually ssh to a box?  There's no public IP on the instance, nor a bastion host we can tunnel through.  Is this something to add later?", "we should remove this", "Yeah, might be fair to remove it for now so there is no key pair for the instance.\r\n\r\nWe previously SSH'd in to the box but required us manually setting up a security group and ELB to go through"]}]}, {"url": "https://github.com/hmcts/cnp-module-api-mgmt.git", "pull_requests": [{"url": "https://github.com/hmcts/cnp-module-api-mgmt/pull/1", "comments": ["'Name of the _existing_ resource group...'?", "yeh, when this was part of the core infra I had it sit in the same sg (made sense). Although it's now separate, I think once we have the A/B envs we'll still want to consider the API Management as part of that same rg. No technical reason obviously.\r\n\r\nAlso, and more importantly, this module makes a new subnet in the core-infra-vnet and requires the resource group name for that\r\n\r\nhttps://github.com/hmcts/moj-module-api-mgmt/blob/master/main.tf#L11-L12 "]}]}, {"url": "https://github.com/dwp/dataworks-aws-data-egress.git", "pull_requests": [{"url": "https://github.com/dwp/dataworks-aws-data-egress/pull/299", "comments": ["I'm not sure this lines up with the - name above.  Can you fix it?   I have seen issues when things aren't perfect in the past - not sure if it's just my eyes tho"]}, {"url": "https://github.com/dwp/dataworks-aws-data-egress/pull/262", "comments": ["Do we need it in here? This is for data-egress", "Removed as not required here"]}, {"url": "https://github.com/dwp/dataworks-aws-data-egress/pull/238", "comments": ["My understanding is that we usually use the bootstrap_terraform.py to populate variables within terraform.tfvars.json", "Looks like it is used elsewhere"]}, {"url": "https://github.com/dwp/dataworks-aws-data-egress/pull/230", "comments": ["Extra new line"]}, {"url": "https://github.com/dwp/dataworks-aws-data-egress/pull/185", "comments": ["maybe put it into a different destination as it is not SAS warehouse"]}, {"url": "https://github.com/dwp/dataworks-aws-data-egress/pull/173", "comments": ["```suggestion\r\n}\r\n\r\n```"]}, {"url": "https://github.com/dwp/dataworks-aws-data-egress/pull/156", "comments": ["Type in \"organistion\"", "fixed"]}, {"url": "https://github.com/dwp/dataworks-aws-data-egress/pull/141", "comments": ["This is a bit too generic for my liking, the other products have a folder name after dwh (or sas or ris) to denote what the data product we are sending is.\r\n", "i.e. this pattern would match all products we send to the datawarehouse, and if we left it as above. The next datawarehouse job would need to change this."]}, {"url": "https://github.com/dwp/dataworks-aws-data-egress/pull/135", "comments": ["why is the `h` lowercase?", "is this the agreed prefix? I thought all SFT egress was to the data warehouse through the data-egress service - this seems too generic", "if you look at the other SFT egress entries - this is a team, not just DataWarehouse - I'm not sure if that is an issue, just thought it was worth discussing."]}, {"url": "https://github.com/dwp/dataworks-aws-data-egress/pull/134", "comments": ["Flag file is called pipeline_success.flag", "to a local directory and picked"]}, {"url": "https://github.com/dwp/dataworks-aws-data-egress/pull/124", "comments": ["Not sure this will be right, but we can leave it and see if it causes any problems during the prod test."]}, {"url": "https://github.com/dwp/dataworks-aws-data-egress/pull/75", "comments": ["```suggestion\r\n```\r\ndon't think you need this as you are passing a role in all the jobs"]}, {"url": "https://github.com/dwp/dataworks-aws-data-egress/pull/24", "comments": ["Kept for future shared volume ticket"]}, {"url": "https://github.com/dwp/dataworks-aws-data-egress/pull/21", "comments": ["```suggestion\r\n    sid = \"PublishedBucketOpsMiObjectRead\"\r\n```", "```suggestion\r\n    sid = \"PublishedBucketTestingObjectPut\"\r\n```"]}, {"url": "https://github.com/dwp/dataworks-aws-data-egress/pull/8", "comments": ["what's this for?", "Do we use any  from ingest terraform output ?\r\n\r\n", "run.sh expects 10 arguments and this test doesn't need all of them", "yes for key "]}, {"url": "https://github.com/dwp/dataworks-aws-data-egress/pull/6", "comments": ["the target size should probably be determined by load, rather than set to 10. You might be able to simply omit this line", "I don't see a corresponding variable being set in the pipeline for this. We should be tracking a SHA", "this has no default and isn't set in tfvars or pipeline"]}, {"url": "https://github.com/dwp/dataworks-aws-data-egress/pull/4", "comments": ["this doesn't seem right, the previous indent aligned the equals symbols. Could your run `terraform fmt` to confirm?", "you should be able to remove this `is_mgmt_env ` block now as it looks like it might be unused", "done", "removed"]}, {"url": "https://github.com/dwp/dataworks-aws-data-egress/pull/1", "comments": ["Is this needed?", "this was part of template\r\n"]}]}, {"url": "https://github.com/demiguelmoreno/terragoat.git", "pull_requests": []}, {"url": "https://github.com/akentosh/hashi-stack.git", "pull_requests": []}, {"url": "https://github.com/olivier2t/stack-nexus.git", "pull_requests": []}, {"url": "https://github.com/interrupt-software/az-basic-vm-git.git", "pull_requests": []}, {"url": "https://github.com/nekochans/qiita-stocker-terraform.git", "pull_requests": [{"url": "https://github.com/nekochans/qiita-stocker-terraform/pull/115", "comments": ["\u3053\u306e\u540d\u524d\u306a\u3093\u3060\u3051\u3069\u4ed6\u306b\u3082\u30c7\u30d7\u30ed\u30a4\u4ee5\u5916\u306e\u7528\u9014\u306bCodeBuild\u3092\u4f7f\u3046\u53ef\u80fd\u6027\u304c\u3042\u308b\u306a\u3089 `buildspec-deploy.yml` \u3068\u304b\u306b\u540d\u524d\u3092\u5909\u3048\u305f\u307b\u3046\u304c\u826f\u3044\u304b\u3082\uff1f\r\n\r\n\u305f\u3060\u4eca\u306e\u3068\u3053\u308d\u4ed6\u306b\u5229\u7528\u30b7\u30fc\u30f3\u306f\u601d\u3044\u3064\u304b\u306a\u3044\u304b\u3089\u3001\u4eca\u306e\u540d\u524d\u3067\u3082\u5168\u7136\u554f\u984c\u306f\u306a\u3044\u3057\u6700\u7d42\u5224\u65ad\u306f\u4efb\u305b\u308b\u3088\ud83d\udc31\uff01", "\u73fe\u6642\u70b9\u3067\u306f\u30c7\u30d7\u30ed\u30a4\u4ee5\u5916\u306e\u7528\u9014\u306f\u7121\u3044\u3068\u601d\u3046\u304b\u3089\u3001\u3053\u306e\u307e\u307e\u306e\u540d\u524d\u306b\u3057\u3088\u3046\u3068\u601d\u3046\uff01\ud83d\udc31\r\n\u307e\u305f\u5fc5\u8981\u306b\u306a\u3063\u305f\u6642\u70b9\u3067\u5bfe\u5fdc\u3059\u308b\u306d\uff01"]}, {"url": "https://github.com/nekochans/qiita-stocker-terraform/pull/69", "comments": ["`aws_security_group.ecs_api`\u306fcount\u304c\u8a2d\u5b9a\u3055\u308c\u3066\u3044\u308b\u305f\u3081\u3001\u914d\u5217\u3067\u5b9a\u7fa9\u3057\u3066\u3044\u308b\u3002\r\n\u306a\u304a\u3001`output \"api\"`\u306emap\u306b`ecs_api_security_id`\u3092\u542b\u3081\u308b\u3068\u3001\u4e0b\u8a18\u306e\u30a8\u30e9\u30fc\u3068\u306a\u308b\u305f\u3081\u3001\u5225\u3067\u5b9a\u7fa9\u3057\u3066\u3044\u308b\u3002\r\n```\r\nmodule.api.output.api: map: all map values must have the same type, got type string then type list in\r\n```"]}, {"url": "https://github.com/nekochans/qiita-stocker-terraform/pull/54", "comments": ["`ebs_block_device`\u306e\u8a2d\u5b9a\u306b\u3064\u3044\u3066\u306f\u3001\u3044\u3063\u305f\u3093\u9069\u5f53\u306b\u8a2d\u5b9a\u3057\u3066\u3044\u308b\u3002\u8abf\u67fb\u5f8c\u3001\u6570\u5024\u3092\u5909\u66f4\u3059\u308b\u4e88\u5b9a\u3002", "\u7d30\u304b\u3044\u3051\u3069\u3001[\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u898f\u7d04](https://github.com/nekochans/qiita-stocker-terraform#%E3%82%B3%E3%83%BC%E3%83%87%E3%82%A3%E3%83%B3%E3%82%B0%E8%A6%8F%E7%B4%84) \u3060\u3068\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u540d\u306f\u30b1\u30d0\u30d6\u30b1\u30fc\u30b9\u3067\u547d\u540d\u3063\u3066\u306a\u3063\u3066\u3044\u308b\u304b\u3089 `modules/aws/ecs/user-data/userdata.sh` \u306b\u5909\u66f4\u3057\u3088\u3063\u304b\ud83d\udc31\uff01", "ECR\u306e\u30ea\u30dd\u30b8\u30c8\u30ea\u306a\u3093\u3060\u3051\u3069\u3001EC2\u30e2\u30fc\u30c9\u3068Fargate\u30e2\u30fc\u30c9\u3067\u5171\u901a\u306a\u306e\u304b\u3001\u305d\u308c\u3068\u3082\u305d\u308c\u305e\u308c\u5225\u3005\u306e\u30ea\u30dd\u30b8\u30c8\u30ea\u3092\u4f5c\u308b\u4e88\u5b9a\u306a\u306e\u304b\u3069\u3063\u3061\u304b\u6c17\u306b\u306a\u3063\u305f\u3088\ud83d\udc31\uff01\r\n\r\n- \u5225\u3005\u3067\u4f5c\u308b\u5834\u5408\r\n\r\n\u547d\u540d\u898f\u5247\u3092 `${terraform.workspace}-ec2-api-php` \u307f\u305f\u3044\u306b\u3057\u305f\u307b\u3046\u304c\u826f\u3044\u3068\u601d\u3046\uff01\r\n\u3069\u306e\u30e2\u30fc\u30c9\u3067\u4f7f\u308f\u308c\u308b\u304b\u3068\u3001\u3069\u306e\u30d7\u30ed\u30c0\u30af\u30c8\uff08\u3053\u306e\u5834\u5408\u306fAPI\u7528\u306ePHP\u30a4\u30e1\u30fc\u30b8\u3060\u3068\u601d\u3046\uff09\u3067\u4f7f\u308f\u308c\u308b\u304b\u3092\u540d\u524d\u306b\u5165\u308c\u305f\u307b\u3046\u304c\u826f\u3044\u304b\u306a\u3068\u601d\u3046\uff01\r\n\r\n- EC2\u30e2\u30fc\u30c9\u3082Fargate\u30e2\u30fc\u30c9\u3082\u540c\u3058ECR\u306e\u30ea\u30dd\u30b8\u30c8\u30ea\u3092\u53c2\u7167\u3059\u308b\u5834\u5408\r\n\r\n\u547d\u540d\u898f\u5247\u3092 `${terraform.workspace}-api-php` \u307f\u305f\u3044\u306a\u611f\u3058\u306b\u3057\u3066\u3069\u306e\u30d7\u30ed\u30c0\u30af\u30c8\u3067\u4f7f\u308f\u308c\u308bPHP\u30a4\u30e1\u30fc\u30b8\u306a\u306e\u304b\u3092\u660e\u793a\u3057\u305f\u307b\u3046\u304c\u826f\u3044\u3068\u601d\u3063\u305f\uff01", "\u3053\u308c\u3082\u540c\u3058\u3088\u3046\u306bEC2\u30e2\u30fc\u30c9\u3068Fargate\u30e2\u30fc\u30c9\u3067\u5225\u3005\u306eALB\u3092\u4f7f\u3046\u306e\u304b\uff1f\u305d\u308c\u3068\u3082\u540c\u3058ALB\u3092\u4f7f\u3046\u306e\u304b\u304c\u6c17\u306b\u306a\u3063\u305f\u3088\ud83d\udc31\uff01\r\n\r\n\u5225\u3005\u306eALB\u3092\u7528\u610f\u3059\u308b\u306a\u3089\u547d\u540d\u898f\u5247\u3092\u5909\u3048\u305f\u307b\u3046\u304c\u826f\u3044\u3068\u601d\u3063\u305f\uff01", "\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u69cb\u6210\u3068\u3044\u3046\u304btfstate\u306e\u5358\u4f4d\u3067\u601d\u3063\u305f\u3093\u3060\u3051\u3069\u3001\u4eca\u4f5c\u308d\u3046\u3068\u3057\u3066\u3044\u308bECS\u306e\u30ea\u30bd\u30fc\u30b9\u3063\u3066\u7d50\u5c40\u306e\u3068\u3053\u308dAPI\u3092\u52d5\u304b\u3059\u70ba\u306e\u30ea\u30bd\u30fc\u30b9\u3060\u304b\u3089 `21-api` \u306e\u4e2d\u306b\u4f5c\u3063\u3066\u3082\u3044\u3044\u304b\u306a\u3068\u601d\u3063\u305f\u3093\u3060\u3051\u3069\u3001\u3069\u3046\u3060\u308d\u3046\ud83d\udc31\uff1f\uff1f\r\n\r\n\u30a4\u30e1\u30fc\u30b8\u7684\u306b\u306f\u2193\r\n\r\n`modules/aws/api/` \u306e\u914d\u4e0b\u306b\u2193\r\n\r\n- ecr.tf\r\n- ecs-iam.tf\r\n- ecs-ec2.tf\uff08EC2\u30e2\u30fc\u30c9\u3067\u8d77\u52d5\u3059\u308b\u70ba\u306b\u5fc5\u8981\u306a\u30ea\u30bd\u30fc\u30b9\u3092\u5b9a\u7fa9\uff09\r\n- ecs-fargate.tf\uff08Fargate\u3067\u8d77\u52d5\u3059\u308b\u70ba\u306b\u5fc5\u8981\u306a\u30ea\u30bd\u30fc\u30b9\u3092\u5b9a\u7fa9 \u3053\u308c\u306f\u6b21\u56de\u4ee5\u964d\u306e\u8ab2\u984c\u3067\u4f5c\u6210\u3055\u308c\u308b\uff09\r\n\r\ntfstate\u306f\u78ba\u304b\u306b\u5206\u5272\u3057\u305f\u307b\u3046\u304c\u30c8\u30e9\u30d6\u30eb\u6642\u306b\u5bfe\u5fdc\u3057\u3084\u3059\u3044\u3063\u3066\u3044\u3046\u30e1\u30ea\u30c3\u30c8\u306f\u3042\u308b\u3093\u3060\u3051\u3069\u3001\u7d30\u304b\u3059\u304e\u308b\u3068\u7ba1\u7406\u304c\u5927\u5909\u306b\u306a\u308b\u3063\u3066\u3044\u3046\u306e\u3068\u3001\u6700\u7d42\u7684\u306a\u30b4\u30fc\u30eb\u3063\u3066 `qiita-stocker-backend` \u3092Fargate\u30e2\u30fc\u30c9\u3067\u8d77\u52d5\u3055\u305b\u308b\u4e8b\u3060\u3068\u601d\u3046\u304b\u3089\u3001\u305d\u3046\u3044\u3046\u610f\u5473\u3067\u3082 `21-api` \u306e\u4e2d\u306b\u3042\u308b\u306e\u304c\u81ea\u7136\u3060\u3068\u601d\u3063\u305f\uff01\r\n\r\n\u5909\u66f4\u3059\u308b\u70ba\u306b\u306f\u4e00\u56de `24-ecr` , `25-ecs` \u306e\u30ea\u30bd\u30fc\u30b9\u3092 `terraform destroy` \u3057\u3066\u518d\u5ea6 API\u5074\u306b\u30ea\u30bd\u30fc\u30b9\u3092\u518d\u5b9a\u7fa9\u3059\u308b\u3063\u3066\u3044\u3046\u306a\u304b\u306a\u304b\u624b\u9593\u304c\u304b\u304b\u308b\u4e8b\u3092\u3084\u3089\u306a\u3044\u3068\u3044\u3051\u306a\u3044\u304b\u3089\u3001\u3069\u3046\u3059\u308b\u304b\u306e\u6700\u7d42\u5224\u65ad\u306f\u304a\u4efb\u305b\u3059\u308b\u3088\ud83d\udc4d", "@keitakn \r\n\u6700\u7d42\u7684\u306b\u306f\u3001`21-api`\u306bECS\u306e\u30ea\u30bd\u30fc\u30b9\u304c\u5165\u3063\u3066\u3044\u308b\u306e\u304c\u7406\u60f3\u7684\u3060\u3068\u601d\u3046\uff01\r\n\u305f\u3060\u958b\u767a\u4e2d\u306b\u9650\u3063\u3066\u306e\u3053\u3068\u306a\u3093\u3060\u3051\u308c\u3069\u3001`21-api`\u306b\u3001EC2\u3001ECS+EC2\u3001Fargate\u306e\u5168\u3066\u306e\u30ea\u30bd\u30fc\u30b9\u304c\u5165\u3063\u3066\u3044\u308b\u3068\u3001terraform\u306e\u5b9f\u884c\u306b\u6642\u9593\u304c\u304b\u304b\u308b\u3001\u304b\u3064\u3001\u308f\u304b\u308a\u306b\u304f\u3044\u304b\u3089\u3001\u4eca\u3059\u3050\u306b`21-api`\u306b\u79fb\u884c\u3057\u306a\u3044\u65b9\u304c\u958b\u767a\u3057\u3084\u3059\u3044\u304b\u306a\uff01\ud83d\udc31\r\nFargate\u306e\u30ea\u30bd\u30fc\u30b9\u4f5c\u6210\u304c\u5b8c\u4e86\u3057\u305f\u6bb5\u968e\u3067\u3001`21-api`\u306bECS+EC2\u3001Fargate\u306e\u30ea\u30bd\u30fc\u30b9\u3092\u79fb\u52d5\u3059\u308b\u3063\u3066\u306e\u306f\u3069\u3046\u3060\u308d\u3046\uff1f\r\n\u79fb\u884c\u81ea\u4f53\u306f\u3001\u307e\u305f\u5225\u306e\u8ab2\u984c\u3092\u4f5c\u3063\u3066\u5bfe\u5fdc\u3059\u308b\u30a4\u30e1\u30fc\u30b8\u3060\u3088\uff01\r\n\r\n`24-ecr`\u3001`25-ecs`\u306e\u30ea\u30bd\u30fc\u30b9\u304c\u5225\u308c\u3066\u3044\u308b\u7406\u7531\u3068\u3057\u3066\u306f\u3001ECR\u306b\u30a4\u30e1\u30fc\u30b8\u304c\u5b58\u5728\u3057\u306a\u3044\u3068ECS\u306e\u30ea\u30bd\u30fc\u30b9\u4f5c\u6210\u6642\u306b\u30a8\u30e9\u30fc\u306b\u306a\u308b\u304b\u3089\u3001\u5206\u3051\u3066\u3044\u308b\u3088\uff01\r\n\u30c7\u30d7\u30ed\u30a4\u306f\u3001ECR\u4f5c\u6210\u2192\u30a4\u30e1\u30fc\u30b8\u306epush\u2192ECS\u4f5c\u6210\u3068\u3044\u3046\u6d41\u308c\u306b\u3057\u305f\u3044\u3068\u601d\u3063\u3066\u308b\uff01", "@kobayashi-m42 \r\n\u306a\u308b\u307b\u3069\uff01\u958b\u767a\u4e2d\u306f\u78ba\u304b\u306b\u5225\u308c\u3066\u305f\u307b\u3046\u304c\u3044\u3044\u304b\u3082\u306d\uff01\r\n\r\n>Fargate\u306e\u30ea\u30bd\u30fc\u30b9\u4f5c\u6210\u304c\u5b8c\u4e86\u3057\u305f\u6bb5\u968e\u3067\u300121-api\u306bECS+EC2\u3001Fargate\u306e\u30ea\u30bd\u30fc\u30b9\u3092\u79fb\u52d5\u3059\u308b\u3063\u3066\u306e\u306f\u3069\u3046\u3060\u308d\u3046\uff1f\r\n\r\n\u79fb\u884c\u306e\u4e88\u5b9a\u3082\u3053\u308c\u3067\u826f\u3044\u3068\u601d\u3046\u304b\u3089\u3001\u3053\u306e\u307e\u307e\u3067\u884c\u3053\u3063\u304b\ud83d\udc31\uff01", "@keitakn  \u3046\u3093\uff01\u5fd8\u308c\u306a\u3044\u3088\u3046\u306b\u79fb\u884c\u306e\u8ab2\u984c\u3060\u3051\u5148\u306b\u4f5c\u6210\u3057\u3066\u304a\u304f\u306d\uff01\ud83d\udc4d", "@keitakn \r\n\u547d\u540d\u306b\u3064\u3044\u3066\u306f\u3001`ecs`\u306fECS\u306eEC2\u30e2\u30fc\u30c9\u306e\u3053\u3068\u3092\u3055\u3057\u3001Fargate\u306b\u3064\u3044\u3066\u306f`fargate`\u3067\u7d71\u4e00\u3057\u3088\u3046\u3068\u601d\u3046\u3093\u3060\u3051\u308c\u3069\u3001\u3069\u3046\u3060\u308d\u3046\uff1f\ud83d\udc31\r\nALB\u306e\u540d\u524d\u306b\u3064\u3044\u3066\u306f\u3001\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u306a\u308b\u30a4\u30e1\u30fc\u30b8\uff01\r\n\r\nEC2\u30e2\u30fc\u30c9\uff1a`stg-ecs-api`\r\nFargate\u30e2\u30fc\u30c9 \uff1a`stg-fargate-api`\r\n\r\n\u307e\u305f\u3001ALB\u81ea\u4f53\u306fEC2\u30e2\u30fc\u30c9\u3068Fargate\u30e2\u30fc\u30c9\u3067\u540c\u3058ALB\u3092\u4f7f\u3046\u3053\u3068\u3082\u53ef\u80fd\u3060\u3051\u3069\u3001\u958b\u767a\u74b0\u5883\u3067EC2\u30e2\u30fc\u30c9\u3068Fargate\u30e2\u30fc\u30c9\u306e\u4e21\u65b9\u3092\u78ba\u8a8d\u3057\u305f\u3044\u30b1\u30fc\u30b9\u306b\u5099\u3048\u3066\u3001\u5225\u306eALB\u3092\u4f5c\u6210\u3057\u305f\u65b9\u304c\u3044\u3044\u304b\u306a\u3068\u601d\u3063\u3066\u308b\u3088\uff01", "@kobayashi-m42 \u3046\u3093\uff01\u3044\u3044\u3068\u601d\u3046\ud83d\udc4d\r\n\r\n\u305d\u306e\u65b9\u91dd\u3067\u3044\u3053\u3063\u304b\ud83d\udc31", "@keitakn \u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u898f\u7d04\u306b\u5408\u308f\u305b\u3066\u4fee\u6b63\u3057\u305f\u3088\uff01", "@keitakn \r\nECR\u306e\u30ea\u30dd\u30b8\u30c8\u30ea\u306f\u3001EC2\u30e2\u30fc\u30c9\u3068Fargate\u30e2\u30fc\u30c9\u3067\u5171\u901a\u306b\u3057\u3088\u3046\u3068\u601d\u3063\u3066\u3044\u308b\u304b\u3089\u4ee5\u4e0b\u306e\u901a\u308a\u306b\u547d\u540d\u3092\u5909\u66f4\u3057\u305f\u3088\uff01\u78ba\u304b\u306b\u3001\u3069\u306e\u30d7\u30ed\u30c0\u30af\u30c8\u304c\u308f\u304b\u3089\u306a\u3044\u3068\u4eca\u5f8c\u3001\u56f0\u3063\u3061\u3083\u3046\u3088\u306d\u30fb\u30fb\ud83d\udca6\r\n`stg-api-php`\r\n`stg-api-nginx`\r\n\r\n\u307e\u3060\u78ba\u8a8d\u4e2d\u306a\u3093\u3060\u3051\u308c\u3069\u3001\u30ea\u30dd\u30b8\u30c8\u30ea\u81ea\u4f53\u306f\u74b0\u5883\u5909\u6570\u3092\u5229\u7528\u3057\u3066nginx\u306econf\u3092\u66f8\u304d\u63db\u3048\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u3068\u601d\u3046\u304b\u3089\u3001EC2\u30e2\u30fc\u30c9\u3068Fargate\u30e2\u30fc\u30c9\u3067\u5171\u901a\u306e\u30ea\u30dd\u30b8\u30c8\u30ea\u3067\u3044\u3051\u308b\u3068\u601d\u3046\uff01\ud83d\udc31", "@kobayashi-m42 \r\n\r\n>\u307e\u3060\u78ba\u8a8d\u4e2d\u306a\u3093\u3060\u3051\u308c\u3069\u3001\u30ea\u30dd\u30b8\u30c8\u30ea\u81ea\u4f53\u306f\u74b0\u5883\u5909\u6570\u3092\u5229\u7528\u3057\u3066nginx\u306econf\u3092\u66f8\u304d\u63db\u3048\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u3068\u601d\u3046\u304b\u3089\u3001EC2\u30e2\u30fc\u30c9\u3068Fargate\u30e2\u30fc\u30c9\u3067\u5171\u901a\u306e\u30ea\u30dd\u30b8\u30c8\u30ea\u3067\u3044\u3051\u308b\u3068\u601d\u3046\uff01\ud83d\udc31\r\n\r\n\u3046\u3093\uff01\u305d\u308c\u3067\u884c\u3051\u305d\u3046\u3060\u306d\ud83d\udc4d\u65b9\u91dd\u3082\u554f\u984c\u306a\u3044\u3068\u601d\u3046\ud83d\udc31\uff01"]}, {"url": "https://github.com/nekochans/qiita-stocker-terraform/pull/40", "comments": ["@kobayashi-m42 \u3053\u308c\u3067RDS\u306e\u30b3\u30fc\u30eb\u30c9\u30b9\u30bf\u30fc\u30c8\uff08\u8d77\u52d5\u6642\u306b\u6700\u5927\u30671\u5206\u304f\u3089\u3044\u5f85\u305f\u3055\u308c\u308b\u73fe\u8c61\uff09\u306f\u306a\u304f\u306a\u3063\u305f\u3051\u3069\u3001\u4e00\u756a\u5b89\u3044\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u3068\u306f\u8a00\u3048\u3001RDS\u306f\u305d\u308c\u306a\u308a\u306e\u6599\u91d1\u304c\u304b\u304b\u308b\u304b\u3089\u3001\u30b9\u30c6\u30fc\u30b8\u30f3\u30b0\u74b0\u5883\u3067\u306f\u4f7f\u308f\u306a\u3044\u6642\u306fRDSCluster\u3092\u505c\u6b62\u3057\u3066\u304a\u304f\u3053\u3068\u3092\u30aa\u30b9\u30b9\u30e1\u3059\u308b\u3088\ud83d\udc31\r\n\r\n<img width=\"1031\" alt=\"clusterstop\" src=\"https://user-images.githubusercontent.com/11032365/51788711-8fb7ba00-21c4-11e9-946b-6ec15ad7b4fb.png\">\r\n\r\n\u30a4\u30e1\u30fc\u30b8\u3068\u3057\u3066\u306f\u958b\u767a\u3057\u3066\u3044\u308b\u307b\u3046\u304c\u3001\u30b9\u30c6\u30fc\u30b8\u30f3\u30b0\u306b\u30c7\u30d7\u30ed\u30a4\u3057\u3066\u52d5\u4f5c\u78ba\u8a8d\u3059\u308b\u524d\u306bCluster\u3092\u8d77\u52d5\u3055\u305b\u3066\u3001\u52d5\u4f5c\u78ba\u8a8d\u7d42\u308f\u3063\u305f\u3089\u3001\u3059\u3050\u306b\u505c\u6b62\u3055\u305b\u308b\u30a4\u30e1\u30fc\u30b8\u3067\ud83d\udc31\r\n\r\n\uff08\u3061\u306a\u307f\u306b\u30011\u30f6\u6708\u307e\u308b\u307e\u308b\u8d77\u52d5\u3055\u305b\u3063\u3071\u306a\u3057\u306b\u3059\u308b\u3068\u3001\u3060\u3044\u305f\u3044\u65e5\u672c\u5186\u30674000\u5186\u307b\u3069\u304b\u304b\u308b\u3068\u601d\u3046\uff01\uff09", "@kobayashi-m42 \u4eca\u56de\u306e\u5bfe\u5fdc\u3067MySQL5.7.12\u306b\u4e92\u63db\u6027\u306e\u3042\u308b\u30d0\u30fc\u30b8\u30e7\u30f3\u306b\u5909\u66f4\u3057\u305f\u3088\ud83d\udc31\r\n\r\n\u7406\u7531\u306f\u30ed\u30fc\u30ab\u30eb\u3067\u4f7f\u3063\u3066\u3044\u308bDB\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u304cMySQL5.7\u3060\u304b\u3089\u305d\u308c\u306b\u5408\u308f\u305b\u305f\u3088\uff01\r\n\r\n\u5c06\u6765\u7684\u306b\u30e6\u30fc\u30b6\u30fc\u304c\u7206\u767a\u7684\u306b\u5897\u3048\u3066 \u300c`Aurora Serverless` \u306e\u307b\u3046\u304c\u5b89\u3044\uff01\u300d\u3063\u3066\u306a\u308b\u53ef\u80fd\u6027\u306f\u5426\u3081\u306a\u3044\u3051\u3069\u3001\u591a\u5206\u305d\u306e\u9803\u306b\u306fMySQL5.7\u4e92\u63db\u306eAurora Serverless\u304c\u30ea\u30ea\u30fc\u30b9\u3055\u308c\u3066\u3044\u308b\u3068\u601d\u3046\u304b\u3089\u3001\u591a\u5206\u554f\u984c\u306a\u3044\u30cf\u30ba\u30fb\u30fb\u30fb\r\n\r\n\u305f\u3060\u78ba\u5b9a\u3058\u3083\u306a\u3044\u304b\u3089\u3001\u5ff5\u306e\u70ba\u3001MySQL5.7\u4e92\u63db\u306eAurora Serverless\u304c\u30ea\u30ea\u30fc\u30b9\u3055\u308c\u308b\u307e\u3067\u306f\u30015.7\u306e\u72ec\u81ea\u6a5f\u80fd\u3067\u3042\u308bJSON\u578b\u3068\u304b\u306f\u4f7f\u308f\u306a\u3044\u307b\u3046\u304c\u826f\u3044\u304b\u3082\u30fb\u30fb\u30fb", "@keitakn \r\n\u4e86\u89e3\uff01\u6599\u91d1\u306e\u8aac\u660e\u3082\u3042\u308a\u304c\u3068\u3046\ud83d\udc31", "@keitakn \r\n\u30d0\u30fc\u30b8\u30e7\u30f3\u306b\u3064\u3044\u3066\u3082\u4e86\u89e3\uff01"]}, {"url": "https://github.com/nekochans/qiita-stocker-terraform/pull/18", "comments": ["\u7d30\u304b\u3044\u3051\u3069\u3001\u4ed6\u306e\u90e8\u5206\u304c\u30b9\u30cd\u30fc\u30af\u30b1\u30fc\u30b9\u306b\u306a\u3063\u3066\u3044\u308b\u304b\u3089\u3001\u3053\u3053\u3082\u30b9\u30cd\u30fc\u30af\u30b1\u30fc\u30b9\u306b\u4fee\u6b63\u3057\u305f\u307b\u3046\u304c\u826f\u3044\u304b\u3082\ud83d\udc31\uff01", "\u7d30\u304b\u3044\u3051\u3069\u3001\u4ed6\u306e\u90e8\u5206\u304c\u30b9\u30cd\u30fc\u30af\u30b1\u30fc\u30b9\u306b\u306a\u3063\u3066\u3044\u308b\u304b\u3089\u3001\u3053\u3053\u3082\u30b9\u30cd\u30fc\u30af\u30b1\u30fc\u30b9\u306b\u4fee\u6b63\u3057\u305f\u307b\u3046\u304c\u826f\u3044\u304b\u3082\ud83d\udc31\uff01", "terraform\u306e\u5236\u7d04\u3067`_`\u3092\u4f7f\u7528\u3059\u308b\u3068\u30a8\u30e9\u30fc\u306b\u306a\u308b\u304b\u3089\u30cf\u30a4\u30d5\u30f3\u3092\u8a2d\u5b9a\u3057\u3066\u3044\u308b\u3088\uff01\ud83d\udc31\r\n```\r\nonly lowercase alphanumeric characters and hyphens allowed in \"cluster_identifier\"\r\n```", "\u3053\u3053\u3082\u4e0a\u3068\u540c\u3058\u7406\u7531\u3067\u3001\u30cf\u30a4\u30d5\u30f3\u3092\u8a2d\u5b9a\u3057\u3066\u308b\u3088\uff01\ud83d\udc31", "\u306a\u308b\u307b\u3069\u3001\u305d\u3046\u3060\u3063\u305f\u304b\ud83d\udc31\uff01\r\n\u308f\u304b\u3063\u305f\uff01\u3058\u3083\u3042\u3053\u306e\u307e\u307e\u3044\u3053\u3063\u304b\ud83d\udc4c", "\u4e86\u89e3\uff01\u305d\u306e\u307e\u307e\u3067\u884c\u3053\u3046\ud83d\udc4c"]}, {"url": "https://github.com/nekochans/qiita-stocker-terraform/pull/17", "comments": ["\u3053\u306e\u5f62\u3060\u3068 \u672c\u756a\u74b0\u5883\u3067\u3082 `prod-www-nekochans.com` \u307f\u305f\u3044\u306a\u611f\u3058\u306b\u306a\u3063\u3061\u3083\u3046\u304b\u3089\u3001\u5404\u74b0\u5883\u6bce\u306b\u5909\u6570\u3092\u7528\u610f\u3059\u308b\u307b\u3046\u304c\u826f\u3044\u304b\u306a\u3068\u601d\u3063\u305f\ud83d\udc31\uff01", "\u306a\u308b\u307b\u3069\uff01\u958b\u767a\u74b0\u5883\u7528\u306e\u8a2d\u5b9a\u306b\u306a\u3063\u3061\u3083\u3046\u3093\u3060\u306d\ud83d\udca6\r\n`modules/aws/frontend/main.tf`\u306b\u3064\u3044\u3066\u3082\u540c\u69d8\u306e\u8a2d\u5b9a\u3092\u884c\u306a\u3063\u3066\u3044\u305f\u304b\u3089\u3001\u3053\u3061\u3089\u306b\u3064\u3044\u3066\u3082\u5408\u308f\u305b\u3066\u4fee\u6b63\u3057\u305f\u3088\uff01"]}, {"url": "https://github.com/nekochans/qiita-stocker-terraform/pull/14", "comments": ["\u4eca\u306f\u3053\u306e\u307e\u307e\u3067\u826f\u3044\u3051\u3069\u3001HTTP\u30ea\u30b9\u30ca\u30fc\u306f\u72ec\u81ea\u30c9\u30e1\u30a4\u30f3\u3067\u63a5\u7d9a\u53ef\u80fd\u306b\u306a\u3063\u305f\u5f8c\u306f\u524a\u9664\u3057\u3061\u3083\u3063\u3066\u554f\u984c\u306a\u3055\u305d\u3046\u3060\u306d\ud83d\udc31\uff01", "\u3053\u306eALB\u306e\u8a3c\u660e\u66f8\u306f\u6771\u4eac\u30ea\u30fc\u30b8\u30e7\u30f3\u306e\u7269\u3092\u5229\u7528\u3059\u308b\u4e8b\u306f\u51fa\u6765\u306a\u304b\u3063\u305f\u611f\u3058\u304b\u306a\ud83d\udc31\uff1f\r\n\u4e00\u6642\u7684\u306a\u3089\u3053\u306e\u307e\u307e\u3067\u826f\u3044\u3068\u601d\u3046\u3051\u3069\u3001\u524d\u306ePR\u3067\u3084\u3063\u3066\u305f\u307f\u305f\u3044\u306a `data \"aws_acm_certificate\"` \u3092\u4f7f\u3048\u3070\u65e2\u5b58\u306e\u8a3c\u660e\u66f8Resources\u3092Terraform\u5074\u3067\u53d6\u5f97\u51fa\u6765\u308b\u3068\u601d\u3063\u305f\u3093\u3060\u3051\u3069\u3001\u4e0a\u624b\u304f\u3044\u304b\u306a\u304b\u3063\u305f\u304b\u306a\uff1f\uff1f\r\n\r\n\u3082\u3057\u4f55\u3089\u304b\u306e\u7406\u7531\u3067\u8a3c\u660e\u66f8\u3092\u53d6\u308c\u306a\u3044\u5834\u5408\u306f\u4ed5\u65b9\u306a\u3044\u3068\u601d\u3046\u3051\u3069\u3001\u8a3c\u660e\u66f8\u306eARN\u306b\u306f `310040406861` \u306e\u3088\u3046\u306aAWS\u30a2\u30ab\u30a6\u30f3\u30c8\u304c\u542b\u307e\u308c\u308b\u304b\u3089\u3001\u3053\u308c\u306f `terraform.tfvars` \u306b\u5165\u308c\u3066\u975e\u516c\u958b\u3068\u3057\u3066\u6271\u3063\u305f\u307b\u3046\u304c\u7121\u96e3\u304b\u3082\uff01\r\n\r\nAWS\u306e\u30a2\u30ab\u30a6\u30f3\u30c8ID\u304c\u30d0\u30ec\u3066\u3082\u305d\u308c\u3060\u3051\u3067\u30a4\u30bf\u30ba\u30e9\u3059\u308b\u4e8b\u306f\u51fa\u6765\u306a\u3044\u3051\u3069\u3001\u653b\u6483\u8005\u306e\u653b\u6483\u6750\u6599\u306b\u306a\u308b\u4e8b\u306f\u9593\u9055\u3044\u306a\u3044\uff08\u30a2\u30ab\u30a6\u30f3\u30c8ID\u304c\u5206\u304b\u308c\u3070\u7279\u5b9a\u306eResources\u306eARN\u3092\u63a8\u6e2c\u3055\u308c\u3066\u653b\u6483\u6750\u6599\u306b\u3055\u308c\u308b\u53ef\u80fd\u6027\u304c\u50c5\u304b\u3060\u304c\u3042\u308b\uff09\u304b\u3089 \u5c11\u306a\u304f\u3068\u3082 `terraform.tfvars` \u306b\u907f\u96e3\u3055\u305b\u308b\u3068\u826f\u3044\u3068\u601d\u3046\ud83d\udc31\uff01", "`idle_timeout = 120` \u3092\u8db3\u3057\u3066\u304a\u3044\u305f\u307b\u3046\u304c\u826f\u3044\u304b\u3082\ud83d\udc31\uff01\r\n\r\nhttps://dev.classmethod.jp/cloud/aws/set_keepalivetimeout_on_apache_for_resolve_elb_timeout/\r\n\r\n120\u306e\u6839\u62e0\u306a\u3093\u3060\u3051\u3069\u3001\u3053\u306e\u8a18\u4e8b\u306b\u3042\u308b\u901a\u308aAWS\u306f\u30bf\u30a4\u30e0\u30a2\u30a6\u30c8\u3092120\u79d2\u306b\u8a2d\u5b9a\u3059\u308b\u4e8b\u3092\u63a8\u5968\u3057\u3066\u3044\u308b\u3088\u3046\u3060\u304b\u3089120\u79d2\u306b\u8a2d\u5b9a\u3057\u3066\u3042\u308b\u3088\uff01", "\u3059\u3054\u304f\u7d30\u304b\u3044\u3051\u3069 `${terraform.workspace}_${lookup(var.api, \"${terraform.env}.name\", var.api[\"default.name\"])}_alb` \u3068\u3057\u3066\u30b9\u30cd\u30fc\u30af\u30b1\u30fc\u30b9\u306b\u7d71\u4e00\u3057\u305f\u307b\u3046\u304c\u826f\u3044\u304b\u306a\ud83d\udc31\uff01\r\n\r\nVPC\u306e\u540d\u524d\u304c `stg_qiita_stocker_vpc` \u307f\u305f\u3044\u306a\u30b9\u30cd\u30fc\u30af\u30b1\u30fc\u30b9\u306b\u306a\u3063\u3066\u3044\u308b\u304b\u3089\u3001\u4ed6\u306e\u90e8\u5206\u3082\u542b\u3081\u3066\u30b9\u30cd\u30fc\u30af\u30b1\u30fc\u30b9\u3067\u7d71\u4e00\u3057\u305f\u307b\u3046\u304c\u9055\u548c\u611f\u306a\u3044\u304b\u3082\uff01\r\n\r\n\u7d50\u69cb\u6642\u9593\u304b\u304b\u308a\u305d\u3046 + \u4e00\u5ea6 `terraform destroy` \u3067Resources\u306e\u524a\u9664\u3057\u3066\u304b\u3089\u518d\u4f5c\u6210\u304c\u5fc5\u8981\u306b\u306a\u308b\u90e8\u5206\u3082\u3042\u308b\u3057\u3001\u5225\u306eissue\u7acb\u3066\u3066\u3001\u305d\u3053\u3067\u5168\u4f53\u898b\u76f4\u3057\u3066\u3082\u826f\u3055\u305d\u3046\u3060\u306d\ud83d\udc31", "\u3053\u308c\u306f\u3001nginx\u306e\u8a2d\u5b9a\u304c\u5fc5\u8981\u3063\u3066\u3053\u3068\u3060\u304b\u3089\u3001\u3053\u3053\u3067\u306f\u5bfe\u5fdc\u3057\u306a\u3044\u3067\u304a\u304f\u306d\uff01", "\u3053\u3053\u306f\u3001\u4eee\u5b9f\u88c5\u3067\u5024\u3092\u8a2d\u5b9a\u3057\u3066\u3044\u305f\u306e\u3092\u305d\u306e\u307e\u307e\u30b3\u30df\u30c3\u30c8\u3057\u3061\u3083\u3063\u3066\u305f\u30fb\u30fb\u30fb\r\n`\"aws_acm_certificate\"`\u3092\u4f7f\u3046\u3088\u3046\u306b\u4fee\u6b63\u3057\u305f\u3088\uff01", "\u4e86\u89e3\uff01\u3053\u306e https://github.com/nekochans/qiita-stocker-terraform/issues/12 \u8ab2\u984c\u3067\u5bfe\u5fdc\u3059\u308b\u306d\uff01\r\n", "\u3053\u3053\u3082\u3001\u540d\u524d\u3092\u30b9\u30cd\u30fc\u30af\u30b1\u30fc\u30b9\u306b\u4fee\u6b63\u3057\u305f\u3088\uff01"]}, {"url": "https://github.com/nekochans/qiita-stocker-terraform/pull/11", "comments": ["\u304a\uff4b\uff01\u8a2d\u5b9a\u7684\u306b\u9593\u9055\u3063\u3066\u3044\u306a\u3044\u3057\u3053\u308c\u3067\u5341\u5206\u306a\u3093\u3060\u3051\u3069\u3001\u30a2\u30af\u30bb\u30b9\u30ed\u30b0\u3092S3Bucket\u306b\u6b8b\u3059\u8a2d\u5b9a\u304c\u3042\u3063\u3066\u3001\u305d\u308c\u3092\u8ffd\u52a0\u3059\u308b\u3068\u3055\u3089\u306b\u826f\u3044\u3068\u601d\u3046\ud83d\udc31\uff01\r\n\r\n\u2193\u3053\u3093\u306a\u611f\u3058\u306eS3BucketResources\u3092\u7528\u610f\u3057\u3066\u2193\r\n\r\n```\r\nresource \"aws_s3_bucket\" \"web_access_logs\" {\r\n  bucket        = \"${terraform.workspace}-qiita-stocker-web-logs\"\r\n  force_destroy = true\r\n}\r\n```\r\n\r\n`aws_cloudfront_distribution` \u306e\u8a2d\u5b9a\u306b\u8ffd\u52a0\u3059\u308b\u5f62\u3067\u2193\r\n\r\n```\r\n  logging_config {\r\n    bucket          = \"${aws_s3_bucket.web_access_logs.bucket_domain_name}\"\r\n    include_cookies = true\r\n    prefix          = \"raw/\"\r\n  }\r\n```\r\n\r\n\u3053\u3046\u3059\u308b\u3068\u30e6\u30fc\u30b6\u30fc\u304c\u30a2\u30af\u30bb\u30b9\u3057\u305f\u30ed\u30b0\u304cS3Bucket\u306b\u6b8b\u308b\u304b\u3089\u4f55\u304b\u5408\u3063\u305f\u6642\u306e\u8abf\u67fb\u304c\u697d\u306b\u306a\u308b\u3088\uff01\r\n\r\n\u3061\u306a\u307f\u306b\u3053\u308c\u306f `\u74b0\u5883\u5909\u6570-qiita-stocker-web-logs` \u3063\u3066\u3044\u3046S3Bucket\u306e `raw/` \u3063\u3066\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u30a2\u30af\u30bb\u30b9\u30ed\u30b0\u3092\u8a18\u9332\u3059\u308b\u3088\u3046\u306b\u3057\u3066\u308b\u3093\u3060\u3051\u3069\u3001\u30ed\u30b0\u3092\u52a0\u5de5\u3057\u3066\u30c7\u30fc\u30bf\u5206\u6790\u7b49\u306b\u5229\u7528\u3059\u308b\u3063\u3066\u30b1\u30fc\u30b9\u306f\u7d50\u69cb\u3042\u3063\u3066\u3001\u305d\u306e\u969b\u306b\u751f\u306e\u30ed\u30b0\u30c7\u30fc\u30bf\u3060\u3088\u30fc\u3063\u3066\u5206\u304b\u308b\u3088\u3046\u306b `raw/` \u3063\u3066\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3092\u5207\u3063\u3066\u3042\u308b\u611f\u3058\uff01\uff08S3Bucket\u306b\u5bfe\u8c61\u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u304c\u306a\u3044\u5834\u5408\u306f\u81ea\u52d5\u3067\u4f5c\u3089\u308c\u308b\u304b\u3089\u554f\u984c\u306a\u3057\uff09\r\n\r\n\u3061\u306a\u307f\u306b\u73fe\u6642\u70b9\u3067\u3082\u5b8c\u4e86\u306e\u5b9a\u7fa9\u306f\u6e80\u305f\u3057\u3066\u3044\u308b\u3057\u3001\u3053\u306e\u5185\u5bb9\u306f\u5225\u306eissue\u3092\u7acb\u3066\u3066\u5bfe\u5fdc\u3059\u308b\u3068\u304b\u3067\u3082\u5927\u4e08\u592b\uff01\u6700\u7d42\u5224\u65ad\u306f\u4efb\u305b\u308b\u3088\ud83d\udc4d", "\u305d\u3046\u305d\u3046\uff01\u3053\u306e `data. aws_acm_certificate` \u3092\u4f7f\u3046\u3068\u65e2\u5b58\u306e\u8a3c\u660e\u66f8\u306eResourcesID\u3092\u53d6\u308c\u308b\u304b\u3089\u3053\u306e\u5bfe\u5fdc\u304c\u30d9\u30b9\u30c8\u3060\u3068\u601d\u3046\ud83d\udc4c\r\n\r\n\u3061\u306a\u307f\u306b\u8a3c\u660e\u66f8\u306e\u767a\u884c\u306b\u95a2\u3057\u3066\u306f\u81ea\u52d5\u5316\u3059\u308b\u306e\u304c\u304b\u306a\u308a\u96e3\u3057\u3044\u3001\u3001\u3001\u9014\u4e2d\u3067DNS\u8a8d\u8a3c\u304b\u30e1\u30fc\u30eb\u8a8d\u8a3c\u306e\u3069\u3061\u3089\u304b\u3092\u7d4c\u7531\u3057\u306a\u3044\u3068\u767a\u884c\u51fa\u6765\u306a\u3044\u306e\u304c\u7406\u7531\u30fb\u30fb\u30fb\ud83d\udc31", "\u306a\u308b\u307b\u3069\u3001\u4e0b\u624b\u306b\u81ea\u52d5\u5316\u3059\u308b\u3088\u308a\u3082\u3053\u3053\u3060\u3051\u624b\u52d5\u3067\u884c\u306a\u3063\u305f\u65b9\u304c\u826f\u3055\u305d\u3046\u3060\u306d\uff01", "CloudFront\u3067\u30a2\u30af\u30bb\u30b9\u30ed\u30b0\u306e\u51fa\u529b\u306e\u8a2d\u5b9a\u307e\u3067\u3067\u304d\u308b\u3093\u3060\u306d\uff01\u4fbf\u5229\u30fb\u30fb\ud83d\udc31\r\nslack\u3067\u5225\u306eIssue\u3092\u7acb\u3066\u308b\u3068\u8a00\u3063\u305f\u3051\u3069\u3001\u5185\u5bb9\u78ba\u8a8d\u3057\u305f\u3089Issue\u3092\u5206\u3051\u308b\u307e\u3067\u3082\u306a\u3044\u3068\u601d\u3063\u305f\u304b\u3089\u5225\u306ePR\u3067\u5bfe\u5fdc\u3059\u308b\u306d\uff01"]}, {"url": "https://github.com/nekochans/qiita-stocker-terraform/pull/9", "comments": ["\u3053\u306e\u30ea\u30e2\u30fc\u30c8State\u306e\u540d\u524d\u306f `bastion` \u304c\u826f\u3044\u304b\u306a\u3068\u601d\u3063\u305f\ud83d\udc31\uff01\r\n\u7406\u7531\u306f `bastion` \u30b5\u30fc\u30d0\u30fc\u306e `tfstate` \u3092\u53c2\u7167\u3057\u3066\u3044\u308b\u304b\u3089\u3001\u540c\u3058\u540d\u524d\u3092\u4ed8\u3051\u3066\u304a\u304f\u306e\u304c\u826f\u3044\u304b\u306a\u3068\u601d\u3063\u305f\uff01", "\u305d\u3063\u304b\uff01[\u3053\u3053](https://github.com/nekochans/qiita-stocker-terraform/pull/9/commits/6e5ea0247889cfbbff38acae3cea07300904b3c4#diff-eba0d8edb11175bb925032cff05af0f4R12)\u3067\u30ea\u30e2\u30fc\u30c8State\u306e\u540d\u524d\u304c`network`\u3068\u306a\u3063\u3066\u3044\u308b\u306e\u306f\u3001`vpc`\u3060\u3051\u3058\u3083\u306a\u304f\u3001`subnet`\u3068\u304b\u3082\u542b\u3081\u305f\u30ea\u30bd\u30fc\u30b9\u304c\u542b\u307e\u308c\u3066\u3044\u308b\u304b\u3089\u3060\u3088\u306d\uff01\ud83d\udc31\r\n\u30b3\u30e1\u30f3\u30c8\u306e\u7b87\u6240\u3067\u6307\u5b9a\u3057\u3066\u3044\u308b\u306e\u306f\u3001`bastion`\u30b5\u30fc\u30d0\u30fc\u306b\u95a2\u3059\u308b`tfstate`\u3060\u304b\u3089`bastion`\u306e\u65b9\u304c\u9069\u5207\u3060\u306d\uff01\r\n\r\n\u30ea\u30e2\u30fc\u30c8State\u306e\u540d\u524d\u3092`bastion`\u306b\u4fee\u6b63\u3057\u305f\u3088\uff01", "`modules/aws/vpc`\u3053\u306e\u30d1\u30b9\u3082`modules/aws/network`\u306b\u4fee\u6b63\u3057\u305f\u65b9\u304c\u3001\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u69cb\u6210\u3068\u3057\u3066\u306f\u3044\u3044\u304b\u306a\uff1f\ud83d\udc31", ">modules/aws/vpc\u3053\u306e\u30d1\u30b9\u3082modules/aws/network\u306b\u4fee\u6b63\u3057\u305f\u65b9\u304c\u3001\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u69cb\u6210\u3068\u3057\u3066\u306f\u3044\u3044\u304b\u306a\uff1f\ud83d\udc31\r\n\r\n\u3053\u308c\u306f\u305d\u306e\u307e\u307e\u3067\u826f\u3044\u3068\u601d\u3046\ud83d\udc4c\r\n\u3068\u3044\u3046\u306e\u30821\u3064\u306etfstate\u3067\u8907\u6570\u306emodule\u3092\u30ed\u30fc\u30c9\u3059\u308b\u3063\u3066\u4e8b\u3082\u3042\u308b\u304b\u3089\u3001VPC\u3060\u3051\u69cb\u7bc9\u3057\u3066\u308b `modules/aws/vpc` \u306f\u3053\u306e\u307e\u307e\u306e\u540d\u524d\u3067\u826f\u3044\u304b\u306a\u3068\u500b\u4eba\u7684\u306b\u306f\u601d\u3046\ud83d\udc31\uff01", "\u306a\u308b\u307b\u3069\u3001VPC\u306e\u69cb\u7bc9\u306b\u95a2\u3059\u308b\u30e2\u30b8\u30e5\u30fc\u30eb\u3060\u304b\u3089`modules/aws/vpc`\u3067\u3082\u554f\u984c\u306a\u3044\u611f\u3058\u304b\u306a\ud83d\udc31\r\n\u3053\u3053\u306f\u3001\u3053\u306e\u307e\u307e\u306b\u3057\u3066PR\u30af\u30ed\u30fc\u30ba\u3059\u308b\u306d\uff01"]}, {"url": "https://github.com/nekochans/qiita-stocker-terraform/pull/8", "comments": ["`ssh_public_key_path` \u306f\u672c\u756a\u7528\u3068\u958b\u767a\u7528\u3067\u7570\u306a\u308b\u304b\u3089\u3001\u3053\u306e\u30d5\u30a1\u30a4\u30eb\u3092Git\u306e\u7ba1\u7406\u5bfe\u8c61\u5916\u3068\u3059\u308b\u3068\u3044\u3046\u5224\u65ad\u306f\u3059\u3054\u304f\u826f\u3044\u3093\u3060\u3051\u3069\u3001\u3053\u306e\u5834\u5408\u306f `providers/aws/environments/20-bastion/terraform.tfvars` \u3063\u3066\u30d5\u30a1\u30a4\u30eb\u3092\u914d\u7f6e\u3057\u3066\u4e2d\u8eab\u3092\u2193\r\n\r\n```\r\nssh_public_key_path = \"~/.ssh/dev_qiita_stocker_aws.pem.pub\"\r\n```\r\n\r\n\u3068\u3057\u3066\u30d5\u30a1\u30a4\u30eb\u3092\u7f6e\u304f\uff08\u3053\u306e\u30d5\u30a1\u30a4\u30eb\u306fGit\u306e\u7ba1\u7406\u5bfe\u8c61\u5916\uff09\u305d\u3057\u3066\u3001`providers/aws/environments/20-bastion/variable.tf` \u306fGit\u306b\u30b3\u30df\u30c3\u30c8\u3057\u3061\u3083\u3063\u3066OK\uff08\u30b3\u30df\u30c3\u30c8\u3057\u305f\u307b\u3046\u304c\u826f\u3044\uff09\u3067\u305d\u306e\u304b\u308f\u308a\u4e2d\u8eab\u3092\u3053\u3093\u306a\u611f\u3058\u306b\u3059\u308b\u2193\r\n\r\n```\r\nvariable \"ssh_public_key_path\" {\r\n  type    = \"string\"\r\n  default = \"\"\r\n}\r\n```\r\n\r\n\u3053\u3046\u3059\u308b\u3068 `terraform.tfvars` \u306b\u66f8\u3044\u305f\u5024\u304c\u5b9f\u884c\u6642\u306b\u4ee3\u5165\u3055\u308c\u308b\u3088\u3046\u306b\u306a\u308b\uff01\r\n\u306a\u305c\u3053\u3093\u306a\u9762\u5012\u306a\u4e8b\u3092\u3059\u308b\u304b\u3068\u3044\u3046\u3068\u3001`variable.tf` \u3092Git\u306e\u7ba1\u7406\u5bfe\u8c61\u5916\u306b\u3057\u3061\u3083\u3046\u3068\u3001\u3069\u306e\u3088\u3046\u306a\u5909\u6570\u304c\u5b9a\u7fa9\u3055\u308c\u3066\u3044\u308b\u304b\u30b3\u30fc\u30c9\u3092\u898b\u305f\u3060\u3051\u3067\u5206\u304b\u3089\u306a\u3044\u3051\u3069\u3001`terraform.tfvars` \u3092\u4f7f\u3046\u3068\u3001\u5c11\u306a\u304f\u3068\u3082\u3053\u3046\u3044\u3046\u540d\u524d\u306e\u5909\u6570\u304c\u5b9a\u7fa9\u3055\u308c\u3066\u3044\u308b\u3068\u3044\u3046\u4e8b\u304c\u5206\u304b\u308b\u304b\u3089\u3053\u3063\u3061\u306e\u65b9\u6cd5\u304c\u30aa\u30b9\u30b9\u30e1\u3060\u3088\ud83d\udc31\uff01", "\u5b89\u4fa1\u306a\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u3060\u3068 [T3\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9](https://dev.classmethod.jp/cloud/aws/t3-instance/) \u3063\u3066\u3044\u3046\u30b7\u30ea\u30fc\u30ba\u304c\u6700\u8fd1\u51fa\u305f\u304b\u3089\u3001`t3.micro` \u3092\u4f7f\u3046\u3068\u826f\u3044\u304b\u3082\ud83d\udc31\uff1f\r\n\r\n\u500b\u4eba\u7684\u306a\u8003\u3048\u3060\u3051\u3069\u4eca\u5f8c\u306f `t2` \u30b7\u30ea\u30fc\u30ba\u3092\u4f7f\u3046\u306e\u3092\u8f9e\u3081\u3066\u3001\u30b3\u30b9\u30d1\uff06\u6027\u80fd\u5171\u306b\u512a\u308c\u308b `t3` \u7cfb\u306e\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u3092\u4f7f\u3063\u3066\u3044\u304f\u306e\u304c\u826f\u3044\u3068\u601d\u3063\u305f\uff01"]}, {"url": "https://github.com/nekochans/qiita-stocker-terraform/pull/7", "comments": ["\u7d30\u304b\u3044\u3051\u3069\u3053\u306e\u30cd\u30fc\u30e0\u30bf\u30b0\u306e\u547d\u540d\u306f\u4ed6\u3068\u5408\u308f\u305b\u3066\u3001 `${terraform.workspace}_igw` \u304c\u3044\u3044\u304b\u306a\ud83d\udc31\uff01\r\n\r\nterraform\u306e\u6163\u4f8b\u3063\u3066\u7d50\u69cb\u3084\u3084\u3053\u3057\u3044\u3093\u3060\u3051\u3069\u3001\u57fa\u672c\u7684\u306b\u2193\r\n\r\n- \u5909\u6570\u540d\u3084\u30ea\u30bd\u30fc\u30b9\u540d\uff08[\u30b9\u30cd\u30fc\u30af\u30b1\u30fc\u30b9](https://wa3.i-3-i.info/word1180.html)\uff09\r\n- \u30d5\u30a1\u30a4\u30eb\u540d\u3068\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u540d\uff08[\u30b1\u30d0\u30d6\u30b1\u30fc\u30b9](https://qiita.com/ybiquitous/items/75288bacb596a82a2805)\uff09\r\n\r\n\u306a\u3093\u304b\u3069\u3063\u3061\u304b\u306b\u7d71\u4e00\u3057\u3066\u3088\u3063\u3066\u601d\u3046\u304b\u3082\u3060\u3051\u3069\u3001Terraform\u306e\u958b\u767a\u5143\u306eHashiCorp\u793e\u306eRepository\u304c\u3053\u3046\u306a\u3063\u3066\u3044\u308b\u304b\u3089\u3001\u4e00\u5fdc\u5408\u308f\u305b\u3066\u3042\u308b\u3088\ud83d\udc31\uff01\r\n\r\nhttps://github.com/hashicorp/terraform-aws-consul/tree/master/modules\r\n\r\n\u4ed6\u306b\u3082\u3053\u306e\u547d\u540d\u30eb\u30fc\u30eb\u306b\u5247\u3063\u3066\u306a\u3044\u7b87\u6240\u304c\u3042\u3063\u305f\u3089\u3053\u306e\u611f\u3058\u3067\u4fee\u6b63\u3059\u308b\u3068\u826f\u3044\u3068\u601d\u3046\uff01", "\u30b3\u30e1\u30f3\u30c8\u3042\u308a\u304c\u3068\u3046\uff01\u547d\u540d\u898f\u5247\u3092\u610f\u8b58\u3057\u3066\u306a\u304b\u3063\u305f\ud83d\udca6\r\n\u30bf\u30b0\u30cd\u30fc\u30e0\u3092\u30b9\u30cd\u30fc\u30af\u30b1\u30fc\u30b9\u306b\u4fee\u6b63\u3057\u305f\u3088\uff01", "\u3053\u3053\u524d\u306e\u6bb5\u968e\u3067\u306f\u898b\u843d\u3068\u3057\u3066\u3093\u3060\u3051\u3069\u3001\u3082\u3046\u3053\u3053\u307e\u3067\u6765\u305f\u3089 `variable \"vpc\"` \u306b\u2193\r\n\r\n```\r\n    default.az_1a = \"ap-northeast-1a\"\r\n    default.az_1c = \"ap-northeast-1c\"\r\n    default.az_1d = \"ap-northeast-1d\"\r\n```\r\n\r\n\u3068\u5b9a\u7fa9\u3057\u305f\u307b\u3046\u304c\u5206\u304b\u308a\u3084\u3059\u3044\u304b\u3082\uff01\r\n\r\n\u305d\u3057\u3066 `variable \"common\"` \u306f\u6d88\u3057\u3061\u3083\u3063\u3066\u3082\u3044\u3044\u304b\u306a\u3068\u601d\u3063\u305f\uff01\r\nregion\u306e\u6307\u5b9a\u306f\u57fa\u672c\u7684\u306b `backend.tf` \u306e\u307b\u3046\u3067\u884c\u3046\u307b\u3046\u304c\u697d\u3060\u3057\u3001availability_zone\u3092Resources\u306e\u5f15\u6570\u306b\u4f7f\u3046\u30b1\u30fc\u30b9\u3063\u3066VPC\u4ee5\u5916\u306b\u306f\u306a\u3055\u305d\u3046\u306a\u306e\u304c\u7406\u7531\u304b\u306a\ud83d\udc31", "\u3054\u3081\u3093\u3001\u3053\u308c\u3082\u3055\u3063\u304d\u898b\u843d\u3068\u3057\u3066\u3066\u3001= \u306e\u4f4d\u7f6e\u304c\u30ba\u30ec\u3066\u308b\u304b\u3089\u3001\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u30eb\u30fc\u30c8\u3067 `terraform fmt` \u5b9f\u884c\u3059\u308b\u3068\u826f\u3044\u304b\u306a\ud83d\udc31\uff01", "\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3092\u4fee\u6b63\u3057\u305f\u3088\uff01\r\n\r\n\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u30eb\u30fc\u30c8\u3067`terraform fmt`\u3092\u884c\u3046\u5fc5\u8981\u304c\u3042\u308b\u3093\u3060\u306d\uff01\r\n`10-network`\u3067\u5b9f\u884c\u3057\u3066\u305f\u304b\u3089\u3001\u6574\u5f62\u3055\u308c\u3066\u306a\u304b\u3063\u305f\ud83d\udca6\u304a\u624b\u6570\u304a\u304b\u3051\u3057\u307e\u3057\u305f\u30fb\u30fb\ud83d\ude47\u200d\u2640\ufe0f\r\n\r\n", "\u306a\u308b\u307b\u3069\u3002\u7121\u7406\u306b\u3001`common`\u3067\u5b9a\u7fa9\u3059\u308b\u5fc5\u8981\u3082\u306a\u3044\u3082\u3093\u306d\uff01\r\n`variable \"vpc\"`\u306baz\u3092\u5b9a\u7fa9\u3059\u308b\u3088\u3046\u306b\u4fee\u6b63\u3057\u305f\u3088\uff01"]}]}, {"url": "https://github.com/UCDenver-ccp/Translator-TM-Provider-Infrastructure-Modules.git", "pull_requests": []}, {"url": "https://github.com/k9securityio/terraform-aws-s3-bucket.git", "pull_requests": [{"url": "https://github.com/k9securityio/terraform-aws-s3-bucket/pull/6", "comments": ["Is the redundant statement necessary because multiple conditions are AND'ed?", "@dweomer - are you asking if `DenyUnencryptedStorage ` is necessary because `DenyStorageWithoutKMSEncyrption` should deny access if `s3:x-amz-server-side-encryption != aws:kms`?\r\n\r\nI do think the policy could be simplified.  It was originally written as an explicit demonstration of a AWS security policy features.  We'll get it fixed up."]}]}, {"url": "https://github.com/xuwang/aws-terraform.git", "pull_requests": []}, {"url": "https://github.com/SweetOps/terraform-google-project.git", "pull_requests": []}, {"url": "https://github.com/xposix/aws_landing_zone.git", "pull_requests": []}, {"url": "https://github.com/emyasa/hashicorp-consul-setup.git", "pull_requests": []}, {"url": "https://github.com/circleci/enterprise-setup.git", "pull_requests": [{"url": "https://github.com/CircleCI-Archived/enterprise-setup/pull/191", "comments": ["```suggestion\r\napt-get -y install docker-ce=5:18.09.9~3-0~ubuntu-$(lsb_release -cs)\r\n```"]}, {"url": "https://github.com/CircleCI-Archived/enterprise-setup/pull/175", "comments": ["Minor: the recommended doesn't match what we are defaulting to.", "Pushed some additional commits to address this.  Let me know if the changes resolve the issue please."]}, {"url": "https://github.com/CircleCI-Archived/enterprise-setup/pull/127", "comments": ["i'm getting a syntax error testing this jq statement on my machine. The assignment operator in jq is `=`", "the syntax error has been fixed", "This actually throws an error on Trusty using jq 1.3. It does work in 1.5.1 but not 1.3, the latest available to Trusty. Adding some brackets solves it:\r\n\r\n```suggestion\r\njq '.[\"userns-remap\"]=\"default\"' /etc/docker/daemon.json > \"$tmp\" && mv \"$tmp\" /etc/docker/daemon.json\r\n```"]}, {"url": "https://github.com/CircleCI-Archived/enterprise-setup/pull/110", "comments": ["Might be worth pointing people to the Prerequisites and Planning doc as well the install guide? https://circleci.com/docs/2.0/aws-prereq/#section=server-administration. This details needing terraform, and all the other bits of info they are going to need to have to hand.", "```suggestion\r\nYou can find teardown instructions at https://circleci.com/docs/2.0/aws-teardown/.\r\n```", "```suggestion\r\nYou can find instructions here: https://circleci.com/docs/2.0/aws/.\r\n```", "```suggestion\r\nIf you want to upgrade an existing installation from a previous version, follow these [upgrade instructions](https://circleci.com/docs/2.0/updating-server/#section=server-administration).\r\n```", "Done", "Done", "```suggestion\r\nPlease refer to our prerequisites documentation here: https://circleci.com/docs/2.0/aws-prereq.\r\n```", "```suggestion\r\nThis package allows you to orchestrate your CircleCI Server cluster in AWS using Terraform.\r\n```"]}, {"url": "https://github.com/CircleCI-Archived/enterprise-setup/pull/109", "comments": ["does it always end up being in ens3 for these installs? ", "ya as far as i know @GERey ", "or else `enp0s3`: https://askubuntu.com/questions/889880/cannot-find-device-eth0#889882\r\nor `ens33`: https://itzgeek.com/how-tos/mini-howtos/change-default-network-name-ens33-to-old-eth0-on-ubuntu-16-04.html\r\n\r\nwe should replace this with a shell command to programatically grab the right network interface", "something like `lshw -C network`"]}, {"url": "https://github.com/CircleCI-Archived/enterprise-setup/pull/102", "comments": ["That ip address seemed to be a mistake? @teresaibarra ", "@junejung I should've added more comments here -- my mistake\r\nThis `curl` command retrieves the instance ID from this URL, as noted in the AWS documentation [here](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html). This instance's information is available from within the running instance, so we just grab the information from that IP address.\r\n\r\nHashicorp does similarly in this [file](https://github.com/hashicorp/terraform-aws-nomad/blob/master/modules/run-nomad/run-nomad#L9).\r\n\r\nIt is kinda weird -- though it is nice that we aren't billed for it. Should I add a comment here about how we get the instance ID?", "Pull that hard-coded IP address out and replace with a variable in the top of the file?"]}, {"url": "https://github.com/CircleCI-Archived/enterprise-setup/pull/77", "comments": ["`force_destroy_s3_bucket`?", "May be named poorly?  The idea is that it will delete an S3 bucket even if it has files in it.", "Ah sorry about that, yeah, I was suggesting a new name, I'll be more verbose in future.\r\n\r\nI think `force_destroy_s3_bucket` is clearer, because it will attempt to delete the bucket regardless of this setting."]}, {"url": "https://github.com/CircleCI-Archived/enterprise-setup/pull/73", "comments": ["Can we flip this around? `services_user_data_enabled` with a default of true?"]}, {"url": "https://github.com/CircleCI-Archived/enterprise-setup/pull/65", "comments": ["missing comma"]}, {"url": "https://github.com/CircleCI-Archived/enterprise-setup/pull/46", "comments": ["Certain calls for NPM and Yarn will require HTTPS. As such, this will need to also have:\r\n`sudo echo 'export https_proxy=\"${http_proxy}\"' >> /etc/default/docker`\r\n", "Same as above", "Done. Thanks @Aghassi!", "Done"]}, {"url": "https://github.com/CircleCI-Archived/enterprise-setup/pull/38", "comments": ["Do we have duplicated  updates now?", "Given Nathan'c comments in #release we should probably remove Server and just have CircleCI... cuz... you know... bizdev....", "I thought that we were explicitly supposed to say \"Server\". Im so confused lol. @ndintenfass ?", "Oops. Yeah. ", "I just read his thing. that motivates me. Will change. ", "```\r\n> make docker the default choice for AWS, but that we should also block access to 169.254.169.254 from builds if we do that\r\n```\r\nCan we explain this a little more?  What is meant by make Docker default choice?  Why are we blocking that IP address?\r\n", "Also... have we tested this?"]}, {"url": "https://github.com/CircleCI-Archived/enterprise-setup/pull/37", "comments": ["Shouldn't the description now say \"enabled by default\"?", "true, thanks, fixed"]}, {"url": "https://github.com/CircleCI-Archived/enterprise-setup/pull/29", "comments": ["@christophermancini you should really use https://www.terraform.io/docs/providers/aws/d/iam_policy_document.html\r\n\r\nThey make for much structured Terraform files instead of using templates", "Good to know. I was just trying to clean up the file and moved blocks of strings into templates."]}, {"url": "https://github.com/CircleCI-Archived/enterprise-setup/pull/4", "comments": ["Matches the default at https://github.com/circleci/enterprise-setup/blob/3a3a3a3/terraform.tfvars#L9, let me know if it should be vice-versa.\n", "Matches the current default in https://s3.amazonaws.com/circleci-enterprise/init-builder-0.2.sh\n", "Matches the recommendation in https://circleci.com/docs/enterprise/config/#supported-builder-instance-types\n"]}, {"url": "https://github.com/CircleCI-Archived/enterprise-setup/pull/1", "comments": ["~~~ What's this used for?\n", "I use it to keep state/var-files in for my many test stacks so I don't have to repeatedly stash them.\n"]}]}, {"url": "https://github.com/linuxlsr/azureLearning.git", "pull_requests": []}, {"url": "https://github.com/bh1m2rn/gitlab-environment-toolkit.git", "pull_requests": []}, {"url": "https://github.com/dwp/dataworks-aws-s3-object-tagger.git", "pull_requests": [{"url": "https://github.com/dwp/dataworks-aws-s3-object-tagger/pull/49", "comments": ["`\r\n\"${local.account.management}.${data.terraform_remote_state.aws_ingestion.outputs.vpc.vpc.ecr_dkr_domain_name}/dataworks-s3-object-tagger:${var.image_version.s3-object-tagger[local.environment]}\"\r\n`\r\n\r\ncouldn't you just append the local.environment here instead of having each environment a key"]}, {"url": "https://github.com/dwp/dataworks-aws-s3-object-tagger/pull/39", "comments": ["These should only be deployed where the tests will be carried out, something like:\r\n\r\n```\r\n   count = local.environment == \"development\" || local.environment == \"qa\" ? 1 : 0\r\n```\r\n\r\nRemember that you will need to use the count when this is called elsewhere ie `aws_batch_job_definition.s3_object_tagger_test_ami[0]`", "same as above", "I think we should use a higher `max_retries` in here. Times for AWS Batch can vary wildly depending on availability of compute resources so, what seems fine now may fail for no reason another time. ", "I don't like `max_retries` being amended - it should really be a constant (the maximum number of retries doesn't change) and a count variable used to increment.", "new line needed ", "where has this come from?", "have you checked the terraform hierarchy on the `aws-common-infra` wiki to ensure that this repo can consume this new remote state?"]}, {"url": "https://github.com/dwp/dataworks-aws-s3-object-tagger/pull/34", "comments": ["```suggestion\r\n            OUTPUTS_PREFIX_NAME: uc_feature_object_tagger_data_classification\r\n```\r\n\r\nEach job has the same issue."]}, {"url": "https://github.com/dwp/dataworks-aws-s3-object-tagger/pull/18", "comments": ["Add TF_WORKSPACE here please and remove the one from meta if it's there.", "TF_WORKSPACE to this and the one above please and remove any fallback one in meta", "Don't you need TF_WORKSPACE here and below?", "Don't you need TF_WORKSPACE here and below?", "Don't you need TF_WORKSPACE here and below?", "Don't you need TF_WORKSPACE here and below?", "We should log out the 3 values above too, useful when debugging"]}, {"url": "https://github.com/dwp/dataworks-aws-s3-object-tagger/pull/16", "comments": ["Can you add TF_WORKSPACE to the dev ones as a param with `default` please? Makes it explicit then. Same as job above.", "Missing TF_WORKSPACE param here I think, same with the other jobs.", "```suggestion\r\n              if [[ \"${SUBSYSTEM}\" == \"PDM\" ]];\r\n```", "```suggestion\r\n              elif [[ \"${SUBSYSTEM}\" == \"PaymentTimelines\" ]];\r\n```", "amended"]}, {"url": "https://github.com/dwp/dataworks-aws-s3-object-tagger/pull/2", "comments": ["it will probably read better when referencing if you do this:\r\n```suggestion\r\noutput \"pdm_object_tagger_batch\" {\r\n```"]}, {"url": "https://github.com/dwp/dataworks-aws-s3-object-tagger/pull/1", "comments": ["just for future reference, there is no need to change this, the file is a temporary one, so can be shared between different pipelines", "can you split the bucket operations from the object operations?", "it shouldn't be tagging the files in the config bucket", "can you specify the path? I think it's this:\r\n```suggestion\r\n      \"${data.terraform_remote_state.common.outputs.config_bucket.arn}/component/rbac/*\",\r\n```", "you should have separate meta resources per environment, otherwise they clash if running at the same time", "```suggestion\r\n          - rbac-csv-upload-integration\r\n```", "can you move all params except `AWS_ROLE_ARN` to `utility/meta.yml` and remove from each environment job", "Didn't know that", "```suggestion\r\n          - rbac-csv-upload-production\r\n```", "```suggestion\r\n          - rbac-csv-upload-preprod\r\n```", "I disagree with this. As the path is configurable in the pipeline for the config bucket, this may be changed on the fly.", "```suggestion\r\n          - rbac-csv-upload-qa\r\n```", "probably don't want these two lines", "May need to be configurable per env. If time shows we don't want to differentiate per environment then it's worth moving to meta.", "you will need to raise a change to add the webhook to https://github.com/dwp/dataworks-github-config/blob/master/dataworks-s3-object-tagger.tf", "you still can due to the way spruce layers them. These are the default that go in meta, you then can override for specific environments. Currently, this is much harder to maintain when the file name or path changes", "that container shouldn't have full access to that config bucket", "List has to be on the entire bucket, so I would agree with Dan on splitting the objects stuff.", "I've made the split but the addition of component/rbac/* to the bucket rather than /* will limit the location of the config CSV going forward. It's currently configurable in the pipeline per env", "```suggestion\r\n      data.terraform_remote_state.common.outputs.config_bucket_cmk.arn,\r\n```"]}]}, {"url": "https://github.com/schostin/streamedcon2020-terraform-module-github-actions-gcloud.git", "pull_requests": []}, {"url": "https://github.com/nishantnasa/terragrunt-modules-gcp.git", "pull_requests": []}, {"url": "https://github.com/dankline/waapdemo.git", "pull_requests": []}, {"url": "https://github.com/replicahq/bqutils.git", "pull_requests": []}, {"url": "https://github.com/Katesagay/terraform-repo.git", "pull_requests": []}, {"url": "https://github.com/wellcomecollection/loris-infrastructure.git", "pull_requests": [{"url": "https://github.com/wellcomecollection/loris-infrastructure/pull/8", "comments": ["```suggestion\r\n## How to update our Loris image\r\n```"]}]}, {"url": "https://github.com/pablocraig/mytest.git", "pull_requests": []}, {"url": "https://github.com/sastels/learn-AWS-terraform.git", "pull_requests": []}, {"url": "https://github.com/marshall7m/terraform-aws-landing-zone.git", "pull_requests": []}, {"url": "https://github.com/plainjanetypes/MCJ.git", "pull_requests": []}, {"url": "https://github.com/schramm-famm/bespin.git", "pull_requests": [{"url": "https://github.com/schramm-famm/bespin/pull/9", "comments": ["Will update this once `sprint05` is merged into `master` in `patches`.", "Will update this once `sprint05` is merged into `master` in `me-you`.", "Do androids dream of electric sheep though?", "\u26a1\ud83d\udc11"]}, {"url": "https://github.com/schramm-famm/bespin/pull/3", "comments": ["What's does `name` field dictate? The name of the cluster? If so, what's `\"riht\"`?", "Resource names like `\"riht\"` are exclusively used just within Terraform and don't show up in AWS. You just use them to reference other Terraform resources, so it's kinda like a variable name in a programming language.\r\n\r\nThe `name` field is the actual name of the cluster in Terraform, yeah."]}]}, {"url": "https://github.com/crabsauce/bridgecrew.git", "pull_requests": []}, {"url": "https://github.com/zoitech/terraform-aws-account.git", "pull_requests": [{"url": "https://github.com/zoitech/terraform-aws-account/pull/13", "comments": ["Hi @smelchior \r\n\r\nIs there a reason why the provider version check was changed from 1.6 to 1.54?\r\n\r\nKind regards,\r\nGraham", "Yes, the required resource has been included in that version:\r\nhttps://github.com/terraform-providers/terraform-provider-aws/blob/master/CHANGELOG.md#1540-december-21-2018", "Looks good, strange that we had 1.6 in there..."]}, {"url": "https://github.com/zoitech/terraform-aws-account/pull/4", "comments": ["We should add the Type here.", "Can you please add a var for the Key-Name? It is ok if it defaults to \"Name\", but we for example use lowercase keys which could configured then."]}]}, {"url": "https://github.com/cbChgit/testrepo.git", "pull_requests": []}, {"url": "https://github.com/chandravadrevu/viya4-aws-iac.git", "pull_requests": []}, {"url": "https://github.com/infracost/example-terraform.git", "pull_requests": [{"url": "https://github.com/infracost/example-terraform/pull/1", "comments": ["```suggestion\r\n machine_type = \"n1-standard-32\" # <<<<< Try changing this to XXXX? to compare the costs\r\n```", "`# <<<<< Try changing this to XXX to compare the costs`", "`# <<<<< Try changing this to XXX to compare the costs`"]}]}, {"url": "https://github.com/raddaoui/stackdriver-logging-sinks-splunk-demo.git", "pull_requests": []}, {"url": "https://github.com/skuczynska/images-app-terraform-upskill-PGS.git", "pull_requests": []}, {"url": "https://github.com/EngineerBetter/kf-infra.git", "pull_requests": []}, {"url": "https://github.com/travis-ci/terraform-config.git", "pull_requests": [{"url": "https://github.com/travis-ci/terraform-config/pull/673", "comments": ["I think we should go to the 4 vcpu machine type (`standard-4`)", "Got numbers? :)", "It's what we are using right now. Also, vcpus affect persistent ssd performance. \r\n\r\nWhere in the terraform is the disk information specified?", "Please see: https://github.com/travis-ci/terraform-config/pull/673/commits/103b2316a2c6b45c0e8da1b668aa7a46b8596ad1#diff-aa235652bd9438b116c459b946cdddf6L59\r\n\r\nCommit message explains my reasoning.\r\n\r\nLine 59: calculation for the cache size\r\nLine 151: calculation for the disk size", "I tried to figure out the data on the [performance page](https://cloud.google.com/compute/docs/disks/performance) of Google, let's talk."]}, {"url": "https://github.com/travis-ci/terraform-config/pull/665", "comments": ["As far as I know, we're not yet making use of the `latest` tag, so [`travisci/gcloud-cleanup:latest` on Docker Hub](https://hub.docker.com/r/travisci/gcloud-cleanup/tags) is 6 months old.", "Where is this used?", "It's not used, will remove", "Not sure what to put here, I used `b28c85d` for staging build, but I guess we want to use latest  here. We could push to latest after this merge https://github.com/travis-ci/gcloud-cleanup/pull/53 wdyt?"]}, {"url": "https://github.com/travis-ci/terraform-config/pull/661", "comments": ["I expect this should be `travis-staging-1`, yes?", "It's a trivial thing, but I would like to get away from referencing this directly and instead looking it up as with https://github.com/travis-ci/terraform-config/blob/9ee6c353d33d1589229c719db74f2a41761a6fe0/dns-production-0/main.tf#L45-L47", "I don't see this being used, and I don't expect you will need to pull in the remote state of the same graph that is being built here.", "Is direct-lvm storage helpful in this case? My understanding was that all blob storage was external.", "I think that this is now redundant/outdated given what `tfw` provides by default. See the squignix setup for a more recent example https://github.com/travis-ci/terraform-config/blob/master/modules/gce_squignix/cloud-init.bash", "With this as the body, I would move the `${file(...)}` directly into the template.", "I assume this should not be hardcoded :grin:  Maybe the generated config in `tfw` should account for registry mirrors: https://github.com/travis-ci/tfw/blob/bfbffd80e1ddbcfd13cf58b9fbe435949e810d3a/bin/tfw#L1270-L1288", "Ahhh I was looking all over for this. Thanks", "Where is the docker config being passed to the docker daemon?"]}, {"url": "https://github.com/travis-ci/terraform-config/pull/660", "comments": ["I assume this is a change unrelated to to warmer and just changes made to NAT or `tfw`", "only other nit: why we name this member (and production workers) with `2` while staging  has`1`, given that we are in `gce-production-1`s main.tf?  Any significance? ", "I was getting an image lookup failure and realized that this list was longer than necessary :man_shrugging: ", "This resource only exists in `gce-production-1` and the purpose it to grant cloud images usage access to the _other_ `gce-.+` projects, which is why this resource has this name."]}, {"url": "https://github.com/travis-ci/terraform-config/pull/623", "comments": ["Can you add another output named `host` whose value is something similar to `https://10.182.64.100:6443` but with the name of the master instead of the IP?\r\n\r\nI put a script at `bin/set-k8s-context` which uses the outputs that you've already included, as well as `host`, and creates a context in your local kubeconfig named after the graph directory.\r\n\r\nThe `macstadium-staging` and `macstadium-prod-1-cluster` directories also have this rule in their Makefile:\r\n\r\n```\r\n.PHONY: context\r\ncontext:\r\n\t$(TOP)/bin/set-k8s-context $(ENV_NAME)\r\n```\r\n\r\nSo you can run `make context` from a graph directory for a K8s cluster and then be able to connect to that cluster from then on with kubectl.", "What types of instances are the nodes in this cluster? Might be good to make it explicit, as I'm not sure what the default is.\r\n\r\nMy personal experience is that the nodes should probably be ~4GB RAM VMs. I'm running a personal cluster with 2GB and it is awfully tight on memory, even without much running on it.", "TODO: variablize"]}, {"url": "https://github.com/travis-ci/terraform-config/pull/622", "comments": ["I'm not sure I understand what is happening with this change.", "This means that iff someone runs `make deps` locally that they won't get the \"deployement\" style `bundle install`, which is more correct imho.", "Ahh, okay cool!"]}, {"url": "https://github.com/travis-ci/terraform-config/pull/621", "comments": ["Is there a good reason to not change the language here to `ruby` and get the RVM install behavior for free?", "That's fine by me, too!", "Since it's already merged, I'd say it's up to you if you feel it's worth it."]}, {"url": "https://github.com/travis-ci/terraform-config/pull/605", "comments": ["This could be an issue, since afaik the quota there is still 20 req/s.", "I've submitted a quota increase for this. \ud83e\udd1e "]}, {"url": "https://github.com/travis-ci/terraform-config/pull/604", "comments": ["not a blocker for merge, but more a curiosity on my part, how do we calculate the managed instance count (or pool size math also) for GCE? "]}, {"url": "https://github.com/travis-ci/terraform-config/pull/599", "comments": ["Just curious--what's this about? (In what cases would `docker version` exit higher than `600`?)", "Maybe we could try the CDN magic in the future! (unless there's a reason not to)", "@soulshake Ah, that's the 10m timeout counter comparison, not an exit code check \ud83d\ude01 ", "I'm happy to keep looking into this in the future, yep! I hesitated to glom it onto this work because of the problems associated with cache invalidation. The solution here is extremely simplified and doesn't deal with cache invalidation outside of capping the `tmpfs` size.", "LOL sorry, reading FTW :woman_facepalming: "]}, {"url": "https://github.com/travis-ci/terraform-config/pull/596", "comments": ["\ud83d\ude39 ", "hey what is this ip_base value?  I looked in K8s terraform provider but no luck.  ", "It's the starting point for the IPs we assign to the cluster VMs. So the master will be .100 and the nodes will be .101 and .102 in this case.", "what are all these `0`s  in the interpolation syntax? Attributes as `nil`? ", "The clone and customize sections are represented as arrays, so you have to index into the first item."]}, {"url": "https://github.com/travis-ci/terraform-config/pull/592", "comments": ["any reason for 4 as default?  Just a number to begin with? ", "My thinking was that it's the default `length(var.zones)` :man_shrugging: "]}, {"url": "https://github.com/travis-ci/terraform-config/pull/559", "comments": ["I'd suggest setting this to `\"false\"` as a default, to be a bit more explicit about the expected default behaviour when nothing is specified."]}, {"url": "https://github.com/travis-ci/terraform-config/pull/554", "comments": ["project is hard coded here", "oh, copy-pasta fail! \ud83d\ude05 thank you!"]}, {"url": "https://github.com/travis-ci/terraform-config/pull/537", "comments": ["This file is part of the image-builder and probably doesn't need to be copied over to staging.", "This config isn't needed for staging.", "We can probably take out the \"hopethisworks\" from here. I think it's a weird relic from the struggles of bringing up the MacStadium terraform the first time.", "I think we lost the \"jupiter-brain-staging-com\" entry here.", "I think we should decide how we want the worker version to behave in staging.\r\n\r\nIn the existing configuration, the `travis_worker_version` variable was used for non-staging workers, and `latest_travis_worker_version` was used for staging workers. The latter variable is populated automatically by a script using the most-recent GitHub release of worker.\r\n\r\nIn my experience, while that may be nice for making sure staging is always running a recent worker, it's not really what I wanted and it made things clumsy when I wanted to test a new worker version on staging. I think I would prefer that we remove `latest_travis_worker_version`, and use the explicit `travis_worker_version` here for the staging workers, similar to how production works. This is even more feasible now, since the variable will be distinct for the two environments, so we can easily test a new version in staging.", "\ud83d\udc4d\ud83c\udffb", "\ud83d\udc4d\ud83c\udffb"]}, {"url": "https://github.com/travis-ci/terraform-config/pull/489", "comments": ["Was the `cleaner` vs `cleanup` here intentional?", "I'm a fan!", "Yes, with my thinking being that this is a role as opposed to an identity, but I am happy to make it `cleanup` for consistency, too :+1: "]}, {"url": "https://github.com/travis-ci/terraform-config/pull/475", "comments": ["Is this correct for `aws_asg_org_canary` to use the `aws_cyclist_com` cyclist?", ":clap: ", "good catch!"]}, {"url": "https://github.com/travis-ci/terraform-config/pull/456", "comments": ["I'm having a hard time seeing why this line gets taken out?", "The main reason was to have the default staging ASG run the stable worker release, and run the latest one on the canary ASG only. The intention being to give us a more stable staging env, I'm happy to revert it though if folks think it's more valuable to always run latest, where latest means latest at time of last terraform apply.", "Makes sense! :+1: ", "Do we still need to connect this to cyclist, since it won't be autoscaled?", "Oh, never mind, I just noticed that it's not actually set further down. \ud83d\ude05 ", "Cyclist is still needed to perform a graceful manual scale-in. We will manually bump the desired instances on the ASG. In the case of lowering desired instances (e.g. setting it to 0) we need cyclist to manage the lifecycle hooks, otherwise the instance will be terminated before the jobs are completed, which could impact production jobs running on the instance."]}, {"url": "https://github.com/travis-ci/terraform-config/pull/447", "comments": ["watch out; changing these may break stuff. unless you think stuff is broken because these are incorrect as it stands!", "ah, you're right @emdantrim ... I was attributing these IP ranges to be the cause of why vsphere-monitor doesn't report to librato, but this was a red herring.\r\n\r\n  I will revert (or new commit to undo)."]}, {"url": "https://github.com/travis-ci/terraform-config/pull/444", "comments": ["You're getting container IDs below via `docker ps --all` which will include any `Exited` containers that may be present. Running `docker kill` on such a container will result in an error like:\r\n```\r\n$ docker kill c0606705324d\r\nError response from daemon: Cannot kill container: c0606705324d: Container c0606705324de62755c03ae45e649cb745754607dea39f2e24239f8dbbe6309d is not running\r\n```\r\n\r\nRight?\r\nI figure that might cause some confusion since it will result in the same error message (`failed to kill container name=${cn}`) as if it fails for some other reason. But maybe you're ok with that :)", "```\r\n$ docker inspect --format='{{ .ExecIDs | json }}' $(docker ps -ql)\r\n[\"351c339e17afa8afdebc493e33245923a98ce6c72b998ce427ffb632712b3583\"]\r\n```\r\n\r\nNeat, I didn't know about this! I'm curious what (if anything) we can do with `ExecID`; I'm not finding much documentation on it at first glance. \r\n\r\nIs this a reliable way to distinguish containers that no longer have any business running??", "Yep, it's definitely sloppy, but I mostly don't care (?) :grimacing: ", "My intent here was to use the presence of an `.ExecIDs` array to infer whether or not travis-worker is actively running the job, yep!"]}, {"url": "https://github.com/travis-ci/terraform-config/pull/435", "comments": ["`make test` wants the vsphere variables referenced for the build to pass \u2705 "]}, {"url": "https://github.com/travis-ci/terraform-config/pull/432", "comments": ["Should this `echo`'d message also omit \"greedy\"?"]}, {"url": "https://github.com/travis-ci/terraform-config/pull/431", "comments": ["We should also get this one from the keychain automatically instead of requiring it to be copy pasted to `.env`.", "The version in the error message should match the condition."]}, {"url": "https://github.com/travis-ci/terraform-config/pull/423", "comments": ["FWIW, this is much the same reasoning behind the creation of the `plandiff` target, but I definitely understand how they differ.  I would prefer a slightly longer, more different than `plan` target name.  Maybe \"planblurp\" :sweat_smile: ?"]}, {"url": "https://github.com/travis-ci/terraform-config/pull/422", "comments": ["Instead of parsing `/etc/default/travis-worker`, I would instead recommend:\r\n\r\n``` bash\r\neval \"$(tfw printenv travis-worker || travis-combined-env travis-worker)\"\r\n# then use \"${TRAVIS_WORKER_POOL_SIZE}\"\r\n```"]}, {"url": "https://github.com/travis-ci/terraform-config/pull/418", "comments": ["This default value for subnet should be `192.168.1.1/24`, IIUC :grimacing: ", "Given that the returns from `__find_local_interface` and `__find_local_subnet` are being used multiple times, what do you think about assigning them to local variables?", "Should this line also have `192.168.1.1/24`?"]}, {"url": "https://github.com/travis-ci/terraform-config/pull/416", "comments": ["I don't think crontab filenames can contain dots!", "They sure can't!  I missed these :man_facepalming: Fixed now!", "Any reason not to just use the same filename in both places (i.e. in the repo and on the host)?", "For me, at least, the `.crontab` extension enables syntax highlighting, which I was assuming at least one other person also appreciated :grin: "]}, {"url": "https://github.com/travis-ci/terraform-config/pull/392", "comments": ["I'm pretty sure the space at the beginning of this line should be removed :grin: "]}, {"url": "https://github.com/travis-ci/terraform-config/pull/387", "comments": ["Does this pool need cyclist, or can we run the ASG at a fixed scale?", "I'm pretty sure this should be `\"production\"`.  Did you run into issues with it being that instead of `\"enigma\"`?", "I think that the `aws_az_1*2` modules can be dropped.  Maybe even trim down to a single AZ?", "Yep, the more I look at this, I'm thinking this should be a fixed size ASG neutral or non-existent scaling policies.", "This `null_resource.language_mapping_json` can be removed, as we only use the one generated in `aws-production-2` :+1: ", "I prefer this to be a copy and not a symlink :heart:", "I'm assuming that if we omit a `cyclist` instance, that it will require some code changes in the `aws_asg` module, perhaps as something like `${var.cyclist_instance_count}` which defaults to `1` and may be set to `0`, which is then used as the `count` param value for any cyclist resources.", "Can we do both? I.e. have cyclist, but run at a fixed scale, like in staging?", "If it's a fixed size, meaning there are no scaling policies, then there should be no scaling lifecycle events being published, which means that cyclist is sitting there doing nothing :grin: ", "I was thinking it would be preferable to have a cyclist instance doing nothing (at least at first) than refactoring code so it works without cyclist, especially since we might want scaling at some point.\r\n(This is partially driven by laziness, because I don't know how much work it would be to remove the dependency on cyclist, or to add it back later. And also partially a desire for parity among pools.)"]}, {"url": "https://github.com/travis-ci/terraform-config/pull/376", "comments": ["We've pinned terraform version to v0.9.11 because of the vpshere provider changes in the 0.10+ version change. ", "err. pinned for macstadium \r\n", "Hardcoding the version might conflict with [bin/ensure-terraform](https://github.com/travis-ci/terraform-config/blob/master/bin/ensure-terraform#L13) arch check ? ", "@Lyoness this version pin will only apply to this graph/dir :+1: "]}, {"url": "https://github.com/travis-ci/terraform-config/pull/373", "comments": ["I'm referring to this double backslash", "@Lyoness I tried with only one backslash, but that seems to result in the same behavior as pasted into the PR description unfortunately", "Terraform interpolation how do you even? ", "I guess the more helpful question is:  doe this bash interpolation get passed in and something happens in the terraform run? ", "I _believe_ when there's a double backslash it results in this line being written to (with a single backslash) `/var/lib/cloud/instances/i-0c47183047b05094c/scripts/cloud-init`:\r\n```\r\n      container_labels=\"${container_labels}\\ ${ipv4_label}\"\r\n```\r\nAnd then that gets appended to `/etc/default/travis-worker-local`:\r\n\r\n```\r\n# cat /etc/default/travis-worker-local \r\nexport TRAVIS_WORKER_DOCKER_CONTAINER_LABELS=travis.instance_id:i-0c47183047b05094c\\ travis.ipv4:10.10.9.85\r\n```\r\n\r\n^ _Apparently_ we can't surround with quotes, because they get stripped because of docker's env file format requirements.\r\nI'm not sure why the `\\` ends up as part of the environment variable though :woman_shrugging: \r\nMaybe @meatballhat has an explanation?", "Maybe this would be easier if we switched to the \",\"-delimited \":\"-paired values like I'd thought it was supposed to be :sweat_smile:   I realllllly don't like multiple levels of escaping and I'd much rather avoid it if possible.", "@meatballhat I totally agree. Can we still merge this for now so that container labels are parsed correctly until worker is updated to look for comma-delimited labels?\r\nI can revert immediately once worker is updated!", "Update: I've opened [a PR](https://github.com/travis-ci/worker/pull/445) to address this in worker, and updated this PR to delimit container labels with commas instead of spaces."]}, {"url": "https://github.com/travis-ci/terraform-config/pull/364", "comments": ["Should this be `/etc/cron.d/high-cpu-check-crontab`?", "I would remove this intermediate step of pulling all of the `docker stats` output into a string, given that you already have a `| while read -r cid usage_as_float name` below.", "Inconsistent variable dereferencing syntax `$foo` vs. `${foo}` (the latter is my preference!)  &lt;/nitpickery&gt;", "Likewise here, instead of declaring an `IFS` and slurping the subshell into a string (or, in this case, assuming it can be treated as an iterable), I def prefer using a `report_greedy_containers \"${max_cpu}\" | while read -r greedy_cid; do` :heart: ", "Can this `for` loop and the zero-result check above be changed into a counter so that only the inner `while read -r ...` is needed and the zero result warning can happen afterward?", "Due to the fact that modifications to the variable don't persist outside the `while read` loop, I've removed the counter entirely, as I don't think it's really needed anyway.", ":grin: I don't understand why the two-step of fetching stats and then `echo`'ing stats is needed :heart: \r\n\r\nDoes this not work?\r\n\r\n```\r\ndocker stats --no-stream --format \"{{.Container}} {{.CPUPerc}} {{.Name}}\" | while read -r cid usage_as_float name; do\r\n  usage_as_float=\"${usage_as_float//%/}\"\r\n  # ... and everything else can stay as-is, AFAICT\r\n```", "I'm sorry for not mentioning this earlier, but I think `max_cpu`, `instance_id`, and `instance_ip` should all be declared as `local`.", "Ack, sorry again!  Please declare `level`, `msg`, `date`, and `log_msg` as `local`, too :heart:", "Purely for readability!\r\nOh, and also for the `count` below.", ":thinking: mmmm I'm sorry I'm stuck on this.  Defining a large-ish string variable and then `echo`'ing and, then checking if it's empty to indicate a counter ... It feels pretty brittle to me :confused: \r\n\r\nI understand if you want to get this merged as-is.  I'll stop commenting and get out of the way :heart: "]}, {"url": "https://github.com/travis-ci/terraform-config/pull/362", "comments": ["I think I would feel better about this being an injected variable :grin:, maybe with a default that's an empty string?", "I had a feeling you'd say that :D\r\nComing right up."]}, {"url": "https://github.com/travis-ci/terraform-config/pull/346", "comments": ["I prefer real arrays whenever possible :grin:\r\n\r\n``` bash\r\nreserved_ranges=(\r\n  128.0.0.0/16\r\n)\r\n# ...\r\n  for r in \"${reserved_ranges[@]}\"; do\r\n# ...\r\n```", "`\"${varname}\"` style whenever possible :heart: &lt;/nit&gt;"]}, {"url": "https://github.com/travis-ci/terraform-config/pull/334", "comments": ["var name needs to be declared since we're generating here, right? ", "dope! ", "\ud83d\ude40 \ud83d\udcaf ", "\ud83d\udc4d  ", "Based on the other code in this file, I'm guessing this should contain `${var.index}` and not `$${index}`.", "\u2b06\ufe0f @Lyoness I don't follow \ud83d\ude01   Help!", "The collectd network username is no longer a secret, so does that mean that it should be used directly instead of its' `sha256` value?", "good catch!", "missing quotes here?", "and here?"]}, {"url": "https://github.com/travis-ci/terraform-config/pull/327", "comments": ["Is this change intentionally included here? (just asking because it wasn't mentioned in the description)", "The [docs](https://www.terraform.io/docs/providers/google/r/compute_firewall.html#priority) mention that 0 is the highest priority and 1000 is the default. What are we achieving with this change?", "Do we still need the previous `worker.service` file then or does this replace it? ", "We don't need the previous worker service file on GCE, but it _is_ in use elsewhere \ud83d\udc4d ", "Ah, thank you for bringing this up!  There's a bit in the commit message, but I forgot to update the PR description.  I made this change to reflect more closely the counts of hosts that were running in gce-production-1 at the time.  The majority of gce-production-1 hosts were in a `TERMINATED` state due to actions that I took in late 2017 prior to holiday time code/config freeze.", "This is another one that I addressed via commit comment but forgot to update the PR description \ud83d\ude05.  The documented highest priority of `0` appears to be either untrue or perhaps terraform is doing something special with the zero value such that repeat terraform plans wanted to change the value to `1000`."]}, {"url": "https://github.com/travis-ci/terraform-config/pull/326", "comments": ["Is this `connection` used?", "Same here; is this `connection` used?", "yep! this connection is used by the `macstadium_dhcp` module's `remote-exec`.", "I... think? This is copied from the `macstadium_go_worker` module, and I assumed it was put in there for a good reason. :/", "How? :grin:  I thought `macstadium_dhcp` was having ssh user and host injected as variables.", "I don't see anything using it, so \u2702\ufe0f \ud83c\udf89 !", "Come to think of it, I don't see what this `resource \"null_resource\"` is doing at all \ud83d\ude01 "]}, {"url": "https://github.com/travis-ci/terraform-config/pull/293", "comments": ["I prefer `sudo service haproxy start` \ud83d\ude01 ", "done!"]}, {"url": "https://github.com/travis-ci/terraform-config/pull/288", "comments": ["nitpick: `&>>` to send stderr, too?", "nitpick: `worker_cid` and `cids` should both be declared as locals prior to subshell definition", "Sorry, I didn't explain this well \ud83d\ude05   Shellcheck gets upset about locals defined in-line via subshell due to issues with exit code handling, so splitting up the declarations and assignments is needed, a la:\r\n\r\n``` bash\r\nlocal somefoo\r\nsomefoo=\"$(docker inspect foo --format '{{ .Id }}')\"\r\n```\r\n\r\nThat's what these errors are about, at least: https://travis-ci.org/travis-infrastructure/terraform-config/builds/308032321#L434-L441", "Do you want the metric to have your initials? \ud83d\ude01 ", "No `set -e` / `set -o errexit`?", "I would wrap this subshell in double quotes, if only for clarity about expecting space-separated values."]}, {"url": "https://github.com/travis-ci/terraform-config/pull/278", "comments": ["I see the `pre_implosion_sleep` local var declared here, but used (undeclared) in `__handle_unresponsive_docker` \ud83d\ude15 \r\n\r\nIIRC the point of the previous `sleep \"${post_sleep}\"` was to allow time for `shutdown` to take effect without re-running all these checks immediately, which made sense in the context of `travis-worker` hook scripts, but I can see how it's not necessary here \ud83d\udc4d ", "Good catches :/"]}, {"url": "https://github.com/travis-ci/terraform-config/pull/277", "comments": ["\ud83d\udc4f "]}, {"url": "https://github.com/travis-ci/terraform-config/pull/251", "comments": ["Is the leading `echo` intentional?", "If docker is unresponsive, won't this `docker kill` block?  If the instance is being imploded, I think this line can be safely removed \ud83d\ude3a ", "I wonder if we should add a check to bypass the changes check so that `./runtests` may be used more easily while working on a change \ud83e\udd14 ", "Touche, removed", "Whoops, nice catch", "Instead of checking `$1`, which is also used below for `--env <env-file>`, what about `if [[ \"${*}\" =~ --force ]]; then` to see if `--force` is anywhere in args?", "Why is `KILL_COMMAND` defined here?", "Is this `cat /tmp/logs/mock.log` a leftover from debugging?"]}, {"url": "https://github.com/travis-ci/terraform-config/pull/250", "comments": ["The spaces here seem to make Travis sad."]}, {"url": "https://github.com/travis-ci/terraform-config/pull/243", "comments": ["This makes for a pretty long line, at least for me.  Can we instead do `git log --format='%h' -1`?"]}, {"url": "https://github.com/travis-ci/terraform-config/pull/222", "comments": ["I don't understand the intent here \ud83d\ude15 \r\n\r\nWhen `worker_asg_scale_out_threshold` has a value of `80`, as is the case for one of the ASGs in production, then `${var.worker_asg_scale_out_threshold * -1/3 -1}` gives me `-27.6`.  Does terraform get a different result?  What _should_ it be?", "Something like \"when we're below the threshold, create n instances. When we're at 50% of the threshold, create n * 2 instances.\"\r\nI pushed another commit with less weird torturous math.", "Do the negative interval bounds translate as drops in headroom?  What do the `metric_interval_lower_bound` and `metric_interval_upper_bound` usually look like?", "The bounds are relative to the threshold. So if the threshold is 10, and the lower bound of one action is -4, then that action will execute when the level is above 6.\r\nIf there's an action with an *upper* bound of -4, then it will execute when the level drops _below_ 6.\r\n\r\n(I think.)", "For the threshold `v1.travis.rabbitmq.consumers.staging.builds.ec2.headroom < 8 for 2 minutes`\r\n\r\nThis is what it translates to (when the threshold is 8): \r\n\r\n![step-scaling](https://user-images.githubusercontent.com/1585815/30442527-01b5bca0-997d-11e7-8535-b008954284c0.png)\r\n\r\nIn other words, headroom is below 8 but more than 4? Add 1 instance. Headroom is below 4? Add 2 instances.\r\n\r\nIf the bounds were positive, it would instead look like this:\r\n\r\n![step-scaling](https://user-images.githubusercontent.com/1585815/30442410-9ee70c78-997c-11e7-9ea2-72160fa94fd9.png)\r\n\r\n", "I think I understand better \u2049\ufe0f \ud83d\ude16 "]}, {"url": "https://github.com/travis-ci/terraform-config/pull/210", "comments": ["I want to make sure we still check for undefined variables most of the time.  It's not documented here, but this was my original intent with using different shebangs (yes, a not great decision...).  I would prefer all files to manage individual shellcheck rules locally via comments.", "@meatballhat agreed; I did this as a workaround for the fact that some of the `.sh` files that weren't getting checked before raised `shellcheck` errors that I don't know how to fix.", "Perhaps instead individual SC2154 occurrences could be ignored using the per-file annotations?\r\nhttps://github.com/koalaman/shellcheck/wiki/Ignore#ignoring-one-specific-instance-in-a-file\r\nhttps://github.com/koalaman/shellcheck/wiki/Ignore#ignoring-all-instances-in-a-file-044", "Oh nice!"]}, {"url": "https://github.com/travis-ci/terraform-config/pull/209", "comments": ["This partly fixes #185 fwiw :-)", "Nice catch @edmorley, thanks!\r\n\r\nBtw, I didn't include `/bin/sh` because `git grep` returns exit code 1 if it doesn't find any matches, so the script aborts because of `set -o errexit`. (We could pass `--no-run-if-empty` to `xargs` but it will still fail because of `set -o pipefail`).\r\n\r\nFeel free to share a graceful solution if you're so inclined :)\r\n\r\nEDIT: I just saw your suggestion in #185:\r\n`git grep -El '^#!/.+\\b(bash|sh)\\b'`\r\n\r\nThat's classy indeed; seeing if I can do that real quick. --> [#210]"]}, {"url": "https://github.com/travis-ci/terraform-config/pull/208", "comments": ["I would like this wrapped around into more lines that are shorter :grin:", "`--write-out`  TIL!"]}, {"url": "https://github.com/travis-ci/terraform-config/pull/199", "comments": ["maybe change this to `travis-pro-staging`? that way the arbitrary apps we check follow some sort of pattern."]}, {"url": "https://github.com/travis-ci/terraform-config/pull/175", "comments": ["I'm confused about our current scaling policy being \"simple\" given the terraform docs about `policy_type` \ud83d\ude15 https://www.terraform.io/docs/providers/aws/r/appautoscaling_policy.html#policy_type which indicate we're using `StepScaling` whether or not we specify it.  Sure enough, source says: https://github.com/hashicorp/terraform/blob/5f24491ea6659c50883d85a063f902a22b8c2a50/builtin/providers/aws/resource_aws_appautoscaling_policy.go#L40-L44", "IIUC we need to specify multiple `step_adjustment` blocks in order to take advantage of the stepping, no?  ...which makes sense to me given the AWS blog example and https://www.terraform.io/docs/providers/aws/r/appautoscaling_policy.html#step_adjustment"]}, {"url": "https://github.com/travis-ci/terraform-config/pull/155", "comments": ["This conflicts with custom-5, I think. Looking at the ports below, I think it should be 11?"]}, {"url": "https://github.com/travis-ci/terraform-config/pull/145", "comments": ["This variable isn't defined yet, waiting on https://github.com/travis-ci/vsphere-monitor/issues/7 to get fixed so I have a version to set.", "Same for this -- waiting on https://github.com/travis-ci/vsphere-monitor/issues/7 to be solved first.", "This was fixed in 57e762db192f50aeffc3e0fdc026a6c0ffdfa4ad.", "This was fixed in 57e762db192f50aeffc3e0fdc026a6c0ffdfa4ad."]}, {"url": "https://github.com/travis-ci/terraform-config/pull/128", "comments": ["Shoot, this is going to break on new provisions since that user doesn't exist yet :thinking:", "This has a race condition since other provisioners might create the user between `getent` and `useradd`, but the same code is used elsewhere so I'm not too worried. We could always add some `|| getent passd travis-worker >/dev/null` again after the `useradd` if it becomes a problem."]}, {"url": "https://github.com/travis-ci/terraform-config/pull/124", "comments": ["This might cause issues, since `Makefile`s don't like spaces. Submitting a fix."]}, {"url": "https://github.com/travis-ci/terraform-config/pull/122", "comments": ["fyi, staging-2 was missing here, and prod-1 was renamed to production and moved up"]}, {"url": "https://github.com/travis-ci/terraform-config/pull/116", "comments": ["This should be `common-2` instead of `common-1`", "This (and all the `1-1` and `1-2` etc.) below it should be `2-1`, the first number is the pod.", "I think the custom workers and jupiter brains should be removed for now, since they are currently only in one pod.", "if the -1 is part of the pod, would it make sense to rename `common-1` to `common` in the filenames and such, similar to how it's done with the others?", "fixing!", "fixing!", "this looks strange, @henrikhodne confirm that this is what we want?", "That looks correct to me. `pod-2` (and `pod-1` in the other one) might be better now that we've\"standardized\" on the \"pod\" wording, but with the current wording everywhere this looks right."]}, {"url": "https://github.com/travis-ci/terraform-config/pull/114", "comments": ["Should this also be configurable?", "I'll leave it out for now, we can make it configurable if we get into a situation where some require ssl. Hope that's ok!"]}, {"url": "https://github.com/travis-ci/terraform-config/pull/112", "comments": ["IMO the keychain update behaviour is something we generally want. For testing out different keychain branches I would rather go with the `TRAVIS_SKIP_KEYCHAIN_UPDATE=true` env var.", "I'm only skipping it on the generates _after_ the first one, so both keychains get updated once, but then not again for the remaining files.", "I think that's good for two reasons:\r\n\r\n1. It's faster because it's fewer `git pulls`\r\n1. It makes sure that we only have one commit of keychain for all the configs, instead of currently when it's possible that someone pushes something in the middle of generating all the configs, and we'll have one version for some commits and another for other configs.\r\n\r\n(Also, there's nothing ensuring that we're getting the `master` branch, this still runs fine if you have a branch of keychain checked out, it just makes sure that you have everything that's been pushed to GitHub. You don't even need to push your latest changes, as long as it's committed and the branch exists on the remote)", "ah, missed that detail :) in this case I think it's fine \ud83d\udc4d "]}, {"url": "https://github.com/travis-ci/terraform-config/pull/107", "comments": ["this right here?  the amazing power of terraform.  thing of beauty :heart: ", "is p cool!"]}, {"url": "https://github.com/travis-ci/terraform-config/pull/97", "comments": ["The `<>` can be a `>` here since I don't think we need to read from the file?", "Should we `exit 1` here too to have the binary as a whole still fail?", "looks like the change wasn't detected, but this has been addressed", "Not a bug that was introduced in this PR, but `$@` should be `\"$@\"`, otherwise paths with spaced in them will break.", "@henrikhodne this var is resolved by `make` rather than `bash`, though.  It's `$(ENV_NAME).tfvars`.", "Or did you mean it should be quoted to prevent issues with `$(ENV_NAME).tfvars` having spaces?", "Oh, good point, I missed that this was Make and not bash, :man_facepalming:. Not sure how Make handles `$@` and spaces and all, but since I don't think `$(ENV_NAME)` will have spaces in it(?) then I don't think it's really much of an issue."]}, {"url": "https://github.com/travis-ci/terraform-config/pull/93", "comments": ["This should be `default = \"staging\"`", "This should be `default = 2`", "ah yes, that is a nicer way of doing it. thanks! :)"]}, {"url": "https://github.com/travis-ci/terraform-config/pull/83", "comments": ["TIL this is a thing! nice :)", "Accidentally copypastaed this from Jupiter Brain, `-$INST` should be removed", "Same here, this `-$INST` also needs to be removed", "This entire file should probably be removed\u2026"]}, {"url": "https://github.com/travis-ci/terraform-config/pull/79", "comments": ["Keeping ICMP might be a good idea.", "Any particular reasons? I'd rather have complete isolation. This also mirrors current prod.", "Debugging, and there are several parts of IP that doesn't work very well without ICMP enabled (I don't remember them off the top of my head, but I'll see if I can dig up a link tomorrow).", "@henrikhodne fyi, icmp from outside is allowed."]}, {"url": "https://github.com/travis-ci/terraform-config/pull/75", "comments": ["It's a minor difference, but I'd put this `curl` above the `tee` to `implode.confirm`.", "done!"]}, {"url": "https://github.com/travis-ci/terraform-config/pull/65", "comments": ["how is `var.latest_docker_image_worker` populated?\n", "That comes from `bin/generate-latest-docker-image-tags`.  Previously, this executable generated variables for all of the `ci-*` stack images.\n", "thanks\n"]}, {"url": "https://github.com/travis-ci/terraform-config/pull/55", "comments": ["What is this for?\n", "That's used in the `trvs` commands as the \"environment\" since we have a finer-grained separation of terraform infras than simply staging/production.\n", "Got it, thanks \ud83d\udc4d \n"]}, {"url": "https://github.com/travis-ci/terraform-config/pull/45", "comments": ["ah. I had to look up difference of why `-drop` and not `-reject` :+1: TIL. \n"]}, {"url": "https://github.com/travis-ci/terraform-config/pull/42", "comments": [":tada: \n"]}, {"url": "https://github.com/travis-ci/terraform-config/pull/41", "comments": [":+1: \n", "why do we test for random here? \n", "I'm having the mocked-out executable echo a random string if there is no stub return value present, mostly so that every mocked-out executable _at least_ has some unpredictable output so that I'm less likely to write brittle tests.\n"]}, {"url": "https://github.com/travis-ci/terraform-config/pull/39", "comments": ["what is the purpose of moving this from terraform.mk and doing `+include $(shell git rev-parse --show-toplevel)/terraform-common.mk` in original file? \n", "are the cache bucket's the beginnings of moving off of quay.io for ASGs?  Or just holding state within AWS? \n", "oh no wait, here do we need quay.io to hold the larger `universe` AMIs? \n", "ah ok. so multiple makefiles are being parsed from `terraform.mk` as the top source of ultimate configurable truth :tm: ?  \n", "ah I see the pattern, just trying to suss out the dep graph/structure\n", "There were some bits I wanted to reuse, and others not, so I figured splitting it up was an OK solution :+1:\n", "These cache buckets are used inside the jobs themselves, e.g. `cache: bundler`.  The bucket, key, and secret all used to be injected, and with this change only the bucket is injected while the IAM bits are generated in terraform land.\n", "No change to anything about how we use quay happening here :smile_cat:, promise!\n", "I use different words in my head to describe it, but maybe we're talking about the same thing! :heart:\n", "@meatballhat this is an orphan :3\n", "@meatballhat very githubby!\n", "yayyyy beginnings of granularity :beach_umbrella: \n", ":100: \n"]}, {"url": "https://github.com/travis-ci/terraform-config/pull/38", "comments": ["we always need a $PARANOID env var :heart_decoration: \n"]}, {"url": "https://github.com/travis-ci/terraform-config/pull/33", "comments": ["If we have >1 AZ defined but each AZ's infrastructure is discrete, how can we be sure that we get any particular AZ at any time? or, alternatively, do we not care?\n\nwould we want to have a separate DNS entry for each AZ as well as one overarching DNS entry for if you wanted to hit Any Ol' AZ (which would theoretically be this record)?\n", "I'm guessing by the code from which I'm copying that we mostly don't care, but I also like the idea of pre-AZ records in addition to these.\n", "only reason I can think of that we'd be concerned about having that amount of granularity is if something was going wrong in one AZ but not in another -- but if we were to want to get into a specific bastion host, it'd be a bit of a treasure hunt to find out which IP is which host.\n\nalso, does route53 do reverse dns as well? b/c if that's the case then we could at least depend on reverse dns to be able to get the AZ out of the respective IPs.\n", "For the case of bastions, we only specify per-AZ records :tada:  We'd have to specifically add a `PTR`/`.arpa` record for reverse dns iiuc.\n", "I'm adding per-AZ records for NATs now\n", "ah right bastions are separate from this.\n\nsounds rad, then!\n"]}, {"url": "https://github.com/travis-ci/terraform-config/pull/32", "comments": ["intentional, I guess?\n", "rather, will this make it so that a whole instance needs to start up before a staging build can be run?\n", "same question as before\n", "for clarification -- we're putting \"cidr\" instead of just \"subnet\" to be 100% explicit that we're not talking about the subnet ID, right?\n", "Yep!\n", "In reality the ASG will have at least one instance spin up automatically because of the scaling rules, but having a minimum of 0 allows us to set the desired capacity to 0 without modifying the ASG, which is something we need to do when tearing down the entire VPC.\n"]}, {"url": "https://github.com/travis-ci/terraform-config/pull/30", "comments": ["I figured pinning to az 1b was acceptable :shrug:\n", "Would it be useful to also specify that it's this script that generated the file?\n"]}, {"url": "https://github.com/travis-ci/terraform-config/pull/28", "comments": ["Is the intention to have this spin up a whole new VPC and \"disconnect\" from our existing production one, since the IP range changed?\n", "Yes.  The intent here is to build out this infrastructure rooted at a different VPC.\n"]}, {"url": "https://github.com/travis-ci/terraform-config/pull/2", "comments": ["`-module-depth=-1` is the default\n"]}]}, {"url": "https://github.com/bhavikkumar/terraform-master.git", "pull_requests": []}, {"url": "https://github.com/KoutaroNohira/hashicat.git", "pull_requests": []}, {"url": "https://github.com/robinbryce/iona.git", "pull_requests": []}, {"url": "https://github.com/shikharms/Terraform-on-Google-Cloud.git", "pull_requests": []}, {"url": "https://github.com/techservicesillinois/aws-enterprise-vpc.git", "pull_requests": []}, {"url": "https://github.com/wallnerryan/terraform-scaleio.git", "pull_requests": []}, {"url": "https://github.com/tedilabs/terraform-aws-account.git", "pull_requests": []}, {"url": "https://github.com/dstine/sites.git", "pull_requests": []}, {"url": "https://github.com/cloudposse/terraform-aws-alb.git", "pull_requests": [{"url": "https://github.com/cloudposse/terraform-aws-alb/pull/142", "comments": ["<details><summary>\n<img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low_new.svg\" alt=\"LOW\" width=\"24px\" align=\"center\">&nbsp;&nbsp;<b style=\"color:black\" >Ensure ALB redirects HTTP requests into HTTPS ones</b>\n            <br>\n            &nbsp;&nbsp;&nbsp;&nbsp;Resource: <a href=\"https://github.com/cloudposse/terraform-aws-alb/blob/aws_v5/main.tf#L72-L99\">module.alb.aws_lb.default</a> | Bridgecrew ID: <code>BC_AWS_NETWORKING_49</code> | Checkov ID: <a href=\"https://docs.bridgecrew.io/docs/ensure-that-alb-redirects-http-requests-into-https-ones\">CKV2_AWS_20</a>\n            <br>\n            \n</summary>\n<h4>How to Fix</h4>\n\n```tf\n\nresource \"aws_lb\" \"lb_good\" {\n}\n\n\nresource \"aws_lb_listener\" \"listener_good\" {\n  load_balancer_arn = aws_lb.lb_good.arn\n  port              = \"80\"\n  protocol          = \"HTTP\"\n\n  default_action {\n    type = \"redirect\"\n\n    redirect {\n      port        = \"443\"\n      protocol    = \"HTTPS\"\n      status_code = \"HTTP_301\"\n    }\n\n  }\n}\n\n\n```\n\n<h4>Description</h4>\nEnsure that the behaviour of the Load balancer is redirect any traffic from the encrypted endpoint rather than handling on http or failing to respond.\n\n</details>", "<details><summary>\n<img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low_new.svg\" alt=\"LOW\" width=\"24px\" align=\"center\">&nbsp;&nbsp;<b style=\"color:black\" >Ensure every Security Group rule has a description</b>\n            <br>\n            &nbsp;&nbsp;&nbsp;&nbsp;Resource: <a href=\"https://github.com/cloudposse/terraform-aws-alb/blob/aws_v5/main.tf#L9-L17\">module.alb.aws_security_group_rule.egress</a> | Bridgecrew ID: <code>BC_AWS_NETWORKING_31</code> | Checkov ID: <a href=\"https://docs.bridgecrew.io/docs/networking_31\">CKV_AWS_23</a>\n            <br>\n            \n</summary>\n<h4>How to Fix</h4>\n\n```tf\nresource \"aws_security_group\" \"examplea\" {\n  name        = var.es_domain\n  description = \"Allow inbound traffic to ElasticSearch from VPC CIDR\"\n  vpc_id      = var.vpc\n\n\n  ingress {\n    cidr_blocks = [\"10.0.0.0/16\"]\n   + description = \"What does this rule enable\"\n    from_port   = 80\n    protocol    = \"tcp\"\n    to_port     = 80\n  }\n}\n```\n\n<h4>Description</h4>\nDescriptions can be up to 255 characters long and can be set and viewed from the AWS Management Console, AWS Command Line Interface (CLI), and the AWS APIs.\n\nWe recommend you add descriptive text to each of your Security Group Rules clarifying each rule's goals, this helps prevent developer errors.  \n\n<h4>Benchmarks</h4>\n<ul>\n<li>ISO27001 A.10.1.1</li>\n<li>SOC2 CC6.3.3</li>\n</ul>\n\n</details>\n<div>&nbsp;&nbsp;&nbsp;&nbsp; :tada: &nbsp; <b>Fixed</b> by commit 1a3cd8c1ed8d1c36981e38568ccb8126e192b567 - bump logs</div>", "<details><summary>\n<img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low_new.svg\" alt=\"LOW\" width=\"24px\" align=\"center\">&nbsp;&nbsp;<b style=\"color:black\" >Ensure every Security Group rule has a description</b>\n            <br>\n            &nbsp;&nbsp;&nbsp;&nbsp;Resource: <a href=\"https://github.com/cloudposse/terraform-aws-alb/blob/aws_v5/main.tf#L30-L39\">module.alb.aws_security_group_rule.https_ingress</a> | Bridgecrew ID: <code>BC_AWS_NETWORKING_31</code> | Checkov ID: <a href=\"https://docs.bridgecrew.io/docs/networking_31\">CKV_AWS_23</a>\n            <br>\n            \n</summary>\n<h4>How to Fix</h4>\n\n```tf\nresource \"aws_security_group\" \"examplea\" {\n  name        = var.es_domain\n  description = \"Allow inbound traffic to ElasticSearch from VPC CIDR\"\n  vpc_id      = var.vpc\n\n\n  ingress {\n    cidr_blocks = [\"10.0.0.0/16\"]\n   + description = \"What does this rule enable\"\n    from_port   = 80\n    protocol    = \"tcp\"\n    to_port     = 80\n  }\n}\n```\n\n<h4>Description</h4>\nDescriptions can be up to 255 characters long and can be set and viewed from the AWS Management Console, AWS Command Line Interface (CLI), and the AWS APIs.\n\nWe recommend you add descriptive text to each of your Security Group Rules clarifying each rule's goals, this helps prevent developer errors.  \n\n<h4>Benchmarks</h4>\n<ul>\n<li>ISO27001 A.10.1.1</li>\n<li>SOC2 CC6.3.3</li>\n</ul>\n\n</details>\n<div>&nbsp;&nbsp;&nbsp;&nbsp; :tada: &nbsp; <b>Fixed</b> by commit 1a3cd8c1ed8d1c36981e38568ccb8126e192b567 - bump logs</div>", "<details><summary>\n<img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low_new.svg\" alt=\"LOW\" width=\"24px\" align=\"center\">&nbsp;&nbsp;<b style=\"color:black\" >Ensure every Security Group rule has a description</b>\n            <br>\n            &nbsp;&nbsp;&nbsp;&nbsp;Resource: <a href=\"https://github.com/cloudposse/terraform-aws-alb/blob/aws_v5/main.tf#L19-L28\">module.alb.aws_security_group_rule.http_ingress</a> | Bridgecrew ID: <code>BC_AWS_NETWORKING_31</code> | Checkov ID: <a href=\"https://docs.bridgecrew.io/docs/networking_31\">CKV_AWS_23</a>\n            <br>\n            \n</summary>\n<h4>How to Fix</h4>\n\n```tf\nresource \"aws_security_group\" \"examplea\" {\n  name        = var.es_domain\n  description = \"Allow inbound traffic to ElasticSearch from VPC CIDR\"\n  vpc_id      = var.vpc\n\n\n  ingress {\n    cidr_blocks = [\"10.0.0.0/16\"]\n   + description = \"What does this rule enable\"\n    from_port   = 80\n    protocol    = \"tcp\"\n    to_port     = 80\n  }\n}\n```\n\n<h4>Description</h4>\nDescriptions can be up to 255 characters long and can be set and viewed from the AWS Management Console, AWS Command Line Interface (CLI), and the AWS APIs.\n\nWe recommend you add descriptive text to each of your Security Group Rules clarifying each rule's goals, this helps prevent developer errors.  \n\n<h4>Benchmarks</h4>\n<ul>\n<li>ISO27001 A.10.1.1</li>\n<li>SOC2 CC6.3.3</li>\n</ul>\n\n</details>\n<div>&nbsp;&nbsp;&nbsp;&nbsp; :tada: &nbsp; <b>Fixed</b> by commit 1a3cd8c1ed8d1c36981e38568ccb8126e192b567 - bump logs</div>", "**[terraform fmt -recursive]** <sub>reported by [reviewdog](https://github.com/reviewdog/reviewdog) :dog:</sub><br>\n```suggestion\n  source                  = \"cloudposse/vpc/aws\"\n  version                 = \"2.1.0\"\n```\n", "**[terraform fmt -recursive]** <sub>reported by [reviewdog](https://github.com/reviewdog/reviewdog) :dog:</sub><br>\n```suggestion\n  context                 = module.this.context\n```\n", "<details><summary>\n<img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low_new.svg\" alt=\"LOW\" width=\"24px\" align=\"center\">&nbsp;&nbsp;<b style=\"color:black\" >Ensure every Security Group rule has a description</b>\n            <br>\n            &nbsp;&nbsp;&nbsp;&nbsp;Resource: <a href=\"https://github.com/cloudposse/terraform-aws-alb/blob/aws_v5/main.tf#L30-L39\">module.alb.aws_security_group_rule.https_ingress[0]</a> | Bridgecrew ID: <code>BC_AWS_NETWORKING_31</code> | Checkov ID: <a href=\"https://docs.bridgecrew.io/docs/networking_31\">CKV_AWS_23</a>\n            <br>\n            \n</summary>\n<h4>How to Fix</h4>\n\n```tf\nresource \"aws_security_group\" \"examplea\" {\n  name        = var.es_domain\n  description = \"Allow inbound traffic to ElasticSearch from VPC CIDR\"\n  vpc_id      = var.vpc\n\n\n  ingress {\n    cidr_blocks = [\"10.0.0.0/16\"]\n   + description = \"What does this rule enable\"\n    from_port   = 80\n    protocol    = \"tcp\"\n    to_port     = 80\n  }\n}\n```\n\n<h4>Description</h4>\nDescriptions can be up to 255 characters long and can be set and viewed from the AWS Management Console, AWS Command Line Interface (CLI), and the AWS APIs.\n\nWe recommend you add descriptive text to each of your Security Group Rules clarifying each rule's goals, this helps prevent developer errors.  \n\n<h4>Benchmarks</h4>\n<ul>\n<li>ISO27001 A.10.1.1</li>\n<li>SOC2 CC6.3.3</li>\n</ul>\n\n</details>\n<div>&nbsp;&nbsp;&nbsp;&nbsp; :tada: &nbsp; <b>Fixed</b> by commit 3fd064e1427967e9b1167c747464bad9596c2842 - bump logs</div>"]}, {"url": "https://github.com/cloudposse/terraform-aws-alb/pull/140", "comments": ["Huh this is beyond the scope of your PR, but noting for myself and any fellow contributors: I'm not even sure why we need to have two of these resources for http_forward + http_redirect. It seems we could just do the conditional logic In the default action itself without requiring two resources. \r\n\r\n@joe-niland do you happen to know the history behind why it was done this way?", "@jbrt for all of these lint errors, you do want to use brackets instead of `.*.` as that is the preferred way of using that operator. ", "@Gowiem sorry I missed this one! I don't know why but it dates back to the initial implementation I think. I agree it could be refactored as you described.", "@joe-niland I'll create an issue and we can see if a passer by wants to pick it up!"]}, {"url": "https://github.com/cloudposse/terraform-aws-alb/pull/124", "comments": ["```suggestion\r\n  description = \"Indicates whether the Application Load Balancer should preserve the Host header in the HTTP request and send it to the target without any change.\"\r\n```", "@nitrocode done"]}, {"url": "https://github.com/cloudposse/terraform-aws-alb/pull/108", "comments": ["```suggestion\r\n  description = \"Whether the default target group should be created or not.\"\r\n```", "updated"]}, {"url": "https://github.com/cloudposse/terraform-aws-alb/pull/107", "comments": ["<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure ALB redirects HTTP requests into HTTPS ones</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource: <a href=\"https://github.com/cloudposse/terraform-aws-alb/blob/remove-access-logs/main.tf#L48-L74\">aws_lb.default</a>  |  ID: <code>BC_AWS_NETWORKING_49</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```tf\n\nresource \"aws_lb\" \"lb_good\" {\n}\n\n\nresource \"aws_lb_listener\" \"listener_good\" {\n  load_balancer_arn = aws_lb.lb_good.arn\n  port              = \"80\"\n  protocol          = \"HTTP\"\n\n  default_action {\n    type = \"redirect\"\n\n    redirect {\n      port        = \"443\"\n      protocol    = \"HTTPS\"\n      status_code = \"HTTP_301\"\n    }\n\n  }\n}\n\n\n```\n\n<h4>Description</h4>\nTBA\n\n<b>Dependent Resources</b>\n<br>\n<br>\n<table>\n<tr><th>Path</th> <th>Resource</th> <th>Connecting Attribute</th></tr>\n<tr><td>/main.tf</td> <td>aws_lb_listener.http_forward</td> <td>load_balancer_arn</td></tr>\n<tr><td>/main.tf</td> <td>aws_lb_listener.http_redirect</td> <td>load_balancer_arn</td></tr>\n<tr><td>/main.tf</td> <td>aws_lb_listener.https</td> <td>load_balancer_arn</td></tr>\n</table>\n</details>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/medium.svg\" alt=\"MEDIUM\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure public facing ALB are protected by AWS Web Application Firewall v2 (AWS WAFv2)</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource: <a href=\"https://github.com/cloudposse/terraform-aws-alb/blob/remove-access-logs/main.tf#L48-L74\">aws_lb.default</a>  |  ID: <code>BC_AWS_NETWORKING_58</code>\n            <br></summary>\n<h4>Description</h4>\nTBD\n<b>Dependent Resources</b>\n<br>\n<br>\n<table>\n<tr><th>Path</th> <th>Resource</th> <th>Connecting Attribute</th></tr>\n<tr><td>/main.tf</td> <td>aws_lb_listener.http_forward</td> <td>load_balancer_arn</td></tr>\n<tr><td>/main.tf</td> <td>aws_lb_listener.http_redirect</td> <td>load_balancer_arn</td></tr>\n<tr><td>/main.tf</td> <td>aws_lb_listener.https</td> <td>load_balancer_arn</td></tr>\n</table>\n</details>"]}, {"url": "https://github.com/cloudposse/terraform-aws-alb/pull/104", "comments": ["So this doesn't show a change to people's resources, it might be better to default this to `null`\r\n\r\n```suggestion\r\n  default     = null\r\n```"]}, {"url": "https://github.com/cloudposse/terraform-aws-alb/pull/96", "comments": ["<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure that ALB redirects HTTP requests into HTTPS ones</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource: <a href=\"https://github.com/cloudposse/terraform-aws-alb/blob/max_length/main.tf#L64-L90\">aws_lb.default</a>  |  ID: <code>BC_AWS_NETWORKING_49</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```tf\n\nresource \"aws_lb\" \"lb_good\" {\n}\n\n\nresource \"aws_lb_listener\" \"listener_good\" {\n  load_balancer_arn = aws_lb.lb_good.arn\n  port              = \"80\"\n  protocol          = \"HTTP\"\n\n  default_action {\n    type = \"redirect\"\n\n    redirect {\n      port        = \"443\"\n      protocol    = \"HTTPS\"\n      status_code = \"HTTP_301\"\n    }\n\n  }\n}\n\n\n```\n\n<h4>Description</h4>\nTBA\n\n<b>Dependent Resources</b>\n<br>\n<br>\n<table>\n<tr><th>Path</th> <th>Resource</th> <th>Connecting Attribute</th></tr>\n<tr><td>/main.tf</td> <td>aws_lb_listener.http_forward</td> <td>load_balancer_arn</td></tr>\n<tr><td>/main.tf</td> <td>aws_lb_listener.http_redirect</td> <td>load_balancer_arn</td></tr>\n<tr><td>/main.tf</td> <td>aws_lb_listener.https</td> <td>load_balancer_arn</td></tr>\n</table>\n</details>", "why do you need to `substr` if when the length is set the label.id will be of the required length?", "The substr is on the target group name which is used to override the label id", "got it thanks"]}, {"url": "https://github.com/cloudposse/terraform-aws-alb/pull/92", "comments": ["```suggestion\r\n  description = \"A list of Security Group IDs to associate with the ALB.\"\r\n```", "```suggestion\r\n  description = \"Whether to create default Security Group for the ALB.\"\r\n```\r\n\r\n"]}, {"url": "https://github.com/cloudposse/terraform-aws-alb/pull/86", "comments": ["@jwstric2 since you added the `context` argument, can you remove the `name`, `namespace`, `stage`, `environment`, `delimiter`, and `tags`? `context` will replace all those values so they're not needed. Obviously, let's keep `attributes`. ", "will do, I forgot to ask if those should be removed when opening up this PR."]}, {"url": "https://github.com/cloudposse/terraform-aws-alb/pull/83", "comments": ["```suggestion\r\n  default     = null\r\n```", "no reasons to add `count` you can just extend condition in the `enabled` ", "GitHub doesn't allow me to comment on line 83 of this file, but that will have to be changed from:\r\n```\r\nbucket = module.access_logs.bucket_id\r\n```\r\nTo:\r\n```\r\nbucket = coalesce(var.access_logs_s3_bucket_id, module.access_logs.bucket_id)\r\n```"]}, {"url": "https://github.com/cloudposse/terraform-aws-alb/pull/68", "comments": ["```suggestion\r\n  version    = \"0.18.2\"\r\n```", "```suggestion\r\n  version              = \"0.34.0\"\r\n```"]}, {"url": "https://github.com/cloudposse/terraform-aws-alb/pull/67", "comments": ["```suggestion\r\n  source     = \"cloudposse/label/null\"\r\n```\r\n\r\nFor `terraform-null-label` module, the provider is `null`\r\n"]}, {"url": "https://github.com/cloudposse/terraform-aws-alb/pull/59", "comments": ["```suggestion\r\n  required_version = \">= 0.12.0\"\r\n```\r\n\r\n@MartinCanovas please also remove the upper limit for TF version, we don't do it anymore", "@aknysh upper limit removed."]}, {"url": "https://github.com/cloudposse/terraform-aws-alb/pull/29", "comments": ["why not provide your custom tags in `var.tags`?\r\nThose will be merged in `label` module with the  a few tags generated by the `label` module.\r\n(unless you want a completely separate set of tags. What's the use case?)\r\n", ">why not provide your custom tags in var.tags?\r\n\r\nThe custom tags are specific to the particular target group and would not make sense being applied to the ALB resource. In my particular case, I want to use a terraform data source to find a target group by a tag specific to the particular kind of workload that will be registered with that target group. Perhaps a compromise might be renaming this `target_group_additional_tags` and merging whatever is passed in with the label tags?", "yes, add `target_group_additional_tags` variable, then merge it with `label.tags` (not `var.tags`, those are included in the `label.tags` - and use the resulting map for the target group tags", ">add target_group_additional_tags variable, then merge it with label.tags \r\n\r\ndone d5c7a49 "]}, {"url": "https://github.com/cloudposse/terraform-aws-alb/pull/28", "comments": ["why downgrade?", "was this tested?\r\nTF 0.11 had issues when you don't specify `[]` for lists even if the provided var is a list itself", "why downgrade?", "why not use the var?", "add description"]}, {"url": "https://github.com/cloudposse/terraform-aws-alb/pull/3", "comments": ["use explicit comparison: `var.http_enabled == \"true\"`", "make sure `http_enabled` is a string. boolean variables in TF are not recommended by terraform."]}, {"url": "https://github.com/cloudposse/terraform-aws-alb/pull/2", "comments": ["https://github.com/cloudposse/terraform-aws-alb/issues"]}, {"url": "https://github.com/cloudposse/terraform-aws-alb/pull/1", "comments": ["\"${aws_lb.default.arn}\" ?", "this will return a list type.\r\nlet's use `splat+join` pattern to return a single value:\r\n\"${join(\"\", aws_lb_listener.https.*.arn)}\" ", "why do we need this output if we have `http_listener_arn`?", "`access_logs_bucket_id`", "this var not used", "add description to all vars", "Add slack url\r\n", "The ID of the zone in which ALB is provisioned", "I think we are moving to this format:\r\n\r\nReview the [docs](https://docs.cloudposse.com/), ask a [question](https://docs.cloudposse.com/discuss-new), file a GitHub [issue](https://github.com/cloudposse/terraform-aws-ssm-iam-role/issues), send us an [email](mailto:hello@cloudposse.com) or reach out to us on [Slack](https://slack.cloudposse.com).\r\n"]}]}, {"url": "https://github.com/byu-oit/terraform-aws-rds.git", "pull_requests": [{"url": "https://github.com/byu-oit/terraform-aws-rds/pull/31", "comments": ["(nit) can you just use the check as the boolean?\r\n```suggestion\r\n  performance_insights_enabled          = var.performance_insights != null # If the object exists then turn on\r\n```"]}, {"url": "https://github.com/byu-oit/terraform-aws-rds/pull/12", "comments": ["Did this change for a reason?", "Yeah when I tried to apply the Terraform in my own tests, it didn't allow `audit`. I assumed that it was something that changed with the provider, it may be nice if someone else could verify my results.", "```Error creating DB Instance: InvalidParameterCombination: You cannot use the log types 'audit' with engine version mysql 8.0.17. For supported log types, see the documentation.```"]}, {"url": "https://github.com/byu-oit/terraform-aws-rds/pull/10", "comments": ["There wasn't a good way to deduce what the database/engine family because the version might have more than 2 digits. I guess we could try to construct it, but it the constructed family might not exist. Thoughts?"]}, {"url": "https://github.com/byu-oit/terraform-aws-rds/pull/6", "comments": ["Maybe add the format of this variable like you defined in maintenance_window below?", "I just stole these descriptions from the Terraform docs here: https://www.terraform.io/docs/providers/aws/r/db_instance.html#backup_retention_period.", "Done"]}, {"url": "https://github.com/byu-oit/terraform-aws-rds/pull/4", "comments": ["change the docs and example to use the next version. so maybe in this case a `v0.2.1` or something like that", "change the version to v0.2.1 or something like that (and change the version in the other example)", "(nit) I usually don't include the optional parameters here in the usage section, but I'm fine either way", "You mean for cloudwatch_logs_exports? I put that in because the default didn't work with MySQL 8.0.11. Terraform just said that 'audit' logs don't work with MySQL 8.0.11.", "Will do.", "Interesting. We'll have to look into this, but for now this should be fine."]}, {"url": "https://github.com/byu-oit/terraform-aws-rds/pull/3", "comments": ["Can we have the example set `deletion_protection` to true?", "done. I initially had it set to false so I could delete my examples after testing the module. By default the deletion_protection variable is set to true"]}]}, {"url": "https://github.com/language-learners/terraform.git", "pull_requests": []}, {"url": "https://github.com/akaron/kubeadm_aws.git", "pull_requests": []}, {"url": "https://github.com/ryte/INF-tf-waf.git", "pull_requests": [{"url": "https://github.com/ryte/INF-tf-waf/pull/11", "comments": ["Please fix the indentation manually until we have a pre-commit hook implemented for this repo", "same here", "updated the changes.\r\nThanks for noticing", "```suggestion\r\nlocals {\r\n```", "```suggestion\r\n- `allowed_headers`\r\n```", "That's not correct. It's a `list`\r\n```suggestion\r\n  type = list(map(string))\r\n```", "See comment in `variables.tf`", "You can't use `id` in the `predicate` when using count. You have to use `data_id = aws_wafregional_byte_match_set.url_match[count.index].id`\r\n\r\nYou'll also have to update the `outputs.tf` to\r\n```hcl\r\noutput \"id\" {\r\n  value = length(var.allowed_headers) >= 1 ? aws_wafregional_rate_based_rule.url_match_rule[0].id : \"\"\r\n}\r\n```", "Why did you add this? The tags should be passed into the module. Otherwise it will always be `squad = inf, env = dev` no matter who uses it", "Did you add this to the repo by accident?"]}]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules.git", "pull_requests": [{"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/373", "comments": ["maybe this would look better :) \n\n```suggestion\n      disk_name = \"panorama-os-disk\"\n```", "I think we should actually do an example with a logging disk. ", "missing documentation ", "since it turned out we cannot use admonitions, I've started to use a notation like this:\n\n```suggestion\n  **Important!** \\\n```\n\nand of course you need to get rid of the following quote marks `>`", "same here", "since we can use both, this validation does not make sense\n\nwe can on the other hand have a situation where both are empty, I think we should check that instead", "proximity placement group should go away as per discussion with Migara", "since this exceeds 130 columns, you can brake it to something like this:\n\n```suggestion\n    condition = alltrue([\n      for _, v in var.logging_disks : (parseint(v.lun, 10) >= 0 && parseint(v.lun, 10) <= 63) if v.lun != null\n    ])\n```", "maybe to simplify the code we could change this to \n\n\n```suggestion\n    condition     = alltrue([for _, v in var.logging_disks : contains(range(2048, 24577, 2048), v.size)])\n```", "same here, over 130 columns", "over 130 columns", "I think it makes the job. Either password must not be null or SSH key must be longer than 0 characters. If both are true, it also passes the validation. If none of them is true, validation fails."]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/372", "comments": ["So when HTTP or HTTPS protocols are used, protocol's default port is used and `port` property can be set to `null` right?", "Lack of description for this property.", "Typo in word \"endpoint\".", "Shouldn't we set default values for numeric properties to whatever is Azure's recommendation?", "Shouldn't the `name` property be required and we can move the default name generation logic to the example? As we did for all other modules.", "We use different indentation for nested maps descriptions, see `vmseries` or `panorama` modules for reference.", "Do you think this map key name is intuitive, maybe we should change it?", "What about making the entire object optional and changing the `name` property to required? Because I suppose that if someone wants to create a rule, it needs to have a name.", "As mentioned inside the variables file, I'd prefer to move name generation logic to the example.", "Ahh, now I see why this property was optional inside the variables file. Such name generation probably complies with our approach, perhaps to be discussed?", "This admonition will not show properly, use this instead (like in `panorama` code for example):\r\n`**Note!** \\`", "As discussed on Slack, entire example code to be discussed on call once you're back.", "yes, right. \r\nNevertheless I set `port` as required. Do you have proposition for better approach in that case?", "Added.", "Fixed.", "I missed that, but I fixed it.", "Right, fixed.", "I don't recall , that we agreed rules for nested maps, but nevertheless I don't see nested maps in `panorama` module - could you please put me URL to example of standard, which I should follow ? ", "For me it is intuitive, but if you prefer different one, what name I should use? ", "We cannot use `optional` for object - here is the error:\r\n\r\n```\r\nInvalid type specification: Keyword \"optional\" is valid only as a modifier for object type attributes.\r\n```\r\n\r\nFrankly speaking I've done it by purpose as we have always 1 rule , which is required - name is not very important here, so it's optional. I propose to leave it as it is - do you agree?", "Let's discuss this in next week (the same argument in 1 comment before).", "Yes, let's discuss it.", "Yes, let's discuss it in next week.", "Fixed.", "While TCP is the default, I think that's the best approach.", "Take a look at `autoscaling_profiles` variable in [vmss module](https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/blob/307-refactor-modules/modules/vmss/variables.tf).", "You set both internal and external tunnel interfaces inside this map, that's why word `ext` concerns me. Perhaps we could change name `ext_int` to just `backend`?", "So you are able to create a rule without a name, correct?", "follow the 130 columns limit", "this notation is less error prone when doing conversions from MD to MDX/Docusaurus \n\n````suggestion\n  ```bash\n  terraform plan\n  ```\n````", "130 columns limit", "missing type definition", "wasn't the lower limit supposed to be `1.5` ?", "Please follow the MD conventions, new line before a list", "can't we have this set up like in the regular [LB](https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/blob/a63213f80532ba637c7d785f53d70c642a0ee59a/modules/loadbalancer/variables.tf#L338)?\n- name - required, as in modules we do not autogenerate anything\n- protocol - required, you take the decision what kind of protocol you want to use\n- port - optional when HTTP(s) is used, then it defaults to protocol's port, required for TCP -> this logic can be handled in validation blocks", "I would also keep this the same as in LB module -> use Azure defaults", "do not use your own defaults, unless Azure ones do not make sense in our deployments -> less maintenance", "if we can only have two backends, I would add a validation for that", "but the description is still wrong", "should we have a default value here? shouldn't it be moved to examples? In other words, is this default value specific to this module? or maybe to the examples?", "I would add here a list of available options, or a link to external documentation (tf provider or azure) where that list can be found.\n\nthat's a general comment, for all variables add accept a finite list of arguments", "no, you cannot, according to provider's documentation, `name` [is required](https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs/resources/lb_rule#name)\n\nif we want to have this as optional i would suggest something like this\n\n```hcl\ndefault = null\nnullable = true\ntype = object({\n  name = string\n  load_distribution = optional(string, \"Default\")\n})\n```\n\nThis would require minor changes in the code to handle `null`", "please bump tf trequirements to min = 1.5 and provider to min 3.80", "I removed `If not specified name is generated from `name` variable and backend key.`, thanks", "Thanks, I adjusted nested maps indentation .", "Ok, I replaced `ext-int` by `backend`.", "no, I was not creating a rule without name - in case name was not provided, I used:\r\n\r\n`name = coalesce(var.lb_rule.name, azurerm_lb.this.frontend_ip_configuration[0].name)`\r\n\r\nNevertheless I changed `name` into required to have the same approach for naming as for other resources.", "I've made `name` as required, name generation logic is moved to the example.", "I've made `name` as required, name generation logic is moved to the example.", "Fixed", "Fixed", "Fixed", "I removed default value for `protocol`, but I don't think that for LB we are following Azure defaults e.g.\r\n- [interval_in_seconds](https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs/resources/lb_probe#interval_in_seconds) have default value 15, but in LB it's missed https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/blob/ad1c4d7ff2cad59a59cb1fe3bf820e65a2586b88/modules/loadbalancer/variables.tf#L357\r\n- [protocol](https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs/resources/lb_probe#protocol) is optional, not required as in https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/blob/ad1c4d7ff2cad59a59cb1fe3bf820e65a2586b88/modules/loadbalancer/variables.tf#L354", "Added", "I added default value for variable `backends` to have it as it's described in https://docs.paloaltonetworks.com/vm-series/10-2/vm-series-deployment/set-up-the-vm-series-firewall-on-azure/deploy-the-vm-series-firewall-with-the-azure-gwlb, but if you don't agree with that approach, I can remove it - can we discuss it on the meeting ?", "done", "Done ", "Done", "Example is going to be delivered in new PR.", "Example is going to be delivered in new PR."]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/371", "comments": ["You're not using this property in main.tf, any reason?", "Same about this one - you're not using this property in main.tf.", "A general comment concerning all descriptions - didn't we end all sentences with a period? That's what I did for previous modules.", "This description, although it starts from a new paragraph, concerns `private_ip_address` property. Doesn't it look better when it's in the same paragraph as the rest of the description? Imo yes, even if it's a bit longer than others.", "A general comment concerning all descriptions - we put 1 space and 1 dash after the longest property name and then indent all other dashes to it, correct? Some of the descriptions don't follow that rule here.", "This approach makes creating zone-redundant PIPs impossible (they'll be zonal instead). I think this approach is fine it that's a PIP for a VM though. :)", "Shouldn't we move this locals block before VM resource (where it is used) as per our general approach?", "Still not sure about adding this resource into the glue code, hope we can discuss on call.", "You could make it like this I believe.\r\n\r\n\r\n```hcl\r\n  validation {\r\n    condition = alltrue([\r\n      for v in var.interfaces : v.public_ip_name != null\r\n      if v.create_public_ip\r\n    ])\r\n    error_message = \"The `public_ip_name` property is required when `create_public_ip` is `true`.\"\r\n  }\r\n``` ", "In false case, shouldn't `var.virtual_machine.identity_ids` length be higher than 0 rather than higher or equal?", "What do you think about defining new variable for `account_kind` with default value `StorageV2` ? ", "Not `required_version = \">= 1.3, < 2.0\"` ? Are we starting from TF 1.5 ?", "The same as in previous one - shouldn't we use `required_version = \">= 1.3, < 2.0\"` ? ", "Is it name of the resource group, not key , yes ? Then maybe we should use name  ` public_ip_resource_group_name` instead of ` public_ip_resource_group` ? ", "Do we need directly pass dependency `azurerm_network_interface.this` if we have ` ip_configuration_name   = azurerm_network_interface.this[each.key].ip_configuration[0].name` ?", "Can we in comments describe in few sentences what is the purpose of having inverted files , then flat filenames across file shares etc. ? It's not clear while looking on that code at the beginning. ", "possible, but most of the settings other than `StorageV2` requier `Premium` tier, so we would have to parametrize both", "maybe lets take that with Migara during a planning session", "yes, done on purpose, making a zone redundand IP for a zonal vm does not really make sense, and was introduced due to some limitation in the 1st versions of the 3.x provider", "yes, lack of this was causing problem with terraform destroy see [here](https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/commit/d7f7116bc027b1608e0032c88cd6ee0bb125e9ba)", "yeah, this should go away", "as we discussed during the call sometimes it makes sens to put it into a separate paragraph, especially if the description is long, or contains codeblocks. But in this case you are right", "well you are probably right, the problem is that we already use this convention in other modules, like [`load balancer`](https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/blob/a63213f80532ba637c7d785f53d70c642a0ee59a/modules/loadbalancer/variables.tf#L72)\n\nso if we decide to change it, it has to be everywhere\n\nand besides, if a property holds a key, it should be prefixed with a `_key`, like [here for example](https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/blob/ff2b20e5f0770267b3ab6bccd8b65a682f26fc43/examples/vmseries/variables.tf#L376)", "fixed", "this was fixed in all examples and modules, from now on all properties that hold a name are suffixed with `_name`", "Bad indentation in this variable's description.", "This admonition looks bad, use this instead:\n`**Important!** \\`", "This admonition looks bad, use this instead:\n`**Important!** \\`", "This admonition looks bad, use this instead:\n`**Important!** \\`", "Let's be consistent and use `PAN-OS` & `VM-Series` terms across all descriptions.\nIn several places it's `PanOS`, `VMSeries`, `vmseries` etc.", "We agreed to end each property's description with a period.", "What about those queations marks? We make this property required, correct? (In Panorama it's required)", "I think that inside the module it's required and doesn't default to what is says it does.", "Another admonition in wrong format.", "Bad indentation.", "Bad indentation.", "Shouldn't `public_ip_resource_group` be `public_ip_resource_group_name` instead?", "Isn't that line too long?", "I think it actually defaults to `false`.", "I don't see a default value defined for that one.", "I don't see a default value defined for that one either.", "We sure we want to add our public IPs into the examples? I'm more into adding `0.0.0.0/0` with a comment for the user to update this one with his own values.", "I believe we don't need `enable_zones` variable anymore.", "Lines 213-218, bad indentation.", "Take a look at admonitions, stuff like `> [!NOTE]` is there.", "We don't need these settings anymore? Wouldn't storage_acl be useful?", "I see, acl has been moved to `azurerm_storage_account_network_rules`.\r\nDo we need the retention settings?", "```suggestion\r\n  Either a new or an existing one (depending on the value of `storage_account.create`).\r\n```", "```suggestion\r\n  storage_account = {\r\n    create = false\r\n  }  \r\n```", "Shall we always keep the same empty space between key - description for all properties or is it different on purpose here?", "since we are converting to `azurerm_linux_virtual_machine` can we support the managed storage option as in the code comments above?", "different description indentations", "this line looks like a duplicate description.", "missing closing quotes for `null`", "Sorry I probably missed it. Why do we remove some examples like VNG?", "Example of VNG on its own doesn't add any value and just clutter up the /examples", "yeah, you are right, although I was not paying that much attention to examples yet", "we needed the example per module in the early development phase. we're almost done with modules refactor, hence I figured we do not need these examples any more. ", "my mistake, this defaults to `file_shares_configuration` values, where default is `10`", "same here", "this is just a mistake, I was fixing the `_name` suffix with `sed` or something. ", "yes, good catch ", "yeah, a left over after the moment where I did not know if we still have limitation on PIPs being only non-zonal or all-zones deployable", "it's required in the resource, but in this variable definition it's optional, see line 139", "any specific place? or just in general?", "supported in the current form ", "It seems fixed."]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/360", "comments": ["Can we change package name from `application_insights` to `ngfw_metrics` ? ", "As we agreed let's go with TF 1.5 ", "What do you think about getting rid of `var.authentication.disable_password_authentication` and use:\r\n\r\n```hcl\r\n disable_password_authentication = length(var.authentication.ssh_keys) > 0 && var.authentication.password == null\r\n```\r\n\r\n?", "I think we have 10 possible metrics, so can we add all of them:\r\n\r\n```\r\nDataPlaneCPUUtilizationPct\r\nDataPlanePacketBufferUtilization\r\npanGPGatewayUtilizationPct\r\npanGPGWUtilizationActiveTunnels\r\npanSessionActive\r\npanSessionConnectionsPerSecond\r\npanSessionSslProxyUtilization\r\npanSessionThroughputKbps\r\npanSessionThroughputPps\r\npanSessionUtilization\r\n```\r\n\r\n?", "Can we avoid hardcoding fragments of names for PIP (`\"${nic.value.name}-public-ip\"`)? ", "Can we avoid hardcoding fragments of names for PIP (`\"${var.name}-autoscale-settings\"`)?", "What do you think about adding validation if `name` is from 10 possible metrics:\r\n```\r\nDataPlaneCPUUtilizationPct\r\nDataPlanePacketBufferUtilization\r\npanGPGatewayUtilizationPct\r\npanGPGWUtilizationActiveTunnels\r\npanSessionActive\r\npanSessionConnectionsPerSecond\r\npanSessionSslProxyUtilization\r\npanSessionThroughputKbps\r\npanSessionThroughputPps\r\npanSessionUtilization\r\n```\r\n?", "I think the idea for this was to allow having both SSH key & password for authentication.", "As recently discussed, shall we add `extension_operations_enabled` property with default set to `false` (how checkov likes it)? I created such variable in Panorama PR for Linux VM (it's called `allow_extension_operations` there).", "correct", "this name is not seen anywhere, you have to dig deep to find it. We have to give it some name, but it does not really matter which one \r\n\r\nit can be just the `nic.value.name`, that's fine with me", "but name can be also a name of the built-in metric, we would have to maintain that list and follow changes on Azure. I'm not a fan of that :) "]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/358", "comments": ["I've did bump the version to 1.5 for vmss, due to two reasons:\n1. I use a string function that is available since 1.5\n2. 1.5 is the older supported release\n\nWondering if we should do the same in every module? or just the ones we need?", "I would say that for long descriptions do EOF like notation ", "if you have `optional()` in property definition you do not have to use explicit `null` in the defaults", "maybe instead of adding a default here (it would be used only when there is no `public_ip_prefix`) add it to the `length` type definition? ", "What do you mean by \"1.5 is older supported release\"? ", "Had to use EOF in order to fit in 130 columns. Unless it doesn't matter in that case?", "But I have 2 mandatory properties, don't I? And isn't providing a default wherever it's applicable a good thing?", "Which default you mean, `null` for entire object or `28` number for length property? I don't understand this remark.", "it suppossed to be `oldest`, what I wanted to write is that 1.5 is the oldest supported Terraform release", "the point of 130 columns is just readability, so whatever you do with the text, just keep in mind that it should be easily digestible :) in all 4 places, `variables.tf`, `README.md`, terraform registry, pan.dev\r\n\r\njust an example:\r\n\r\n```hcl\r\ndescription = <<-EOF\r\n  A map of subnet IDs what will be bound with this NAT Gateway.\r\n\r\n  Value is the subnet ID, key value does not matter but should be unique.\r\n  Typically it can be a subnet name.\r\n\r\n  EOF\r\n```\r\n", "i think this one is not applicable anymore, when I wrote this comment the code was the following:\r\n\r\n```hcl\r\n  default = {\r\n    create              = true\r\n    name                = null\r\n    resource_group_name = null\r\n  }\r\n  type = object({\r\n    create              = optional(bool)\r\n    name                = optional(string)\r\n    resource_group_name = optional(string)\r\n  })\r\n```", "this code also changed since the comment", "I think it's a joint decision for all the modules. If for VMSS you need 1.5 maybe it makes sense to use 1.5 throughout the whole codebase."]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/355", "comments": ["\n```suggestion\n                                     originated from within it.\n```"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/348", "comments": ["Why we are removing test file?", "What do you think about splitting object, at least for `in_rules` and `out_rules` ? \r\nEspecially when it's also separated in Azure console into:\r\n- load balancing rules\r\n- outbound rules", "Currently we have:\r\n- `azurerm_lb_rule`\r\n- `azurerm_lb_outbound_rule`\r\n\r\nbut we are missing `azurerm_lb_nat_rule` - what do you thing about adding support for that ?", "mea culpa, a mistake", "we can, if there is a use case for it, with NGFW that is", "I thought about it, but I couldn't find any reasons to do so. When writing `tfvars` it still feels IMO more natural to have the rules under a specific FIP.\n\nI know we can have it that way in the example code, but separate it in the module, but then it wouldn't make sense", "@sebastianczech I've made [this example](https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/blob/f8cc1ca464757aa5338e6a04b8e89129f7ef5e7f/examples/lb/example.tfvars#L33-L86), IMO it's less readable - we still have a huge block of code"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/346", "comments": ["try to avoid indented code blocks in favour of explicit ones, with langugae notation\n\n`````suggestion\n```hcl\nprovider \"azurerm\" {\n  features {\n    resource_group {\n      prevent_deletion_if_contains_resources = false\n    }\n  }\n}\n```\n`````", "Maybe we could use [GH admonitions](https://github.com/orgs/community/discussions/16925)? to make it look better?", "the example is obsolete, for example the worskspace name is required", "`nullable` makes sense only if you have a default value", "two things here: \n1. multiline description, an `EOF` like notation would probably look better\n2. check if the default value is still `PerGB2018`. Maybe we could drop `default` here and `null` this value instead, to relay on Azure defaults. If it's not possible, add `nullable` to force the `default` value.", "Multiline description, add `EOF` notation\n\nAnd maybe block-quote the possible values, like: `0`, `30`, `60`, etc", "there are only 4 properties here, I would avoid pointing the user to module's documentation if it's not really necensary, like when you omit some nested props to avoid duplicating documentation.", "see comment around `workspace_sku` variable, if we need to keep the default value in the module's variable definition, add `nullable` to the definition, skip the default value here. This way you control the default value only in one place and you do not overwrite it in the example code.", "if we need to keep the default value in the module, set the parentised text to soemthing like `optional, default to module defaults`"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/345", "comments": ["I think we should go for zone-redundant by default, with all 3 zones", "since it will cause a resource to recreate (when you specify a subset of zones) maybe let;s limit it to all or none? either non-zonal, or available in all 3 zones?", "what do you think about combining some of the variables into blocks? group them logically? like `capacity_configuration` or `basic_configuration` etc. This way we would achive block-like variables.", "smae here, group all policy settings into something like `ssl_configuration`?", "\n```suggestion\n    error_message = \"Possible values for `protocol` are `Http` and `Https`.\"\n```", "provide the actual value \n```suggestion\n    error_message = \"If `Https` protocol is used, then SSL certificate (from file or Azure Key Vault) is required\"\n```", "maybe brake this to multiline, to be below 130 chars?", "\n```suggestion\n    error_message = \"If `Https` protocol is used, then SSL certificate password is required\"\n```", "\n```suggestion\n  - `name`                     - (`string`, optional) The name of the backend settings\n  - `path`                     - (`string`, optional) The Path which should be used as a prefix for all HTTP requests.\n  - `hostname_from_backend`    - (`bool`, optional) Whether host header should be picked from the host name of the backend server.\n  - `hostname`                 - (`string`, optional) Host header to be sent to the backend servers.\n  - `port`                     - (`number`, required) The port which should be used for this Backend HTTP Settings Collection.\n  - `protocol`                 - (`string`, required) The Protocol which should be used. Possible values are Http and Https.\n  - `timeout`                  - (`number`, required) The request timeout in seconds, which must be between 1 and 86400 seconds.\n  - `cookie_based_affinity`    - (`string`, required) Is Cookie-Based Affinity enabled? Possible values are Enabled and Disabled.\n  - `affinity_cookie_name`     - (`string`, optional) The name of the affinity cookie.\n  - `probe`                    - (`string`, optional) Probe's key.\n  - `root_certs`               - (`map`, optional) A list of trusted_root_certificate names.\n```", "this is actually required, please check with [provider](https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs/resources/application_gateway#:~:text=name%20%2D%20(-,Required)%20The%20name,-of%20the%20Backend%20HTTP), which values are required and which not", "\n```suggestion\n  - `name`                      - (`string`, required) The name for this Frontend Port.\n  - `port`                      - (`string`, required) The port used for this Frontend Port.\n  - `protocol`                  - (`string`, optional) The Protocol to use for this HTTP Listener.\n  - `host_names`                - (`list`, optional) A list of Hostname(s) should be used for this HTTP Listener.\n                                  It allows special wildcard characters.\n  - `ssl_profile_name`          - (`string`, optional) The name of the associated SSL Profile which should be used for this HTTP Listener.\n  - `ssl_certificate_path`      - (`string`, optional) Path to the file with tThe base64-encoded PFX certificate data.\n  - `ssl_certificate_pass`      - (`string`, optional) Password for the pfx file specified in data.\n  - `ssl_certificate_vault_id`  - (`string`, optional) Secret Id of (base-64 encoded unencrypted pfx) Secret\n                                  or Certificate object stored in Azure KeyVault.\n  - `custom_error_pages`        - (`map`, optional) Map of string, where key is HTTP status code and value is\n```", "\n```suggestion\n  - `name`         - (`string`, optional, defaults to `vmseries`) name of the backend pool.\n```", "\n```suggestion\n  - `vmseries_ips` - (`list`, optional, defaults to `[]`) IP addresses of VMSeries' interfaces that will serve as backends for the Application Gateway.\n```", "this is required, but all values are optional?", "\n```suggestion\n  - `name`        - (`string`, required) The name used for this Probe\n  - `path`        - (`string`, required) The path used for this Probe\n  - `host`        - (`string`, optional) The hostname used for this Probe\n  - `port`        - (`number`, optional) Custom port which will be used for probing the backend servers.\n  - `protocol`    - (`string`, optional) The protocol which should be used.\n  - `interval`    - (`number`, optional) The interval between two consecutive probes in seconds.\n  - `timeout`     - (`number`, optional) The timeout used for this Probe, which indicates when a probe becomes unhealthy.\n  - `threshold`   - (`number`, optional) The unhealthy Threshold for this Probe, which indicates\n                    the amount of retries which should be attempted before a node is deemed unhealthy.\n  - `match_code`  - (`list`, optional) The list of allowed status codes for this Health Probe.\n  - `match_body`  - (`string`, optional) A snippet from the Response Body which must be present in the Response.\n```", "when something is optional, all the defaults value in the documentation string", "what happens when you do not specify a name?", "doesn't it have a default value? even if no, I would say that typical approach would be to give it `false`", "doesn't it have a default value? even if the provider does not have one, I would keep to the UI defaults", "possibly add line wrapping\n```suggestion\n  - `name`         - (`string`, required) Rule name.\n  - `priority`     - (`string`, required) Rule evaluation order can be dictated by specifying an integer value from 1 to 20000 with 1 being the highest priority and 20000 being the lowest priority.\n  - `backend`      - (`string`, optional) Backend settings` key\n  - `listener`     - (`string`, required) Listener's key\n  - `rewrite`      - (`string`, optional) Rewrite's key\n  - `url_path_map` - (`string`, optional) URL Path Map's key\n  - `redirect`     - (`string`, optional) Redirect's ky\n```", "and add optionals' defaults", "woah, where is the whole documentation? examples? config snippets, etc?", "this is a complex module, I wouldn't drop it", "advanced examples added", "done", "i'm not supporter of such hardcoding, but ok - done", "From resource documentation https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs/resources/application_gateway this 3 variables (`capacity`, `capacity_max`, `capacity_min`) are part of 2 different blocks (`sku`, `autoscale_configuration`) - that's why initially it was splited, but I rebuilt it and now we have 1 object defining capacity.", "fixed", "fixed", "done", "fixed", "done", "I added default value for backend.", "done", "done", "done", "done", "it was a mistake - fixed and changed to required", "fixed", "Not all optionals have default values in provider documentation , but I added this, which were missed. \r\nLines wrapping fixed.", "I fixed it - name is required, previously it was an error.", "fixed", "it's rebuilt", "\n```suggestion\nBelow are sample values for `appgws` map (in comments you can find also commands to create SSL/TLS certificates, if required):\n```", "IMHO the previous README was better :D you not only had examples, but they had some introduction and comments. Now we only have a huuuuge block of code. For someone who's new to this module/terraform, it can be unreadable and discouraging :) \n\nI know the previous README was long, but this change is for worst IMO :D ", "\n```suggestion\n  # A unique set of ports will be created upfront and then referenced in the listener's config.\n```", "just an idea, does not have to be a good one: maybe instead of adding `enabled` control WAF by either setting this map to `null` (default, means disabled) or by specifying a map (means enabled)", "maybe set this to a bool value? something like `prevention_mode = true/false`? it's highly unlikely that we will have a 3rd option, and maybe this would make this less error-prone (type-o's, etc)", "\n```suggestion\n                                        For the `Predefined` policies, check the Microsoft documentation\n```", "here, and in some other places as well, line wrapping at 130 column", "We had a conversation with @acelebanski about this setting. I think we should add a default of `127.0.0.1` here. Otherwise, when you define a backed and a probe with just the defaults, the code will fail. The other option is to investigate again a possibility to add NICs to the backend pool. But it has to be tested with a public Load Balancer hooked to the same NICs. If this would work, then we could skip a default for this setting and set `backends.hostname_from_backend = true` (this would work with VMSS as well).", "\n```suggestion\n  A rule combines, backend, listener, rewrites and redirects configurations.\n```", "it's either backend or redirect, they are mutually exclusive, but at least one is required - I think we should have a validation block for that", "should we add an option to source an existing IP?", "I added support for existing public IP", "I added validation, but either `backend`, `redirect` or `url_path_map` is required, so it's a little bit extended.", "fixed", "ok, changed", "We have validation, so there will be no errors in deployment:\r\n```\r\n  validation {\r\n    condition     = contains([\"Detection\", \"Prevention\"], coalesce(var.waf.firewall_mode, \"Detection\"))\r\n    error_message = \"For `firewall_mode` possible values are Detection and Prevention\"\r\n  }\r\n```\r\n\r\nI prefer to have it as string, because this is the way how it's defined in https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs/resources/application_gateway.\r\n\r\nNevertheless I changed it as you proposed.", "I added lifecycle precondition, which check if:\r\n- there is host defined for health probe or\r\n- there is overridden host name defined for backend settings (as in our backend we have IPs for VM-Series or VMSS)\r\n\r\nhttps://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/blob/249642e9bdecadb6855bf503c40c8dd49e934cdf/modules/appgw/main.tf#L323-L332\r\n\r\nLifecycle precondition protects us and code is not failing. Is it acceptable approach ?", "I rebuild the README, but I don't want to repeat all properties, which are in tables below examples. \r\nPlease let me know, if that changed README is acceptable. ", "I extended validation to 3rd option - pick host name from backend target:\r\n\r\nhttps://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/blob/e78e0d91cbba7ad5d16e95980aba44807b0335dd/modules/appgw/main.tf#L323-L335\r\n\r\nUnfortunately in backend pool for application gateway there is no possibility to use NIC, so we are using IPs for VMSS.\r\n\r\nI was not removing `hostname_from_backend` , because if `hostname` is not defined for backend, if `hostname_from_backend` is `false`, then by default the Application Gateway sends the same HTTP host header to the backend as it receives from the client - because of that we cannot set `pick_host_name_from_backend_address` to `true` if `hostname` is not defined, so I leave both options `hostname` and `hostname_from_backend` in `backends`:\r\n\r\nhttps://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/blob/249642e9bdecadb6855bf503c40c8dd49e934cdf/modules/appgw/variables.tf#L391-L429\r\n\r\nNevertheless lifecycle precondition protects us before creating custom health probes without hostname defined for probe or backend settings."]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/342", "comments": ["Are we going to remove support for TF 1.2 ?", "Do we need also upgrade Terratest in https://github.com/PaloAltoNetworks/terraform-modules-vmseries-tests-skeleton as this is used in this repository ?", "Can we remove that comment ?", "yes, but with the refactor", "that's a good question. The tests work w/o Terratest being updated in the skeleton repo. Question is, if we bump it there, shouldn't we also bump it in the other repos?", "Actually we can put this property back. It was a false-positive. It was not the one causing Terratest to crash Terraform. "]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/339", "comments": ["I think an example could become handy here as we don't use this module in examples.", "the description says `load balancer`, should be VNG", "maybe lets use `EOF` notation for wrapping descriptions?", "what if a null value is assigned? can we live with that? or should we do `nullable=false`?\n\n", "Same applies to other multi-sentence descriptions", "same applies to all variables with default values", "This should start with one sentence description, like: `Controls whether the private IP is enabled on the gateway.`", "how about chainging to `zones` ?\n```suggestion\nvariable \"zones\" {\n```", "I'm wondering shouldn't we add validation here, either no zones, or all 3? Is that an option? I'm guessing this reflects the PIP as well", "can we have two configs with the same name? if no, I would drop the default value and leave the name property as required + a validation that checks if the name property is unique", "do we even consider doing basic?", "when looking at the code it looks like the name property is required, not optional, see `main.tf`, lines `101`&`108` and `118`&`120`", "I would suggest the following whenever we have optional value, even if it's `null`\n```suggestion\n  - `aad_tenant`              - (`string`, optional, defaults to `null`) AzureAD Tenant URL\n```", "all the properties are optional but the variable is required?", "try maybe wrapping manually lines longer than 130 chars", "this validation could fail if you assign `null`\n", "try adding `nullable=false`", "instead of doing a condition against `null` you can use coalesce, like this:\n```suggestion\n        for_each = { for t in coalesce(vpn_client_configuration.value.root_certificate, {}) : t.name => t }\n```", "this will brake when you assign null to `var.custom_route`, see comments in `variables.tf` about `nullable`", "Dynamic allocation has two properties:\n1. it does not need NSG for incoming internet traffic\n2. IP is being rotated when the service becomes offline\n\nFor VPN configs I would say we should only do Static + NSG - to be sure that the IP is always the same and to control the incoming traffic", "maybe instead of doing this complex condition play around with `nullable` and/or default values, for example, if we set `active-active` to `false` by default, set `zones` to `null` by default. next to that to verifications:\n- validation in `zones` variable: either `null` or a valid list of zones\n- precondition in PIP resource, when `active-active` is true, `zones` cannot be `null`", "I would place this in the top, I know it does not make more difference for TF, but it makes the code more self-documenting", "place tags as the bottom of a resource - that's the convention in azure resource we have for a long time", "this is defined as an optional list, w/o any default value, hence `null` - this will fail -> add a default value of `[]` to type", "this is defined as an optional list, w/o any default value, hence null - this will fail -> add a default value of [] to type", "fixed", "fixed", "fixed", "Thanks, I've added `nullable=false` (in other places too)", "ok", "thanks, changed", "added, thanks", "fixed, thanks", "ok, fixed", "moved", "yes, I've added an example", "resolved", "yes, you are right, fixed", "added", "added", "ok, fixed this and the others optionals too", "done", "I propose to leave that flexibility to choose e.g. for the lab do we need standard ?", "ok, I added", "you are right, fixed", "I propose to leave that flexibility to choose e.g. for the lab cannot we use dynamic ?", "I added", "According to internal discussion, I defined allocation method for public IP as `Static` and SKU `Standard`.", "According to internal discussion, I defined allocation method for public IP as `Static` and SKU `Standard`.", "I'm not saying you code is wrong :) just an idea I'd like to share:\n```hcl\ntoset([ for ipc in var.ip_configuration : ipc.name if ipc.create_public_ip ])\n```", "cannot this be just `var.zones`? default is null and everything else is governed by the validation block", "`try` would be shorter", "what do you think about adding this as a standard? so to all `main.tf` files?", "you're not consistens when it comes to line wrapping :) , see lines: 141-143, 195, 197, 202, 259, 297, 320, 323 and 324", "done", "done", "I agree :) I was adding this in comments to have quick link to the documentation while developing the module :) ", "done", "fixed"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/338", "comments": ["```suggestion\r\n  - `create_virtual_network`  - (`bool`, optional, defaults to `true`) when set to `true` will create a VNET, `false` will source an existing VNET.\r\n```", "```suggestion\r\n  - `create_virtual_network`  - (`bool`, optional, defaults to `true`) when set to `true` will create a VNET, `false` will source an existing VNET.\r\n```", "```suggestion\r\n  - `create_virtual_network`  - (`bool`, optional, defaults to `true`) when set to `true` will create a VNET, `false` will source an existing VNET.\r\n```", "```suggestion\r\n  - `create_virtual_network`  - (`bool`, optional, defaults to `true`) when set to `true` will create a VNET, `false` will source an existing VNET.\r\n```", "```suggestion\r\n  - `create_virtual_network`  - (`bool`, optional, defaults to `true`) when set to `true` will create a VNET, `false` will source an existing VNET.\r\n```", "```suggestion\r\n  - `create_virtual_network`  - (`bool`, optional, defaults to `true`) when set to `true` will create a VNET, `false` will source an existing VNET.\r\n```", "```suggestion\r\n  - `create_virtual_network`  - (`bool`, optional, defaults to `true`) when set to `true` will create a VNET, `false` will source an existing VNET.\r\n```", "Can we add validation for `next_hop_type`, because we know possible values are: `VirtualNetworkGateway`, `VnetLocal`, `Internet`, `VirtualAppliance` and `None` ?"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/323", "comments": ["Maybe we can say \"vmseries examples\" to make it more clear\r\n```suggestion\r\nTo use this code, please deploy one of the vmseries examples first. Then copy the [`examples.tfvars`](./example.tfvars) to `terraform.tfvars` and edit it to your needs.\r\n```", "```suggestion\r\n            next_hop_in_ip_address = \"10.0.0.30\" # TODO: replace with IP address of the private Load Balancer in the transit VNET\r\n```"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/316", "comments": ["Maybe we should go with [`v2`](https://github.com/tibdex/github-app-token/releases/tag/v2.0.0), especially if it revokes the created token at the end of the job with a [post script](https://docs.github.com/en/actions/creating-actions/metadata-syntax-for-github-actions#runspost).", "```suggestion\r\n        uses: tibdex/github-app-token@v2\r\n```", "In `v2` we don't have `installation_id`, so maybe we should configure it in below way:\r\n\r\n```suggestion\r\n          installation_retrieval_mode: id\r\n          installation_retrieval_payload: ${{ secrets.CHATOPS_APP_INSTALLATION_ID }}          \r\n```\r\n\r\nor maybe we should use `installation_retrieval_mode` as `organization` as defined in https://github.com/tibdex/github-app-token/blob/v2.0.0/action.yml ? ", "Good catch"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/306", "comments": ["I would be great to also output the IPSec VPN configurations (ynamic \"ipsec_policy\") since those need to match exactly to the remote site and can be easily copy-pasted from here .\r\n\r\nThe ones that count are : ike + IPSec encryption and integrity , PFS group . SA Datasize and lifetime don't need to match as those are negotiated .", "I've added additional output with IPsec policy. Thank you for feedback.", "\n```suggestion\npackage virtual_network_gateway\n```", "the number of peering addresses depends on a type of VNG (active-active or single node). Maybe we could add some validation throwing an error if you provide 2 peering addresses for a non redundand gateway. ", "same suggestion as [here](https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/306#discussion_r1321159362)", "This depends on Generation and SKU, should we add some validation? Or just rely on error messages thrown by the API?", "Unfortunately in Terraform the condition for `validation` in variable can only refer to the variable itself, so we cannot for `local_bgp_settings` refer to value of `active_active`, in which we are defining type of VNG (active-active or single node). \r\n\r\nIn variable description I've already put that information: https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/blob/cfd34e1c6e0d0e4038d4a8632570f6aa03622b7e/modules/virtual_network_gateway/variables.tf#L168-L170\r\n\r\nCould it be sufficient ? ", "same reply as [here](https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/306#discussion_r1321333921)", "Thank you for feedback, you are right.\r\n\r\nI've added validation for `type`, `vpn_type`, `sku` and `generation` e.g.: https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/blob/64b2fbfce7645aa94d04ec23e2c2a11f8be6e2b1/modules/virtual_network_gateway/variables.tf#L99-L107\r\n\r\nCould it be sufficient ?", "no :) we could use `lifecycle { precondition {} }`. You can operate there on all available variables", "i was not clear enough, I thought about adding precondition block", "@FoSix , no problem, thank you for feedback.\r\n\r\nI've added `lifecycle precondition` to check SKU, which depends on generation: \r\n\r\nhttps://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/blob/872dce18522fce79418298c412c036ccf8e34c7b/modules/virtual_network_gateway/main.tf#L80-L85\r\n\r\nI hope it fullfil requirement about check generation and SKU.", "@FoSix thank you for feedback.\r\n\r\nI've added checking number of peering addresses:\r\n\r\nhttps://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/blob/872dce18522fce79418298c412c036ccf8e34c7b/modules/virtual_network_gateway/main.tf#L86-L89", "I've added checking number of Azure BGP APIPA IP addresses:\r\n\r\nhttps://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/blob/872dce18522fce79418298c412c036ccf8e34c7b/modules/virtual_network_gateway/main.tf#L90-L93"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/304", "comments": ["What do you think about adding `help` command , which will display possible options ? For people rarely using ChatOPS it may be useful to quickly get info how to use commands (without going deep in the code) .", "What is the reason to have capital letters for Terratest actions ?", "Why for PR CI we are going to use workflow `release_ci.yml` ? ", "my bad, a leftover from tests", "the action is being passed to `go test -run HERE` directly (passing through sub-workflows, action, Makefile). You can pass all-lowercase, like this:\n```bash\nmake examples/common_vmseries ACTION=validate\n::group::DOWNLOADING GO DEPENDENCIES\n::endgroup::\n::group::ACTION >>validate<<\ntesting: warning: no tests to run\nPASS\nok  \tgithub.com/PaloAltoNetworks/terraform-azure-vmseries-modules/examples/common_vmseries\t1.694s\n::endgroup::\n```\n\nSomething is being run, but I do not know what TBH. \nWhen you run it with 1st letter capital, it matches the test name. You can see the output is different:\n\n```bash\nmake examples/common_vmseries ACTION=Validate\n::group::DOWNLOADING GO DEPENDENCIES\n::endgroup::\n::group::ACTION >>Validate<<\nTestValidate 2023-08-29T12:00:56+02:00 retry.go:91: terraform [init -upgrade=true]\nTestValidate 2023-08-29T12:00:56+02:00 command.go:100: Running command terraform with args [init -upgrade=true]\nTestValidate 2023-08-29T12:00:56+02:00 command.go:185: Upgrading modules...\nTestValidate 2023-08-29T12:00:56+02:00 command.go:185: - ai in ../../modules/application_insights\nTestValidate 2023-08-29T12:00:56+02:00 command.go:185: - appgw in ../../modules/appgw\nTestValidate 2023-08-29T12:00:56+02:00 command.go:185: - bootstrap in ../../modules/bootstrap\nTestValidate 2023-08-29T12:00:56+02:00 command.go:185: - bootstrap_share in ../../modules/bootstrap\nTestValidate 2023-08-29T12:00:56+02:00 command.go:185: - load_balancer in ../../modules/loadbalancer\nTestValidate 2023-08-29T12:00:56+02:00 command.go:185: - natgw in ../../modules/natgw\nTestValidate 2023-08-29T12:00:56+02:00 command.go:185: - vmseries in ../../modules/vmseries\nTestValidate 2023-08-29T12:00:56+02:00 command.go:185: - vnet in ../../modules/vnet\nTestValidate 2023-08-29T12:00:56+02:00 command.go:185:\nTestValidate 2023-08-29T12:00:56+02:00 command.go:185: Initializing the backend...\nTestValidate 2023-08-29T12:00:57+02:00 command.go:185:\nTestValidate 2023-08-29T12:00:57+02:00 command.go:185: Initializing provider plugins...\nTestValidate 2023-08-29T12:00:57+02:00 command.go:185: - Finding hashicorp/azurerm versions matching \"~> 3.25\"...\nTestValidate 2023-08-29T12:00:57+02:00 command.go:185: - Finding hashicorp/random versions matching \"~> 3.1\"...\nTestValidate 2023-08-29T12:00:57+02:00 command.go:185: - Finding latest version of hashicorp/http...\nTestValidate 2023-08-29T12:00:58+02:00 command.go:185: - Finding latest version of hashicorp/local...\nTestValidate 2023-08-29T12:00:58+02:00 command.go:185: - Using previously-installed hashicorp/random v3.5.1\nTestValidate 2023-08-29T12:00:58+02:00 command.go:185: - Using previously-installed hashicorp/http v3.4.0\nTestValidate 2023-08-29T12:00:58+02:00 command.go:185: - Using previously-installed hashicorp/local v2.4.0\nTestValidate 2023-08-29T12:00:58+02:00 command.go:185: - Installing hashicorp/azurerm v3.71.0...\nTestValidate 2023-08-29T12:01:06+02:00 command.go:185: - Installed hashicorp/azurerm v3.71.0 (signed by HashiCorp)\nTestValidate 2023-08-29T12:01:06+02:00 command.go:185:\nTestValidate 2023-08-29T12:01:06+02:00 command.go:185: Terraform has made some changes to the provider dependency selections recorded\nTestValidate 2023-08-29T12:01:06+02:00 command.go:185: in the .terraform.lock.hcl file. Review those changes and commit them to your\nTestValidate 2023-08-29T12:01:06+02:00 command.go:185: version control system if they represent changes you intended to make.\nTestValidate 2023-08-29T12:01:06+02:00 command.go:185:\nTestValidate 2023-08-29T12:01:06+02:00 command.go:185: Terraform has been successfully initialized!\nTestValidate 2023-08-29T12:01:06+02:00 command.go:185:\nTestValidate 2023-08-29T12:01:06+02:00 command.go:185: You may now begin working with Terraform. Try running \"terraform plan\" to see\nTestValidate 2023-08-29T12:01:06+02:00 command.go:185: any changes that are required for your infrastructure. All Terraform commands\nTestValidate 2023-08-29T12:01:06+02:00 command.go:185: should now work.\nTestValidate 2023-08-29T12:01:06+02:00 command.go:185:\nTestValidate 2023-08-29T12:01:06+02:00 command.go:185: If you ever set or change modules or backend configuration for Terraform,\nTestValidate 2023-08-29T12:01:06+02:00 command.go:185: rerun this command to reinitialize your working directory. If you forget, other\nTestValidate 2023-08-29T12:01:06+02:00 command.go:185: commands will detect it and remind you to do so if necessary.\nTestValidate 2023-08-29T12:01:06+02:00 retry.go:91: terraform [validate]\nTestValidate 2023-08-29T12:01:06+02:00 command.go:100: Running command terraform with args [validate]\nTestValidate 2023-08-29T12:01:19+02:00 command.go:185: Success! The configuration is valid.\nTestValidate 2023-08-29T12:01:19+02:00 command.go:185:\nPASS\nok  \tgithub.com/PaloAltoNetworks/terraform-azure-vmseries-modules/examples/common_vmseries\t23.190s\n::endgroup::\n```", "It's clear, thank you for explanation \ud83d\udc4d ", "you can see an example run [here](https://github.com/PaloAltoNetworks/vm-series-gh-actions/pull/76#issuecomment-1697175116)", "Great, it's perfect . Thank you"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/299", "comments": ["there's a bug in the dedicated vmss: `\"type=dhcp\"`, maybe we could use this PR to fix it there", "dedicated vmss is non-zonal. Maybe we could make this example zone-enabled?", "Yes saw that, I was going to open a separate PR for that but let me update this then.", "Shall we add this `var.enable_zones` condition to other examples as well? It doesn't check for the enable_zones variable in others.", "converted the example to zone-enabled but there is a couple of things to note; since NATGWs are zonal resources it's removed from the example and the outbound internet traffic is provided from public IP addresses assigned to public interfaces of firewalls in the VMSS. \r\nAnother point is since we don't have a NATGW, I needed to enable public IPs on management interfaces as well, otherwise it wouldn't be possible for the firewalls to bootstrap with publicly accessible Panorama or do their initial licensing with Palo Alto update servers since they won't have internet access. \r\nWe might add a note for this on README perhaps; mentioning that public IP addresses on management interfaces can be removed after the deployment and all management traffic can be forwarded to the firewalls' private interfaces to get NATed to the internet (after the firewalls get configured to NAT this traffic). Any other ideas?", "> Another point is since we don't have a NATGW, I needed to enable public IPs on management interfaces as well, otherwise it wouldn't be possible for the firewalls to bootstrap with publicly accessible Panorama or do their initial licensing with Palo Alto update servers since they won't have internet access.\r\n\r\nthat's not entirely true. A VM with just private IP and default NSG rules (or no NSG) can access the internet, it's not accessible from the internet. So you don't need public IPs on management to contact a publicly available Panorama (which probably will never happen) or to download updates.\r\nIn our examples we do not block the default outbound route, so we do not need public IPs for that.\r\n", "I would keep keep it as it is and start to create a list of things to refactor. We already have #280 and #279 that will make a huge change in the code. Maybe we can move all three to a single issue?", "why did you remove it?", "as discussed in some other place, we do not need this", "we could also skip this and use outbound rules in public LB? ", "same here, why this got removed?", "and again", "same", "This variable is not there anymore in load balancer module. avzones variable within the load balancer is used instead.", "Same with others.", "As we don't have LB outbound rules in reference architectures we decided to keep it the same.", "After testing and troubleshooting with public IPs removed from management interfaces, we have found out that default outbound access is blocked if VMs are attached to a Load Balancer or they have any additional interface with a public IP assigned. We have both so relying on the default outbound access won't be possible. \r\n\r\nAnd since NATGWs are zonal, this leaves us with 2 feasible options I believe:\r\n* Assigning public IP to both public and management interfaces\r\n* Creating a separate backend pool for the management interfaces in order to create outbound rules from them (but this is problematic as well since we don\u2019t support creating separate backend pools for different interfaces on our current LB module)\r\n\r\n~~As a note if we assign public IPs to the management interfaces and the user wants to remove them we can put a comment on README saying that public IP addresses on management interfaces can be removed after the deployment with management traffic forwarded to the firewalls\u2019 private interfaces (private LB) to get NATed to the internet (after the firewalls get configured to NAT this traffic).~~ Sorry this can't be done on a scaling set since new instances will not have the config to nat the management traffic before bootstrapping.", "It is agreed to keep public IP addresses on management interfaces for the simplicity of the example and put a disclaimer on how to avoid it.", "Converted it back to match with the other examples. Put a comment on #280 for this.", "Agreed to keep it. Details on the other thread."]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/296", "comments": ["The image is transparent. I think we should change it to one with a solid background as it's unreadable when using a dark mode in GH\r\n![image](https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/assets/42772730/98a12c97-59eb-412f-ad7d-7bb92edb0c92)\r\n", "```suggestion\r\nThe Terraform code presented here will deploy Palo Alto Networks Panorama management platform in Azure in management only mode (without additional logging disks). For option on how to add additional logging disks - please refer to panorama [module documentation](../../modules/panorama/README.md#input_logging_disks)\r\n```", "Fixed"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/294", "comments": ["```suggestion\r\nVirtual Machine Scale Sets (VMSS) are used for autoscaling to run the Next Generation Firewalls, with custom data plane oriented metrics published by PAN-OS it is possible to adjust the number of firewall appliances to the current workload (data plane utilization). Since firewalls are added or removed automatically, they cannot be managed in a classic way. Therefore they are not assigned with public IP addresses. To ease licensing, management and updates a Panorama appliance is suggested. Deployment of a Panorama instance is not covered in this example, but a [dedicated one exists](../standalone_panorama/README.md).\r\n```"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/287", "comments": ["@migara - pushed the required access to run workflows to `maintain`"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/278", "comments": ["Maybe we should split testskeleton from AWS and Azure into the separate repository at this point. ", "Same as testskeleton.", "Comment :) ", "I was not aware of this repo https://github.com/PaloAltoNetworks/terraform-modules-vmseries-tests-skeleton", "I propose to import external package (instead of using internal folder `go`):\r\n\r\n```suggestion\r\n\t\"github.com/PaloAltoNetworks/terraform-modules-vmseries-tests-skeleton/pkg/testskeleton\"\r\n```", "As @pimielowski suggested, I propose to remove folder `go` with all `*.go` files and use external packages from https://github.com/PaloAltoNetworks/terraform-modules-vmseries-tests-skeleton.\r\n", "Previously we introduced `makefile.sh` in order to in have in every `Makefile` only 1 command for 1 action e.g. for AWS VM-Series modules we have in `Makefile`:\r\n\r\n```\r\ntest:\r\n\t@../../makefile.sh test\r\n```\r\n\r\nand in `makefile.sh`:\r\n\r\n```\r\n  test)  \r\n    echo \"::  DOWNLOADING GO DEPENDENCIES  ::\"\r\n    go get -v -t -d && go mod tidy\r\n    echo\r\n    echo \"::  EXECUTING TERRATEST  ::\"\r\n    go test -v -timeout 120m -count=1\r\n    echo\r\n    ;;\r\n```\r\n\r\nNow after removing `makefile.sh`, we need to repeat 3 lines for every example e.g.:\r\n\r\n```\r\n\t@echo \"::group::TESTING INFRASTRUCTURE\" && \\\r\n\tgo test -run Deploy -timeout 60m -count=1 && \\\r\n\techo \"::endgroup::\"\r\n```\r\n\r\nWhy we are removing `makefile.sh` ?", "I think we can, I'm trying to figure out if we can have perhaps a single makefile?", "\ud83d\udc4d\ud83c\udffb unless the code required by Azure did not get released yet\r\n", "yes, but [PR 3](https://github.com/PaloAltoNetworks/terraform-modules-vmseries-tests-skeleton/pull/3) is approved, we can merge it and execute manually release action (to not to wait until Thursday) :) ", "and previously makefiles where made of two parts, one that was common and one that was specific to a module (namely setting up unique variables).\r\nwith Terratest the latter one was moved to `main_test.go`, leaving the makefile quite generic. It's easier just to copy it between modules w/o any changes to itself.", "If there is a chance to not repeat the same code by copying files, I prefer to do it. Nevertheless it's better to have consistent approach through all clouds for VM-Series modules. Are we then removing `makefile.sh` from all repositories ?", "> If there is a chance to not repeat the same code by copying files...\r\nyou will still copy them, they are still the same, the content is different though, meaning they originally contained a reference to `makefile.sh`, now they just have 3~4 lines per target.\r\n\r\nMy point is that when we had complex logic in `Makefile`s, a lot of variables, etc it was easier to move the code to a separate file (especially that all code in a `Makefile` is a oneliner, you can't control `set -e` and `set -o pipefail` that easily, it's harder to operate on env variables, etc).\r\n\r\nBut now the logic is moved to `main_test.go` and I do not see a point in keeping a `makefile.sh` in this situation as the `Makefile`'s code is way more simpler, not parametrized and we no longer need to control execution env to use for example `grep` w/o failing the whole pipeline.", "should we use the same approach in all repos? I do not know TBH, the `Makefile` is a common abstraction layer, but what it contains does not have to be IMO.", "code was changed to use this repo as a source for the testskeleton module", "fixed ", "fixed"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/276", "comments": ["Some debug? ", "Why you remove the tf_version here? ", "Following the discussion yesterday on planning - we will run `apply` only on the latest TF version, if you do not specify any here it will automatically pick up `latest`, if you put here any version, `1.5` in example, you will have to update the code each time something new is released", "yeah, good catch :smile: ", "Got it!"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/273", "comments": ["Just wondering if we need the `outputs` here or is this just a utility module that just does something and *exists*.", "I would say: no defaults here. The VNET name is mandatory, otherwise the module does not make sense.\r\n\r\n```suggestion\r\n```", "same here", "this actually is applicable to all `local_` and `peer_` properties, this one and all the ones below: should we really duplicate them? This gives flexibility of course, but this is also a module that will be used with NGFWs, so traffic settings should be symetrical IMO.", "Done!", "For `allow_virtual_network_access` and `allow_forwarded_traffic` they could be the same but the other two actually require combinations for the NVA to work - for example if you want to use `use_remote_gateways` in one VNET - you must have `use_remote_gateways` + `allow_gateway_transit` in the other one - otherwise it will not work .\r\n\r\nIt's a bit more variables - true - but at least it offers you full flexibility .", "It's just something to be there so we can have an outputs file - we may change the output itself . I doubt there are any resources in which we would use outputs from this module - but I didn't want to not have one either.", "How about adding an ability to specify exact peering names and fall back to ones generated based on VNet names when it's not provided (similar to what we currently have in [GCP](https://github.com/PaloAltoNetworks/terraform-google-vmseries-modules/blob/main/modules/vpc-peering/main.tf))?", "I think it may also be useful to output peering IDs.", "We do output virtual_network_id in the VNet module, so we could allow to either provide the IDs directly (thus skip extra datasource read) or get ones based on RG/VNet name as it's done right now.", "Agreed! Added!", "Added!", "that would be nice, but what would happen if you specify both? we would need some additional logic to cover that. \r\n\r\nAnd that would be two additional variables, making this small module quite complex. I'm not saying no, I'm far from that, but maybe we should also rethink how to define variables so that they are more grouped? readable?\r\n\r\ngroup them into maps? one for local vnet, one for remote? just and idea \ud83e\udd14 ", "I refactored the code using maps - but it does seem that we have some checks failing for version 1.2 when the validate job is running . I believe the optional value inside the object is the issue :\r\n```\r\n  type = object({\r\n    vnet_name                    = string\r\n    resource_group_name          = string\r\n    name                         = optional(string)\r\n    allow_virtual_network_access = bool\r\n    allow_forwarded_traffic      = bool\r\n    allow_gateway_transit        = bool\r\n    use_remote_gateways          = bool\r\n  })\r\n```\r\n\r\nI did find something regarding this topic here : https://medium.com/@apr_1985/terraform-optional-attributes-and-defaults-d73643185341", "After discussion with @FoSix - we will use `map(any)` for now until we introduce a refactoring of the `map(any)` variables.", "since [this](https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/blob/82370696752ed913e697945e114e4d0830fe4fa6/examples/dedicated_vmseries_and_autoscale/variables.tf#L258) format is more or less approved, can you align variables to match it? It will be less work when we will refactor the other modules.", "```suggestion\r\n  - `vnet_name`                   - (`string`, required) the local peer VNET name.\r\n```", "```suggestion\r\n  name                         = try(var.local_peer_config.name, \"${var.local_peer_config.vnet_name}-to-${var.remote_peer_config.vnet_name}\")\r\n```\r\n\r\ntwo reasons for that change:\r\n- when working with existing resource name (like `vnet_name`, it has to be a full name of an existing resource, with prefixes and everything, as we use it in a datasource) we would already have a prefix starting the peering name, so for `hub-` prefix this would give us: `hub-hub-vnet-to-hub-othervnet` <- does not make sense\r\n- this is not a resource, meaning you cannot see it in a resource group (if I'm not wrong here), hence it's name should be descriptive, but does not need to have a prefix IMO, you will see it inside a VNET in the peerings list", "[this comment](https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/273/files#r1267689419) applies also here", "Done! \ud83d\udc4d "]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/272", "comments": ["@jamesholland-uk you need to change this in the `variables.tf` and then re-generate the README file.\r\n\r\nOtherwise the release CI will fail as it tries to run `terraform_docs` and looks for changes:\r\n\r\n![image](https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/assets/42772730/80454764-7798-4b1b-80ef-ef41d670168e)\r\n"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/258", "comments": ["this property is missing in the bootstrap variable description\r\n\r\nthis applies to the `main.tf` files in the other (VMSeries based) examples", "what do we need this one for?", "```suggestion\r\n    List of IP CIDR ranges (like `[\"23.23.23.23\"]`) that are allowed to access the Storage Account.\r\n```", "```suggestion\r\n  [\r\n    module.vnet.subnet_ids[\"subnet-mgmt\"],\r\n    module.vnet.subnet_ids[\"subnet-pub\"],\r\n    module.vnet.subnet_ids[\"subnet-priv\"]\r\n  ]\r\n```", "```suggestion\r\n  If you are using [vnet module](../vnet/README.md) - set `storage_private_access` to true for the specific subnet.\r\n```", "```suggestion\r\n  description = \"If `true`, storage account network rules will be activated with Deny as the default statement.\"\r\n```", "I would add here some `lifecycle.precondition` - it's possible now to set the `password` to `null` and not specify any SSH keys. At least one should be set.\r\n\r\nthis. can probably apply to the scale set as well", "why do we rely here on a single key? and not on a list of keys like in the `vmseries` module?", "That solves the issue in which checkov status that you must disable password auth for more security. Putting it under a condition eliminates the scan basically (because it's dependent on the input).", "Added lifecycle to both vmss and virtual machine in which you `var.password` and `var.ssh_keys` cannot be null/empty list at the same time :\r\n\r\n```\r\nlifecycle {\r\n      precondition {\r\n      condition = var.password != null || var.ssh_keys != []\r\n      error_message = \"Either password or ssh_keys must be set in order to have access to the device\"\r\n  }\r\n}\r\n```", "Apologies - this was was left from a few months ago when my knowledge on the subiect was sparse - I updated it now.", "maybe let's add here a condition, I do not see much sense in running this source if we do not use full bootstrapping with acl. So either check if a bootstrap storage is defined, or even better, check if you have bootstrap storage with network ACL defined", "these are not subnet IDs, but a map containing keys for vnet and subnet definitions. I would drop the `_ids` suffix\r\n```suggestion\r\n  - `storage_allow_vnet_subnets` : (defaults to `[]`) whitelist containing the allowed vnet and associated subnets that are allowed to access the Storage Account. Note that the respective subnets require `enable_storage_service_endpoint` set to `true` to work properly.\r\n```", "```suggestion\r\n  - `storage_allow_inbound_public_ips` : (defaults to `[]`) whitelist containing the allowed public IP subnets that can access the Storage Account. Note that the code automatically tries to query [https://api.ipify.org](https://api.ipify.org) to obtain the public IP address of the machine executing the code so that the bootstrap files can be successfully uploaded to the Storage Account.\r\n```", "this would have to follow the suggestion above\r\n``` suggestion\r\nstorage_allow_vnet_subnets = {\r\n```", "see suggestion below\r\n```suggestion\r\n  storage_allow_vnet_subnet_ids    = try(flatten([for v in each.value.storage_allow_vnet_subnets : [module.vnet[v.vnet_key].subnet_ids[v.subnet_key]]]), [])\r\n```", "Added a count condition to it to trigger only when the `bootstrap_storage` map variable is not empty and if the value of `storage_acl` is `true` :\r\n\r\n```\r\ndata \"http\" \"this\" {\r\n  count = length(var.bootstrap_storage) > 0 && contains([for v in values(var.bootstrap_storage) : v.storage_acl], true) ? 1 : 0\r\n  url = \"https://api.ipify.org\"\r\n}\r\n```"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/251", "comments": ["What do you think about adding blackhole for `appgw` subnet ?\r\n\r\n```suggestion\r\n          }\r\n          \"appgw_blackhole\" = {\r\n            address_prefix = \"10.0.0.48/28\"\r\n            next_hop_type  = \"None\"\r\n          }\r\n```", "The same here - what do you think about adding blackhole for `appgw` subnet ?\r\n\r\n```suggestion\r\n          }\r\n          \"appgw_blackhole\" = {\r\n            address_prefix = \"10.0.0.48/28\"\r\n            next_hop_type  = \"None\"\r\n          }\r\n```", "Could we define NSG for Application Gateway ?\r\n\r\n```suggestion\r\n      }\r\n      \"appgw\" = {\r\n        name = \"appgw-nsg\"\r\n        rules = {\r\n          allow_inbound = {\r\n            priority                   = 120\r\n            direction                  = \"Inbound\"\r\n            access                     = \"Allow\"\r\n            protocol                   = \"Tcp\"\r\n            source_address_prefixes    = [\"134.238.135.137\", \"130.41.247.15\"]\r\n            source_port_range          = \"*\"\r\n            destination_address_prefix = \"*\"\r\n            destination_port_ranges    = [\"22\", \"80\", \"443\"]\r\n          }\r\n          # required for application gateway: https://learn.microsoft.com/en-us/azure/application-gateway/configuration-infrastructure#network-security-groups\r\n          required_appgw = {\r\n            priority                   = 110\r\n            direction                  = \"Inbound\"\r\n            access                     = \"Allow\"\r\n            protocol                   = \"Tcp\"\r\n            source_port_range          = \"*\"\r\n            destination_port_range     = \"65200-65534\"\r\n            source_address_prefix      = \"GatewayManager\"\r\n            destination_address_prefix = \"*\"\r\n          }\r\n        }\r\n      }\r\n```", "After creating NSG for Application Gateway, we need to associate it: \r\n\r\n```suggestion\r\n        address_prefixes       = [\"10.0.0.48/28\"]\r\n        network_security_group = \"appgw\"\r\n```", "Could we please prepare description for `vmss` variable?", "nope, you do not define NSGs for AppGWs, you can if you really want to limit traffic, but normally an APPGW subnet is publicly open ", "no nsg for appgw, see above", "good point :D \r\n", "think of it from this perspective - you put an AppGW in front of an HTTP application (webpage, REST endpoint, etc). An HTTP app is normally available to anyone. If you want to hide it or you want to limit access to it, you do it internal. Of course you can come up with a scenario where IP filtering for a web page could be handy, but I'm guessing:\r\n1. we want to make this example simple\r\n2. there are couple of other/better methods to achieve it than limiting access by IPv4", "Ok, I understand your arguments. Of course my suggestion can be skipped. \r\n\r\nI was only thinking in the same way as we have currently for frontend LB, which has public IP, which is also for HTTP traffic and which have NSG assigned to protect traffic using rules based on IP addresses:\r\n\r\n```\r\nload_balancers = {\r\n  \"public\" = {\r\n    name                        = \"public-lb\"\r\n    network_security_group_name = \"example-public-nsg\"\r\n    network_security_allow_source_ips = [\r\n      #  \"x.x.x.x\", # Put your own public IP address here  <-- TODO to be adjusted by the customer\r\n      \"0.0.0.0/0\",\r\n    ]\r\n...\r\n```", "IMO we should skip that part as well, looks a little bit strange to put a *firewall* in front of a **Firewall**.\r\n\r\nOn the other hand, NSG is different, this is TCP/UDP traffic, this can be i.e. some Site2Site VPN setting that we want to open to specific IPs only. But for HTTP traffic I would say have it public", "ok, let's skip my code suggestion and do as you propose \ud83d\udc4d ", "\ud83d\udc4d\ud83c\udffd ", "Please update the README, in particular - there's only one sample `tfvars` file available for this example.\r\nSame with a few other READMEs for the examples.", "Parameter is called `subnet_name` but it actually refers a subnet key, which may be a bit confusing.  How about renaming it to `subnet` or `subnet_key`?\r\nSame with `vnet_name` above actually (although key and name are same there), subnet and lb references in vmsereis configurations.", "Nit: maybe use keys that more indivate a \"firewall\", than a \"vm\" here, like `fw-1`/`fw01`?", "The need for adding a name_prefix at module level can be mitigated in the \"glue code\", please refer to this example: https://github.com/PaloAltoNetworks/terraform-google-vmseries-modules/pull/182/files#diff-8fdcb1bfa2b32baa79c1716fd9558e3ef35f1ad0a13bc71267300689ddf9e206R64", "A static string is part of this name. Also in a few other AI related parts of the code:\r\nhttps://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/251/files#diff-9e1c24bf63ecdd30b06e538a06f020db09beae8d112e53baed683c79620f0cbfR127\r\nhttps://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/251/files#diff-9e1c24bf63ecdd30b06e538a06f020db09beae8d112e53baed683c79620f0cbfR166", "```suggestion\r\noutput \"natgw_public_ips\" {\r\n```\r\nOr `natgw_pips`?", "```suggestion\r\noutput \"vmseries_mgmt_ips\" {\r\n```", "There are no such files in the example.", "I think we should still keep it ignored and either use the \"*.sample\" approach or maybe make a simple template out of existing iinit-cfg files, if the goal is to make it as smooth for the end users as possible", "```suggestion\r\n        name = \"panorama-mgmt-nsg\"\r\n```", "```suggestion\r\n        name                   = \"panorama-snet\"\r\n```\r\nOr maybe `panorama-mgmt-snet`?", "```suggestion\r\noutput \"mgmt_ips\" {\r\n```", "I can see this suffix being added throughout the PR, in different modules. I think we should avoid any static suffixes in resource names whenever possible.", "\ud83d\udc4d\ud83c\udffb ", "I do not see a place where they could harm the code or usability. Especially that these are only names, we operate on keys everywhere, so the code does not depend on them. \r\n\r\nAnd it is more readable when you look in Azure portal. Keeping the naming schema, where each related resource get's a prefix in the form of the main resource + some suffix that usually describes a type of a resource groups the related resources together: \r\n![image](https://user-images.githubusercontent.com/42772730/234247998-5ffdb681-70f4-4d12-90a9-60996e2c8054.png)\r\n", "what we could do is work on keeping the suffixes the same across modules. Or even make them configurable, example: public IP get's `-pip` but you can overwrite it with a variable (one variable for all PIP suffixes)", "I was thinking about it, this is a management subnet and NSG, but in this example maybe you are right, this is the Panorama subnet and it is a dedicated Panorama example. No sense in complicating stuff.", "there is some inconsistency in the outputs. For examples I would say we should stick to plural. 90% of outputs are maps or lists. In this case it sounds more natural to make it plural. For resources that are single in nature (like `password` or `username`) - stick to singular. ", "Readme's are not done yet", "comment same as [here](https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/251#discussion_r1176312253)", "READMEs are not done yet", "done", "I think we can be opinionated here with the prefixes(ie. pip, nsg, etc.). I don't have a strong preference. If we need to have a variable to control the suffix let's do that via another PR", "Maybe instead of putting diagram in git repository, it's better to upload images into https://user-images.githubusercontent.com ?", "If we want to deploy 2 pairs of VM-Series with 2 different versions, then it's not possible. What do you think about defining PANOS version for each VM-Series group (inbound, outbound etc.) ?", "The same comment as for VM-Series - if we want deploy 4 instances of Panorama, from which 2 of them will be working in management mode in version X and 2 of them as loggers in version Y, then it's not possible with below configuration. ", "i thought about it to be honest, also in terms of usernames/passwords and other shared variables, but for the standalone VMs. I was reluctant then to add this possibility (I didn't want to multiply variables), but now when the code is meant to be flexible and we do multiply variables (like bootstrap options, for example) it might be a good idea \ud83d\udc4d\ud83c\udffb ", "done", "done, it's in the code and variables ,but I did leave the example simple, only one common version, I did add also a possibility to specify vm size per each VM/VMSS/PANORAMA", "same as above"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/249", "comments": ["I know it does not affect this module directly, but it affects the way we use the module in glue code - I would suggest to add the backend pool ID to the outputs of the `appgw` module. Otherwise, if we create the VMSS and AppGW in one module, we need to additionally source the AppGW to retrieve the backend pool ID. Additional step, not really required.", "```suggestion\r\n  description = \"Identifier of the Application Gateway's backend pool to associate with the public interface of each VM-Series firewall.\"\r\n```", "Thank you for review :) \r\nI prepared changes in outpouts for ``appgw`` module in #250 . Could you please review it too, please ?", "reviewed and merged"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/240", "comments": ["why do we explicitly set this to `null`", "This is the output example. However in output_rules in locals we set backend_port to null if it's not provided. That's because the NSG rules are created with a for_each over output_rules in which we specify the destination port to match with the backend port if provided, or to match the front end port if not provided. Related line:\r\n\r\nhttps://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/blob/239-support-for-frontend-and-backend-ports-in-loadbalancer-module/modules/loadbalancer/main.tf#L179\r\n", "Behaviour of functions `try` and `coalesce` is different, especially when `each.value.rule.backend_port` will have value `\"\"`. Should we here use `coalesce` instead of `try` ?", "Actually the `each.value.rule.backend_port` might not exist at all in the object. How about the following `coalesce(try(each.value.rule.backend_port, null), each.value.rule.port)` ?", "yes, you are right and your proposition seems to be the perfect one  ", "Thanks!", "\ud83d\ude33 you're right", "```suggestion\r\n  description                 = \"Auto-generated for load balancer ${var.name} port ${each.value.protocol}/${coalesce(try(each.value.rule.backend_port, null), each.value.rule.port)}: allowed inbound IP ranges\"\r\n```\r\n\r\nas `coalesce` does not work on non existing entities maybe we should use the same `coalesce(try())` combo also here", "Actually it's already there. backend_port is set to null with a try condition in the output_rules, and we are looping over output_rules.", "\ud83d\udc4d\ud83c\udffb "]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/229", "comments": ["```suggestion\r\n# --- VNET CONFIGURATION --- #\r\n```", "Shouldn't happen, but please verify the resource group will be retained if an existing resource group is used.", "```suggestion\r\n# --- LOAD BALANCING CONFIGURATION --- #\r\n```", "```suggestion\r\n# --- VMSERIES CONFIGURATION --- #\r\n```", "For clarity, let's use `backend_pool_name` instead. Otherwise, the user needs to have prior knowledge that [we are creating a backend pool with the load balancer name](https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/blob/9dfe470572d5b7b2e53cb8a30c43a116ea784870/modules/loadbalancer/main.tf#L119) and introduce a `backend_pool_name` after line #106\r\n\r\nNot related to this, but please fix the [variable description](https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/blob/9dfe470572d5b7b2e53cb8a30c43a116ea784870/modules/loadbalancer/variables.tf#L154-L156) to indicate that we are defaulting to load balancer name if a name is not provided for the backend.", "@migara this happens only in scenarios where AppInsights is deployed. Two resources are typically left. They are not created by Terraform. \r\n\r\nI also thought that since this is an example, not production code, we should just cleanup after our selves. Maybe a comment about that would nice.", "well, you're right, this name is confusing, but this is not the backend name, it's actually the load balancer name. If you look [here](https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/blob/228-examples-refactor-transit_vnet_common/examples/transit_vnet_common/main.tf#L133) you'll see that we are using the `backend_pool_lb_name` property to target a specific load balancer and then we just access it's backend pool ID. Backend name in this situation i never used.\r\n\r\nmaybe we should change it to something like:\r\n\r\n```suggestion\r\n        load_balancer_name = \"lb-private\"\r\n```\r\n\r\nThis change will have to be reflected of course also in `main.tf` and `variables.tf`. ", "> Shouldn't happen, but please verify the resource group will be retained if an existing resource group is used.\r\n\r\nIt will, this is used only when we create an RG with our code"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/227", "comments": ["Anything below 3.25 is not installable. That's due to some changes that will be introduced in 4.x but were already introduced in 3.x for compatibility. \r\nThis is (almost) a cosmetic change, but maybe it's worth to have it. \r\n```suggestion\r\n      version = \"~> 3.25\"\r\n```", "Anything below 3.25 is not installable. That's due to some changes that will be introduced in 4.x but were already introduced in 3.x for compatibility. \r\nThis is (almost) a cosmetic change, but maybe it's worth to have it. \r\n```suggestion\r\n      version = \"~> 3.25\"\r\n```", "`>= 0.15` -> i'm wondering how to deal with this, there is a PR pending that will pop up the minimum version to `1.0`. Question is: should we already include this change in this PR?", "`name` alone does not give a hint what this variable is defining.\r\n\r\n```suggestion\r\ngwlb_name                = \"gwlb-example\"\r\n```", "Maybe add some minimum description, type and defaults (if applicable) to all variables missing them. ", "Do we really need to output the whole frontend IP config? we do need only the ID and there will be only one, so maybe we can make this simpler?", "all components are optional, but there is no default value for this variable, hence you still need to define at least one property. \r\n\r\nMaybe add some default value that would work with the `try` statement in `main.tf`?", "```suggestion\r\n  Each tunnel interface specification consists of following settings (refer to [provider documentation](https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs/resources/lb_backend_address_pool#tunnel_interface) for details):\r\n```", "```suggestion\r\n  - `port`       - (Required|int) Interface port.\r\n```", "This might now work if you specify two maps, each with a different set of properties. \r\n```suggestion\r\n  type = any\r\n```", "```suggestion\r\n  description = \"IP addresses for VM-Series management (https or ssh).\"\r\n```", "I think that the convention we follow in other descriptions is that all resources are started with an upper case, like Virtual Machine, Public IP, Application Gateway, etc. \r\n\r\nIf this suggestion should be followed this kind of changes should done in other places as well.\r\n\r\n```suggestion\r\n  description = \"IP addresses of the application Load Balancer.\"\r\n```", "Done.", "Updated to `1.0`.", "Moved to `gwlb` variable.", "Variable descriptions/types updated.", "Updated to only output id.", "Updated.", "`VXLAN` protocol has been hardcoded, rest is mandatory, so now all items have to have same structure.", "Updated.", "Updated.", "`subnet_id` is actually required.", "Done.", "This is static map, do you maybe think to put it into the *.tfvars file? ", "I would say we can leave it like this. A refactor of all examples is coming. It would touch not only this map, but probably the rest of the code as well. Maybe it does not make sense to do a mix of new and all approaches as it might mean extra work at the end.", "and what if I do not want SSH keys? password as an option?", "and we do use Firewall's keys for application. Even though this is an example only, I would split them to 2 different variables", "check also possibility to do outgoing traffic with GWLB:\r\n\r\n* just sending outgoing traffic\r\n* utilising the outgoing rules", "Added password as an option and separate ssh_key settings for app vm.", "Added outbound traffic inspection using outbound rules.", "I'm worried about this - this changes are available on `main` already. This *diff* should not pop up here.", "```suggestion\r\nname_prefix         = \"example-\"\r\n```\r\n\r\nwe need this prefix fixed as we use it's value to replace it with `ghci` in CI workflows. `ghci` is used to identify all resources deployed during release testing when it comes to cleaning up the subscription after the tests. \r\n\r\nWhen we'll move to terratest this will become obsolete, but for now it's mandatory", "I would avoid braking the code structure we use in the other examples. The whole idea is that they are the same and you can literally use any example to deploy any infra by just changing the vars file.\r\n\r\nOf course there are some minor differences and probably we will not put GWLB into reference architecture examples, but the *common* code should be the same IMO.", "don't we need a peering between the two VNETs?", "```suggestion\r\noutput \"password\" {\r\n```\r\n\r\nto keep the convention\r\n\r\nAnd we do miss the `username` in the outputs.", "as per recent discussion -> these should be relative links\r\n\r\n```suggestion\r\n  All are used directly as inputs for `vmseries` module (please see [documentation](../../modules/vmseries/README.md) for details), except for the last three:\r\n```", "No, there's no need for direct connection between VNets, all communication is done via Gateway Load Balancer.", "Done.", "This has been cherry-piced from main actually. Fixed after a full rebase.", "Done.", "As discussed, for now only moving `interfaces` to per instance configuration.", "Done.", "<details><summary>\n<img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/high_new.svg\" alt=\"HIGH\" width=\"24px\" align=\"center\">&nbsp;&nbsp;<b style=\"color:black\" >Azure instance does not authenticate using SSH keys</b>\n            <br>\n            &nbsp;&nbsp;&nbsp;&nbsp;Resource: <a href=\"https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/blob/gwlb-support/modules/virtual_machine/main.tf#L47-L128\">module.appvm.azurerm_virtual_machine.this</a> | Policy ID: <code>806079733791502336_AZR_1680031706399</code> | Checkov ID: <a href=\"https://docs.paloaltonetworks.com/content/techdocs/en_US/prisma/prisma-cloud/prisma-cloud-code-security-policy-reference/azure-policies/azure-networking-policies/bc-azr-networking-1.html\">CKV_AZURE_1</a>\n            <br>\n            \n</summary>\n<h4>Description</h4>\nRefer the documentation for more details,\nhttps://docs.bridgecrew.io/docs/bc_azr_networking_1\n</details>", "@migara is there a way to skip some checks for this check? we do ignore them already in our checkov config"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/222", "comments": ["If we have default value for ``domain_name_label``, then can we skip ``try`` function ? ", "@alperenkose  in this form, when `var.domain_name_label` is not specified, you get the following input:\r\n```\r\nfqdn = {\r\n  \"public_appgw\" = tostring(null)\r\n}\r\n```\r\n\r\nWhich works, but doesn't look nice ;) \r\n\r\nAnd we never know how this will be treated in future provider versions. So maybe wrap it in some condition like:\r\n\r\n```\r\nvar.domain_name_label == null ? null : azurerm_public_ip.this.fqdn\r\n```", "normal behaviour "]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/221", "comments": ["Could we make it simpler e.g. ``coalesce(var.existing_pip_prefix_resource_group_name, var.resource_group_name)`` ? ", "In case, when ``create_pip_prefix`` is false and ``existing_pip_prefix_name`` is null, we just use ``try(data.azurerm_public_ip_prefix.this[0], null)`` as in line 73 ? Maybe we could simplify it by making ``create_pip_prefix`` local which is true only if variable ``existing_pip_prefix_name`` is empty ? ", "yes, why not. There were some problems with `coalesce` though, can't remember details. ", "1. I do not follow :) you would have to drop a code suggestion\r\n2. having this logic here gives two benefits:\r\n  * you call this data source only when you need to\r\n  * this condition documents itself (although it is hard to read ;))\r\n\r\nIf I understood correctly you want to simplify the condition and move part of the logic to a `try` statement further in the code. But this would brake both bullet points.", "I'm sorry for unclear description. I was mainly thinking about simplifying and making it easier to understand that condition by use local - then it's ready to catch that we are using data source if we are creating NAT GW and we want to use public IP prefix e.g.\r\n\r\n```suggestion\r\n  count = (var.create_natgw && local.use_pip_prefix) ? 1 : 0\r\n```\r\n\r\nwhere local is true on following condition:\r\n\r\n```\r\nlocals {\r\n  use_pip_prefix = !var.create_pip_prefix && var.existing_pip_prefix_name != null\r\n}\r\n```", "if there are problems with `coalesce`, let's leave it as it's ", "I would stick to the original code. We only split the logic into to places. If someone really wants to understand what is happening, one has to go to `locals` to figure it out.", ":+1: did coalesce as suggested"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/219", "comments": ["for whatever reason this throws an error when used in glue code (not observed during tests though):\r\n```\r\nError: Inconsistent conditional result types\r\n\u2502\r\n\u2502   on .terraform/modules/vnet/modules/vnet/main.tf line 23, in resource \"azurerm_subnet\" \"this\":\r\n\u2502   23:   for_each = var.create_subnets ? var.subnets : {}\r\n\u2502     \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\r\n\u2502     \u2502 var.create_subnets is true\r\n\u2502     \u2502 var.subnets is object with 3 attributes\r\n\u2502\r\n\u2502 The true and false result expressions must have consistent types. The 'true' value includes object attribute \"management\", which is absent in the 'false' value.\r\n```"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/210", "comments": ["I was thinking of how to deduplicate this part since we have it in all Makefiles.\r\nMaybe we can create one Makefile with all that options and we can pass it through \r\n`make -f ../Makefile TF_PARAMS='${TF_PARAMS}'` do you thing this is achievable? ", "achievable, but not for the moment. Having this duplicated gives you flexibility when moving module by module from plain commands to `terratest`"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/191", "comments": ["How about not adding a variable for a single key, but rather a set of key data - having only an option for a single key is rather a development/demo use case, in real world there will be multiple users. That's actually how it's done in GCP VM-Series module.\r\n", "I think that `password` var should no longer be a required one (ie. have a default set to `null`). Additionally, it would be good to document the fact that if password auth is disabled, then at least one key has to be specified (https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs/resources/virtual_machine#ssh_keys).", "good point, I've set `null` as the default for the `password` variable. ", "For the moment the code is supporting only a single account. Changing it to setup multiple accounts - that would be a conceptual change. ", "implemented", "We need to think about standardise how we use this statement, sometimes is:\r\n`for_each = var.ssh_key != null ? [\"one\"] : []` and sometimes it is `for_each = var.ssh_key != null ? [1] : []` :) ", "This is an old example, `[\"one\"]` is used in most of the loops, hence it follows this standard. But this will be addressed in #187 ", "Same point as in this thread https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/191/files#r984585354", "fixed", "```suggestion\r\nvariable \"ssh_keys\" {\r\n```", "```suggestion\r\nvariable \"ssh_keys\" {\r\n```", "`ssh_key` -> `ssh_keys`, updates made also in `main.tf`"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/179", "comments": ["I'd propose to use the latest possible versions from each branch or, at least, for 0.15. Additionally, let's either skip 1.0 in favour of 1.1 or test all 1.x branches.", "On linux (ubuntu) `find ...` results in a following warning:\r\n\r\n```\r\nfind: warning: you have specified the global option -maxdepth after the argument -type, but global options are not positional, i.e., -maxdepth affects tests specified before it as well as those specified after it.  Please specify global options before other arguments.\r\nfind: warning: you have specified the global option -mindepth after the argument -type, but global options are not positional, i.e., -mindepth affects tests specified before it as well as those specified after it.  Please specify global options before other arguments.\r\n```", "```suggestion\r\n      - name: run module validation\r\n```", "```suggestion\r\n      - name: run example validation\r\n```", "I'd propose to swap the two lines for a better ordered output (job name in this case).", "ditto", "Do we enable it? ", "at some point - yes, initially the idea is to run it manually and then merge it into the 'regular' ci/cd workflow", "the line is configurable and I set it up as an example, so let's have a bigger discussion how to set it up. We can step over each minor version, but then the output will be huge (for these 3 this is almost 50 steps to look at). On the other hand it does not hurt, we can do a very detailed check with this workflow.", "I've changed the name to be shorter and more descriptive, and this particular name will not get displayed anymore as it is a part of a local action", "same as with modules", "fixed", "this is not used for naming steps anymore", "so finally we do `tf_versions: 0.15 1.0 1.1 1.2` - this brings in the latest patch level from each minor version."]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/176", "comments": ["Maybe add validation? Some of `string` values in Azure are case sensitive (especially since provider v. 3.x), so it would make sense to check if the spelling is correct by verifying if the value is one of  `Standard_LRS`, `StandardSSD_LRS`, `Premium_LRS` or `UltraSSD_LRS`.", "shouldn't we add the same functionality to managed disks? For the moment the disk type is hardcoded [there](https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/blob/develop/modules/panorama/main.tf#L96).", "Good catch, I add that :) ", "I add Some logic, but there is a catch - since we add disks via map I add logic to specify disk type for each disks, but I drop validation here (It can look too complex in one line). "]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/175", "comments": ["Is `try(var.app_insights_settings.workspace_mode, true)` should be `try(var.app_insights_settings.workspace_mode, false)` ?", "`metrics_retention_in_days` default is set to null, not 90 \r\n`  retention_in_days   = try(var.app_insights_settings.metrics_retention_in_days, null)`", "ditto", "Is try(var.app_insights_settings.workspace_mode, true) should be try(var.app_insights_settings.workspace_mode, false) ?", "The old (standard) app-insights will be depricated on Feb 29th 2024. So the module is using the app-insights with workspaces as the default set. This is the reason of having `True` here. ", "True, the 90 is the azure default value if you set variable to `null`. But, I will change this description.", "Same as the previous comment, the workspace is used by default.", "what is the a default value here? a note on one would make things more clear", "if only one value is valid, why do we have this as param?", "how about dropping this property and using the `app_insights_settings` as a whole to trigger the AI creation? No one will ever specify:\r\n```\r\napp_insights_settings = {\r\n  create = false\r\n}\r\n```\r\n\r\nThe fact that one defines the map is enough to decide that AI should be created.", "do we need this explicit dependency? ", "And maybe an info that the `Classic` is deprecated and not supported in all locations would be nice (if the comment is not to long).", "maybe another example with minimum settings would be helpful - so that one would now how to set up AI with just the defaults.", "yeah, this explicit dependency is not needed here, will be removed.", "Sounds logical, so the simplest `app_insights_settings` declaration would be `{}`, and this will enable app insights with the default parameters", "yes and no, how to declare that you do not want any AI? `app_insights_settings = null`? or maybe leave the name as the required value?", "My plan is to set default value to `null`:\r\n\r\n```\r\nvariable \"app_insights_settings\" {\r\n  default     = null\r\n  type        = map(any)\r\n}\r\n```\r\nAnd in the module, the check would look like this:\r\n```\r\nresource \"azurerm_log_analytics_workspace\" \"this\" {\r\n  count = var.app_insights_settings != null\r\n```\r\nNow, the part I don't like. To enable the App Insights with the default settings, you need to define empty variable, like:\r\n``` app_insights_settings = {} ```\r\n\r\nis this approach OK?", "I would say yes? As long as it is documented. \r\nOn the other hand it is couter-schema, meaning that in other places we do use an empty map **not** to trigger a resource creation. \r\n", "This value doesn't have default value, either in resource itself since it is a optional value and in module codebase :) "]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/171", "comments": ["I think you can declare local variable and reuse that part **merge(var.frontend_ips, var.outbound_rules)**.\r\nIn if statement in OR ( || ) part is always dependent on the second argument:\r\n\r\n\r\n```\r\n> (!try(true,false) && !(true))\r\nfalse\r\n> (!try(false,false) && !(true))\r\nfalse\r\n> (!try(false,false) && !(false))\r\ntrue\r\n```\r\nSo you can simplify to ``!can(merge(var.frontend_ips, var.outbound_rules)[v.public_ip_name]))``\r\n\r\nIMO If you add new local value it will looks cleaner ", "your're right, simplified the bool logic + a local with combined rules was added"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/166", "comments": ["Let's get rid of the default value here", "Let's get rid of the default value here", "Perhaps match these tags to generic tags we use throughout the rest of the repo?", "It would be nice to add a `validation` block here ", "\ud83d\udc4d\ud83c\udffb ", "\ud83d\udc4d\ud83c\udffb ", "I actually removed the example values. This is what we have in other modules. This way it matches a pattern.", "\ud83d\udc4d\ud83c\udffb and tested", "```suggestion\r\nThis example covers creation of a single Storage Account with two File Shares: one for Next Generation Firewalls handling inbound traffic and one for firewalls handling outbound and east-west (OBEW) traffic.\r\n```", "I assume this one should be uncommented?", "```suggestion\r\n```\r\nWe can take the opportunity and remove this line.", "In this case it's not actually true - ie. that it holds files for bootstrap.", "```suggestion\r\nstorage_share_name   = \"bootdiagshare\"\r\n```", "\ud83d\udc4d\ud83c\udffb ", "\ud83d\udc4d\ud83c\udffb ", "Since we do not have default here, maybe we could add some validation?", "why we need this here?", "TF cannot resolve this dependency automagically?", "due to the way terraform resolves dependencies. Even though you use this:\r\n```\r\nexisting_storage_account = module.bootstrap.storage_account.name\r\n```\r\nTerraform tries to parallelise execution of both modules, most probably  because the `output` is set to a `local` instead of a resource (regardless the fact that this local refers to a resource under some condition).\r\n\r\nSo there are situation, where the module that creates only a File Share runs before the actual storage is available. Explicit `depends_on` solves the problem. ", "same as above", "yeah, good one, i'll look for Azure limitations ", "[validation added](https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/commit/971b922fcd25691216a7590dc6d0577d0046890e)", "```suggestion\r\n  description = \"Names of the File Shares within Azure Storage.\"\r\n```", "```suggestion\r\n  description = \"Identifiers of the File Shares within Azure Storage.\"\r\n```", "This variable is a required one, let's keep it in example.tfvars.", "not sure where this came from  - added back"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/160", "comments": ["```suggestion\r\n    List of IP CIDR ranges (like `[\"23.23.23.23\"]`) that are allowed to access management interface of Panorama.\r\n```", "```suggestion\r\n```", "Shouldn't this be `var.enable_zones ? var.avzones : null`? @pimielowski ", "@pimielowski can you please improve the variable description of `frontend_ips` to include the key `zones`?", "You are right, thanks :) ", "Sure, you are right, that one is clearly missing there, thanks!", "Fixed", "Fixed"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/156", "comments": ["This is a default, so I would propose to either skip it or softcode it to allow to provide other value.", "```suggestion\r\nvariable \"log_analytics_workspace_name\" {\r\n```", "```suggestion\r\nvariable \"application_insights_workspace_mode\" {\r\n```", "This is just an enhancement idea, but I thought that maybe we could change that creation condition based on retention days count to some `true/false` flag? Like we have in different modules. \r\nSomething like:\r\n```\r\ncount = var.create_appinsights && var.application_insights_mode_workspace ? 1 : 0\r\n```\r\n\r\nwith\r\n\r\n```\r\nvariable \"create_appinsights\" {\r\n  default = true\r\n}\r\n```\r\n\r\nBeing dependent only on number of retention days saves us one variable, but IMO it's not that obvious when using the module.", "Maybe change the order so that it fits other variables strucutre:\r\n```\r\ndescription\r\ndefault\r\ntype\r\n```", "Now, do we want that? We change the default behaviour by disabling AI. If i'm not wrong `null != 0`, therefore AI was always created and with retention set to `null` a default value from Azure was taken. \r\n\r\nNow seting this value explicitly to `0` we (by default) disable AI. This also adds to the comment in line `117` - do we really want to relay on this value for enabling/disabling this functionality?", "Agreed, I also thought about suggesting such an approach.\r\n\r\nAdditionally, apart from the conditional var, all other AI/log analytics/metrics variables could potentially be wrapped into a single map.", "A variable \\\"log_analytics_workspace_sku\\\" has been added in ac0d6871933d91ab81d96dbac38b404f4f9cb44f", "Variable name has been changed as suggested in ac0d6871933d91ab81d96dbac38b404f4f9cb44f", "variable name has been changed as suggested in ac0d6871933d91ab81d96dbac38b404f4f9cb44f", "I think a good idea would be to point to MS documentation, to a list of possible values. ", "You say `defaults to 30` but the default is `null`. I know that you probably meant the Azure defaults, but in this case I would suggest leave a comment like `defaults to Azure default value`. Azure default tend to change w/o notice.\r\n\r\nMaybe a link do documentation would also help. \r\n\r\nAnd please use multiline comment in this case (`EOF` style)", "same thing like for the `vmseries` module", "Agreed. Also, no need for the last sentence, since it's already stated in the line below :)", "What do you think about wrapping all configuration options for app_insight/log_analytics into one vairable of map type? All those are related to a single, common purpose in the modules.", "We bump up Azure version to 3.7.0", "Everywhere we use version 3.1 :) ", "We bump up Azure version to 3.7.0", "We bump up Azure version to 3.7.0", "We bump up Azure version to 3.7.0", "We bump up Azure version to 3.7.0"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/154", "comments": ["```suggestion\r\noutput \"load_balancer\" {\r\n  value       = azurerm_lb.lb\r\n  description = \"The load balancer object.\" \r\n}\r\n```\r\n\r\nHi there! It seems like you forgot to add a closing bracket to your output :)"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/148", "comments": ["I think that maybe it could be better to provide link to documentation with all values: https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs/resources/application_gateway#cipher_suites", "Wow, nice to see validation in use :) ", "New line :) ", "good point, fixed", "setting up the config is to complex to just depend on documentation :)", "\ud83d\udc4d "]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/138", "comments": ["Please removed commented out lines.", "This local value is no longer used, please remove it.", "fixed", "fixed"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/130", "comments": ["Hi @hanfil and welcome. Could you rename the new variable to something like `mgmt_pip_prefix_id` to clarify that it gets bound to the *mgmt* IP address, and not to the *public* (dataplane) address?", "Please run `pre-commit run -a` on the repository. I see that the README.md file did not get updated with the new variable of yours."]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/129", "comments": ["Definitely either `--ff-only` or `-r` option here. The raw pull can have *peculiar* results.", "This instruction (from here to the very end) can be easily a shared document in the [terraform-best-practices](https://github.com/PaloAltoNetworks/terraform-best-practices). The only thing that changes from one repo to the other is the repo name itself.\r\n\r\nI see no point in working on it on many separate repositories.\r\n\r\n\r\nAlso I dislike a lot that it is not framed as an example, but as a \"workflow\". So it's very official. This means an experienced newcomer is compelled to go through it initially, where in reality it can be shortened to \"use standard github practices and a bit of common sense\". How about framing it as an \"example contribution\"?", "What is `dev`?\r\n", "A second commit is not needed if you are using `pre-commit` locally.\r\n\r\n```suggestion\r\nThe first `git commit` attempt can show it is possible to show \"terraform-docs: Failed\". This is expected behavior, which occurs due to the `pre-commit` git hook. Simply look at `git status` and it should show changes to the `README.md` file. Issue `git add README.md` and then re-attempt `git commit`. It should pass.\r\n```", "If the wording is fine with you I will contribute a screenshot. This should be very visible.\r\n\r\nI would also place it in the doc in a way that makes sure that the \"experienced newcomer\" will see it. This is the only thing here which can easily trip anyone who didn't use file generation with pre-commit, no matter how much experienced with everything else on github.\r\n\r\nAlso, I really like the idea to fully automate terraform-docs in the CI/CT pipeline which we chatted about earlier."]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/126", "comments": ["I think it's better to only have the most usual attributes in the snippet here. Maybe remove from here and add ten lines above?\r\n\r\nI don't think `enable_ip_forwarding` should be the first thing a newcomer is seeing. It's quite niche.", "Updated", "\"Enable\" true allows any traffic, right?:\r\n\r\n```suggestion\r\n  - `enable_ip_forwarding`: If false, the network interface will discard packets sent to an IP address other than its own. True disables this and allows the network interface to receive any traffic.\r\n```", "Duplicated terraform-doc content starting from line 123 to the end of file."]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/123", "comments": ["While not mandatory, it's recommended to include a type constraint for a variable.\r\n\r\nActually, a number of vars here miss that.", "Fixed this var and more, good catch.\r\n\r\nThe vars which do not have a type now is because how broken is Terraform handling of `map(any)`."]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/122", "comments": ["The list below is missing tfsec.", "Although tfsec is present in the install.sh, it is not currently used by the pre-commit on this repo, see https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/blob/8a46c04fb56edb40886a5b0f6e16a5a0a87eb459/.pre-commit-config.yaml#L5-L9\r\n\r\nGood catch nevertheless! \ud83d\ude42 \r\n"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/118", "comments": ["```suggestion\r\n<!--- Include the output of `terraform version` and other relevant details about -->\r\n<!--- the environment you experienced the bug in -->\r\n```\r\n\r\nOne specific item that we'd probably always need to proceed is the `terraform version`. Its output also includes the azurerm provider version, which would be of interest."]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/115", "comments": ["```suggestion\r\n  description = \"Optional map of MD5 hashes. Normally the map should be empty, it is intended to be used for the files created in the same Terraform run as this module, which would not be automatically hashed. The keys of the map should be the same as the keys of the `files` input, while the values should be MD5 hashes generated from file contents. For example `{\\\"dir/my.txt\\\" = \\\"6f7ce3191b50a58cc13e751a8f7ae3fd\\\"}`\"\r\n```", "Uh, I've meant something else. Let me know how would the text below work for you?\r\n\r\n```suggestion\r\n  description = \"Optional map of MD5 hashes of file contents. Normally the map could be all empty, because all the files that exist before the `terraform apply` will have their hashes auto-calculated. This input is necessary only for the selected files which are created/modified within the same Terraform run as this module. The keys of the map should be identical with selected keys of the `files` input, while the values should be MD5 hashes of the contents of that file. For example `{\\\"dir/my.txt\\\" = \\\"6f7ce3191b50a58cc13e751a8f7ae3fd\\\"}`\"\r\n```", "@damianfedeczko  Any idea how to address that ugliness? Or is that explanation sufficient?", "Indeed, all clear now, thank you \ud83d\udc4d ", "```suggestion\r\nThe error message below indicates that one or more of the keys in the `files` input map are not valid - check the file name and the declared file path for possible misspellings or an invalid path reference.\r\nFor current versions of Terraform it is not possible to make this message more readable:\r\n```\r\n\r\nNit.", "```suggestion\r\nIf the file does not exist because it is supposed to be generated by the same Terraform run (such as a `local_file` resource), add the hash of its contents to the input `files_md5`.\r\n\r\nFor example `{\\\"dir/my.txt\\\" = \\\"6f7ce3191b50a58cc13e751a8f7ae3fd\\\"}`\"\r\n```", "@jabielecki I feel that this explanation is sufficient - but added 2 small suggestions to consider.", "Thanks, makes more sense now."]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/114", "comments": ["nit: What about putting the \"create_virtual_network\" before \"virtual_network_name\", so the user understands the available options just a liiiiitle bit earlier?", "Why do we select the inbound resource group for the Virtual Network here?", "What do you think about using the attribute references for the `location` and `address_space` of a pre-existing Virtual Network, if we decide to use it?", "Nit:\r\n```suggestion\r\n  name                = var.outbound_lb_name\r\n```\r\nor\r\n```suggestion\r\n  name                = var.olb_name\r\n```\r\nTo be compliant to the `olb_private_ip`.", "Nit:\r\n```suggestion\r\n  name                              = var.inbound_lb_name\r\n```\r\nor:\r\n```suggestion\r\n  name                              = var.ilb_name\r\n```", "Nit:\r\n```suggestion\r\n  Other possible metrics include `panSessionActive`, `panSessionThroughputKbps`, `panSessionThroughputPps`, `DataPlanePacketBufferUtilization`.\r\n```", "```suggestion\r\n  description = \"The address space used by the Virtual Network. You can supply more than one address space.\"\r\n```", "```suggestion\r\nvariable \"name_scale_set\" {\r\n  description = \"Name of the virtual machine scale set.\"\r\n  default     = \"VMSS\"\r\n}\r\n```", "Technically it makes sense. But in terms of education, I think it would be just too much for this example.", "True, thanks."]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/112", "comments": ["There is a fix on the module to allow a default `zone` here.", "Before, omitting zone on logging_disks always resulted in\r\nError: expected \"zones.0\" to not be an empty string and thus it\r\nhad effectively no working default value.\r\n\r\nNow the same input will default to the value of input avzone,\r\nso that the disk is placed together with the owning virtual machine\r\nand not susceptible to accidental zone separations.", "Should we do a small PR in other repos to update these versions on tflist and terraform docs ? ", "I've registered internal tickets for that, yes."]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/104", "comments": ["13,14,and 15, neat!", "this default is just so the example will run properly? ", "Yes, a static IP works is desired here. Potentially every spoke in its own tfstate is referencing it, so we need to be double sure it never changes (it would be an interruption to production traffic)."]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/103", "comments": ["The `.sample` files are named so to signify they are for education.\r\n\r\nDo not try to use them directly, and do not imply that users should\r\nmodify them for their further continued use. Tell users how to proceed.", "I simply don't want to pollute the user-facing changelog with a lot of breaking changes to `vmss`. It's far from being usable."]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/101", "comments": ["sensitive...", "As this example is **not intended to be copy-pasted** into maintainable\r\ncodebases, a majority of usual variables are inlined into the main.tf\r\ncode. This way users see everything together, which can aid their\r\nlearning.", "Create a very minimal example. It's the only one which is 0.12.29\r\ncompatible, because it does not employ module `depends_on` or module\r\n`for_each` anywhere.", "Doc was outdated.", "```suggestion\r\n  \"191.191.191.191\", # Put your own public IP address here, visit \"https://ifconfig.me/\"\r\n```\r\nnit: Since it's an educational example, maybe let's give a hint for the user how to quickly check the public IP address?\r\n", "```suggestion\r\n      network_security_group = \"management-security-group\"\r\n```\r\nnit: Maybe let's make this example more verbose for educational purposes, and use easily identifiable values instead of shortcuts?\r\n"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/100", "comments": ["Required before 2.46, produces a warning on 2.46+.", "\r\nThe sensitive outputs are best viewed with `-json` flag.", "If we pass an entire object and some attributes are provider-marked as sensitive, the 0.15 requires the entire object to be now sensitive.\r\n\r\nIt calls for adding a separate single non-sensitive module's output (one object with attributes manually copied) or multiple outputs (each attribute becomes a separate module's output).", "Why aren't we pinning the `azurerm` provider to version `2.58` here? From what I've understood, every version older than 2.46 will be pinned that way. Please ignore the following comments if I didn't understood your intention correctly.", "Ditto.", "Ditto.", "Ditto.", "Ditto.", "Ditto.", "Ditto."]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/99", "comments": ["bugfix, input storage_share_name was ignored previously", "refactor(loadbalancer): use map key\r\n\r\nThe `azurerm_public_ip.this[k].name` is always equal to `k`, hence the expression\r\nbecomes much simpler.", "Make `rules` optional for convenience."]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/98", "comments": ["```suggestion\r\n{\r\n  \"frontend01-balancessh\" = {\r\n    \"fipkey\"      = \"frontend01\"\r\n    \"frontend_ip\" = \"34.34.34.34\"\r\n    \"index\"       = 0\r\n    \"port\"        = 22\r\n    \"protocol\"    = \"tcp\"\r\n    \"rulekey\"     = \"balancessh\"\r\n  }\r\n}\r\n```", "Yikes, leftmost columns 1 and 2 break the `<<-EOF` convention, but I see what you mean:\r\n\r\n```suggestion\r\n  {\r\n    \"frontend01-balancessh\" = {\r\n      \"fipkey\"      = \"frontend01\"\r\n      \"frontend_ip\" = \"34.34.34.34\"\r\n      \"index\"       = 0\r\n      \"port\"        = 22\r\n      \"protocol\"    = \"tcp\"\r\n      \"rulekey\"     = \"balancessh\"\r\n    }\r\n  }\r\n```", "Perhaps add something along the lines `autogenerated`  to the description\r\n", "Should we highlight that these rules are auto generated / do not touch in the rule name? Just to make the user aware so that they will not alter these rules to find out they get overridden during the next apply", "ok", "ok"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/96", "comments": ["Using this module, can you `terraform apply` an example successfully on version 0.15.0? I'd be much surprised, which is why I ask.\r\n\r\nMaybe let's do that in a separate PR, even if solely for Changelog-related reasons.", "Good catch, Azure says \"Use Standard SKU public IP for Availability Zone scenarios\".", "This is the version I have installed:\r\n```bash\r\n$ terraform version\r\nTerraform v0.14.3\r\n+ provider registry.terraform.io/hashicorp/azurerm v2.56.0\r\n+ provider registry.terraform.io/hashicorp/random v3.1.0\r\n\r\nYour version of Terraform is out of date! The latest version\r\nis 0.15.0. You can update by downloading from https://www.terraform.io/downloads.html\r\n```\r\n\r\nTerraform apply with TF 0.15.0 below, didn't work prior to the change:\r\n```bash\r\n$ terraform apply -auto-approve\r\n\r\nmodule.panorama.azurerm_managed_disk.this[\"disk_name_1\"]: Refreshing state... [id=/subscriptions/137***016/resourceGroups/salsop_panorama/providers/Microsoft.Compute/disks/pano-deploy-disk-disk_name_1]\r\nmodule.panorama.azurerm_public_ip.this[0]: Refreshing state... [id=/subscriptions/137***016/resourceGroups/salsop_panorama/providers/Microsoft.Network/publicIPAddresses/ip]\r\nmodule.panorama.azurerm_network_interface.this: Refreshing state... [id=/subscriptions/137***016/resourceGroups/salsop_panorama/providers/Microsoft.Network/networkInterfaces/mgmt]\r\nmodule.panorama.azurerm_virtual_machine.panorama: Refreshing state... [id=/subscriptions/137***016/resourceGroups/salsop_panorama/providers/Microsoft.Compute/virtualMachines/pano-deploy]\r\nmodule.panorama.azurerm_virtual_machine_data_disk_attachment.this[\"disk_name_1\"]: Refreshing state... [id=/subscriptions/137***016/resourceGroups/salsop_panorama/providers/Microsoft.Compute/virtualMachines/pano-deploy/dataDisks/pano-deploy-disk-disk_name_1]\r\n\r\nApply complete! Resources: 0 added, 0 changed, 0 destroyed.\r\n```\r\n", "Oh, a misunderstanding. Please do not try to `apply` a module. That is not how it is supposed to work. Test a module as used in the example:\n\n```\ncd example/panorama\nterraform init\n\n  Error: ...\n\n```\n\nIf you'd like to have 0.15.x, I'd suggest to do it in a separate PR, even if solely for Changelog-related reasons.", "Yes, you're correct that errors as the TF Example have a version constraint of `required_version = \">=0.13, <0.14\"` also, I have not changed this, but I can update this also to match as needed?", "I was thinking to not to tie 0.15 support to a bugfix regarding the Standard SKU IP. These are not related changes, am I right?", "Yes, unrelated, I just needed TF 0.15 so added in this. How do I remove this single change? Or can you just approve the other change? Or do I need to do a whole new Pull Request?", "The simplest way on GitHub is to use the first icon when typing a code review comment. The icon that says `Insert a suggestion <ctrl+g>`. I am doing it right now for you:\r\n\r\n```suggestion\r\n  required_version = \">=0.12.29, <0.14\"\r\n```", "If you could `Commit suggestion` now, I'll gladly approve \ud83d\udc4d "]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/95", "comments": ["I'm doubtful of any explicit depends_on by now. I wonder if it will cause any strange problems down the road or not. Honestly it has bitten me so many times.", "Let's operate on facts, not feelings. Our vmseries with loadbalancer modules doesn't teardown properly. Point and document any use case that it might raise other issue or just write an issue to azurerm repo and ask them for repair, but for now we need fix for it.", "All right, you seem optimistic about it after all. What situations did you test? I mean possibilities like: Destroys? Modifications? Additions (i.e. add new interface with lb_ba_pool when some interfaces already exist)? Were there any errors?\r\n\r\nWhen I have not seen any tests, I have defaulted to veto. Don't get me wrong, if this approach actually solves the problem and does not add a worse problem, I will decidedly agree and change my vote."]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/94", "comments": ["We can now use the Registry syntax. It would be best to update all the snippets with this one. The previous github syntax has no version, which is horribly unstable.", "The snippet was outdated by a lot.", "The `try(1)` is exactly the same as `1`. For the try() to do anything,\r\nit needs to have two or more arguments: `try(1, null)` or `try(1, 2, 3,\r\n4)`", "Avoid `\"false\"` which has type `string`, to be compared to `false`, which has\r\ntype `bool`. This way if user uses `\"False\"` capitalized the behavior\r\nwill be saner.", "\ud83d\udc4d\r\n\r\n...but ;-) in examples related to a single module only, maybe we could use \"latest\" tag or sth like this?", "Missing \"sensitive\"", "Ummm... I'd rather not?", "I'd rather not mix different changes. This PR is not for 0.15 preparation."]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/92", "comments": ["I wonder what Ref-Arch guides say about private-subnet NSG. Is there anything needed there?\r\n\r\nPractically the private subnet does not need any NSG rules. The subnet already allows traffic from itself to itself/spokes via the default rules.", "This PR incorporates also commits from the parallel PR. I cannot easily change this now \ud83e\udd15  Please ignore anything related to `avzone` and `avset_id` when reviewing this. Apologies.", "Just moving the same code around.", "Cumbersome way to specify \"ingress allowed from the same networks for data as for management\". Needs further refactoring.", "Sovled: changed the base to dummy and back \ud83d\udc4d ", "Ref-Arch guide shows allowall, but says that user should apply more stringent rules.", "```suggestion\r\n    [var.network_security_groups.sg-mgmt.rules.vm-management-rules.source_address_prefix]\r\n```\r\nThis way the variable type is satisfied when using a string to define the `source_address_prefix`", "I've added a lot of  `sensitive` attributes. These are required by tf-0.15 and allowed by tf-0.12.29 and above.", "mgmt is done inside main.tf", "because it is  `sensitive`", "I didn't divide sku into inbound and outbound, because that's a very unlikely use case (to use bundle1 for inbound and byol for outbound).", "Avoided that big `try()` altogether, too ugly for my taste.", "Good idea. But do we need to mark every output as `sensitive`?\r\nIt's really cool for passwords and things that are internal only.\r\nBut it could be maybe nice to have some names in logs?", "```suggestion\r\noutput \"mgmt_ip_addresses\" {\r\n```", "```suggestion\r\noutput \"frontend_ips\" {\r\n```", "```suggestion\r\noutput \"mgmt_ip_addresses\" {\r\n```", "```suggestion\r\n  direction                   = \"Inbound\"\r\n  access                      = \"Allow\"\r\n```", "\ud83d\udc4d  I like the \"base priority\"", "Maybe some information, that \"admin\" is not allowed here?", "Do we need these specific (and commented out) IP ranges?", "Maybe we could correct \"lb_backend\" and similar names to \"this\" in this PR?", "Cannot we assume that all vmseries (inbound and outbound) have the same version and vm_size since they must have the same sku?", "These are required by tf-0.15 and allowed by tf-0.12.29 and above. We want 0.15.", "We can assume it, sure.", "done", "done", "My mistake, yup.\r\n```suggestion\r\n```\r\n", "Good point", "```suggestion\r\n  description = \"Initial administrative username. Do not use names admin and root, they are both insecure.\"\r\n```", "Nope. Too scary.", "Next pull-request, sure.", ":basecamp: "]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/91", "comments": ["Is this workflow approved anyhow? It can be only my feeling, but the \"Contact Sales\" note on an open-source repository \"Getting Help\" section feels a little bit... weird.\r\n\r\nI also feel that first paragraph can be easily hooked up under the \"Contributing\" section.", "All this was discussed between me and Migara on a PR that introduced this README. We had a plan at that time, but forgot to put it later in a Jira ticket.", "Scott asked for this \"contact sales\" in TERRAM-54.\r\n", "Thanks for clarification Konrad, noted \ud83d\udc4d  \r\n\r\n```suggestion\r\nFor consulting support, please contact [Sales](services-sales@paloaltonetworks.com) or your [Palo Alto Networks](https://www.paloaltonetworks.com) Account Manager.\r\n```", "Alternative wording to Damian's. I don't like capitalization, because it makes it more corpo-speak. Also reveal the email as an email:\r\n\r\n```suggestion\r\nFor consulting support, please contact services-sales@paloaltonetworks.com or your Palo Alto Networks account manager.\r\n```\r\n\r\ncc: @sokupski"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/90", "comments": ["Remove Availability Set from the example. Azure says it has much lower\r\nSLA than zones. The drawback is that some weaker regions do not support\r\nzones yet.", "The old advice is not relevant anymore in Azure cloud.\r\n\r\nThe limitation with AZ is quite strong, so note it visibly here.", "Availability Set =! zones. it is for different purpose.\r\n\r\n\"Ultimately, availability zones are used to protect applications from entire Azure data center failures, while availability sets are used to protect applications from hardware failures within an azure datacenter.\"\r\n", "If you have a way to use both Set and Zone at the same time, this would be very interesting. Would you make a quick draft PR? I think they simply cannot be used together.", ">A VM can be replicated across two or more Availability Zones. You define this when creating a VM. At that point, you must decide if the machine will be part of an Availability Set (AS), which does not provide redundancy across Availability Zones, or within an Availability Zone (AZ), which does guarantee multi-AZ redundancy.\r\n\r\n[Source](https://cloud.netapp.com/blog/azure-availability-zones-an-in-depth-look)"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/89", "comments": ["That is *hugely confusing* for any user. Let's use a standard Azure VM module here, not ours. We just need some Ubuntu, right? Maybe it's less familiar to us. However this part of example is the most important in user's worldview - it is their \"app\" that they hope to secure.", "Much more expensive, why this change?", "Per meeting, Ref-Arch has the entry here. (As well as many \"None\" routes.)", "I was thinking about this, it would be much cleaner to use official repo. I can change it.", "First I need tests scenarios for what version somehow has issue with bootstraping, until now not sure why for me 9.1.3 bundle1 doesn't bootstrap correctly. ", "9.1.3 always bootstraps well for me, both byol and bundle1.", "and then I realized we have the same issue with vnet module etc... so changing only one resource doesn't make sense for me ;) This is only example, should be good enough and support custom image or different OSes. Moreover spoke vm machine example allows us to do more scenarios with this modules in real life. ", "There is no issue with vnet module. I think vnet will be clear for a user. You call a module called vnet to build a virtual net. Makes sense.\n\nBut calling something named `vmseries` to spin up Ubuntu, that's simply confusing. If you want to create a test code, please do not put it in the `examples` directory, that's all. The directory illustrates to the public the proper usage of our modules. Lets keep the confusing types of usage out of sight.", "Looking at other spoke vars, maybe it would be better to call this one something like `spoke_nb_public_ip`. Otherwise users may be confused whether it is about Ubuntus or about VM-Series.\r\n\r\n", "Users may be confused whether it is about Ubuntus or about VM-Series. Since this example works with one VM and there is no obvious need for a second VM (there is no private spoke LB anyway), I'd just hardcode it as 1 and remove variable?\r\n\r\n```suggestion\r\n```", "This was needed for the traffic to pass when I deployed it:\r\n\r\n```suggestion\r\n        next_hop_in_ip_address = \"10.110.0.21\"\r\n```", "```suggestion\r\n  description = \"Definition of Route Tables to create. Refer to the `vnet` module documentation for more information.\"\r\n```", "```suggestion\r\n  description = \"Definition of Subnets to create. Refer to the `vnet` module documentation for more information.\"\r\n```", "```suggestion\r\nvariable \"spoke_vm_size\" {\r\n  description = \"Spoke VM size (type) to be created.\"\r\n  type        = string\r\n  default     = \"Standard_DS1_v2\"\r\n}\r\n\r\nvariable \"spoke_vm_name\" {\r\n  description = \"The VM name in Spoke Vnet.\"\r\n  type        = string\r\n}\r\n```", "Somehow it became `VNet` again, while our module is uncapitalized `vnet`. Altogether in this PR in four different places.", "Microsoft's comment is not really helpful or I can't understand it all to well. Maybe:\r\n\r\n```suggestion\r\n  description = \"Set to 0 to not assign any public IP addresses to a spoke Virtual Machine. Set to 1 to create a new Public IP and assign it.\"\r\n```\r\n\r\nOr alternatively make it a true/false instead, whatever works for you."]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/88", "comments": ["`my-stack` was informative for users, empty value isn't.", "`123456789012345` is informative for users (i.e. formatting it as a bare number `123` instead of `\"123\"`, and disambiguating from the `authcode` which can be easily mistaken to go here).", "Ah wait, do you mean that users should just run bootstrap.xml and forget about Panorama? But how would they possibly know that?", "my-stack doesn't exist anywhere, ip address either why customer should bother with that ?", "hardcoded number from nowhere can affected deployment of vm-series in next releases and it will be very hard to troubleshooting ", "Realistically, what are the actual steps that you think user will take to get a *working* VM-Series after this PR? Because the `terraform apply` right now does not load init-cfg.sample.txt. It specifically points to a non-existing init-cfg.txt instead. This is on purpose.", "Is this a problem with the PR or is the original user story incorrect? ", "I updated documentation to point source of truth. According to documentation for 9.1 version our init-cfg is wrong. Maybe because it has not been tested enough ;), please approve.", "I've re-reviewed and I still do not see how is this change is improving anything. The `*.sample.*` file is named so to be illustrative for users. It is not intended to be used for any testing scenario - maybe we need a different file for a testing scenario, I do not have a problem with the idea.\r\n\r\nIf user sees only this:\r\n```\r\nvm-auth-key=\r\n```\r\nThey may put:\r\n```\r\nvm-auth-key=I11223344\r\n```\r\nOr maybe\r\n\r\n```\r\nvm-auth-key=\"I11223344\"\r\n```\r\n\r\nOr maybe\r\n```\r\nvm-auth-key='123456789012345'\r\n```\r\n\r\nThese are *all* wrong ideas, despite being plausible. If the same user sees this:\r\n\r\n```\r\nvm-auth-key=123456789012345\r\n```\r\nThey will probably understand what can they put here, because they have a full example.\r\n\r\nBy *user* I mean me, next month.\r\n\r\nIf you claim that the docs page is more readable, yes, we could use as well this:\r\n\r\n```\r\nvm-auth-key=7550362253****\r\n```\r\n", "It's a sample to illustrate a typical situation, when bootstrapping from a Panorama. Customers do not have to bother themselves, it is a convenient sample - not a part of some tailored solution."]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/87", "comments": ["Remove unused input `create_storage_account` bool.", "Location is not null by default.", "Remove whole example\r\n\r\nThis example is presently broken. No worries, it can be re-introduced by\r\nbasing a branch on the git commit id of the parent of this commit.", "Ensure users prepare the files.\r\n\r\nDefaulting to *.sample files can confuse user into editing them\r\nin-place. Instead we should encourage them to copy to proper names.\r\nAs with example.tfvars, we want to avoid committing the copies into the\r\ngit (especially not authcodes!).", "Users do not have anything interesting to tweak in the outbound load\r\nbalancer. Removing it from tfvars to greatly simplify code.\r\n\r\nThe inbound frontends are very interesting to users, to the point that\r\nthey may be even confused thinking that \"private_frontends\" also refer\r\nto the inbound traffic, but to the private IP addressing. (Which is not\r\nthe case.) Hence naming the input just \"frontend_ips\".", "One module, one backend. Typical use case for VM-Series.", "Consistently use inbound/outbound for loadbalancers, as the Reference Architecture does, instead of public/private terminology.", "### consistent naming thing_name\r\n\r\nUse everywhere the same convention as `backend_name` or\r\n`resource_group_name`. Hence now `probe_name`.\r\n\r\nAs in other modules, the core object just has an input `name` (instead\r\nof `lb_name` or the existing `name_lb`).", "Allow both destination_address_prefixes and destination_address_prefix.\r\nThe former is the main use case, as our examples typically need two\r\nranges: 10.0.0.0/8 and user's public IP."]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/85", "comments": ["```suggestion\r\n  location            = var.location\r\n  resource_group_name = var.resource_group_name\r\n```", "```suggestion\r\n  sku                 = \"Standard\"\r\n```", "```suggestion\r\n  sku                 = \"Standard\"\r\n```", "Yeees. I've got my next pull request with this change, I'll make sure it's there.", "Yeees. I've got my next pull request with this change, I'll make sure it's there.", "Yeees. I've got my next pull request with this change, I'll make sure it's there."]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/84", "comments": ["There's still management_ips in variables.tf and example.tfvars", "Why? How do you configure no prefix at all?", "`management_subnet` does not exist", "Is the `management_ips` still needed?", "Do we use it?", "Removed, thank you!", "No we don't - removed, ty!", "Removed the whole `subnet` comment section, there is a reference to check the VNet documentation for more information regarding subnets.", "Nit: These lines of the example showcase how unwieldy is the `vnet` module.", "Is this line needed?", "How about this?:\r\n\r\n```suggestion\r\nvariable \"vnet_tags\" {\r\n  description = \"A mapping of tags to assign to the created virtual network and other network-related resources. By default equals to `common_vmseries_tags`.\"\r\n```", "Needs a comment/description - \"external peering access\".", "Nit: These routes are insecure. There is a Jira issue for this already (aka blackholing). Next pull request, not this one.", "When you have an empty state (after `tf destroy`) does the next `tf destroy` work or throw an error? Workaround possible:\r\n\r\n```suggestion\r\n      subnet_id           = lookup(module.vnet.subnet_ids, \"subnet-mgmt\", null)\r\n```\r\n\r\nDitto remaingin two subnets \r\n```", "Let's keep it! Btw. don't use the name `tags` above, there is another comment of mine about it.", "Will keep it - talked with Lukasz, he will reach out to Migara regarding this topic.", "I only removed the `-` suffix from the default value because it was responsible for creating a double-dash-name for the Resource Group, so by default, when using:\r\n`\"${var.name_prefix}-vmseries-rg\")`\r\nThe default Resource Group was named `pantf--vmseries-rg` which is a little bit ugly. I've now adjusted the rest of the variables to create the resources name in a `name_prefix` `-` `something` - `suffix` way, which is more clear, like:\r\n`\"pantf-fw01-public\"`\r\n`\"pantf-vmseries-rg\"`", "Not needed when creating only on VNet, didn't noticed that after deleting the second virtual network, thanks!", "Good with me.", "Noted!", "Thanks for that, appreciate the help", "This NSG is attached to both, public and private subnets.\r\n1) I'm not sure if we should open everything on public interface\r\n2) I don't like naming \"public-xxx\" if it is also attached to private subnet", "Let's capture it in a Jira issue like discussed on Slack and decide how to improve that on a next PR \ud83d\udc4d "]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/82", "comments": ["If the module supports Terraform v0.12.29, wouldn't we want to have the same version support in our example? Asking for a friend.", "Yes, we want that. Good catch btw. If you review an entire example, there is still one module-level `depends_on` that cannot be removed atm. One more PR needed for that."]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/80", "comments": ["Should we extend the logic a bit more so that we can catch cases where customer specify\r\n```\r\nhigh_availability = {\r\n  avzone = 1\r\n  avset_id = <id>\r\n}\r\n```", "I thought about it and experimented, but there is actually no benefit:\r\n\r\n- still as `<id>` is dynamic, the validation counter-intuitively happens in the middle of `apply`, not during `plan`\r\n- so, no benefit of early detection\r\n- We'd be intruding into azurerm behavior. I see no reason why azurerm in next minor version wouldn't allow to have both avzone and avset for the same vm. (Other than it would be actually user friendly.) So, even less benefit."]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/76", "comments": ["You can now remove `depends_on` and use the `location` variable :)", "In line 94 you use a hardcoded value - you know my opinion on that from PR75 - please pick one approach and stick to it :)", "If we leave the location, can the `depends_on` argument be removed also here?", "I think we can get rid of this comment.", "Same here, the comment below explains whats going to happen, no need to have both of them.", "```suggestion\r\n  description = \"PAN Device password.\"\r\n```", "```suggestion\r\n  description = \"Total number of VM-Series instances to deploy per direction (inbound/outbound).\"\r\n```", "Have you test removing depends_on apporach ? - it rises exception\r\n\r\n```\r\nError: Error: Resource Group \"lucaVMSSexample\" was not found\r\n\r\n  on ../../modules/loadbalancer/main.tf line 1, in data \"azurerm_resource_group\" \"this\":\r\n   1: data \"azurerm_resource_group\" \"this\" {\r\n\r\n```", "Kuba has a PR for making the `location` input variable obligatory to ditch the `depends_on` in the VNet module - check this out - https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/77", "It is not the scope of this PR - changing any module, only example regarding legacy loadbalancer. If there is PR 77 there should be change this behavior. ", "Sorry but you have already approved it in different PR - https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/71 - and because i rebase from Konrad branch you see his changes ;) It is not my part - i want close only legacy loadbalancer here - not refactoring.", "use blame function again ....", "use blame function again ....", "use blame function again ....", "So basically you want to update the example in a way that is going to be obsolete, cuz PR77 is going in any moment now.", "done", "PR 77 TERRAM-50 fix(vnet) - points vnet - for vmss and loadbalancer - need to be generating separate PR. In one PR will will not solve everything and generate huge PR. ", "Let's have it as is, we'll need to remove depends_on later. No biggie.", "Can you put it into example.tfvars for simplicity and use `create_public_ip = true` there?\r\n", "\ud83d\udc4d ", "We can keep for now and remove later.", "It's interesting to think about how the PR's affect each other. It is a key point in continuous integration, keep the PRs small and merge often because there can be a lot of interdependency. "]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/75", "comments": ["Maybe `name_lb = var.outbound_lb_name` ?", "```suggestion\r\n  description = \"Name of the Resource Group to use.\"\r\n```", "I wouldn't focus to much about variables in example. The simple example should present baseline, how to use the module.", "But why not? It's a simple change, which allows the example to be more adjustable. Please remember that someone can actually take this example from the repository and deploy it. And I can imagine that something like a loadbalancer name would be a thing that the majority of the users would like to change. And this would be much easier to do via a variable than changing a hardcoded value. Thats my opinion.", "This is example code, but at the same time customer-ready code. I think we should keep the coalesce and the local.resource_group_name. This is a very common brownfield requirement (i.e. \"we already have our own RG for this deployment\").", "Per the details in TERRAM-50, please keep the `location` anyway:\r\n\r\n```suggestion\r\n  resource_group_name = azurerm_resource_group.this.name\r\n  location            = var.location\r\n```", "Per the details in TERRAM-50, please keep the `location` anyway:\r\n\r\n```suggestion\r\n  resource_group_name = azurerm_resource_group.this.name\r\n  location            = var.location\r\n```", "Customer-ready code: they always need to specify various aspects of load balancers inside the tfvars. I'm afraid it will not fly as a `local`.", "The first line in the vnet example points 'greenfield deployment', and we discussed many times that the examples should only do support greenfield, so your comment doesn't make any sense for me ;) ", "Do you have any proposal for the example if in the main.tf the clients want to create resource and reuse it in the frontend_ips later (public ip etc) ?", "yes and no, the motivation is ok, but let's look at official approved repositories from other parties. https://registry.terraform.io/modules/Azure/network/azurerm/latest - no one ask you to find variable file and check out what was set in specific variable - in the examples it is hardcoded. I will change it but we waste time on those cosmetics.", "But you are missing the context just saying to \"look at other repositories\" - we will use our examples during customer engagements, and I will need to change that hardcoded value. So it's not cosmetics, and it's not a waste of time - it's making our lives a little bit easier in the long run.", "examples for public repo != examples for customer/brownfield deployment.\r\nBut there should be one full fledge baseline E2E example for customer engagement you are referring to and for CI testing purpose as well. It should be priority here. ", "We have to agree to disagree. And the E2E topic is out of the scope of this discussion and this PR.", "All right then, closing this thread.", "The basic pattern is: `for_each = {for k, v in var.frontend_ips: k => { ... add dynamic stuff here ... } }`", "```suggestion\r\n  description = \"Name of the public-facing load balancer.\"\r\n```", "```suggestion\r\n  description = \"Name of the private load balancer.\"\r\n```", "```suggestion\r\n  description = \"The name for public IP address to create for the public-facing load balancer.\"\r\n```", "Nitpick: Private works better with a static address. If we add a spoke in a separate tfstate (or done manually outside of terraform), it is a lot of hassle to pass the dynamic next hop ip (with acceptably short downtime).", "Glad you've noticed it :)", "Users don't know if you expect the thing to exist or if you are creating it.\r\n\r\n```suggestion\r\n  description = \"Name of the Resource Group to create.\"\r\n```", "You know, if you'd like, maybe just `create_public_ip = true`. Why bother.", "Agree on the usage of `Static` here", "Let's keep this example as simple as possible. Since we are treating this as a greenfield example why not introduce a few more static variables here?\r\n\r\n```\r\nvar.backend_name\r\nvar.backend_port\r\nvar.create_public_ip\r\n```\r\n\r\nThen get rid of the `local` block in the `main.tf` file. Simply use the above static vars inside the module\r\n....\r\n\r\n", "```suggestion\r\n  sku                 = \"Standard\"\r\n```", "```suggestion\r\n  sku                 = \"Standard\"\r\n```", "I'll do it myself then."]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/74", "comments": ["nit: I think this should be `sh` not `bash` (but I could be wrong)", "Works both ways :)"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/71", "comments": ["```suggestion\r\nresource_group_name = \"vmss-example-rg\"\r\nlocation            = \"East US\"\r\nname_prefix         = \"vmssexample\"\r\nvmseries_count      = 7\r\n```\r\n\r\nFormatting", "<Everything below this line>\r\nDo we need all of those security groups, routes and subnets for this example?", "Let's remove the comments?", ">  Do we need all of those security groups, routes and subnets for this example?\r\n\r\n@migara has a strategy on this one that we can discuss off line. Perhaps we do need to remove these things. ", "Please do run `terraform fmt` :)", "Have you consider add SSL port ? to access to vm-series console ?", "and the output can contain array of public ip for vm-series scalesets ", "There is a parallel PR which requires this:\r\n\r\n```suggestion\r\n  resource_group_name     = azurerm_resource_group.this.name\r\n  location                = var.location\r\n```\r\n\r\nCould you please add it at this point? More details in TERRAM-50.", "Todo :)", "Not needed once you add `location`, see TERRAM-50.", "rm 2 empty lines", "For consistency:\r\n\r\n```suggestion\r\nmodule \"inbound_bootstrap\" {\r\n```", "For consistency:\r\n\r\n```suggestion\r\nmodule \"outbound_bootstrap\" {\r\n```", "Same var.files, but two different file shares? Why?", "\ud83d\udc4d ", "```suggestion\r\nmodule \"inbound_scaleset\" {\r\n```", "Don't delete. Just add to vmss the inputs:\r\n\r\n```\r\nimg_sku = var.vmseries_sku\r\nimg_version = var.vmseries_version\r\n```\r\n\r\n"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/70", "comments": ["Delete? Looks unused.\r\n```suggestion\r\n```"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/62", "comments": ["I would use bullets (instead of numbers) here.", "Affirmative, changed that in other 3 PRs."]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/57", "comments": ["Operational nitpick: Next time try this:  delete the files in the first commit. Rename the files in the second commit. Modify the files in the third, fourth, etc, commits. This way `git log` will have a chance to apply some \"magic\". It can detect file rename and retain the old history of the file, but it does so reliably only if the renames are in the separate commit. (For future only - it's ok to keep this PR as is.)", "Out of curiosity, what will happen if storage_account_name is null? Also, if user entered a name of the storage account (I don't mean the name of the RG), why are you doing `substr`, `lower`, or `replace` at all? As a user, I would not be happy if my inputs got changed for no good reason. If it was a good idea, it would be done inside provider's `azurerm_storage_account` implementation.", "```suggestion\r\n| create\\_storage\\_account | If true, create a Storage Account and ignore `existing_storage_account`. | `bool` | `true` | no |\r\n```", "Unnecessary variable? Why don't you use `resource_group_name` instead?", "```suggestion\r\n  resource_group_name = data.azurerm_resource_group.this.name\r\n```", "Yeah, using `resource_group_name = data.azurerm_resource_group.this.name` makes this variable unecessary - thanks!", "should there be a \"type\" set on this one? ", "While type constraints are optional, it's recommended to specifying them, so why shouldn't there be a `type` set on this variable?", "Please change the existing examples as a part of this PR. It's not ok to leave broken examples for later.\r\n\r\nAlso I see no example whatsoever to run your module. Having at least one good example is helpful for reviewers, e.g. I'd like to see the behavior on 0.12.29.", "Noted, ty \ud83d\udc4d ", "If the `storage_account_name` is `null`, the storage account will not be created - an error will be returned. I could set a default value if you think thats better? @jabielecki \r\n\r\nAs for the `substr`, `lower` and `replace` - its done to make sure that the storage account name complies to the rules defined in Azure:\r\n\r\n![image](https://user-images.githubusercontent.com/26055333/111642668-93708580-87fe-11eb-9aae-a4b95e5fef5f.png)\r\n", "Noted, will do \ud83d\udc4d ", "@jabielecki Added an example with all the files required by our module structure requirements.", "Added this information to the input variable description.", "\"Folder\" might confuse Registry users.\r\n\r\nFor the internal links, do not send all users to `develop` branch, we may have different tags/branches in future (for example `v1.0.1` users should not go to the bleeding-edge `develop`). Are there any issues/problems with a relative link here?\r\n\r\n```suggestion\r\nThis Terraform example uses the [Palo Alto Networks Bootstrap module](../../modules/bootstrap) to deploy a Storage Account and the dependencies required\r\n```", "This example has its own required_version. If it doesn't work, no advice inside the `modules/*` can help us.\r\n\r\n```suggestion\r\n1. Install [Terraform](https://www.terraform.io/). The Terraform version required to run this module can be checked [here](./versions.tf).\r\n```", "Nitpick: My suggestion is to skip the `plan` for simplicity.", "This `depends_on` is:\r\n\r\n1. Not adding anything useful.\r\n2. Preventing the 0.12.29 compatibility.\r\n\r\n```suggestion\r\n```", "Empty line missing. Here and also 3 more in this file.\r\n\r\n```suggestion\r\n}\r\n\r\noutput \"storage_account_id\" {\r\n```\r\n", "Remove `version` here, you have `required_providers` in a separate file.", "Good to have a new example. \r\n\r\nStill, removing `module/vm-bootstrap` is leaving these files broken. The `source=` line needs to be adjusted in every case:\r\n\r\n- examples/panorama/main.tf\r\n- examples/scaleset-vm-series/main.tf\r\n- examples/standalone-vm-series/main.tf", "Nitpick:  How about to tell \"Copy example.tfvars to terraform.tfvars\" instead of \"-var-file\"? It will help with future git conflicts.", "This example is educational, right? It doesn't look like the best candidate for a-template-to-copy-into-prod-code, so lets make it real simple.\r\n\r\n```suggestion\r\n  description = \"Region to deploy vm-series bootstrap resources.\"\r\n```", "```suggestion\r\n  Default name of the storage account to create.\r\n```", "Remove this entire variable to make the example more educational.\r\nAlso remove `create_storage_account` bool above.", "Nitpick:  Probably the `storage_account_name` is nice to have here, no?\r\nYou've put machinery in place to calculate the `location`, lets not teach users to include this anymore.\r\n\r\n```suggestion\r\n  storage_account_name= var.storage_account_name\r\n```", "Everything we give to Azure has some limitations. Good that you've got the `description` right, now let user cleanly fail like we do in every other case:\r\n```suggestion\r\n  name                     = var.storage_account_name\r\n```\r\n\r\nWhat we previously had here was this:   calculate a sane default SA name from an RG name. This is why the subst/lower/replace was here.", "I've confirmed this approach works for tf 0.12.29, so we may use it elsewhere. Yay! \ud83c\udf7e  cc @lucap01 ", "On the other hand, if you will not add `depends_on`, even with the implicit dependency - there is some kind of a race condition and apparently the Resource Group is created later than the Data Source is able to check its existence :/\r\n\r\nThe Azure module registry uses the same approach, example [VNet](https://registry.terraform.io/modules/Azure/vnet/azurerm/latest)", "Nitpick:  If you try to `terraform delete` when having an empty tfstate (double `delete`), it will say\r\n\r\n```\r\nError: Invalid index\r\n\r\n  on ../../modules/bootstrap/main.tf line 23, in locals:\r\n  23:   storage_account = var.create_storage_account ? azurerm_storage_account.this[0] : data.azurerm_storage_account.this[0]\r\n    |----------------\r\n    | azurerm_storage_account.this is empty tuple\r\n\r\nThe given key does not identify an element in this collection value.\r\n```\r\n\r\n```suggestion\r\n  storage_account = var.create_storage_account ? try(azurerm_storage_account.this[0], null) : data.azurerm_storage_account.this[0]\r\n```", "FIxed, ty!", "SI se\u00f1or.", "Updated the bootstrap part.", "spaces: fmt please", "But why?", "Yeah, better to remove these.", "Since above we copied to terraform.tfvars, no need:\r\n\r\n```suggestion\r\n1. Run `terraform apply` to apply the changes required to reach the desired state of the configuration specified for this example.\r\n```", "Damian said in earlier comment \"if you will not add depends_on, even with the implicit dependency - there is some kind of a race condition and apparently the Resource Group is created later than the Data Source is able to check its existence :/ The Azure module registry uses the same approach, example https://registry.terraform.io/modules/Azure/vnet/azurerm/latest \". To me it looks just like yet another instance of the known [depends_on problem](https://github.com/PaloAltoNetworks/terraform-best-practices/blob/master/data_depends_on_and_tf13.md).\r\n\r\nAh, so big decision time. There is a tradeoff we face for every one of our modules (not only bootstrap, but vmseries, loadbalancer, panorama, etc). Either we have the input:\r\n\r\n```\r\n  location = azurerm_resource_group.this.location\r\n```\r\n\r\nor instead of that 1 line we have a different 1 line:\r\n\r\n```\r\n  depends_on = [azurerm_resource_group.this]\r\n```\r\n\r\nIf there's a third way, please point it out, I don't see it.\r\n\r\nThe second alternative looks less obvious. I'll probably to forget to put it on every module and receive a strange error which I need to use my time to solve. If I forget `location` I get a straightforward error, \"you need to set `location`\".\r\n\r\nTherefore I recommend the first way, plain obligatory `location` with no extra logic.", "Yup.", "same", "Aw, my bad - fixed, thanks!", "Deleted these from all `variables.tf` affected by this PR.", "Good catch, fixed.", "@damianfedeczko what is the TF version you were using when ran into the raise condition? I have seen this issue with 0.12.x but not with 0.13.x", "@migara I have this issue when using terraform 0.13.0 and 0.13.6. Looking at this with Konrad at this moment.", "I vote for obligatory `location` variable (instead of `depends_on`). It will make `data azurerm_resource_group` inside the module obsolete, so we will have a bit less code ;-)\r\n\r\nI wonder if this is really a but, not feature. In my understanding, this one is caused by updating data resources in `refresh` phase (without depends_on) vs `apply` phase caused by `depends_on`.", "Agree, we've checked the option with removing the `data_source` from the module and not using `depends_on` in the examples - setting the obligatory `location` looks just fine.\r\n\r\nBootstrap example:\r\n```hcl\r\nprovider \"azurerm\" {\r\n  features {}\r\n}\r\n\r\nresource \"azurerm_resource_group\" \"this\" {\r\n  name     = var.resource_group_name\r\n  location = var.location\r\n  tags     = {}\r\n}\r\n\r\nmodule \"bootstrap\" {\r\n  source = \"../../modules/bootstrap\"\r\n\r\n  resource_group_name  = azurerm_resource_group.this.name\r\n  location             = azurerm_resource_group.this.location\r\n  storage_account_name = var.storage_account_name\r\n  files                = var.files\r\n}\r\n```\r\n\r\nTested this solution also on `vmseries_scalset` and `transit_vnet_common` - works good.\r\n\r\nI would vote for this option, it's cleaner and allows to get a straightforward error, like Kuba mentioned.", "@migara please let us know if its ok to drop to change the approach (remove `data_source` and `depends_on` -> obligatory `location`, as described in the comments).", "Sounds good, let's remove `depends_on` and make `location` a required input \ud83d\udc4d\ud83c\udffd ", "Roger that \ud83d\udc4d ", "\ud83e\udd73 A consensus? Unbelievable! \ud83d\udc7f ", "Maybe keep the auto-generated name as in `description`? It's mainly intended for environments like our lab - one subscription, many people, many resource groups.\r\n\r\n```suggestion\r\n  default     = null\r\n```", "Conflict sneaked in as text\r\n\r\n```suggestion\r\n1. Run `terraform apply` to apply the changes required to reach the desired state of the configuration specified for this example.\r\n```", "```suggestion\r\n  count = var.create_storage_account ? 0 : 1\r\n```\r\n\r\nBecause I saw this error on tf13:\r\n\r\n```\r\nError: Invalid count argument\r\n\r\n  on ../../modules/bootstrap/main.tf line 12, in data \"azurerm_storage_account\" \"this\":\r\n  12:   count = var.existing_storage_account != null ? 1 : 0\r\n\r\nThe \"count\" value depends on resource attributes that cannot be determined\r\nuntil apply, so Terraform cannot predict how many instances will be created.\r\n```\r\n\r\n"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/56", "comments": ["```suggestion\r\n    mgmt = {\r\n```", "```suggestion\r\n    mgmt = {\r\n```", "```suggestion\r\n    mgmt = {                          // Only one interface in Panorama VM is supported\r\n```", "Let's also add another output to expose `private_mgmt_ip`. Mgmt IP is not always going to be public.", "```suggestion\r\noutput \"public_mgmt_ip\" {\r\n```\r\nReplace - with _ to keep naming consistent.\r\nVariable name doesn't have to say it's panorama as this module only output variables related to Panorama?\r\n", "Will second panorama clash this default? Isn't it better to use `coalesce()` and:\r\n\r\n```suggestion\r\n  default     = null\r\n```", "What is the map doing here? It's not compatible with neither old `vm-series` or the new `vmseries`. What's the point?", "I assumed that if user would like setup second instance in HA mode - the variable should be set per instance.", "Even only one interface is support now - i would keep baseline code to enable quickly multi-interface support.", "I added new output.", "Yes, that is why I'm asking. Look at the pending `vmseries` PR. The `interfaces` could be either a list or an object, but not a map.", "Nitpick: For coherence with `modules/vmseries`?:\r\n\r\n```suggestion\r\n    name              = coalesce(var.os_disk_name, \"${var.panorama_name}-disk\")\r\n```", "I'm worried that in lab use, it makes life harder for us.", "It cannot be changed because it was defined in our wiki inputs sets for panorama and it was approved. Moreover the key is also name of the interface - in ' list way ' it was hardcoded as 'primary' - so less flexibility - especially if interfaces are created separately. To summarize - to change the inputs first it needs be agreed on our calls and then we can update wiki page otherwise could be mess here. ", "Lets base the discussion on Jira (or on the PR alternatively). GitHub Wiki makes online discussion/collaboration really cumbersome. For example, could you move what is relevant to the Jira TERRAM-32 and delete the rest of LB inputs from wiki? I did similar thing for vmseries a while ago.", "Nice \ud83d\udc4c ", "I think Panorama only supports 2048 MiB units, not smaller.", "Nice", "The pipe character present in the string `// (optional|bool, ...` broke here the rendering of markdown. On GitHub, if I use the `View File` from this file's menu, it is clearly visible that the text is abruptly cut at `// (optional`\r\n", "```suggestion\r\n  description = \"The name of OS disk. The name is auto-generated when not provided.\"\r\n```", "Nitpick: I argue that when you set `azurerm_network_interface.this.name` at line 20 it doesn't really matter what is the name of `ip_configuration`. That's why my older code used 'primary' everywhere and didn't find it a problem so far. I wonder whether it is something that I still need to learn, maybe it's just me not seeing how it can be useful.", "```suggestion\r\n```\r\n\r\nNitpick: Looks like both lines can just be removed, no?", "Do we still need a loop for a single interface? ", "It was modified."]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/55", "comments": ["nit: markdown file should end with a single blank line ", "0.12.29 version will be hard to maintain and tests, let's start from 0.13 ?", "The README is just stating the fact: majority of the modules _do_  support 0.12.29. If this changes, we'll change the README.\r\n\r\nWe talked it over with Migara and Anton for literally two months, just before you joined. The current consensus is to include 0.12.29. No hard reasons, I think it was more of an intuition.", "```suggestion\r\nto your applications running on Azure Cloud. Deploys VM-Series as virtual machine instances and configures\r\nservices such as virtual networks, subnets, network security groups, storage accounts, service principals,\r\n```\r\n", "Yeah I know I'm boring, but I don't like the wording on this paragraph (same for the AWS doc) - feel free to ignore if you like it.", "The Azure official docs mostly use phrase \"virtual machines\", not \"instances\" or \"virtual machine instances\".\r\n\r\nI'm not using the word \"services\", because it has a specific sense in Azure:   https://azure.microsoft.com/en-us/services/"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/51", "comments": ["```suggestion\r\n  source  = \"github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/modules/vmseries\"\r\n```\r\nDelete the extra backslash.", "To be compliant with other modules the prefixes and suffixes should be removed.", "The each.key should be sufficient", "Let's remove completely RG from our modules, only required inputs", "Don't we want customized_id for VM-Series ?", "Or as discussed today, lets stick to the `localpath` for the source instead?", "I'll post the registry-only source in a separate PR.", "```suggestion\r\n  source  = \"../../modules/vmseries\"\r\n```", "But it's not a module...", "Each interface needs a unique name. Is it more readable to user of the example if one of the interfaces is named the same as a VM?", "It's an example and not a module.", "Hmm? No comprendo.", "This is going to be deleted before we public, either we should use our new LB module or Azure LB module", "This is going to be deleted before we public, either we should use our new LB module or Azure LB module\r\n\r\n", "I thought we renamed this module to `bootstrap` ?", "We shouldn't assume that boot diagnostics are leveraging the `bootstrap_storage_account` \r\n\r\nCan you please introduce a couple of new vars?\r\nhttps://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/blob/0fdbdc145ccd254ba2862e853d4616d72990578b/modules/panorama/main.tf#L75-L78", "@migara A [Pull Request](https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/57) to do so has been created", "Thanks @damianfedeczko, can you please merge that PR first?", "Will do @migara ", "The custom images are handled in `storage_image_reference`. The `plan` clause handles the Azure Marketplace \"user agreement\".", "\u0141ukasz working on our module, and I'd use it.", "I'd rather have a different solution. Lets migrate to `azurerm_linux_virtual_machine` as recommended by provider. This changes the syntax of this subclause.", "\u0141ukasz working on our module, and I'd use it."]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/50", "comments": ["remove \"s\" to be consistent with module's output.", "`route_table_ids` ?", "Thanks!", "Nit: Could the three example subnets here be part of the 10.2.0.0/16 shown above? ", "Nit question: Why should they?", "Why is this text on the Quick Start path as the first thing? And why the \"NOTE\"? I'd rather have it later in the doc.\r\n\r\nI wonder if `example.auto.tfvars` is a better idea than `example.tfvars`. On one hand it's easier to newcomers. On the other hand, if I customize my tfvars, for sure I won't be removing example.auto.tfvars. (To see why, try to actually do that and then `git pull` or `git pull -r` a new version of the code where examples.auto.tfvars were slightly changed - quite cumbersome.) The bulletproof way to have an executable example which can be customized and can be git-pulled, is to create a z.auto.tfvars for override (because z > e, alphabetically).\r\n\r\nThis is why in my code I opted to simply have `examples.tfvars` which can sit around forever and do not get auto-included in every example run. But if it changes, I'd still need to update mycustom.auto.tfvars manually (it is out of git obviously), which I admit is a pain. Not sure what to recommend, just throwing this at you.\r\n\r\nIs the `-var-file` needed in any case? Is there anything to gain by mentioning it?", "Optional request (non-blocking): Could you please migrate to the exact IP address ranges used in the Reference Architecture Deployment Guide ? This is because there are Panorama xml configs spread around using that. They are simple to re-use, but not so simple to modify the IPs used there.", "Sure, will change that \ud83d\udc4d ", "```suggestion\noutput \"route_table_ids\" {\n```\n", "Putting a \"NOTE\" at the beginning of the \"Quick Start\" was my idea to stress the way how Terraform handles the input variables hierarchy - just as information for newcomers. \r\n\r\nI've checked multiple module examples from HashiCorp and couldn't really figure out which way of using variables in an example module is the recommended pattern. HashiCorp itself doesn't have this figured out and uses `*.tfvars`, `*.auto.tfvars` or default variable values depending on a repository. I think we should unify that and include that information in our [best-practices](https://github.com/PaloAltoNetworks/terraform-best-practices#4-terraform-module-structure), because for now, it looks like we should set the default values in the `variables.tf` file, which also is a valid solution. \r\n\r\nAlso, my initial note about using a different `*.tfvars` file will be corrected, instead of:\r\n>If you wish to use different variable values, you can either modify the `example.auto.tfvars` file, or delete it and use a newly created custom file using the `-var-file` flag to specify it by name.\r\n\r\nIt will be:\r\n>If you wish to use different variable values, create a new `*.tfvars` and use it with the `-var-file` when running Terraform commands.\r\n\r\n\r\n", "Ty \ud83d\udc4d ", "I would add:\r\n\r\n> That way the `example.auto.tfvars` will be still read, but the new `*.tfvars` file can override variables one by one.\r\n\r\nHowever I still don't see what so Quickstart-ish about it. It's not a thing that a quickstarter even needs to know. The \"1. Install Terrafrom [link to explain]\" is a good first item, no need to change that.", "Okey, I hear you. So, maybe I will change `Quick Start` to `Usage` and put the input variables \"NOTE\" at the bottom?", "Updated.", "```suggestion\r\n  value = azurerm_virtual_network.this\r\n```", "Keep this simple, we don't have to turn this into a map. This modules creates a single VNET, and when you reference the value you will know which VNET it is by the module name\r\n\r\n`module.vnet1.virtual_network_id`\r\n\r\nEven if you have were to vnet module with `for_each` you will still reference it as below\r\n`module.vnet[\"vnet1\"].virtual_network_id`\r\n\r\n", "Please see https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/50#discussion_r591464700", "Fixed, thanks!", "```suggestion\r\n  value = azurerm_virtual_network.this.id\r\n```"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/48", "comments": ["Please remove all legacy variables ", "Please replace `:` with `=` to keep it consistent ", "Please move this inside the interfaces block as another optional parameter.\r\n\r\n```\r\n interfaces = {\r\n    public = {\r\n      subnet_id = module.vnet.vnet_subnets[0]\r\n      [....]\r\n      primary_interface = true\r\n    }\r\n}\r\n```\r\n", "Please rename the example name from `networking-panorama` to `panorama`. This will reduce the confusion for users in future", "Could you please add boot diagnostics to this virtual machine? This will allow users to gain serial console access if needed.\r\n\r\nexample: https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/blob/e3762a82e9ee7c6bdd7a8f500915eaf83e4d894f/modules/vm-series/main.tf#L136-L139\r\n\r\nCan you add a parameter (`boot_diagnostic_storage_uri ` (optional:string, default: null) at the root level to enable/disable this please? If `boot_diagnostic_storage_uri` is defined add boot_diagnostics, if not leave it.\r\n\r\nStorage bucket should be created at the root module, allowing user to pass an existing bucket uri rather than creating a new one for Panorama\r\n", "I will update the wiki to reflect this", "Yes it is confused and i changed it. I did not find any legacy variables yet, for instance `management_ips` is still used in example module for nsg.", "done", "done", "Do we still use prefixes (especially in resource name)?", "Misleading comment, as we are building all interfaces here", "Remove prefix or add \"sep\" part to be consistent with naming convention", "I would change the name here (\"${var.panorama_name}-os-disk\" or sth like that) to allow creation of >1 Panoramas.", "Pls add information that size is in gigabytes.\r\n\r\n+ \"In all modes, the first logging disk on the Panorama VM must be at least 2TB in order to add additional disks. If the first logging disk is smaller than 2TB, you will be unable to add additional disk space.\" So maybe we could use terabytes here?", "I would call it \"panorama-publicipS\", because we can have more than one here.\r\nAlso, maybe we could describe it as a \"list of...\"", "Good point, no we shouldn't IMO. What do you guys think, seems redundant and adds complexity to the code", "Let's remove `name_prefix`", "Heard rumours that Panorama supports bootstrapping, but I have never tested this myself. Did this work for you? ", "`var.bootstrap_storage_account.primary_blob_endpoint` should be replaced with `var.boot_diagnostic_storage_uri`\r\n\r\nThe reason is we may not necessarily (if at all) bootstrap a panorama and therefore pass `var.bootstrap_storage_account` into the module. Even if we bootstrap we may still want to use a separate storage account to store the boot diagnostics.\r\n", "Legacy vars?", "~~I am open on proposal about naming convention in our modules, but i thing this is out of scope of this PR.~~\r\n\r\nDone", "As matter of fact the variable is still used in our example in nsg modules - for security reason - this is not part of panorama modules itself", "The disk specifications include zone numbers, nice. ", "we did this so the user of the module does not have to set a value for \"boot_diagnostic_storage_uri\" correct? ", "What is this note for checking the complexity? Is this something we need to do programatically? Or how is this check performed? ", "Hm I am not following this. If the 0th interface is public, and the 1st interface is mgmt, why do we go to all this trouble to set and track the primary_interface? \r\n\r\nIs it in case people reverse the order of public and management in the map variable? \r\n\r\n(I mean this)\r\n```\r\n interfaces = {\r\n    public = {\r\n    }\r\n    mgmt = {\r\n   }\r\n}\r\n```\r\n", "Maybe we could introduce variable here? Sth like \"${each.key}-${var.ipconfig_suffix\"", "Maybe another small improvement: \"${var.panorama_name}-${var.os-disk-suffix\" with nice default for customers that want to have ALL UPPERCASE or have some other naming schema?", "Does having logging disks smaller than 2TB makes any sense? This example seems to be a bit misleading for me.", "We should add information what will happen if location is not provided, e.g. \"Region to deploy Panorama into. If not provided location will be taken from Resource Group\"", "Recommended size is 2048GB in here, but 50GB few lines later.", "Azurerm requires to set primary interface is there is more the one interface - the key name doesn't indicate which interface is the primary - the flag \"primary_interface\" pointing it. Anyhow we want to avoid situation if user by mistake set the flag in \"true\" in different interface, that's why only first value from array is selected [0]. We can image more use-case for it: What if mgmt should be primary interface etc..", "yes i thinking about this - but we decided to remove name_prefix which was involved here and now adding new prefix doesn't look like the same ? Eventually I can add default value for ipconfig_suffix - but bear in mind it is a dynamic block - not the name of interface. ", "This is only example, testing the module with 2TB - could be very tricky. I added description in variable, that 2TB is minimum.", "password complexity:\r\n```\r\nPassword must have 3 of the following: 1 lower case character, 1 upper case character, 1 number, and 1 special character.\r\nThe value must be between 12 and 72 characters long.\r\n```\r\n\r\nDo we want **Custom Validation Rules** here ?, can you put here an example for this validation if so ?", "yes", "ok i updated it", "Nope. I proposed to add suffix, not prefix. The idea is to allow not only \"blah-upconfig\", but \"blah-IP-CONFIG\" or whatever customer put into this variable.\r\nWe agreed, that we do not want to use prefixes, as they can be handled directly by the root module. \r\n", "yes i could not confirm it so i removed this part, but it would be great in automatic deployment or DR.", "Do we have often such use case ? ", "yes i took it into consideration and changed the description. In the example also 2TB ?", "I created new commit without name_prefix", "The `random_password` string generated [is explained here: https://registry.terraform.io/providers/hashicorp/random/latest/docs/resources/password](https://registry.terraform.io/providers/hashicorp/random/latest/docs/resources/password). \r\n\r\nI see the \"complexity\" was defined using the parameters specified in: resource \"random_password\" \"password\"\r\n\r\nMy guess is we would be OK since we have special set to true, unless anyone sees a reason why not. \r\n\r\nWe could create a test case to run this 20 or 30 times and validate the password complexity is sufficient maybe? (Since pass is shown in output)", "Yes OK my guess was correct :)", "I think we shouldn't worry too much trying to support all types of customer naming conventions. We are going to pollute the module every time we add support for different type of custom logic. @thedevilsvoice", "We did talk through one historical case where a customer wanted this. Sounds like a corner case though. Perhaps we just go with what we have for now  and we can always change it later if the need becomes more prevalent. ", "The issue  around this was it takes a lot longer to test when it's set to 2TB than if you set a smaller value. \r\n\r\ni think test with the smaller disk size but make sure it is set at 2TB when this gets checked in. ", "```suggestion\r\n      size : \"2048\"\r\n```", "```suggestion\r\n      dize : \"4096\"\r\n```", "```suggestion\r\n      size : \"2048\"\r\n```", "```suggestion\r\n      dize : \"4096\"\r\n```", "This requirement is enforced on our marketplace image on Azure to avoid customers creating weak passwords. I don't think we should be too worried about how to generate a random password matching the password complexity enforced on the marketplace image for two reasons.\r\n1. In production environments the likelihood of generating random passwords and storing that in Terraform state is not recommended, customers should use a tool such as vault/key manager to store these.\r\n2. Password complexity requirements can change over time and how to generate a password matching that complexity shouldn't be addressed here. \r\n\r\nCertainly customers can use this as a helper when they starting out so we should leave it as is."]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/46", "comments": ["good catch here!", "so @migara I think this should be templated in the .gitignore file TF best practices repo. ", "@thedevilsvoice great idea! Could you please add a PR for this? \ud83d\ude80 ", "Let's remove `name_prefix` altogether from everywhere? Now that we have the capability to define the names of LBs, frontend/backend names I don't see the need for this. Do you agree?", "Please remove all the legacy variables", "Captured! https://jira.paloaltonetworks.com:8443/browse/TERRAM-6", "Perhaps rename `pip-existing` to `fe1-pip-existing` to be more clear in the example?\r\n\r\n", "same here, `fe2-pip-create2` instead of `pip-create2`?\r\n", "```suggestion\r\n    rules                         = lookup(v, \"rules\", {})\r\n```", "Just to handle the case if user wants to create a FE without any rules for the time being", "Doesn't make sense to output a bunch of IDs, this should be a map of maps \r\n```\r\n{\r\n  backend_name_1 = backend_id\r\n  backend_name_2 = backend_id\r\n}\r\n```\r\n\r\nPerhaps rename `backend-pools-id` to `backend-pool-ids`?", "Same here, a map of maps\r\n\r\n```\r\n{\r\n  frontend_name_1 = frontend_id\r\n  frontend_name_2 = frontend_id\r\n}\r\n```", "And when you want to reference the ID of an object you can refer it by name later\r\n\r\nie. `module.foo.backend-pools-ids[\"bar\"]` gives you the ID for bar\r\n", "Can someone explain to me the versioning strategy for azurerm provider across all modules? \r\n\r\nAre we wanting to stay between 2.26.0 and 2.42? \r\n\r\nThis is what I see when I switch between pull requests as shown below. In my opinion this is a STRONG argument for a test suite that includes TF files to build ALL the code as shown in the examples. \r\n\r\nAs you probably have already considered, we have to consider all the modules as a group as well as individual. We should figure out how to do APPLY before and after every merge to develop and again to master.\r\n\r\n```\r\n|21:45:55|franklin@ps_automation_docker:[panorama]> more versions.tf \r\nterraform {\r\n  required_version = \">=0.13, <0.14\"\r\n  required_providers {\r\n    azurerm = {\r\n      source  = \"hashicorp/azurerm\"\r\n      version = \"~>2.42\"\r\n    }\r\n    random = {\r\n      source  = \"hashicorp/random\"\r\n      version = \"~>3.0\"\r\n    }\r\n  }\r\n}\r\n|21:45:59|franklin@ps_automation_docker:[panorama]> git checkout origin/lb_frontend_v2\r\nPrevious HEAD position was b42108a feat(panorama): pre-commit\r\nHEAD is now at d518221 feat(loadbalancer): outputs, legacy variables, naming\r\n|21:46:22|franklin@ps_automation_docker:[panorama]> more versions.tf \r\nterraform {\r\n  required_version = \">=0.12.29, <0.14\"\r\n  required_providers {\r\n    azurerm = {\r\n      source  = \"hashicorp/azurerm\"\r\n      version = \">=2.26.0\"\r\n    }\r\n  }\r\n}\r\n|21:46:25|franklin@ps_automation_docker:[panorama]>\r\n```", "Removed", "good point", "```\r\nState path: terraform.tfstate\r\n\r\nOutputs:\r\n\r\nprivate-backend-pool-ids = {\r\n  \"backend1_name\" = \"/subscriptions/d47f1af8-9795-4e86-bbce-da72cfd0f8ec/resourceGroups/lucaRG-lb-test/providers/Microsoft.Network/loadBalancers/LB-private/backendAddressPools/backend1_name\"\r\n}\r\nprivate-frontend-ip-configs = {\r\n  \"internal_fe\" = \"/subscriptions/d47f1af8-9795-4e86-bbce-da72cfd0f8ec/resourceGroups/lucaRG-lb-test/providers/Microsoft.Network/loadBalancers/LB-private/frontendIPConfigurations/internal_fe\"\r\n}\r\npublic-backend-pool-ids = {\r\n  \"backend1_name\" = \"/subscriptions/d47f1af8-9795-4e86-bbce-da72cfd0f8ec/resourceGroups/lucaRG-lb-test/providers/Microsoft.Network/loadBalancers/LB-public/backendAddressPools/backend1_name\"\r\n  \"backend2_name\" = \"/subscriptions/d47f1af8-9795-4e86-bbce-da72cfd0f8ec/resourceGroups/lucaRG-lb-test/providers/Microsoft.Network/loadBalancers/LB-public/backendAddressPools/backend2_name\"\r\n  \"backend3_name\" = \"/subscriptions/d47f1af8-9795-4e86-bbce-da72cfd0f8ec/resourceGroups/lucaRG-lb-test/providers/Microsoft.Network/loadBalancers/LB-public/backendAddressPools/backend3_name\"\r\n}\r\npublic-frontend-ip-configs = {\r\n  \"fe1-pip-create-pip-fip\" = \"/subscriptions/d47f1af8-9795-4e86-bbce-da72cfd0f8ec/resourceGroups/lucaRG-lb-test/providers/Microsoft.Network/loadBalancers/LB-public/frontendIPConfigurations/fe1-pip-create-pip-fip\"\r\n  \"fe1-pip-existing\" = \"/subscriptions/d47f1af8-9795-4e86-bbce-da72cfd0f8ec/resourceGroups/lucaRG-lb-test/providers/Microsoft.Network/loadBalancers/LB-public/frontendIPConfigurations/fe1-pip-existing\"\r\n}\r\n```\r\n\r\nCurrent output\r\n\r\n", "yes, i faced the with some issue regarding different azurerm definition - there will be more issue in E2E tests.\r\n\r\nThe proposed version \r\n```\r\n  required_version = \">=0.13, <0.14\"\r\n  required_providers {\r\n    azurerm = {\r\n      source  = \"hashicorp/azurerm\"\r\n      version = \"~>2.42\"\r\n```", "That's just wrong, even it if passes an `apply`. I suggest:\r\n\r\n```suggestion\r\n    subnet_id                     = try(v.subnet_id, null)\r\n    private_ip_address_allocation = try(v.private_ip_address_allocation, null)\r\n    private_ip_address            = try(v.private_ip_address, null)\r\n    rules                         = try(v.rules, {})\r\n```\r\n\r\nIf you go with `try()` let's do it everywhere. Alternatively, do `lookup()` everywhere. They are quite similar, whatever you like best:\r\n\r\n```suggestion\r\n    subnet_id                     = lookup(v, \"subnet_id\", null)\r\n    private_ip_address_allocation = lookup(v, \"private_ip_address_allocation\", null)\r\n    private_ip_address            = lookup(v, \"private_ip_address\", null)\r\n    rules                         = lookup(v, \"rules\", {})\r\n```", "`fmt` please, some missing spaces.", "This place needs separate testing for tf-0.12 and tf-0.13. This is exactly the situation described here: https://github.com/PaloAltoNetworks/terraform-best-practices/blob/master/README.md#33-how-to-normalise-data\r\n\r\n> If the code needs to retain Terraform-0.12 and 0.13 compatibility, the input `var.resource_group_name` needs to be a static string and not come from another Terraform object (in a typical case, it should not come from a `resource`). It is allowed for Terraform-0.14+ though.\r\n\r\nIf it works well, we can use similar `data` in every module, but if there are issues, it's better to use a dumbed-down pattern (always provide a literal `var.location` and `var.resource_group_name`).\r\n\r\nThat situation gave us hell some time ago. Let me know whether you tested it as described?", "Let them see the error, instead of silently ignoring it:\r\n```suggestion\r\n      private_ip_address            = lookup(frontend_ip_configuration.value, \"private_ip_address \", null)\r\n```\r\n", "Nitpick (non-blocking): Since it's a new module, how about using underscores right away? I'm thinking:\r\n\r\n```suggestion\r\noutput \"backend_pool_ids\" {\r\n```\r\n\r\nWhile terraform supports dashed identifiers, it is a leftover from v0.10 times. All current providers consistently use underscores (e.g. `azurerm_public_ip.resource_group_name` and not `azurerm-public-ip.resource-group-name`).", "Nitpick: Yes, also `>=` was not accompanied with any `<`. It's better to assume that the code is incompatible with azurerm 3.0 (the `~>` operator understands that  \ud83e\udd47  ). After we make the module compatible with `3.x`, we test, we bump that module to allow also that version.\r\n\r\nOne by one is fine with me, no need to bump all our modules and examples in a single PR.", "First, we should drop support for v0.12 but yes, it can be an issue for testing in future. The scenario regard testing will be crucial here - our assumption is - check last point - [common tasks](https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/wiki#common-tasks) therefore it should be discussed ", "I beg to disagree. If the `required_version` says you support version 0.12.29, we need to test 0.12.29 before merge. Not after. That problem is too serious to ignore, if it happens here.\r\n\r\nAlso this fragment of code will appear in all modules. So it's kinda crucial.", "IDs, plural :-)", "These lookup() are redundant. Since we are iterating over local.frontend_ips, which always has all of these keys, we could simply do \"frontend_ip_configuration.value.public_ip_address_id\" here.", "in code we have \r\n```\r\n| Name | Version |\r\n|------|---------|\r\n| terraform | >=0.13, <0.14 |\r\n| azurerm | ~>2.42 |\r\n```\r\n\r\n", "First rule DRY ;) I went one step further and updated variable from loadbalancer frontend, which should not be evaluated again. ", "IaC is a declarative way how the setup should be created and those end-client should be prevented to do any mistake. We do not know if the Azure API will accept such issue in future and set wrong IP, silently . The \"Static\" checking in this case is a next layer to serve user correctly. ", "I think we should remove defaults here", "```suggestion\r\nA terraform module for deploying an Inbound/Outbound Load Balancer for VM-Series firewalls. Supports both standalone and scale set deployments.\r\n```", "```suggestion\r\n  source = \"github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/modules/loadbalancer\"\r\n\r\n```", "This seems unnecessary? We can provide the full name required to be used as the key, what is the use case here?", "Perhaps this should be `frontend_ip_ids`? We are just returning a map of IDs", "Should we define a default value here? @kbechler ", "We are missing a key output here, a map of frontend_name => ip\r\n\r\nIP can be a private or public based on the LB module mode it is used in (private/public)", "The default value has to be use because of this feature:\r\n\r\n```coalesce(var.location, data.azurerm_resource_group.this.location)```", "We had the same situation regarding - panorama modules - so to be compliance with other module I set this suffix here as well. ", "The default value can be set here but if someone decided to use the module to create many LBs - the probe name will be the same everywhere - the name is not gnerated \r\nbased on key+suffix. For purposes i did not put here default value. // or we can assume that this is the problem of user.", "I think description was not clear enough, i changed it. There is already map of fronted_name_ip output `frontend_ip_configs`", "I think I have somehow slipped that in the review of the panorama module. Why do we need a suffix again? @lucap01 If there is a no valid use case we should try to move away from prefixes and suffixes", "Yes agree, that makes sense ", "The `frontend_ip_configs` output returns a map of frontend ID (`v.id`) not IPs. Am I missing something?", "@kbechler - we had case with suffix on Panorama module, you proposed the suffix can you introduce pros and cons this approach ? Let's start discussion here that everyone should be aware about the naming convention for variables. \r\n@kbechler  - Do you know use-cases that the public ip name,  created within module should have possibility to set customer naming ?", "I had such case with customer. They wanted to have all names uppercased, e.g. REGION-PALO-FW01-PIP. We had \"-pip\" hardcoded in our module, which was against their naming convention. We ended with REGION-PALO-FW01-pip during QuickStart, and they said, they will alter our code later (we worked on test env).", "Pros:\r\n- we can adapt to customers' naming convention (e.g. \"all uppercase\" or \"-public\" instead of \"-pip\"\r\n\r\nCons:\r\n- more variables\r\n\r\nIn my opinion, there nothing more.", "In Konrads [comment](https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/46#discussion_r591351478) i responded that I completely remove lookup ", "No, not for now. This link will pull `master` branch, not the git HEAD where you are currently working on. For now `../..` is just fine.", "As a user I will sooner or later write this input:\r\n\r\n```\r\nsubnet_id = azurerm_subnet.this.id\r\n\r\nprivate_ip_address = \"192.168.11.11\"\r\n```\r\n\r\nRuns without errors. I would not suspect any bug, but there is one. (I now see in the newest version this one is fixed, nice.)", "@migara Do you approve dropping Terraform 0.12.29 for load balancers? That makes it LGTM.", "Nit:  (nit means very minor issue) did we ever figure out how to standardize the spelling of \"VM-Series\" across all modules? ", "It is a corner case but agree there is no drawback to this change since it is defaulted. \r\n\r\nI think it is good practice to set a type on \"probe_port\"", "Regarding our last discussion, I've made major changes for the output. Please asses if it is good direction I have to do regex on the ID for public IP provided by client - based on that i was able make data source. ", "Closing this thread, will create a continuation. Why: to place it on the new code, so we could see the version that will receive approve.", "```suggestion\r\n  type        = string\r\n```\r\n\r\nNo quotes is simpler.", "Continuing [old thread](https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/46#discussion_r591506195). @migara \r\n\r\nToo complex and too fragile. Let's not use `data` here, as for Azure public IP it has oh so visible limitation. I would suggest simply only give the user the exact public IP in a situation when we have just created it. So, if we know the `azurerm_public_ip.this[v.name].ip_address` output it nicely, else output `null` instead. If we document that fact, no harm in having simple code, right?\r\n\r\nAs a user: if I feed the `xxx.id`, I can easily obtain `xxx.ip_address`, without going through the hops.", "```suggestion\r\n  description = \"The IP addresses of the frontends of the private Load Balancer.\"\r\n```", "```suggestion\r\n  description = \"The IP addresses of the frontends of the public Load Balancer.\"\r\n```", "You wrote about it, but I have a doubt. Can we make this `name_probe` optional? I see no reason why it cannot be auto-generated to be equal to the `name_lb`. You wrote that it may be handy when a customer has multiple load balancers. How is this helping in this example?", "I talked about it in example main.tf, I suggest:\r\n```suggestion\r\n  name                = coalesce(var.name_probe, var.name_lb)\r\n```", "Remove? Or document?\r\n```suggestion\r\n```", "```suggestion\r\nvariable \"name_probe\" {\r\n  description = \"The loadbalancer probe name.\"\r\n  default     = null\r\n  type        = string\r\n}\r\n```", "```suggestion\r\n  type        = string\r\n```", "Reduce. You are already saying how to use entire module at the top of README. Here you are explaining just `frontends_ips` input, so no need to showcase all the other inputs.", "Good idea.", "good point", "In the vnet module we used the same approach let's keep this way.", "should not be here, removed", "i took your suggestion and make name_lb optional.", "done in commit", "Yeah let's do that \ud83d\udc4d\ud83c\udffd ", "In code it will be `vmseries`. When creating documentation it will be `VM-Series `", "Do you want to set the default value to `null` please?", "@jabielecki Do you see any corner cases why this will break?\r\n\r\nPerhaps we should split this into multiple lines for readability.", "Yes, i changed this variable definition.", "Just noting - this use of `data` looks safe for v0.12.29 as far as I tested it.", "Yup.", "Nitpick: I still think it's best to drop the `name_probe` from the examples.", "Nitpick:  Also drop the `location`? The simpler the more educational."]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/44", "comments": ["I think we should support (and test!) at least two versions (v0.13 and v0.14)\r\nThe goal is to support three last versions of course, but starting with two seems to be OK for me.", "As the most common scenario, I would define \"var.location\" to single region and use it for all created resources.\r\n\r\nOf course we have some challenge here: how to test different sets of variables (e.g. defined / not defined \"location\").", "That's good. Using clean dependencies instead of \"depends_on\" is nice.", "I here, subnet has its own resource name (mgmt) and key name (subnet_1). We should discuss how we want to name such \"internal\" objects in our examples. \r\n", "Line 19 ensures that dependency tree will be fine, so this one is redundant", "Pick one way :-)\r\nEither each.value.xxx on a first place or \"globally\" defined variables\r\n\r\nHmmm, I wonder if we should have support for these two fields here at all. \r\nIn case of greenfield, it doesn't make sense.\r\nIf case of brownfield... I would prefer to create more instances of \"vnet\" module and have all subnets clearly attached to vnet from it's instance...", "This one will introduce some problems when \"var.virtual_network_name\" is in use, as we should not depends on azurerm_virtual_network. I think we could just remove it (for now).", "Changing to ` required_version = \">= 0.13, <= 0.14\"` to support the use of both versions.", "For this scenario, I will remove the possibility to select a location for the resources created within the module, by default they will  reference the location from the resource group created outside the module.", "Fixed", "Removed, have a implicit dependency now - `virtual_network_name = azurerm_virtual_network.this.name`, thx!", "Asked Migara how to proceed with this.", "Let's proceed with using the `key` as the name of the object.", "this method would give us a flexibility in terms of location for different resources\r\n```\r\nlocation = coalesce(var.location, data.azurerm_resource_group.azlb.location)\r\n```", "Indeed, and I discussed this today with Konrad, but we decided that for the first iteration of the greenfield deployment scenario we will use the resource group and its location as a reference for all of the other resources created in the module.", "I thought the point of \"depends_on\" was to control the order of preservation/deletion when we do terraform apply beyond the first one. \r\n\r\nWere we doing something different? ", "@damianfedeczko @kbechler Why are you passing NSGs and NSG rules as two different variables?", "@damianfedeczko @kbechler same here, why are we passing RTBs and RTB rules as two different variables?", "We merged that in 2 variants using `locals` - want to ask which way to proceed during todays standup.", "Fixed.", "Maybe I am not understanding but it appears to be resolved as Migara directed?\r\n\r\n", "Yeah just want to know which variant to go with, I would rather to do this within this PR than creating a new one - will wait for the meeting just to confirm that.", "This should be a map of maps, subnet_ids alone not going to make much sense (subnet_name => subnet_id)\r\n\r\n```\r\n{ \r\n  subnet_name_1 = subnet_id \r\n  subnet_name_1 = subnet_id \r\n}\r\n```", "Perhaps rename the output name from `subnet_id` to `subnet_ids`?", "Could you please also add outputs for other resources we create within this module? It is better to export those values for future use (NSGs, Route tables)", "hm yes it's a nit but I cannot disagree, unless I'm misunderstanding something. ", "oh shoot did we really forget to discuss this after not one but TWO conversations ", "This way you can easily reference the subnet ID you wanted by name\r\n\r\n`module.foo.subnet_ids[\"bar\"]` gives you the ID of subnet `bar`", "Also the singular/plural usage is important, gives you an indication of what to expect in the output (multiple subnet info vs single subnet id)", "Changed the outputs structure to map `resource_name` = `resource_id` if we expect more than one of them, changed the output names taking into account the quantity  of created resources.\r\n\r\nExample output:\r\n![Screenshot 2021-03-04 at 10 04 24](https://user-images.githubusercontent.com/26055333/109939416-528e5200-7cd1-11eb-9615-455f54992ea6.png)\r\n", "Added :)", "```suggestion\r\noutput \"subnet_ids\" {\r\n```", "```suggestion\r\noutput \"network_security_group_ids\" {\r\n```", "```suggestion\r\noutput \"route_table_ids\" {\r\n```"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/43", "comments": ["Can you please add a link to the providers documentation regarding Availability Zones identifiers? [Link](https://docs.microsoft.com/pl-pl/azure/availability-zones/az-overview#availability-zones)", "Can you please also add link to those docs in English for those of us who are still trying hard to learn Polish \ud83d\ude05", "I swear I've changed that to english!  \ud83d\ude05\r\n\r\n\r\n"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/40", "comments": ["Why does this default to true if it's unsupported? ", "I feel the `description` is quite clear. By default have SR-IOV on all interfaces where PAN-OS allows. Do not ever set it for mgmt, because it's never supported there. How can I phrase this better?", "Ah, perhaps my question is too simple! \r\n\r\nIf we know the variable will always be set to \"false\", why is the default set to \"true\" in the declaration? ", "Actually I'd recommend accelerated_networking to be left at true. Rewritten the description as it was misleading, please see the new commit and approve @thedevilsvoice", "Enabling this looks like it will speed things up for us. I'd be curious to see some \"with\" and \"without\" benchmarks. \r\n\r\nScan looks OK. We wouldn't concern ourselves with locks in a module AFAIK.\r\n\r\n```sh\r\n17:19:20|franklin@ps_automation_docker:[terraform-azurerm-vmseries-modules]> git branch | head -1\r\n* (HEAD detached at origin/vmss_sriov)\r\n\r\n\r\nViolation Details -\r\n    \r\n        Description    :        Ensure that Azure Resource Group has resource lock enabled\r\n        File           :        main.tf\r\n        Line           :        2\r\n        Severity       :        LOW\r\n        -----------------------------------------------------------------------\r\n\r\n\r\nScan Summary -\r\n\r\n        File/Folder         :   /home/franklin/workspace/ps_automation/terraform/azure/modules/vmss\r\n        IaC Type            :   terraform\r\n        Scanned At          :   2021-03-01 17:20:01.547588888 +0000 UTC\r\n        Policies Validated  :   562\r\n        Violated Policies   :   1\r\n        Low                 :   1\r\n        Medium              :   0\r\n        High                :   0\r\nfranklin \u07f7 ~/w/p/t/a/m/vmss \u27a4 (dev10-20210227)                       \r\n```\r\n", "Good catch on setting the type!"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/38", "comments": ["Strong disagree. You are forcing an innocent resource (storage account) to be always on the same location as a resource group. Is there a reason to force that upon users?\r\n\r\nAs a further consequence, also `data` would not be needed.", "ditto\r\n```suggestion\r\n  location            = var.location\r\n```", "I would suggest this everywhere throughout this PR:\r\n\r\n```suggestion\r\n  resource_group_name = var.resource_group_name\r\n```", "ditto", "Ah and what's worse that pattern was already there before...", "Agree, let's not force the location based on the RG location ", "@jabielecki do you think it's a waste of resources to check the existence of the RG?", "Can you please elaborate? @jabielecki ", "I am looking at one of the Azure official modules. Why don't we do\r\nOptional; if not provided, will use Resource Group location", "We will need this if we are going to do https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/38#discussion_r581014161"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/35", "comments": ["Can we please have it all lower case?\r\n```suggestion\r\nvariable \"logical_unit_number\" {\r\n```", "rm please", "```suggestion\r\n  description = \"Enable Panorama HA. Creates two Panorama virtual machines instead of one. Requires `location` to be one of the Azure regions that support Availability Zones.\"\r\n```", "Many Azure regions don't support AZ at all, so this should be conditional/optional.\r\n\r\nOtherwise users in these regions wouldn't be able to deploy a single Panorama nor a double Panorama.", "Also `[count.index + 1]` maybe. ~otherwise it's a warning on 0.12+.~", "In other modules I've done this approximately as:\r\n\r\n```\r\nfor_each = var.panoramas\r\n\r\nname = coalesce(try(each.value.pip_name, null), \"${var.name_prefix}${each.key}\")\r\n```\r\nThis has less variables and less artificial constraints (constraints like: the pip name must have the same suffix as the vm name).", "Lowercase for consistency with the logging disk:\r\n\r\n```suggestion\r\n    name              = \"${var.name_prefix}\"${var.name_prefix}${var.sep}osdisk${var.sep}${element(var.panorama_ha_suffix_map, count.index)}\"\r\n```", "Nitpick: In the naming convention it would be better to anticipate that Panorama is likely to have more than one logging disk. Also, for migration between slower and faster storage type, users might want to remove the first disk while keeping the second.\r\n\r\nThat's all in future, here I'd only care not to block the road to that future.", "Why this key? May be troublesome. After using a panorama module, I'd like to subsequently refer to the first IP address. Say I need the `panos` provider to create some stuff. I'm having trouble coming up with the code to do this... `my_primary_panorama = module.panorama.panorama-publicip[???]`\r\n\r\nAlso, if the output's guts are changed anyway, isn't it better to rename it to use underscores instead of dashes? So `public_ips` instead of `panorama-publicip`?\r\n", "```suggestion\r\n  required_version = \">=0.12.29, < 0.15\"\r\n```", "we should agree to and implement consistency. ", "Nothing here precludes the future change you are describing. The refactoring should be minor/quick unless I am missing something? \r\n\r\nI know we are adding availability zones for the vm-series module in the regions where it is possible. I would prefer to see that happen for any Panorama disk now so we are in step with the changes going into the vm-series module. Can someone please enlighten me on the strategy around this.", "Jakub please propose an alternative for the offending lines. \r\n\r\nI agree on underscore instead of dashes. I also notice in the updates to the README we are introducing dashes to blocks where everything else is underscore already. I vote we just continue using underscore. ", "@jabielecki Please explain why this is the preferred convention, and then we can plan to do it the same everywhere. "]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/34", "comments": ["I would use \"azurerm_resource_group.this.name\" here and get rid of depens_on[]", "Like in line 17", "I think we don't need these in examples/ directory", "We should have variable for this port"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/33", "comments": ["Maybe put the URL pointing to the information that a list of user managed identity ids is **required** to be assigned to the VM if the `identity_type` is set to `UserAssigned`?\r\n\r\n[Link](https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs/resources/virtual_machine#identity_ids)"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/28", "comments": ["Since you mentioned that the name can only consist of lowercase letters, maybe throw in a `lower()` function?"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/27", "comments": ["I can't figure out how exactly this block works... Can you give me a hint Kuba? To be more specific, I don't understand where/how the conditional `true_val` and `false_val` are used after evaluating the `enable_plan` variable value.", "Took that to Slack... The `for_each = []` path means it is all ignored."]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/25", "comments": ["Not used variable ?", "Done - good catch."]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/24", "comments": ["The special character used for this was \"---\" instead of \"##\", maybe we should keep this form. Cosmetic.", "Good catch, didn't noticed the diff in the font size - thanks!"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/20", "comments": ["Since this should be created automatically after implementing the web-hook, did you set this up as a \"base\" to start with?", "Automatic I think. Because [of this line of code](https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/blob/cb7ae8e5f32d508786b5fe266f64798fe20d506b/modules/vmss/versions.tf#L2)", "yes, without this - the pre-commit tests fail"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/19", "comments": ["I very much like one empty line as a separator after `source =` or `for_each =` .\r\n\r\nNot all inputs are made equal (or similar). It's subjective, just an idea.", "All the content that is above BEGINNING: do we need it in the main.tf now? I think the huge comment in main.tf will confuse future contributors.", "Good point, more readable, thanks!", "Right, once again, thanks!"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/17", "comments": ["Create **outbound** vm-series", "Yes, but here I'm deleting this comment together with the surrounding code :)"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/15", "comments": ["Maybe add a separator with `${var.sep}` ?", "This part of code is per-user, because it's an example. Let them just put there the string they need, without extra fuss."]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/14", "comments": ["Is that the intention that the \"Requirements\" and \"Providers\" sections provide the same information? I would expect that the first one would refer to a required terraform binary version, and the second one - as it is now - to the providers versions information. Any chance you know if terraform-docs is capable to distinct these sections?", "Good point. This is auto-generated by `terraform-docs` (which we don't execute directly, but by using `pre-commit`), any ideas how to fix is somehow?", "Looking at https://github.com/terraform-docs/terraform-docs/blob/master/docs/CONFIG_FILE.md - from what I see, we could create a `.terraform-docs.yml` file and define which sections we wish to be created/updated with the `pre-commit`.", "Looking at it, even better would be to just do this in pre-commit yaml:\r\n\r\n```yaml\r\nrepos:\r\n- repo: git://github.com/antonbabenko/pre-commit-terraform\r\n  rev: v1.43.0 # Get the latest from: https://github.com/antonbabenko/pre-commit-terraform/releases\r\n  hooks:\r\n    - id: terraform_fmt\r\n    - id: terraform_docs\r\n      args: [\r\n        --args=--hide providers,\r\n        --args=--sort-by-required,\r\n      ]\r\n    - id: terraform_tflint\r\n      ...\r\n```", "I'll do it on future PR.", "Awesome!", "fyi, the requirements in my case are generated in proper way.\r\n```\r\n terraform-docs markdown panorama/\r\n```\r\n\r\n## Requirements\r\n\r\n| Name | Version |\r\n|------|---------|\r\n| terraform | >=0.12.29, <0.14 |\r\n| azurerm | >=2.26.0 |\r\n"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/13", "comments": ["Let's change the source module name from networking-panorama to panorama and reflect that change here as well. This goes for other modules as well, to keep the naming consistency across other two repos (AWS and GCP)", "Acknowledged. Nevertheless, the `networking-panorama` is nothing like a duplicate of `panorama`. It seems to deploy the (opinionated) dependencies of `panorama` module. On next PR I think it's possible to put most of these resources directly into `panorama` and make them optional where needed (with the standard `count = var.enable_that ? 1 : 0`).", "Looking at the `networking-panorama` module, I see that the resource responsible for creating the management subnet is called  \"subnet-panorama-mgmt\":\r\n```\r\nresource \"azurerm_subnet\" \"subnet-panorama-mgmt\" {\r\n```\r\nDoesn't that mean that the value for `subnet_mgmt` should equal to `module.net_panorama.subnet-panorama-mgmt` instead of `module.net_panorama.panorama-mgmt-subnet`? Asking for a friend.", "Ah ok, I now see it is set to the defined output variable named \"panorama-mgmt-subnet\", my bad."]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/6", "comments": ["\ud83d\udc4e I'm against duplicating \"Terraform best practices\" to each of the three repositories until there is one team that is contributing to all of them. One source of truth is maybe more optimal, how about https://github.com/PaloAltoNetworks/terraform-best-practices\r\n\r\nIf discussion is desired, please split it off to another PR, so that such discussion doesn't block SemVer Release workflow.", "I can't see any logical reason to have the best practices in three repos either.", "@jabielecki  you want to cherry-pick the other files out and resubmit?", "done"]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/4", "comments": ["Ouch, lets use a local dir. If you branch, this will use `master` code and ignore per-branch changes of that module. We don't want that.\r\n", "Good, simplicity.", "Yes, example can use a full url.", "This format is an improvement \ud83d\udc4d "]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/3", "comments": ["We've settled on `this` mainly in order not to repeat ourselves (aka DRY).\r\n\r\nThe module is called \"x-load-balancer\" and, within it, the resource type is \"x_resource_group\". What benefit do you see to re-assert it again with \"lb\" and \"rg\"? (Same everywhere around: \"pip\", \"fip\", \"backend\")\r\n\r\nThere is no other azurerm_resource_group in this context that could be possibly confused, so our thinking goes: lets reduce the cognitive load. Lets use something that is short to type and that obviously carries zero additional information. Hence `this`.\r\n\r\n```suggestion\r\n  resource_group_name = azurerm_resource_group.this.name\r\n```\r\n\r\nI see literally no context within Terraform syntax where this would be problematic or confusing. Am I missing something?\r\n\r\nYou are right that if you need many different instances of a resource, you need informative names.", "I personally think it's helpful to understand the purpose of a resource at it's declaration, and not it's implementation.\r\n\r\nTake the below example:\r\n```hcl\r\nresource \"azurerm_public_ip\" \"this\" {\r\n}\r\nresource \"azurerm_network_interface\" \"nic1\" {\r\n}\r\nresource \"azurerm_network_interface\" \"nic2\" {\r\n}\r\nresource \"azurerm_network_interface\" \"nic3\" {\r\n  public_ip_address_id = azurerm_public_ip.this.id\r\n}\r\n```\r\n\r\nWithout the context of the other subnet resources, we don't know why azurerm_public_ip is defined, we only know it _is_ defined. We have to trace it through the rest of the terraform code to understand why it's there.\r\n\r\nAlternatively, for the price of a few extra characters you can write it like this:\r\n```hcl\r\nresource \"azurerm_public_ip\" \"subnet3-pip\" {\r\n}\r\nresource \"azurerm_network_interface\" \"nic1\" {\r\n}\r\nresource \"azurerm_network_interface\" \"nic2\" {\r\n}\r\nresource \"azurerm_network_interface\" \"nic3\" {\r\n  public_ip_address_id = azurerm_public_ip.subnet3-pip.id\r\n}\r\n```\r\n\r\nThis is just my opinion though, so I'm happy to cede to the rest of the team and refactor this code.", "Lets say I have no problem with `subnet3` as a name for the sake of this thread. But look at `azurerm_public_ip.subnet3-pip` I need to parse `pip` and conclude it probably means a `public-ip`. Therefore it becomes in my head `azurerm_public_ip.subnet3-public-ip`. But why do I need to be told that? Just a couple of characters to the left the same information was included, because Terraform mandates it. You *had* to put `azurerm_public_ip` in front of the name. So in my head it's  `azurerm_public_ip.for_subnet3_and_yes_just_wanted_to_confirm_yes_really_a_public_ip`.\r\n", "True. the \"pip\" portion of it is totally unnecessary. ", "I'll do a renaming pass before the end of the week to fix the references and bring them up to the standard.", "Nitpick: Needs to be a variable `var.management_ips`, otherwise we won't be ever able `apply` this example in CI. CI I think would use the `terraform.tfvars`. I agree that the basic \"show-me\" examples **do not** benefit from many variables. Less is more definitely. (Huge examples do need to use big number of vars to be easily copied to a real use. Small examples are to aid understanding.) Are we on the same page @migara and @kbechler ?", "Nitpick: Shrug, in future we could just randomize it (`random` provider), output to user and bid farewell to scary warnings. What are your thoughts?", "Add 1 empty line after `source` for readability plz.", "What's the idea behind these empty lines? They make it look like something special is happening, while we're simply passing all the vars through. Make it one block then?", "ditto.", "Again, bothered by the groupings...", "empty line", "empty line... and everywhere below", "`fmt` please. It works marvelously for me if I have automated formatting on every save on my editor. Greatly aids the collaboration.", "rm empty line", "ditto fmt", "I don't like adding/removing the bootstrap module, because now it lost its commit history and (maybe less importantly) attribution. Any reason why the restoration cannot be done with `git rebase -i origin/develop`? As I'm quite fond of it, I can screen share and quickly show how would I do that \"restoring\" operation on my local copy of this repo.", "Idea for maybe next PR. Can we be more flexible and also simpler? The convention could be:\r\n\r\n```suggestion\r\n  name     = var.resource_group_name != null ? var.resource_group_name : \"${var.name_prefix}-verbatim-suffix-i-deemed-to-recommend\"\r\n```\r\n\r\nThis way users either say \"I don't care\" or can use their own naming convention. User's convention is unpredictable (sometimes outright nonsensical), for example: put \"rg\" at the front or put the region name at the front.", "Why did you decide to go with textual handling as opposed to Terraform's IP builtin functions? Do we expect all the users to be okay with 8-bit or 16-bit subnetting?", "First thought (not directly related to what Jakub wrote): I think that this example should be moved to modules/networking/examples (or sth similar). examples/ directory should be reserved to examples that refers to reference architecture document (because it is a requirement of terraform registry).\r\n\r\nI like the smallest possible examples better, because it shows how to use the module in general. With just a bunch of required parameters. But maybe we could think of having another example with all options used. Something similar to this one here: https://github.com/PaloAltoNetworks/terraform-aws-vmseries-modules/tree/develop/modules/vpc/examples/vpc_all_options", "I'm not sure we should fix prefix with /16", "\"networking\" module can create resource_group (but have no output for that). So why can't we use instead of using direct azurerm_resource_group here?", "\u2714\ufe0f That's a better solution.", "Another option is to check in a tfvars file along with each example with some sane variables in there, or simply configure defaults for everything, I'm open to however you guys want to do it.", "\u2714\ufe0f ", "\u2714\ufe0f ", "\u2714\ufe0f ", "I could rebase, but the commit history of this fork should be squashed before merge anyway, so the commit history of this particular PR is of little consequence. \r\n\r\nFurther, the commit history isn't lost, you can see me incorrectly delete it and then re-add it in place:\r\n\r\n>5c73ec3 Restore bootstrap module\r\n8ab8a68 Inbound-load-balancer\r\n7ab876b bootstrap module\r\n", "I like this idea but this is definitely a job for Future Adam as refactoring the naming conventions is horrible. ", "The textual handling allows people to inflict their addressing requirements on the code without also forcing them to renumber all the other individual subnets. \r\n\r\nHowever, I wasn't aware of cidrsubnets when I wrote this code, which would be a more elegant solution.\r\n\r\nhttps://www.terraform.io/docs/configuration/functions/cidrsubnets.html\r\n\r\nWe could use cidrsubnets and let the client specify the relevant blocks, then extrapolate out the additional networks.\r\n\r\nDo you think this is a better approach?", "Updated by specifying a random resource in each example and changing the value passed to each module as a coalesce between var.password (now has a default of `null`) and the random password value,", "From my colleagues in apac, customer requirements often require the networking, application and security pieces of the environment be in separate resource groups, as Azure can provision RBAC based on that.", "Ah, disregard, that code shouldn't be there, I was thinking of the actual implementation not that reference. ", "@kbechler there could be some misunderstanding about the \"requirement of terraform registry\", scratching my head here \ud83e\udd28 \ud83d\ude15   Let's talk it over soon.\r\n@adambaumeister we have documented somewhere practices used in this project, I'll try to augument it with whatever we establish in this thread.", "Ah I see. Some folks just hit merge button. LGTM.", "A similar thread https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/3#discussion_r510099769 let's maybe continue together there?", "Why the decision to deploy inbound firewalls always coupled with outbound firewalls? These look like two modules or two invocations of a module. I wonder if it wouldn't be better to let end user compose inbound with outbound.\r\n\r\nThere is also a reference architecture variant \"Transit VNet model (Common Firewall Option)\" incompatible with this module. It would require a very similar, but separate, module and it would be a lot of code duplication.", "Nitpick: customers also need UDP.", "Good. Our reference architecture suggests peering with the Panoramas' Vnet. I totally forgot about it.", "Unsuitable for many customers. Just because there are many security-related scanners allergic to `/0` rules.\r\n", "Why couple together Panorama vnet with VM vnet in the same module?\r\n\r\nThere are users who don't want any Panorama. There are users who already have Azure Panoramas. There are users that already have on-prem Panoramas.", "Majority of users will have vnet already created (aka brownfield). Can we somehow make this code available to them?\r\n\r\nI mean generally, we want to give useful code for a user who has already created vnet + subnet using their own methods. Typically such brownfield subnet would become our inside subnet (aka trust subnet, aka private subnet).\r\n\r\nAlthough brownfield approach is maybe out of scope of this particular PR, but the structure is already closing that door. Maybe split it more, to allow brownfield to happen in future?", "Good catch, the reference architecture promotes that heavily.", "```suggestion\r\n  description = \"Region to deploy load balancer and dependencies.\"\r\n```", "Ditto, outbound coupled with inbound.", "Ahh I've messed up, I should have said:\r\n\r\n```suggestion\r\n  name     = coalesce(var.resource_group_name, var.main_vnet_name, \"${var.default_name_prefix}-rg\")\r\n```", "Coalesce is the best solution, but I will do in a separate PR. We can move this convo to issues.", "Updated to split the VM-series into two modules, one that deploys both directions of firewall at once (vm-series-combo) and one that deploys a single at a time (vm-series).\r\n\r\nBoth support the passing of count, which defaults to two, so in either case anyone consuming either module will be deploying at minimum a redundant pair of firewalls. \r\n\r\nThis separation introduces a minor bit of inefficiency in that the module includes a public IP for the external interface regardless of whether it's required or not. I think this is a better tradeoff than maintaining two modules (inbound-vm-series + outbound-vm-series) ", "Updated the *rules* variable to include protocol.\r\n\r\n```hcl\r\nvariable \"rules\" {\r\n  description = \"A list[objects] of ports and names that will be assigned to inbound LB rules. Useful for testing.\"\r\n  type = list(object({\r\n    port = number\r\n    name = string\r\n    protocol = string\r\n  }))\r\n}\r\n```\r\n", "even as the destination address? Surely not.", "I've now split the networking modules by their use case as I think this requirement is pretty likely.\r\n\r\nTwo new modules:\r\n* networking-panorama\r\n* networking-vm-series ", "The user can create the subnets and VNETs and pass them to the other modules but I don't think there's a very clean way of further splitting up the individual networking module to cope with brownfield deployments.\r\n\r\n```hcl\r\n# Create inbound vm-series\r\nmodule \"inbound-vm-series\" {\r\n  source = \"../../modules/vm-series\"\r\n  subnet-mgmt                   = module.networks.subnet-mgmt\r\n  subnet-private                = module.networks.subnet-private\r\n  subnet-public                 = module.networks.subnet-public\r\n}\r\n```\r\n\r\nSomething else that may be possible for a savvy customer is to use `terraform import` to bring in the depedencies - but I haven't tried that?", "OK, to make it clean. After short discussion with @migara, all examples should be in a single place (examples/). Examples for reference architecture will be prefixed with underscore (to make sure they're on the top of the list).", "Yes, I understand the stupidity. But, also, the readability? Can we proceed like this?:\r\n\r\n```suggestion\r\n  destination_address_prefix  = \"*\"\r\n```", "We've discussed yesterday - all examples stay in the main /examples/ directory. We will worry if we don't put too much there later.", "It looks like it can support narrow subnets (7 bits or less), so it addresses a valid customer problem.\r\n\r\nAnother PR, I think.", "A hard pass on `import` from me.\r\n\r\nCould this route table belong to a load-balancer module, or is it too far-fetched?", "How is it going? \ud83d\ude04 ", "Moving this conversation to an issue - we can update this code in a secondary PR", "Fixed this in all relevant modules", "I think it makes more sense to keep it where it is but I see the problem. In the event the user has already created the subnets/vnets It's fair to assume they are comfortable bypassing the networking module alltogether and passing them directly to the other modules (vm-series, lbs, etc).\r\n\r\nIf they are happy to edit their own terraform configuration (i.e write a main file for their environment instead of consuming one of our examples) they could use *data source* objects to retrieve the existing subnets. I think this is the most \"terraform safe\" way of doing things.", "Added and updated all the other location descriptions as well", "There is a decision to make here. I propose:\r\n\r\n```\r\n<!-- BEGINNING OF PRE-COMMIT-TERRAFORM DOCS HOOK -->\r\n... here text is auto-generated ...\r\n<!-- END OF PRE-COMMIT-TERRAFORM DOCS HOOK -->\r\n```\r\n- Proposed decision: Use README with partial auto-generate (the magic comments - [documented here](https://github.com/antonbabenko/pre-commit-terraform/blob/master/README.md#notes-about-terraform_docs-hooks) and I started doing them [in my PR](https://github.com/PaloAltoNetworks/terraform-google-vmseries-modules/pull/22) yesterday)\r\n- Cost: Need to use [Babenko's hooks](https://github.com/antonbabenko/pre-commit-terraform)  on all developers' laptops (hooks bring complication and have some dependencies, in particular Python3)\r\n- Benefit: Less textual duplication. No big comment on main.tf that repeats in README.\r\n- Benefit: A bit less confusion what is going to be overwritten. (I mean a scenario when someone just merges a manual change to the auto-generated README.)\r\n- Alternative to consider: What you Adam are doing here, so a complete generation of entire README.\r\n\r\nThe decision is either to use proposed method or alternative method. (Is there any third way to consider? I see none.)\r\n\r\nImportantly, the longer it's undecided, the more effort to migrate. I don't see an easy migration between the two methods - is there any? Let's just merge the small-ish bits of documentation (Adam's and mine) and correct them manually later. (I'm saying we absolutely don't want to block *this* PR with that decision.)\r\n\r\nSummon @migara @kbechler @seanyoungberg @ancoleman ", "Nitpick: We decidedly want to use `for_each` instead of `count` (when there is more than one resource created) [because this](https://spring.paloaltonetworks.com/mekanayake/terraform-best-practices#22-looping). Future PR.", "I'm confused why did you divided the code that way. Honestly I don't see: why do you need this `combo` module at all?\r\n\r\nIsn't it possible to use `modules/vm-series` twice, where the first instantiation created inbound firewalls, and the second instantiation *of the same code* creates outbound firewalls? That would be DRY.", "This file mostly duplicates `modules/vm-series-combo/inbound-vmseries.tf `, right?", "@adambaumeister can you please move this to `versions.tf` instead as per our `PS Terraform Module Organization` doc?", "Well, we're on the same page. Sooo, how such a user (again - it's a typical situation, not many users are 100% greenfield) can set up the routes? They simply cannot use this code.", "After reviewing this code I agree. The combination was due to a long-way back in the development of this code where the vm-series firewalls were not consistent aka the outbound/inbound config diverged, but this is no longer the case, so it can go.", "decoupled the vmss into a simplified module and added a second declaration of it in it's example\r\n\r\nditto with the vm-series", "My two cents but pre-commit hooks are a PITA to maintain if they have any external dependencies. I have been through that battle already with another PAN repo where the hooks don't work on windows at all, meaning there is effectively no path for windows development unless you zero out all the hooks.\r\n\r\nWhatever the solution is, it needs to be fully automated otherwise the documentation will get out of sorts quickly and this is a common complaint from colleagues here in APAC.", "Fixed!", "I am leaning towards running terraform-docs locally by the developer. \r\n\r\n@jabielecki Let's stay out of pre-commit hook for docs generation for now, need to think about this a bit more, don't want this to become a blocker for this PR. ", "@migara This PR cannot be blocked, because it was merged quite a while ago ;) Waiting for you then to as you say \"think more\"."]}, {"url": "https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/pull/2", "comments": ["I think better avoid `existing` in basic examples. As a user, I want self-contained code that succeeds out-of-the-box."]}]}, {"url": "https://github.com/UrbanOS-Examples/common.git", "pull_requests": [{"url": "https://github.com/UrbanOS-Examples/common/pull/528", "comments": ["I'm assuming we already changed the worker types to something more powerful?", "Yes"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/524", "comments": ["This is a lot of acronyms in one name! ```eks_wafv2_web_acl_arn```", "i'd like to name it waffle_clarn"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/508", "comments": ["does andi user need this permission?", "Good catch, probably not. I'll remove this"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/485", "comments": ["required for WAFv2", "required for WAFv2 ACL ARN annotation support\r\nhttps://kubernetes-sigs.github.io/aws-alb-ingress-controller/guide/ingress/annotation/#wafv2-acl-arn"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/476", "comments": ["Why?"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/457", "comments": ["```suggestion\r\n  description = \"Inspector Assessment Schedule\"\r\n```", "I'm assuming that these are defaults and are not ones that are specific to an AWS account.", "this doesn't need an `Allow` in here somewhere?", "Can we add the workspace to the name?  Really only useful for sandbox.", "```suggestion\r\n  description = \"Allowed duration of assessment in minutes\"\r\n```", "does latest make sense here?", "Nope", "Good catch.", "Sure thing.", "Yes - will explore what happens when this fails."]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/454", "comments": ["I'm not really happy about having to know the kdp bucket name here, but we really need to re-work a bunch of stuff if we want to be able to get this in a better spot. Maybe it would be better if Forklift owned this and grabbed remote state from KDP's terraform?", "Could this be done in KDP's terraform?", "Maybe an optional parameter to KDP that has it drop a configmap with the bucket name in a list of namespaces?"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/451", "comments": ["should this be 2020?"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/449", "comments": ["Why can't this section be removed?", "If we change the name our the `kubelet_extra_args` it rolls the entire EKS cluster.  I felt like changing that wasn't worth rolling the cluster."]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/411", "comments": ["Is there a reason this starts as Stmt3 instead of Stmt1?"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/404", "comments": ["What about appending _ro to this and maybe beginning it with svc or something similar?", "Is that a convention? I was matching a different service account we'd made in this format. (manually)"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/398", "comments": ["do we want to move this into the vars file or alternatively remove the corresponding var that isn't being used so as not to confuse anyone?", "wait, that var not being used for the main group?"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/396", "comments": ["You probably want to run the terraform formatter. It would put a space before this line.", "What's up with this new line?"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/388", "comments": ["are we going to override this for prod?  If not is micro big enough?", "Thought right now is not until we need it.  We can grow up and out too so I'm not terribly concerned."]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/382", "comments": ["This allows it to accept multiple TLS certs. NOTE: due to the way we handle env/OS right now, this does not work in sandbox. We'd likely have to introduce an env-durable (basically, account level resources) to handle the root certificate exactly once."]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/375", "comments": ["Should we be using a version? I know you didn't change this, but it might be an opportunity to improve it.", "Why did you guys need to toLowerCase this?"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/371", "comments": ["Is this an intentional change?", "Good call Chris. We've updated it back, and added KDC to the correct env var files"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/370", "comments": ["This is super nit-picky, but should the last sentence be `it to **begin** resolving correctly`?", "Thanks, fixed that and a couple other small typos"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/369", "comments": ["Looks like there's still a stub of this file left (data sources and variable declarations); do we still need that around for any reason?", "If these are being aggregated in the #pre_prod_alerts slack channel, is there any obvious info that will differentiate alerts coming from dev from those in staging? if not, would it make sense to just disable this \"feature\" in dev and only have it on in staging and prod?", "That makes sense to me, unless we want to test alerts in dev, although I think we can do that by just enabling the feature in dev. I'll fix that part", "Correction: we added code to the alerts to reference the tf-workspace", "Never mind; i see the terraform workspace pre-pending the alerts.", "Wasn't sure about this - how we could have TF delete the entire workspace if the workspace didnt exist anymore.  So left the \"stub\" with no real resources, will deploy and delete the resources in prod, then have another PR to remove the entire folder"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/358", "comments": ["Why is this value still here if we're deprecating it? Will we be removing it later / are we keeping it for compatibility?", "Compatibility - since it's an output something is using it and will need updated to use the new internal_dns_zone_name output or that (unknown) deployment would break."]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/351", "comments": ["?", "We're not back in `us-east-2` yet so we don't want to commit this.", "`eks-cluster` should be our only default for sandbox.", "I know you're not a fan of this `slice` strategy. I'm not either. It seems like it will be fragile moving forward.\r\n\r\nIs there something else we could do? \r\n\r\nThoughts, @rubberduck203 @kMaiSmith @bbrewer-pillar?", "Fixed", "reverted back to Oregon", "Johnson, there is a problem if you attempt to 'rm -rf ~/.terraform.d .terraform' and then do terraform init, the random package will fail to be downloaded and thus not found when needed.  The line of code I added resolves this since it is in the common/env/main.tf area.  Also, it would be reasonable to update jenkins build to remove these dirs as a pre-step before building.  Jenkins build would fail.   thoughts?", "There\u2019s a card *somewhere* about fixing this problem with \u201cpreinstalled\u201d tf providers. ", "I\u2019m not familiar with this code. Can anyone explain what we\u2019re doing here? I won\u2019t be much help otherwise. ", "Ah, thanks @jeffreylutz. Can we leave a comment around this explaining why we're doing it?", "The goal is to move cloud break and HDP to separate private subnets. By doing this we end up with 6 private subnets in the VPC. The code above simply says put datalake stuff in the newly created private subnets 3..6. We also had to go through existing features like EKS and force resources to be put in the original private subnets by using slice 0..3. \r\n\r\nDo you have a better suggestion for doing this instead of us remembering us to slice every time we add new features?\r\n\r\n I originally thought we could define something like original_private_subnets and datalake_private_subnets as outputs then pass those in the features. This did not work so I had to revert back to using directly resource defined in the module (it is possible that I might be doing something wrong). This would work if we separate common into modules and we use outputs as the contract between the modules. ", "It is important to have forward and reverse lookup-able DNS names used as hostnames for Kerberos.  So, the thought is to create small subnets for HDP with mechanically generated range of DNS names.  The DNS names would be used for hostnames using the subnet IP range.", "Does this sort of method for commenting the goal work for everyone?\r\nresource \"random_pet\" \"this_exists_to_download_random_plugin_if_terraform_cache_is_removed\" {}\r\n\r\n", "We *might* be able to abuse the `database` or `elasticache` subnets from the VPC module we're using??\r\nhttps://github.com/terraform-aws-modules/terraform-aws-vpc", "Or, probably better, how about we encapsulate the slicing in a `local`?", "Done", "renamed"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/347", "comments": ["Yeah... this was just wrong.", "Not sure why this one wasn't here (other than the variable name was confusing)"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/342", "comments": ["Maybe change to username for consistency?", "Good call. Done."]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/340", "comments": ["See https://github.com/SmartColumbusOS/discovery-api/pull/25#pullrequestreview-182257883 - it would be neat to see the cert ARN switching logic occur here if possible, as nearly no kube stuff in prod uses the non-prod cert.", "Nearly none is not the same as none.\r\nWe can't do the switching logic here because some things (grafana) do use the `internal` cert.\r\nThe only thing I can think to do is to add the `prod` cert to this map once we're running the \"prod only\" infrastructure in our other environments."]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/339", "comments": ["I think it would be more clear if this was a destroy provisioner on the resource that creates the cloudbreak instances", "Extra space here between the #! and the /bin/bash", "Mayhaps this should also be `/usr/bin/env bash`, like the previous script", "Non critical: I think it would be clearer if the conditional block was on getting the list of features, something like:\r\n```\r\nif all_features; then\r\n  features=$(ls features/ | sed -e 's/^_feature_//g')\r\nelse\r\n  features=$(_get_tfvar \"${varfile}\" enabled_features | jq --raw-output '.[]')\r\nfi\r\n```\r\nThen the _create_symlink can be either deleted or it can replace the contents of the features for loop", "Is this script only meant to be for deleting cloudbreak?  If so, maybe it should go in modules/datalake/scripts or something", "Just a style comment: This should probably go above --help so that the order reflects the help document for some mild clarity of reading", "You can do `<<-EOF` and indent the script to match the rest of the indentation, i believe", "The thought was that can be later parameterized. Really it just destroys ec2 instances based on a tag. We extracted out the `tag_to_delete` so we can do this in the future"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/337", "comments": ["I'm guessing you didn't mean to check in changes to sandbox.tfvars.", "Or the database lifecycle.", "Please uncomment.", "\ud83d\udcaf ", "Here too.", "Did you mean to delete this file?"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/333", "comments": ["Wait, aren't these already supplied by the ALM? Should these be at the `main.tf` level, in any case?", "\ud83d\udc40 oh, they totally are. oops. \ud83d\udc7e"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/327", "comments": ["Are you sure this wasn\u2019t introduced by Grunewald for reverse dns lookups?"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/326", "comments": ["Maybe variablize this so we can add retention in prod if we decide to?", "resolved."]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/322", "comments": ["Probably want to make this a variable", "make this false in Dev and Sandbox (maybe staging???)", "Probably don't need 100 gb in lower ENVs", "Pulled out into a variable.", "Done", "Lowered this value in the other envs"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/313", "comments": ["It seems weird to me that our S3 buckets have a public read access control list. I guess there is no concern that anyone can list our artifacts etc as long as only the proper resource can actually fetch the artifact?", "We're publishing a chart of something that is public so there is nothing secure/secret here, which is why it is public.", "Cool, makes sense. Thanks!"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/312", "comments": ["Does terraform let you make a variable a map that you can use? I doubt it, but it would be neat to DRY this part and the next up with this.", "Not a huge deal, but would it be possible to have the module do a data query for this given the `datalake_dns_zone_id`?", "I was wondering that myself, I'll look into it- Erin"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/311", "comments": ["does this need to be a 0 or does false work?", "Bools are just 0s & 1s in terraform. ", "so either is acceptable, but true/false is more explicit of intent IMO.", "\ud83d\udc4d Agreed on intent, I just hadn't used it in that way, so I wanted to ask for my knowledge and to just double check."]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/309", "comments": ["Moving this decouples Joomla feature from Kylo"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/302", "comments": ["Why did you guys move from the Jenkins specific load balancer to the more generic aws elb service? (Just curious)"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/290", "comments": ["minor thing but can we rename this variable to be less prescriptive like \"inbound_monitoring_sg\" or at least \"prometheus_monitor_sg\"? this could read a little misleading outside of EKS or if prometheus were not in Kubernetes at all.", "Any specific reason this is a new SG and not a SG_rule attached to the existing groups for the hadoop cluster?\r\nI could see a full group, depending on a connection from another full group (defined outside of the datalake module, i.e. the eks_worker_sg) stalling a cluster destroy operation when tearing down a sandbox deployment but an isolated rule should be easily deletable without stalling any `terraform destroy`s"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/289", "comments": ["Do we need this large of an instance in dev and staging, and really prod for that matter?  These cost $252/mo being multi-az.  Dev and Staging could probably be single AZ and it would cut that cost in half.", "Does Kylo require 5.7 or can we use a newer version of MySQL?", "See above comment about pricing", "Do we want longer retention period in prod?", "kylo says its compatible with 5.x"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/288", "comments": ["Does both the healthy and unhealthy threshold being the same number just mean it must be exactly 2?"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/287", "comments": ["Should we generate this and store it in a secret instead?", "Can we put this into an AWS secret?", "you're not wrong; it just didn't feel necessary for this specific card since the user has virtually no access beyond reading the directory tree.", "that and every other password? (we currently have four associated with the datalake module).", "Done; secretsmanager now stores the admin passwords for cloudbreak, ambari, freeipa admin, and the binduser so they can be passed around as variables for future ldap configurations or more easily referenced via the secretsmanager api.", "per conversation, not doing this for the various rds db passwords, but did do so for admin accounts."]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/277", "comments": ["Remove this?", "I've never seen double dollar signs like this before.\r\nWhat's that do?\r\n~Chris", "I don't know how to do this any differently, but it at least deserves a \"why\" comment here.\r\n~Chris", "In rare cases `hostname -I` will return IPv6 addresses. At least I've seen this with EC2 restarts and re-provisioning", "https://media.giphy.com/media/ujUdrdpX7Ok5W/giphy.gif", "$$ is one way of telling terraform to ignore variables that are intended to be bash variables in a template that is being provisioned or used in a userdata script. I assume when it actually produces the template it strips off the extra $.", "Never mind. It looks like these scripts will never run more than once on the same node, so that error case won't happen.", "We were able to clean up the way the master reverse record is generated but since terraform can't apply a function to a list and output a list as a result this doesn't seem to be improvable. Added a comment detailing the limitation.", "Done"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/275", "comments": ["do we need this? i thought we were avoiding hive-interactive?", "It is turned off, we just tweaked it b/c Ambari was telling us that it was set. \ud83e\udd37\u200d\u2642\ufe0f "]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/274", "comments": ["Refer to what I said to you in person."]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/273", "comments": ["You can get rid of these, and ensure that you have some sort of policy that lets EKS workers access the bucket (as discussed)."]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/270", "comments": ["Will approve when this becomes a version", "Remember to retag", "Done"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/263", "comments": ["Nice! I didn't know you could do this to trigger null resources!", "Does `var.remote_management_cidr` represent the ALM network?\r\nIf so, we may want to just snag it from a data query.\r\nI've done that elsewhere and can dig up an example if you like.", "This doesn't seem to update.\r\nIt looks like it creates if the blueprint doesn't exist.", "Same as above. Update seems like a misleading name.", "so within the module we're decoupling this from ALM by making it a var, and then passing that var in where the module is actually called (env/features/datalake.hcl) by setting the variable with `remote_management_cidr   = \"${data.terraform_remote_state.alm_remote_state.vpc_cidr_block}\"`", "Yeah, we intended this originally but discovered it was undesirable to be trying to update existing blueprints and didn't rename the file along with the rest of the changes."]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/256", "comments": ["do we want to support more of the jupyterhub workers than regular cluster workers? would increasing this number in the future cause a full redeploy of the cluster or anything potentially disruptive?", "Increasing the number works much the same way that autoscaling does on our existing worker group so I would not expect that to have any interruption in service.  Reducing the number would probably have service issues as pod reshuffling would need to happen and take time.", "We talked about it but leaving it as a comment, too.\r\n\r\nCan we generate this value by getting the size of `worker_groups`?", "seriously?!", "^^ BEN", "That\u2019s cool!", "This fork-bomb protection is most relevant in the JupyterHub workers. Wouldn't hurt to have it in both, but we'll definitely want it there.", "You can move the file on me, but my question remains the same:\r\n\r\nCan we reference the size of `worker_groups` instead of having to hard code a value here?", "\ud83d\ude31 "]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/233", "comments": ["Did you mean to comment this out?", "Bruh. Merge conflict got checked in. ", "Actually, they got un-checked in (Cromer said this)", "Yes, it appears to break sandbox.", "Yeah, the merge conflict markers are in master HEAD right now. I'm cleaning them up."]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/231", "comments": ["this `depends_on` shouldn't be necessary, but we noticed it too late in the game to remove it and properly test that - Just Ben", "No special chars in the pass?", "Name = \u201cname\u201d? This filter doesn\u2019t look like it should work. ", "But ++ for using filters instead of Id. ", "We should really start randomizing these. We keep loading services onto the 0th subnet. ", ":100:", "We\u2019re letting this assume any role?", "Super petty, but does terraform let us multi-line arrays?", "Are we sure about this? \r\nIf I\u2019m reading this right, this will attach cloudbreak to the public facing lb. \r\nI wouldn\u2019t think we\u2019d want that. ", "Duplicate line. ", "Oh snap. Not sure how we missed that. I guess they must be or'd together :/", "Agreed", "We figured it would be less painful until we can get these to automatically add the credential role. It may be better just to restrict this to that and manually add just that role as the default credential", "Yep, was thinking about that. Also, our last TODO is to optionally add that sg because it won't be there for prod", "We can double check, but last I looked it was not on the public one, just the private one", "Good catch. So weird", "Good catch. As far as we know it doesn't care, but honestly we're guilty of copy pasta here", "might want to check that kubernetes_internet sg as well; if that's the one i think it is, then that's  what allows ingress from the k8s loadbalancer into the cluster, in which case it wouldn't be the source of traffic coming from k8s to hadoop/cloudbreak; for that we'd want the cluster worker sg.", "does this get evaluated on the host calling terraform or the one being built by terraform?", "wow; cloudbreak is a resource hog.", "trailing newline?", "do we need this? should default to 1 unless you're looking to toggle on and off which doesn't seem necessary with a totally internal name.", "I'm more of the opinion that if we're gonna keep this LB configuration around, can we rename it to something other than \"old_prod_loadbalancer\"? else it would be nice to start clean with a new and different one to just rip this out when ckan is sunset.", "Maybe new_prod_loadbalancer ?", "On the host. Honestly we could just move that all to the template file", "On the host. Honestly we could just move that all to the template file", "Yeah, I wish there was a better way to document that. Cloudbreak appends to the file and it breaks if there is not a new line. Terraform template removes it from the template file so it has to be here :(", "This is Kyle's fault as we copied his code here", "Comments can make great documentation.", "Your call. I'm good either way.", "The kubernetes_internet group allows k8s to access the CKAN api.\r\nWithout it, the Jupyter notebook can't query CKAN in any environment but prod.", "Taking a second look at this, I'm 98% certain this is a public facing load balancer in prod.\r\nI don't think we want cloudbreak accessible off vpn.", "This works. We're filtering on the 'name', so the 'name' of the filter is 'name.' ", "Yarp. This is the recommended minimum.", "Pretty sure you're right on this, Jeff. It's been removed.", "Not a blocker - 40 chars is perty good"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/229", "comments": ["i assume we don't want this to exit any longer.", "This caused the \u201cprod only\u201d terraform to fail last night because it didn\u2019t specify our new `enabled_features` in the variable file. "]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/228", "comments": ["That's a lot of permissions... do we really need all this?"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/224", "comments": ["These are pretty hard to rename.\r\nAre you sure you this is the name you want?", "brother eye?"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/223", "comments": ["You've set `min` twice. \r\nThis will give us a minimum of 15 worker nodes.", "Nice catch, thanks"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/215", "comments": ["Do we need/want the `20180921-081715edt` on this?", "Was this intended to be null or empty string?", "I don't really want to muck with the Joomla UI to change it to be honest.", "It was intended to be empty so we can override the value in the terraform if it's specified."]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/214", "comments": ["does this have to be a space-separated string? can't be a space-separated list or comma-separated?", "Is it worthwhile to create a module that takes a name and then sets up these rules?\r\nI think we've duplicated this several times in the code base now.", "What's the unit for storage? Can we comment?", "We only need multi_az in prod (and *maybe* staging). Can we create a variable for this?\r\nIt does cost about 2x for multi az.", "Or a terraform formatted list?\r\nI now we're parsing this with bash, but it would be *nice* to have it be an hcl list.\r\nWouldn't block this on that though.", "I do agree that there is duplicated code right now, but at the same time I'm not confident that these resources will remain as convergent as they currently appear. Until we actually build services on top of these databases, it might be premature to attempt to DRY anything up here.", "Now that we tie the tf-init version with the common repository, we can make this change in the future and maintain total backward compatibility ", "Unit is gigabytes.  I agree that we need comments for a justification for the size"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/213", "comments": ["it would be great if we used `local` or `local -r` here just as a general practice, but it won't break my heart if we don't - Ben", "I\u2019d like to see us using fully specified flags in scripts we check in. In this case `\u2014raw` instead of `-r`. ", "Fixed"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/211", "comments": ["Don't forget to switch this back to a release.", "Can we get this to unlink features that are no longer specified?", "If I'm reading this correctly, this is expecting a `.tfvars` file in the root of the project, not under `env`.\r\nI don't think this works.", "here hear - Ben", "it requires the working directory to be the same as your terraform project directory, so `env`, `alm`, etc.", "it does already unlink any non-specified features -- see line 58"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/205", "comments": ["Should we turn on multi-AZ for staging too? I was debating this. Dev is definitely overkill. Staging might be nice to have as a sanity check.\r\n\r\nThoughts?", "I don\u2019t see a compelling reason to. We don\u2019t really need staging to be highly available and AWS makes it pretty transparent. It\u2019s not the kind of discrepancy between environments that concerns me. \r\n\r\nOn the other hand, it\u2019s like a 5 minute change now that I\u2019ve already tested in sandbox. \r\n\r\nI\u2019m going to merge this and we can mull it over a bit more tomorrow. "]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/200", "comments": ["Is there a reason the spacing was added?"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/193", "comments": ["Describe me pls", "Double `count` variables", "No need for that first condition check", "You can use the `doStageIf` closure here:\r\n\r\n```groovy\r\nscos.doStageIf(scos.changeset.shouldDeploy('prod'), 'Apply prod specific infrastructure') {\r\n    // ...\r\n}\r\n```"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/191", "comments": ["holy cow, nice"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/189", "comments": ["Can we inject in the version from an environment variable?", "if you're only reloading for config files, reload would work.  IF this is to restart the whole app, restart is fine.", "Why do we need to uninstall? Is it because we changed from git to s3?", "I\u2019m 99% certain we do this on the \u201coutside\u201d in the setup script that calls this one. ", "We originally did it because the version wasn't changing, so pip didn't see a need to update. That version has been fixed though", "What is the effect of this? Does it embed the content in the plan?"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/183", "comments": ["Is there some way we can phrase this as a positive? I definitely hard to think about what this expression means. It\u2019s also weird to think about \u201cnot a release, but is a prod release\u201d. ", "Why the change to `sh` instead of `bash`? Do we simply not need the `set -e` anymore?", "There's only one command in this script, so it will fail with an `exit 1` whether we `set -e` or not. The shebang isn't necessary because our shell is bash by default (as set in Jenkins configuration)."]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/181", "comments": ["I'm guessing that 'external0dns' is a typo?", "dammit!\r\nyes"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/180", "comments": ["Does this work for prod?\r\nI can never remember what we're doing with DNS out there.", "i believe we're just creating alias/cname records to the internal addresses. i don't see any other code handling this in prod that would indicate otherwise."]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/167", "comments": ["Really?! Could you bother to break this out onto separate lines? - Ben"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/160", "comments": ["Can we document how to recover these passwords should we need.", "We seem to use `subnets[0]` a lot. Would it be better to use a random subnet?", "This makes me so happy.\r\nAFAIK the .ini file wasn't in source control anywhere until now.", "Do we need a module to DRY up the two instances of ckan?", "Just curious why we ignore this.\r\nAdd a comment maybe?", "If I understand the random provider correctly, there's a block we can put in here that will make it so the password only gets regenerated if a \"parent\" resource was modified.\r\nA \"keeper\".\r\n\r\nIs that something we'd benefit from leveraging?", "We listen on 8443, but don't have a VirtualHost for it?", "Please doublecheck the value of `var.root_dns_zone` for prod.", "Working on that as we speak, or as I type, whatever. Don't judge me bro", "The random string won't get regenerated unless the random string resource is destroyed.  The keeper forces it to be recreated more frequently, for example, with the recreation of the database instance", "This is a great idea, but implementation is non-trivial and we don't think it's wise to block on this issue", "\ud83c\udf82 ", "This cannot be DRY'd.  Thanks terraform", "No idea why this is being ignored.  Will be removed", "Booo", "There might be a good reason. I just don\u2019t know it. ", "Dead code", "I don't think there is...", "Yup, removed", "Thanks for this. I know @rajones-hntb & the data team do sometimes need direct database access to fix table field types during large dataset loading.", "We curl this twice?", "Requests to the metadata service are cheap.  Since we need two values from the json string, we figured it would be more readable to curl it twice than to introduce another variable", "Ensure this bucket can't be deleted?", "What are the risks of exposing these passwords when this is applied to production?  What users will be able to access these?", "\ud83d\udc4d ", "I would put a Sid that describes what this policy is for, so any of us in IAM can easily attach meaning to it.", "Sid?", "So ignore this. We need to take this to A&Cs.", "Should this be hardcoded across dev/staging/prod?"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/153", "comments": ["Please delete - Ben"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/151", "comments": ["Please do remove the `params.alm` parameter - Ben", "Is there any way we can get `vpc_name` cleaned up and removed too like you just did with the `kubernetes_cluster_name`? It would be nice to take care of that sooner rather than later.", "I had some bit of trouble getting the staging vpc named \u201cstaging\u201d instead of test. Can\u2019t remember exactly what it was we ran into though. "]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/138", "comments": ["shouldn't this change be done for all three directories that get `kubectl apply`ed? There are also manifests in the k8s/tiller-role and k8s/persistent-storage that may only have a single file each at the moment but that's not to say that they will forever\r\nperhaps just co-locate all the files in the same k8s-setup directory and loop over all of them in one go?", "\ud83d\udc4d "]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/136", "comments": ["these could probably stand to be change to `...jupyter_backup.arn` to not have to do the ARN part on the front."]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/130", "comments": ["Can we make the just on port 80?", "And 443 =;)-"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/128", "comments": ["Is this going to cause naming conflicts?", "Won't this create `prod.smartcolumbusos.com` ?", "Only if you try to deploy two ci-webhooks in a given vpc", "This would create a `prod.internal.smartcolumbusos.com`\r\n\r\nWe will need to make another card to address owning the root authority zone `smartcolumbusos.com`"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/121", "comments": ["You don't need to wrap your Closure in parens. You don't need them at all when your only argument is a Closure. I think that this is easier to read:\r\n\r\n```groovy\r\ndef environments = params.environmentParameter.trim().split(\"\\n\").collect { environment -> \r\n    environment.trim()\r\n}\r\n```", "Do you need to `trim` twice? I'd guess that the `trim` of each collected line would be enough but I'm probably missing something.", "The first trim catches leading or trailing whitespace which get converted into their own array elements if you don't trim them."]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/119", "comments": ["this is a typo, I think you meant `\u00fee olde main function`"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/117", "comments": ["Can this go to the block below? or does it need to be applied to `resource: *` ?", "We are following the guide here: https://github.com/kubernetes-incubator/external-dns/blob/master/docs/tutorials/aws.md . So for now I think we'll leave these in parity with the documentation."]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/112", "comments": ["you can chain these into a single `sed` with multiple `-e` arguments since you're applying them against the same file. ", "I'd pull out the `--kubeconfig` and the `KUBECONFIG=...` above and standardize on a `withEnv` block wrapping any commands we run with context-specific kubeconfig files.", "Could this be replaced with `ec2:Describe*`?", "Ditto. Could we simplify this with `List*` and `Get*` wildcards?"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/111", "comments": ["That is beautiful", "Now it's not so beautiful, but I'm sure we'll tighten it down when we get a chance ;)", "Yeah, just to catch others up when reading this:\r\n\r\n@bbrewerpillar had approved it when I originally had a bad copy/paste in. It looked like it was a EKS specific. But after fixing the copy/paste, this allows any ARN in dev or staging to pull images from our ALM ECR.\r\n\r\nI don't consider this a big deal because it is strictly pull only."]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/109", "comments": ["If the config file is still being named after the environment as well, this is going to drop a file for each environment like /var/jenkins_home/.kube/dev/dev; just to keep in mind for when we're setting the environment variable for the block that needs to make a call against that environment's cluster.\r\n\r\nYou'll also need to explicitly set the KUBECONFIG to that file in a withEnv block unless you have a separate change to run the jenkins master as the jenkins user if that file will no longer be in the /root/.kube directory.", "It\u2019s just named `config` right now. \r\nhttps://github.com/SmartColumbusOS/common/pull/109/files#diff-58231b16fdee45a03a4ee3cf94a9f2c3L121\r\n\r\nSo it comes out as `dev/config`, `staging/config`, etc. \r\n", "You\u2019re right though. This may be premature to merge until the staging card is done. ", "Not necessarily; you should be able to pretty easily throw a \"withEnv\" around the current `kubectl` calls and just point to that", "I just did an audit of our projects that deploy to k8s.\r\nThe only place that needs change before merging this is Jupyterhub.\r\n\r\nhttps://github.com/SmartColumbusOS/jupyterhub/blob/master/Jenkinsfile#L38", "I would agree that Jupyterhub would need to change before this get's merged in.  I would wait until Paul and Jessie are done moving Jupyterhub to EKS though as I think there would be no worked required at that point.", "@JarredOlson this PR already made the Jupyterhub change needed to merge this.\r\nhttps://github.com/SmartColumbusOS/jupyterhub/pull/10"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/108", "comments": ["Much nicer. +1", "I\u2019m not sure what we have in production right now, but are we sure about this change?", "What happens if we don\u2019t specify this?", "Do we specify smaller instances in lower environments?", "for this, cota, etc, remember to add the `.dev`, etc. portion to the ALM part", "Yes, this value came from production", "You will be asked to supply it when you run a plan. However, prod is set to blank, so we replicated that.", "Looks like dev is set to `db.t2.large`", "The defaults are all set to prod values and then overwritten where necessary in variables/dev.tfvars ", "LGTM"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/106", "comments": ["Will `streaming-service` expect these to be on the master node? All of these right here are occurring on a temporary agent container.", "my intention with the previous implementation was to keep the \"caching\" of those credentials temporary/ephemeral by leaving it in the context of the workspace to be deleted at the end of each build; if you need it again you run the terraform output function again."]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/101", "comments": ["Are these boilerplate comments? If they are I'd prefer they be trimmed down, if possible.", "Is it possible to tighten these down?"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/99", "comments": ["Are we going to deploy PR code to dev?", "By putting this conditional inside of the `stage('Deploy to staging')` block, you will always have an empty stage appear in the pipeline UI. On previous projects, we've usually elected to not show unexecuted stages.\r\n\r\nI don't think the empty stage is necessarily a bad thing, but I wanted to call it out.", "If we're not going to use the symlinks (`env/backends/dev.conf`, etc), this PR should delete them.\r\n\r\nAlso, make sure you talk to @alexmarkley about this if you haven't already. He'll want to discuss.", "Just to sanity check, which public key is this?", "That was the idea. We talked it over with everyone we could find yesterday afternoon. Everyone seemed to like the idea. ", "I\u2019ve done that before too. The UI changes and you can\u2019t see the history. I could go either way honestly. Will ask the team at standup. ", "The same one as dev. Easy change if we want a different one for staging. ", "I usually err on the side of wrapping the stage in the `if` as the empty stage (green, but didn't run anything), always seems a bit deceiving to me.", "You could throw an \"else\" and explicitly call out the \"skipping deploy\" or something.", "Interesting. I was not involved with these conversations, but I would like to understand why this is a good thing..."]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/98", "comments": ["Since `bastion_host_ip` and `joomla_old_ip` are now parameters, you should reference them directly and delete these `bastion_host` and `joomla_old_ip` local declarations.", "There should be a newline separating variable definitions. There are a few nitpicks like these but `terraform fmt` should fix them all.", "Good idea commenting these out instead of deleting them \ud83d\udc4d ", "It will probably fix a few that you didn't introduce too \u00af\\\\\\_(\u30c4)\\_/\u00af"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/95", "comments": ["Dead code", "I'm taking a closer look at this (trying to get a feel for what the merge conflicts will be) and I'm wondering. Correct me if I'm wrong, but this means the private key for the entire cluster will only be stored inside the docker container that ran this?\r\n\r\nI'm not saying things should be as lose as they are now, but shouldn't that key be easily available for *somebody* should we need to shell into a cluster for some reason?", "I can stop over, but the key will be stored inside the Jenkins master itself as `k8s-no-pass`", "Gotchya. Now I'm following. Thanks.", "Or, I should clarify. `k8s-no-pass` will already exist and this will just ensure that all public keys set for `env` use the public key side of the private key."]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/92", "comments": ["can \"this\" be more descriptive? ", "It feels like either this module wants to be called \"load_balancer_internal\" and the following one just wants to be called \"load_balancer\" or they both want to specify internal vs. external.", "why are we not ignoring the sandbox tfvars but committing the regular CI environments' version of those files?", "Should we explicitly name internal ALBs the same way we're explicitly naming external ALBs?", "Should this just be `is_internal` and invert the logic on the name ternary? Feels weird this way.", "Feels weird to multiply a number by a boolean (I get why we're doing it), but is something like this more readable?\r\n\r\n```hcl\r\ncount = \"${var.is_enabled ? length(local.lb_rules) : 0}\"\r\n```", "There's no environment in the production dns names.\r\nDo we need a switch for `if prod` or are we changing them?\r\n\r\nhttps://console.aws.amazon.com/ec2/v2/home?region=us-east-1#ELBRules:type=app;loadBalancerName=prod-scos-elb;loadBalancerId=618bbec5b694be62;listenerId=bb2e26a0a2620579", "Can you add a description to this?", "This is the way it is so we can match prod today.", "done", "done\r\n", "I'm not exactly sure here", "done"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/87", "comments": ["Do we want to let it output the plan for review?", "I'll see if it can get past that real quicklike"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/69", "comments": [":cancer:"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/67", "comments": ["How does this behave is the user fails to pass in the `environment` argument.\r\nMaybe we should make the script fail if required args aren't supplied."]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/66", "comments": ["If this is the same everywhere, why is it a variable?", "I think I\u2019d rather see a `jupyter` file than a `dns_records` file. I think it makes more sense to organize by application, but would like others\u2019 opinions. ", "Any particular reasoning behind appending the environment to the name? Shouldn\u2019t it be fairly obvious which environment it belongs to? Could we use tags instead?", "This feels weird. If we don\u2019t want to create it, why would we include the module at all?", "Because eventually this will be open source - we should not be hardcoding any references to smart columbus.", "Ran into duplicate name errors - cannot have 2 ELBs with the same name in the same account/region - so we appended the workspace name.", "The module is ran in all environments but these records only are added in prod so this is the logic to do so."]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/58", "comments": ["```../modules/``` ?", "where did this come from? what is the team consensus around the management of private key material?", "Shouldn't this be `${terraform.workspace}`? Or does it assume the `terraform` part?"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/54", "comments": ["Our current Kubernetes has 5 workers.  Wasn't that part of the AC of one of these EKS cards (I can't remember which one)?", "@JarredOlson the ACs are 3x3 currently (changed during entrance) thanks for the heads-up", "Empty line?"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/52", "comments": ["Why this change? Are we using this elsewhere?", "It\u2019s different between sandbox and alm. No idea how it ever worked the way it was. ", "It\u2019s different between sandbox and alm. No idea how it ever worked the way it was. ", "Ah, gotcha. \ud83d\udc4d "]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/51", "comments": ["Talk to kyle and make sure we cant pull this in dynamically."]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/49", "comments": ["These need deleted. ", "Delete this file. ", "Is there a reason we're using 5.6 and not 5.7?  (An answer of Joomla only supports 5.6 is a completely valid answer)", "This would need to change if we go to 5.7", "We should encrypt the DB.  You cannot enable encryption after it is created.\r\nhttps://www.terraform.io/docs/providers/aws/r/db_instance.html#storage_encrypted\r\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.Encryption.html", "To enable automatic backups these two options should be set:\r\nhttps://www.terraform.io/docs/providers/aws/r/db_instance.html#backup_retention_period\r\nhttps://www.terraform.io/docs/providers/aws/r/db_instance.html#backup_window\r\n\r\nIf we want a final snapshot to be taken before destroying:\r\nhttps://www.terraform.io/docs/providers/aws/r/db_instance.html#skip_final_snapshot", "What needs access to this DB?  I don't see anything specifying ingress on 3306 (default MySQL port).  This may be covered by a different, wider policy somewhere, but it stuck out to me.  In the past I have done by creating an [aws_security_group](https://www.terraform.io/docs/providers/aws/r/security_group.html) and specifying the [vpc_security_group_ids](https://www.terraform.io/docs/providers/aws/r/db_instance.html#vpc_security_group_ids) on the RDS resource.", "That's what we have installed in production right now.\r\nI can't answer beyond that.", "Our current database isn't encrypted, but I agree that we should fix this now since it can't be changed after creation. Noted.", "Noted. Current prod settings\r\n\r\nAutomated backups: Enabled (7 Days)\r\nBackup window: 05:16-05:46 UTC (GMT)\r\nMaintenance window: tue:09:55-tue:10:25 UTC (GMT)", "It's covered here by a wider policy that allows traffic between servers in the same security group. Again, I'm just mirroring what we currently have in prod.\r\n\r\nhttps://github.com/SmartColumbusOS/common/blob/joomla-restore/env_joomla/joomla.tf#L80-L86\r\n\r\nWait. Nope. I missed adding that security group to the JoomlaDb. Good catch.", "Kyle's view on this was that Joomla encrypts the data before it's in the database so he felt that it was redundant.", "Good enough for me", "This won\u2019t work in prod. The production VPC isn\u2019t terraformed yet, so there will be no remote state to query. We\u2019ll need to tag the subnets and directly query the aws state. "]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/47", "comments": ["where am I on here?", "Do you mean why are you not on here?\r\nBecause we forgot to add you when you joined the team and I copy/pasted the manually created policy for the other repositories into here. \r\n\r\nIf you\u2019re not Ben, then you\u2019re here so you have rights to pull images from the repository for local development. ", "Or `jolson`", "Both added along with the other new team members."]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/46", "comments": ["It would be better to just not to define a default I think. ", "Yeah, you'll want to delete the entire `default` line so Terraform will prompt for the key. As is, it won't prompt and your infrastructure will be unreachable."]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/45", "comments": ["`jmorris2@pillartechnology.com` ??? I guess we agree to this already as a first pass?"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/42", "comments": ["Lets make this description more clear.", "Is it too late to extract a local for the port?", "Can we query for this (or the name) with a data block instead?", "It would be better to just not define this if we don\u2019t know it right now. If it\u2019s not defined, terraform will stop and prompt. "]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/40", "comments": ["This doesn't appear to actually retry.\r\nI think we need a `retry(2)` here.\r\nEither that or terraform apply doesn't return a non-zero exit.", "This line hangs forever if kube isn't up and running."]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/38", "comments": ["good catch!"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/18", "comments": ["You've got 2 space indentation here but 4 space indentation above. This block should probably be 4 spaced, since I think that's the suggested Groovy style."]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/17", "comments": ["Since this is a user script, a `read` with a y/n query after this to allow the user to review the changes before they are applied.", "this appears to be redundant of line 10, and commented", "This variable was deleted.  this line should be removed, not commented out", "Spacing is inconsistent with the rest of the file", "Can we tee this so it doesn\u2019t look like the job is hung?", "You're mostly 4-spaced indentation, but it's 8-spaced here. It should be 4-spaced everywhere.", "Same here with the indentation."]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/16", "comments": ["You probably don't want to commit this file, at least not named like this.", "We probably don't want to commit this change.", "Do we want this one? @jeffreylutz or @bbalser, thoughts?", "Nitpick, but spacing is inconsistent here before and after `=`.", "Same here.", "This line and the two above it have inconsistent spacing before and after `=`.", "Indentation inside this module config block is inconsistent.", "This version is unnecessary since we're pointed at a module on the filesystem.", "Another one around `=`.", "This hard codes us to exactly 1 Joomla container running for this cluster. Is that what we want?", "This comment block means we need to copy the MIT license into this project, right? We did this with the Apache license elsewhere.", "Need a space between `\"` and `{`.", "Same here.", "Delete the commented out code.", "Should we be defining Joomla vars in both `env/variables/sandbox.tfvars` and `joomla_env/variables/sandbox.tfvars`? \r\n\r\nSeems like we'd only need them in one or the other.", "Fixed", "Fixed", "Fixed", "Fixed. A bunch of this script is copy and paste from another script so I suspect we had the same problems in other places. To fix all of these we simply need to run ```terraform fmt``` before committing the code", "You are correct", "Fixed", "I am not sure about that. I don't believe running HA Joomla is as simple as increasing the count but I may be wrong. I would rather be explicit about it at this point.", "I can add the MIT license. This code code is also used in Jenkins BTW. Do you suggest we put the MIT license under common directly?  Or we can rewrite the Load Balancer. Had to do more tweaks than the comment says.", "Done", "Done", "done", "Cleaned up bunch of vars"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/11", "comments": ["Delete me", "Done", "Do we only want 2-3 k8s workers? Should we make this 5-5?", "This doesn't feel like the right key. Thoughts?", "Ah, nevermind. We talked through this and I missed what this was doing.", "Parameterize these values."]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/10", "comments": ["Do we need this since it's commented out?"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/8", "comments": ["`proove`", "For sandbox use, wouldn't we want to use a personalized workspace? Something like:\r\n\r\n```sh\r\nterraform workspace use johnson\r\n```", "Do we need documentation about how to setup the `sandbox` profile in your AWS configs? Maybe it's something that should go into Confluence?", "Bad link. Also, add a description?", "This should go in confluence. "]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/6", "comments": ["I think we only need one here. \r\nWe\u2019re not using dedicated workers at the moment. ", "Never mind previous comment. \r\nWe could set the desired capacity here. "]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/3", "comments": ["guessing this should not be included in the commit ;)", "should have a lookup to get the latest or a pinned ami", "this should be a template file imo", "Could you add `*.tfstate` to the ignore list?", "@bilsch You would guess wrong.  The bootstrap terraform state is not stored in the s3 bucket since bootstrap defines the s3 bucket.  This means that when changes need to be made to the s3 bucket or DyanmoDB table the state needs to come from somewhere, and it makes more sense to me to just store the tfstate of the state bucket and dynamodb table in git than to have to re-import the state every time", "I'm not sure I follow.  How is this not a pinned AMI?", "I'm saying you should not pin to the ami here but look it up and keep it current. Example https://github.com/SmartColumbusOS/streaming/blob/master/modules/registry/main.tf#L4", "Is this being created by another terraform script? Assuming it is look up the state. Is this a chicken/egg issue maybe?", "This tfstate file is associated with the bootstrap project.  The reason i have it here on the openvpn pull request is that we had some trouble with the state lock on dynamodb which required the dynamodb table to be required, but when i went to rebuild the dynamodb table it threw a bunch of errors because it was trying to create a whole new dynamodb table and s3 bucket, while both of them already existed.\r\n\r\nIf this state file had been there it would have been able to fix the issue on the fly without me having to do manual intervention.  This state should not be stored in s3 because the most likely reason to need to reference the state file is that if something went wrong with the s3 bucket or the dynamodb table that the bootstrap terraform script describes.  ", "Ah, i see.  Given the licensing  and other oddities with OpenVPN, i wouldn't be comfortable deploying any AMI other than this one without some sort of test deployment.  Creating an AMI resource for terraform seems a bit overkill for what we're trying to do. ", "Good idea"]}, {"url": "https://github.com/UrbanOS-Examples/common/pull/2", "comments": ["not sure about this tag ;) We have been doing terraform.workspace \r\n\r\nExample from below:\r\n```\r\n   tags = {\r\n     Owner       = \"${var.name}\"\r\n     Environment = \"${var.environment}\"\r\n     Name        = \"${var.owner}\"\r\n   }\r\n```", "why are we dropping the arn here?", "We are transitioning from storing state in sandbox AWS account to a newly created ALM account. As the first step we want to be able as an user in that account to execute terraform script. Next step is putting back the role arn so the script can be executed by a dev in another account. We have stories for this. This arn would be invalid anyway for the new S3 bucket and dynamo DB table.", "I agree. These tags are more meaningful. We have to come up with a standard approach for tags but this is outside the scope of this card.", "Should it be \r\n```\r\nOwner = \"${var.owner}\"\r\nName  = \"${var.name}\"\r\n```", "These terraform scripts will be run as a jenkins user who does not need to assume roles to manipulate aws."]}]}, {"url": "https://github.com/darogina/terragrunt-aws-modules.git", "pull_requests": []}, {"url": "https://github.com/cloudspout/Gefjun.git", "pull_requests": []}, {"url": "https://github.com/xerris/terraform-eks-bootstrap.git", "pull_requests": []}, {"url": "https://github.com/AlexReisSantos/terraform-helm-release.git", "pull_requests": []}, {"url": "https://github.com/cloudposse/terraform-aws-ecs-web-app.git", "pull_requests": [{"url": "https://github.com/cloudposse/terraform-aws-ecs-web-app/pull/234", "comments": ["This is the fundamental change that differs from #225 "]}, {"url": "https://github.com/cloudposse/terraform-aws-ecs-web-app/pull/216", "comments": ["```suggestion\r\n  description = \"The protocol version. One of `HTTP1`, `HTTP2`, `GRPC`. Only applicable when protocol is HTTP or HTTPS. Specify GRPC to send requests to targets using gRPC. Specify HTTP2 to send requests to targets using HTTP/2. The default is `HTTP1`, which sends requests to targets using HTTP/1.1\"\r\n```", "@zaksamalik ", "Please also run `make pr/auto-format`", "@nitrocode updated and formatted. Also just want to call out this bumps the pinned version for `alb-ingress` module to `0.25.1` to support the `protocol_version` variable."]}, {"url": "https://github.com/cloudposse/terraform-aws-ecs-web-app/pull/210", "comments": ["Why is using `var.codepipeline_enabled` not enough ? Why do we need a new input `var.ecr_enabled` ?\r\n\r\nAlso, `module.this.enabled` should be part of this too", "Because there are situations (like ours) where we use ECR but publish to it from GitHub Actions rather than CodePipeline and we don't want the registry destroyed if we set `codepipeline_enabled` to `false`.", "There is `var.enabled` but not seeing it used in this module.", "var.enabled is used in module.this which is set to module.this.enabled which is implicitly used on every cloudposse module via `context` input.\r\n\r\nIf you override the `enabled` argument on any cloudposse module, then you also need to pass in the `module.this.enabled` in the logic.\r\n\r\ni.e.\r\n\r\n```hcl\r\n  enabled = module.this.enabled && (var.ecr_enabled || var.codepipeline_enabled)\r\n```", "cc: @joe-niland ^", "Updated."]}, {"url": "https://github.com/cloudposse/terraform-aws-ecs-web-app/pull/207", "comments": ["This would need a dynamic\r\n\r\nhttps://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/ecs_task_definition#runtime_platform\r\n\r\nsince the example shows that it's a block, not an argument\r\n\r\n```hcl\r\n  runtime_platform {\r\n    operating_system_family = \"WINDOWS_SERVER_2019_CORE\"\r\n    cpu_architecture        = \"X86_64\"\r\n  }\r\n```", "also, it's unclear from the documentation if we're allowed to add multiple `runtime_platform` blocks", "Please test this change ", "@nitrocode this is an input to the module https://github.com/cloudposse/terraform-aws-ecs-alb-service-task\r\n\r\nIn that module it is constructed as a dynamic", "Ah I see. I assumed this input was added to the raw resource, not the upstream module. Thank you for correcting me."]}, {"url": "https://github.com/cloudposse/terraform-aws-ecs-web-app/pull/189", "comments": ["Please do not upgrade to 1.3. we're not ready to do this yet.\r\n\r\nMany consumers are still using older tf versions and we've run into issues with the optional argument.\r\n\r\nPlease correct me if I'm wrong @Nuru @mcalhoun @osterman @aknysh .\r\n\r\nThis has come up several times and it would be nice if we had a decision and a link to send when it comes up.", "Ok - for now I will leave this PR pending until a decision to upgrade is made because this complex object is very annoying for a user to manage without optional properties.", "Using type any is the best way forward for now"]}, {"url": "https://github.com/cloudposse/terraform-aws-ecs-web-app/pull/182", "comments": ["<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure that CloudWatch Log Group is encrypted by KMS</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/cloudposse/terraform-aws-ecs-web-app/blob/master/main.tf#L15-L21\">aws_cloudwatch_log_group.app</a> |  ID: <code>BC_AWS_GENERAL_85</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```tf\n\nresource \"aws_cloudwatch_log_group\" \"pass\" {\n  ...\n+ kms_key_id        = \"someKey\"\n}\n```\n\n<h4>Description</h4>\nLog group data requires mandatory encryption settings in CloudWatch Logs. Developers can optionally use AWS Key Management Service for this encryption. This approach has several limitations:\n- If you revoke CloudWatch Logs access to an associated CMK or delete an associated CMK, your encrypted data in CloudWatch Logs can no longer be retrieved. \n- You cannot associate a CMK with a log group using the CloudWatch console.\n\n</details>", "Not really relevant to this PR.", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure that CloudWatch Log Group is encrypted by KMS</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/cloudposse/terraform-aws-ecs-web-app/blob/master/main.tf#L15-L21\">module.web_app.aws_cloudwatch_log_group.app</a> |  ID: <code>BC_AWS_GENERAL_85</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```tf\n\nresource \"aws_cloudwatch_log_group\" \"pass\" {\n  ...\n+ kms_key_id        = \"someKey\"\n}\n```\n\n<h4>Description</h4>\nLog group data requires mandatory encryption settings in CloudWatch Logs. Developers can optionally use AWS Key Management Service for this encryption. This approach has several limitations:\n- If you revoke CloudWatch Logs access to an associated CMK or delete an associated CMK, your encrypted data in CloudWatch Logs can no longer be retrieved. \n- You cannot associate a CMK with a log group using the CloudWatch console.\n\n<b>Dependent Resources</b>\n<br>\n<br><p>Calculating...</p>\n</details>\n<p>:tada: &nbsp; <b>Fixed</b> by commit bd4b14f532f6541576bef99703812effac34f8ca - fix: add check if the module is enabled before calls to coalesce</p>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure that CloudWatch Log Group is encrypted by KMS</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/cloudposse/terraform-aws-ecs-web-app/blob/master/main.tf#L15-L21\">module.ecs_web_app.aws_cloudwatch_log_group.app</a> |  ID: <code>BC_AWS_GENERAL_85</code>\n            <br></summary>\n<h4>How to Fix</h4>\n\n```tf\n\nresource \"aws_cloudwatch_log_group\" \"pass\" {\n  ...\n+ kms_key_id        = \"someKey\"\n}\n```\n\n<h4>Description</h4>\nLog group data requires mandatory encryption settings in CloudWatch Logs. Developers can optionally use AWS Key Management Service for this encryption. This approach has several limitations:\n- If you revoke CloudWatch Logs access to an associated CMK or delete an associated CMK, your encrypted data in CloudWatch Logs can no longer be retrieved. \n- You cannot associate a CMK with a log group using the CloudWatch console.\n\n<b>Dependent Resources</b>\n<br>\n<br><p>Calculating...</p>\n</details>\n<p>:tada: &nbsp; <b>Fixed</b> by commit bd4b14f532f6541576bef99703812effac34f8ca - fix: add check if the module is enabled before calls to coalesce</p>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure that CloudWatch Log Group is encrypted by KMS</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/cloudposse/terraform-aws-ecs-web-app/blob/master/main.tf#L15-L21\">module.ecs_web_app.aws_cloudwatch_log_group.app</a> |  ID: <code>BC_AWS_GENERAL_85</code>\n            <br></summary>\n<h4>Description</h4>\nLog group data requires mandatory encryption settings in CloudWatch Logs. Developers can optionally use AWS Key Management Service for this encryption. This approach has several limitations:\n- If you revoke CloudWatch Logs access to an associated CMK or delete an associated CMK, your encrypted data in CloudWatch Logs can no longer be retrieved. \n- You cannot associate a CMK with a log group using the CloudWatch console.\n\n</details>\n<p>:tada: &nbsp; <b>Fixed</b> by commit 5107808c9c6946c32f66e4c0a49d879d79a6eb0a - fix: No need to check if module enabled for container_name</p>", "<details>\n    <summary>\n        <img src=\"https://bc-network-graph-icons.s3.us-west-2.amazonaws.com/prCommentsSeverityIcons/low.svg\" alt=\"LOW\" width=\"64px\" align=\"center\">\n            &nbsp;&nbsp;<b style=\"color:black\" >Ensure that CloudWatch Log Group is encrypted by KMS</b>\n            <br>\n               &nbsp;&nbsp;&nbsp;&nbsp;Resource:  <a href=\"https://github.com/cloudposse/terraform-aws-ecs-web-app/blob/master/main.tf#L15-L21\">module.web_app.aws_cloudwatch_log_group.app</a> |  ID: <code>BC_AWS_GENERAL_85</code>\n            <br></summary>\n<h4>Description</h4>\nLog group data requires mandatory encryption settings in CloudWatch Logs. Developers can optionally use AWS Key Management Service for this encryption. This approach has several limitations:\n- If you revoke CloudWatch Logs access to an associated CMK or delete an associated CMK, your encrypted data in CloudWatch Logs can no longer be retrieved. \n- You cannot associate a CMK with a log group using the CloudWatch console.\n\n</details>\n<p>:tada: &nbsp; <b>Fixed</b> by commit 5107808c9c6946c32f66e4c0a49d879d79a6eb0a - fix: No need to check if module enabled for container_name</p>", "Why do the container names also need to use the enable logic", "AFAIK `coalesce` has to return a not-null value and if this module is disabled and `var.alb_container_name` is not set (it's optional), this line will raise an error.\r\n\r\nI could replace it with `try` if you don't like this approach:\r\n```tf\r\ncontainer_name = try(coalesce(var.alb_container_name, module.this.id), null)\r\n```", "Can we update the line to drop coalesce then?\r\n\r\n```hcl\r\n    container_name   = var.alb_container_name != null ? var.alb_container_name : module.this.id\r\n```\r\n", "Done \ud83d\udc4d\ud83c\udffb "]}, {"url": "https://github.com/cloudposse/terraform-aws-ecs-web-app/pull/160", "comments": ["I confirmed that these are the same defaults in the upstream module\r\n\r\n https://github.com/cloudposse/terraform-aws-alb-ingress"]}, {"url": "https://github.com/cloudposse/terraform-aws-ecs-web-app/pull/152", "comments": ["I think it should be this.\r\n\r\n```suggestion\r\n  enabled = module.this.enabled && var.alb_enabled\r\n```", "It would be safer to have a `local` at the top that has the following\r\n\r\n```hcl\r\nlocals {\r\n  alb_enabled = module.this.enabled && var.alb_enabled\r\n}\r\n```\r\n\r\nand then reference `local.alb_enabled` here and below", "```suggestion\r\n  load_balancers     = var.nlb_ingress_target_group_arn != \"\" ? concat(local.alb_load_balancers, [local.nlb]) : local.alb_load_balancers\r\n```", "```suggestion\r\n  enabled = local.alb_enabled && var.alb_target_group_alarms_enabled\r\n```", "Fixed this line and a couple of others I found, `var.alb_enabled` should only be referenced when setting the local variable now. ", "The more I look at this, I realize that were being inconsistent here. We're using `var.nlb_ingress_target_grouo_arn` to determine if we add the nlb to the list of load balancers. We already have a similar variable for the alb. Why don't we use that same logic here for the alb?\r\n", "Easy enough update, I drop the `alb_enabled` variable", "Looks like this module doesn't support NLB creation, but does support ALB creation. I think that bit of inconsistency prompted the additional variable fwiw", "Exploring the TF that it looks like an alb also isn't created within this module, looking at bit at the collection of module I might have missed some of the configuration of submodules. I might have been able  to set `alb_ingress_enable_default_target_group` to `false` to achieve similar behavior", "@gausnes is this change no longer needed ?"]}, {"url": "https://github.com/cloudposse/terraform-aws-ecs-web-app/pull/147", "comments": ["Variable name should be `codebuild_cache_type`.\r\nI think defaulting to `NO_CACHE` will be best, otherwise you will hit the same error you encountered. I think we need to test this PR with values `S3` and `NO_CACHE`.", "Variable on ecs-codepipeline module is named `cache_type`", "```suggestion\r\n  cache_type = var.codebuild_cache_type\r\n```", "@joe-niland - thanks, I'll make the change and set the default to `NO_CACHE`. Actually, I have been testing with NO_CACHE locally, and seems to have resolved the original problem I had messaged in slack about. ", "description says \"Defaults to S3\", but declaration says \"NO_CACHE\"", "@gregnphe - good catch, I should have been more vigilant.", "```suggestion\r\n  default     = \"S3\"\r\n```"]}, {"url": "https://github.com/cloudposse/terraform-aws-ecs-web-app/pull/138", "comments": ["You probably did not mean to delete this, but in any case, the `workflow_dispatch` trigger needs to remain"]}, {"url": "https://github.com/cloudposse/terraform-aws-ecs-web-app/pull/126", "comments": ["For compatibility with https://github.com/cloudposse/terraform-aws-alb-ingress/pull/51", "For compatibility with https://github.com/cloudposse/terraform-aws-alb-ingress/pull/45", "I do not feel comfortable with modifying context.tf since a standard supported across modules.\r\nI think if we need a min_lenght then we should add that to the null-label module to support it.", "@jamengual I'm a bit confused - this is the latest context.tf that is installed via `make github/init` in the build-harness, pulled from [here](https://raw.githubusercontent.com/cloudposse/terraform-null-label/master/exports/context.tf).", "ohhhhh sorry, I guess this module has not been updated in a while......", "No problem! I just rebased onto the latest master and fixed the conflicts."]}, {"url": "https://github.com/cloudposse/terraform-aws-ecs-web-app/pull/105", "comments": ["Why are we reverting to the slash comments?", "Just generally reverting to TF 0.12 support by reverting some commits. No special reason.", "`context.tf` has the // anyway, so it's not going to pass lint. Will fix when we update `context.tf`"]}, {"url": "https://github.com/cloudposse/terraform-aws-ecs-web-app/pull/88", "comments": ["**Error Description**: [Ensure CloudWatch logs are encrypted at rest using KMS CMKs](https://docs.bridgecrew.io/docs/logging_21)\n                            **Category**: Logging | **Severity**: LOW\n                            **Resource**: aws_cloudwatch_log_group [app], lines: 62 - 66", "**Error Description**: [Ensure CloudWatch logs are encrypted at rest using KMS CMKs](https://docs.bridgecrew.io/docs/logging_21)\n                            **Category**: Logging | **Severity**: LOW\n                            **Resource**: aws_cloudwatch_log_group [app], lines: 61 - 65", "**Error Description**: [Ensure CloudWatch logs are encrypted at rest using KMS CMKs](https://docs.bridgecrew.io/docs/logging_21)\n                            **Category**: Logging | **Severity**: LOW\n                            **Resource**: aws_cloudwatch_log_group [app], lines: 61 - 65"]}, {"url": "https://github.com/cloudposse/terraform-aws-ecs-web-app/pull/78", "comments": ["I think this should be called container_environment and the one below called map_container_environment", "@joe-niland fixed"]}, {"url": "https://github.com/cloudposse/terraform-aws-ecs-web-app/pull/77", "comments": ["please just use \r\n```\r\nrequired_version = \">= 0.12\"\r\n```", "```suggestion\r\n    template = \">= 2.0\"\r\n```", "```suggestion\r\n    null     = \">= 2.0\"\r\n```", "```suggestion\r\n    local    = \">= 1.3\"\r\n```"]}, {"url": "https://github.com/cloudposse/terraform-aws-ecs-web-app/pull/68", "comments": ["Seems like this is losing a log of the current configuration options ", "Why is this whole section removed?", "this could yield to problems with the alb name size that is max 32 char", "I think the region needs to stay", "same as before, we should not remove sections from the tests", "True, but I think we should still add it to the tests. We might need to update any fixtures if this gets too long.", "E.g. the user can always reduce the length of the parameters, but our contract should be we pass the parameters to all modules. ", "Yes, agree", "If this was causing a problem, share the problem and let's discuss the remedy. ", "I removed it because `terraform validate` said:\r\n\r\n```\r\nError: Unsupported argument\r\n\r\n  on main.tf line 26, in module \"subnets\":\r\n  26:   region                   = var.region\r\n\r\nAn argument named \"region\" is not expected here.\r\n```", "The problem is that `terraform validate` said:\r\n\r\n```\r\nError: Unsupported argument\r\n\r\n  on main.tf line 103, in module \"web_app\":\r\n 103:   log_configuration = {\r\n\r\nAn argument named \"log_configuration\" is not expected here.\r\n```\r\nThe `main.tf` of the module itself (also) sets the `log_configuration` based on the variables, it wasn't clear to me why this specific configuration was required in the example itself?\r\n"]}, {"url": "https://github.com/cloudposse/terraform-aws-ecs-web-app/pull/62", "comments": ["```suggestion\r\n  description = \"The environment variables to pass to the container. This is a map of string: {key: value}. `environment` overrides `map_environment`\"\r\n```"]}, {"url": "https://github.com/cloudposse/terraform-aws-ecs-web-app/pull/45", "comments": ["```suggestion\r\n  ignore_changes_task_definition    = var. ignore_changes_task_definition\r\n```\r\n\r\nWe can use the same name to avoid name explosion :)  ", "```suggestion\r\nvariable \"ignore_changes_task_definition\" {\r\n```", "why `ulimits` was removed from the generated docs?\r\nCan you please run these commands again:\r\n\r\n```\r\nmake init\r\nmake readme/deps\r\nmake readme\r\n```\r\n\r\n", "This is simply what happened when I ran this. I re-ran and confirmed ulimits was present, so this should be solved.", "Fixed in lastest rev", "Fixed in latest rev"]}, {"url": "https://github.com/cloudposse/terraform-aws-ecs-web-app/pull/28", "comments": ["```suggestion\r\n  source     = \"git::https://github.com/cloudposse/terraform-aws-ecr.git?ref=tags/0.5.0\"\r\n```\r\n\r\nThe previous version did not have `enabled` flag\r\n", "sorry, my bad. I checked master."]}, {"url": "https://github.com/cloudposse/terraform-aws-ecs-web-app/pull/25", "comments": ["Make it a variable so you don't have to hack up the example"]}, {"url": "https://github.com/cloudposse/terraform-aws-ecs-web-app/pull/21", "comments": ["I think we should just pin to `master` for the *example* because this always falls out of date. We do recommend version pinning, but don't do it in the docs for this reason. \r\n\r\nWhat do you think?", "That's a great idea!", "```suggestion\r\n  source                       = \"git::https://github.com/cloudposse/terraform-aws-ecs-web-app.git?ref=master\"\r\n```\r\n\r\nLet's be explicit and show that we use `master` for the example", "```suggestion\r\n    source                       = \"git::https://github.com/cloudposse/terraform-aws-ecs-web-app.git?ref=master\"\r\n```"]}, {"url": "https://github.com/cloudposse/terraform-aws-ecs-web-app/pull/20", "comments": ["pin to a release", "```suggestion\r\n  description = \"The URL of the build badge when `badge_enabled` is enabled\"\r\n```", "This branch has been merged and a release (0.4.0) cut"]}, {"url": "https://github.com/cloudposse/terraform-aws-ecs-web-app/pull/19", "comments": ["I've cut a new release since merging this branch: 0.6.3"]}, {"url": "https://github.com/cloudposse/terraform-aws-ecs-web-app/pull/18", "comments": ["Let's keep the output consistent. Rename to `service_security_group_id`", "ahh yeah, from before... "]}, {"url": "https://github.com/cloudposse/terraform-aws-ecs-web-app/pull/17", "comments": ["Can you update readme.yaml example with environment variables. Then build readme.", "just a nitpick, but this TF snippet needs `terraform fmt`", "just a nitpick, but this TF snippet needs `terraform fmt`\r\nwell be regenerated after updating in `README.yaml` and then rebuilding README\r\n\r\n```\r\nmake init\r\nmake readme/deps\r\nmake readme\r\n```\r\n", "can you add\r\ntype        = \"list\"\r\n\r\n(and do `terraform fmt`)\r\n"]}, {"url": "https://github.com/cloudposse/terraform-aws-ecs-web-app/pull/4", "comments": ["better to keep consistent names than optimize for length. We didn't optimize for length in `terraform-aws-ecs-cloudwatch-sns-alarms`, so shouldn't do it here.", "I think this is a misleading name since it's actually related to the target group and we have another module for monitoring the alb, no?", "update readme"]}, {"url": "https://github.com/cloudposse/terraform-aws-ecs-web-app/pull/1", "comments": ["Update related to link to all other ECS related repos", "Update inline usage example", "Lets default to `cloudposse/default-backend` and make this a `variable`", "Make variables", "Make this a variable", "Make this a variable", "add variable for `hosts` and `paths`"]}]}, {"url": "https://github.com/vx-labs/infra.git", "pull_requests": []}, {"url": "https://github.com/oracle-quickstart/oci-cis-landingzone-quickstart.git", "pull_requests": [{"url": "https://github.com/oracle-quickstart/oci-cis-landingzone-quickstart/pull/139", "comments": ["Missing file add confirmed."]}]}, {"url": "https://github.com/kitchen/personal-terraform.git", "pull_requests": []}, {"url": "https://github.com/koenighotze/koenighotze-gcp-base-setup.git", "pull_requests": []}, {"url": "https://github.com/skyscrapers/terraform-vault.git", "pull_requests": [{"url": "https://github.com/skyscrapers/terraform-vault/pull/5", "comments": ["you want to put the replica table _in_", "If it has 2 regions enabled, should it output where they are? That way running `terraform output` will help with diagnosis?", "done"]}, {"url": "https://github.com/skyscrapers/terraform-vault/pull/3", "comments": ["I'm not convinced about this. IMO this should have been the right approach from the beginning, as previously the dynamodb table name was hardcoded to \"vault-dynamodb-backend\", which would prevent multiple Vault setups in the same AWS account.\r\nOn the other hand, changing this now to a dynamic name introduces a huge overhead when rolling this out to the current Vault setups, as we'll need to migrate data to another db, which will require some downtime and it'll probably be time consuming. So I'm not sure if it's worth the effort.", "There is only one small thing to consider. If the test fails for any reason some resources might still be there and not cleaned-up so it might be a good idea to make sure that all the test resources have been destroyed ", "I'll created an issue to create a test AWS account, where to run the tests: https://github.com/skyscrapers/engineering/issues/37\r\n\r\nOk for you to approve this PR?", "don't forget to also add this to the release", "sure", "can all commented code be ceaned up? afaik it doesn't add any value"]}]}, {"url": "https://github.com/stackabletech/t2.git", "pull_requests": [{"url": "https://github.com/stackabletech/t2/pull/33", "comments": ["```suggestion\r\n* https://github.com/stackabletech/spark-operator[Apache Spark]\r\n* https://github.com/stackabletech/zookeeper-operator[Apache ZooKeeper]\r\n* https://github.com/stackabletech/kafka-operator[Apache Kafka]\r\n```", "```suggestion\r\nThe script expects the private SSH key (matching one of the public keys in the Stackable cluster definition) to be in your keystore (`~/.ssh/` in Linux). If you keep it at another location, you can provide the path to the private key with the `-i` option.\r\n```", "I think I'd call this publicKeys just to be totally sure that there is no confusion about this being a private key that is rolled out to enable sshing betwen machines or something else that people could come up with.\n", "Should we maybe add an optional field to specify tags? Then again, I could imagine it becoming a bit complex passing these to the cloud provider and then reading them back out into Ansible to pass to the agent ...", "\"Spring Boot\" I believe\n", "If I am not mistaken by adding different templates we could use other providers than IONOS? If so, maybe stay \"neutral\" here.", "nit: maybe \"configured\" instead of \"connected\"", "I suggest we add them once we have a use case for the tags, okay?", "Good idea, I'll change that.", "To be honest, I am not sure if merely a change in the template would allow us to use other providers. Maybe there will be a code change required as well (not a huge one though). But I agree that we should be neutral in our definition file. I assume we'll end up with a subsection that contains cloud-vendor-specific fields.", "I agree that \"connected\" does not sound right. I omitted the adjective entirely though.", "Done"]}]}, {"url": "https://github.com/glenngillen/terraform-demo-cost-estimation-azure.git", "pull_requests": []}, {"url": "https://github.com/davidmaceachern/dev.git", "pull_requests": []}, {"url": "https://github.com/acmucsd/tech-stack.git", "pull_requests": []}, {"url": "https://github.com/william-goltz-calendar/RancherQuickstart.git", "pull_requests": []}, {"url": "https://github.com/bjornhofer/vwan-test.git", "pull_requests": []}, {"url": "https://github.com/mcgrof/kdevops_terraform.git", "pull_requests": []}, {"url": "https://github.com/alstard/terraform.git", "pull_requests": []}, {"url": "https://github.com/nubisproject/nubis-terraform-cloudhealth.git", "pull_requests": []}, {"url": "https://github.com/Terraform-Projects/lead-terraform-Dashboard.git", "pull_requests": []}, {"url": "https://github.com/ragul28/terraform-mulitcloud-k8s.git", "pull_requests": []}, {"url": "https://github.com/fecgov/fec-infrastructure.git", "pull_requests": [{"url": "https://github.com/fecgov/fec-infrastructure/pull/80", "comments": ["Next time for testing/temporary replicas, we should do `prevent_destroy = false`"]}, {"url": "https://github.com/fecgov/fec-infrastructure/pull/40", "comments": ["Do we want to keep this at `1,000` for our default and adjust to 1ms manually when we are actively profiling for a complete picture or just set it to 1ms in general, based on some of the other feedback we had received?", "IMO, the former - set it to `1000` for our default, and override it when we are actively profiling.", "\ud83d\udc4d  I like the idea of keeping this as a default and overriding during periods when we need more data.", "Sounds good!  Let's coordinate a plan for deployment.  This shouldn't result in any restarts but just want to be sure and monitor just in case. :-)", "I just confirmed that this is a dynamic setting in [RDS' PostgreSQL parameter group documentation](http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Appendix.PostgreSQL.CommonDBATasks.html#Appendix.PostgreSQL.CommonDBATasks.Parameters) (you'll have to search for the `log_min_duration_statement` setting in the table), so there should be zero downtime and no restarts."]}, {"url": "https://github.com/fecgov/fec-infrastructure/pull/23", "comments": ["It looks like this should be the role policy, not the assume role policy--the first is what the role is allowed to do, and the second is who is allowed to assume the role. I think you want to move this policy to a separate `aws_iam_role_policy` resource and associate the policy resource with the role: https://www.terraform.io/docs/providers/aws/r/iam_role_policy.html.", "The syntax here should be:\r\n\r\n```hcl\r\nresource \"aws_iam_role_policy\" \"test_policy\" {\r\n  name = \"test_policy\"\r\n  role = \"${aws_iam_role.test_role.id}\"\r\n  policy = <<EOF\r\n...\r\nEOF\r\n}\r\n```\r\n\r\nThe docs at https://www.terraform.io/docs/providers/aws/r/iam_role_policy.html include a good example. You can also use the `terraform validate` command to check whether the configuration is valid.", "This doesn't look like a policy that controls what can assume the role. Unless the docs for RDS monitoring say something different, I'm guessing you'll want the standard assume role policy from the docs:\r\n\r\n```json\r\n{\r\n  \"Version\": \"2012-10-17\",\r\n  \"Statement\": [\r\n    {\r\n      \"Action\": \"sts:AssumeRole\",\r\n      \"Principal\": {\r\n        \"Service\": \"ec2.amazonaws.com\"\r\n      },\r\n      \"Effect\": \"Allow\",\r\n      \"Sid\": \"\"\r\n    }\r\n  ]\r\n}\r\n```", "Probably needs to be `arn:aws-us-gov:logs:*:*:*`.", "I was trying to mirror the way I set up the logging role I set up in the console, but if the standard policy is better, I can go with that. ", "Looks like these policies are reversed--the `assume_role_policy` on the role should control `AssumeRole`, and the `policy` on the policy should control logging.", "Thanks for catching that, it seems obvious now that you say it. ", "Looks like this variable name should be `monitoring_role_arn`."]}, {"url": "https://github.com/fecgov/fec-infrastructure/pull/22", "comments": ["Going to confirm the units on this and update if needed\r\n", "yep, we needed kb here"]}, {"url": "https://github.com/fecgov/fec-infrastructure/pull/19", "comments": ["@vrajmohan, do you know if this is the correct way to set this?  Looking over the [Postgres documentation](https://www.postgresql.org/docs/9.6/static/runtime-config-replication.html#GUC-MAX-STANDBY-STREAMING-DELAY) appears to be a value in milliseconds, but it's also not entirely clear.  I'm trying to look in the RDS documentation too to see and verify.", "Also noting that this is a `dynamic` parameter, which means that it should just be applied immediately to an instance without the need to reboot: http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Appendix.PostgreSQL.CommonDBATasks.html#Appendix.PostgreSQL.CommonDBATasks.Parameters", "Ah yes, the data type is `integer` for this, and the description in the RDS parameter settings says it's milliseconds:  `(ms) Sets the maximum delay before canceling queries when a hot standby server is processing streamed WAL data.`\r\n\r\nSo it looks like for this to be an hour, it needs to be set to `3600000`.  Just double checking:  is an hour appropriate here?", "From https://www.postgresql.org/docs/9.5/static/runtime-config-replication.html#GUC-MAX-STANDBY-STREAMING-DELAY, \"_Units are milliseconds if not specified_\". @LindsayYoung and I discussed the value and decided that `1h` was a reasonable tradeoff between performance and having data current.", "The discussion settled on an hour gives a big buffer to keep queries moving. Do you have any concerns with it being too long or short?", "On the issue of it being a dynamic parameter, does that mean it should be specified differently in `terraform`?", "No concerns on the timeframe, was just verifying!  And as for dynamic parameter, that was in reference to RDS-managed PostgreSQL instances.  Dynamic parameters should not require a reboot to be applied, so this should take effect immediately once it's pushed. :-)"]}, {"url": "https://github.com/fecgov/fec-infrastructure/pull/9", "comments": ["This is correct, but IMO it's clearer to stick with the reference instead of the literal name in case the identifier ever changes."]}, {"url": "https://github.com/fecgov/fec-infrastructure/pull/8", "comments": ["This defaults to `true`, but never hurts to set for explicitness: https://www.terraform.io/docs/providers/aws/r/db_instance.html#auto_minor_version_upgrade.", "AWS won't let you change a database identifier without destroying and recreating, which terraform captures using the `ForceNew` flag: https://github.com/hashicorp/terraform/blob/master/builtin/providers/aws/resource_aws_db_instance.go#L103-L109. We're setting the `prevent_destroy` lifecycle flag in this file to prevent potentially unintended destroys and recreates, so AFAIK this change will cause terraform to crash--it wants to destroy the database because the identifier changed, but it can't because we told it never to destroy these resources. If changing the identifier is important (I'm guessing it isn't, because we're already setting the database names), then you can also temporarily drop the `prevent_destroy` flags, then restore them after applying these changes.", "Oh wow, this is not what I was seeing when I was looking at the docs before - somehow I was only seeing the parameter names, no values!", "Ah right, good catch!  I was changing them here because we were seeing strings with just random alphanumeric characters in them for the names when we looked in the console, which were not all that clear in terms of what was what.\r\n\r\n@LindsayYoung, do you think we should go ahead and change them?  If so, now is definitely the time to do it as opposed later on, I would think (except for staging at the moment due to the aforementioned ATO reason).", "I see the difference (note the `d` instead of the `r` in the URL path), not sure how I didn't get to what you were looking at, but I somehow got to here: https://www.terraform.io/docs/providers/aws/d/db_instance.html#storage_type\r\n\r\nNot as useful. :-)", "Those are the data source docs--they're for importing information from external resources or another terraform confirmation: https://www.terraform.io/docs/configuration/data-sources.html. We want the resource docs, which actually provision infrastructure.", "I have a slight preference to changing the names to something more friendly, I think it might help reduce human error that might happen from thinking you are a different rds box than you are.", "Ok, I think this might also be a good excuse to restore from a backup and document that. \r\n\r\nLet me see if I understand the steps:\r\nchange the code to allow destroy for this pr\r\ndouble check that we have the last back up\r\nwork with infrastructure to run the terraform commands\r\nRestore from back up (would we do this from the AWS console?)\r\nmake a new pr that disallows destroy \r\n\r\ndoest that sound right @jmcarp ", "The goal of terraform is to avoid having to use the console most of the time, and to capture all changes in configuration. Terraform lets you create an rds instance from a snapshot identifier, so I think you'd want to:\r\n\r\n* Change the configuration to allow destroy, *and* to set the `snapshot_identifier` attributes of the instances you want to restore\r\n* Apply changes via terraform (this should happen automatically on merge, but you might need to coordinate if there's a config error)\r\n* Change the configuration to prevent destroy", "Thanks for clarifying that is helpful!"]}, {"url": "https://github.com/fecgov/fec-infrastructure/pull/5", "comments": ["Did this change just to match the job name above and/or the script name below?  Trying to recall what this is in reference to.", "We need to share this information with folks like @erik-burgess just like the RDS credentials, right?", "Yep, just renamed for consistency.", "Right!"]}, {"url": "https://github.com/fecgov/fec-infrastructure/pull/3", "comments": ["I think I called this out before, but we're definitely excited to use this as an opportunity to also upgrade to 9.6.1.  Thank you!", "I just spoke with Rohan and Wei at FEC, we'd like to bump this up to 2 TB (`2000`) for all environments.", "Same note as above about bumping size up (`2000`).", "Same note as above about bumping size up (`2000`)."]}, {"url": "https://github.com/fecgov/fec-infrastructure/pull/2", "comments": ["These resources are the info about the RDS instances being created and the tags required for billing, correct?  I'm trying to remember what else was on the screen that @mogul showed us.", "This is a pull request containing primarily the Terraform updates/changes, correct?", "As Chandika should already be setup at this point, there shouldn't be anything else needed after this step (unless an error occurred), right?  Or is that what you were referring to with `all resources are properly tagged` a few steps above?", "If terraform has created a new rds instance (which won't happen often), fec will need to get its endpoint url. That will show up in the terraform output, which infrastructure will have to send via fugacious or similar. This is kind of a headache, but it saves fec from having to manage and lock down a concourse instance.", "Right!", "Two parts to this:\r\n* FEC should tag every resource with the appropriate tag (whatever that is!) via terraform, and infrastructure should check those tags when reviewing pull requests.\r\n* FEC should list resources in chandika so that chandika doesn't destroy them.", "Ah okay, thank you for clarifying!", "Oh right, so if a new RDS instance were created (which you're right, should not be often!), then that endpoint URL will need to be added to Chandika, but otherwise we should be okay then, correct?", "I'm guessing chandika manages resources by ARN, so we might need to output that too--what I was thinking of was grabbing the endpoint url so that you all know where to point your apps.", "Okay, I see now (sorry, only exposure to Chandika currently is what @mogul showed us briefly when we spoke last week).  And yes, we'd definitely need the endpoints for the apps too. :-)  Thanks!", "I'm unclear on this bit... What Concourse credentials will an FEC team member have? 18F infrastructure owns the Concourse team, right?", "FEC might want to update the database name / username / password on an RDS instance.", "This is no longer needed, right?", "Because everything in the account gets billed to FEC?", "Yes, tagging only matters for accounts that are shared, eg 18F sandboxes supervised by Chandika."]}]}, {"url": "https://github.com/exekube/demo-grpc-project.git", "pull_requests": []}, {"url": "https://github.com/raghudevops53/terraform-payment.git", "pull_requests": []}, {"url": "https://github.com/pangealab/pegasus.git", "pull_requests": []}, {"url": "https://github.com/dropseed/pullapprove-enterprise.git", "pull_requests": []}, {"url": "https://github.com/chtest0410/tf1.git", "pull_requests": []}, {"url": "https://github.com/jtaylormayfield/tf-omega.git", "pull_requests": []}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws.git", "pull_requests": [{"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/1244", "comments": ["Looks like these have extra whitespace hangover from previous version", "Can you please format to align the `=`? Thank you."]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/988", "comments": ["Where do we manage these emails - in the AWS console? I think it'd be helpful to have a link or short description in case we ever want to make changes.", "Good idea."]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/982", "comments": ["```suggestion\r\n        run: invoke requirements-dev\r\n```\r\nlikewise for line 31 (I can't add as a suggestion...) which should be replaced for\r\n```\r\n        run: invoke test\r\n```"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/956", "comments": ["`# Or ${var.ssh_key_name}` - what does this mean?", "Why this new blank line?", "@bjgill this is a copy-paste from the current instance block, but appears to be a reference that you may wish to use your own variable (as defined in https://github.com/alphagov/digitalmarketplace-aws/blob/889d2e369bbd25c939f69d8bec39aa6c4143938d/terraform/accounts/main/jenkins.tf#L2-L3)", "removed in 889d2e3."]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/911", "comments": ["Though, what's the significance of this date?", "It means we're using the latest version of the policy language and we have to include it - see https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_elements_version.html"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/910", "comments": ["Why do we need to bump this version?", "@bjgill I got an error about legacy providers and the upgrade not being able to proceed before I did this. I think maybe the version bump makes it fetch the new provider version which solved the issue as a side-effect.", "Sounds reasonable. Would have been nice to have this information in the commit/PR description.", "@bjgill fair point, I've updated the PR description now."]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/841", "comments": ["Nice. But is this going to get lost next time we update dependencies manually?", "No I think it will be fine"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/840", "comments": ["Any reason not to go to `python:3.6.13-slim` now?", "\ud83d\udc40  good spot @alex9smith updated now in 79cd77a"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/750", "comments": ["This looks a little suspect...", "Yes - I think this may be the cause of the error you were seeing for Preview. We'll take a look.", "Some extra curly braces snuck in here", "Oh dear. I'd recommend not reviewing further - probably more efficient for us to fix all of these first."]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/700", "comments": ["Line break missing here", "good spot \ud83d\udc40   fixed in 5434ff0"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/681", "comments": ["\ud83d\ude0d this is a great catch!", "Nice find! Did you try a success run on Preview with this new environment variable?", "@katstevens whilst I forced the jobs to fail by constraining the memory, they did get as far as connecting to the database and starting following steps before running out of memory, so I am confident this works.", "Excellent stuff \ud83d\udc4d "]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/680", "comments": ["I'm not sure I understand why the `> /dev/null` is needed; if I do `TEST=$(echo hello world)` on my machine nothing gets echoed to stdout, so why is stuff getting echoed here? \ud83e\udd14 ", "I think it shows up as part of `stderr` in the error case i.e. here:  https://ci.marketplace.team/job/database-backup/1137/console", "the `ERR` prefix maps to `stderr` as per https://docs.cloudfoundry.org/devguide/deploy-apps/streaming-logs.html", "So should we be redirecting `stderr` instead of `stdout`?", "Possibly, that said I'm not sure if that'd work either thinking more about it. If it is just dumping the command history."]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/675", "comments": ["Despite what it says here (\ud83d\ude3f), our preview/staging/prod lambdas are all currently on 10.x. Do we want to upgrade to 12? Any breaking changes expected?", "That's a good question. I chose to bump into 12 because it's the current active LTS. I had a look at https://nodejs.org/tr/blog/uncategorized/10-lts-to-12-lts/ and the code and nothing raised any alarms. Do you think it's maybe best to scope out the move to 12 out of this PR to unblock the other PR?", "On retrospect, having a look again, the code is quite old and I can't find the original code it's based off. I also don't want to impact the work @gidsg is doing, so I'll switch to 10.\r\nWe'll need to revisit in 6 months time when 10 reaches end of life, but I'll add a card to the backlog with a date to remind us."]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/674", "comments": ["I think this is the line that's failing the `terraformat` linting.", "I know these were already there, but can we get rid of the extra `for` in the comments \ud83d\ude38 ", "I agree with the commit message - as discussed elsewhere, if the attacker is sophisticated enough to piggyback on a valid reset, 1 minute vs 5 minutes is unlikely to make a difference. However we should make a note to review this as a key alert if/when we get set up with Splunk. ", "Ack! My bad!, completely forgot to run terraform plan... looking at it now", "I did think about this, actually. And wondered if it was meant as `for \"for every 300 seconds\"` \ud83e\udd23 I will clean up", "I'll add the comment about Splunk to the tech debt card", "tech debt card added, resolving"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/622", "comments": ["Does this depend on a fixed ordering of routes? I remember that biting us in the past...", "It does. It uses the same pattern as where it inherited it before here:\r\nhttps://github.com/alphagov/digitalmarketplace-aws/blob/master/paas/_base.j2#L15\r\n\r\nWe could probably hard code this now we know what app we're operating on.\r\n\r\nBut might not need to change this at app now\r\n\r\nalphagov/digitalmarketplace-antivirus-api#59\r\nalphagov/digitalmarketplace-utils#550"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/621", "comments": ["We don't have a requirements-app for the AWS repo, just requirements.txt.", "\ud83e\udd26\u200d\u2642 good point"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/620", "comments": ["This will make a few things fail - `user.marketplace.team` is a safelisted domain for both buyers and admins. I believe we've also set up Notify to only pretend to send emails to that domain.", "Yeah, I had a feeling there would be issues like this; do you think the change is worth the hassle?", "Let's go back to the user need. When/where do we need to know what role the user has? ", "Good question.\r\n\r\nThis PR was originally prompted by this [Slack thread comment by @aliuk2012]( https://gds.slack.com/archives/CFLL8967N/p1575015824006500?thread_ts=1575015193.005000&cid=CFLL8967N), as Al said there this change probably wouldn't help him, as his need is being able to see is logged into the system just by looking at the screens.\r\n\r\nHowever it does give more context when you are on the account page of a user; and if the user name is on the page for some reason (say for instance in the header in some way) it would be informative."]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/611", "comments": ["Hmm, we seem to have left these in for a reason - another file imports them", "I couldn't find where else imports TemplateSyntaxError. As for UndefinedError, I've just added that specific import into test_utils rather than importing it to here and then importing it from here to there"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/604", "comments": ["See L4", "Copied from paas/db-backup.j2", "Copied from db-backup", "For saftey, see commit", "* Overrides are specified in manifest and vars files now\r\n* `APPLICATION_NAME=db-migration` makes the generate manifest step creat with the new manifest.\r\n* Leave no-route for safety", "This should be `process`, `none` is deprecated\r\n\r\n```suggestion\r\n    health-check-type: process\r\n```", "I'm a bit confused about using `APPLICATION_NAME=db-migration` and `${APPLICATION_NAME}:${RELEASE_NAME}` (which presumably has `APPLICATION_NAME=api` to get the right Docker image) in the same line...?", "This might be clearer/less prone to failure\r\n\r\n```suggestion\r\n\tcf push ${APPLICATION_NAME}-db-migration -f <(make -s -C ${CURDIR} generate-manifest APPLICATION_NAME=db-migration) -o digitalmarketplace/${APPLICATION_NAME}:${RELEASE_NAME} --no-route\r\n```", "Although to be honest, since we're special casing the api app here, we might as well take out the outer ${APPLICATION_NAME} references and hardcode api\r\n\r\n```suggestion\r\n\tcf push api-db-migration -f <(APPLICATION_NAME=db-migration make -s -C ${CURDIR} generate-manifest) -o digitalmarketplace/api:${RELEASE_NAME} --no-route\r\n```"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/603", "comments": ["If `--health-check-type none` is present, why do we need `--health-check-http-endpoint none`?", "I don't know, not a great design. But reading between the lines of the error\r\n\r\n> Health check type must be 'http' to set a health check HTTP endpoint.\r\n\r\nwe're setting `--health-check-type none` with the command line override then trying to set `health-check-http-endpoint` in the manifest here: https://github.com/alphagov/digitalmarketplace-aws/blob/master/paas/_base.j2#L18", "Ahh I see - we disable healthcheck on `cf push` but then `generate-manifest` puts one in anyway? \ud83e\udd14  ", "Yeah, the manifest puts in a url for the health check even though we set the 'healthcheck type' to `none` on the command line. CF throws a wobbly :/"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/579", "comments": ["Does this also prevent us destroying the instance with Terraform? Would we have to change & apply this attribute first if we needed to destroy for some reason?", "I believe if for some reason we wanted to destroy the instance we would just remove it from the terraform file, and then terraform would see that it was terminated.\r\n\r\nAlternatively we could terminate it from the AWS console by first removing the termination protection from the AWS console (https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/terminating-instances.html#Using_ChangingDisableAPITermination). This information is in the terraform manual for the aws_ec2_instance resource.", "Hmm, ok. Let's make sure we note this down in the manual."]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/574", "comments": ["We're hoping to move to all policy documents eventually. https://www.terraform.io/docs/providers/aws/d/iam_policy_document.html\r\n\r\nCan we do these with policy docs?", "Ooh let's try it"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/572", "comments": ["Unless this is used anywhere I wouldn't bother defining it", "hard to know what `assume_role_arn` is at a glance. It's called `account_id`, `validate_account_id` and `assume_role_arn` in different places. Can we normalise this?"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/569", "comments": ["This will get overwritten on production by the router block in:\r\nhttps://github.com/alphagov/digitalmarketplace-aws/blob/master/vars/production.yml#L9\r\n\r\nhttps://github.com/alphagov/digitalmarketplace-aws/blob/master/vars/README.md\r\n> Values in a STAGE named file will override those in common.yml.", "Ah right yes - I was aware this PR was going to need some further screwing with, but hadn't noticed that one... had only worried about getting preview working to start with. "]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/565", "comments": ["Is there a reason we're using an inline policy here over a `policy_document`? I think we want to use the latter where possible. ", "I was following the convention of existing policies, if they were inlined I left them inlined. But I can change them, if everyone prefers the TF syntax over inlined JSON. We have 25 inlined policies, not only bucket related. Should we prefer one format over the other, I think it is better to create a ticket for it."]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/564", "comments": ["I thought we were on the default (5) for buyer before? Can we just delete this bit?", "If ya like"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/557", "comments": ["```suggestion\r\nfor HOSTNAME_PATH in $(jq -r '.[env.STAGE][] | \"\\(.hostname) \\(.path)\"' vars/ip_whitelist_routes.json); do\r\n```"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/554", "comments": ["Could we instead leave a TODO in the makefile with the commented out script call (but still move the blurb to the script file itself)? Then we'd know which stage to put it in."]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/546", "comments": ["Will this include a slow POST with a small request size? ", "all conditions operated by &&, so all four must be true to send the alarm", "I think we probably want to know about small slow POSTs. I'd be happy to remove the `!= POST` condition.", "I can also separate the two conditions with an || and put them into brackets."]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/545", "comments": ["Should the new route be whitelisted before we unmap the old route? ", "Is there a programmatic way to do this so that we don't have to update this later when we add `/_metrics` to the other FE apps?\r\n\r\nWe can get a list of hostnames and paths for an app from `cf curl /v2/apps/${APP_GUID}/routes | jq -r '.resources[].entity.host'` and `cf curl /v2/apps/${APP_GUID}/routes | jq -r '.resources[].entity.path'` (we use this method on the `map-route.sh` and `unmap-route.sh` scripts).", "While I don't like the idea of having to have another variables file just for this one script I also don't like the idea of hard coding `_metrics` in to everything. We could conceivably change `_metrics` to anything we like. Equally we could want to IP whitelist a route that is not `_metrics`.\r\n\r\nIt's a bit of a rock and a hard place solution. But I erred on the side of explicitly defining them.", "Is this info not already in the app manifest?", "No\r\n\r\n1 There is no way of telling between routes we want protected from the manifest and routes we don't\r\n2 The routes exist in the vars files as uninterpolated templates  eg `dm-{env}.apps.internal`", "We could add that information to the manifest? Rather than adding a new source of information. Then pass the expanded manifest to the script?", "I tried that, but they're for fundamentally different information.\r\n\r\nWe need to specify a subset of the routes that are defined in the manifest. _But_ we need to have them once they've been interpolated with the various variables.\r\n\r\n", "```suggestion\r\n}\r\n\r\n```", "I _think_ it will be fine to do it before we unmap actually yeah. I've updated and I'm going to give it a whirl on preview"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/534", "comments": ["So is this `name` the thing we supply when we define `module \"jenkins_elb_log_bucket\"` in `main.tf`?", "Yup"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/533", "comments": ["Should this and the AV API one below be `dm-search-api-{env}.cloudapps.digital/_metrics`?", "Good catch \ud83d\udc4d ", "Done \ud83d\udc4d "]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/529", "comments": ["Are we backing up archived repos then?", "Removed archived ones \ud83d\udc4d "]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/528", "comments": ["Are we just doing the APIs first, or do we need this added to the other FEs too?", "Just apis for now"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/522", "comments": ["Should the `status_code_alarm` name be `dropped_av_sns_alarm`?", "The missing logs alarm has an empty `insufficient_data_actions` in this section, do we need it here?", "`router_500_alarm` - c+p-ed from above I think?", "Na, we don't need i there either to be fair.\r\nYou have reminded me to put a treat_missing_data value on these though. We don't care if data is missing because we have the `missing logs` alarms", "Have removed it and added missing data actions in another commit"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/520", "comments": ["> buckete", "> buckete", "On jenkins:\r\n```\r\n> aws s3 ls digitalmarketplace-database-backups | grep production | sort -r | head -1 | awk '{print $4}'\r\nproduction-201903190300.sql.gz.gpg\r\n```\r\n\r\nThe file is brought down from S3 with the timestamp attached. \r\nThe `%.*` strips the `.gpg` suffix so it becomes:\r\n```\r\nproduction-201903190300.sql.gz.gpg\r\n```\r\n\r\nThis means we'll be uploading the file as `production-201903190300.sql.gz` which won't action the versioning as it'll have a different name in the bucket."]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/507", "comments": ["Is the plan to move this inline policy to its own `aws_iam_policy_document` at some point as well?", "Yeah, wanted to avoid the PR noise. I actually put in a ticket on the tech debt board this morning to have a look at some of this stuff. \r\nProblem is converting this one now means I should probably convert the jenkins one too, and that's a beast."]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/505", "comments": ["If we can assume that `$EGRESS_APPLICATION_NAME-release` is always going to have suffix `-release`, can we assume that for the `${APPLICATION_NAME}${APPLICATION_SUFFIX}` too?", "I made `$APPLICATION_SUFFIX` customizable _really_ so that this script could double up for the `add-all-app-network-policies` command, for which we need to operate on the actual target application name - in this case `$APPLICATION_SUFFIX` can be left blank.", "(whereas we always need to consider the possibility of the \"other party\" app being in the middle of a release, so operate against both possibilities)", "Cool - makes sense \ud83d\udc4d ", "This comment doesn't give us much info on the _why_ it's done here. Just that it's important it is done here.\r\n\r\nSomething like:\r\n# This step must be performed after XYZ but before ABC to ensure DEF\r\n\r\nWould help other devs get where they need to be quicker", "The `... that's probably fine` is ambiguous for anyone using the output to debug.\r\n\r\nCan't we check why it's failed? And notify accordingly?\r\n\r\nOr failing that can we check at the end that everything we expect to exists exists and exit 1/ 0 the whole thing based on that?", "Or if we're expecting failures then don't print out anything.", "I'll take a look and try, but the exact reason for it will probably have a long long explanation for it - it's not something I've actually thought about in terms of english language, it's just that I found this order of operations impossible to trip up no matter where it gets interrupted...", "Um yeah, I'm not sure what's the best thing to do here - the output is indeed a bit ambiguous, but really the whole operation is a bit ambiguous. It's something that's kind of a cooperation between two release processes. It slightly relies on having the things that fail on one of them succeed on the other. And it's hard to create definite output as to whether that's ended up happily being the case or not... I'm going to think about this too", "See, the way I determined the validity of this scheme was really by playing a sort of card game in my text editor trying to find different interleaving orders that would end up starting an app without its policies in place:\r\n![screen1](https://user-images.githubusercontent.com/807447/53799467-55afa580-3f32-11e9-93e4-e865a4c11783.png)\r\n", "In fact, the following is a particularly interesting case, because from B's POV, both of its attempted policy additions would have appeared to fail, but actually the end result would end up being fine because _both_ of A's additions of them should have succeeded.\r\n![screen1](https://user-images.githubusercontent.com/807447/53800172-05394780-3f34-11e9-8ccc-ea76479172c7.png)\r\n\r\nI _do_ think though I can make the failure messages a bit more illustrative of this.\r\n"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/504", "comments": ["Should this be a different name? `jenkins-main-volume-disk-space`?", "Does this mean 'everything'? Or are we waiting on a hardcoded value?", "Means everything, and according to the AWS interface has to be everything.", "Nice catch \ud83d\udc4d updated "]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/497", "comments": ["Could move these in to the sub query for efficiency but doesn't make much odds at all \ud83d\udc4d  ", "I _think_ the query planner's able to perform that optimization itself"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/496", "comments": ["Is it possible to use json_build_object here? Obviously not necessary but I'm curious.", "It is using `json_build_object`, it's just wrapped in `json_strip_nulls` too so I can choose to \"omit\" keys by simply outputting them as `null`. It's less painful than other syntaxes to do this.", "Running this locally I noticed this fake brief responses bit doesn't have an `echo` line for the output, hopefully it's not too out of scope to add one in \ud83d\ude38  "]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/484", "comments": ["Oh - it comes through as a service - cool."]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/478", "comments": ["...and so we should use the aws console to do this if we ever need to replace it?", "Yeah, I'm documenting that in the README, not sure about leaving this in, I'll make a decision when the README is done.", "I would say leave it in."]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/477", "comments": ["Can we restrict this to our main account?", "Done"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/474", "comments": ["Which user is this? Should we be hardcoding this ID? ", "We have `Version: 2012-10-17` all over our terraform stuff and I am not sure what it refers to. Terraform version? The policy version? AWS resource version?", "Ah, good spot.\r\n\r\nThis is an annoying thing about the Elastic Load Balancer, the way to include it in a policy is just to include this account ID from [this table](https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/enable-access-logs.html#w281aac21b9c17c11b9b8b3b5b3) in the AWS docs.\r\n\r\nIt would be nice to document this somewhere, but I don't think you can put comments in JSON...", "I know right!\r\n\r\nI think it's policy document specification version. It's in all the AWS documentation examples. We could try leaving it out...", "https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_elements_version.html", "Reading The Fine Documentation reveals that if we don't specify a version, we lose out on newer features... \ud83e\udd37\u200d\u2640\ufe0f ", "Can put comments in tf files:\r\nhttps://github.com/alphagov/digitalmarketplace-aws/blob/master/terraform/environments/production/s3_buckets.tf#L11\r\n\r\nHard coding it does seem to be the standard way of getting it in there:\r\nhttps://github.com/search?utf8=%E2%9C%93&q=156460612806+extension%3Atf&type=Code&ref=advsearch&l=&l=\r\n", "We could use a local to make it more readable \ud83e\udd37\u200d\u2642\ufe0f \r\nhttps://www.terraform.io/docs/configuration/locals.html\r\n\r\nBut we don't use them elsewhere so maybe a comment is better.", "Comment added to just above the policy definition"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/466", "comments": ["Do the top two need to be preview and staging?", "Do the top two need to be preview and staging?", "Do the top two need to be preview and staging?"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/464", "comments": ["Ooooh nice `_` wildcard there", "Yep, I think these were left over from before the org size migration."]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/458", "comments": ["The replication configuration needs to live on the bucket you're replicating from, the source, rather than the destination.\r\n\r\nIn the backups terraform I defined the destination bucket above the source bucket because semantically it makes sense to have the  replication bucket exist before you can tell something to replicate in to it.", "The role `replication` gets its permissions from 2 places in the replication set up. The first is in the `replication_policy` attached to the role (looks good btw \ud83d\udc4d ) and the second is by being listed on the source bucket as the role to perform replication. We don't actually need it to have any permissions on the destination bucket other than those supplied by the role policy IIRC if it exists within the same account.", "I've pushed a couple of commits which:\r\n- move the `replication_configuration` blocks to the source buckets\r\n- get rid of the destination bucket policies\r\n- fixes trailing commas on the IAM role lists\r\n- created the destination buckets for prod\r\n\r\nI ran `make plan` for the roles in dev/prod and all seems fine; I can't run the plan for the buckets until those roles are created for real, as they're on different Makefiles."]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/457", "comments": ["A small pet peeve, we can leave trailing commas for the last item in a list in terraform, so that diffs are cleaner.\r\n\r\nIt is just a personal taste thing though so please feel free to ignore me \ud83d\ude1d "]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/443", "comments": ["Another annoying question; why are two roles needed?", "The first one is the dev group, i.e. us - so I can access/debug the bucket in the console.\r\nThe second one is the Jenkins role - the script needs access to upload the file. We can probably remove this once the job is fully tested/run in prod.", "Right, thanks"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/442", "comments": ["Aren't these used in the router nginx template? That's why I added `reports_s3_url` last week..."]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/440", "comments": ["We need to add this to the router template I think."]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/438", "comments": ["You'll probably want to add this var to  the `Makefile` nginx linting command as well (and maybe `docker-compose.yml.example`?)", "Wait those are in the router repo. I've got myself confused \ud83d\ude38 "]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/434", "comments": ["typos: `inclided`, `process` -> `processes`"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/433", "comments": ["`-v` to me is `--verbose` but hey whatever", "I'm happy to change it to something else", "Maybe this could be mentioned in the actual `help` string?", "Done", "It might be an idea to update Jinja to 2.10 to bring in line with the FE apps (the AWS repo has it at 2.8 currently) to avoid running into further 'why is Jinja behaving weirdly' gotchas in future...", "To be honest I think I'd prefer grabbing each var explicitly so we know what's expected/allowed. \r\n\r\nNot for this PR but: why are we using `click.option` for this script? We use docopt in our other scripts, we might as well be consistent and use it here too? Or indeed use `click.option` everywhere (docopt is not exactly my favourite tool!).\r\n\r\n", "Yeah definitely agree...", "I'm not sure what you mean by explicitly here?", "`click` is nice but I don't think it's doing much heavy lifting here, looking at it I think we could probably implement the same thing using `argparse` and save ourselves a dependency.", "I mean having separate options for `--dump-file-name`, `--s3-post-url-data` etc. Long winded and less flexible, but also less risky that the wrong thing will end up in the manifest.", "Oh that makes sense, I totally get where you're coming from now.\r\n\r\nMy worry with doing it this way is then we have to specify the arguments in two places; what about instead we looked at raising errors if the manifest template doesn't use one or more of the vars?", "I think we'd run in to trouble with the other Makefile commands that use this function. Unless we had a separate `s3_app_paas_manifest` function that checked the vars, then called this one? (Ugh!)\r\n\r\nThe reason I'm being picky about this is that our usage of paas manifests (for which apps, what is expected) is not well documented or tested at the moment (I have that ticket to make example manifests of course!). Perhaps we should just have a comment here describing what's going on and the sort of vars we'd expect."]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/429", "comments": ["~Isn't this duplication of what you've defined in `access.tf`?~ Nope, this is the bucket policy.", "Does this extend the policy defined above? Nifty..."]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/426", "comments": ["Does this still need to be called jenkins3?", "Possibly not actually. I previously thought it wasn't going to be able to change these names, but have since learned that it might. I'll have a go.", "Yep, it was totally possible. All done.", "Nice!"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/419", "comments": ["As I said, miiiight be nicer to have this as `antivirus_api_host` rather than `antivirus_api_url` as it's clearer and just accept we're going to handle all the path stuff here."]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/417", "comments": ["I guess the thought is that as long as we have SSH access we can take a peek at what's going wrong the the web interface, but not having SSH we're stuffed and need a reboot?", "It was more than when bringing up a new, clean instance, nothing is listening on port 80 as nginx isn't there, so there'll be no 200 OK. ssh is there though."]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/408", "comments": ["So this data step converts the above policy definition into json? Nice!", "No policy for this bucket?", "No policy on this bucket either?", "Yeah, pretty nifty. Better than writing plain json", "![screen shot 2018-07-26 at 15 36 58](https://user-images.githubusercontent.com/3469840/43269041-eb2e23a4-90e9-11e8-8bc0-d8f613b06ebd.png)\r\n", "Nada \ud83e\udd14  Bit weird", "![screen shot 2018-07-26 at 15 36 41](https://user-images.githubusercontent.com/3469840/43269049-f27c21c4-90e9-11e8-83bf-52c9f2bcc192.png)\r\n\r\nSame\r\n"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/402", "comments": ["Do you need this particular block? You've got these in the block below, but for the backups bucket.", "Could this have a more descriptive variable name? `cloudtrail_s3_bucket_name` maybe.", "We're using 731 above, maybe this should match.", "Good call that shouldn't have made it in ", "Can this be deleted if we're not outputting anything?", "Wasn't this going to be the same as `prod_infrastructure_users`?", "\ud83d\udc4d Done", "This variable name mirrors the variable name given by terraform here:\r\nhttps://www.terraform.io/docs/providers/aws/r/cloudtrail.html#s3_bucket_name\r\n\r\nThe choices are I guess:\r\n1) To change it globally in our code, make every instance of `s3_bucket_name` into `cloudtrail_s3_bucket_name`\r\n2) Only change it in the `cloudtrail/cloudtrail-bucket` submodule\r\n3) Leave it as is\r\nI'm fairly easy. I think I'd prefer 1 or 3, that way the variable has a globally consistent name on our side. It's just whether there's more value in having that name be the same as the cloudtrail terraform variable or have it be more descriptive.\r\n\r\nAny preference? ", "Good call, 730 won't run, it's not a valid choice iirc", "Yeah I added this because of this bit in the docs:\r\nhttps://www.terraform.io/docs/modules/create.html#standard-module-structure\r\n>>> main.tf, variables.tf, outputs.tf. These are the recommended filenames for a minimal module, even if they're empty. main.tf should be the primary entrypoint. For a simple module, this may be where all the resources are created. For a complex module, resource creation may be split into multiple files but all nested module usage should be in the main file. variables.tf and outputs.tf should contain the declarations for variables and outputs, respectively.\r\n\r\nBut it's not consistent with the rest of our modules and it doesn't do anything so actually I'm going to get rid. If we're going to have empty files just to indicate no input and no output then we should do it globally.", "Good call, admins can assume anything anyway (tested) \ud83d\udc4d ", "Go with 3, it's not a big issue. It's meaning gets clarified by the context it's being used in anyway.", "Interesting - wasn't aware of those recommendations. But yeah, agree consistency is probably better otherwise the empty files existence may be confusing.", "Nice. Good to know."]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/401", "comments": ["It might be worth getting that jenkins 2 branch of the credentials repo merged too? Should make things a bit smoother.", "Is this the updated ami? I can't remember...", "This key pair could probably have a better name. It was only called `jenkins2_2` originally because I mucked up the first key pair for the original `jenkins2`.", "Yeah trouble is I'm still having to hack on that fairly constantly. I think I probably need to move a bunch of things into a separate file so that it's easier to manage. Not sure...", "oh, you're telling me this can't land without the creds repo landing first? argh :)", "This one claims to be \"Canonical, Ubuntu, 16.04 LTS, amd64 xenial image build on 2017-07-21\".\r\n\r\nThe old one is some custom thing from 2015. So yeah I suppose it's more up-to-date. I dunno if that's good or not really in terms of reproducibility, but so far I doubt any of the problems I've seen have been caused by OS-level stuff, so it's probably overall good.", "Yeah it could land, it just means that we'd have stuff on the master branch that wouldn't succesfully plan or apply using the master credentials branch. It feels like we should be keeping things in sync.", "Does this image mitigate spectre and meltdown? I feel like they were newer than 2017?", "Done - \"jenkins\" will probably do as a name, as it's now the same key as used for the current jenkins box. (We can always rotate in a new key later once the new box is the live box, but this keeps things simple in the creds repo.)", "Have updated the box to the latest equivalent AMI, we'll see what gives...", "nice! i didn't know about this", "Is this subdomain redundant now? Is the plan to point ci.marketpalce.team at a new Jenkins box? If so, should the record the A record above be pointed at the new boxes ip instead?\r\n\r\nOr maybe it should be a two phase thing - bring the new box up, then switch the record when we're happy its healthy.", "Could change the naming of things to just 'jenkins'?", "Until this works then we need to run both servers in parallel. So this PR can land while we're still using the current Jenkins.", "I think each time we need a new box we'll need a similar process of running two in parallel, unless it's an emergency. So I think it's likely we'll just keep incrementing the number e.g. jenkins3 etc", "Cool. Didn't you mention in slack the other day that you were deleting the ci2. domain?", "Yeah I was checking that if I wiped it all, I could get it back again :)"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/390", "comments": ["`.PHONY: terraformat-apply`?", "Or change both to `terraformat`?", "`terraformatest`?"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/381", "comments": ["It feels like the part about avoiding false positives should be linked to the sentence about the time period being 15 minutes rather than linked with the 5 minute smoke test sentence", "It feels like this and the variable below it should be in the script rather than this library file (would involve probably passing it as a param to the create_log functions). Aware that is a bit of work though so can go either way...", "Agreed. It's not too much work and it'll be useful if we want to eventually run the script for just one alert."]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/380", "comments": ["Can we do something like we do in the users table update and include the ID here so we get some differences between all the entries? Something like `contact_name = 'Supplier Contact #' || id, phone_number = '01234 ' || id`, etc etc.", "How about this?\r\n```\r\ndigitalmarketplace=# UPDATE\r\ndigitalmarketplace-#   contact_information\r\ndigitalmarketplace-# SET\r\ndigitalmarketplace-#   (\r\ndigitalmarketplace(#     contact_name,\r\ndigitalmarketplace(#     phone_number,\r\ndigitalmarketplace(#     email,\r\ndigitalmarketplace(#     address1,\r\ndigitalmarketplace(#     city,\r\ndigitalmarketplace(#     postcode\r\ndigitalmarketplace(#   ) = (\r\ndigitalmarketplace(#     'Supplier #' || supplier_id::TEXT || ' Contact',\r\ndigitalmarketplace(#     '555' || supplier_id::TEXT,\r\ndigitalmarketplace(#     'simulate-delivered@notifications.service.gov.uk',\r\ndigitalmarketplace(#     'Supplier #' || supplier_id :: TEXT || ' Contact Address 1',\r\ndigitalmarketplace(#     'Supplier #' || supplier_id :: TEXT || ' Contact City',\r\ndigitalmarketplace(#     'AA11 1AA'\r\ndigitalmarketplace(# );\r\nUPDATE 7833\r\ndigitalmarketplace=# select * from contact_information limit 1\r\n;\r\n  id  | supplier_id |      contact_name       | phone_number |                      email                      |             address1              |             city             | postcode \r\n------+-------------+-------------------------+--------------+-------------------------------------------------+-----------------------------------+------------------------------+----------\r\n 7169 |       92301 | Supplier #92301 Contact | 55592301     | simulate-delivered@notifications.service.gov.uk | Supplier #92301 Contact Address 1 | Supplier #92301 Contact City | AA11 1AA\r\n(1 row)\r\n\r\n```"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/373", "comments": ["Presumably this is _necessary_ in order for the update to not fail -- because if it isn't required to be there then I imagine it's just slowing the query down.", "I copied it from another JSON blob sanitisation below - `signed_agreement_details`.", "You shouldn't need the `- 'respondToEmailAddress'` the `||` updates existing.\r\n\r\nThere are 2 different ways of casting used there, the `::JSONB` and the `cast(data AS TEXT)`.\r\n\r\nEffectively:\r\n`cast(data AS TEXT) == data::TEXT`\r\nand\r\n`cast(data AS JSONB) == data::jsonb`\r\n\r\nWe may also need to limit on `data::text != '{}'` IIRC \ud83e\udd14 ", "That makes sense. I'll try and apply the casting consistently. Do you know if we need both `data IS NOT NULL AND cast(data AS TEXT) != 'null'`? ", "Actually I don't _think_ we need either of those.\r\nOur json fields should be `'{}'::json` if empty."]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/368", "comments": ["`VIRTUALENV_ROOT` ?", "That won't be defined at this point, I think, because the venv hasn't been activated. That var gets set once you activate it.", "Maybe not?", "Can we call the `virtualenv` step at the beginning of this step (as per some of the other steps, e.g. `make generate-manifest`)?"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/367", "comments": ["Might be nice to have something that outputs what env/app an alert has been created for. Might help if it falls over for some reason too?", "I can see `b` but not `a` - does HostedGraphite just use the top level `metric`/`alert_criteria` as 'a'?", "I had a similar thought, found this (tldr: yes it just uses the top level): https://www.hostedgraphite.com/docs/alerting/alerting_api.html\r\n", "Will add", "Do we not have an existing list of \"all apps\" we can piggyback on here? I can imagine someone adding a new app (if I grit my teeth :grimacing:) and neglecting to add it here...", "Yet", "Ahh, fair point!", "Good question, let me look into this"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/364", "comments": ["Who is `dm-andras`?", "Aha, interesting - this might be why I haven't been able to run this stuff successfully!", "On the top level README I think it's worth making it clear that all these bits need to be installed separately (i.e. not with pip), not just Terraform.", "This is a bit weird - are we trying to `source` the wrapper - if so, then the command needs to be\r\n```\r\n. ../../terraform-wrapper output\r\n```\r\nand if we're not trying to source it, then the initial `./` is unnecessary.", "Is the clean-ness here something about the remote environment, or something about the checkout? I don't quite follow when we are supposed to need these instructions.", "By installed do you mean with `make`? I'm not sure I realised that! - isn't it enough to run `make requirements` at the top level? The other makefiles are then specific to actually deploying things into AWS, rather than building local environments / build artefacts?\r\n\r\n(I must admit I find it a bit confusing having makefiles at multiple levels, not sure I want to suggest a remedy for that though :-) )", "So I think this is the situation where we have no existing AWS infrastructure.\r\n\r\nE.g. we have no s3 buckets that store our terraform state, we have no users.\r\n\r\nThis is obviously not the situation that we are currently in (and unlikely to be in?).\r\n\r\nI can either remove this section on the assumption that it will never be useful or I can give a better explanation. I'm leaning towards the later. Opinions?\r\n\r\n", "Andras is someone who set up a bunch of this (we were borrowing him from Notify briefly I think).", "Ah, okay yeah maybe \"How we created the AWS environment\".\r\n\r\n(Trouble I suppose is: is that true? Or is this an idealised version of how we might have created it if we hadn't have been iterating something that existed already? Or is it just how we _might_ create it if we needed to - and is that a realistic thing that could happen if somehow our AWS infrastructure got wiped out by an extreme data fail scenario?)", "I've added a commit that I hope makes this a bit clearer.", "Not trying to source it. I'll drop the initial `./`", "`dependencies`", "I think this is tricky. When George and I were playing around with Terraform we noticed that it reported it was backwards incompatible (i.e. if someone has run terraform plan/apply with version v0.11.3 and I come along and try to run it with v0.11.2, it will say that I need to update my tool). This might mean that suggesting a version number here is pretty much always going to be out of date as Terraform forces everyone onto the latest version.", "We should add a link here to the relevant page.", "Might be better to link to this (https://alphagov.github.io/digitalmarketplace-manual/aws-accounts.html#available-roles) rather than provide a partial extract.\r\n\r\nMaybe.", "Or `.bash_profile`/equivalent so that you don't need to define it in multiple places.", "Thanks. Will fix", "Will add", "Will add", "I've added a paragraph to clarify this."]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/359", "comments": ["Should we be putting `:max` on this like the rest of our targets? I notice that it wasn't there before but not sure if that was a mistake on my behalf or intentional. Any idea?\r\n  ", "Good call, it was defaulting to average without. I've added it on."]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/357", "comments": ["I don't see that the outer `Math.floor` will ever do anything here, as the thing it's acting on is already guaranteed to be an integer.\r\ne.g.\r\n```\r\nMath.floor(Math.floor(12345.09876) * 1000) \r\n= Math.floor(12345 * 1000)\r\n= Math.floor(12345000)    // Always an integer in here so floor has no effect?\r\n= 12345000\r\n```\r\nOr have I missed something?", "Belt and braces. Anyone coming along to this code doesn't even need to *think* about the possibility of it being non-integer if they see that `floor`. What was js's Number weirdness around the 53bit mark again? Doesn't matter.", "And also I'm just not risking something stupid going wrong in our log-critical code.", "It's confusing though (at least, it confused me and I had to spend time in a Javascript console convincing myself what was going on).  Is there really a possibility that the integer multiplication inside the brackets might give a non-integer? I don't see it.", "> Is there really a possibility that the integer multiplication inside the brackets might give a non-integer?\r\n\r\ndefinitely not if you wrap it in `floor`"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/356", "comments": ["We probably don't want to change the refresh rate?", "So in the past we explicitly chose (but we probably didn't do a very good job on documenting this, my bad, sorry) to use max.\r\n\r\nThis was because when leadbutt calls for a metric, it says get me metrics for the past 10 minutes. Cloudwatch returns a list of 10 timestamps with their related value.\r\n```\r\ntimestamp10: 100\r\ntimestamp9: 89\r\n...\r\ntimestamp2: 288\r\ntimestamp1: 300\r\n```\r\nwhere timestamp 1 is the oldest.\r\n\r\nThen it calls again a minute later to get the data and gets a similar list but with 1 minute difference in the time period. (compare this list to the one above)\r\n```\r\ntimestamp11: 49\r\ntimestamp10: 100\r\ntimestamp9: 89\r\n...\r\ntimestamp2: 288\r\n```\r\n\r\nWe used to graph based on metrics like `cloudwatch.request_time_buckets.$environment.router.request_time_bucket_0.samplecount:avg`. But we would get weird data were the value shown on the graph was half values like 170.5 which isn't a valid number of requests. It turned out that cloudwatch can give you different data for a very recent timestamp because it is still processing it. So if timestamp 1234567890 gives you value 100 when you first get it, a minute later you might get a slightly higher number like 1234567890: 117 because cloudwatch hadn't finished processing the data the first time round. So we would have the following data in HG.\r\n\r\n```\r\n1234567890: 100\r\n1234567890: 117\r\n```\r\n\r\nAnd then in terms of the hostedgraphite graphing functions, using `avg` on these would give us a value of `108.5` which is incorrect. Similarly, using `sum` would give us `217` which is again wrong. By using `max` we would get the correct value. Unlike we had previously thought, the HG graphing functions are based on multiple data points for the same timestamp rather than doing an operation on a group of data covering multiple timestamps. This was the best solution we could come up with a reasonable amount of time (although retrospectively I think we should instead have looked at how are asking for metrics from cloudwatch).\r\n\r\nSo yeah, I would advise that we probably don't want to use the HG `sum` function on data coming through.\r\n\r\nIn terms of using `sum` on the cloudwatch metrics side of things, that could potentially work though so do investigate and see how you get on but you'll definitely want to try and what we get in hostedgraphite with what we are seeing logs (you could try triggering some 500s/429s yourself and confirming the number in the logs match the numbers you are getting out).\r\n\r\nBest of luck. Oh and popping a screenshot of grafana in the PR message when you are ready for a final review would also be useful :)\r\n\r\n\r\n", "It seems weird that Hosted Graphite works on multiple datapoints if you update a metric with the same timestamp. I've had a search around and other sources suggest that Graphite should overwrite the value for a timestamp with the latest data sent to it. I've pinged an email to their support to see if they have any insights.\r\n\r\nWas there any reason for sending the last 10 minutes worth of metrics every minute? Other than for redundancy in case of a network error or our leadbutt app going down of something?", "This is what I got back from Hosted Graphite. It might be worth recording this somewhere in case it crops up again in future. Might stick in in the manual.\r\n\r\n> Hosted Graphite does work differently to normal Graphite. Graphite by default uses a last-write-wins setup so that you can overwrite your datapoints. However that also means that you have to pre-aggregate your datapoints to match the resolution of your storage scheme.\r\n\r\n> Hosted Graphite always merges datapoints you send us for the same timestamp, in order to create our Data Views and to ensure that users don't need any kind of separate aggregation service like StatsD or carbon-aggregator. That works perfectly for real time metrics, but it does mean that updating historic datapoints with specific values isn't possible.\"", "Will we need to add this version to the staging/production terraform files?", "ooo yes, good shout!"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/349", "comments": ["Do we need the default here? I don't think it adds anything when we're doing an `if` check; only needed when iterating with `for`, I'd have thought.", "Because the Jinja environment is set up in `StrictUndefined` mode in the generate paas manifest script (http://jinja.pocoo.org/docs/2.9/api/#jinja2.StrictUndefined), the only operation allowed on an undefined object is to check if it is defined. Therefore, if `routes` is not defined and you try `if routes` then we will throw an exception. Therefore we need to use the `default` filter (https://github.com/pallets/jinja/blob/master/jinja2/filters.py#L355) I believe.", "Maybe what we want to actually check then is that it's defined? i.e `if routes is defined`?"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/348", "comments": ["We are definitely good to delete this one? I don't entirely understand the packer stuff but obviously it mentions jenkins so that's why I ask", "Hmm. Yeah, this got caught in the wide `git rm` net, but maybe it's worth dropping it as well. Essentially the only thing it does is create an AMI with a larger root volume (so instead of the default 8Gb you get 20Gb). Otherwise it's the same as stock ubuntu image.\r\n\r\nIt was worth keeping the template around, but in practice we've never had to recreate the AMI and would probably restore Jenkins from the EBS snapshot in the future. So as long as that image is not deleted, I'd suggest we drop this template just to remove the overhead of having to know about packer at all."]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/344", "comments": ["Could you explain this line for me please? It reads like maintenance mode would be on by default and I couldn't find anything else in our aws repo in terms of setting this variable so it seems new", "That's the existing nginx `mode` flag from Terraform. When this is set to `maintenance_mode: maintenance` nginx will be deployed with a maintenance page.\r\n\r\nThe environment variable is just called `DM_MODE`, but I felt like it's worth expanding the name a bit here, even though I agree it's not ideal.", "Cheers. Yeah it's not the key that is the issue so much, more the value that can be a little confusing."]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/337", "comments": ["This doesn't seem like a flake8 change? It looks over-indented, it changes a key, and it duplicates the key below?", "Are any of the changes in this file intentional?", "Damn, they snuck in there, good spot.", "Done \ud83d\udc4d "]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/334", "comments": ["I'm not decoding credentials to check this, but what's the logic behind moving the token out of the \"shared_tokens\" section?  Feels like that's exactly what it is."]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/330", "comments": ["This might be my rusty SQL knowledge showing, but does this always put `now()` into `submitted_at` and the case statement into `created_at`? Shouldn't it be the other way around?", "This line is no longer up to date", "Nice use of MOD", "The number of essential requirements and n2h requirements may not be equal to the number the brief is looking for. Can you think of any implications of this? \r\n\r\nFor example, I think... if someone logged in as the buyer of a random brief and tried to download the responses, it might fail. \r\n\r\nTrying to figure out if this is acceptable or not (it might be a fair bit harder to create the correct number of pieces of evidence)", "I'm not too up to date with services, but is there ever a reason why the declaration would be complete but they don't have an organisation size?", "Copied declarations should all have a value here - see https://github.com/alphagov/digitalmarketplace-aws/blob/master/scripts/clean-db-dump.sql#L108", "Live also all have it too as it's been a required value on all declarations.", "I think that provisioning for this would take a lot of work.\r\n```\r\ndigitalmarketplace=# select len, count(len) from (select json_array_length((data->>'essentialRequirements')::json) as len from briefs) as len_table group by len;\r\n len | count \r\n-----+-------\r\n     |     0\r\n   8 |    82\r\n  16 |    16\r\n  15 |    22\r\n   4 |  3172\r\n  20 |    13\r\n   1 |    40\r\n  13 |    41\r\n   5 |   121\r\n  11 |    49\r\n   3 |   135\r\n  14 |    26\r\n  17 |    18\r\n  19 |    20\r\n  12 |    39\r\n  10 |    96\r\n  18 |    21\r\n   9 |   133\r\n   6 |   117\r\n   2 |   126\r\n   7 |   112\r\n```\r\n\r\nThe majority of briefs have 4 essential requirements. I could try and find out if there's some sql to make them match but I can't think of any off the top of my head.", "Ah I'd need to add another essential requirement to the test data for a start.", "Found a way. In terms of creating test data I think it'll do. Creates an `essentialRequirements` with the same number of 'evidences' as there are essential requirements on the brief.", "Nice on the essential requirements length. Can we also do it for the nice to have requirements as they can be off various length?", "Also is there anyway to split this line over multiple lines to improve the readability whilst still writing valid SQL?", "Done \ud83d\udc4d \r\n", "Fixed \ud83d\udc4d \r\n", "Technically the brief response is 'submitted' rather than 'closed'", "Could also say the same about nice to have length", "So as we are doing MOD 6 on the supplier ID and MOD 5 on the nice to haves am I right in thinking we will have the following cases:\r\nA response which is not submitted which has `niceToHaveRequirements`: []\r\nA response which has been submitted which has `niceToHaveRequirements`: []\r\nA response which is not submitted which has `niceToHaveRequirements`: [correct number of nice to haves]\r\nA response which has been submitted which has `niceToHaveRequirements`: [correct number of nice to haves]\r\n\r\nI don't think the first two responses are realistic data that we would see. If they had started an application but not yet answered the nice to have requirements question then we would see no key for nice to have requirements. If they had submitted the application, then they would have answered nice to have requirements and would have data in the list (even if it just said that \"yesNo\": false). \r\n\r\nYou could go to the effort of trying to change the first two cases so you the key only exists with the correct number of nice to haves.\r\nYou could also simplify it so that they always have the key full of nice to haves.\r\n\r\nDo correct me if any of my interpreting of your SQL is wrong. Also please do double check any of my assumptions if something you decide to change relies on them as this is all of the top of my head.", "Should it be `\"yesNo\": true` rather than `\"yesNo\": \"true\"`? "]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/328", "comments": ["Noticed the 'decode' call at the end of this: is there any guarantee that bcrypt returns a string that can be interpreted as UTF-8? Isn't it just an arbitrary byte-string at this point? Presumably we're passing it straight on to a URI-encoding function, in which case it might be better if this function did just return bytes to be fed in there, rather than a unicode string?", "bcrypt hashes contain a base64 string and `$` signs for version/cost factor, so they're safe to decode. We're printing them out right away, so I don't think we need to decode, but it can be useful if the function will end up being used anywhere else."]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/324", "comments": ["I think the path for the brief-responses app needs moving to the array pattern like the others.", "Can you simplify to just `{{ path }}`?", "Good spot. Thanks."]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/322", "comments": ["\ud83c\udfc6 "]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/317", "comments": ["So does moving this to a script mean we no longer need the `sleep 10`s when switching spaces?", "Could make this into a command apparently:\r\nhttps://coderwall.com/p/cezf6g/define-your-own-function-in-a-makefile", "I am learning a lot about bash today \ud83d\ude04 ", "Should we set `-x` on all the pipefails?", "Nice - I haven't seen `tr` used before!", "Question: are we using `DELETE CASCADE` by default on our DB?", "What happens when the production data is a migration (or two) behind preview/staging? Is this handled in a later script or make step?", "Yeah, I think the `sleep 10`s thing was me misunderstanding cloud foundry and wasn't actually needed. When switching spaces it turns out it does happen in a subshell which only returns when it's done, so it's all good.", "Whoops, I meant to take this out. I was using this for debugging!", "This was the first time I heard of/used it. Stack overflow is a wonderful thing.", "That's a good question.\r\n\r\nI guess that when the clean prod data is migrated to the stage, it could break? In that scenario we would could re-release the latest api release up to preview/staging which will run the latests migrations against the new data?", "I don't know to be honest, I'm not super familiar with it. The SQL here is pretty much a copy/paste job from our old cleanup script.\r\n\r\nWould it be beneficial?", "Thinking out loud: let's say preview contains some new api code with a migration for e.g. an altered column. If we feed in the cleaned prod data dump before we build the app and run those migrations - e.g. for a dev getting set up locally - it would likely be fine. But if we're just updating the preview DB on a Sunday night, we should first check whether the migration version is in sync or not. If preview has a later alembic version stamp than prod, we can roll back to the prod version, apply the dump, then roll forward again to the preview head version. What do you think?", "I think using `CASCADE` is slightly more efficient for deleting child objects/avoiding orphans - so e.g. deleting draft `Brief` objects would also delete their child `BriefUser` objects without needing a separate statement. However it's obviously less explicit what's being deleted and what's not. If the script above has been serving us well in the past then I'm happy for it to continue \ud83d\ude04 ", "Yeah, that makes sense. Do we need to roll back? If preview has a later version stamp we could just run the migrations immediately after applying the dump?", "This could be a little clearer if it was defined as some plpgsql functions/ variables but I gather this is mostly a copy paste from another script right? In that case probably out of scope to rewrite all this?", "Might be worth dropping the case declaration onto a new line for readability\r\n```\r\nSET declaration = (\r\n    CASE\r\n         WHEN (declaration->'status') IS NULL OR (declaration->'nameOfOrganisation') IS NULL \r\n         THEN '{}'\r\n         ELSE '{\r\n             \"status\": \"' || (declaration->>'status') || '\",\r\n             \"nameOfOrganisation\": \"' || replace((declaration->>'nameOfOrganisation'), '\"', '') || '\",\r\n             \"primaryContactEmail\": \"supplier-user@example.com\",\r\n             \"organisationSize\": \"' || (ARRAY['micro', 'small', 'medium', 'large'])[MOD(supplier_id, 4)+1] || '\" \r\n```", "We can fit all that on one line and not declare it as a variable. Line limit should be at 120.\r\n`return bcrypt.hashpw(bytes(password), bcrypt.gensalt(cost_factor)).decode('utf-8')`", "Oops, yes, you're right - `psql` won't care about the 'new' structure yet. This also has the advantage of nicely simulating what will happen when we apply any complicated migrations on prod \ud83d\ude04 ", "We actually have command that does this already in the Makefile, I'll update to use.", "Yeah, it's the same SQL as we used before. How much work would it be?", "Cool. I was trusting by beautifier too much I think!", "Nice.", "Even though the cost factor doesn't matter in this case, I think with this being the only use of `/scripts/generate-bcrypt-hashed-password.py` at the moment it's possible this line could end up being copied for use somewhere else, where it does matter. So seeing as it's only done once and shouldn't noticeably slow down the script I suggest we bump it to the recommended 12.\r\n\r\nAlternatively, I'd drop the cost argument completely and hardcode it in the script to the recommended value.", "I think adding psql as a pipe stage might make this a bit easier to read:\r\n\r\n    echo ... | gpg2 ... | gunzip | psql ${DB_URI}", "There is a small chance that there's a new backup created during the window between downloading the latest one to restore to db-cleanup and this moment, so our cleaned dump will assume a future date. It's not a big risk and it probably won't matter most of the time.", "I'd call this `TARGET` instead of `TARGET_STAGE` then and rename the script to match. STAGE has a more set meaning which usually doesn't include google drive, so it might be not obvious that there's an additional option in this case."]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/315", "comments": ["db snapshot?", "Is there a way to get 9.5 to match the versions we have everywhere else?", "`/tmp` feels like a weird location for these, maybe `/` or `/app`", "Maybe make `'Digital Marketplace DB backups'` an environment variable value", "I'd be interested to see if the custom format makes a big difference in terms of memory usage, size or speed of backup / restore, but that's something we can tweak later", "typo, should still be `.44`", "If terraform complains in the future we'll need to add `mfa_delete = true` to this once we've switched it on. ", "We generate the file name for `S3_POST_URL_DATA`, is there a way for us to store it and use that? It would allow us to use the script to check any backup as well as making sure we're checking the thing we've just created and not some other file that happens to have a later date for some reason."]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/313", "comments": ["Can we remove this now that we've started renaming `-release` metrics?", "I think all of these should be `.samplecount:sum`.  Averages aren't very interesting in this case, especially when it comes to 500s and slow requests", "The bars show request counts, so maybe \"Request counts grouped by time\"? ", "Why does the main dashboard need the app selector? It should be one dashboard per environment. I don't remember if we've talked about it, but I think it should show nginx requests and slow requests, api requests and slow requests, nginx 500s and combined memory (and maybe cpu) metrics across all apps.", "Can we make this 12h or 24h? 6h is not very useful in the morning.", "So using `sum` or `avg` on these is for an individual metric at a timestamp rather than any aggregation of a metric over a period of time.\r\n\r\nFor example if we have\r\n```\r\nrequests_bucket_1 50 1500031162\r\nrequests_bucket_1 100 1500031162\r\n```\r\nthen using `sum`  would give us\r\n```requests_bucket_1 150 1500031162```\r\nor using `avg` would give us\r\n```requests_bucket_1 75 1500031162```\r\n\r\nWe did had a problem that we were sending different values for the same metric for the same timestamp (first an incomplete value and then the full value) so would make a difference if we chose sum or avg. However, we have fixed this so there is no duplicated metric data being sent and therefore it should not matter if we choose sum or avg. \r\n\r\nTherefore it feels like we are fine to keep avg. If we really wanted to cover the case were we would have double metrics being sent per timestamp then we could use the `max` filter.", "If we set this to `false` it removes the Edit buttons and prevents the dashboards from being modified in the interface, so I think we should do that.", "Very minor, but let's drop the dash like in \"DM Overview\"", "I'd maybe think about moving the templates to a top-level directory alongside kibana (like `graphite` or `grafana`) and adding it to the README as it took me a bit to find it in the checkout.", "Ok, just to point out, this only changes whether or not you can change the rows. You will still be able to move graphs around or change what is displayed in them, just you'll not be able to add and change the rows.", "Does it? For me it removes the \"Edit\" buttons from the graphs. I can still drag things around on the dashboard but when I leave it doesn't offer to save any changes", "Weird.. Well, I guess we'll find out soon \ud83d\ude04 "]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/306", "comments": ["I think we might still need `$.url NOT EXISTS` here as not all app logs might have the field"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/293", "comments": ["Let's keep cloudwatch and ec2 permissions, everything else we don't have or wouldn't want in Grafana anyway.", "Same here, elb permissions are fine, everything else we shouldn't need"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/274", "comments": ["Is it worth pulling this back to the environment specific vars files at all?"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/269", "comments": ["This should be 10 years for production"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/263", "comments": ["There's no space here and the formatting looks kind of strange.", "What do you mean?  I don't think there's a problem with the HTML itself.", "<img width=\"823\" alt=\"screen shot 2017-05-08 at 15 15 50\" src=\"https://cloud.githubusercontent.com/assets/11633362/25808258/7202ec94-3401-11e7-9a00-c95006bb28cb.png\">\r\n"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/261", "comments": ["Booooo", "Booo"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/258", "comments": ["`{{ nginx_configs[current_config] }}` and then we might be able to get rid of the duplicate task", "```\r\nnginx_configs:\r\n  live:\r\n    - www\r\n    - ...\r\n  maintenance:\r\n    - maintenance\r\n```", "I'd call this something like `mode=live` or `mode=maintenance`. As long as it doesn't clash with any existing variables."]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/249", "comments": ["this is too broad, this should be:\r\n```\r\n{\r\n   \"Version\": \"2012-10-17\",\r\n   \"Statement\": [\r\n      {\r\n        \"Principal\": {\r\n           \"AWS\": \"arn:aws:iam::${var.access_account_id}:root\"\r\n        },\r\n        \"Action\": [\r\n          \"s3:ListBucket\",\r\n          \"s3:GetBucketLocation\"\r\n        ],\r\n        \"Effect\": \"Allow\",\r\n        \"Resource\": \"arn:aws:s3:::${var.bucket_name}\"\r\n      },\r\n      {\r\n        \"Principal\": {\r\n           \"AWS\": \"arn:aws:iam::${var.access_account_id}:root\"\r\n        },\r\n        \"Action\": [\r\n          \"s3:DeleteObject\",\r\n          \"s3:GetObject\",\r\n          \"s3:PutObject\"\r\n        ],\r\n        \"Effect\": \"Allow\",\r\n        \"Resource\": \"arn:aws:s3:::${var.bucket_name}/*\"\r\n      }\r\n   ]\r\n}\r\n```", "In this case the module name should be \"dev_uploads_s3_bucket\" or similar. Also it's a good rule to use underscores instead of dashes in module/resource names.", "Because I don't know anything about terraform, my only contribution here is (trivially) to complain that 'EOF' is a confusing heredoc terminator, and END_POLICY might be better :)", "Why are the `List` and `Get` actions required on the bucket? What would a user not be able to do without them?", "If I rename the module to something less broad, like `dev-s3-bucket`, does it make sense to just define the bucket resource within `root/aws-dm-dev` as it's the only environment where it's actually going to be used? Or is it better practise to define everything in modules and import them, even if that module would only ever be used once?", "You mean the ListBucket and GetBucketLocation ones? ListBucket allows you to list the contents of the bucket, the GetBucketLocation helps you find the region for the bucket (although this is only needed probably when the region is not explicitly set in the client)\r\n\r\nSee: http://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_examples.html#iam-policy-example-s3", "Yeah that makes sense. I don't actually know what heredoc is, was just copying other examples! I think you can use POLICY instead of EOF which would be better.", "If the module is not reused then I would say it's even better if you just define it directly in aws-dm-dev.", "The Terraform examples use it like this, probably because this could be a file reference, so we can say this is an inline policy file.", "Yeah they're the ones. So does this mean that you can ListBucket and GetBucketLocation from the aws cli? Or the console as well? And if the bucket was only going to be used via the apps, would you still need these permissions; if the apps know which bucket to use is being able to Delete/Get/PutObject enough?", "Cool. My original thought was to just have an s3-bucket module which could then be pulled in by any of the environments and parameterised to suit, but as you can't reuse the same name I don't think it'd work. I think this bucket/policy is quite specific so I'll move it in.", "The console uses the same IAM permissions.\r\n\r\nThe list permission changes the behaviour of non-existing items in the bucket:\r\n - if you don't have listing permission then a non-existing item responds with 403, if you have it it's the expected 404."]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/238", "comments": ["I think we should pass in a decrypted file with `<(sops_wrapper ...)` and then we won't need this. I think we've tried this and it seemed to work before and it would decouple the manifest generation from the credentials encryption.", "That's true, I'm surprised why I haven't done that this way in the first place :) Changed.", "At which point does this start sending live traffic to the new deployment? It doesn't look like it's modifying the routes, so I'm assuming it happens when we change the app name? Or will both apps be receiving a share of the traffic since the have they same routes set?", "What happens if the rollback app has already been stopped, but not deleted?", "This doesn't seem to do anything", "How does run.sh end up in the application release?", "When the cf push finished the new app version starts getting traffic right away. Then we upscale it to the same number and remove the old version. (It should be only a short amount of time)", "Rollback needs to be always a careful manual process, so you have to check what's the current status. The paas-rollback is just a convenient command for the most common cases.", "The Jenkins job adds it when deploying.", "Removed"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/236", "comments": ["Would it make sense to sort this list to make it easier to check / add things in the future?", "I think we should mention the common \"how to run terraform\" in the main README, and maybe link to this one for the setup instructions.", "What are these S3 permissions for?", "Why do we need another key?", "Yeah, I'll sort them.", "It was a copy-paste originally, I moved these to the big list as \"s3:Get*\" and \"s3:List*\"", "I wouldn't put that there as the main README can grow quite big and containing too much information. We can link the Terraform docs in the main README.", "If the Ireland region becomes inaccessible we can still decrypt the credentials with the other master key."]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/233", "comments": ["I think this could be written as \r\n```sql\r\nDELETE FROM draft_services WHERE supplier_id NOT IN (\r\n    SELECT supplier_id FROM suppliers INNER JOIN supplier_frameworks on suppliers.supplier_id=supplier_frameworks.supplier_id\r\n)\r\n```\r\n\r\nNot sure if it's better.", "Your suggestion works but I think we should keep what I had before because that particular snippet of SQL shows up a few times in this file.", "Some audit events are used... Admin uses service update events to show diffs (upcoming work on this v.soon from submissions). And some others (draft service updates maybe?) Used to find dates to display.\r\n\r\nI'm not saying we should keep these necessarily, but it's wrong to say that we don't use them at all.", "We use declaration fields for a lot of the close-of-framework scripts, and also in the admin front-end (\"nameOfOrganisation\", company number and address details are rendered in the countersigning flow.", "Yes, I remember we talked about this the other day.\r\n\r\nProbably worth keeping them in then, eh?", "Let's add the keys that are used by the apps with sanitized values. I don't think we can keep the entire declaration", "That would be good if possible I think.  The bits to look at for required keys are the signing templates in supplier app and countersigning in admin app.  \r\n\r\nI think it's namOfOrganisation, the various address fields (three for G8 and DOS2, one for earlier frameworks) and company number.  But there might be a couple more that get referenced.", "I'm not sure... if we have no \"changed\" audit events we should still be able to test the service editing flow - it will should just treat the current version of services as fresh and new.  Feels like a pain to keep just certain events.  And the draft edit date ones I think only make sense during a live procurement, so those drafts shouldn't be copied over anyway.  \r\n\r\nI just remember seeing some pages break when those audit events have been deleted.", "After talking about this in person yesterday, we agreed not to preserve any audit events (this is what we're doing now).  We could cherry pick some to help us with given scenarios, but ideally we should just be able to create the audit events we need for our test scenarios. (for example, if we're testing the diff page, it's quite easy to make a simple edit to a service and in that way generate an audit event.)", "I've kept the current declaration and run through a few scenarios to see what breaks. \r\n\r\n1. signing an agreement as a supplier\r\n2. putting an agreement on hold as an admin\r\n3. countersigning an agreement as an admin\r\n\r\nTurns out that nothing breaks.  We get some empty fields (including an empty link(!) for the companies' house address), but that doesn't actually cause an error.\r\n\r\nThis is the result: \r\n![screen shot 2017-01-25 at 15 45 51](https://cloud.githubusercontent.com/assets/2454380/22298398/4cd5267e-e318-11e6-92dc-95375f8a220c.png)\r\n\r\nPersonally, I'd argue that keeping the declaration as small as possible is more important than a fake address and a bad link, so if we're happy with this then I'll just merge this PR as-is."]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/229", "comments": ["Setting a default here feels a bit scary, since it could mean that it will start using your production credentials when you don't expect it. Can we pass the profile_name in `dump_to_target` explicitly?", "yup.", "I think these are the places you need to pass `profile_name` instead of in `create_scrubbed_instance`.\r\nThe original `ctx` will match the profile, since Jenkins takes care of that by setting `AWS_PROFILE` for the run. It's when we switch to the target context that we need to override it with the target stage.", "Gotcha.  Updated it."]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/224", "comments": ["Should we drop all of them? I don't think there's anything special about the draft ones. And the files aren't there anyway, so it's not like they'd be useful for the admin flow.", "Yeah, fair enough. "]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/221", "comments": ["Shouldn't this be the default `$proxy_host`? Or can we drop this line altogether? (I'm not sure if nginx will use default headers when all the proxy_set_header inheritance is involved)", "thats a good point - by setting, say, `proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;` we should ignore the earlier proxy_set_header calls, and leave Host untouched from the client. i'll try and test it out locally", "@allait updated to `$proxy_host`, seems to work locally"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/205", "comments": ["It looks like these keys (repo, release, stage, etc.) should always exist, but might it be worth doing `.get()`s just in case?  Although maybe it should break if something is missing.\n", "Feels like we could do with a test around this setting the right value for `created_at`.\n", "I think we want those keys to exist, otherwise we're not publishing the correct data. That JSON is manually built at the moment and we shouldn't normally need this once each release publishes it's own data.\n", "Added a payload `assert`\n"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/197", "comments": ["Out of interest, any reason these go in reverse order? \n", "And why `?all` rather than `-all`\n", "OK I just read a bit more about it... `?all` seems weaker than we might want?  Or is it because we're not sure who might legitimately be sending digital services store emails?\n(My meagre knowledge was just gleaned from https://emailcopilot.com/blog/how-should-i-end-my-spf-record-all/)\n", "I copied the existing records for now. I don't really now the motivation behind them and you're right that it might be worth thinking about them some more, but it seemed like the safest thing to do at the moment.\n"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/195", "comments": ["This file doesn't contain anything specific to Digital Services Store - should/could it have a more generic name in case it might be re-used in future for other domains?  Or are there things here that we really only want to use for DSS?\n"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/194", "comments": ["Might `st1` instances be OK for this?  They're half the price of `gp2`, and use cases include \"log processing\" (https://aws.amazon.com/ebs/details/).\n", "Isn't three instances the minimum recommended for an elasticsearch cluster?\n", "It's a $1/month difference for SSD instead of HDD. And I think `st1` has a 500Gb volume size minimum. \n", "For a production cluster I'd say yes \u2013 it's the minimum HA set up. But in this case I don't think we care that much if we lose the data or the instance goes down for a short time, so I went with the cheapest possible option to begin with.\n", "Where do these `console.log` messages end up? Can we ever get to see them?\n", "It creates a new log group in CloudWatch for each function. It's a bit annoying since I don't think there's a way to configure it and it sets them to never expire by default. But I don't think the functions write very much, and I set a shorter expiration for preview manually.\n", "It also has monitoring for the function runs and failures, so you can see the stats in Lambda interface and go to CloudWatch from there.\n", "Might be worth having a comment in the code about why we need `.slice(-2)` here as it seems a pretty funky thing to do. (I guess it is because of this? http://stackoverflow.com/questions/3605214/javascript-add-leading-zeroes-to-date)\n", "The `isFinite` check seems redundant if it can be parsed as a float?\n", "I haven't really read most of this to be honest \ud83d\ude04 This is the function that AWS console creates when you set up streaming to ES through the web interface. I extended `buildSource` a bit to clean up some repeated fields and drop support for non-JSON logs, but apart from that this is as-is, which might make it easier to update if AWS makes a newer version. (Although I'm not sure if we'd want to and I don't know how we'd find out).\n", "``` javascript\n> parseFloat(1/0)\nInfinity\n\n> parseFloat(\"Infinity\")\nInfinity\n```\n\n\u00af\\_(\u30c4)_/\u00af\n", "Is this something that will generally be done via a Jenkins job rather than from local command line?  If so we could say that in the README too, to make it clear.\n", "The commit message says \"*.logs.beta domains\" - is `stacks.route53zone.outputs.HostedZoneName` always going to evaluate to \"beta\"? \n", "We might want to expand this to all `/_status` requests?  These will all generally be the \"Apps are up\" smoketests.  Not sure if there's anything else we can obviously throw away at this stage... probably keep it all for now.\n", "I'm not sure I follow what this is for - is this to get another new cert?  And then we kill it once they have verified the server and issued the cert to us?  Would we then need to turn it back on for renewal in a couple of years time?   Or have I misunderstood?\n", "OK cool.  500Gb is probably overkill!\n", "LOL, remind me never to work with Javascript.\n", "Seems reasonable.  Will we also have everything in Cloudwatch still, or are we going to kill Cloudwatch in favour of Kibana?\n", "We do need CloudWatch \u2013 it's where instances send logs to begin with, so streaming is for CloudWatch to Kibana. Also it's a more robust permanent storage than an ES cluster, so the idea is to keep only a few weeks of recent data in Kibana to simplify debugging/monitoring.\n", "Could be either. For now, I've done this locally, but we could set up a Jenkins job to deploy new changes after review.\n", "Right now it is, and it's set in the stack variables, so we'd need another commit if we decide to change it to something else.\n", "Letsencrypt creates a standalone server for a few minutes when it updates a certificate, so we do need it open every few months.\n\nI went back and forth on keeping it open all the time. What I've done is move all nginx stuff to 443, so Jenkins and log proxies are only available via HTTPS and the security group for 443 only allows  AH IPs. Which should make it safe to open port 80 for everyone, so that we can use it for renewing letsencrypt certs. We could close it when we don't need it to avoid accidental nginx misconfiguration, but apart from that it shouldn't make any difference since nothing is listening most of the time.\n"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/172", "comments": ["Is the `EnvVarDmS3DocumentBucket` obsolete now? If so it would be good to remove it to avoid clutter.\n", "It is at the moment but once this change goes in the admin app can be updated and then `EnvVarDmS3DocumentBucket` can be removed.\n", "I suppose it's about time we gave up on this getting fixed\n"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/170", "comments": ["Do we need dev access to production to take a snapshot or is this to avoid manually creating security groups for snapshot DB?\n\nI'm a bit worried that the difference between cleaning up a snapshot and wiping out production data is `tmp_` in the `RDSPostgresClient` argument.\n", "I think we might be able to skip this, since creating dev access plan should gather database info and fill variable values anyway.\n", "I think you accidentally a word\n", "I suspect it's a boto thing, but just to check: why do we need to get all snapshots if we try to delete the conflicting one either way?\n", "Could be `self.delete_snapshot`?\n", "This works pretty well for staging, but for `preview` using user id makes it harder to find out what user account can be used for each supplier. For preview, can we do something similar to what API to API script is doing now: instead of importing existing users create a `suppier-<supplier_id>@user.dmdev` user for each active supplier (and maybe change the supplier contact details to match that email).\n", "I'm a bit lost about what this does. We're deleting supplier_frameworks for open frameworks (which shouldn't have live services). So that doesn't affect live frameworks. This query then tries to create records for existing live frameworks, which should already exist in production.\n\nThis also checks for supplier ids without any records, but what we're actually interested is whether the `(supplier_id, framework_id)` pair already exists.\n", "No, the sentence is as intended. If it's not clear I can make it more explicit.\n\n> Create a new RDS snapshot deleting the existing snapshot if there is one.\n", "Yes, this is how you get a specific db snapshot. If it doesn't exist it will raise a 404 short circuiting the delete.\n", "Yes, good call.\n", "On preview we don't have `supplier_frameworks` records for G-Cloud 5 (I haven't checked if this is the case on production). We remove any suppliers that don't have any `supplier_frameworks` record on the assumption that they're only associated with open frameworks. This statement adds in records for suppliers that have services to avoid us trying to delete those suppliers.\n\nThe deletion of dangling suppliers has changed since this was done though so it might warrant another look. Maybe building the list of dangling suppliers my checking both `supplier_frameworks` and `services`.\n", "The data on preview will get replaced though, what matters is that `supplier_frameworks` records for all live frameworks are not affected by the deletion of open frameworks. If that's the case then whatever live supplier frameworks exist (~~or not~~ Sorry, I've just realised that the problem is in the dangling supplier delete if production doesn't have records for live frameworks and the app handles that. I don't think we have special cases for existing live frameworks though, but it might be worth checking what happens with expired ones.) in production should be fine for staging and preview (assuming production data is correct, otherwise we need to fix that first).\n", "To the first question; yes. Although that's a good point, it would be good to handle that in the RDS client, I'll take a look at it.\n", "With stacks replaced by 'built stacks' on the original context I'm not really sure whether we can be sure that this new context doesn't have any data carried over from the original environment. I think it might be better to do a fresh `ctx.load_stacks(stacks_file)`, unless I'm missing a reason why we need a copy.\n", "`src_pg_client` seems to be closed in `dump_to_target`\n", "Do we need to explicitly close this connection the same way we close `src_pg_client`?\n", "The reason we don't do a fresh `ctx.load_stacks(stacks_file)` is that we don't have the `stacks_file` at the point that this is used (in the `migratedata` command). The reason we need a new context is to create and delete stacks in two different environments at the same time. \n\nIf you think might be a risk it may be worth while just biting the bullet and getting all the construction code out of `dmaws.cli.py`. What do you think?\n", "We can store the `stacks_file` in `ctx.stacks_file`, since we'd still need to find a way to pass it in even if we move the logic from `@cli_command`. And most commands still need one context, so I'm not sure if moving it out is worth it right now.\n", "Nice spot, that's a bug.\n"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/168", "comments": ["Is the order of versions that this returns guaranteed by `beanstalk`? It needs to be ordered with the oldest first for this method to work. (At least to avoid deleting recent versions.)\n", "It's returned with the most recent first and this will remove the tail of that list.\n", "Ah yes, the \"slice\" notation - so terse it's easy to completely miss it. (At least on the bus early in the morning.)\n"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/160", "comments": ["Other rules in this file have a space between the `^` and `~` - I don't know enough about nginx config to say if that is significant at all.\n", "It's a different kind of rule. The ones that start with a `~` on it's own are regular expression rule. This one (`^~`) is a prefix rule that overrides regular expression rules.\n\nhttp://nginx.org/en/docs/http/ngx_http_core_module.html#location\n"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/138", "comments": ["Are we going to get these things written up in the manual at some point? Seems pointless to keep the URLs in otherwise.\n", "The file is HTTP5xx alarm but the message is about login failures - doesn't seem right?\n", "Yep - I think you have the messages round the wrong way - the Login Failure one should be here?\n", "500s feel like something we could alert on with fewer than ten - in that we shouldn't ever see them and if we do then the app might need to be fixed.  So maybe even just one as a threshold? Or are there cases where we do expect a 5xx out of the app?\n", "This doesn't look like a `.json` file - should this also be `.j2`?  Or is Cloudformation happy with this as JSON?\n", "Yes, I'm going to do that today.\n", "Agreed, I copied over the original threshold with the idea that I'd reduce them in a separate pull request which wouldn't block this one if there was disagreement. I think two people is enough though.\n", "Our dmaws tool runs this through jinja and the result is valid json.\n", "Bums, good spot.\n", "Sweet :)\n"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/126", "comments": ["300 whats? is that millis or seconds? Is it long?\n"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/125", "comments": ["5 minutes sounds like quite a long grace period. Does this affect how quickly it will apply the update?\n", "Yes, since it should update instances one by one this will act as an additional delay for each instance.\n\nI was trying to figure out a bit more about this as it's not clear when the timer starts (is it the instance start time or the time between EC2 health check and ELB one, since default EC2 health check seemed to work fine without it etc.). But most things I found recommend setting it to a high value, mostly because otherwise ASG can fail to bring up new instances and just restart them over and over again.\n\nThis should only delay the AMI updates which we had to do manually anyway, so shouldn't be that bad.\n", "Fair point. :shipit: \n"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/98", "comments": ["Out of interest, where does this ami number come from?\n"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/83", "comments": ["Let's move this to a variable in case we'll have different mailing lists for environments in the future\n", "Good call. Done.\n", "Let's merge `rds` with `database` variable\n"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/78", "comments": ["I really like that all these conditions are in one place now.\n"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/75", "comments": ["PR description says \"In development and preview RDS instances do not need to be MultiAZ\", but this is `true`.\n", "That is a very good point :no_mouth:.\n"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/73", "comments": ["I'd keep the password_salt in the secret config, just to be on the safe side. Otherwise there's no reason to keep it as environment variable, it can just be set in app config directly\n", "OK maybe I'll do that - i.e. move it into app config file. From what it said in the docs you linked to I don't think it needs to be secret.\n"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/72", "comments": ["I don't think this should be here. The specific stacks that require it should depend on it.\n", "Delete traverses dependencies in the opposite order. If monitoring isn't listed in the `all` group the stack won't get deleted unless explicitly mentioned\n"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/71", "comments": ["Why does elasticsearch use the `GroupTag` but Nginx doesn't?\n", "I'm not sure if that's what you mean, but GroupTag is used for elasticsearch cluster discovery (so that nodes only join within their own environment). Since nginx doesn't cluster there's no need for GroupTag.\n\nThe stream name is a bit redundant, `elasticsearch-preview-preview` inside the `preview-preview` group. But since it's also the cluster name, I think it makes sense.\n"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/70", "comments": ["Are the `EnvVarDmApiUrl` and `ApiAuthToken` still used then?\n"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/69", "comments": ["Is it worth mentioning where we can find the passwords?  Or too secret for here?\n", "Fair point, I've added a note.\n"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/68", "comments": ["Surprisingly nice.\n"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/61", "comments": ["`deps` could be both dependencies and dependants, it might be better to have the full word here, just like we do in `create(self, create_dependencies=True)`\n"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/38", "comments": ["Why do we ignore errors here?\n", "There's no step that depends on this being successful, and we still need to remove downloaded file and do the dev-access teardown\n", "Where is this script from?\n", "API repo path, which we take as an argument. It'll get replaced with something more suitable as soon as the API is pushing updates to Elasticsearch\n", "I think it would still be useful to know that it has failed.\n", "The command output is printed in any case, this just doesn't raise the exception\n", "Ah, I see, missed the `cwd`.\n", "It swallows the fact that there was any error. If the command being run doesn't output anything you have no feedback that it failed. A log message to say that the command has failed would be helpful.\n", "Added start and finish log messages to run_cmd. Prints the command name only and return code on exit.\n"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/37", "comments": ["We should return the URL with the new domain here, since it's used to link the apps together. We'll just have to switch it to https when the certificates is in place.\n"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/32", "comments": [":sob: \n"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/28", "comments": ["This will be a merge conflict with https://github.com/alphagov/digitalmarketplace-aws/pull/27/files#diff-82cedc58a55843ad9169fc5b6ea91af6R82 if both land, so we should probably chose whichever looks better and keep it\n", "I like a mix of the two actually. I like having an explicit `keys` method and I like the list comprehension based `items` method that knows nothing about `_cache`. Looking at the pull requests as a whole #27 is less contentious and should probably therefore be merged first. Would you object if I changed `items` to the list comprehension style after it's merged?\n", "Sounds good. I'm :+1: with the PR otherwise\n"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/27", "comments": ["This took me a bit of thinking to understand. If what we're trying to say is \"Prefix any capital letter that is not at the start of the string with an underscore\" could this just be done with `re.sub('(.)([A-Z])', r'\\1_\\2', name)`\n", "Bums, I've implemented this in one of my PRs. Race to first merge!!\n", "This splits things like `HTTPRequest` into `http_request` too, while the simpler methods don't. We don't actually _need_ this, since you can use `HttpRequest` in parameter name and it will be uppercased anyway, but I'd still keep the current version.\n", "Ahh, I see. Sounds good then.\n"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/19", "comments": ["Can we use the repository URL as the command argument instead? That way we only rely on the `digitalmarketplace-{app_name}` convention and can deploy from other clones if needed\n", "I would be reluctant to allow us to release from other clones unless we have a good reason. I think it's fine for the development account but for production I'd want it more explicit.\n", "We should remove all untracked and ignored files at this point too, including build artefacts from previous builds and npm/bower modules\n", "Good spot, this is in fact completely wrong, `git reset --hard origin` isn't even a valid command.\n", "This is probably a stage more than environment (even though it's used as both)\n", "What do you think about having one AWS_PROFILE per stage, instead of one per AWS account (i.e. preview/staging/production profiles)? That way we could either use the same access keys for staging/production and get the same behaviour or look into separating permissions where possible\n", "ValueError?\n", "This is probably safe enough for us, but one case where this won't work as expected is if origin master was force-pushed. How about `fetch` followed by `git reset --hard origin/master` instead of `pull`?\n", "I went with environment because it's a more commonly understood term. It's the language that's used throughout GDS and the service manual.\n", "Yea, ok...\n", "At some point we have to have the knowledge of which stages are associated with which accounts. I'd rather that be recorded somewhere in git, the jenkins credentials file will probably not be.\n", "That's a good point. I'm not sure if Jenkins is the place we need to be worried about being commonly understood since it's less accessible than the deployment repository itself. At the same time, I feel like it's best to be consistent in our usage of `stage` vs `environment`, otherwise it can get confusing.\n\nMaybe it's worth changing `stage` to `environment` and `environment` to `??` since this keeps coming up.\n", "After chatting in real life we've agreed to document this in the manual.\n", "Yep, good spot.\n", "Agreed in real life to rename this variable to STAGE and then look at renaming STAGE to ENVIRONMENT and ENVIRONMENT to ENVIRONMENT_CONTEXT.\n", "`--from-account=preview`? Or maybe `--from-profile` would probably make more sense now.\n"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/18", "comments": ["Won't this push the commits as well? This gets called for the development deploys too as far as I can tell, which might contain unpublished code\n", "`ValueError` seems to fit quite well here\n", "`os.close(package_file)`\n", "Discussed irl, gonna put this in the release task.\n", "Good call.\n", ":smile: \n"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/17", "comments": ["Do these need to be overridden int he `production.yml`?\n", "Should the elasticsearch cluster be configurable in the same way?\n", "It already is but it just has `instance_count` instead of `min_` and `max_` because we can't autoscale it\n", "Yes, but I think we should do this once we have the production account and know the final instance sizes that we'll use\n"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/13", "comments": ["Where is this `build.sh` script? Can't see it in this project or in the apps being deployed?\n", "It's run from the repository being deployed. I have a script for the admin-frontend that I'll send for review a bit later.\n", "So (just to clarify) do we still need Ansible for 'provision' but are dropping it for create/delete/deploy?\n", "The `production.yml` and `preview.yml` subnets are identical - is that right? And if so do we need both files, or could we just have one file that is used for both stages?\n", "Yeah. And we're gathering the variables in python and sending the full dictionary to ansible, so it's only responsible for actually running the provisioning tasks\n"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/9", "comments": ["I don't think the 'or' should have been removed here.\n", "Looking at the docs it seems the or should go?\n\"CidrIp - Specifies a CIDR range.\"\n http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-security-group-ingress.html#cfn-ec2-security-group-ingress-cidrip\n"]}, {"url": "https://github.com/Crown-Commercial-Service/digitalmarketplace-aws/pull/4", "comments": ["These registered variables get really long. We should think about a terse convention for them.\n", "I'm trying to use a simple consistent naming scheme for now, so staying away from abbreviations.  This way the vars that end up in common/user var files hopefully will be self-descriptive. But I do agree that a terse convention might be better if we come up with a good one.\n"]}]}, {"url": "https://github.com/levmichael3/terraform.git", "pull_requests": []}, {"url": "https://github.com/robgeiner/hello-containers-20171114184238928.git", "pull_requests": []}, {"url": "https://github.com/vuvuzella/jt-aws-serverless-app.git", "pull_requests": []}, {"url": "https://github.com/utilitywarehouse/tf_telecom.git", "pull_requests": []}, {"url": "https://github.com/hmcts/cnp-module-app-service-plan.git", "pull_requests": [{"url": "https://github.com/hmcts/cnp-module-app-service-plan/pull/14", "comments": ["feel free to try it but we've tried before, if you look at the issue nitin's another one linked to it, normally we bin the plan and rebuild it when this happens"]}]}, {"url": "https://github.com/cds-snc/terraform-modules.git", "pull_requests": [{"url": "https://github.com/cds-snc/terraform-modules/pull/378", "comments": ["Could you change this to default to empty and then only create the alias resource if requested?  That way we won't get `latest` aliases auto created for all our functions:\r\n```suggestion\r\n  description = \"(Optional, default '') Lambda function's alias name\"\r\n  default     = \"\"\r\n```", "And then the check here to conditionally create the alias:\r\n```suggestion\r\n  count            = var.alias_name != \"\" ? 1 : 0\r\n  name             = var.alias_name\r\n```"]}, {"url": "https://github.com/cds-snc/terraform-modules/pull/362", "comments": ["This just needs to be tweaked like so:\r\n```suggestion\r\n  bucket = var.s3_bucket_name == \"\" ? \"${var.domain_name_source}-${random_string.suffix.result}\" : var.s3_bucket_name\r\n```"]}, {"url": "https://github.com/cds-snc/terraform-modules/pull/319", "comments": ["Just to make sure we don't accidentally overflow with a long cluster name, could you also add a substring like so:\r\n```suggestion\r\n  function_name     = substr(var.cluster_name, 0, 64)\r\n```", "Thanks Pat for the suggestion (as always). This has been corrected. "]}, {"url": "https://github.com/cds-snc/terraform-modules/pull/317", "comments": ["Could we also attach the ECS task role policy so the example works:\r\n```suggestion\r\n}\r\n\r\nresource \"aws_iam_role_policy_attachment\" \"simple\" {\r\n  role       = aws_iam_role.simple.name\r\n  policy_arn = \"arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy\"\r\n}\r\n```"]}, {"url": "https://github.com/cds-snc/terraform-modules/pull/308", "comments": ["I assume this file isn't required?", "It defines what outputs the module has for reference in other modules"]}, {"url": "https://github.com/cds-snc/terraform-modules/pull/243", "comments": ["Instead of building up an arn just accept the arn as the input. ", "Same as above comment...\r\n\r\nInstead of building up an arn just accept the arn as the input.", "Thanks Calvin! Sorry for the basic question, but how would this work though given that we are applying it all accounts and we don't know the arn information when we are applying it [here](https://github.com/cds-snc/aft-global-customizations/blob/main/terraform/auto_revoke_sg_rules.tf)? Would you suggest creating a local block in the global customizations module something similar to the code below?:\r\n```\r\nlocals {\r\n  sns_topic_arn = \"arn:aws:sns:${local.region}:${local.account_id}:internal-sre-alert.arn\"\r\n}\r\n\r\nmodule \"auto_revoke_sg_rules\" {\r\n  source            = \"github.com/cds-snc/terraform-modules?ref=v5.0.3//auto_revoke_sg_rules\"\r\n  billing_tag_value = \"SRE\"\r\n  sns_topic_arn  = sns_topic_arn\r\n}\r\n```\r\nAnd then of course in the module code, we will have input value sns_topic_arn and the Resource will be changed to that input value. ", "So instead of using the data lookups for data and region within this module the code that calls it will do that and build the arn that way. \r\n\r\nI was only thinking of passing an arn because we can then modify in the future to pass multiple arns if we want to alert to multiple things. \r\n\r\nBut we can always change that in the future so I'll approve as is."]}, {"url": "https://github.com/cds-snc/terraform-modules/pull/214", "comments": ["Can you switch this like so:\r\n```suggestion\r\n    for_each = length(keys(var.file_system_config)) == 0 ? [] : [var.file_system_config]\r\n```\r\nWhat this does is check if the `file_system_config` has any attributes, and if yes, creates a single item list of that `file_system_config` map object that gets looped over once by the `for_each` loop."]}, {"url": "https://github.com/cds-snc/terraform-modules/pull/211", "comments": ["Can we add tags to some of those resources, if not then we should just delete this file. ", "This is no longer being used by anything, maybe we should delete the inputs, or re-enable the tags that it's associated with", "The tags will be added automatically by Azure Landing Zone.  I'll delete this file.", "added a simple example "]}, {"url": "https://github.com/cds-snc/terraform-modules/pull/209", "comments": ["Consider making this a variable with the current value as the default. Here is an example\r\n\r\nhttps://github.com/cds-snc/terraform-modules/blob/main/sentinel_forwarder/main.tf#L35\r\n\r\nand here is the input\r\n\r\nhttps://github.com/cds-snc/terraform-modules/blob/main/exposed_iam_credentials_disabler/input.tf#L13-L27\r\n\r\nThis could avoid potential namespace collisions, however unlikely.\r\n\r\n", "Thanks for the suggestion Max - I have made the change. "]}, {"url": "https://github.com/cds-snc/terraform-modules/pull/208", "comments": ["Change this to `boolean`", "(var.critical_tag_key) = var.critical_tag_value ? \"true\": \"false\"", "done", "updated as discussed"]}, {"url": "https://github.com/cds-snc/terraform-modules/pull/191", "comments": ["```suggestion\r\n            echo \"\ud83d\udca9 The following files need to be committed:\"\r\n```", "Resolved"]}, {"url": "https://github.com/cds-snc/terraform-modules/pull/165", "comments": ["Should this be `aws_lambda_function.this.version`?", "Yes \ud83e\udd26 "]}, {"url": "https://github.com/cds-snc/terraform-modules/pull/143", "comments": ["```suggestion\r\n- This code embeds security features such as least privileged access\r\n```", "Or even more general to cover: `This code adopts security best practices for Terraform`?"]}, {"url": "https://github.com/cds-snc/terraform-modules/pull/133", "comments": ["should we store this in scan-files and grant access to org ?", "I like that idea - let me look into making it happen"]}, {"url": "https://github.com/cds-snc/terraform-modules/pull/130", "comments": ["this is pretty neat, haven't seen it before!", "what do you think about making this configurable. one variable for `status code` and another for `headers`. This would allow this module to be used for any response purpose. We could default to what you have.", "that's a nifty idea - I've updated so that the response code and headers are now configurable.  I'm sure we'll see each other again when the `body` also gets added \ud83d\ude08 "]}, {"url": "https://github.com/cds-snc/terraform-modules/pull/128", "comments": ["Any reason to not just use the same `${var.name}-eip${count.index}` naming?  I'm thinking just from a code simplicity standpoint.", "Could this just be the `local.nat_gateway_count`?", "What if we added the `var.enable_eip` check in here and then just had a constant `nat_gateway_count` that could be used in the other `.tf`?\r\n```hcl\r\n# Not sure if this is valid HCL\r\nnat_gateway_count = var.enable_eip ? (var.single_nat_gateway ? 1 : local.max_subnet_length) : 0\r\n```", "Same idea of just using `local.nat_gateway_count` here if possible, and expect it to be 0 if `var.enable_eip = false`", "i like it", "no reason, just didn't like the numbers when it would always be 1. But good point on the simplicity. I've reverted back to the count naming convention.", "didn't work as expected, so i reverted back to the original method."]}, {"url": "https://github.com/cds-snc/terraform-modules/pull/117", "comments": ["Just a minor comment - you can have this as the `identifier` and it ends up being the same behaviour:\r\n```hcl\r\nidentifiers = [data.aws_caller_identity.current.account_id]\r\n```", "Is it required to do a for each on this or can we simply do something like \r\n\r\n```hcl \r\n      principals {\r\n        type        = \"Service\"\r\n        identifiers = [var.kms_event_sources]\r\n      }\r\n```\r\n\r\nand have the count be something like:\r\n\r\n```hcl\r\n   count = (length(var.kms_event_sources) > 0) ? 1 : 0\r\n```\r\n\r\nThere is a limit to the number characters a policy can have.\r\n\r\nIt is 6144 characters so we have room, so not a big deal if we can't.\r\n\r\nhttps://aws.amazon.com/premiumsupport/knowledge-center/iam-increase-policy-size/#:~:text=For%20more%20information%2C%20see%20IAM,for%20a%20service%20quota%20increase.", "Same comment as above", "\ud83d\udc4d "]}, {"url": "https://github.com/cds-snc/terraform-modules/pull/103", "comments": ["Super minor, but could you change the resource name to something like:\r\n```hcl\r\ndata \"aws_iam_policy\" \"read_only\"\r\n```", "It would make more sense so +1 to that!", "You can drop the version - the `aws_iam_policy_document` `json` attribute adds this in for us.", "Could this maybe change names to something like `assume_policy`?  It threw me off for a bit because I was expecting it to be a list of multiple policies and I was trying to figure out how things were working in your examples.", "\ud83d\udcaf ", "good catch, updated!"]}, {"url": "https://github.com/cds-snc/terraform-modules/pull/102", "comments": ["Do we need the level of configuration this gives us? \r\n\r\nDo we have a use case for this other than replicate everything in a bucket into another bucket in the same region? ", "Should this just be the ARN of the destination bucket for simplicity's sake?", "For cloud based sensor, I'll need to control encryption with a KMS key and changing object ownership.\r\n\r\nThings like `metrics` and `replication_time` could be dropped with no problem.  I could also wipe out the `filters` and just use full object replication (default to a blank filter).\r\n", "Yes I'd like to keep it as simple as possible, we can always add in the complexity if needed later."]}, {"url": "https://github.com/cds-snc/terraform-modules/pull/84", "comments": ["nit: spelling of `lambda` in the description"]}, {"url": "https://github.com/cds-snc/terraform-modules/pull/72", "comments": ["Can we use the default memory_size of 128 MB ? Does this need 1GB of memory ?", "suggest uuid like we do in covidalert incase there's a name collision with other statements in the future", "Good catch - it most certainly does not.  Lowered to 128.", "heh, I just know this would've gotten me in the future.  I've added the `function_name` to make it unique."]}, {"url": "https://github.com/cds-snc/terraform-modules/pull/58", "comments": ["So this will allow ingress on 443 as well we should change the name of the PR and more importantly the variable. \r\n\r\nMaybe we can name it just `allow_https` or we can add two variables `allow_https_ingress`, `allow_https_egress` though if we were to do that we should probably go further and just split it into four variables.\r\n\r\n\r\n", "Good point about the naming.  I like that idea of two variables `allow_https_ingress` & `allow_https_egress` to control both pieces of the flow.", "I ended up going with 4 variables and updating the PR description with the new behaviour."]}, {"url": "https://github.com/cds-snc/terraform-modules/pull/43", "comments": ["For consistency, how about an `(Optional)` or `(Required)` prefix to all var descriptions.", "Same comment if we want `(Optional)` and `(Required)` suffixes in the var descriptions.", "Same comment re: description optional/required suffixes.", "SID description?"]}, {"url": "https://github.com/cds-snc/terraform-modules/pull/21", "comments": ["Suggest changing  to `username` to align with the discontinued use of the `master` noun", "Suggest changing  to `password` to align with the discontinued use of the `master` noun", "good idea I was just parroting the AWS terminology\r\n", "will do"]}, {"url": "https://github.com/cds-snc/terraform-modules/pull/8", "comments": ["Shouldn't this be `$.responseElements.ConsoleLogin = \\\"Failure\\\"`?", "If CDS wants the public service to fail fast then we shouldn't think of failures as a bad thing, so in a way all of our failures are successes."]}]}, {"url": "https://github.com/rribeiro1/terraform-aws-budget-alarms.git", "pull_requests": [{"url": "https://github.com/rribeiro1/terraform-aws-budget-alarms/pull/1", "comments": ["**[tfsec]** <sub>reported by [reviewdog](https://github.com/reviewdog/reviewdog) :dog:</sub>\nResource 'aws_sns_topic.account_budgets_alarm_topic-2' defines an unencrypted SNS topic."]}]}, {"url": "https://github.com/FairwindsOps/terraform-vpc.git", "pull_requests": [{"url": "https://github.com/FairwindsOps/terraform-vpc/pull/49", "comments": ["This is blocked until we migrate the name i think"]}, {"url": "https://github.com/FairwindsOps/terraform-vpc/pull/19", "comments": ["Line 6 looks further indented than 7 - 12.\n", "Indentation on 3-7 seems further over here and > 2 spaces within the blocks that follow.\n"]}, {"url": "https://github.com/FairwindsOps/terraform-vpc/pull/4", "comments": ["does this really use one or the other? how does that not throw errors?\n", "so if count=0 then the resource isn't created? fascinating\n", "I was skeptical too. The plan though shows appropriately empty values:\n\n### Gateway:\n\n```\n+ module.vpc.aws_route_table.private.0\n    route.#:                                     \"\" => \"1\"\n    route.~3252072605.cidr_block:                \"\" => \"0.0.0.0/0\"\n    route.~3252072605.gateway_id:                \"\" => \"\"\n    route.~3252072605.instance_id:               \"\" => \"\"\n    route.~3252072605.nat_gateway_id:            \"\" => \"${element(aws_nat_gateway.nat_gateway.*.id, count.index)}\"\n    route.~3252072605.network_interface_id:      \"\" => \"\"\n    route.~3252072605.vpc_peering_connection_id: \"\" => \"\"\n    tags.#:                                      \"\" => \"1\"\n    tags.Name:                                   \"\" => \"private_az1\"\n    vpc_id:                                      \"\" => \"${aws_vpc.default.id}\"\n```\n\n### Instance:\n\n```\n+ module.vpc.aws_route_table.private.0\n    route.#:                                     \"\" => \"1\"\n    route.~4093859331.cidr_block:                \"\" => \"0.0.0.0/0\"\n    route.~4093859331.gateway_id:                \"\" => \"\"\n    route.~4093859331.instance_id:               \"\" => \"${element(aws_instance.nat.*.id, count.index)}\"\n    route.~4093859331.nat_gateway_id:            \"\" => \"\"\n    route.~4093859331.network_interface_id:      \"\" => \"\"\n    route.~4093859331.vpc_peering_connection_id: \"\" => \"\"\n    tags.#:                                      \"\" => \"1\"\n    tags.Name:                                   \"\" => \"private_az1\"\n    vpc_id:                                      \"\" => \"${aws_vpc.default.id}\"\n```\n", "It works... looking at the plans and the results of two runs. Maybe this approach is too sketchy though. I couldn't think of a clean way though to separate all the bits that interact with the NAT layer from the rest: EIP, instances or gateways, sg's, and routing tables,. \n"]}]}, {"url": "https://github.com/sammaritan12/terraform-personal-website.git", "pull_requests": []}, {"url": "https://github.com/willfarrell/terraform-logs-module.git", "pull_requests": []}, {"url": "https://github.com/nilessssh/bp.git", "pull_requests": []}, {"url": "https://github.com/mantvydasb/Red-Team-Infrastructure-Automation.git", "pull_requests": []}, {"url": "https://github.com/falldamagestudio/UE4-GHA-BuildSystem.git", "pull_requests": []}, {"url": "https://github.com/NaamaCohenIvgi/terragoat.git", "pull_requests": []}, {"url": "https://github.com/chrislittle/AzureSubscriptionAutomation.git", "pull_requests": []}, {"url": "https://github.com/cookpad/terraform-aws-eks.git", "pull_requests": [{"url": "https://github.com/cookpad/terraform-aws-eks/pull/341", "comments": ["I see this block is very similar to `resource \"kubernetes_config_map\" \"aws_auth\"` why we have this twice?", "In web-platform-X  we use` instanceProfile: EKSNode` [here](https://github.com/cookpad/global-web-platform/blob/main/k8s/infrastructure/base/karpenter/provisioner-default.yaml#L35) we will have to change it in the provisioner?", "maybe more clear to rename this file to karpenter_spot_node_interruption_queue.tf?", "maybe more clear karpenter-spot-node-interruption-${var.name}?", "add a description", "5.1.0 maybe?", "2.21.1 is the latest", "we want as well flux-system namespace to run on Fargate? Is not strictly necessary because it uses deployments but maybe as is a critical service....", "The `kubernetes_config_map` creates the configmap, whereas this resource manages the content of the `data` field.\r\n\r\nManaging this this way means we get changes to the data in the terraform plan.\r\n\r\nI copied the idea for this from this module https://github.com/terraform-aws-modules/terraform-aws-eks/blob/master/main.tf#L536-L569", "`>= 4.47.0` covers this, since we expect other projects to depend on this module we should have loose constraints (within reason).", "Same", "That is the intention, but we can add the old profile name to the map during transition.", "I don't think it makes it clearer, this queue will have a number of different events - not only spot interruptions."]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/337", "comments": ["```suggestion\r\n  name                 = \"${var.iam_role_name_prefix}-EksEBSCSIDriver-${var.name}\"\r\n```\r\nwould be nice for readability - or do you need this as-written to be compatible with with what you've implemented for the web platform clusters?", "I think this makes the prefix non optional (default role name will be `-EksEBSCSIDriver-nanana`)?", "Perhaps we can do something like\r\n```suggestion\r\n  name                 = join(\"-\", compact([var.iam_role_name_prefix, \"EksEBSCSIDriver\", var.name]))\r\n```", "\ud83e\udd37 then we have `-` in the middle of camelcased names though\r\n\r\n`GlobalWebPlatformEksEBSCSIDriver-clustername`\r\n\r\nvs\r\n\r\n`GlobalWebPlatform-EksEBSCSIDriver-clustername`", "ah yes neater than the suggestion I was mid-writing with a var null condition \u2764\ufe0f "]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/331", "comments": ["I had to double-check, but passing `null` through to the `eks_addon` resource is equivalent to not passing the option\r\n\r\nhttps://developer.hashicorp.com/terraform/language/expressions/types#null\r\n", "Possibly contentious variable naming - I've preserved the addon name as-is, including the kebab case. _Possibly_ makes it easier to identify that `vpc-cni` is the addon, and `configuration_values` is the argument.\r\n\r\nHappy to go full snake case.", "On the whole our rule is to just snake case everything for consistency ... \ud83e\udd37 I am 50/50 on this one though!", "We could use structural typing here to do some kind of validation on the inputs... unless this is already handled internally by the provider???\r\n\r\n```suggestion\r\n  type = object({ computeType = string, corefile=string, nodeSelector=object(string), replicaCount=number, resources=object(string)})\r\n  default  = null\r\n```", "Different versions of an EKS addon have different schema for their configuration values - so the provider simply transparently passes the json-encoded string, and leaves mapping the addon version <-> configuration value schema to the user.\r\n\r\nBecause we hard-code the addon versions, it _is_ technically possible for us to provide a well typed interface with the configuration values. **I will do this.**\r\n\r\nI should note a drawback that this adds more steps to our upgrade process for this module. We will need through each addon version we've updated, fetch the latest configuration values schema, and map that into the variables.\r\n\r\nWe should probably do this activity anyway however, to notify users of breaking changes in the configuration value schema.\r\n\r\n\r\n> :memo: Note to self: command to check configuration value schema is\r\n> ```\r\n> $ envchain aws aws --profile=cookpad-global-1 eks describe-addon-configuration --addon-name aws-ebs-csi-driver --addon-version v1.10.0-eksbuild.1 | jq '.configurationSchema' -r | jq\r\n> ```", "CI is failing with \r\n\r\n> Message_: \"ConfigurationValue provided in request is not supported: Json schema validation failed with error: [$: null found, object expected]\"\r\n\r\nso we need to check this. Checking the jsonschemas for the addon configurations we can pass an empty object as the default ", "If we do this I think we could look at adding a unit test to check our well typed interface against the jsonschema for the addon", "I think we can use https://pkg.go.dev/github.com/hashicorp/terraform-config-inspect/tfconfig#LoadModule within a unit test to load [the cluster module and its Variables](https://pkg.go.dev/github.com/hashicorp/terraform-config-inspect/tfconfig#Module)", "or keep null as default and don't call `jsonencode` in the `aws_eks_addon` resources", "Ah of course - the `jsonencode` is the source of the problem.\r\n\r\nIts not _totally_ clear what the expected behaviour is for `configuration_values = \"{}\"`, because whilst none of the fields are included in `required`, they also have no defined jsonschema `default`.", "Ah yes you're right - perhaps better to avoid the call to `jsonencode` then \ud83d\udc4d ", "I chose a different direction - see https://github.com/cookpad/terraform-aws-eks/pull/331#issuecomment-1428155603"]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/330", "comments": ["I think its safe to make this `true` by default. It reduces the number of steps required to migrate, and has no effect for users who do not want to migrate.", "I think this is risky actually ... please test, but I think it may force a delete and recreate on an existing cluster!", "I am guessing we will need some instructions in UPGRADING to explain the manual state migration steps that will be needed!", "Could I request some support on (or information about) the testing process?\r\n\r\nThe [docs mention pre-production testing](https://github.com/cookpad/terraform-aws-eks/blob/main/RELEASING.md#branching) - do we have a test cluster configured for this purpose?"]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/324", "comments": ["I would remove autoscaler from the module. why? because Flux can install it and with POD priority we can say to the scheduler to schedule 1st PODS with high priority. Other reason is because maybe we want to install other node autoscaler system.", "same, I would remove autoscaler instlation", "In case of using autoscaler, we will want to set the param that sets the avg cpu/mem for each node, before scale, staging for example nodes are underutilitzated", "Yeah this PR is just to get the new version of k8s up and running with the existing setup.\r\n\r\nI am working on some additional changes, including depreciation of the autoscaler addons. There is a quite a bit of complexity here in order to make the module testable! So I am going to make those changes in an additional PR", "ok! just for curiosity, in autoscaler you have this param:\r\n\r\nThe scaleDownUtilizationThreshold defines the proportion between requested resources and capacity, which under the value cluster-autoscaler will trigger the scaling down action.\r\n\r\nOur default value is 65%, which means in order to scale down, one of the nodes has to have less utilization (CPU/memory) than this threshold."]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/313", "comments": ["I think name like \"required\" or \"enforced\" would be more descriptive", "changed to imdsv2_required", "do we need to set this everywhere in the examples - it is the default?", "the default is true, I'll remove it from here just to make it cleaner"]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/307", "comments": ["Have you verified that [this](https://github.com/cookpad/terraform-aws-eks/commit/dc5394ac5f253eb3e528cb6ad8bd6471bd075c1c) has been resolved?", "In theory has been fixed in 1.22 https://docs.aws.amazon.com/eks/latest/userguide/kubernetes-versions.html but I'll check if the configmap of kube-proxy binding metricsBindAddress is now to 0.0.0.0 instead of 127.0.0.1", "I have created with terraform apply the example cluster that is in the /example folder of this repo and the bindaddress of the configmap \"kube-proxy-config\" is BindAddress: 0.0.0.0:10256, so the kube-proxy addon issue was fixed.", "I get:\r\n\r\n```\r\nError: failed to download \"eks/aws-node-termination-handler\" at version \"1.15.0\"\r\n```\r\n\r\nI think the latest helm chart version is 0.18.4", "Fixed to 0.18.4", "The docs recommend `1.22.6-eksbuild.1` https://docs.aws.amazon.com/eks/latest/userguide/managing-kube-proxy.html", "Thx! fixed", "are we sure nothing depends on this?", "or does it default to \"disabled\" anyway?", "It might be more robust to have this be a bool, then use a ternary to choose one of the two valid strings..\r\n\r\ni.e.\r\n\r\n```hcl\r\nhttp_tokens  = var.nodes_metadata_http_tokens ? \"required\", \"optional\"\r\n```\r\n", "If we did that then the name should be something more like `require_instance_metadata_tokens`", "`instance_metadata_tags      = \"disabled\"`.  Is the default option:\r\nhttps://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/launch_template\r\nis a new feature of  Jan 6, 2022 so very likely no cluster uses it, because in the EKS module there is no refference to this variable:\r\nhttps://aws.amazon.com/about-aws/whats-new/2022/01/instance-tags-amazon-ec2-instance-metadata-service/\r\n\r\nWDYT @errm ?", "sorted out", "OK makes sense... I didn't know it was a very new feature ...", "Also need to remove the corresponding `module \"aws_ebs_csi_driver\"` from this file", "Removed from this PR everything regarding this addon EBS-CSI, i'll add it in different PR", "I think there's going to be a deployment challenge here as the old AWS provider constraint was `~> 3.49` and the new one is `~>4.17`. These two constraints are incompatible so we won't be able to upgrade some clusters to this module version and not others within a single project? \ud83d\ude2d", "Might we be able to change the older 1.21-rc module to `>=3.49` so there's at least a pathway? That seems risky too, though, as that's allowing future major version bumps even beyond 4. Might need an upper constraint too (if that's possible)?", "```suggestion\r\n  service_account_role_arn = local.aws_ebs_csi_driver_iam_role_arn\r\n```\r\n\r\nOtherwise this will fail when `var.aws_ebs_csi_driver_iam_role_arn` is set.", "`var.aws_ebs_csi_driver` sets if this ebs driver should be used, or if we default to the in tree one, either we need to make the addon conditional on this, or remove the ability to choose which driver is used.", "we can add an upper constraint:\r\n\r\nLets do this:\r\n\r\n* for 1.22 change the constraint to: `>= 3.49.0, < 5.0.0`\r\n* Add something to release notes saying that for 1.22 we support provider versions 3 and 4 (but 4 is recommended) and that 1.23 will drop support for 3.\r\n* We will have to be careful not to use any features only available in provider v4 in the 1.22 release and should do some manual validation of the rc against both versions of the provider - but keep the automated tests running against v4.", "@jportasa - this might be a big / tricky enough topic that it makes sense to extract this provider version stuff to a separate PR - as this would make it easier to cherry-pick a commit onto 1.21 if we decide that that is needed?", "changed, thx", "fixed.  Use of CSI is optional, but if chosen to use it, should use the EKS addon.", "fixed"]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/306", "comments": ["In theory we should be able to switch to using the `aws_eks_addon` resource for `kube-proxy` now.\r\n\r\nWe couldn't before as there was an issue that prevented prometheus from scraping metrics from `kube-proxy` - perhaps we should add a test that this could be done..."]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/298", "comments": ["Maybe add a note about not requiring the nvidia device plugin when using bottlerocket+gpu because the AMIs come with the device plugin? ", "Or update the daemonset in the module [to satisfy](https://github.com/bottlerocket-os/bottlerocket/blob/develop/QUICKSTART-EKS.md#aws-k8s--nvidia-variants):\r\n\r\n> If you already have a daemonset for the device plugin in your cluster, you may need to use taints and tolerations to keep it from running on Bottlerocket nodes.\r\n\r\n?\r\n", "Yeah. Good call - I suspect there's very limited use-cases for people to be running both bottlerocket and not-bottlerocket gpu nodes, but let's cater for that.", "Hmm... I think we're actually set for this, but now I'm not sure where the nvidia-device-plugin is actually supposed to run.\r\n\r\nhttps://github.com/cookpad/terraform-aws-eks/blob/c39fd8600f2a67bb019ed657da5112315dfdbbf1/modules/asg_node_group/main.tf#L24\r\n\r\nhttps://github.com/cookpad/terraform-aws-eks/blob/c39fd8600f2a67bb019ed657da5112315dfdbbf1/modules/cluster/addons/nvidia-device-plugin.yaml#L77-L79", "Mm I think we're not set for \r\n\r\n> If you already have a daemonset for the device plugin in your cluster, you may need to use taints and tolerations to keep it from running on Bottlerocket nodes.\r\n\r\nI think with the current change we'll tag both bottlerocket and non-bottlerocket nodes with `{ \"nvidia.com/gpu\" = \"true\" }`\r\nhttps://github.com/cookpad/terraform-aws-eks/blob/c39fd8600f2a67bb019ed657da5112315dfdbbf1/modules/asg_node_group/main.tf#L24\r\n\r\nBut we need to tag bottlerocket nodes with something else to prevent the nvidia device plugin scheduling there with the current toleration ", "@ettiee isn't that what the `NoSchedule` effect does?", "Oh, I think I get it. It's a toleration for the corresponding taint. ", "yup and we don't want a toleration for the nvidia plugin on bottlerocket gpu nodes (to solve the recommendation from bottlerocket of not scheduling the driver on bottlerocket nodes)", "hm, I suspect the simplest thing to do would be to add a further label to tag it as a bottlerocket node, and re-jig the nodeSelector.", "\ud83d\udc4d sounds good", "I think that https://github.com/cookpad/terraform-aws-eks/pull/298/files#diff-571d8d76bc35ff080312258572db903f8fcb59a504d6d7491112722634c42a5b should do the trick."]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/264", "comments": ["I'm thinking better categorizations \ud83d\udcdd ", "\u267b\ufe0f https://github.com/cookpad/terraform-aws-eks/pull/264/commits/01ec4f3c6cdb29b13b97a4ea7b4d3ea236137ea6\r\n\r\nIMO, it's personal preference. If we need better categorizations, let's update the template.", "```suggestion\r\nWe use GitHub's [automated release note](https://docs.github.com/en/repositories/releasing-projects-on-github/automatically-generated-release-notes) feature to generate release notes for this module. Please follow the steps below to enforce our release policies described in this page.\r\n```", "```\r\n* Review the pull requests merged since the last release, and ensure all required labels have been applied \r\n```\r\n\r\nSomething like this? I think it's useful to have a piece of documentation for the person running the release ", "```suggestion\r\n\t\tfmt.Sprintf(\"%s/releases/new?tag=%s&target=%s&title=%s&prerelease=%s\", repositoryURL, tag, target, strings.Replace(title, \" \", \"%20\", -1), preRelease),\r\n```\r\nThis resolved the issue I had on my machine and populates the release title as expected", "Suggest you const the expressions, and compile the regexps where you use them, rather than declare globals. ", "Probably should be a const (if nothing else, to stop it being buried this far down into the code).", "```\r\nurl, err := url.Parse( fmt.Sprintf(\"%s/releases/new\", repositoryURL))\r\n...\r\nq := url.Query()\r\nq.Add(\"tag\", tag)\r\n...\r\nu.RawQuery = q.Encode()\r\n```\r\n\r\n(and then you don't need to worry about https://github.com/cookpad/terraform-aws-eks/pull/264/files#diff-b2e438117526510a85bf4b119d773c8c48941505d8dc1ccce5a244f59180b754R86-R89)", "good suggestion!", "\u267b\ufe0f  https://github.com/cookpad/terraform-aws-eks/pull/264/commits/e51a3af22f2cc1d885c7504afe076cd76400e52e", "\u267b\ufe0f https://github.com/cookpad/terraform-aws-eks/pull/264/commits/7f98d7fb73098170c7b5bf821250978f80cca3f9", "@aidy thanks! Your suggestion produces the following outputs\r\n\r\n```\r\n https://github.com/cookpad/terraform-aws-eks/releases/new?tag=1.19.2&target=release-1-19&title=Release+1.19.2&prerelease=false\r\n```\r\n\r\nin the URL white space becomes `+` which I don't expect as an URL encoding. I'd rather choose a percent encoding since this is not the URL generated by forms. If we are fine to use `+`, \r\n\r\n```\r\n\turl, err := url.Parse(\r\n\t\tfmt.Sprintf(\"%s/releases/new?tag=%s&target=%s&title=%s&prerelease=%s\", repositoryURL, tag, target, url.QueryEscape(title), preRelease),\r\n\t)\r\n```\r\n\r\nis also alternative. Do you have ideas to achieve the percent encoding for white spaces?", "\ud83e\udd14 The `+` encoding works when I click the link so \ud83e\udd37 I guess it is OK if it makes the code simple!", "sounds reasonable! \u267b\ufe0f  https://github.com/cookpad/terraform-aws-eks/pull/264/commits/0e69b952bf107bb725b8c2ad54a38f20aaed6ee8"]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/263", "comments": ["Might want to add -recursive here", "also this action now won\u2019t need the github token in the environment ", "Ah, yes - good call.", "Spotted that this doesn't line up with https://github.com/cookpad/terraform-aws-eks/blob/main/.terraform-version\r\nCould we improve this by reading that file to an environment variable to use in `terraform_version` ? Would be nice to only define it in 1 place in the project", "Yes - we should do something to have them be in sync.\r\n\r\nNot here though - keeping it as 0.12.24 so it's an atomic change."]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/261", "comments": ["aws provider?", "This error message might not be intuitive to some users - maybe give some indication of what variable to change to not hit the error?\r\nE.g. update name variable\r\nmaybe throw contents of node_group_label too so they can inspect", "Maybe covered by https://github.com/cookpad/terraform-aws-eks/pull/261/files#r750337723 already (and vice versa). This validation is more intuitive to a user ", "Yeah, I had some conflict about what to do here - the general style of tf errors seems to be to just state the error, rather than suggested resolutions.\r\n\r\nI *think* the tf philosophy is that it's not supposed to be a black box, and it's intended to be inspected, but you're probably right, and it's better to be more verbose, even if that's not in keeping with the style of other errors.", "The vice versa doesn't apply, as if this isn't present, the label is calculated.\r\n\r\nAlthough this is redundant, it seemed more user friendly to duplicate it here. Also, I think the native tf validation fail is nicer.", "not sure what this means", "Got it. "]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/257", "comments": ["nits: add descriptions \ud83d\udcdd "]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/249", "comments": ["Let's use the [latest Go version](https://github.com/actions/go-versions/blob/main/versions-manifest.json#L3) since our [CI also installs the version](https://github.com/cookpad/terraform-aws-eks/blob/6646f5f1214c750f5fd4c3bdac867caf128b6db2/.github/actions/terratest/Dockerfile#L11).\r\n\r\n```suggestion\r\n          go-version: 1.17.2\r\n```", "`go install` is used for binary installations and not for package installations.\r\n\r\n```suggestion\r\n          go get ./...\r\n```", "`ioutil` package is [deprecated in Go 1.16](https://pkg.go.dev/io/ioutil#ReadDir). I know you specified Go 1.15 in CI but I don't think we have reasons to use the old version.\r\n\r\n```suggestion\r\n\taddonFiles, err := os.ReadDir(addonsPath)\r\n```", "```suggestion\r\n\t\t\tcrds, err := readManifest(addonsPath + fileName)\r\n\t\t\tif err != nil {\r\n\t\t\t    // do something for error handling\r\n\t\t\t    // e.g\r\n\t\t\t    // t.Fatalf(\"err=%#v\\n\" , err)\r\n\t\t\t}\r\n```", "Let's return errors and handle them in test code.\r\n\r\n```suggestion\r\nfunc readManifest(filename string) ([]parsedCRD, error) {\r\n```", "```suggestion\r\n\t\treturn nil, err\r\n```", "```suggestion\r\n\treturn crds, nil\r\n```", "Why don't you have general `if err != nil {}`? The current code can capture `io.EOF` but cannot catch other errors.", "Also could you leave `Makefile` to automate these steps for local tests?", "yeah sure thing", "Consider breaking these out into their own types, rather than nesting. More idiomatic.", "Consider something like\r\n```\r\nif v.Metadata.Annotations.EksAmazonawsComRoleArn != \"\" {\r\n  assert.True(t, v.Metadata.Annotations.Eks..., fmt.Sprintf(\"%s should be true, ...))\r\n}\r\n```\r\nMakes it a little more obvious what you're actually testing for, imo.\r\n\r\n```", "The project was using 1.15 before https://github.com/cookpad/terraform-aws-eks/blob/main/test/go.mod#L3\r\nHappy to upgrade to 1.17 \ud83d\udc4d  ", "Hm, I think the implementation here is trying to parse every yaml entity as a crd, so errors are expected for the not-crds.\r\n\r\nThat said, would this condition ever fire? I think the `== nil { continue }` would win.", "defer f.Close() ?", "I think you need to re-goimports this", "I don't think you need to double bag this\r\n\r\nhttps://github.com/cookpad/terraform-aws-eks/pull/249/files#diff-b1a079e8d2b72d05971b0c6d094ba1f8adc1ee7528e4f3ae70da8c4aec63294fR68", "I think you could specify the type as bool.\r\n\r\nIf not, assert.Equal()", "By that, I mean, you populated crds with only things that had a Kind of ServiceAccount, I don't think you need to filter here.", "Oh, it's a literal string, not a yaml bool.\r\n\r\nyeah - `assert.Equal()`", "this condition fires when all elements in the yaml file have been parsed, so if we remove this we get an infinite loop\r\n\r\nI think this will cover the questions?\r\n\r\n```\r\n\t\tif errors.Is(err, io.EOF) {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n```", "Why doesn't `if &crd == nil { continue }` win? If we've reached the end of the file, I'd expect that we would not got a crd populated.", "Oh! Because it's *never* nil, because it's a defined variable which you're taking a reference from.", "So maybe...\r\n```\r\nif errors.Is(err, io.EOF) {\r\n    break\r\n}\r\n\r\nif crd == parsedCRD{} {\r\n   continue\r\n}\r\n```\r\n\r\nI think your `if err != nil { return nil, err }` would not work. Because I *think* you'd get an error if the given yaml token couldn't be unmarshalled into the parsedCRD struct.", "Maybe overkill, but I'd be tempted to add a `assert.NotEqual(t, 0, len(crds))`", "Are you deliberately introducing a typo? :)", "heh no ", "I pulled this back out - it's a valid usecase to read a manifest and not have any Kind ServiceAccount"]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/230", "comments": ["Another reference to master on line 41", "```suggestion\r\nand updates should be merged here via pull request. `main` should be maintained\r\n```"]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/213", "comments": ["```suggestion\r\n- github.com/kubernetes-sigs/aws-ebs-csi-driver/deploy/kubernetes/overlays/stable/?ref=release-1.0\r\n```\r\n\r\n??", "Ah thanks - spuriously placed decimal point! 8cb8814 .."]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/209", "comments": ["```suggestion\r\n  description = \"Support required for IPV6.\"\r\n```", "I am not sure the support_ipv6 == true part of this branch is appropriate...\r\n\r\nAs I understand the comment here https://github.com/aws/amazon-vpc-cni-k8s/issues/1078#issuecomment-804655593 the idea is that we can bypass some detection for v4 vs v6 if we specify 127.0.0.1...\r\n\r\nSince I don't think we are using ipv6 stack at all anywhere I am not sure how to test the behaviour ... I think it would be fine to hardcode this, and make a note in the readme that we don't currently support ipv6", ":exclamation: I don't think this is a great fix since we are allowing any host to connect under IPv4 as well. Seems like kube-proxy doesn't handle this configuration very gracefully!\r\n\r\nRegardless, since we do not use IPv6 ATM and we are not supporting it (i.e., we haven't tested it at all), can we simply drop IPv6 for now? \r\n\r\n```suggestion\r\n      bind_address = \"127.0.0.1\"\r\n```"]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/204", "comments": ["We currently (at cookpad) have the pattern of many clusters sharing a VPC, perhaps we should make this an array of cluster names?", "hmm, I'm kinda wary about this...", "It feels wrong to have certificate credentials as part of a generic deploy. Perhaps these should be tf vars or something?\r\n\r\n(If we're using this cert, I think we should change it, too)", "Yeah it doesn't feel nice - @dan-slinky-ckpd and I had a chat about this a couple of weeks ago.\r\nIt's ended up in here because the current process for including helm charts in the module is to template the chart [here](https://github.com/cookpad/terraform-aws-eks/blob/master/hack/generate_addons.sh#L14) then include the manifests. This chart generates the cert when you template https://github.com/aws/eks-charts/blob/0db3d7d464ddf8f0d7fcae8d5c77d5f7276ab216/stable/aws-load-balancer-controller/templates/webhook.yaml#L1\r\n\r\nSome discussion on the project https://github.com/aws/eks-charts/issues/347\r\n\r\nI guess there was a design choice in the way that we include helm add-ons (template + commit generated manifests) - easier to debug, don't require users to install helm \ud83e\udd14\r\n\r\nI think the solution would be to add a new command to combine the template+deploy for helm charts and use that [here](https://github.com/cookpad/terraform-aws-eks/blob/master/modules/cluster/addons.tf#L136).\r\nFor now though - this cert isn't used anywhere I think, we're terminating SSL at the load balancer - I believe the cert is using for integrating with cert manager, but we're not using cert manager with the load balancer controller.", "We can avoid the cert generation from the helm templating if we use cert-manager https://github.com/fernando-villalba/aws-load-balancer-controller/commit/668af05a45bace8457e0acce55ad2eec81abbfa5 - I think this is the cleanest solution ", "Discussed in person - will handle in a separate PR from issue https://github.com/cookpad/terraform-aws-eks/issues/205"]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/203", "comments": [":question: Shouldn't we replace this with the new label, instead of just removing it?", "Already in place: https://github.com/cookpad/terraform-aws-eks/blob/remove-deprecated-zone-label/modules/asg_node_group/main.tf#L175"]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/202", "comments": ["I don't think we should need this any more?", "Can we loose this?", "this role name is still used by [the instance profile](https://github.com/cookpad/terraform-aws-eks/blob/118ad3076872b052e6cc293ea3be500c840a9b21/modules/cluster/outputs.tf#L9-L10). Otherwise, we still need to retrieve the name using `data` sources. I will consider if I can drop the variable with another way.", "removed with https://github.com/cookpad/terraform-aws-eks/pull/202/commits/bd8756da24e4f0063b242f88f149d6c10e6dff28", "perhaps this is not always true when we pass `iam_config.node_role_arn` without the IAM module. Let me consider more \ud83e\udd14 ", "should be fine to update with a variable for [`asg_node_group`](https://github.com/cookpad/terraform-aws-eks/blob/7f79fd495912bb03243abd8af83c62b517b6af2a/modules/asg_node_group/variables.tf#L9-L9). Let me keep the change."]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/201", "comments": ["\ud83d\udcdd We support terraform >=0.12\r\nhttps://github.com/cookpad/terraform-aws-eks/blob/master/versions.tf#L2\r\nbut `depends_on` requires >=0.13"]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/200", "comments": ["Should the eks_service_policy be removed at L10, given that it's been removed as a resource ?", "No, I think we need this line. \r\n\r\nThe IAM role for an EKS control plane (a.k.a master or cluster) is still necessary with `AmazonEKSClusterPolicy` but the `AmazonEKSServicePolicy` is no more necessary. For that reason, I'd like to change the name of the IAM role.", "@takanabe Line 10, `aws_iam_role_policy_attachment.eks_service_policy` but you've removed it above. "]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/199", "comments": ["I can't find this as a flag. The only option I've seen is --delete-local-data=false ?\r\nhttps://github.com/kubernetes/kubernetes/issues/80228\r\nCan you explain what this is doing (in the PR).", "There is one PR linked in that issue\r\n\r\nhttps://github.com/kubernetes/kubernetes/pull/95076\r\n\r\nBasically, only the name of this flag is changed. What it does is unchanged. The original flag (`--delete-local-data`) seems to be misleading, that's why the new flag `--delete-emptydir-data` was introduced.", "That PR is targeting the 0.20.0 release of kubernetes, should we introduce this change with our 0.20.0 release?", "> That PR is targeting the 0.20.0 release of kubernetes, should we introduce this change with our 0.20.0 release?\r\n\r\nRight, maybe it's better to align the version with our release version.\r\n\r\nSo shall we revisit this PR when we're upgrading to v0.20.0 then?", "Yes sounds good to me, I think it's cleaner to align client with server versions "]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/195", "comments": ["should be 18->19 ?", "why downgrading nvidia-device-plugin here? rebase from master. ", "why `1.1.0` and not the current `1.1.5`? Afterall, that is the version defined in the gitRef we're getting the CRDs from below. ", "We're getting the manifests from the helm chart, but the CRDs via a kustomize base also from the helm repository. Can we not just reference the bases from https://github.com/kubernetes-sigs/aws-load-balancer-controller/tree/main/config - there currently feels a bit of a disconnect between the two so it's not obvious without poking around if both are coming from the same version.\r\n", "`bases` is deprecated.\r\n\r\n```suggestion\r\nresources:\r\n```", "```suggestion\r\n| [AWS Load Balancer Controller](https://github.com/kubernetes-sigs/aws-load-balancer-controller) | `aws_load_balancer_controller` | \u274c disabled | `aws_load_balancer_iam_role_arn` |\r\n```", "ah yes ta", "yeah that makes sense", "```suggestion\r\n  tag: v2.1.3\r\n```\r\n\r\nThis will then match `app.kubernetes.io/version`"]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/191", "comments": ["The use of the `latest` tag caught my eye here. The `latest` image tag is built from the `master` branch of https://github.com/kubernetes-sigs/aws-ebs-csi-driver/\r\n\r\nI note we're referencing the `alpha` overlay [here](https://github.com/cookpad/terraform-aws-eks/blob/master/modules/cluster/addons/kustomize/overlays/aws-ebs-csi-driver/kustomization.yaml#L4)\r\n\r\nThis includes `base` which does specify `latest`.\r\n\r\nIf we update our kustomization to use the `stable` overlay, we'll return to using the `v0.9.0` tag, as defined [here](https://github.com/kubernetes-sigs/aws-ebs-csi-driver/blob/v0.9.0/deploy/kubernetes/overlays/stable/kustomization.yaml#L7)", ">The use of the latest tag caught my eye here. \r\n\r\nYes, I have the same opinion and I don't want to use the latest tag in this module.\r\n\r\nUsing `stable` overlay is the best choice if we don't support the `alpha` feature \r\n\r\n>Starting from Kubernetes 1.17, CSI migration is supported as beta feature (alpha since 1.14). If you have persistence volumes that are created with in-tree kubernetes.io/aws-ebs plugin, you could migrate to use EBS CSI driver. To turn on the migration, set CSIMigration and CSIMigrationAWS feature gates to true for kube-controller-manager and kubelet.", "@dan-slinky-ckpd \r\n\r\n[Accroding to the official document](https://docs.aws.amazon.com/eks/latest/userguide/kubernetes-versions.html), EKS 1.17 does not support the CSI migration feature and the later version didn't say they support the feature.\r\n\r\n>EKS has not enabled the CSIMigrationAWS feature flag. This will be enabled in a future release, along with detailed migration instructions. For more info on CSI migration, see the Kubernetes blog.\r\n\r\nSo, +1 to the stable + `v0.9.0` tag. WDYT?", "\ud83d\udc4d `stable`", "when I added this to the module we were on alpha because beta didn't support volume resizing.\r\n\r\nIt would be good to check the status on that!", "Ok... volume resizing is beta since 1.16 so LGTM!"]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/190", "comments": ["Don't we want to keep using tags instead of branches?\r\n\r\n```suggestion\r\n- github.com/kubernetes-sigs/aws-ebs-csi-driver/deploy/kubernetes/overlays/alpha/?ref=v0.9.0\r\n```\r\n\r\nhttps://github.com/kubernetes-sigs/aws-ebs-csi-driver/tree/v0.9.0"]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/189", "comments": ["In SemVer language: the version number that gets bumped each quarter is the minor version.\r\n\r\nIMO minor versions should aim to be stable, so we should only release new patch versions for:\r\n\r\n* Security related patches\r\n* Patches for bugs that make a release unusable\r\n\r\n```suggestion\r\nWe will continue to support the latest 3 minor EKS versions. Security fixes will be back-ported and released on as a new patch version. Other major bugs may be back-ported based on user demand.\r\n```\r\n\r\nIn the past I spent a lot of time back-porting too many things, and it's mostly just painful, and having a lot of change on minor versions is something we want to avoid anyway for stability... lets try to enhance on new minor versions only!\r\n\r\n", "```suggestion\r\nAWS release a new minor version of EKS approximately once per quarter (see the [EKS Kubernetes release calendar](https://docs.aws.amazon.com/eks/latest/userguide/kubernetes-versions.html#kubernetes-release-calendar)). We aim to release a new stable minor version of `terraform-aws-eks` within one month of the upstream EKS release.\r\n```"]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/179", "comments": ["Patched addition from [default config](https://github.com/aquasecurity/kube-bench/blob/main/cfg/config.yaml)", "Patched addition from [default config](https://github.com/aquasecurity/kube-bench/blob/main/cfg/config.yaml)", "Patched addition from [default config](https://github.com/aquasecurity/kube-bench/blob/main/cfg/config.yaml)", "Removed `/var/lib/kube-proxy/config.conf` from [default config](https://github.com/aquasecurity/kube-bench/blob/main/cfg/config.yaml#L163)", "As per https://github.com/aquasecurity/kube-bench/pull/809/files", "@aidy why was this line removed? (I'm working on the assumption that this patch is based off https://github.com/aquasecurity/kube-bench/pull/809/files)", "Not removed - but only added to kube-bench master 5 hours ago! https://github.com/aquasecurity/kube-bench/pull/820", "Ah yes! \ud83d\udca1 "]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/173", "comments": ["I can see this has been superseded by https://github.com/hashicorp/setup-terraform as well \u270d\ufe0f perhaps some more cleanup in another task"]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/150", "comments": ["Perhaps we should drop the `\"node\"` argument and let all kube-bench run on all `eks-1.0` targets? https://github.com/aquasecurity/kube-bench#running-kube-bench \r\nIs there any reason to run this against nodes only?\r\n```suggestion\r\n          command: [\"kube-bench\", \"--benchmark\", \"eks-1.0\", \"--json\"]\r\n```", "kube-bench has to run on the node that it is testing, on EKS we can't schedule workloads to run on the masters since they are managed.\r\n\r\nAlso as users of EKS we have to trust AWS to keep the control plane secure.\r\n\r\nThe manifest here is very closely based on https://github.com/aquasecurity/kube-bench/blob/master/job-eks.yaml and the instructions here https://github.com/aquasecurity/kube-bench#running-in-an-eks-cluster\r\n\r\nThe only difference is that I don't feel it is necessary to build our own container and push it to a ECR repo, since it will only ever be run on an isolated test cluster.", "The `eks-1.0` CIS Benchmark does not run on the masters, please check the table here: https://github.com/aquasecurity/kube-bench#running-kube-bench . It targets controlplane, node, policies and managedservices; it does not target master nodes nor etcd.", "Right... we are not specifying the `--targets` flag here, so the command we run will run the benchmarks for that list.\r\n\r\nThe sub command node, just lets kubebench know that it is running on a node, rather than a master.\r\n\r\nIf we run this command:\r\n\r\n`[\"kube-bench\", \"--benchmark\", \"eks-1.0\", \"--json\"]`\r\n\r\nEverything works, but we get the following warnings in the log output:\r\n\r\n```\r\nW1007 12:31:31.906369   23804 util.go:96]\r\nUnable to detect running programs for component \"apiserver\"\r\nThe following \"master node\" programs have been searched, but none of them have been found:\r\n\t- kube-apiserver\r\n\t- hyperkube apiserver\r\n\t- hyperkube kube-apiserver\r\n\t- apiserver\r\n\r\n\r\nThese program names are provided in the config.yaml, section 'master.apiserver.bins'\r\n```\r\nIt looks like running kube-bench in this way generates a lot of \"Not Scored\" results, this means that the checks couldn't run, or are manual!\r\n\r\nI am fairly sure this is the correct way to check the node configuration https://github.com/aquasecurity/kube-bench#running-in-an-eks-cluster", "I understand now, thank you! :bow: "]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/145", "comments": ["```suggestion\r\n\u26a0\ufe0f Bottlerocket does not yet [support GPU nodes](https://github.com/bottlerocket-os/bottlerocket/issues/769), do not set `gpu = true` when `bottlerocket = true`, as this may result in an invalid configuration!\r\n```"]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/121", "comments": ["I think `--metrics-bind-address` needs the port too, so `--metrics-bind-address=0.0.0.0:10249`\r\n\r\nhttps://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/kube-proxy/config/v1alpha1/types.go#L117"]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/119", "comments": ["I don't think that we want to set desired_capacity.\r\n\r\ncluster_autoscaler is responsible for setting this.\r\n\r\nIf cluster_autoscaler increases this value then we run terraform we could cause unexpected scale in!"]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/117", "comments": ["I think this needs a more specific name:\r\n```suggestion\r\nvariable \"cluster_autoscaler_iam_permissions_boundary\" {\r\n```"]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/110", "comments": ["Why are we defining this value, given that we're using the default value anyway? https://github.com/aws/amazon-vpc-cni-k8s/blob/501ca48d682670c45e8303c631cec8e178db6c89/pkg/networkutils/network.go#L935\r\n\r\nMaybe it would be better to have us use the default value, which presumably would be the recommended value for what is the most common setup (linux, amd64) for this tool?", "I think setting the default here is OK ... it makes it more explicit so we can see what it is without checking the sourcecode.\r\n\r\nAlso it's best not to change the yaml from the upstream if we can help it ... it makes updates simpler!", "Oh I didn't realize this was the upstream manifest. Cool let's keep it. :smiley: "]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/107", "comments": ["Really just a nit but unless for some reason the current regex is more efficient than the following, I'd suggest we'd use this instead, since it is a more common \"idiom\" and a bit easier to parse.\r\n```suggestion\r\n            - --collector.filesystem.ignored-mount-points=^/(dev|var/lib/docker|proc|sys|var/lib/kubelet)/?$\r\n```", "Oh I guess I was too slow!... :sweat: ", "noted ...", "I don't think that's what we want here. It doesn't match for example a mount point like /var/lib/kubelet/pods/path/to/volume.", "It would match the exact same thing it is matching currently AFAIK. I see what you mean though, but if you're ignoring `/var/lib/kubelet`, which is covered by the regex, wouldn't your example be ignored as well implicitly? ", "The current regular expression lets us ignore a mount point like `/var/lib/kubelet/pods/path/to/volum`, but your regular expression doesn't. It only matches `/var/lib/kubelet` or `/var/lib/kubelet/`, which are probably not even mount points.", "Oh I see the misunderstanding here, this `collector.filesystem.ignored-mount-points` option does not enforce the resulting string to be the full path of the mount, so if there is no string termination it will match anything that could be appended to the path. Got it."]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/99", "comments": ["Aren't these two resources redundant? They both enable comm from the control plane to the nodes and the first allows all protocols instead of just TCP. It feels like the second one should be removed. Am I missing something? Thanks. :bow: ", "yes you are correct."]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/95", "comments": ["It would be nice to provide this as an actual script, to ease migration and reduce errors.", "I'm not sure I understood the wording here, is this what you mean? \r\n```suggestion\r\n  description = \"Should we create security groups for the cluster and nodes (rather than using the cluster security group). **If changed after provisioning, it forces the cluster to be recreated**\"\r\n```\r\nIs it easier to understand like this?", "Good idea!", "agreed this is pretty lousy ... hopefully this is a little better!"]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/88", "comments": ["I set this to default as `true` since it doesn't seem to cause any harm to try and run on a non-gpu node.\r\n\r\nBut it kindof ties into https://github.com/cookpad/terraform-aws-eks/issues/87#issuecomment-615109193 perhaps we should default stuff like this to false...\r\n\r\nAlternatively perhaps we should just add a label to target the DaemonSet to gpu nodes \ud83e\udd14 ", "I went down the nodeSlector route!"]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/80", "comments": ["nit: `-m` implies `-a`\r\n\r\n```suggestion\r\ngit tag v<major>.<minor>.<patch> -m \"Version <major>.<minor>.<patch>\"\r\n```", "I guess this command results in an error.\r\n\r\n```suggestion\r\ngit checkout release-<major>-<minor>\r\n```\r\n\r\nor maybe we skip `git checkout`:\r\n\r\n```suggestion\r\ngit tag -m \"Version <major>.<minor>.<patch>\" v<major>.<minor>.<patch> origin/release-<major>-<minor>\r\n```"]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/77", "comments": ["Wasn't this same function used elsewhere to provision some other services? :thinking: ", "Oh I see what you did here, no breaking changes. :ok_hand: "]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/73", "comments": ["```suggestion\r\n* Prepares the auto scaling group(s) to be scaled by the cluster autoscaler.\r\n```", "```suggestion\r\nintra-cluster communication between pods running on the cluster.\r\n```", "```suggestion\r\neach node to the cluster, via the eks bootstrap script, as well as setting the\r\n```"]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/68", "comments": ["What? :sob: Is terraform trying to interpolate that?..", "no the shell ..."]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/62", "comments": ["This logic seems to be setting a default value for the `command_template` variable. Why can't we set the default value of `${path.module}/command.sh` to that variable instead of having this ternary expression?", "Unfortunately you can't make function calls in a variable default ... \ud83e\udd14 perhaps if we just passed the path to a file... ", "> Unfortunately you can't make function calls in a variable default ... thinking perhaps if we just passed the path to a file...\r\n\r\nI think that would be great. :smile: "]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/51", "comments": ["Under what circumstances will the value be zero length ?", "If you don't set the variable and it gets defaulted to `\"\"` https://github.com/cookpad/terraform-aws-eks/pull/51/files#diff-76496b08ca6fb0459f794a35dd92d389R103", "This is just a test showing that we can write and retrieve/validate secrets ? No validation of the encryption setup here - is that correct ?", "Yes correct ... The intention of this test is to check that enabling encryption didn't break the behaviour of secrets.\r\n\r\nThe blog post did mention a way that you could look though some logs and check that KMS got called ... but I think that this sort of internal poking around is not a good test (we want to test behaviour, not implementation) I think it's OK to assume that AWS have there own tests for this functionallity!"]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/48", "comments": ["What's the meaning of the double slash in this context ?", "It's just how you reference submodules that are hosted on Terraform Registry ...\r\n\r\nSee https://registry.terraform.io/modules/errm/test/aws/0.0.3/submodules/cheese as an example!", "https://www.terraform.io/docs/modules/sources.html#modules-in-package-sub-directories"]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/47", "comments": ["```suggestion\r\nthe cluster module's `vpc_config` variable.\r\n```", "```suggestion\r\nThis module provisions an AWS VPC network that can be used to run EKS clusters.\r\n```", "```suggestion\r\nIn order to run an EKS cluster you must create subnets in at least 3 availability\r\n```"]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/45", "comments": ["I think we can infer the device path through the instance generation.", "We don't need to because:\r\n> Amazon Linux also creates a symbolic link from the device name in the block device mapping (for example, /dev/sdf), to the NVMe device name.\r\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/nvme-ebs-volumes.html", "Oh nice that's good to know! :bowing_man: "]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/33", "comments": ["I'm starting to feel that we're doing too many of these shelled-out destructive actions, which are somewhat dangerous, just for ensuring that tests are passing and cleaning-up after themselves. I don't think that testing should be making our code more brittle, much on the contrary.\r\n\r\nOne other approach we could take for cleaning these up is tagging the resources that we know are problematic on the destruction phase with a well known tag (`Name: destroy, Value: true` or something like that) and have a Jenkins job or some other cronjob running periodically and cleaning all resources with that tag. ", "Currently I am treating that the module can be removed from a terraform configuration (thus cleaning up the resources used by the cluster it is managing) as a feature.\r\n\r\nIf we don't think that cleanup is an important feature of the module... then we could I think stop testing the behaviour of `terraform destroy`.\r\n\r\nWe would still need to cleanup after ourselves but that could a process like:\r\n\r\n- `terraform destroy` (this might fail)\r\n- run a cleanup script\r\n- `terraform destroy --refresh=false` (this should not)", "also this is a \ud83d\udc1b ", "I can't even tell if there's a bug on it or not! :laughing: But I think it could be improved by using the `aws_arn` data.", "> Currently I am treating that the module can be removed from a terraform configuration (thus cleaning up the resources used by the cluster it is managing) as a feature.\r\n\r\nSorry I don't understand how that would work. This action is only executed when you run an explicit `terraform destroy`, right? :thinking: \r\n\r\n> If we don't think that cleanup is an important feature of the module... then we could I think stop testing the behaviour of `terraform destroy`.\r\n> \r\n> We would still need to cleanup after ourselves but that could a process like:\r\n> \r\n>     * `terraform destroy` (this might fail)\r\n> \r\n>     * run a cleanup script\r\n> \r\n>     * `terraform destroy --refresh=false` (this should not)\r\n\r\nClean-up is definitely important, but we can achieve it in several different manners, and if doing it \"online\" is too much of an hassle, we can differ it to some sort of cronjob.", "The bug was `s/delete-security-group/delete-network-interface/` it's fixed now on master ...", "> Sorry I don't understand how that would work. This action is only executed when you run an explicit terraform destroy, right? \ud83e\udd14\r\n\r\nYeah I think you are correct:\r\n\r\n> Destroy-time provisioners can only run if they remain in the configuration at the time a resource is destroyed. If a resource block with a destroy-time provisioner is removed entirely from the configuration, its provisioner configurations are removed along with it and thus the destroy provisioner won't run. \r\nhttps://www.terraform.io/docs/provisioners/index.html#destroy-time-provisioners\r\n\r\nThere is a work around ... but it basically means you have to set `count = 0` on the resource where you want the provisioner to run... see also https://github.com/hashicorp/terraform/issues/13549", "My understanding is that terraform configuration should always reflect the desired infrastructure (that is, it is declarative). AFAIK, there's no way to declare something that should not exist though. For that reason, the way do achieve what you intended is:\r\n\r\n1. Keep the code as-is.\r\n1. Open a PR removing the configuration that represents the infrastructure you want to remove.\r\n1. Get approval.\r\n1. Run `terraform destroy`.\r\n1. Merge PR.\r\n\r\nIt would be much nicer to have some sort of `terraform converge` command that could be ran after removing some configuration but again AFAIK that is not possible. :disappointed: ", "I opened a new issue to track these kinds of thing:\r\n\r\nhttps://github.com/cookpad/terraform-aws-eks/issues/37\r\n\r\nBasically this is a limitation of terraform.", "At the moment, if feels like a design choice and not a limitation, so I wouldn't hold my breath on that being changed. :disappointed: "]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/24", "comments": ["Can't we use `depends_on` on the `control_plane` on whatever resource is failing with the error you mention in the PR's description?", "Unfortunately not... the AWS EKS api sometimes reports that the resource is ready a short time (usually no more than a few seconds) before the API begins to receive traffic.\r\n\r\nI think the dependency already works properly... we just need to delay it a little somehow, sometimes."]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/15", "comments": ["I think I get what's going on here with the `list` and `dict` mergers after reading this: https://cloudinit.readthedocs.io/en/latest/topics/merging.html \r\n\r\nI do not understand the `str` one though. Why do we pass it if we don't define any special behaviour to it? It is my understanding that the purpose of this options is to configure the behaviour of each merger, and not to enabled them per-se; my understanding might be wrong though.", "Yeah I think the `str()` is non functional ... I just copy pasted this from somewhere...", "> Yeah I think the `str()` is non functional ... I just copy pasted this from somewhere...\r\n\r\nhttps://effectivesoftwaredesign.files.wordpress.com/2016/05/copying_and_pasting.jpg :smile: \r\n\r\nIn all seriousness now:\r\n\r\n> This tells cloud-init that when it encounters a list it should append the new one to the old, when it encounters a list inside a dictionary it should use the previous list rule, and **when it encounters a string it should use the default behaviour (replace the old value)**.\r\n\r\nFrom https://ash.berlintaylor.com/writings/2017/08/reusable-terraform-modules-extending-userdata/\r\n\r\nThis is what we want I think, i.e., if a value is already present on the existing cloud-init config, the one passed in this module will override it."]}, {"url": "https://github.com/cookpad/terraform-aws-eks/pull/12", "comments": ["Is 100% a value that makes sense universally or should we add it to a variable? YAGNI is also a valid answer. :smiley: ", "Nit-pick: single quotes on the valid values are misplaced on the first value and missing on the second.", "~~This should removed or at least added to a variable, defaulting to `false,` right?~~\r\nNevermind, this is just a test example. :man_facepalming: ", "For compatibility with the cluster autoscaler we want to be certain if a particular asg will launch an on-demand or spot instance.\r\n\r\nThe supported way to have both on_demand and spot instances will be to use this module twice ... once with each setting (thus creating 2 ASG (per az))", "\ud83d\udc4d ", "What does this `version` field defines? I can't find it on the docs: https://www.terraform.io/docs/providers/kubernetes/index.html#argument-reference", ":+1: ", "The version of the kubernetes provider ... version is a standard field on all providers..."]}]}, {"url": "https://github.com/web3-storage/ipfs-elastic-provider-infrastructure.git", "pull_requests": [{"url": "https://github.com/elastic-ipfs/infrastructure/pull/199", "comments": ["There is a new context object that provides this we could make use of instead of making a REST call", "Done! "]}, {"url": "https://github.com/elastic-ipfs/infrastructure/pull/193", "comments": ["will need to add this to `prod.tfvars` in order to take effect", "@blucas that's not true, prod.tfvars isn't overriding `storage_bucket_names`", "This branch is out of date with `main`. `prod.tfvars` _is_ overriding `storage_bucket_names`"]}, {"url": "https://github.com/elastic-ipfs/infrastructure/pull/190", "comments": ["We could call it `s3_policy_read` now, because it's no longer strongly attached with dotstorage.\r\nThat would require state mv", "```suggestion\r\nsns_topic_trigger_names = [\r\n```", "I'll leave this out for now.  Its a larger task than just this one resource.  `dotstorage` is used in multiple places, and we should have a cleanup task to resolve it."]}, {"url": "https://github.com/elastic-ipfs/infrastructure/pull/182", "comments": ["Assumes topic is in same account. May just want to call that out", "Could you check to see what, if any, difference there is with this versus `for_each = toset(var.sns_topic_trigger_arns)`", "Could you check to see what, if any, difference there is with this versus `for_each = toset(var.sns_topic_trigger_arns)`", "If my comment above works, might consider making this a `set`", "Should this lambda be able to receive messages from other account topics?\r\nThat makes me think about the region as well... It used to make sense having one \"bucket-to-indexer-lambda\" per region/account when it was triggered directly by a bucket event. \r\n\r\nNow that it comes from multiple SNS sources, we could always use the same lambda...", "toset is better here. This complex structure only makes sense when handling object properties."]}, {"url": "https://github.com/elastic-ipfs/infrastructure/pull/173", "comments": ["Move roles, policies and attachments to \"auth.tf\"", "Put this file inside a /helm folder", "We used to have [kube-prometheus-stack](https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack). Is the change intentional?", "yes, this chart has grafana and operator on it."]}, {"url": "https://github.com/elastic-ipfs/infrastructure/pull/172", "comments": ["Change description to test or autocannon", "There is no need to clone this repo. What we need is a way of making the [actual test code](https://github.com/elastic-ipfs/bitswap-peer/tree/refactor/aws-client/test/e2e) to run inside this machine. Should we copy and run a script to start it (like I've done in bucket mirror) or create a workflow that delivers it somehow?", "Remove this", "Description changed", "Clone removed", "removed", "I think docs need to be updated. Mixing \"-\" and \"_\"", "We're not copying the code with shell (like bucket to mirror), so there's no need for this disclaimer", "let's use \"t3\"", "Aha! Found a \"bucket mirror\" wondering in wrong places :sweat_smile: ", "Done", "Sure thing, changed.", "Haha! Thanks, fixed!", "Removed!"]}, {"url": "https://github.com/elastic-ipfs/infrastructure/pull/171", "comments": ["Just curious, is this runner script using IMDSv2?", "`terraform fmt` this?", "Just curious, is there a way to \"clean up\" these advertisements?  I assume after storetheindex picks these up, they can be removed.  I'm wondering if we can save costs here.", "`terraform fmt`", "Done", "Done", "AFAIK we have to keep the entire chain. IMO that makes sense in case they want/need to replay all events.", "I'll tell you in slack for security reasons :smile: "]}, {"url": "https://github.com/elastic-ipfs/infrastructure/pull/170", "comments": ["I'm on the fence about this.  Should we enable global exclusions, or be specific and specify these exclusions at a per-resource level?  I know the latter is more work.  I'm concerned that if we turn it off globally and introduce something which may be eligible for encryption we will end up missing out on one advantage of having these rules enabled at a global level.", "Based on what we have agreed about encryption at rest at this project phase, it will be a bad experience if we have to add new ignores every time we introduce a new queue, table, etc.", "Also, whenever this becomes important, it will also be easier to see all places that must be secured after disabling a global exclusion."]}, {"url": "https://github.com/elastic-ipfs/infrastructure/pull/168", "comments": ["Cant we get the full name from the `cloudflare_record` resource?  I'd prefer it, if we can avoid having to concat the two resources.", "Done"]}, {"url": "https://github.com/elastic-ipfs/infrastructure/pull/163", "comments": ["Do you need these block in conjunction with the declarations in `required_providers` ?\r\n\r\nAdditionally, I don't see anything in this PR that authorizes GHA to communicate with Cloudflare API.", "> Do you need these block in conjunction with the declarations in required_providers ?\r\n\r\nYes", "> Additionally, I don't see anything in this PR that authorizes GHA to communicate with Cloudflare API.\r\n\r\nI've added the required environment variables to the workflow and secrets.", "This request about updating the workflow with credentials was a good reminder of these technical debts\r\n\r\n- https://www.notion.so/Elastic-IPFS-log-868adc5d3a8f4094bf5cd0eb26679c15?p=b2c874b5b037410698a32ccd10a04e0e&pm=s\r\n- https://www.notion.so/Elastic-IPFS-log-868adc5d3a8f4094bf5cd0eb26679c15?p=bdc2847e1e1341898602df5df5c755be&pm=s", "I've tried to simply run the workflow in the self runner but that came with a bunch of other necessary improvements (Rolled back)", "I temporarily removed the failed stack to see the plan for DNS stack:\r\nhttps://github.com/elastic-ipfs/infrastructure/runs/7793501635?check_suite_focus=true  ", "> I temporarily removed the failed stack to see the plan for DNS stack: https://github.com/elastic-ipfs/infrastructure/runs/7793501635?check_suite_focus=true\r\n\r\nRemember, you should be able to create a PR comment such as \"terraspace plan dns\" to avoid having to remove the stack entirely."]}, {"url": "https://github.com/elastic-ipfs/infrastructure/pull/158", "comments": ["You might want to consider that these two resources should live outside of the `event` stack as they could be reused by other components.  If the intent is that this KMS key/alias is only meant to be used for the context of the event stack, then ignore my first statement.", "We could put that key in the shared stack to have a single key for all Elastic IPFS components, but I don't really see benefit in doing that (except having less resources to maintain and therefore reducing complexity). With the \"one key per stack\" strategy we have better decoupling and security responsibility/concern."]}, {"url": "https://github.com/elastic-ipfs/infrastructure/pull/156", "comments": ["Not sure if this is right. If possible, I want users of this module to not have to provide a value for this at all, and if none is proivded, the value should be tf `null`. If it is provided, it has to be this string value.\r\n\r\nIf it's not possible to express that.... then I probably need to update all the other uses of this `lambda-from-sqs` module to pass in `function_response_types = null`. But I didn't see any lint/plan errors that required that.... I could be missing something", "You set a value where it expects a type. The [workflow](https://github.com/elastic-ipfs/infrastructure/runs/7622729302?check_suite_focus=true) (Terraspace - All Plan Logs) shows this error:\r\n\r\n\u2502 Error: Invalid type specification\r\n\u2502 \r\n\u2502   on ../../modules/lambda-from-sqs/variables.tf line 6, in variable \"sqs_trigger\":\r\n\u2502    6:     function_response_types            = \"ReportBatchItemFailures\"\r\n\u2502 \r\n\u2502 A type specification is either a primitive type keyword (bool, number,\r\n\u2502 string) or a complex type constructor call, like list(string).", "The optional feature you tried to use is the best approach in my opinion but \" Optional object type attributes are experimental\", so it's unstable to use it right now.\r\n\r\nSo it might be better to create a different variable (primitive string) for this use case. You can achieve what you're trying to do by using the \"default\" keyword for a variable. Read this: https://www.terraform.io/language/values/variables\r\n\r\n", "That should be a list instead. Check:\r\n- https://github.com/hashicorp/terraform-provider-aws/issues/22068#issuecomment-999399168\r\n- https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/lambda_event_source_mapping\r\n\r\n", "thx. changed here https://github.com/elastic-ipfs/infrastructure/pull/156/commits/a05a0ad81d3c1f57dba1be4f3d8e267fc6020117", "@francardoso93 thanks. I added a separate variable with default https://github.com/elastic-ipfs/infrastructure/pull/156/commits/a05a0ad81d3c1f57dba1be4f3d8e267fc6020117"]}, {"url": "https://github.com/elastic-ipfs/infrastructure/pull/148", "comments": ["```suggestion\r\n    \"NODE_ENV\" = var.node_env\r\n    \"EVENT_TARGET\" = \"https://webhook.site/e3781bb4-42be-4c61-b9d1-173ad18efaed\"\r\n```", "\ud83c\udf89 ", "I've added EVENT_TARGET value for staging and prod envs in these files:\r\nterraspace/app/stacks/event/tfvars/us-west-2/staging.tfvars\r\nterraspace/app/stacks/event/tfvars/us-west-2/prod.tfvars\r\n"]}, {"url": "https://github.com/elastic-ipfs/infrastructure/pull/137", "comments": ["Remind me, how are we ensuring the name is unique across environments/regions ? ", "In order for `create_before_destroy` to operate as expected, this `resource`s name needs to be unique.  I don't see that happening here.", "v1_blocks_table = {\r\n  name     = \"<%= expansion(':ENV') %>-ep-v1-blocks\"", "Useful for migrating from one policy to a new one (with different name) without removing existing policies from roles"]}, {"url": "https://github.com/elastic-ipfs/infrastructure/pull/136", "comments": ["Add the `fluentdLambda.namespace` property"]}, {"url": "https://github.com/elastic-ipfs/infrastructure/pull/134", "comments": ["You need to give values for this variable in the `fvars` files", "I would use `base.tfvars` and follow the same structure as bitswap_peer_namespace", "Call it \"<%= expansion(':ENV') %>-logging\""]}, {"url": "https://github.com/elastic-ipfs/infrastructure/pull/124", "comments": ["Dunno if we want to trigger a TF plan each time _any_ github workflow has been modified.", "did you try this locally?  I've seen some bugs reported about this flag not operating as intended.", "Changed for triggering only when changes happened in this workflow", "It has worked both locally and in this PR run, see:\r\nhttps://github.com/ipfs-elastic-provider/ipfs-elastic-provider-infrastructure/runs/6678484234?check_suite_focus=true\r\nThe 128 ignored were from downloaded packages like EKS.\r\n"]}, {"url": "https://github.com/elastic-ipfs/infrastructure/pull/119", "comments": ["We should add a ticket to the board about the org move from `web3-storage`", "I'd hold off merging this PR until we can point it back to `HEAD`", "Don't see harm in doing it right now :) \r\nDone", "Done!"]}, {"url": "https://github.com/elastic-ipfs/infrastructure/pull/116", "comments": ["I wonder if we should expose `account_id` and `env` as standard terraform `local` references, so we don't have to mix terraspace erb with terraform interpolations.  My thought process here is... \"Try to avoid using ERB within our stack's `*.tf` files.\"\r\n\r\nThese lines would end up becoming:\r\n```hcl\r\nbucket = \"ipfs-ep-terraform-state-${local.account_id}-${var.indexing_stack_region}\"\r\nkey    = \"${var.indexing_stack_region}/${local.env}/stacks/indexing/terraform.tfstate\"\r\n```"]}, {"url": "https://github.com/elastic-ipfs/infrastructure/pull/114", "comments": ["Reverse this IF"]}, {"url": "https://github.com/elastic-ipfs/infrastructure/pull/112", "comments": ["can we avoid hardcoding the registry?", "can we avoid hardcoding the registry?", "missing whitespace in `=\"<%=`", "is this line intentional?", "We should stick to `#` for comments", "run `terraform fmt`", "can we avoid hardcoding the registry?", "can we avoid hardcoding the registry?", "Done! Made it consistent with the indexing stack.", "Done! Made it consistent with the indexing stack.", "Yes, intentional and temporary", "Done", "It doesn't work for tfvars file.. But fixed the formatting manually!", "Done", "Done! Made it consistent with the indexing stack.", "Done! Made it consistent with the indexing stack."]}, {"url": "https://github.com/elastic-ipfs/infrastructure/pull/111", "comments": ["Do we need an `example` directory under the `stack`?  The stack is the actual use case, so I don't see the point of an `example` in this context.", "Is there a reason we want to make this optional within the stack?", "Is there a reason we want to make this optional within the stack?", "lets talk about what this `for` loop ends up generating.", "do we need these trouble shooting rules anymore?", "could you add a `todo` here to investigate an alternative approach so we don't have to go through the public internet to achieve this?", "this should be configurable, at least at the env level.", "is there a reason we are only utilizing fargate in these specific availability zones?", "this is already set in the base", "shouldn't this be a string?", "similar to our previous discussion, if the stack only needs the vpc name, lets make that the variable rather than a whole object.", "should be a variable", "at least the subnets, and possibly also the booleans should be variables.", "Removed", "Removed", "Removed", "It is useful when we need to execute `traceroute` within a container, without that the command won't work.. But we can remove those and remember to add later if we need to do that again. What do you think?", "Done", "Not going to do that because VPC object is going to have new attributes based on another comments (cidr, private_subnets, etc...)", "Not going to do that because VPC object is going to have new attributes based on another comments (cidr, private_subnets, etc...)", "Done", "Done :)", "I think that when I did that I wanted to have at least one subnet available for EC2 only.. But now I don't think that make sense anymore. Let's allow Fargate to run on any private subnet", "Cluster version is now part of the EKS object. \r\nTerraspace layer functionality unfortunately doesn't work for \"mixing\" attributes of the same object that have different property values on each layer. The whole object needs to be re-specified. Even though we loose that possibility when grouping stuff I think it is worth it because keep the object consistent with the actual resource being created.", "Done", "This is no longer necessary. Removed.\r\nThis was used by Terratest so it could assert if the roles were properly created. As we're not sure about how tests are going to be structured now (or if there are going to be tests at all) I won't even bother making this 'sensitve' and just removed to hide the arn's.", "In that case, I'd have them commented out with an informational message to uncomment if you'd like to enable tracerouting.  You could make it \"smarter\" by having a `var.enable_tracerouting` to include/exclude those rules.  Given it is just for break-glass troubleshooting, I think thats overkill.", "we don't need to specify the `-var token=...` via the command line do we?", "remind me, we should look at including tflint on module changes, so that we cover items like adding `description` on variables.", "eventually, will we want to rename this nodegroup from `test-ipfs...` to something else?", "looks like that MR has been merged.  Might want to include that change here, or spin up another task to do it after we get this PR merged.", "Is this comment intentional?", "I didn't see a reference to any of these `/spec/**.yaml` files within the terraform. I could have easily missed it.  Just wanted to understand the use case and for the `/troubleshoot/` specs, are they conditional?", "are you wanting to resolve this `TODO` before the PR is merged?", "as mentioned earlier, are we going to keep this `test-ipfs-...` name or use a different name?", "`version` isn't allowed here (according to `variables.tf`)", "Not really. I prefer to do that verification in the development environment", "They really are not used in Terraform, but useful for quickly creating pods manually that can help you troubleshooting.\r\nI kept them there so it could help other team members, but if you don't see value I can remove it.", "Didn't get that.. Let's talk about this", "Ended up doing the enable_tracerouting variable! :)\r\nIt might be overkill but at least give us the flexibility of changing without affecting other environments", "No, I'm very happy that we don't! :)\r\nI wrote that nightmare there and then forgot to erase it. Done now.", "Yes that makes sense. I just wouldn't block this specific PR over that. Let's add it for next ones?", "Removed", "It has been merged a long time ago and I didn't have the time to come back to that :)\r\nI would put it in another task, but LMK if you think this is a blocker for getting this PR approved", "We can definitely use a better name than that.. I would just have some extra work migrating the states.\r\nDo you have a naming suggestion? ", "We can definitely use a better name than that.. I would just have some extra work migrating the states.\r\nDo you have a naming suggestion? ", "Correct.  No need to block this PR due to that.", "`<env>-ep-peer` or `ep-peer-<env>` - whatever our convention is currently ?", "Not a blocker.", "We don't have to block this PR for it.  I would say, if this is just for reference and not really related to terraform or terraspace, we should just put it in a subfolder under `docs/*` for \"Troubleshooting\" or something", "Done! Created an \"utils\" folder at root and moved the troubleshooting away from unrelated terraform structure.", "Done!", "Done", "Removed"]}, {"url": "https://github.com/elastic-ipfs/infrastructure/pull/110", "comments": ["From what I can tell, the stack only uses the `url` of this topic.  Is it possible to remove the `arn` and convert this variable from an `object({url, arn})` to simply `string` and rename the variable to `shared_stack_sqs_multihashes_topic_url` ?  Maybe this is overkill.", "Done!"]}, {"url": "https://github.com/elastic-ipfs/infrastructure/pull/109", "comments": ["this file can be moved up a directory.  Instead of it living in `shared/tfvars/us-west-2` it can live in `shared/tfvars`", "Done. I've also added the region prefix do the config bucket name so it's unique."]}, {"url": "https://github.com/elastic-ipfs/infrastructure/pull/108", "comments": ["Do we actually use a self-hosted runner at all?", "With the new folder structure, you'll need to remove any references to `infra-prj-a`", "as mentioned previously remove `infra-prj-a`", "as mentioned previously remove `infra-prj-a`", "as mentioned previously remove `infra-prj-a`", "as mentioned previously remove `infra-prj-a`", "as mentioned previously remove `infra-prj-a`", "as mentioned previously remove `infra-prj-a`", "This will be the last time I mention it, but you get the picture \ud83d\ude04 ", "I'm not sure you need this in the root, it makes more sense to be in `terraspace/.gitignore` no?", "Worth updating this readme in our subsequent PRs once we have our specific stacks and modules to talk about", "FYI, We most likely will not be making use of this concept.  I can explain more over chat", "Ah, you found `:MOD_NAME` well done \ud83d\ude04 .", "FYI another way to represent this is `<%= Terraspace.env %>`", "Yes! We need this for Kubernetes changes. \r\nRemember that we whitelist source IPs. ", "I know, I choose to use it like this for consistency with the other variables. \r\nIt is way easier to find docs about \"expansion\" than \"Terraspace.\"", "Agree!", "Well most projects that I see usually have .gitignore in root.. Maybe placing it anywhere else might be confusing.\r\nA newcomer might take a look at root gitignore and think that stuff is missing (Because this person didn't see that there was a second .gitignore)", "Yeah I'd keep it in root...", "Oh?  I didn't connect the dots for that one. Will pick your brain about that later.", "why nodejs?", "I wouldn't add `golang` until we actually add a `terratest`", "This file is missing a few other components that are used by the workflow files (`tfsec`, `tflint`, etc.). Please check my example branch for reference.", "My bad, I copied the wrong file instead of copying yours. Good eye! ", "there is a new version out, `0.13.3` might as well bump to it.", "`~>` and other types of constraints [are not supported](https://github.com/terraform-linters/tflint/blob/master/docs/user-guide/plugins.md#version)", "That sucks.. but done!"]}, {"url": "https://github.com/elastic-ipfs/infrastructure/pull/100", "comments": ["Suggestion: terraform.bucket-to-indexer.tfstate", "This won't be needed here", "This won't be needed here.\r\nOnly indexer lambda sends messages to notifications queue.", "The environment variable \"SQS_PUBLISHING_QUEUE_URL\" (All of those env vars acatually) is still something specific of the indexer lambda. Now that this is a generic module, we should define all environment variables from the outside and receive the complete map from the outside (map variable)", "bucket to indexer lambda uses a environment variable called SQS_INDEXER_QUEUE_URL", "File name is `ibucket-to-indexer-auto-deploy.yaml`. Is that starting \"I\" a typo?", "suggestion: bucket-to-indexer-lambda"]}, {"url": "https://github.com/elastic-ipfs/infrastructure/pull/74", "comments": ["Are we going to do this later or should it already be here?", "Does it ever go inside that IF even though you configured this workflow to run only on issue comments?", "Curiosity: Are we currently using these (and plan) logs anywhere? \r\nIs this thinking about improving the checks section in the future?", "Shared function", "later", "good spot, this isn't needed anymore", "> Are we currently using these (and plan) logs anywhere?\r\n\r\nIf I understand the question properly, we are using it to display in the console output what the detailed results of the `plan` and `up` were for each stack", "done"]}, {"url": "https://github.com/elastic-ipfs/infrastructure/pull/70", "comments": ["tfsec check aws-ecr-enable-image-scans failed. \n\nDescription: Image scanning is not enabled.\n\nSeverity: HIGH\n\nFor more information, see:\n\n- https://aquasecurity.github.io/tfsec/v1.15.0/checks/aws/ecr/enable-image-scans/\n- https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/ecr_repository#image_scanning_configuration\n", "tfsec check aws-ecr-enforce-immutable-repository failed. \n\nDescription: Repository tags are mutable.\n\nSeverity: HIGH\n\nFor more information, see:\n\n- https://aquasecurity.github.io/tfsec/v1.15.0/checks/aws/ecr/enforce-immutable-repository/\n- https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/ecr_repository\n", "tfsec check aws-ecr-repository-customer-key failed. \n\nDescription: Repository is not encrypted using KMS.\n\nSeverity: LOW\n\nFor more information, see:\n\n- https://aquasecurity.github.io/tfsec/v1.15.0/checks/aws/ecr/repository-customer-key/\n- https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/ecr_repository#encryption_configuration\n"]}, {"url": "https://github.com/elastic-ipfs/infrastructure/pull/65", "comments": ["Use SDK v3: https://github.com/aws/aws-sdk-js-v3", "Use `console.error`.", "Use SDK v3 - See other comment.", "Done", "Fixed", "Done", "Not really used to generators but I think this code looks fine.\n\nI would say just make sure the `yield` in the final iteration (not sure if it yields `[]`, `null` or `undefined`) doesn't make the `main` iteration fail."]}, {"url": "https://github.com/elastic-ipfs/infrastructure/pull/62", "comments": ["Pode remover esse metric filter tambem"]}, {"url": "https://github.com/elastic-ipfs/infrastructure/pull/61", "comments": ["This should be marked as `sensitive`", "Is there any way for us to look this up rather than pass it in?  I'd hate for it to be exposed in console somewhere", "will this be masked out properly when passed to the shared-workflow?", "Isn't this required by the `observability-grafana` root instead of the `shared-subsystem` root?", "GitHub actions doesn't print secrets when running script, it shows like: *******", "and oooops.. correcting the workflow", "Done.\r\nIt shouldn't be exposed."]}, {"url": "https://github.com/elastic-ipfs/infrastructure/pull/50", "comments": ["typo in `autoscaler`", "typo in `autoscaler`", "typo in `autoscaler`", "Is this right?", "Is there a reason for this to be `camelCase` and the other variables to be `snake_case`", "Fixed", "Fixed", "Fixed", "Fixed", "Yes.. I was able to install it in the cluster."]}, {"url": "https://github.com/elastic-ipfs/infrastructure/pull/1", "comments": ["Tip - https://terraform-docs.io can be used to generate some additional information here", "Can we add some basic tagging to our resources? `team`, `project`, `environment` perhaps?\r\n\r\nOther teams are going to be using this account also - so let's start with some decent hygiene around our stuff", "I agree! I've added these default tags as you suggested\r\n\r\n```\r\nprovider \"aws\" {\r\n  profile = \"default\"\r\n  region  = \"us-east-2\"\r\n  default_tags {\r\n    tags = {\r\n      Team        = \"NearForm\"\r\n      Project     = \"AWS-IPFS\"\r\n      Environment = \"POC\"\r\n    }\r\n  }\r\n}\r\n```", "Cool tip. I was able to create module specific documentation using that.\r\n- [api-gateway-to-s3](https://github.com/web3-storage/AWS-IPFS-Infrastructure/blob/api-gateway-to-s3/terraform/modules/api-gateway-to-s3/api-gateway-to-s3.md)\r\n- [indexing-subsystem](https://github.com/web3-storage/AWS-IPFS-Infrastructure/blob/api-gateway-to-s3/terraform/modules/indexing-subsystem/indexing-subsystem.md)\r\n", "Whenever we have a pipeline for this project, we could integrate this tool for continuous documentation update :smile: "]}]}, {"url": "https://github.com/robertlupinek/rh-ex407.git", "pull_requests": []}, {"url": "https://github.com/dmolchanov/tf-nextcloud.git", "pull_requests": []}, {"url": "https://github.com/JamesWoolfenden/terraform-aws-workspaces.git", "pull_requests": []}, {"url": "https://github.com/dtelaroli/devops-test.git", "pull_requests": []}, {"url": "https://github.com/kmarilleau/a-cloud-guru-gcp-cloud-engineer-terraform.git", "pull_requests": []}, {"url": "https://github.com/ndebuhr/cloud-native-workstation.git", "pull_requests": []}, {"url": "https://github.com/Bot-Casey/pdf_billing_generator.git", "pull_requests": []}, {"url": "https://github.com/ghoshkunal123/aws-infra-as-code.git", "pull_requests": []}, {"url": "https://github.com/keithnoguchi/do-in-action.git", "pull_requests": []}, {"url": "https://github.com/bastiandg/scaling-in-the-cloud.git", "pull_requests": []}, {"url": "https://github.com/ayltai/hknews-infrastructure.git", "pull_requests": []}, {"url": "https://github.com/AaronForce1/terraform-aws-infrastructure-eks.git", "pull_requests": []}, {"url": "https://github.com/sika-training-examples/2022-04-22--heidelbergcement--terraform-monorepo.git", "pull_requests": []}, {"url": "https://github.com/skehlet/aws-batch-processing.git", "pull_requests": []}, {"url": "https://github.com/JamesWoolfenden/terraform-azurerm-mysql.git", "pull_requests": []}, {"url": "https://github.com/ae-lexs/terraform_modules.git", "pull_requests": []}, {"url": "https://github.com/vrutkovs/okd-singlenode-on-aws.git", "pull_requests": []}]