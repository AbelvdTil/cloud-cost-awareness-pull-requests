{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45e03a43-7920-4679-a955-ed3118ef1201",
   "metadata": {},
   "source": [
    "# Pull request scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a05420a-77b4-4d26-acdd-b6ca46d0f239",
   "metadata": {},
   "source": [
    "## GitHub credentials\n",
    "A private access token is necessary to make use of less restrictive API limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18030255-77ee-4ed0-b11b-b2824e704349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated as: AbelvdTil\n"
     ]
    }
   ],
   "source": [
    "from github import RateLimitExceededException, Github\n",
    "\n",
    "# Providing access token\n",
    "access_token = \"\"\n",
    "g = Github(login_or_token=access_token)\n",
    "\n",
    "# Confirm your login is successful\n",
    "user = g.get_user()\n",
    "print(f\"Authenticated as: {user.login}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09550648-f771-420c-bfbc-d3cd7bceec95",
   "metadata": {},
   "source": [
    "## Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5be4139-d47b-42f1-b4a6-eee6d6de92a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    " \n",
    "STEP4_TFCOMMITS = os.path.join(\"data\", \"step4-tf-commits.json\") \n",
    "STEP5_TF_REPOS_WITH_PR = os.path.join(\"data\", \"step5-tf-repos-with-pr.json\")\n",
    "STEP6_TF_REPOS_COMMITS = os.path.join(\"data\", \"step6-tf-repos-commits.json\")\n",
    "STEP7_TF_REPOS_WITH_TF_PR = os.path.join(\"data\", \"step7-tf-repos-with-tf-pr.json\")\n",
    "STEP8_TF_KEYWORD_PR = os.path.join(\"data\", \"step8-tf-keyword-pr.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1dc4f3-4c41-422a-af1a-817915c2fb00",
   "metadata": {},
   "source": [
    "## File seperator and combinator\n",
    "\n",
    "Files over 100MB are not stored on GitHub, therefore we need to seperate large files into smaller ones.\n",
    "Any step5 and step7 files can be split into multiple smaller ones and be combined together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a8300a-3f1f-4b55-9c2f-319d2213d816",
   "metadata": {},
   "source": [
    "The repositories are split on pull request level. The first pull request is stored in part 1, the 2nd in part 2 etc. This will make sure that it is fairly equally distributed.\n",
    "\n",
    "Each pull request is accomodated with the url of the repository. Therefore it is possible to reconstruct the original file again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93d27ae3-61d8-444e-99e5-bfffe7e66185",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "\n",
    "FILE_TO_SEPERATE = STEP7_TF_REPOS_WITH_TF_PR\n",
    "\n",
    "nr_parts = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae8c9fe-a182-4600-bd3c-6e3fee8607a0",
   "metadata": {},
   "source": [
    "### File seperator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac6757a0-cacc-4792-87d7-3ade5ff857f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39062\n"
     ]
    }
   ],
   "source": [
    "parts_data = []\n",
    "\n",
    "for i in range(nr_parts):\n",
    "    parts_data.append([])\n",
    "\n",
    "file = open(FILE_TO_SEPERATE)\n",
    "seperator_data = json.load(file)\n",
    "\n",
    "count = 0\n",
    "for repository in seperator_data:\n",
    "    for pull_request in repository[\"pull_requests\"]:\n",
    "        part = (count % nr_parts)\n",
    "        count += 1\n",
    "        parts_data[part].append({\"repo_url\": repository[\"url\"], \"pull_request\": pull_request})\n",
    "\n",
    "for i in range(nr_parts):\n",
    "    with open(FILE_TO_SEPERATE.split(\".\")[0] + \"-part-\" + str(i+1) + \".json\", \"w\") as outfile:\n",
    "        json.dump(parts_data[i], outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98739107-471c-4478-960c-5baae19446b0",
   "metadata": {},
   "source": [
    "### File combinator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4402f5cd-318a-4fcc-a368-5624b44fa766",
   "metadata": {},
   "source": [
    "Also reverts changes in data structure \n",
    "\n",
    "From:\n",
    "\n",
    "{\n",
    "    [\n",
    "        {\n",
    "        \"url\": string,\n",
    "        \"pull_request\": { PR }\n",
    "    ]\n",
    "}\n",
    "\n",
    "To:\n",
    "\n",
    "{\n",
    "    [\n",
    "        {\n",
    "        \"url\": string,\n",
    "        \"pull_requests\": [ { PR } ]\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8823ce5d-8c0f-4d9a-9c59-f4f62c8f69aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_dict = {}\n",
    "combinator_data = []\n",
    "index_count = 0\n",
    "for part in range(nr_parts):\n",
    "    part_file = open(FILE_TO_SEPERATE.split(\".\")[0] + \"-part-\" + str(part+1) + \".json\", \"r\")\n",
    "    part_data = json.load(part_file)\n",
    "\n",
    "    for nugget in part_data:\n",
    "        # find repo using url\n",
    "        index = url_dict.get(nugget[\"repo_url\"], None)\n",
    "\n",
    "        if (index == None):\n",
    "            repo = {\"url\": nugget[\"repo_url\"], \"pull_requests\": []}\n",
    "            combinator_data.append(repo)\n",
    "            \n",
    "            url_dict[nugget[\"repo_url\"]] = index_count\n",
    "            index_count += 1\n",
    "        else:\n",
    "            repo = combinator_data[index]\n",
    "            \n",
    "        repo[\"pull_requests\"].append(nugget[\"pull_request\"])\n",
    "\n",
    "with open(FILE_TO_SEPERATE, \"w\") as outfile:\n",
    "    json.dump(combinator_data, outfile) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96031760-e0b7-4b4e-99ab-b75d1ad3ee10",
   "metadata": {},
   "source": [
    "## STEP 5: Pull request scraping script\n",
    "\n",
    "For each repository, get all pull request data. This includes PR Title, description, (review) comments and commit hashes. Exclude any repositories that do not have pull requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "492cb012-8537-42cb-8c58-3d9d45b21aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exception: 404 {\"message\": \"Not Found\", \"documentation_url\": \"https://docs.github.com/rest/repos/repos#get-a-repository\"}\n",
      "exception: 404 {\"message\": \"Not Found\", \"documentation_url\": \"https://docs.github.com/rest/repos/repos#get-a-repository\"}\n",
      "exception: 404 {\"message\": \"Not Found\", \"documentation_url\": \"https://docs.github.com/rest/repos/repos#get-a-repository\"}\n",
      "exception: 404 {\"message\": \"Not Found\", \"documentation_url\": \"https://docs.github.com/rest/repos/repos#get-a-repository\"}\n",
      "exception: 404 {\"message\": \"Not Found\", \"documentation_url\": \"https://docs.github.com/rest/repos/repos#get-a-repository\"}\n",
      "exception: 404 {\"message\": \"Not Found\", \"documentation_url\": \"https://docs.github.com/rest/repos/repos#get-a-repository\"}\n",
      "exception: 404 {\"message\": \"Not Found\", \"documentation_url\": \"https://docs.github.com/rest/repos/repos#get-a-repository\"}\n",
      "exception: 404 {\"message\": \"Not Found\", \"documentation_url\": \"https://docs.github.com/rest/repos/repos#get-a-repository\"}\n",
      "exception: 404 {\"message\": \"Not Found\", \"documentation_url\": \"https://docs.github.com/rest/repos/repos#get-a-repository\"}\n",
      "exception: 404 {\"message\": \"Not Found\", \"documentation_url\": \"https://docs.github.com/rest/repos/repos#get-a-repository\"}\n",
      "exception: 404 {\"message\": \"Not Found\", \"documentation_url\": \"https://docs.github.com/rest/repos/repos#get-a-repository\"}\n",
      "exception: 404 {\"message\": \"Not Found\", \"documentation_url\": \"https://docs.github.com/rest\"}\n",
      "exception: 404 {\"message\": \"Not Found\", \"documentation_url\": \"https://docs.github.com/rest/repos/repos#get-a-repository\"}\n",
      "exception: 404 {\"message\": \"Not Found\", \"documentation_url\": \"https://docs.github.com/rest/repos/repos#get-a-repository\"}\n",
      "exception: 404 {\"message\": \"Not Found\", \"documentation_url\": \"https://docs.github.com/rest/repos/repos#get-a-repository\"}\n",
      "exception: 404 {\"message\": \"Not Found\", \"documentation_url\": \"https://docs.github.com/rest/repos/repos#get-a-repository\"}\n",
      "exception: 404 {\"message\": \"Not Found\", \"documentation_url\": \"https://docs.github.com/rest/repos/repos#get-a-repository\"}\n",
      "exception: 404 {\"message\": \"Not Found\", \"documentation_url\": \"https://docs.github.com/rest/repos/repos#get-a-repository\"}\n",
      "exception: 404 {\"message\": \"Not Found\", \"documentation_url\": \"https://docs.github.com/rest/repos/repos#get-a-repository\"}\n",
      "exception: 404 {\"message\": \"Not Found\", \"documentation_url\": \"https://docs.github.com/rest/repos/repos#get-a-repository\"}\n",
      "exception: 404 {\"message\": \"Not Found\", \"documentation_url\": \"https://docs.github.com/rest/repos/repos#get-a-repository\"}\n",
      "exception: 404 {\"message\": \"Not Found\", \"documentation_url\": \"https://docs.github.com/rest/repos/repos#get-a-repository\"}\n",
      "09:49:21 : current iteration: 310 url: https://github.com/tedilabs/terraform-aws-account.git\n",
      "exception: [Errno 2] No such file or directory: 'data/step5-tf-pullrequests.json'\n",
      "exception: [Errno 2] No such file or directory: 'data/step5-tf-pullrequests.json'\n",
      "09:58:11 : current iteration: 317 url: https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules.git\n",
      "10:06:05 : current iteration: 317 url: https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules.git\n",
      "10:15:23 : current iteration: 318 url: https://github.com/UrbanOS-Examples/common.git\n",
      "10:24:29 : current iteration: 323 url: https://github.com/cloudposse/terraform-aws-ecs-web-app.git\n",
      "10:34:23 : current iteration: 329 url: https://github.com/stackabletech/t2.git\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 86\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pr \u001b[38;5;129;01min\u001b[39;00m repo\u001b[38;5;241m.\u001b[39mget_pulls(state\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     83\u001b[0m \n\u001b[1;32m     84\u001b[0m     \u001b[38;5;66;03m# retrieve all review comments, not required if there are none.\u001b[39;00m\n\u001b[1;32m     85\u001b[0m     comments \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 86\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[43mpr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreview_comments\u001b[49m \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m     87\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m review \u001b[38;5;129;01min\u001b[39;00m pr\u001b[38;5;241m.\u001b[39mget_reviews():\n\u001b[1;32m     88\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m (review\u001b[38;5;241m.\u001b[39mbody\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/github/PullRequest.py:328\u001b[0m, in \u001b[0;36mPullRequest.review_comments\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreview_comments\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m--> 328\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_completeIfNotSet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_review_comments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_review_comments\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/github/GithubObject.py:416\u001b[0m, in \u001b[0;36mCompletableGithubObject._completeIfNotSet\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_completeIfNotSet\u001b[39m(\u001b[38;5;28mself\u001b[39m, value: Attribute) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, _NotSetType):\n\u001b[0;32m--> 416\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_completeIfNeeded\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/github/GithubObject.py:420\u001b[0m, in \u001b[0;36mCompletableGithubObject._completeIfNeeded\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_completeIfNeeded\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    419\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__completed:\n\u001b[0;32m--> 420\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/github/GithubObject.py:425\u001b[0m, in \u001b[0;36mCompletableGithubObject.__complete\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_url\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IncompletableObject(\u001b[38;5;241m400\u001b[39m, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturned object contains no URL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 425\u001b[0m headers, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_requester\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequestJsonAndCheck\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_url\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storeAndUseAttributes(headers, data)\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__completed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/github/Requester.py:548\u001b[0m, in \u001b[0;36mRequester.requestJsonAndCheck\u001b[0;34m(self, verb, url, parameters, headers, input)\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequestJsonAndCheck\u001b[39m(\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    542\u001b[0m     verb: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    546\u001b[0m     \u001b[38;5;28minput\u001b[39m: Optional[Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    547\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Any]:\n\u001b[0;32m--> 548\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__check(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequestJson\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__customConnection\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/github/Requester.py:713\u001b[0m, in \u001b[0;36mRequester.requestJson\u001b[0;34m(self, verb, url, parameters, headers, input, cnx)\u001b[0m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode\u001b[39m(\u001b[38;5;28minput\u001b[39m: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m, json\u001b[38;5;241m.\u001b[39mdumps(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m--> 713\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__requestEncode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcnx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/github/Requester.py:810\u001b[0m, in \u001b[0;36mRequester.__requestEncode\u001b[0;34m(self, cnx, verb, url, parameters, requestHeaders, input, encode)\u001b[0m\n\u001b[1;32m    806\u001b[0m     requestHeaders[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m], encoded_input \u001b[38;5;241m=\u001b[39m encode(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNEW_DEBUG_FRAME(requestHeaders)\n\u001b[0;32m--> 810\u001b[0m status, responseHeaders, output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__requestRaw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcnx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequestHeaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoded_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Consts\u001b[38;5;241m.\u001b[39mheaderRateRemaining \u001b[38;5;129;01min\u001b[39;00m responseHeaders \u001b[38;5;129;01mand\u001b[39;00m Consts\u001b[38;5;241m.\u001b[39mheaderRateLimit \u001b[38;5;129;01min\u001b[39;00m responseHeaders:\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrate_limiting \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# ints expected but sometimes floats returned: https://github.com/PyGithub/PyGithub/pull/2697\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mfloat\u001b[39m(responseHeaders[Consts\u001b[38;5;241m.\u001b[39mheaderRateRemaining])),\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mfloat\u001b[39m(responseHeaders[Consts\u001b[38;5;241m.\u001b[39mheaderRateLimit])),\n\u001b[1;32m    817\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/github/Requester.py:844\u001b[0m, in \u001b[0;36mRequester.__requestRaw\u001b[0;34m(self, cnx, verb, url, requestHeaders, input)\u001b[0m\n\u001b[1;32m    842\u001b[0m     cnx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__createConnection()\n\u001b[1;32m    843\u001b[0m cnx\u001b[38;5;241m.\u001b[39mrequest(verb, url, \u001b[38;5;28minput\u001b[39m, requestHeaders)\n\u001b[0;32m--> 844\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mcnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    846\u001b[0m status \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus\n\u001b[1;32m    847\u001b[0m responseHeaders \u001b[38;5;241m=\u001b[39m {k\u001b[38;5;241m.\u001b[39mlower(): v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m response\u001b[38;5;241m.\u001b[39mgetheaders()}\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/github/Requester.py:196\u001b[0m, in \u001b[0;36mHTTPSRequestsConnectionClass.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    194\u001b[0m verb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverb\u001b[38;5;241m.\u001b[39mlower())\n\u001b[1;32m    195\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprotocol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 196\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mverb\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m RequestsResponse(r)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/requests/sessions.py:602\u001b[0m, in \u001b[0;36mSession.get\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[1;32m    595\u001b[0m \n\u001b[1;32m    596\u001b[0m \u001b[38;5;124;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;124;03m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;124;03m:rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    601\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 602\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:715\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    714\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 715\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[1;32m    729\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:467\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    462\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    463\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    464\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    465\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    466\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 467\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:462\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 462\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    464\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    465\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    466\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    467\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/http/client.py:1368\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1366\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1367\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1368\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1369\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1370\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/http/client.py:317\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 317\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/http/client.py:278\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 278\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/ssl.py:1273\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1270\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1271\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1272\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1273\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1274\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/ssl.py:1129\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1129\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1131\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# SETTINGS\n",
    "check_limit_every_x_calls = 5\n",
    "api_limit_buffer = 10\n",
    "api_calls_per_debug = 500\n",
    "\n",
    "# INITIALIZATION\n",
    "\n",
    "import json\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "# INITIALIZATION\n",
    "terraform_output = open(STEP4_TFCOMMITS)\n",
    "step4_output = json.load(terraform_output)\n",
    "\n",
    "# Retrieve data from previous run\n",
    "try:\n",
    "    previous_run = open(STEP5_TF_REPOS_WITH_PR)\n",
    "    repoData_dict = json.load(previous_run)\n",
    "except FileNotFoundError as e:\n",
    "    repoData_dict = []\n",
    "\n",
    "iteration = 0\n",
    "calls_till_next_debug = 0\n",
    "calls_till_limit_checkup = 0\n",
    "\n",
    "# Check for api limits, also periodically calls print debug.\n",
    "def CheckForApiLimit():\n",
    "    global calls_till_limit_checkup\n",
    "    global calls_till_next_debug\n",
    "    global api_calls_per_debug\n",
    "    global api_limit_buffer\n",
    "\n",
    "    # check for limit\n",
    "    if (calls_till_limit_checkup == 0):\n",
    "        core_limit = g.get_rate_limit().core\n",
    "\n",
    "        # sleep when exceeded api core limit\n",
    "        if (core_limit.remaining <= api_limit_buffer):\n",
    "            time_to_sleep = core_limit.raw_data['reset'] - time.time() + 1\n",
    "            print(\"Rate limit exceeded, sleeping for\", time_to_sleep, \"seconds.\", \"Actual remaining calls\", core_limit.remaining)\n",
    "            time.sleep(time_to_sleep)\n",
    "\n",
    "        calls_till_limit_checkup = check_limit_every_x_calls\n",
    "    \n",
    "    calls_till_limit_checkup -= 1\n",
    "\n",
    "    # check for debug\n",
    "    if (calls_till_next_debug == 0):\n",
    "        PrintDebug()\n",
    "        calls_till_next_debug = api_calls_per_debug\n",
    "\n",
    "    calls_till_next_debug -= 1\n",
    "\n",
    "# Prints debug message\n",
    "def PrintDebug():\n",
    "    global iteration\n",
    "    global repo_url\n",
    "\n",
    "    print(datetime.datetime.now().strftime(\"%H:%M:%S\"), \":\", \n",
    "              \"current iteration:\", iteration, \n",
    "              \"url:\", repo_url)\n",
    "\n",
    "# Pull request scraping script\n",
    "for rp in step4_output[\"repositories\"]:\n",
    "    try:\n",
    "        iteration += 1\n",
    "            \n",
    "        repo_url = rp[\"name\"]\n",
    "\n",
    "        # skip already scraped repositories\n",
    "        if any(d[\"url\"] == repo_url for d in repoData_dict):\n",
    "            continue\n",
    "\n",
    "        # Get the repo object from the url\n",
    "        split_list = repo_url.split(\"/\")\n",
    "        actual_url = (split_list[3]+ '/' + split_list[4]).split('.git')[0]\n",
    "        repo = g.get_repo(actual_url)\n",
    "        \n",
    "        # Get required info for pull requests\n",
    "        pull_requests_dict = []\n",
    "        pull_requests = repo.get_pulls(state=\"closed\")\n",
    "\n",
    "        if len(pull_requests) != 0:\n",
    "            for pr in repo.get_pulls(state=\"closed\"):\n",
    "    \n",
    "                # retrieve all review comments, not required if there are none.\n",
    "                comments = []\n",
    "                if (pr.review_comments > 0):\n",
    "                    for review in pr.get_reviews():\n",
    "                        if (review.body.strip() != \"\"):\n",
    "                            comments.append(review.body)\n",
    "                    CheckForApiLimit()\n",
    "    \n",
    "                if (pr.comments > 0):\n",
    "                    for comment in pr.get_issue_comments():\n",
    "                        if (comment.body.strip() != \"\"):\n",
    "                            comments.append(comment.body)\n",
    "                    CheckForApiLimit()\n",
    "    \n",
    "                # retrieve all connected commits.\n",
    "                commits = []\n",
    "                for commit in pr.get_commits():\n",
    "                    commits.append(commit.sha)\n",
    "                CheckForApiLimit()\n",
    "    \n",
    "                pull_requests_dict.append({\"url\": pr.html_url, \"title\": pr.title, \"body\": pr.body, \"comments\": comments, \"commits\": commits})\n",
    "            \n",
    "            CheckForApiLimit()        \n",
    "            repoData_dict.append({\"url\": repo_url, \"pull_requests\": pull_requests_dict});\n",
    "            \n",
    "            with open(STEP5_TF_REPOS_WITH_PR, \"w\") as outfile:\n",
    "                json.dump(repoData_dict, outfile)\n",
    "    except Exception as e:\n",
    "        print(\"exception:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c661aa7-2628-416b-9121-fc9d06060467",
   "metadata": {},
   "source": [
    "## STEP 6: Find tf commits for tf repos with pr's \n",
    "\n",
    "For remaining repositories from step 5, collect all commits that modify a terraform file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa3cc0b8-8193-4bc1-821c-39080379904d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at iteration 0\n",
      "at iteration 50\n",
      "at iteration 100\n",
      "at iteration 150\n",
      "at iteration 200\n",
      "at iteration 250\n",
      "at iteration 300\n",
      "at iteration 350\n",
      "at iteration 400\n",
      "at iteration 450\n",
      "at iteration 500\n",
      "at iteration 550\n",
      "at iteration 600\n"
     ]
    }
   ],
   "source": [
    "from pydriller import Repository\n",
    "\n",
    "import json\n",
    "\n",
    "step5 = open(STEP5_TF_REPOS_WITH_PR)\n",
    "step5_dict = json.load(step5)\n",
    "\n",
    "terraform_keywords = ['.tf', '.tf.json']\n",
    "\n",
    "iteration = 0\n",
    "    \n",
    "# Pull request scraping script\n",
    "repo_dic = []\n",
    "for rp in step5_dict:\n",
    "    try:\n",
    "        if (iteration % 50 == 0):\n",
    "            print(\"at iteration\", iteration)\n",
    "            with open(STEP6_TF_REPOS_COMMITS, \"w\") as outfile:\n",
    "                json.dump(repo_dic, outfile)\n",
    "\n",
    "        iteration += 1\n",
    "\n",
    "        repo = Repository(rp[\"url\"])\n",
    "\n",
    "        # Get each commit\n",
    "        commit_dic = []\n",
    "        for commit in repo.traverse_commits():\n",
    "\n",
    "            modified_terraform = False\n",
    "            # find if it changes a terraform file\n",
    "            for file in commit.modified_files:\n",
    "                if any(key in file.filename for key in terraform_keywords):\n",
    "                    modified_terraform = True\n",
    "            \n",
    "            if modified_terraform:\n",
    "                commit_dic.append({\"hash\": commit.hash, \n",
    "                                   \"url\": rp[\"url\"].split(\".git\")[0] + \"/commit/\" + commit.hash, \n",
    "                                   \"date\": str(commit.author_date), \n",
    "                                   \"body\": commit.msg})\n",
    "  \n",
    "        repo_dic.append({\"url\":rp[\"url\"], \"commits\":commit_dic})\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"exception:\", e)\n",
    "\n",
    "with open(STEP6_TF_REPOS_COMMITS, \"w\") as outfile:\n",
    "        json.dump(repo_dic, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa74b07b-f462-4646-a413-5747db1f864f",
   "metadata": {},
   "source": [
    "## STEP 7: filter out pull requests without tf commit\n",
    "\n",
    "Removes any pull request that does not include a commit from the previous step, for the remaining pull requests, it combines the two datasets into one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93e6ca7c-17ff-4858-a7a0-8b4530b4f1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "step5 = open(STEP5_TF_REPOS_WITH_PR)\n",
    "repository_input = json.load(step5)\n",
    "\n",
    "step6 = open(STEP6_TF_REPOS_COMMITS)\n",
    "commit_input = json.load(step6)\n",
    "\n",
    "iteration = 0\n",
    "\n",
    "output_dict = []\n",
    "\n",
    "# for each repository\n",
    "for repository in repository_input:\n",
    "    # find commits for repo from step 7\n",
    "    commit_input_list = next(repo[\"commits\"] for repo in commit_input if repo[\"url\"] == repository[\"url\"])\n",
    "\n",
    "    pr_dict = []\n",
    "    # for each pull request\n",
    "    for pull_request in repository[\"pull_requests\"]:\n",
    "        commit_dict = []\n",
    "\n",
    "        # for each commit\n",
    "        for commit_hash in pr[\"commits\"]:\n",
    "            # Find the exact commit from step 7\n",
    "            commit_data = next((commit for commit in commit_input_list if commit[\"hash\"] == commit_hash), None)\n",
    "            if (commit_data is not None):\n",
    "                commit_dict.append(commit_data)\n",
    "\n",
    "        pull_request[\"total_commits\"] = len(pull_request[\"commits\"])\n",
    "        pull_request[\"commits\"] = commit_dict\n",
    "        \n",
    "        if (len(commit_dict) > 0):\n",
    "            pr_dict.append(pull_request)\n",
    "    \n",
    "    if (len(pr_dict) > 0):\n",
    "        output_dict.append({\"url\": repository[\"url\"], \"pull_requests\": pr_dict})\n",
    "\n",
    "with open(STEP7_TF_REPOS_WITH_TF_PR, \"w\") as outfile:\n",
    "    json.dump(output_dict, outfile) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10ca568-c990-49f9-b5ba-80d5345aff95",
   "metadata": {},
   "source": [
    "## STEP 8: list all tf pull request with a keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "922f5e46-7106-4995-b526-19b3030b0f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_keywords = [\"cheap\", \"expens\", \"cost\", \"efficient\", \"bill\", \"pay\"]\n",
    "\n",
    "step7 = open(STEP7_TF_REPOS_WITH_TF_PR)\n",
    "repo_input = json.load(step7)\n",
    "\n",
    "pullrequest_dict_output = []\n",
    "for repository in repo_input:\n",
    "    for pr in repository[\"pull_requests\"]:\n",
    "        \n",
    "        title   = True if (pr[\"title\"]        is not None and any(key in pr[\"title\"].lower()    for key in cost_keywords)) else False\n",
    "        body    = True if (pr[\"body\"]         is not None and any(key in pr[\"body\"].lower()     for key in cost_keywords)) else False\n",
    "        comment = True if (any(comment        is not None and     key in comment.lower()        for key in cost_keywords for comment in pr[\"comments\"])) else False\n",
    "        commit  = True if (any(commit[\"body\"] is not None and     key in commit[\"body\"].lower() for key in cost_keywords for commit  in pr[\"commits\"]))  else False\n",
    "            \n",
    "        reason = ((\"title \" if title else \"\") + \n",
    "                  (\"body \" if body else \"\") + \n",
    "                  (\"comment \" if comment else \"\") + \n",
    "                  (\"commit \" if commit else \"\"))\n",
    "        \n",
    "        if (title or body or comment or commit):\n",
    "            pullrequest_dict_output.append({\"reason\": reason.strip(), \"pull_request\": pr})\n",
    "\n",
    "with open(STEP8_TF_KEYWORD_PR, \"w\") as outfile:\n",
    "    json.dump(pullrequest_dict_output, outfile) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f216e1-5413-40cb-94fc-61185aa45963",
   "metadata": {},
   "source": [
    "## STEP 9: results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b231bb8-ced9-404b-890f-643e35b3df9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total repositories: 1278\n",
      "Existing repositories with pull requests: 610\n",
      "Repositories with TF pull requests: 476\n",
      "\n",
      "\n",
      "Total PR's with keywords found: 1135\n",
      "\n",
      "\n",
      "PR with keyword in:\t Only in:\n",
      "Title:\t\t 283 \t 8\n",
      "Description:\t 457 \t 183\n",
      "Comment:\t 314 \t 257\n",
      "commit message:\t 655 \t 230\n",
      "\n",
      "\n",
      "Total amount of commits in terraform pr's: 131521\n",
      "Total amount of terraform commits in terraform pr's: 5883\n",
      "Terraform commits with a keyword in terraform pr's: 862\n",
      "\n",
      "\n",
      "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/345\n",
      "https://github.com/Azure/sap-automation/pull/462\n",
      "https://github.com/Azure/sap-automation/pull/421\n",
      "https://github.com/Azure/sap-automation/pull/408\n",
      "https://github.com/Azure/sap-automation/pull/372\n",
      "https://github.com/Azure/sap-automation/pull/278\n",
      "https://github.com/Azure/sap-automation/pull/407\n",
      "https://github.com/Azure/sap-automation/pull/458\n",
      "https://github.com/Azure/sap-automation/pull/276\n",
      "https://github.com/Azure/sap-automation/pull/441\n",
      "https://github.com/Azure/sap-automation/pull/416\n",
      "https://github.com/Azure/sap-automation/pull/454\n",
      "https://github.com/Azure/sap-automation/pull/440\n",
      "https://github.com/Azure/sap-automation/pull/414\n",
      "https://github.com/Azure/sap-automation/pull/357\n",
      "https://github.com/Azure/sap-automation/pull/452\n",
      "https://github.com/Azure/sap-automation/pull/439\n",
      "https://github.com/Azure/sap-automation/pull/438\n",
      "https://github.com/Azure/sap-automation/pull/509\n",
      "https://github.com/Azure/sap-automation/pull/375\n",
      "https://github.com/Azure/sap-automation/pull/436\n",
      "https://github.com/Azure/sap-automation/pull/409\n",
      "https://github.com/oracle-quickstart/oci-cis-landingzone-quickstart/pull/26\n",
      "https://github.com/aztfmod/terraform-azurerm-caf/pull/1207\n",
      "https://github.com/ministryofjustice/cloud-platform-environments/pull/22771\n",
      "https://github.com/ministryofjustice/cloud-platform-environments/pull/2035\n",
      "https://github.com/ministryofjustice/cloud-platform-environments/pull/22768\n",
      "https://github.com/ministryofjustice/cloud-platform-environments/pull/692\n",
      "https://github.com/Echo-Stream/terraform-aws-control/pull/11\n",
      "https://github.com/ministryofjustice/modernisation-platform-environments/pull/515\n",
      "https://github.com/ministryofjustice/modernisation-platform-environments/pull/3837\n",
      "https://github.com/broadinstitute/terraform-terra/pull/71\n",
      "https://github.com/SUSE/ha-sap-terraform-deployments/pull/476\n",
      "https://github.com/SUSE/ha-sap-terraform-deployments/pull/446\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "cost_keywords = [\"cheap\", \"expens\", \"cost\", \"efficient\", \"bill\", \"pay\"]\n",
    "\n",
    "step4 = open(STEP4_TFCOMMITS)\n",
    "step4_data = json.load(step4)\n",
    "\n",
    "step5 = open(STEP5_TF_REPOS_WITH_PR)\n",
    "step5_data = json.load(step5)\n",
    "\n",
    "step7 = open(STEP7_TF_REPOS_WITH_TF_PR)\n",
    "repo_input = json.load(step7)\n",
    "\n",
    "step8 = open(STEP8_TF_KEYWORD_PR)\n",
    "pr_reason_input = json.load(step8)\n",
    "\n",
    "\n",
    "# GENERAL REPOSITORY DATA\n",
    "\n",
    "print(\"Total repositories:\" , step4_data[\"no_of_repos\"])\n",
    "print(\"Existing repositories with pull requests:\", len(step5_data))\n",
    "print(\"Repositories with TF pull requests:\", len(repo_input))\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "# GENERAL PULL REQUEST DATA\n",
    "\n",
    "print(\"Total PR's with keywords found:\", len(pr_reason_input))\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"PR with keyword in:\\t\", \"Only in:\")\n",
    "print(\"Title:\\t\\t\", len([pr for pr in pr_reason_input if \"title\" in pr[\"reason\"]]), \"\\t\", len([pr for pr in pr_reason_input if \"title\" == pr[\"reason\"]]))\n",
    "print(\"Description:\\t\", len([pr for pr in pr_reason_input if \"body\" in pr[\"reason\"]]), \"\\t\", len([pr for pr in pr_reason_input if \"body\" == pr[\"reason\"]]))\n",
    "print(\"Comment:\\t\", len([pr for pr in pr_reason_input if \"comment\" in pr[\"reason\"]]), \"\\t\", len([pr for pr in pr_reason_input if \"comment\" == pr[\"reason\"]]))\n",
    "print(\"commit message:\\t\", len([pr for pr in pr_reason_input if \"commit\" in pr[\"reason\"]]), \"\\t\", len([pr for pr in pr_reason_input if \"commit\" == pr[\"reason\"]]))  \n",
    "\n",
    "print(\"\")\n",
    "\n",
    "# GENERAL COMMIT DATA\n",
    "\n",
    "print(\"Total amount of commits in terraform pr's:\", sum([pr[\"total_commits\"] for repo in repo_input for pr in repo[\"pull_requests\"]]))\n",
    "print(\"Total amount of terraform commits in terraform pr's:\", len([commit for pr_reason in pr_reason_input for commit in pr_reason[\"pull_request\"][\"commits\"]]))\n",
    "print(\"Terraform commits with a keyword in terraform pr's:\", len([commit for pr_reason in pr_reason_input for commit in pr_reason[\"pull_request\"][\"commits\"] if any(key in commit[\"body\"].lower() for key in cost_keywords)]))\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "count = 0\n",
    "for repo in repo_input:\n",
    "    for pr in repo[\"pull_requests\"]:\n",
    "        if (pr[\"total_commits\"] >= 250):\n",
    "            print(pr[\"url\"])\n",
    "            count += 1\n",
    "print(count)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
