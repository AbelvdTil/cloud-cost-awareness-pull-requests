{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45e03a43-7920-4679-a955-ed3118ef1201",
   "metadata": {},
   "source": [
    "# Pull request scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a05420a-77b4-4d26-acdd-b6ca46d0f239",
   "metadata": {},
   "source": [
    "## GitHub credentials\n",
    "A private access token is necessary to make use of less restrictive API limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "18030255-77ee-4ed0-b11b-b2824e704349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated as: AbelvdTil\n"
     ]
    }
   ],
   "source": [
    "from github import RateLimitExceededException, Github\n",
    "\n",
    "# Providing access token\n",
    "access_token = \"\"\n",
    "g = Github(login_or_token=access_token)\n",
    "\n",
    "# Confirm your login is successful\n",
    "user = g.get_user()\n",
    "print(f\"Authenticated as: {user.login}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09550648-f771-420c-bfbc-d3cd7bceec95",
   "metadata": {},
   "source": [
    "## Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f5be4139-d47b-42f1-b4a6-eee6d6de92a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    " \n",
    "STEP4_TFCOMMITS = os.path.join(\"data\", \"step4-tf-commits.json\") \n",
    "STEP5_TF_PULLREQUESTS = os.path.join(\"data\", \"step5-tf-pullrequests.json\")\n",
    "STEP6_TF_REPOS_WITH_PR = os.path.join(\"data\", \"step6-tf-repos-with-pr.json\")\n",
    "STEP7_TF_REPOS_COMMITS = os.path.join(\"data\", \"step7-tf-repos-commits.json\")\n",
    "STEP8_TF_REPOS_WITH_TF_PR = os.path.join(\"data\", \"step8-tf-repos-with-tf-pr.json\")\n",
    "STEP9_TF_KEYWORD_PR = os.path.join(\"data\", \"step9-tf-keyword-pr.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1dc4f3-4c41-422a-af1a-817915c2fb00",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## File seperator and adder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "93d27ae3-61d8-444e-99e5-bfffe7e66185",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "\n",
    "FILE_TO_SEPERATE = STEP5_TF_PULLREQUESTS\n",
    "\n",
    "nr_parts = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae8c9fe-a182-4600-bd3c-6e3fee8607a0",
   "metadata": {},
   "source": [
    "### File seperator\n",
    "\n",
    "Output of step 5 will likely be too large for github, make sure each file is under 100MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac6757a0-cacc-4792-87d7-3ade5ff857f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = open(FILE_TO_SEPERATE)\n",
    "repoData_dict = json.load(results)\n",
    "\n",
    "size_per_part = math.ceil(len(repoData_dict) / nr_parts) \n",
    "\n",
    "part_data = []\n",
    "\n",
    "i = 0\n",
    "current_part = 0\n",
    "for rp in repoData_dict:\n",
    "    i += 1\n",
    "    part = math.floor(i / size_per_part)\n",
    "    if (part == current_part):\n",
    "        part_data.append(rp)\n",
    "    else:\n",
    "        part_data.append(rp)\n",
    "        with open(FILE_TO_SEPERATE.split(\".\")[0] + \"-part-\" + str(current_part+1) + \".json\", \"w\") as outfile:\n",
    "            json.dump(part_data, outfile) \n",
    "        part_data = []\n",
    "        current_part = part\n",
    "    \n",
    "if part_data != []:\n",
    "    with open(FILE_TO_SEPERATE.split(\".\")[0] + \"-part-\" + str(current_part+1) + \".json\", \"w\") as outfile:\n",
    "            json.dump(part_data, outfile) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98739107-471c-4478-960c-5baae19446b0",
   "metadata": {},
   "source": [
    "### File combinator\n",
    "\n",
    "Combine the seperate parts back together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8823ce5d-8c0f-4d9a-9c59-f4f62c8f69aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "repoData_dict = []\n",
    "for current_part in range(nr_parts):\n",
    "    part_file = open(FILE_TO_SEPERATE.split(\".\")[0] + \"-part-\" + str(current_part+1) + \".json\", \"r\")\n",
    "    part_data = json.load(part_file)\n",
    "\n",
    "    for rp in part_data:\n",
    "        repoData_dict.append(rp)\n",
    "\n",
    "with open(FILE_TO_SEPERATE, \"w\") as outfile:\n",
    "            json.dump(repoData_dict, outfile) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96031760-e0b7-4b4e-99ab-b75d1ad3ee10",
   "metadata": {},
   "source": [
    "## STEP 5: Pull request scraping script\n",
    "\n",
    "Also includes settings, initialization and helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "492cb012-8537-42cb-8c58-3d9d45b21aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:44:46 : current iteration: 1 url: https://github.com/tkhoa2711/terraform-digitalocean.git\n",
      "exception: 404 {\"message\": \"Not Found\", \"documentation_url\": \"https://docs.github.com/rest/repos/repos#get-a-repository\"}\n"
     ]
    }
   ],
   "source": [
    "# SETTINGS\n",
    "check_limit_every_x_calls = 10\n",
    "api_limit_buffer = 50\n",
    "api_calls_per_debug = 1000\n",
    "\n",
    "# INITIALIZATION\n",
    "\n",
    "import json\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "# INITIALIZATION\n",
    "terraform_output = open(STEP4_TFCOMMITS)\n",
    "step4_output = json.load(terraform_output)\n",
    "\n",
    "# Retrieve data from previous run\n",
    "try:\n",
    "    previous_run = open(STEP5_TF_PULLREQUESTS)\n",
    "    repoData_dict = json.load(previous_run)\n",
    "except FileNotFoundError as e:\n",
    "    repoData_dict = []\n",
    "\n",
    "iteration = 0\n",
    "calls_till_next_debug = 0\n",
    "calls_till_limit_checkup = 0\n",
    "\n",
    "# Check for api limits, also periodically calls print debug.\n",
    "def CheckForApiLimit():\n",
    "    global calls_till_limit_checkup\n",
    "    global calls_till_next_debug\n",
    "    global api_calls_per_debug\n",
    "    global api_limit_buffer\n",
    "\n",
    "    # check for limit\n",
    "    if (calls_till_limit_checkup == 0):\n",
    "        core_limit = g.get_rate_limit().core\n",
    "\n",
    "        # sleep when exceeded api core limit\n",
    "        if (core_limit.remaining <= api_limit_buffer):\n",
    "            time_to_sleep = core_limit.raw_data['reset'] - time.time() + 1\n",
    "            print(\"Rate limit exceeded, sleeping for\", time_to_sleep, \"seconds.\", \"Actual remaining calls\", core_limit.remaining)\n",
    "            time.sleep(time_to_sleep)\n",
    "\n",
    "        calls_till_limit_checkup = check_limit_every_x_calls\n",
    "    \n",
    "    calls_till_limit_checkup -= 1\n",
    "\n",
    "    # check for debug\n",
    "    if (calls_till_next_debug == 0):\n",
    "        PrintDebug()\n",
    "        calls_till_next_debug = api_calls_per_debug\n",
    "\n",
    "    calls_till_next_debug -= 1\n",
    "\n",
    "# Prints debug message\n",
    "def PrintDebug():\n",
    "    global iteration\n",
    "    global repo_url\n",
    "\n",
    "    print(datetime.datetime.now().strftime(\"%H:%M:%S\"), \":\", \n",
    "              \"current iteration:\", iteration, \n",
    "              \"url:\", repo_url)\n",
    "\n",
    "# Pull request scraping script\n",
    "for rp in step4_output[\"repositories\"]:\n",
    "    try:\n",
    "        iteration += 1\n",
    "\n",
    "        if (iteration > 10):\n",
    "            break\n",
    "            \n",
    "        repo_url = rp[\"name\"]\n",
    "\n",
    "        # skip already scraped repositories\n",
    "        if any(d[\"url\"] == repo_url for d in repoData_dict):\n",
    "            continue\n",
    "\n",
    "        # Get the repo object from the url\n",
    "        split_list = repo_url.split(\"/\")\n",
    "        actual_url = (split_list[3]+ '/' + split_list[4]).split('.git')[0]\n",
    "        repo = g.get_repo(actual_url)\n",
    "        \n",
    "        # Get required info for pull requests\n",
    "        pull_requests_dict = []\n",
    "        for pr in repo.get_pulls(state=\"closed\"):\n",
    "\n",
    "            # retrieve all review comments, not required if there are none.\n",
    "            comments = []\n",
    "            if (pr.review_comments > 0):\n",
    "                for review in pr.get_reviews():\n",
    "                    if (review.body.strip() != \"\"):\n",
    "                        comments.append(review.body)\n",
    "                CheckForApiLimit()\n",
    "\n",
    "            if (pr.comments > 0):\n",
    "                for comment in pr.get_issue_comments():\n",
    "                    if (comment.body.strip() != \"\"):\n",
    "                        comments.append(comment.body)\n",
    "                CheckForApiLimit()\n",
    "\n",
    "            # retrieve all connected commits.\n",
    "            commits = []\n",
    "            for commit in pr.get_commits():\n",
    "                commits.append(commit.sha)\n",
    "            CheckForApiLimit()\n",
    "\n",
    "            pull_requests_dict.append({\"url\": pr.html_url, \"title\": pr.title, \"body\": pr.body, \"comments\": comments, \"commits\": commits})\n",
    "        \n",
    "        CheckForApiLimit()        \n",
    "        repoData_dict.append({\"url\": repo_url, \"pull_requests\": pull_requests_dict});\n",
    "        \n",
    "        with open(STEP5_TF_PULLREQUESTS, \"w\") as outfile:\n",
    "            json.dump(repoData_dict, outfile)\n",
    "    except Exception as e:\n",
    "        print(\"exception:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16621013-7ada-4264-9bd1-b1aa8b5c234c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## STEP 6: Reduce to repositories with pull requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dcd98b77-0f24-4a23-b82a-9bdb7f2df158",
   "metadata": {},
   "outputs": [],
   "source": [
    "step5 = open(STEP5_TF_PULLREQUESTS)\n",
    "step5_dict = json.load(step5)\n",
    "\n",
    "output_dict = []\n",
    "for rp in step5_dict:\n",
    "    if len(rp[\"pull_requests\"]) != 0:\n",
    "        output_dict.append({\"url\": rp[\"url\"], \"pull_requests\": rp[\"pull_requests\"]})\n",
    "\n",
    "with open(STEP6_TF_REPOS_WITH_PR, \"w\") as outfile:\n",
    "            json.dump(output_dict, outfile) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c661aa7-2628-416b-9121-fc9d06060467",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## STEP 7: Find tf commits for tf repos with pr's \n",
    "\n",
    "This will only store commits that modify a terraform file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa3cc0b8-8193-4bc1-821c-39080379904d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at iteration 0\n",
      "at iteration 50\n",
      "at iteration 100\n",
      "at iteration 150\n",
      "at iteration 200\n",
      "at iteration 250\n",
      "at iteration 300\n",
      "at iteration 350\n",
      "at iteration 400\n",
      "at iteration 450\n",
      "at iteration 500\n",
      "at iteration 550\n",
      "at iteration 600\n"
     ]
    }
   ],
   "source": [
    "from pydriller import Repository\n",
    "\n",
    "import json\n",
    "\n",
    "step6 = open(STEP6_TF_REPOS_WITH_PR)\n",
    "step6_dict = json.load(step6)\n",
    "\n",
    "terraform_keywords = ['.tf', '.tf.json']\n",
    "\n",
    "iteration = 0\n",
    "    \n",
    "# Pull request scraping script\n",
    "repo_dic = []\n",
    "for rp in step6_dict:\n",
    "    try:\n",
    "        if (iteration % 50 == 0):\n",
    "            print(\"at iteration\", iteration)\n",
    "            with open(STEP7_TF_REPOS_COMMITS, \"w\") as outfile:\n",
    "                json.dump(repo_dic, outfile)\n",
    "\n",
    "        iteration += 1\n",
    "\n",
    "        repo = Repository(rp[\"url\"])\n",
    "\n",
    "        # Get each commit\n",
    "        commit_dic = []\n",
    "        for commit in repo.traverse_commits():\n",
    "\n",
    "            modified_terraform = False\n",
    "            # find if it changes a terraform file\n",
    "            for file in commit.modified_files:\n",
    "                if any(key in file.filename for key in terraform_keywords):\n",
    "                    modified_terraform = True\n",
    "            \n",
    "            if modified_terraform:\n",
    "                commit_dic.append({\"hash\": commit.hash, \n",
    "                                   \"url\": rp[\"url\"].split(\".git\")[0] + \"/commit/\" + commit.hash, \n",
    "                                   \"date\": str(commit.author_date), \n",
    "                                   \"body\": commit.msg})\n",
    "  \n",
    "        repo_dic.append({\"url\":rp[\"url\"], \"commits\":commit_dic})\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"exception:\", e)\n",
    "\n",
    "with open(STEP7_TF_REPOS_COMMITS, \"w\") as outfile:\n",
    "        json.dump(repo_dic, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa74b07b-f462-4646-a413-5747db1f864f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## STEP 8: filter out pull requests without tf commit\n",
    "\n",
    "Removes any pull request that does not include a commit from the previous step, for the remaining pull requests, it combines the two datasets into one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93e6ca7c-17ff-4858-a7a0-8b4530b4f1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "step6 = open(STEP6_TF_REPOS_WITH_PR)\n",
    "repository_input = json.load(step6)\n",
    "\n",
    "step7 = open(STEP7_TF_REPOS_COMMITS)\n",
    "commit_input = json.load(step7)\n",
    "\n",
    "iteration = 0\n",
    "\n",
    "output_dict = []\n",
    "\n",
    "# for each repository\n",
    "for rp in repository_input:\n",
    "    # find commits for repo from step 7\n",
    "    commit_input_list = next(repo[\"commits\"] for repo in commit_input if repo[\"url\"] == rp[\"url\"])\n",
    "\n",
    "    pr_dict = []\n",
    "    # for each pull request\n",
    "    for pr in rp[\"pull_requests\"]:\n",
    "        commit_dict = []\n",
    "\n",
    "        # for each commit\n",
    "        for commit_hash in pr[\"commits\"]:\n",
    "            # Find the exact commit from step 7\n",
    "            commit_data = next((commit for commit in commit_input_list if commit[\"hash\"] == commit_hash), None)\n",
    "            if (commit_data is not None):\n",
    "                commit_dict.append(commit_data)\n",
    "\n",
    "        pr[\"total_commits\"] = len(pr[\"commits\"])\n",
    "        pr[\"commits\"] = commit_dict\n",
    "        \n",
    "        if (len(commit_dict) > 0):\n",
    "            pr_dict.append(pr)\n",
    "    \n",
    "    if (len(pr_dict) > 0):\n",
    "        output_dict.append({\"url\": rp[\"url\"], \"pull_requests\": pr_dict})\n",
    "\n",
    "with open(STEP8_TF_REPOS_WITH_TF_PR, \"w\") as outfile:\n",
    "    json.dump(output_dict, outfile) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10ca568-c990-49f9-b5ba-80d5345aff95",
   "metadata": {},
   "source": [
    "## STEP 9: list all tf pull request with a keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "922f5e46-7106-4995-b526-19b3030b0f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_keywords = [\"cheap\", \"expens\", \"cost\", \"efficient\", \"bill\", \"pay\"]\n",
    "\n",
    "step8 = open(STEP8_TF_REPOS_WITH_TF_PR)\n",
    "repo_input = json.load(step8)\n",
    "\n",
    "pullrequest_dict_output = []\n",
    "for repository in repo_input:\n",
    "    for pr in repository[\"pull_requests\"]:\n",
    "        \n",
    "        title   = True if (pr[\"title\"]        is not None and any(key in pr[\"title\"].lower()    for key in cost_keywords)) else False\n",
    "        body    = True if (pr[\"body\"]         is not None and any(key in pr[\"body\"].lower()     for key in cost_keywords)) else False\n",
    "        comment = True if (any(comment        is not None and     key in comment.lower()        for key in cost_keywords for comment in pr[\"comments\"])) else False\n",
    "        commit  = True if (any(commit[\"body\"] is not None and     key in commit[\"body\"].lower() for key in cost_keywords for commit  in pr[\"commits\"]))  else False\n",
    "            \n",
    "        reason = ((\"title \" if title else \"\") + \n",
    "                  (\"body \" if body else \"\") + \n",
    "                  (\"comment \" if comment else \"\") + \n",
    "                  (\"commit \" if commit else \"\"))\n",
    "        \n",
    "        if (title or body or comment or commit):\n",
    "            pullrequest_dict_output.append({\"reason\": reason.strip(), \"pull_request\": pr})\n",
    "\n",
    "with open(STEP9_TF_KEYWORD_PR, \"w\") as outfile:\n",
    "    json.dump(pullrequest_dict_output, outfile) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f216e1-5413-40cb-94fc-61185aa45963",
   "metadata": {},
   "source": [
    "## STEP 10: results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4b231bb8-ced9-404b-890f-643e35b3df9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total PR's found: 888\n",
      "\n",
      "PR's with keyword in title: 283\n",
      "ONLY keyword in title: 12\n",
      "\n",
      "PR's with keyword in description: 457\n",
      "ONLY keyword in description: 195\n",
      "\n",
      "PR's with keyword in review comment: 16\n",
      "ONLY keyword in review comment: 10\n",
      "\n",
      "PR's with keyword in commit message: 655\n",
      "ONLY keyword in commit: 239\n",
      "157\n",
      "53\n",
      "53\n",
      "51\n",
      "51\n",
      "78\n",
      "52\n",
      "73\n",
      "250\n",
      "https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/345\n",
      "114\n",
      "57\n",
      "77\n",
      "108\n",
      "59\n",
      "117\n",
      "76\n",
      "120\n",
      "162\n",
      "160\n",
      "115\n",
      "87\n",
      "81\n",
      "102\n",
      "61\n",
      "52\n",
      "56\n",
      "57\n",
      "145\n",
      "60\n",
      "250\n",
      "https://github.com/Azure/sap-automation/pull/509\n",
      "103\n",
      "99\n",
      "61\n",
      "54\n",
      "250\n",
      "https://github.com/Azure/sap-automation/pull/462\n",
      "250\n",
      "https://github.com/Azure/sap-automation/pull/458\n",
      "250\n",
      "https://github.com/Azure/sap-automation/pull/454\n",
      "250\n",
      "https://github.com/Azure/sap-automation/pull/452\n",
      "215\n",
      "250\n",
      "https://github.com/Azure/sap-automation/pull/441\n",
      "250\n",
      "https://github.com/Azure/sap-automation/pull/440\n",
      "250\n",
      "https://github.com/Azure/sap-automation/pull/439\n",
      "250\n",
      "https://github.com/Azure/sap-automation/pull/438\n",
      "250\n",
      "https://github.com/Azure/sap-automation/pull/436\n",
      "250\n",
      "https://github.com/Azure/sap-automation/pull/421\n",
      "250\n",
      "https://github.com/Azure/sap-automation/pull/416\n",
      "250\n",
      "https://github.com/Azure/sap-automation/pull/414\n",
      "250\n",
      "https://github.com/Azure/sap-automation/pull/409\n",
      "250\n",
      "https://github.com/Azure/sap-automation/pull/408\n",
      "250\n",
      "https://github.com/Azure/sap-automation/pull/407\n",
      "124\n",
      "250\n",
      "https://github.com/Azure/sap-automation/pull/375\n",
      "250\n",
      "https://github.com/Azure/sap-automation/pull/372\n",
      "250\n",
      "https://github.com/Azure/sap-automation/pull/357\n",
      "172\n",
      "250\n",
      "https://github.com/Azure/sap-automation/pull/278\n",
      "250\n",
      "https://github.com/Azure/sap-automation/pull/276\n",
      "62\n",
      "62\n",
      "55\n",
      "91\n",
      "57\n",
      "60\n",
      "59\n",
      "100\n",
      "55\n",
      "60\n",
      "127\n",
      "114\n",
      "141\n",
      "250\n",
      "https://github.com/oracle-quickstart/oci-cis-landingzone-quickstart/pull/26\n",
      "60\n",
      "51\n",
      "55\n",
      "90\n",
      "172\n",
      "56\n",
      "124\n",
      "169\n",
      "83\n",
      "54\n",
      "177\n",
      "146\n",
      "55\n",
      "67\n",
      "66\n",
      "84\n",
      "51\n",
      "51\n",
      "67\n",
      "80\n",
      "58\n",
      "158\n",
      "72\n",
      "250\n",
      "https://github.com/aztfmod/terraform-azurerm-caf/pull/1207\n",
      "95\n",
      "90\n",
      "148\n",
      "97\n",
      "107\n",
      "51\n",
      "121\n",
      "115\n",
      "152\n",
      "208\n",
      "69\n",
      "53\n",
      "93\n",
      "54\n",
      "82\n",
      "81\n",
      "69\n",
      "136\n",
      "132\n",
      "123\n",
      "130\n",
      "145\n",
      "60\n",
      "65\n",
      "90\n",
      "59\n",
      "58\n",
      "60\n",
      "108\n",
      "78\n",
      "61\n",
      "250\n",
      "https://github.com/ministryofjustice/cloud-platform-environments/pull/2035\n",
      "98\n",
      "108\n",
      "250\n",
      "https://github.com/ministryofjustice/cloud-platform-environments/pull/692\n",
      "189\n",
      "64\n",
      "162\n",
      "89\n",
      "250\n",
      "https://github.com/Echo-Stream/terraform-aws-control/pull/11\n",
      "99\n",
      "61\n",
      "138\n",
      "51\n",
      "158\n",
      "141\n",
      "224\n",
      "123\n",
      "59\n",
      "170\n",
      "107\n",
      "101\n",
      "133\n",
      "59\n",
      "123\n",
      "93\n",
      "91\n",
      "76\n",
      "74\n",
      "129\n",
      "118\n",
      "91\n",
      "56\n",
      "63\n",
      "180\n",
      "62\n",
      "67\n",
      "53\n",
      "56\n",
      "56\n",
      "131\n",
      "97\n",
      "53\n",
      "224\n",
      "161\n",
      "119\n",
      "118\n",
      "56\n",
      "109\n",
      "65\n",
      "102\n",
      "70\n",
      "250\n",
      "https://github.com/ministryofjustice/modernisation-platform-environments/pull/3837\n",
      "80\n",
      "95\n",
      "51\n",
      "60\n",
      "57\n",
      "163\n",
      "65\n",
      "157\n",
      "51\n",
      "117\n",
      "244\n",
      "127\n",
      "127\n",
      "97\n",
      "222\n",
      "77\n",
      "93\n",
      "154\n",
      "79\n",
      "70\n",
      "72\n",
      "70\n",
      "52\n",
      "51\n",
      "250\n",
      "https://github.com/ministryofjustice/modernisation-platform-environments/pull/515\n",
      "80\n",
      "60\n",
      "133\n",
      "133\n",
      "79\n",
      "250\n",
      "https://github.com/broadinstitute/terraform-terra/pull/71\n",
      "53\n",
      "97\n",
      "232\n",
      "52\n",
      "157\n",
      "156\n",
      "56\n",
      "192\n",
      "250\n",
      "https://github.com/SUSE/ha-sap-terraform-deployments/pull/476\n",
      "250\n",
      "https://github.com/SUSE/ha-sap-terraform-deployments/pull/446\n",
      "149\n",
      "146\n",
      "61\n",
      "53\n",
      "101\n",
      "51\n",
      "57\n",
      "63\n",
      "71\n",
      "153\n",
      "58\n",
      "59\n",
      "52\n",
      "53\n",
      "64\n",
      "162\n",
      "54\n",
      "128\n",
      "107\n",
      "93\n",
      "113\n",
      "66\n",
      "51\n",
      "72\n",
      "63\n",
      "32\n",
      "\n",
      "Total amount of commits in terraform pr's: 130672\n",
      "Total amount of terraform commits in terraform pr's: 5000\n",
      "Terraform commits with a keyword in terraform pr's: 862\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "cost_keywords = [\"cheap\", \"expens\", \"cost\", \"efficient\", \"bill\", \"pay\"]\n",
    "\n",
    "step9 = open(STEP9_TF_KEYWORD_PR)\n",
    "pr_reason_input = json.load(step9)\n",
    "\n",
    "step8 = open(STEP8_TF_REPOS_WITH_TF_PR)\n",
    "repo_input = json.load(step8)\n",
    "\n",
    "print(\"Total PR's found:\", len(pr_reason_input))\n",
    "\n",
    "print(\"\\nPR's with keyword in title:\", len([pr for pr in pr_reason_input if \"title\" in pr[\"reason\"]]))\n",
    "print(\"ONLY keyword in title:\", len([pr for pr in pr_reason_input if \"title\" == pr[\"reason\"]]))\n",
    "\n",
    "print(\"\\nPR's with keyword in description:\", len([pr for pr in pr_reason_input if \"body\" in pr[\"reason\"]]))\n",
    "print(\"ONLY keyword in description:\", len([pr for pr in pr_reason_input if \"body\" == pr[\"reason\"]]))\n",
    "\n",
    "print(\"\\nPR's with keyword in review comment:\", len([pr for pr in pr_reason_input if \"comment\" in pr[\"reason\"]]))\n",
    "print(\"ONLY keyword in review comment:\", len([pr for pr in pr_reason_input if \"comment\" == pr[\"reason\"]]))      \n",
    "\n",
    "print(\"\\nPR's with keyword in commit message:\", len([pr for pr in pr_reason_input if \"commit\" in pr[\"reason\"]]))\n",
    "print(\"ONLY keyword in commit:\", len([pr for pr in pr_reason_input if \"commit\" == pr[\"reason\"]]))    \n",
    "\n",
    "count = 0\n",
    "for repo in repo_input:\n",
    "    for pr in repo[\"pull_requests\"]:\n",
    "        if (pr[\"total_commits\"] > 50):\n",
    "            print(pr[\"total_commits\"])\n",
    "        if (pr[\"total_commits\"] >= 250):\n",
    "            print(pr[\"url\"])\n",
    "            count += 1\n",
    "print(count)\n",
    "    \n",
    "print(\"\\nTotal amount of commits in terraform pr's:\", sum([pr[\"total_commits\"] for repo in repo_input for pr in repo[\"pull_requests\"]]))\n",
    "print(\"Total amount of terraform commits in terraform pr's:\", len([commit for pr_reason in pr_reason_input for commit in pr_reason[\"pull_request\"][\"commits\"]]))\n",
    "print(\"Terraform commits with a keyword in terraform pr's:\", len([commit for pr_reason in pr_reason_input for commit in pr_reason[\"pull_request\"][\"commits\"] if any(key in commit[\"body\"].lower() for key in cost_keywords)]))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aefdaa-7ede-486e-bf13-8c447690dd48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
