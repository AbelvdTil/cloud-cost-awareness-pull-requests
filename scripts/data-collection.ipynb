{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## GitHub credentials\n",
    "\n",
    "A private access token is necessary to make use of less restrictive API limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated as: AbelvdTil\n"
     ]
    }
   ],
   "source": [
    "from github import RateLimitExceededException, Github\n",
    "\n",
    "# Providing access token\n",
    "access_token = \"\"\n",
    "g = Github(login_or_token=access_token)\n",
    "\n",
    "# Confirm your login is successful\n",
    "user = g.get_user()\n",
    "print(f\"Authenticated as: {user.login}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data files\n",
    "\n",
    "Path to output files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "STEP1_HCLREPOS =   os.path.join(\"data2\", \"step1-hcl-repositories.txt\")\n",
    "STEP2_TFREPOS =    os.path.join(\"data2\", \"step2-tf-repositories.txt\")\n",
    "STEP2_404REPOS =   os.path.join(\"data2\", \"step2-404-repositories.txt\")\n",
    "STEP3_KWCOMMITS =  os.path.join(\"data2\", \"step3-keyword-commits.json\")\n",
    "STEP3_ERRORREPOS = os.path.join(\"data2\", \"step3-error-repositories.txt\")\n",
    "STEP4_TFCOMMITS =  os.path.join(\"data2\", \"step4-tf-commits.json\")\n",
    "STEP5_TFISSUES =  os.path.join(\"data2\", \"step5-tf-issues.json\")\n",
    "STEP5_TFISSUES_ERROR =  os.path.join(\"data2\", \"step5-tf-issues-error-list.json\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Steps\n",
    "\n",
    "The steps to collect the data used for both RQ1 (commits) and RQ2 (issues)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Step 1 - Recover GitHub repositories containing HCL IaC\n",
    "\n",
    "For each day from 2014, query the GitHub search API for repositories that use HCL as language.\n",
    "Some dates queried do not exist, an exception is caught to avoid interruptions.\n",
    "\n",
    "Every repository is saved in '`data/step1-hcl-repositories.txt`' so no progress is lost in case of interruptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping month 1 of year 2014\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m date \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonth\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mday\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 11\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# sleep to reset API search limit\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     repos \u001b[38;5;241m=\u001b[39m g\u001b[38;5;241m.\u001b[39msearch_repositories(query\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreated:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m language:HCL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m repo \u001b[38;5;129;01min\u001b[39;00m repos:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "script_urls = []\n",
    "for year in range(2014, 2023):\n",
    "    for month in range(1, 13):\n",
    "        print(f\"Scraping month {month} of year {year}\")\n",
    "        for day in range(1, 32):\n",
    "            # Formatting compatible with search parameters\n",
    "            date = f\"{year}-{month:02d}-{day:02d}\"\n",
    "            try:\n",
    "                time.sleep(2)  # sleep to reset API search limit\n",
    "                repos = g.search_repositories(query=f\"created:{date} language:HCL\")\n",
    "                for repo in repos:\n",
    "                    time.sleep(0.2)  # sleep to reset API core limit\n",
    "                    # URLs are added to a txt file to avoid data loss\n",
    "                    with open(STEP1_HCLREPOS, \"a\") as file:\n",
    "                        file.write(f\"{repo.clone_url}\\n\")\n",
    "                    script_urls.append(repo.clone_url)\n",
    "            except RateLimitExceededException:\n",
    "                print(\"Rate Limit Exception reached!\")\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                # These are impossible dates (31-2-2022)\n",
    "                print(f\"Skipping: {date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Number of HCL repositories obtained\n",
    "print(len(script_urls))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Step 2 - Filter repositories with Terraform files\n",
    "\n",
    "Read the repositories from the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%# read urls from the file and strip the '\\n'\n"
    }
   },
   "outputs": [],
   "source": [
    "# read urls from the file and strip the '\\n'\n",
    "gitUrls_file = open(STEP1_HCLREPOS, \"r\")\n",
    "repo_links = gitUrls_file.readlines()\n",
    "repo_links = [repo.strip() for repo in repo_links]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Scan the content of each repository looking for files with extension '`.tf`' and '`.tf.json`' (i.e., Terraform artifact files).\n",
    "\n",
    "Suitable repositories are saved in '`data/step2-tf-repositories.txt`'.\n",
    "\n",
    "Repositories that are not reachable for any reason are saved in '`data/step2-404-repositories.txt`'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got to 0\n",
      "Got to 100\n",
      "Got to 200\n",
      "Got to 300\n",
      "Got to 400\n",
      "Got to 500\n",
      "Got to 600\n",
      "404 {\"message\": \"Not Found\", \"documentation_url\": \"https://docs.github.com/rest/repos/repos#get-a-repository\"}\n",
      "https://github.com/davidjyeo/az_multi_region.git\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Request GET /repos/aidapsibr/budget-az-network failed with 403: Forbidden\n",
      "Setting next backoff to 707.450359s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got to 700\n",
      "Got to 800\n",
      "Got to 900\n",
      "Got to 1000\n",
      "Got to 1100\n",
      "Got to 1200\n",
      "Got to 1300\n",
      "404 {\"message\": \"Not Found\", \"documentation_url\": \"https://docs.github.com/rest\"}\n",
      "https://github.com/FM1337/.github.git\n",
      "Got to 1400\n",
      "Got to 1500\n",
      "Got to 1600\n",
      "Got to 1700\n",
      "Got to 1800\n",
      "Got to 1900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Request GET /repos/ssoogur/TerraformExecute failed with 403: Forbidden\n",
      "Setting next backoff to 1338.896339s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got to 2000\n",
      "Got to 2100\n",
      "404 {\"message\": \"Not Found\", \"documentation_url\": \"https://docs.github.com/rest\"}\n",
      "https://github.com/LandmakTechnology/.github-workflows-terra.git\n",
      "Got to 2200\n",
      "Got to 2300\n",
      "Got to 2400\n",
      "Got to 2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Request GET /repos/RoshanFathima/FinalProjectGroup13/contents/prod failed with 403: Forbidden\n",
      "Setting next backoff to 1369.540823s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m file_content \u001b[38;5;241m=\u001b[39m contents\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_content\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdir\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 26\u001b[0m     contents\u001b[38;5;241m.\u001b[39mextend(\u001b[43mrepo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_contents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_content\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file_content\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(key \u001b[38;5;129;01min\u001b[39;00m file_content\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m terraform_keywords):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/github/Repository.py:2171\u001b[0m, in \u001b[0;36mRepository.get_contents\u001b[0;34m(self, path, ref)\u001b[0m\n\u001b[1;32m   2169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_defined(ref):\n\u001b[1;32m   2170\u001b[0m     url_parameters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mref\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ref\n\u001b[0;32m-> 2171\u001b[0m headers, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_requester\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequestJsonAndCheck\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2172\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2173\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/contents/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquote\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2175\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2177\u001b[0m \u001b[38;5;66;03m# Handle 302 redirect response\u001b[39;00m\n\u001b[1;32m   2178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m headers\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m302 Found\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m headers\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/github/Requester.py:548\u001b[0m, in \u001b[0;36mRequester.requestJsonAndCheck\u001b[0;34m(self, verb, url, parameters, headers, input)\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequestJsonAndCheck\u001b[39m(\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    542\u001b[0m     verb: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    546\u001b[0m     \u001b[38;5;28minput\u001b[39m: Optional[Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    547\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Any]:\n\u001b[0;32m--> 548\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__check(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequestJson\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__customConnection\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/github/Requester.py:713\u001b[0m, in \u001b[0;36mRequester.requestJson\u001b[0;34m(self, verb, url, parameters, headers, input, cnx)\u001b[0m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode\u001b[39m(\u001b[38;5;28minput\u001b[39m: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m, json\u001b[38;5;241m.\u001b[39mdumps(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m--> 713\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__requestEncode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcnx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/github/Requester.py:810\u001b[0m, in \u001b[0;36mRequester.__requestEncode\u001b[0;34m(self, cnx, verb, url, parameters, requestHeaders, input, encode)\u001b[0m\n\u001b[1;32m    806\u001b[0m     requestHeaders[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m], encoded_input \u001b[38;5;241m=\u001b[39m encode(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNEW_DEBUG_FRAME(requestHeaders)\n\u001b[0;32m--> 810\u001b[0m status, responseHeaders, output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__requestRaw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcnx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequestHeaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoded_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Consts\u001b[38;5;241m.\u001b[39mheaderRateRemaining \u001b[38;5;129;01min\u001b[39;00m responseHeaders \u001b[38;5;129;01mand\u001b[39;00m Consts\u001b[38;5;241m.\u001b[39mheaderRateLimit \u001b[38;5;129;01min\u001b[39;00m responseHeaders:\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrate_limiting \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# ints expected but sometimes floats returned: https://github.com/PyGithub/PyGithub/pull/2697\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mfloat\u001b[39m(responseHeaders[Consts\u001b[38;5;241m.\u001b[39mheaderRateRemaining])),\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mfloat\u001b[39m(responseHeaders[Consts\u001b[38;5;241m.\u001b[39mheaderRateLimit])),\n\u001b[1;32m    817\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/github/Requester.py:844\u001b[0m, in \u001b[0;36mRequester.__requestRaw\u001b[0;34m(self, cnx, verb, url, requestHeaders, input)\u001b[0m\n\u001b[1;32m    842\u001b[0m     cnx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__createConnection()\n\u001b[1;32m    843\u001b[0m cnx\u001b[38;5;241m.\u001b[39mrequest(verb, url, \u001b[38;5;28minput\u001b[39m, requestHeaders)\n\u001b[0;32m--> 844\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mcnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    846\u001b[0m status \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus\n\u001b[1;32m    847\u001b[0m responseHeaders \u001b[38;5;241m=\u001b[39m {k\u001b[38;5;241m.\u001b[39mlower(): v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m response\u001b[38;5;241m.\u001b[39mgetheaders()}\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/github/Requester.py:196\u001b[0m, in \u001b[0;36mHTTPSRequestsConnectionClass.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    194\u001b[0m verb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverb\u001b[38;5;241m.\u001b[39mlower())\n\u001b[1;32m    195\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprotocol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 196\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mverb\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m RequestsResponse(r)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/requests/sessions.py:602\u001b[0m, in \u001b[0;36mSession.get\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[1;32m    595\u001b[0m \n\u001b[1;32m    596\u001b[0m \u001b[38;5;124;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;124;03m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;124;03m:rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    601\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 602\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:892\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[1;32m    891\u001b[0m response\u001b[38;5;241m.\u001b[39mdrain_conn()\n\u001b[0;32m--> 892\u001b[0m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    893\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetry: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url)\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[1;32m    895\u001b[0m     method,\n\u001b[1;32m    896\u001b[0m     url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw\n\u001b[1;32m    908\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/urllib3/util/retry.py:432\u001b[0m, in \u001b[0;36mRetry.sleep\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m slept:\n\u001b[1;32m    430\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 432\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sleep_backoff\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/urllib3/util/retry.py:416\u001b[0m, in \u001b[0;36mRetry._sleep_backoff\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backoff \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 416\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackoff\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def current_milli_time():\n",
    "    return round(time.time() * 1000)\n",
    "\n",
    "lastTime = current_milli_time()\n",
    "\n",
    "counter = 0\n",
    "terraform_keywords = ['.tf', '.tf.json']\n",
    "terraform_relevant_repos = []\n",
    "for repo_url in repo_links:\n",
    "    if counter % 100 == 0:\n",
    "        print(f'Got to {counter}')\n",
    "    try:\n",
    "        # check if last operation was faster than 750 milliseconds, \n",
    "        # if so wait until at least 750 milliseconds since last api call.\n",
    "        if (lastTime + 750 > current_milli_time()):\n",
    "            time.sleep((lastTime + 750 - current_milli_time()) / 1000)  # sleep for API search limit\n",
    "        lastTime = current_milli_time()\n",
    "        \n",
    "        split_list = repo_url.split(\"/\")\n",
    "        actual_url = split_list[3]+ '/' + split_list[4]\n",
    "        repo = g.get_repo(actual_url.split('.git')[0])\n",
    "        contents = repo.get_contents('')\n",
    "        while contents:\n",
    "            file_content = contents.pop(0)\n",
    "            if file_content.type == \"dir\":\n",
    "                contents.extend(repo.get_contents(file_content.path))\n",
    "            else:\n",
    "                if file_content.name is not None and any(key in file_content.name.lower() for key in terraform_keywords):\n",
    "                    terraform_relevant_repos.append(repo_url)\n",
    "                    with open(STEP2_TFREPOS, \"a\") as file:\n",
    "                        file.write(f\"{repo_url}\\n\")\n",
    "                    break\n",
    "        counter += 1\n",
    "    except RateLimitExceededException:\n",
    "        print(\"Rate Limit Exception reached!\")\n",
    "    except Exception as e:\n",
    "        print(f\"{e}\\n{repo_url}\")\n",
    "        with open(STEP2_404REPOS, \"a\") as file:\n",
    "            file.write(f\"{repo_url}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Step 3 - Extract commits with cost-related keywords"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Read the previously filtered Terraform repositories. \n",
    "\n",
    "Then style a keyword list meant to be used in the commit message filtering phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189512\n"
     ]
    }
   ],
   "source": [
    "# read urls from the file and strip the '\\n'\n",
    "all_repos = open(STEP2_TFREPOS, \"r\")\n",
    "repo_links = [repo.strip() for repo in all_repos.readlines()]\n",
    "cost_keywords = [\"cheap\", \"expens\", \"cost\", \"efficient\", \"bill\", \"pay\"]\n",
    "print(len(repo_links))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Using PyDriller, traverse the commits of each repository.\n",
    "\n",
    "For every commit containing one or more keywords in its message, extract **commit id**, **message**, **date** and **list of modified files**.\n",
    "\n",
    "The final list of extracted commits is saved as JSON in '`data/step3-keyword-commits.json`'.\n",
    "\n",
    "If an error occur while trying to access a commit, the repository URL is saved in '`data/step3-error-repositories.txt`'.\n",
    "\n",
    "> NOTES:\n",
    "> - To foster privacy, we only save the information needed for the study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'repo_links' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m relevant_repos \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m repo \u001b[38;5;129;01min\u001b[39;00m \u001b[43mrepo_links\u001b[49m:\n\u001b[1;32m      7\u001b[0m     commits \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m count \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'repo_links' is not defined"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pydriller import Repository\n",
    "\n",
    "relevant_repos = []\n",
    "count = 0\n",
    "for repo in repo_links:\n",
    "    commits = []\n",
    "\n",
    "    if count % 100 == 0:\n",
    "        print(\"Got to {}\".format(count))\n",
    "\n",
    "    try:\n",
    "        # For each commit in the repository\n",
    "        for commit in Repository(repo).traverse_commits():\n",
    "            # If any of the keyword appear in the commit message\n",
    "            if commit.msg is not None and any(key in commit.msg.lower() for key in cost_keywords):\n",
    "                changed_files = []\n",
    "                # Save the modified files\n",
    "                for file in commit.modified_files:\n",
    "                    changed_files.append(file.filename)\n",
    "                commit_dic = {\"id\": commit.hash, \n",
    "                              \"msg\":commit.msg, \n",
    "                              \"date\":str(commit.author_date),\n",
    "                              \"modified_files\": changed_files}\n",
    "                commits.append(commit_dic)\n",
    "        repo_dic = {\"name\":repo, \"commits\":commits}\n",
    "\n",
    "        # Mark the repository as relevant if it has any relevant commits\n",
    "        if len(commits) != 0:\n",
    "            relevant_repos.append(repo_dic)\n",
    "    except Exception as e:\n",
    "        # so that we document what errors can happen when accessing commits\n",
    "        print(f\"{e}\\n{repo}\")\n",
    "        with open(STEP3_ERRORREPOS, \"a\") as file:\n",
    "            file.write(f\"{repo}\\n\")\n",
    "    count = count + 1\n",
    "\n",
    "output = {\"no_of_repos\":len(relevant_repos) ,\"repositories\": relevant_repos}\n",
    "with open(STEP3_KWCOMMITS, \"w\") as outfile:\n",
    "    json.dump(output, outfile)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ1 - Commit Collection\n",
    "\n",
    "From the remaning tasks for RQ1, the only automation was the selection of commits that modify Terraform files.\n",
    "\n",
    "That means, the removal of commits from forks, the filtering by relevance and the coding were manual steps and are not covered in this script.\n",
    "\n",
    "The final result (i.e., set of units of analysis pertaining to commits) can be found in the file '`dataset.json`'."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Filter commits that modify Terraform files \n",
    "\n",
    "Refines the previous JSON file so that only commits that modify '`.tf`' and '`.tf.json`' files are taken into consideration.\n",
    "\n",
    "The final list of filtered commits is saved as JSON in '`data/step4-tf-commits.json`'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2945\n",
      "Identified 1485\n"
     ]
    }
   ],
   "source": [
    "# Opening JSON file\n",
    "terraform_output = open(STEP3_KWCOMMITS)\n",
    "selected_repos = json.load(terraform_output)\n",
    "\n",
    "filtered_repos = []\n",
    "terraform_keywords = ['.tf', '.tf.json']\n",
    "print(len(selected_repos[\"repositories\"]))\n",
    "\n",
    "for repo in selected_repos[\"repositories\"]:\n",
    "    relevant_commits = []\n",
    "    flag = False\n",
    "    for commit in repo[\"commits\"]:\n",
    "        for mod_file in commit[\"modified_files\"]:\n",
    "            if mod_file is not None and any(key in mod_file for key in terraform_keywords):\n",
    "                relevant_commits.append(commit)\n",
    "                flag = True\n",
    "                break\n",
    "\n",
    "    if flag:\n",
    "        # new_commit_repo = {\"name\":repo[\"name\"], \"commits\":relevant_commits}\n",
    "        repo[\"commits\"] = relevant_commits\n",
    "        filtered_repos.append(repo)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Identified {len(filtered_repos)}\")\n",
    "\n",
    "output = {\"no_of_repos\":len(filtered_repos) ,\"repositories\": filtered_repos}\n",
    "with open(STEP4_TFCOMMITS, \"w\") as outfile:\n",
    "    json.dump(output, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3682\n",
      "2993\n"
     ]
    }
   ],
   "source": [
    "with open(STEP4_TFCOMMITS, \"r\") as input1:\n",
    "    relevant_repos = json.load(input1)\n",
    "\n",
    "commits = []\n",
    "for repo in relevant_repos[\"repositories\"]:\n",
    "    for com in repo[\"commits\"]:\n",
    "        commits.append(com[\"id\"])\n",
    "print(len(commits))\n",
    "print(len(set(commits)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ2 - Issue Collection\n",
    "\n",
    "From the remaning tasks for RQ2, the only automation was the collection of issues that contain one or more keywords.\n",
    "\n",
    "That means, the filtering by relevance and the coding were manual steps and are not covered in this script.\n",
    "\n",
    "The final result (i.e., set of units of analysis pertaining to issues) can be found in the file '`dataset.json`'."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting issues from repositories with keywords\n",
    "\n",
    "Take the repository URLs from all the commits that contain at least one of our keywords (i.e., from '`data/step3-keyword-commits.json`').\n",
    "\n",
    "Use Perceval to extract any issue that contains a cost-related keyword in either the title, body or comments.\n",
    "\n",
    "This process is time-consuming. If the GitHub API limit is reached, a proper waiting time is set by calculating how long it takes to reset the limits.\n",
    "\n",
    "The final list of collected issues is saved as JSON in '`step5-tf-issues.json`'.\n",
    "\n",
    "If an error occur while trying to extract an issue, the repository URL is saved in '`step5-tf-issues-error-list.json`' for re-assessment and re-download (if applicable).\n",
    "\n",
    "> NOTES:\n",
    "> - To foster privacy, we only save the information needed for the study\n",
    "> - The output file provided in this repository has been anonymized and manually inspected to replace usernames in text with '`@user`'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import calendar\n",
    "from perceval.backends.core.github import GitHub as pGithub\n",
    "from github import Github\n",
    "from pathlib import Path\n",
    "\n",
    "# Opening JSON file\n",
    "terraform_output = open(STEP3_KWCOMMITS)\n",
    "selected_repos = json.load(terraform_output)\n",
    "\n",
    "# Get list of repositories that contain commits with related keywords (i.e., step 3 output)\n",
    "terraform_keyworded_urls = [entry['name'] for entry in selected_repos['repositories']]\n",
    "\n",
    "# Extract issues from the repositories\n",
    "relevant_repos = []\n",
    "count = 0\n",
    "for repo in terraform_keyworded_urls:\n",
    "    print(repo)\n",
    "    time.sleep(2)\n",
    "    count += 1\n",
    "    try:\n",
    "        if count % 50 == 0:\n",
    "            time.sleep(120)\n",
    "            print(f\"At: {count}\")\n",
    "\n",
    "        # Extracting owner username and repository name from the URL\n",
    "        owner = repo.split('/')[3]\n",
    "        repository = \".\".join(repo.split('/')[4].split('.')[:-1])\n",
    "        fetched = pGithub(owner=owner, repository=repository, api_token=[access_token])\n",
    "        issue_list = []\n",
    "\n",
    "        for item in fetched.fetch():\n",
    "            time.sleep(1)\n",
    "            # do not save pull requests\n",
    "            if 'pull_request' in item_data:\n",
    "                continue\n",
    "            \n",
    "            # initialize all entries in case of empty fields (to prevent errors)\n",
    "            item_data = item['data']\n",
    "            title_flag = False\n",
    "            body_flag = False\n",
    "            comment_flag = False\n",
    "\n",
    "            # If title, body or comments contain any of the keywords, then the issue is relevant\n",
    "            if 'title' in item_data and item_data['title'] is not None and any(key in item_data['title'] for key in cost_keywords):\n",
    "                title_flag = True\n",
    "            elif 'body' in item_data and item_data['body'] is not None and any(key in item_data['body'] for key in cost_keywords):\n",
    "                    body_flag = True\n",
    "            elif 'comments_data' in item_data and 'comments_data' is not None:\n",
    "                for comment in item_data['comments_data']:\n",
    "                    if 'body' in comment and comment['body'] is not None and any(key in comment['body'] for key in cost_keywords):\n",
    "                        comment_flag = True\n",
    "                        break\n",
    "\n",
    "            time.sleep(1)\n",
    "\n",
    "            if title_flag or body_flag or comment_flag:\n",
    "                print(\"-adding elements to dictionary\")\n",
    "                issue_dict = {\n",
    "                'title': '' if 'title' not in item_data else item_data['title'],\n",
    "                'html_url': None if 'html_url' not in item_data else item_data['html_url'],\n",
    "                'body': '' if 'body' not in item_data else item_data['body'],\n",
    "                'comments_data': [] if 'comments_data' not in item_data else item_data['comments_data']\n",
    "                }\n",
    "                issue_dict['comments_data'] = [c['body'] for c in issue_dict['comments_data'] if c.get('body')]\n",
    "                issue_list.append(issue_dict)\n",
    "\n",
    "        repo_dic = {\"name\":repo, \"issues\":issue_list}\n",
    "        if len(issue_list) > 0:\n",
    "            relevant_repos.append(repo_dic)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Repo: {repo} failed\")\n",
    "        print(e)\n",
    "        core_rate_limit = g.get_rate_limit().core\n",
    "        reset_timestamp = calendar.timegm(core_rate_limit.reset.timetuple())\n",
    "        sleep_time = reset_timestamp - calendar.timegm(time.gmtime()) + 5  # add 5 seconds to be sure the rate limit has been reset\n",
    "        time.sleep(sleep_time)\n",
    "        with open(STEP5_TFISSUES_ERROR, \"a\") as file:\n",
    "            file.write(f\"{repo}\\n\")\n",
    "\n",
    "\n",
    "output = {\"no_of_repos\":len(relevant_repos) ,\"repositories\": relevant_repos}\n",
    "with open(STEP5_TFISSUES, \"w\") as outfile:\n",
    "    json.dump(output, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
